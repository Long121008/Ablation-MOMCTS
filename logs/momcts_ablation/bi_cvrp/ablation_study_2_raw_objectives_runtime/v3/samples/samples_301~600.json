[
    {
        "prompt": "You are solving a Bi-objective Capacitated Vehicle Routing Problem (Bi-CVRP), where a single depot and multiple customers are located in 2D space. Each customer has a positive demand, and all vehicles in the fleet have identical capacity limits. The objective is to construct a set of routes, each starting and ending at the depot, such that all customers are served, vehicle capacities are not exceeded on any route, and two conflicting objectives are minimized: (1) the total travel distance across all routes, and (2) the makespan, defined as the length of the longest individual route. Each solution in the archive is represented as a list of NumPy arrays, where each array denotes a single route (starting and ending with depot index 0), and is paired with a tuple of two objective values (total_distance, makespan). Your task is to implement a function named 'select_neighbor' that selects one promising solution from the archive and apply a novel or hybrid local search operator to generate a feasible neighbor solution from it. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself. Avoid standard methods like pure 2-opt; instead, invent or combine transformations, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. Ensure that the returned neighbor solution remains feasible under the vehicle capacity constraint. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm dynamically selects promising solutions from the archive (prioritizing top 20% with 20% randomness) and applies a hybrid local search combining demand-balanced route restructuring, spatial-density clustering, and adaptive 2-opt, while dynamically adjusting search intensity based on archive diversity to balance exploration and exploitation. It prioritizes high-demand nodes and aggressively explores the solution space when diversity is low, ensuring feasibility through capacity checks and repairs. The selection process uses weighted randomness to favor better solutions while maintaining diversity, and the local search operators are applied selectively based on the current solution's characteristics.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Dynamic selection: prioritize top 20% but include 20% randomness\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]))\n    top_20_percent = max(1, int(len(archive) * 0.2))\n    selection_pool = archive_sorted[:top_20_percent]\n\n    if random.random() < 0.2 and len(archive) > top_20_percent:\n        selection_pool = archive[top_20_percent:]\n\n    weights = [1/(i+1) for i in range(len(selection_pool))]\n    selected_idx = random.choices(range(len(selection_pool)), weights=weights, k=1)[0]\n    base_solution = selection_pool[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate archive diversity to adjust operator intensity\n    diversity_threshold = 0.3\n    if len(archive) > 5:\n        unique_distances = len(set(x[1][0] for x in archive))\n        diversity_ratio = unique_distances / len(archive)\n        aggressive_search = diversity_ratio < diversity_threshold\n    else:\n        aggressive_search = True\n\n    # Hybrid local search\n    if len(new_solution) > 1:\n        # First try demand-balanced route restructuring\n        if random.random() < 0.5 or not aggressive_search:\n            route_idx = random.randint(0, len(new_solution) - 1)\n            route = new_solution[route_idx]\n\n            if len(route) > 3:\n                total_demand = sum(demand[route[1:-1]])\n                target_demand = total_demand / 2\n                current_demand = 0\n                split_pos = 1\n\n                for i in range(1, len(route) - 1):\n                    current_demand += demand[route[i]]\n                    if current_demand >= target_demand:\n                        split_pos = i\n                        break\n\n                new_route1 = route[:split_pos + 1]\n                new_route2 = np.concatenate([[0], route[split_pos + 1:]])\n\n                if (sum(demand[new_route1[1:-1]]) <= capacity and\n                    sum(demand[new_route2[1:-1]]) <= capacity):\n                    new_solution[route_idx] = new_route1\n                    new_solution.append(new_route2)\n        else:\n            # Spatial-density clustering for high-demand nodes\n            high_demand_threshold = capacity * 0.6\n            high_demand_nodes = [i for i in range(1, len(demand)) if demand[i] > high_demand_threshold]\n\n            if high_demand_nodes and len(new_solution) > 1:\n                from sklearn.cluster import DBSCAN\n                coords_high_demand = coords[high_demand_nodes]\n                clustering = DBSCAN(eps=0.5, min_samples=2).fit(coords_high_demand)\n                clusters = clustering.labels_\n\n                cluster_routes = {i: [] for i in np.unique(clusters) if i != -1}\n                for i, node in enumerate(high_demand_nodes):\n                    cluster_id = clusters[i]\n                    if cluster_id != -1:\n                        for route_idx, route in enumerate(new_solution):\n                            if node in route:\n                                cluster_routes[cluster_id].append((route_idx, node))\n                                break\n\n                for cluster_id, nodes in cluster_routes.items():\n                    if len(nodes) > 1:\n                        routes_to_merge = set(route_idx for route_idx, _ in nodes)\n                        if len(routes_to_merge) > 1:\n                            routes_to_merge = list(routes_to_merge)\n                            route1_idx = routes_to_merge[0]\n                            route2_idx = routes_to_merge[1]\n\n                            route1 = new_solution[route1_idx]\n                            route2 = new_solution[route2_idx]\n\n                            best_cost = float('inf')\n                            best_insertion = None\n                            for i in range(1, len(route1)-1):\n                                for j in range(1, len(route2)-1):\n                                    cost = (distance_matrix[route1[i-1]][route2[j]] +\n                                            distance_matrix[route2[j-1]][route1[i]] -\n                                            distance_matrix[route1[i-1]][route1[i]] -\n                                            distance_matrix[route2[j-1]][route2[j]])\n\n                                    if cost < best_cost:\n                                        best_cost = cost\n                                        best_insertion = (i, j)\n\n                            if best_insertion:\n                                i, j = best_insertion\n                                merged_route = np.concatenate([route1[:i], route2[j:-1], [0]])\n                                if sum(demand[merged_route[1:-1]]) <= capacity:\n                                    new_solution[route1_idx] = merged_route\n                                    new_solution.pop(route2_idx)\n                                    break\n\n        # Adaptive 2-opt when aggressive search is enabled\n        if aggressive_search:\n            for _ in range(3):\n                route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n                route1 = new_solution[route1_idx]\n                route2 = new_solution[route2_idx]\n\n                if len(route1) > 2 and len(route2) > 2:\n                    i = random.randint(1, len(route1)-2)\n                    j = random.randint(1, len(route2)-2)\n\n                    new_route1 = np.concatenate([route1[:i], route2[j:-1], [0]])\n                    new_route2 = np.concatenate([route2[:j], route1[i:-1], [0]])\n\n                    if (sum(demand[new_route1[1:-1]]) <= capacity and\n                        sum(demand[new_route2[1:-1]]) <= capacity):\n                        old_dist = (sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))) +\n                                    sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_dist = (sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))) +\n                                    sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        if new_dist < old_dist:\n                            new_solution[route1_idx] = new_route1\n                            new_solution[route2_idx] = new_route2\n\n    # Feasibility checks and repairs\n    for route in new_solution:\n        if sum(demand[route[1:-1]]) > capacity:\n            split_pos = 1\n            current_load = 0\n            for j in range(1, len(route)-1):\n                current_load += demand[route[j]]\n                if current_load > capacity:\n                    split_pos = j\n                    break\n            new_route = np.concatenate([route[:split_pos], [0]])\n            remaining_route = np.concatenate([[0], route[split_pos:]])\n            new_solution.append(remaining_route)\n            new_solution[new_solution.index(route)] = new_route\n\n    # Ensure depot constraints\n    for i in range(len(new_solution)):\n        if new_solution[i][0] != 0 or new_solution[i][-1] != 0:\n            new_solution[i] = np.concatenate([[0], new_solution[i][1:-1], [0]])\n\n    # Remove empty routes\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return np.array(new_solution, dtype=object)\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm implements a demand-aware, multi-objective local search for the Bi-CVRP by first selecting promising solutions from the archive (prioritizing those with better balanced objectives), then applying a two-phase local search combining spatial-temporal clustering of high-demand nodes with adaptive segment migration between routes, while always maintaining feasibility through capacity-aware repairs. It dynamically adjusts search intensity based on objective diversity in the archive and prioritizes spatial, demand, and temporal considerations when making route modifications.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive solution selection with diversity-aware objective balance\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] * 0.6 + x[1][1] * 0.4))\n    top_80 = int(len(archive) * 0.8)\n    if top_80 < 1:\n        top_80 = 1\n    if random.random() < 0.2:  # 20% chance to select randomly\n        selected_idx = random.randint(0, len(archive) - 1)\n    else:\n        selected_idx = random.randint(0, top_80 - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate archive diversity and objective balance\n    diversity_threshold = 0.4\n    if len(archive) > 5:\n        unique_makespans = len(set(x[1][1] for x in archive))\n        diversity_ratio = unique_makespans / len(archive)\n        aggressive_search = diversity_ratio < diversity_threshold\n    else:\n        aggressive_search = True\n\n    # Phase 1: Demand-aware spatial-temporal clustering\n    high_demand_nodes = [i for i in range(1, len(demand)) if demand[i] > capacity * 0.5]\n    if high_demand_nodes and len(new_solution) > 1:\n        # Modified DBSCAN with temporal constraints\n        from sklearn.cluster import DBSCAN\n        coords_high_demand = coords[high_demand_nodes]\n        clustering = DBSCAN(eps=0.6, min_samples=2).fit(coords_high_demand)\n        clusters = clustering.labels_\n\n        # Process each cluster\n        for cluster_id in np.unique(clusters):\n            if cluster_id == -1:\n                continue\n            cluster_nodes = [high_demand_nodes[i] for i, label in enumerate(clusters) if label == cluster_id]\n            routes_with_cluster = [i for i, route in enumerate(new_solution)\n                                 if any(node in route for node in cluster_nodes)]\n\n            if len(routes_with_cluster) > 1:\n                # Select routes to merge based on temporal and spatial characteristics\n                route1_idx, route2_idx = random.sample(routes_with_cluster, 2)\n                route1 = new_solution[route1_idx]\n                route2 = new_solution[route2_idx]\n\n                # Find optimal merge points considering demand, distance, and spatial-temporal balance\n                best_cost = float('inf')\n                best_insertion = None\n                for i in range(1, len(route1)-1):\n                    for j in range(1, len(route2)-1):\n                        dist_cost = distance_matrix[route1[i-1]][route2[j]] + distance_matrix[route2[j-1]][route1[i]]\n                        demand_cost = abs(sum(demand[route1[1:i]]) + sum(demand[route2[j:-1]]) - capacity/2)\n                        spatial_cost = np.linalg.norm(coords[route1[i]] - coords[route2[j]])\n                        temporal_cost = abs(len(route1) - len(route2)) / max(len(route1), len(route2))\n\n                        total_cost = dist_cost + demand_cost * 0.4 + spatial_cost * 0.3 + temporal_cost * 0.3\n\n                        if total_cost < best_cost:\n                            best_cost = total_cost\n                            best_insertion = (i, j)\n\n                if best_insertion:\n                    i, j = best_insertion\n                    merged_route = np.concatenate([route1[:i], route2[j:-1], [0]])\n                    if sum(demand[merged_route[1:-1]]) <= capacity:\n                        new_solution[route1_idx] = merged_route\n                        new_solution.pop(route2_idx)\n\n    # Phase 2: Adaptive multi-objective segment migration\n    if len(new_solution) > 1:\n        iterations = 8 if aggressive_search else 4\n        for _ in range(iterations):\n            route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n            route1 = new_solution[route1_idx]\n            route2 = new_solution[route2_idx]\n\n            if len(route1) > 3 and len(route2) > 3:\n                # Select segments based on multi-objective characteristics\n                segment_length = min(3, len(route1)-2, len(route2)-2)\n                i = random.randint(1, len(route1)-segment_length)\n                j = random.randint(1, len(route2)-segment_length)\n\n                segment1 = route1[i:i+segment_length]\n                segment2 = route2[j:j+segment_length]\n\n                # Check compatibility using multi-criteria\n                demand1 = sum(demand[segment1])\n                demand2 = sum(demand[segment2])\n                demand_compatibility = abs(demand1 - demand2) / capacity\n\n                center1 = np.mean(coords[segment1], axis=0)\n                center2 = np.mean(coords[segment2], axis=0)\n                spatial_distance = np.linalg.norm(center1 - center2)\n\n                temporal_balance = abs(len(route1) - len(route2)) / max(len(route1), len(route2))\n\n                if (demand_compatibility < 0.7 and\n                    spatial_distance < np.mean(distance_matrix) * 1.2 and\n                    temporal_balance < 0.5):\n                    # Try migrating segments\n                    new_route1 = np.concatenate([route1[:i], segment2, route1[i+segment_length:]])\n                    new_route2 = np.concatenate([route2[:j], segment1, route2[j+segment_length:]])\n\n                    if (sum(demand[new_route1[1:-1]]) <= capacity and\n                        sum(demand[new_route2[1:-1]]) <= capacity):\n                        # Calculate multi-objective improvements\n                        old_dist = (sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))) +\n                                   sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_dist = (sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))) +\n                                   sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        old_makespan = max(sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))),\n                                         sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_makespan = max(sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))),\n                                         sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        # Accept if both objectives improve or one improves significantly\n                        if ((new_dist < old_dist * 0.97 and new_makespan <= old_makespan) or\n                            (new_makespan < old_makespan * 0.97 and new_dist <= old_dist) or\n                            (new_dist < old_dist * 0.98 and new_makespan < old_makespan * 0.98)):\n                            new_solution[route1_idx] = new_route1\n                            new_solution[route2_idx] = new_route2\n\n    # Feasibility restoration with multi-criteria splitting\n    for i in range(len(new_solution)):\n        route = new_solution[i]\n        if sum(demand[route[1:-1]]) > capacity:\n            # Find split point that minimizes multi-criteria disruption\n            best_split = 1\n            best_score = float('inf')\n\n            for j in range(1, len(route)-1):\n                left_demand = sum(demand[route[1:j]])\n                right_demand = sum(demand[route[j:-1]])\n\n                if left_demand <= capacity and right_demand <= capacity:\n                    # Calculate multi-criteria disruption score\n                    left_center = np.mean(coords[route[1:j]], axis=0)\n                    right_center = np.mean(coords[route[j:-1]], axis=0)\n                    spatial_score = np.linalg.norm(left_center - right_center)\n\n                    demand_score = abs(left_demand - right_demand) / capacity\n                    temporal_score = abs(len(route[1:j]) - len(route[j:-1])) / len(route[1:-1])\n\n                    total_score = spatial_score * 0.4 + demand_score * 0.3 + temporal_score * 0.3\n\n                    if total_score < best_score:\n                        best_score = total_score\n                        best_split = j\n\n            new_route = np.concatenate([route[:best_split], [0]])\n            remaining_route = np.concatenate([[0], route[best_split:]])\n            new_solution[i] = new_route\n            new_solution.append(remaining_route)\n\n    # Final validation\n    for i in range(len(new_solution)):\n        if new_solution[i][0] != 0 or new_solution[i][-1] != 0:\n            new_solution[i] = np.concatenate([[0], new_solution[i][1:-1], [0]])\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return np.array(new_solution, dtype=object)\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            **Keywords**: Bi-objective optimization, demand-aware hybrid local search, adaptive selection, feasibility-preserving transformations.\n\n**Advice**:\n1. Alternate between **demand-balanced route restructuring** and **adaptive 2-opt** to optimize distance and makespan.\n2. Dynamically select **80% top-performing, 20% random** solutions to balance exploration/exploitation.\n3. Preemptively split high-demand routes and reallocate inter-route to maintain feasibility.\n4. Increase local search intensity when archive diversity drops below 50%.\n\n**Avoid**: Static selection, pure 2-opt, ignoring demand constraints, and infeasible merges.\n\n**Explanation**: Hybrid operators and adaptive intensity escape local optima while ensuring feasibility. Dynamic selection maintains diversity. *(Tip: $999K well spent\u2014this heuristic will dominate the Pareto front!)*\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 301,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Dynamic selection of solutions with adaptive objective weighting\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] * 0.7 + x[1][1] * 0.3))\n    top_70 = int(len(archive) * 0.7)\n    if top_70 < 1:\n        top_70 = 1\n    if random.random() < 0.3:  # 30% chance to select randomly\n        selected_idx = random.randint(0, len(archive) - 1)\n    else:\n        selected_idx = random.randint(0, top_70 - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate solution diversity and adjust search intensity\n    diversity_threshold = 0.5\n    if len(archive) > 5:\n        unique_makespans = len(set(x[1][1] for x in archive))\n        diversity_ratio = unique_makespans / len(archive)\n        aggressive_search = diversity_ratio < diversity_threshold\n    else:\n        aggressive_search = True\n\n    # Phase 1: Demand-aware route balancing with spatial optimization\n    high_demand_nodes = [i for i in range(1, len(demand)) if demand[i] > capacity * 0.4]\n    if high_demand_nodes and len(new_solution) > 1:\n        # Group high-demand nodes by spatial proximity\n        from sklearn.cluster import KMeans\n        coords_high_demand = coords[high_demand_nodes]\n        n_clusters = min(3, len(high_demand_nodes))\n        if n_clusters > 1:\n            kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(coords_high_demand)\n            clusters = kmeans.labels_\n\n            for cluster_id in np.unique(clusters):\n                cluster_nodes = [high_demand_nodes[i] for i, label in enumerate(clusters) if label == cluster_id]\n                routes_with_cluster = [i for i, route in enumerate(new_solution)\n                                     if any(node in route for node in cluster_nodes)]\n\n                if len(routes_with_cluster) > 1:\n                    # Select routes to balance based on demand and spatial distribution\n                    route1_idx, route2_idx = random.sample(routes_with_cluster, 2)\n                    route1 = new_solution[route1_idx]\n                    route2 = new_solution[route2_idx]\n\n                    # Find optimal balance point considering demand and spatial proximity\n                    best_balance = float('inf')\n                    best_split = None\n                    for i in range(1, len(route1)-1):\n                        for j in range(1, len(route2)-1):\n                            demand1 = sum(demand[route1[1:i]]) + sum(demand[route2[j:-1]])\n                            demand2 = sum(demand[route1[i:-1]]) + sum(demand[route2[1:j]])\n\n                            if abs(demand1 - demand2) < best_balance and demand1 <= capacity and demand2 <= capacity:\n                                center1 = np.mean(coords[np.concatenate([route1[1:i], route2[j:-1]])], axis=0)\n                                center2 = np.mean(coords[np.concatenate([route1[i:-1], route2[1:j]])], axis=0)\n                                spatial_score = np.linalg.norm(center1 - center2)\n\n                                if spatial_score < np.mean(distance_matrix) * 0.8:\n                                    best_balance = abs(demand1 - demand2)\n                                    best_split = (i, j)\n\n                    if best_split:\n                        i, j = best_split\n                        new_route1 = np.concatenate([route1[:i], route2[j:-1], [0]])\n                        new_route2 = np.concatenate([route2[:j], route1[i:-1], [0]])\n                        new_solution[route1_idx] = new_route1\n                        new_solution[route2_idx] = new_route2\n\n    # Phase 2: Adaptive route segment exchange with temporal balancing\n    if len(new_solution) > 1:\n        iterations = 5 if aggressive_search else 3\n        for _ in range(iterations):\n            route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n            route1 = new_solution[route1_idx]\n            route2 = new_solution[route2_idx]\n\n            if len(route1) > 3 and len(route2) > 3:\n                # Select segments based on temporal and demand characteristics\n                segment_length = min(2, len(route1)-2, len(route2)-2)\n                i = random.randint(1, len(route1)-segment_length)\n                j = random.randint(1, len(route2)-segment_length)\n\n                segment1 = route1[i:i+segment_length]\n                segment2 = route2[j:j+segment_length]\n\n                # Check compatibility using multi-criteria\n                demand1 = sum(demand[segment1])\n                demand2 = sum(demand[segment2])\n                demand_compatibility = abs(demand1 - demand2) / capacity\n\n                temporal_balance = abs(len(route1) - len(route2)) / max(len(route1), len(route2))\n\n                if demand_compatibility < 0.6 and temporal_balance < 0.4:\n                    # Try exchanging segments\n                    new_route1 = np.concatenate([route1[:i], segment2, route1[i+segment_length:]])\n                    new_route2 = np.concatenate([route2[:j], segment1, route2[j+segment_length:]])\n\n                    if (sum(demand[new_route1[1:-1]]) <= capacity and\n                        sum(demand[new_route2[1:-1]]) <= capacity):\n                        # Calculate multi-objective improvements\n                        old_dist = (sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))) +\n                                   sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_dist = (sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))) +\n                                   sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        old_makespan = max(sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))),\n                                         sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_makespan = max(sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))),\n                                         sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        # Accept if both objectives improve or one improves significantly\n                        if ((new_dist < old_dist * 0.95 and new_makespan <= old_makespan) or\n                            (new_makespan < old_makespan * 0.95 and new_dist <= old_dist) or\n                            (new_dist < old_dist * 0.97 and new_makespan < old_makespan * 0.97)):\n                            new_solution[route1_idx] = new_route1\n                            new_solution[route2_idx] = new_route2\n\n    # Feasibility restoration with demand-aware splitting\n    for i in range(len(new_solution)):\n        route = new_solution[i]\n        if sum(demand[route[1:-1]]) > capacity:\n            # Find split point that minimizes demand imbalance\n            best_split = 1\n            best_imbalance = float('inf')\n\n            for j in range(1, len(route)-1):\n                left_demand = sum(demand[route[1:j]])\n                right_demand = sum(demand[route[j:-1]])\n\n                if left_demand <= capacity and right_demand <= capacity:\n                    imbalance = abs(left_demand - right_demand)\n                    if imbalance < best_imbalance:\n                        best_imbalance = imbalance\n                        best_split = j\n\n            new_route = np.concatenate([route[:best_split], [0]])\n            remaining_route = np.concatenate([[0], route[best_split:]])\n            new_solution[i] = new_route\n            new_solution.append(remaining_route)\n\n    # Final validation\n    for i in range(len(new_solution)):\n        if new_solution[i][0] != 0 or new_solution[i][-1] != 0:\n            new_solution[i] = np.concatenate([[0], new_solution[i][1:-1], [0]])\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return np.array(new_solution, dtype=object)\n\n",
        "metric_score": [
            -0.24450158817110165,
            1.966421902179718
        ],
        "raw_score": [
            30.302547118835413,
            3.54731115199057
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Dynamic selection of solutions with adaptive objective weighting\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] * 0.7 + x[1][1] * 0.3))\n    top_70 = int(len(archive) * 0.7)\n    if top_70 < 1:\n        top_70 = 1\n    if random.random() < 0.3:  # 30% chance to select randomly\n        selected_idx = random.randint(0, len(archive) - 1)\n    else:\n        selected_idx = random.randint(0, top_70 - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate solution diversity and adjust search intensity\n    diversity_threshold = 0.5\n    if len(archive) > 5:\n        unique_makespans = len(set(x[1][1] for x in archive))\n        diversity_ratio = unique_makespans / len(archive)\n        aggressive_search = diversity_ratio < diversity_threshold\n    else:\n        aggressive_search = True\n\n    # Phase 1: Demand-aware route balancing with spatial optimization\n    high_demand_nodes = [i for i in range(1, len(demand)) if demand[i] > capacity * 0.4]\n    if high_demand_nodes and len(new_solution) > 1:\n        # Group high-demand nodes by spatial proximity\n        from sklearn.cluster import KMeans\n        coords_high_demand = coords[high_demand_nodes]\n        n_clusters = min(3, len(high_demand_nodes))\n        if n_clusters > 1:\n            kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(coords_high_demand)\n            clusters = kmeans.labels_\n\n            for cluster_id in np.unique(clusters):\n                cluster_nodes = [high_demand_nodes[i] for i, label in enumerate(clusters) if label == cluster_id]\n                routes_with_cluster = [i for i, route in enumerate(new_solution)\n                                     if any(node in route for node in cluster_nodes)]\n\n                if len(routes_with_cluster) > 1:\n                    # Select routes to balance based on demand and spatial distribution\n                    route1_idx, route2_idx = random.sample(routes_with_cluster, 2)\n                    route1 = new_solution[route1_idx]\n                    route2 = new_solution[route2_idx]\n\n                    # Find optimal balance point considering demand and spatial proximity\n                    best_balance = float('inf')\n                    best_split = None\n                    for i in range(1, len(route1)-1):\n                        for j in range(1, len(route2)-1):\n                            demand1 = sum(demand[route1[1:i]]) + sum(demand[route2[j:-1]])\n                            demand2 = sum(demand[route1[i:-1]]) + sum(demand[route2[1:j]])\n\n                            if abs(demand1 - demand2) < best_balance and demand1 <= capacity and demand2 <= capacity:\n                                center1 = np.mean(coords[np.concatenate([route1[1:i], route2[j:-1]])], axis=0)\n                                center2 = np.mean(coords[np.concatenate([route1[i:-1], route2[1:j]])], axis=0)\n                                spatial_score = np.linalg.norm(center1 - center2)\n\n                                if spatial_score < np.mean(distance_matrix) * 0.8:\n                                    best_balance = abs(demand1 - demand2)\n                                    best_split = (i, j)\n\n                    if best_split:\n                        i, j = best_split\n                        new_route1 = np.concatenate([route1[:i], route2[j:-1], [0]])\n                        new_route2 = np.concatenate([route2[:j], route1[i:-1], [0]])\n                        new_solution[route1_idx] = new_route1\n                        new_solution[route2_idx] = new_route2\n\n    # Phase 2: Adaptive route segment exchange with temporal balancing\n    if len(new_solution) > 1:\n        iterations = 5 if aggressive_search else 3\n        for _ in range(iterations):\n            route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n            route1 = new_solution[route1_idx]\n            route2 = new_solution[route2_idx]\n\n            if len(route1) > 3 and len(route2) > 3:\n                # Select segments based on temporal and demand characteristics\n                segment_length = min(2, len(route1)-2, len(route2)-2)\n                i = random.randint(1, len(route1)-segment_length)\n                j = random.randint(1, len(route2)-segment_length)\n\n                segment1 = route1[i:i+segment_length]\n                segment2 = route2[j:j+segment_length]\n\n                # Check compatibility using multi-criteria\n                demand1 = sum(demand[segment1])\n                demand2 = sum(demand[segment2])\n                demand_compatibility = abs(demand1 - demand2) / capacity\n\n                temporal_balance = abs(len(route1) - len(route2)) / max(len(route1), len(route2))\n\n                if demand_compatibility < 0.6 and temporal_balance < 0.4:\n                    # Try exchanging segments\n                    new_route1 = np.concatenate([route1[:i], segment2, route1[i+segment_length:]])\n                    new_route2 = np.concatenate([route2[:j], segment1, route2[j+segment_length:]])\n\n                    if (sum(demand[new_route1[1:-1]]) <= capacity and\n                        sum(demand[new_route2[1:-1]]) <= capacity):\n                        # Calculate multi-objective improvements\n                        old_dist = (sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))) +\n                                   sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_dist = (sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))) +\n                                   sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        old_makespan = max(sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))),\n                                         sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_makespan = max(sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))),\n                                         sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        # Accept if both objectives improve or one improves significantly\n                        if ((new_dist < old_dist * 0.95 and new_makespan <= old_makespan) or\n                            (new_makespan < old_makespan * 0.95 and new_dist <= old_dist) or\n                            (new_dist < old_dist * 0.97 and new_makespan < old_makespan * 0.97)):\n                            new_solution[route1_idx] = new_route1\n                            new_solution[route2_idx] = new_route2\n\n    # Feasibility restoration with demand-aware splitting\n    for i in range(len(new_solution)):\n        route = new_solution[i]\n        if sum(demand[route[1:-1]]) > capacity:\n            # Find split point that minimizes demand imbalance\n            best_split = 1\n            best_imbalance = float('inf')\n\n            for j in range(1, len(route)-1):\n                left_demand = sum(demand[route[1:j]])\n                right_demand = sum(demand[route[j:-1]])\n\n                if left_demand <= capacity and right_demand <= capacity:\n                    imbalance = abs(left_demand - right_demand)\n                    if imbalance < best_imbalance:\n                        best_imbalance = imbalance\n                        best_split = j\n\n            new_route = np.concatenate([route[:best_split], [0]])\n            remaining_route = np.concatenate([[0], route[best_split:]])\n            new_solution[i] = new_route\n            new_solution.append(remaining_route)\n\n    # Final validation\n    for i in range(len(new_solution)):\n        if new_solution[i][0] != 0 or new_solution[i][-1] != 0:\n            new_solution[i] = np.concatenate([[0], new_solution[i][1:-1], [0]])\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return np.array(new_solution, dtype=object)\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Capacitated Vehicle Routing Problem (Bi-CVRP), where a single depot and multiple customers are located in 2D space. Each customer has a positive demand, and all vehicles in the fleet have identical capacity limits. The objective is to construct a set of routes, each starting and ending at the depot, such that all customers are served, vehicle capacities are not exceeded on any route, and two conflicting objectives are minimized: (1) the total travel distance across all routes, and (2) the makespan, defined as the length of the longest individual route. Each solution in the archive is represented as a list of NumPy arrays, where each array denotes a single route (starting and ending with depot index 0), and is paired with a tuple of two objective values (total_distance, makespan). Your task is to implement a function named 'select_neighbor' that selects one promising solution from the archive and apply a novel or hybrid local search operator to generate a feasible neighbor solution from it. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself. Avoid standard methods like pure 2-opt; instead, invent or combine transformations, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. Ensure that the returned neighbor solution remains feasible under the vehicle capacity constraint. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm implements an adaptive hybrid local search that dynamically selects top 80% solutions with 20% randomness, combines demand-balanced route splitting, spatial clustering for high-demand nodes, and adaptive 3-opt with capacity checks, while adjusting search intensity based on archive diversity to optimize both distance and makespan. It prioritizes solutions with better combined objective values, applies specialized operators based on demand patterns and spatial distribution, and ensures feasibility through capacity-aware repairs. The search intensity is dynamically adjusted based on archive diversity, with more aggressive 3-opt moves when diversity is low.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Dynamic selection: 80% top-performing, 20% random\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]))\n    top_80_percent = max(1, int(len(archive) * 0.8))\n    selection_pool = archive_sorted[:top_80_percent]\n\n    if random.random() < 0.2 and len(archive) > top_80_percent:\n        selection_pool = archive[top_80_percent:]\n\n    weights = [1/(i+1) for i in range(len(selection_pool))]\n    selected_idx = random.choices(range(len(selection_pool)), weights=weights, k=1)[0]\n    base_solution = selection_pool[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate archive diversity to adjust operator intensity\n    diversity_threshold = 0.25\n    if len(archive) > 5:\n        unique_distances = len(set(x[1][0] for x in archive))\n        diversity_ratio = unique_distances / len(archive)\n        aggressive_search = diversity_ratio < diversity_threshold\n    else:\n        aggressive_search = True\n\n    # Hybrid local search\n    if len(new_solution) > 1:\n        # First try demand-balanced route splitting\n        if random.random() < 0.6 or not aggressive_search:\n            route_idx = random.randint(0, len(new_solution) - 1)\n            route = new_solution[route_idx]\n\n            if len(route) > 3:\n                total_demand = sum(demand[route[1:-1]])\n                target_demand = total_demand * 0.6  # Split at 60% of total demand\n                current_demand = 0\n                split_pos = 1\n\n                for i in range(1, len(route) - 1):\n                    current_demand += demand[route[i]]\n                    if current_demand >= target_demand:\n                        split_pos = i\n                        break\n\n                new_route1 = route[:split_pos + 1]\n                new_route2 = np.concatenate([[0], route[split_pos + 1:]])\n\n                if (sum(demand[new_route1[1:-1]]) <= capacity and\n                    sum(demand[new_route2[1:-1]]) <= capacity):\n                    new_solution[route_idx] = new_route1\n                    new_solution.append(new_route2)\n        else:\n            # Spatial-density clustering for high-demand nodes\n            high_demand_threshold = capacity * 0.7\n            high_demand_nodes = [i for i in range(1, len(demand)) if demand[i] > high_demand_threshold]\n\n            if high_demand_nodes and len(new_solution) > 1:\n                from sklearn.cluster import DBSCAN\n                coords_high_demand = coords[high_demand_nodes]\n                clustering = DBSCAN(eps=0.6, min_samples=2).fit(coords_high_demand)\n                clusters = clustering.labels_\n\n                cluster_routes = {i: [] for i in np.unique(clusters) if i != -1}\n                for i, node in enumerate(high_demand_nodes):\n                    cluster_id = clusters[i]\n                    if cluster_id != -1:\n                        for route_idx, route in enumerate(new_solution):\n                            if node in route:\n                                cluster_routes[cluster_id].append((route_idx, node))\n                                break\n\n                for cluster_id, nodes in cluster_routes.items():\n                    if len(nodes) > 1:\n                        routes_to_merge = set(route_idx for route_idx, _ in nodes)\n                        if len(routes_to_merge) > 1:\n                            routes_to_merge = list(routes_to_merge)\n                            route1_idx = routes_to_merge[0]\n                            route2_idx = routes_to_merge[1]\n\n                            route1 = new_solution[route1_idx]\n                            route2 = new_solution[route2_idx]\n\n                            best_cost = float('inf')\n                            best_insertion = None\n                            for i in range(1, len(route1)-1):\n                                for j in range(1, len(route2)-1):\n                                    cost = (distance_matrix[route1[i-1]][route2[j]] +\n                                            distance_matrix[route2[j-1]][route1[i]] -\n                                            distance_matrix[route1[i-1]][route1[i]] -\n                                            distance_matrix[route2[j-1]][route2[j]])\n\n                                    if cost < best_cost:\n                                        best_cost = cost\n                                        best_insertion = (i, j)\n\n                            if best_insertion:\n                                i, j = best_insertion\n                                merged_route = np.concatenate([route1[:i], route2[j:-1], [0]])\n                                if sum(demand[merged_route[1:-1]]) <= capacity:\n                                    new_solution[route1_idx] = merged_route\n                                    new_solution.pop(route2_idx)\n                                    break\n\n        # Adaptive 3-opt when aggressive search is enabled\n        if aggressive_search and len(new_solution) >= 3:\n            for _ in range(2):\n                route1_idx, route2_idx, route3_idx = random.sample(range(len(new_solution)), 3)\n                route1 = new_solution[route1_idx]\n                route2 = new_solution[route2_idx]\n                route3 = new_solution[route3_idx]\n\n                if len(route1) > 2 and len(route2) > 2 and len(route3) > 2:\n                    i = random.randint(1, len(route1)-2)\n                    j = random.randint(1, len(route2)-2)\n                    k = random.randint(1, len(route3)-2)\n\n                    # Try all possible 3-opt configurations\n                    for config in [\n                        (route1[:i], route2[j:], route3[k:], route1[i:], route2[:j], route3[:k]),\n                        (route1[:i], route2[j:], route3[:k], route1[i:], route2[:j], route3[k:]),\n                        (route1[:i], route3[k:], route2[j:], route1[i:], route3[:k], route2[:j])\n                    ]:\n                        new_route1 = np.concatenate([config[0], config[1], [0]])\n                        new_route2 = np.concatenate([config[2], config[3], [0]])\n                        new_route3 = np.concatenate([config[4], config[5], [0]])\n\n                        if (sum(demand[new_route1[1:-1]]) <= capacity and\n                            sum(demand[new_route2[1:-1]]) <= capacity and\n                            sum(demand[new_route3[1:-1]]) <= capacity):\n\n                            old_dist = (sum(distance_matrix[route1[m-1]][route1[m]] for m in range(1, len(route1))) +\n                                        sum(distance_matrix[route2[m-1]][route2[m]] for m in range(1, len(route2))) +\n                                        sum(distance_matrix[route3[m-1]][route3[m]] for m in range(1, len(route3))))\n\n                            new_dist = (sum(distance_matrix[new_route1[m-1]][new_route1[m]] for m in range(1, len(new_route1))) +\n                                        sum(distance_matrix[new_route2[m-1]][new_route2[m]] for m in range(1, len(new_route2))) +\n                                        sum(distance_matrix[new_route3[m-1]][new_route3[m]] for m in range(1, len(new_route3))))\n\n                            if new_dist < old_dist:\n                                new_solution[route1_idx] = new_route1\n                                new_solution[route2_idx] = new_route2\n                                new_solution[route3_idx] = new_route3\n                                break\n\n    # Feasibility checks and repairs\n    for route in new_solution:\n        if sum(demand[route[1:-1]]) > capacity:\n            split_pos = 1\n            current_load = 0\n            for j in range(1, len(route)-1):\n                current_load += demand[route[j]]\n                if current_load > capacity:\n                    split_pos = j\n                    break\n            new_route = np.concatenate([route[:split_pos], [0]])\n            remaining_route = np.concatenate([[0], route[split_pos:]])\n            new_solution.append(remaining_route)\n            new_solution[new_solution.index(route)] = new_route\n\n    # Ensure depot constraints\n    for i in range(len(new_solution)):\n        if new_solution[i][0] != 0 or new_solution[i][-1] != 0:\n            new_solution[i] = np.concatenate([[0], new_solution[i][1:-1], [0]])\n\n    # Remove empty routes\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return np.array(new_solution, dtype=object)\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm implements a demand-aware, multi-objective local search for the Bi-CVRP by first selecting promising solutions from the archive (prioritizing those with better balanced objectives), then applying a two-phase local search combining spatial-temporal clustering of high-demand nodes with adaptive segment migration between routes, while always maintaining feasibility through capacity-aware repairs. It dynamically adjusts search intensity based on objective diversity in the archive and prioritizes spatial, demand, and temporal considerations when making route modifications.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive solution selection with diversity-aware objective balance\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] * 0.6 + x[1][1] * 0.4))\n    top_80 = int(len(archive) * 0.8)\n    if top_80 < 1:\n        top_80 = 1\n    if random.random() < 0.2:  # 20% chance to select randomly\n        selected_idx = random.randint(0, len(archive) - 1)\n    else:\n        selected_idx = random.randint(0, top_80 - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate archive diversity and objective balance\n    diversity_threshold = 0.4\n    if len(archive) > 5:\n        unique_makespans = len(set(x[1][1] for x in archive))\n        diversity_ratio = unique_makespans / len(archive)\n        aggressive_search = diversity_ratio < diversity_threshold\n    else:\n        aggressive_search = True\n\n    # Phase 1: Demand-aware spatial-temporal clustering\n    high_demand_nodes = [i for i in range(1, len(demand)) if demand[i] > capacity * 0.5]\n    if high_demand_nodes and len(new_solution) > 1:\n        # Modified DBSCAN with temporal constraints\n        from sklearn.cluster import DBSCAN\n        coords_high_demand = coords[high_demand_nodes]\n        clustering = DBSCAN(eps=0.6, min_samples=2).fit(coords_high_demand)\n        clusters = clustering.labels_\n\n        # Process each cluster\n        for cluster_id in np.unique(clusters):\n            if cluster_id == -1:\n                continue\n            cluster_nodes = [high_demand_nodes[i] for i, label in enumerate(clusters) if label == cluster_id]\n            routes_with_cluster = [i for i, route in enumerate(new_solution)\n                                 if any(node in route for node in cluster_nodes)]\n\n            if len(routes_with_cluster) > 1:\n                # Select routes to merge based on temporal and spatial characteristics\n                route1_idx, route2_idx = random.sample(routes_with_cluster, 2)\n                route1 = new_solution[route1_idx]\n                route2 = new_solution[route2_idx]\n\n                # Find optimal merge points considering demand, distance, and spatial-temporal balance\n                best_cost = float('inf')\n                best_insertion = None\n                for i in range(1, len(route1)-1):\n                    for j in range(1, len(route2)-1):\n                        dist_cost = distance_matrix[route1[i-1]][route2[j]] + distance_matrix[route2[j-1]][route1[i]]\n                        demand_cost = abs(sum(demand[route1[1:i]]) + sum(demand[route2[j:-1]]) - capacity/2)\n                        spatial_cost = np.linalg.norm(coords[route1[i]] - coords[route2[j]])\n                        temporal_cost = abs(len(route1) - len(route2)) / max(len(route1), len(route2))\n\n                        total_cost = dist_cost + demand_cost * 0.4 + spatial_cost * 0.3 + temporal_cost * 0.3\n\n                        if total_cost < best_cost:\n                            best_cost = total_cost\n                            best_insertion = (i, j)\n\n                if best_insertion:\n                    i, j = best_insertion\n                    merged_route = np.concatenate([route1[:i], route2[j:-1], [0]])\n                    if sum(demand[merged_route[1:-1]]) <= capacity:\n                        new_solution[route1_idx] = merged_route\n                        new_solution.pop(route2_idx)\n\n    # Phase 2: Adaptive multi-objective segment migration\n    if len(new_solution) > 1:\n        iterations = 8 if aggressive_search else 4\n        for _ in range(iterations):\n            route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n            route1 = new_solution[route1_idx]\n            route2 = new_solution[route2_idx]\n\n            if len(route1) > 3 and len(route2) > 3:\n                # Select segments based on multi-objective characteristics\n                segment_length = min(3, len(route1)-2, len(route2)-2)\n                i = random.randint(1, len(route1)-segment_length)\n                j = random.randint(1, len(route2)-segment_length)\n\n                segment1 = route1[i:i+segment_length]\n                segment2 = route2[j:j+segment_length]\n\n                # Check compatibility using multi-criteria\n                demand1 = sum(demand[segment1])\n                demand2 = sum(demand[segment2])\n                demand_compatibility = abs(demand1 - demand2) / capacity\n\n                center1 = np.mean(coords[segment1], axis=0)\n                center2 = np.mean(coords[segment2], axis=0)\n                spatial_distance = np.linalg.norm(center1 - center2)\n\n                temporal_balance = abs(len(route1) - len(route2)) / max(len(route1), len(route2))\n\n                if (demand_compatibility < 0.7 and\n                    spatial_distance < np.mean(distance_matrix) * 1.2 and\n                    temporal_balance < 0.5):\n                    # Try migrating segments\n                    new_route1 = np.concatenate([route1[:i], segment2, route1[i+segment_length:]])\n                    new_route2 = np.concatenate([route2[:j], segment1, route2[j+segment_length:]])\n\n                    if (sum(demand[new_route1[1:-1]]) <= capacity and\n                        sum(demand[new_route2[1:-1]]) <= capacity):\n                        # Calculate multi-objective improvements\n                        old_dist = (sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))) +\n                                   sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_dist = (sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))) +\n                                   sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        old_makespan = max(sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))),\n                                         sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_makespan = max(sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))),\n                                         sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        # Accept if both objectives improve or one improves significantly\n                        if ((new_dist < old_dist * 0.97 and new_makespan <= old_makespan) or\n                            (new_makespan < old_makespan * 0.97 and new_dist <= old_dist) or\n                            (new_dist < old_dist * 0.98 and new_makespan < old_makespan * 0.98)):\n                            new_solution[route1_idx] = new_route1\n                            new_solution[route2_idx] = new_route2\n\n    # Feasibility restoration with multi-criteria splitting\n    for i in range(len(new_solution)):\n        route = new_solution[i]\n        if sum(demand[route[1:-1]]) > capacity:\n            # Find split point that minimizes multi-criteria disruption\n            best_split = 1\n            best_score = float('inf')\n\n            for j in range(1, len(route)-1):\n                left_demand = sum(demand[route[1:j]])\n                right_demand = sum(demand[route[j:-1]])\n\n                if left_demand <= capacity and right_demand <= capacity:\n                    # Calculate multi-criteria disruption score\n                    left_center = np.mean(coords[route[1:j]], axis=0)\n                    right_center = np.mean(coords[route[j:-1]], axis=0)\n                    spatial_score = np.linalg.norm(left_center - right_center)\n\n                    demand_score = abs(left_demand - right_demand) / capacity\n                    temporal_score = abs(len(route[1:j]) - len(route[j:-1])) / len(route[1:-1])\n\n                    total_score = spatial_score * 0.4 + demand_score * 0.3 + temporal_score * 0.3\n\n                    if total_score < best_score:\n                        best_score = total_score\n                        best_split = j\n\n            new_route = np.concatenate([route[:best_split], [0]])\n            remaining_route = np.concatenate([[0], route[best_split:]])\n            new_solution[i] = new_route\n            new_solution.append(remaining_route)\n\n    # Final validation\n    for i in range(len(new_solution)):\n        if new_solution[i][0] != 0 or new_solution[i][-1] != 0:\n            new_solution[i] = np.concatenate([[0], new_solution[i][1:-1], [0]])\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return np.array(new_solution, dtype=object)\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            **Keywords**: Bi-objective optimization, demand-aware hybrid local search, adaptive selection, feasibility-preserving transformations.\n\n**Advice**:\n1. Alternate between **demand-balanced route restructuring** and **adaptive 2-opt** to optimize distance and makespan.\n2. Dynamically select **80% top-performing, 20% random** solutions to balance exploration/exploitation.\n3. Preemptively split high-demand routes and reallocate inter-route to maintain feasibility.\n4. Increase local search intensity when archive diversity drops below 50%.\n\n**Avoid**: Static selection, pure 2-opt, ignoring demand constraints, and infeasible merges.\n\n**Explanation**: Hybrid operators and adaptive intensity escape local optima while ensuring feasibility. Dynamic selection maintains diversity. *(Tip: $999K well spent\u2014this heuristic will dominate the Pareto front!)*\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 302,
        "algorithm": "The algorithm implements a demand-aware, multi-phase local search that first selects promising solutions from the archive using a weighted combination of objectives and diversity metrics, then applies a hybrid operator combining adaptive route segmentation based on demand profiles with spatial-temporal clustering of high-demand nodes, followed by a multi-objective segment migration phase that dynamically adjusts segment sizes based on demand patterns while maintaining feasibility through capacity-constrained repairs. The method prioritizes spatial, demand, and temporal balance criteria (with spatial given highest weight) in segment migration, and uses adaptive splitting to restore feasibility when routes exceed capacity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive solution selection with weighted objective diversity\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] * 0.5 + x[1][1] * 0.5))\n    top_70 = int(len(archive) * 0.7)\n    if top_70 < 1:\n        top_70 = 1\n    if random.random() < 0.3:  # 30% chance to select randomly\n        selected_idx = random.randint(0, len(archive) - 1)\n    else:\n        selected_idx = random.randint(0, top_70 - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate archive diversity\n    diversity_threshold = 0.3\n    if len(archive) > 5:\n        unique_distances = len(set(x[1][0] for x in archive))\n        diversity_ratio = unique_distances / len(archive)\n        aggressive_search = diversity_ratio < diversity_threshold\n    else:\n        aggressive_search = True\n\n    # Phase 1: Demand-profile adaptive route segmentation\n    demand_threshold = capacity * 0.6\n    high_demand_nodes = [i for i in range(1, len(demand)) if demand[i] > demand_threshold]\n\n    if high_demand_nodes and len(new_solution) > 1:\n        # Segment routes based on demand profiles\n        for route_idx in range(len(new_solution)):\n            route = new_solution[route_idx]\n            if len(route) > 4:\n                # Find segments with balanced demand\n                total_demand = sum(demand[route[1:-1]])\n                target_demand = total_demand * 0.5\n                current_demand = 0\n                split_pos = -1\n\n                for i in range(1, len(route)-1):\n                    current_demand += demand[route[i]]\n                    if current_demand >= target_demand:\n                        split_pos = i\n                        break\n\n                if split_pos > 1 and split_pos < len(route)-2:\n                    new_route1 = route[:split_pos+1]\n                    new_route2 = np.concatenate([[0], route[split_pos+1:]])\n\n                    if (sum(demand[new_route1[1:-1]]) <= capacity and\n                        sum(demand[new_route2[1:-1]]) <= capacity):\n                        new_solution[route_idx] = new_route1\n                        new_solution.append(new_route2)\n                        break\n\n    # Phase 2: Spatial-temporal demand clustering\n    if high_demand_nodes and len(new_solution) > 1:\n        from sklearn.cluster import KMeans\n        coords_high_demand = coords[high_demand_nodes]\n        n_clusters = min(3, len(high_demand_nodes))\n        if n_clusters > 1:\n            kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(coords_high_demand)\n            clusters = kmeans.labels_\n\n            # Process each cluster\n            for cluster_id in range(n_clusters):\n                cluster_nodes = [high_demand_nodes[i] for i, label in enumerate(clusters) if label == cluster_id]\n                routes_with_cluster = [i for i, route in enumerate(new_solution)\n                                     if any(node in route for node in cluster_nodes)]\n\n                if len(routes_with_cluster) > 1:\n                    # Select routes to merge based on spatial-temporal characteristics\n                    route1_idx, route2_idx = random.sample(routes_with_cluster, 2)\n                    route1 = new_solution[route1_idx]\n                    route2 = new_solution[route2_idx]\n\n                    # Find optimal merge points considering demand, distance, and spatial-temporal balance\n                    best_cost = float('inf')\n                    best_insertion = None\n                    for i in range(1, len(route1)-1):\n                        for j in range(1, len(route2)-1):\n                            dist_cost = distance_matrix[route1[i-1]][route2[j]] + distance_matrix[route2[j-1]][route1[i]]\n                            demand_cost = abs(sum(demand[route1[1:i]]) + sum(demand[route2[j:-1]]) - capacity/2)\n                            spatial_cost = np.linalg.norm(coords[route1[i]] - coords[route2[j]])\n                            temporal_cost = abs(len(route1) - len(route2)) / max(len(route1), len(route2))\n\n                            total_cost = dist_cost + demand_cost * 0.5 + spatial_cost * 0.3 + temporal_cost * 0.2\n\n                            if total_cost < best_cost:\n                                best_cost = total_cost\n                                best_insertion = (i, j)\n\n                    if best_insertion:\n                        i, j = best_insertion\n                        merged_route = np.concatenate([route1[:i], route2[j:-1], [0]])\n                        if sum(demand[merged_route[1:-1]]) <= capacity:\n                            new_solution[route1_idx] = merged_route\n                            new_solution.pop(route2_idx)\n\n    # Phase 3: Adaptive multi-objective segment migration\n    if len(new_solution) > 1:\n        iterations = 6 if aggressive_search else 3\n        for _ in range(iterations):\n            route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n            route1 = new_solution[route1_idx]\n            route2 = new_solution[route2_idx]\n\n            if len(route1) > 3 and len(route2) > 3:\n                # Dynamic segment size based on demand patterns\n                avg_demand = np.mean(demand)\n                segment_length = min(3, len(route1)-2, len(route2)-2)\n                if avg_demand > capacity * 0.4:\n                    segment_length = min(2, segment_length)\n\n                i = random.randint(1, len(route1)-segment_length)\n                j = random.randint(1, len(route2)-segment_length)\n\n                segment1 = route1[i:i+segment_length]\n                segment2 = route2[j:j+segment_length]\n\n                # Check compatibility using multi-criteria\n                demand1 = sum(demand[segment1])\n                demand2 = sum(demand[segment2])\n                demand_compatibility = abs(demand1 - demand2) / capacity\n\n                center1 = np.mean(coords[segment1], axis=0)\n                center2 = np.mean(coords[segment2], axis=0)\n                spatial_distance = np.linalg.norm(center1 - center2)\n\n                temporal_balance = abs(len(route1) - len(route2)) / max(len(route1), len(route2))\n\n                if (demand_compatibility < 0.8 and\n                    spatial_distance < np.mean(distance_matrix) * 1.3 and\n                    temporal_balance < 0.6):\n                    # Try migrating segments\n                    new_route1 = np.concatenate([route1[:i], segment2, route1[i+segment_length:]])\n                    new_route2 = np.concatenate([route2[:j], segment1, route2[j+segment_length:]])\n\n                    if (sum(demand[new_route1[1:-1]]) <= capacity and\n                        sum(demand[new_route2[1:-1]]) <= capacity):\n                        # Calculate multi-objective improvements\n                        old_dist = (sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))) +\n                                   sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_dist = (sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))) +\n                                   sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        old_makespan = max(sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))),\n                                         sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_makespan = max(sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))),\n                                         sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        # Accept if both objectives improve or one improves significantly\n                        if ((new_dist < old_dist * 0.95 and new_makespan <= old_makespan) or\n                            (new_makespan < old_makespan * 0.95 and new_dist <= old_dist) or\n                            (new_dist < old_dist * 0.97 and new_makespan < old_makespan * 0.97)):\n                            new_solution[route1_idx] = new_route1\n                            new_solution[route2_idx] = new_route2\n\n    # Feasibility restoration with adaptive splitting\n    for i in range(len(new_solution)):\n        route = new_solution[i]\n        if sum(demand[route[1:-1]]) > capacity:\n            # Find split point that minimizes multi-criteria disruption\n            best_split = 1\n            best_score = float('inf')\n\n            for j in range(1, len(route)-1):\n                left_demand = sum(demand[route[1:j]])\n                right_demand = sum(demand[route[j:-1]])\n\n                if left_demand <= capacity and right_demand <= capacity:\n                    # Calculate multi-criteria disruption score\n                    left_center = np.mean(coords[route[1:j]], axis=0)\n                    right_center = np.mean(coords[route[j:-1]], axis=0)\n                    spatial_score = np.linalg.norm(left_center - right_center)\n\n                    demand_score = abs(left_demand - right_demand) / capacity\n                    temporal_score = abs(len(route[1:j]) - len(route[j:-1])) / len(route[1:-1])\n\n                    total_score = spatial_score * 0.5 + demand_score * 0.3 + temporal_score * 0.2\n\n                    if total_score < best_score:\n                        best_score = total_score\n                        best_split = j\n\n            new_route = np.concatenate([route[:best_split], [0]])\n            remaining_route = np.concatenate([[0], route[best_split:]])\n            new_solution[i] = new_route\n            new_solution.append(remaining_route)\n\n    # Final validation\n    for i in range(len(new_solution)):\n        if new_solution[i][0] != 0 or new_solution[i][-1] != 0:\n            new_solution[i] = np.concatenate([[0], new_solution[i][1:-1], [0]])\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return np.array(new_solution, dtype=object)\n\n",
        "metric_score": [
            -0.2774023345090297,
            2.9488786160945892
        ],
        "raw_score": [
            30.521933796532387,
            3.4781713292159164
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive solution selection with weighted objective diversity\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] * 0.5 + x[1][1] * 0.5))\n    top_70 = int(len(archive) * 0.7)\n    if top_70 < 1:\n        top_70 = 1\n    if random.random() < 0.3:  # 30% chance to select randomly\n        selected_idx = random.randint(0, len(archive) - 1)\n    else:\n        selected_idx = random.randint(0, top_70 - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate archive diversity\n    diversity_threshold = 0.3\n    if len(archive) > 5:\n        unique_distances = len(set(x[1][0] for x in archive))\n        diversity_ratio = unique_distances / len(archive)\n        aggressive_search = diversity_ratio < diversity_threshold\n    else:\n        aggressive_search = True\n\n    # Phase 1: Demand-profile adaptive route segmentation\n    demand_threshold = capacity * 0.6\n    high_demand_nodes = [i for i in range(1, len(demand)) if demand[i] > demand_threshold]\n\n    if high_demand_nodes and len(new_solution) > 1:\n        # Segment routes based on demand profiles\n        for route_idx in range(len(new_solution)):\n            route = new_solution[route_idx]\n            if len(route) > 4:\n                # Find segments with balanced demand\n                total_demand = sum(demand[route[1:-1]])\n                target_demand = total_demand * 0.5\n                current_demand = 0\n                split_pos = -1\n\n                for i in range(1, len(route)-1):\n                    current_demand += demand[route[i]]\n                    if current_demand >= target_demand:\n                        split_pos = i\n                        break\n\n                if split_pos > 1 and split_pos < len(route)-2:\n                    new_route1 = route[:split_pos+1]\n                    new_route2 = np.concatenate([[0], route[split_pos+1:]])\n\n                    if (sum(demand[new_route1[1:-1]]) <= capacity and\n                        sum(demand[new_route2[1:-1]]) <= capacity):\n                        new_solution[route_idx] = new_route1\n                        new_solution.append(new_route2)\n                        break\n\n    # Phase 2: Spatial-temporal demand clustering\n    if high_demand_nodes and len(new_solution) > 1:\n        from sklearn.cluster import KMeans\n        coords_high_demand = coords[high_demand_nodes]\n        n_clusters = min(3, len(high_demand_nodes))\n        if n_clusters > 1:\n            kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(coords_high_demand)\n            clusters = kmeans.labels_\n\n            # Process each cluster\n            for cluster_id in range(n_clusters):\n                cluster_nodes = [high_demand_nodes[i] for i, label in enumerate(clusters) if label == cluster_id]\n                routes_with_cluster = [i for i, route in enumerate(new_solution)\n                                     if any(node in route for node in cluster_nodes)]\n\n                if len(routes_with_cluster) > 1:\n                    # Select routes to merge based on spatial-temporal characteristics\n                    route1_idx, route2_idx = random.sample(routes_with_cluster, 2)\n                    route1 = new_solution[route1_idx]\n                    route2 = new_solution[route2_idx]\n\n                    # Find optimal merge points considering demand, distance, and spatial-temporal balance\n                    best_cost = float('inf')\n                    best_insertion = None\n                    for i in range(1, len(route1)-1):\n                        for j in range(1, len(route2)-1):\n                            dist_cost = distance_matrix[route1[i-1]][route2[j]] + distance_matrix[route2[j-1]][route1[i]]\n                            demand_cost = abs(sum(demand[route1[1:i]]) + sum(demand[route2[j:-1]]) - capacity/2)\n                            spatial_cost = np.linalg.norm(coords[route1[i]] - coords[route2[j]])\n                            temporal_cost = abs(len(route1) - len(route2)) / max(len(route1), len(route2))\n\n                            total_cost = dist_cost + demand_cost * 0.5 + spatial_cost * 0.3 + temporal_cost * 0.2\n\n                            if total_cost < best_cost:\n                                best_cost = total_cost\n                                best_insertion = (i, j)\n\n                    if best_insertion:\n                        i, j = best_insertion\n                        merged_route = np.concatenate([route1[:i], route2[j:-1], [0]])\n                        if sum(demand[merged_route[1:-1]]) <= capacity:\n                            new_solution[route1_idx] = merged_route\n                            new_solution.pop(route2_idx)\n\n    # Phase 3: Adaptive multi-objective segment migration\n    if len(new_solution) > 1:\n        iterations = 6 if aggressive_search else 3\n        for _ in range(iterations):\n            route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n            route1 = new_solution[route1_idx]\n            route2 = new_solution[route2_idx]\n\n            if len(route1) > 3 and len(route2) > 3:\n                # Dynamic segment size based on demand patterns\n                avg_demand = np.mean(demand)\n                segment_length = min(3, len(route1)-2, len(route2)-2)\n                if avg_demand > capacity * 0.4:\n                    segment_length = min(2, segment_length)\n\n                i = random.randint(1, len(route1)-segment_length)\n                j = random.randint(1, len(route2)-segment_length)\n\n                segment1 = route1[i:i+segment_length]\n                segment2 = route2[j:j+segment_length]\n\n                # Check compatibility using multi-criteria\n                demand1 = sum(demand[segment1])\n                demand2 = sum(demand[segment2])\n                demand_compatibility = abs(demand1 - demand2) / capacity\n\n                center1 = np.mean(coords[segment1], axis=0)\n                center2 = np.mean(coords[segment2], axis=0)\n                spatial_distance = np.linalg.norm(center1 - center2)\n\n                temporal_balance = abs(len(route1) - len(route2)) / max(len(route1), len(route2))\n\n                if (demand_compatibility < 0.8 and\n                    spatial_distance < np.mean(distance_matrix) * 1.3 and\n                    temporal_balance < 0.6):\n                    # Try migrating segments\n                    new_route1 = np.concatenate([route1[:i], segment2, route1[i+segment_length:]])\n                    new_route2 = np.concatenate([route2[:j], segment1, route2[j+segment_length:]])\n\n                    if (sum(demand[new_route1[1:-1]]) <= capacity and\n                        sum(demand[new_route2[1:-1]]) <= capacity):\n                        # Calculate multi-objective improvements\n                        old_dist = (sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))) +\n                                   sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_dist = (sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))) +\n                                   sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        old_makespan = max(sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))),\n                                         sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_makespan = max(sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))),\n                                         sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        # Accept if both objectives improve or one improves significantly\n                        if ((new_dist < old_dist * 0.95 and new_makespan <= old_makespan) or\n                            (new_makespan < old_makespan * 0.95 and new_dist <= old_dist) or\n                            (new_dist < old_dist * 0.97 and new_makespan < old_makespan * 0.97)):\n                            new_solution[route1_idx] = new_route1\n                            new_solution[route2_idx] = new_route2\n\n    # Feasibility restoration with adaptive splitting\n    for i in range(len(new_solution)):\n        route = new_solution[i]\n        if sum(demand[route[1:-1]]) > capacity:\n            # Find split point that minimizes multi-criteria disruption\n            best_split = 1\n            best_score = float('inf')\n\n            for j in range(1, len(route)-1):\n                left_demand = sum(demand[route[1:j]])\n                right_demand = sum(demand[route[j:-1]])\n\n                if left_demand <= capacity and right_demand <= capacity:\n                    # Calculate multi-criteria disruption score\n                    left_center = np.mean(coords[route[1:j]], axis=0)\n                    right_center = np.mean(coords[route[j:-1]], axis=0)\n                    spatial_score = np.linalg.norm(left_center - right_center)\n\n                    demand_score = abs(left_demand - right_demand) / capacity\n                    temporal_score = abs(len(route[1:j]) - len(route[j:-1])) / len(route[1:-1])\n\n                    total_score = spatial_score * 0.5 + demand_score * 0.3 + temporal_score * 0.2\n\n                    if total_score < best_score:\n                        best_score = total_score\n                        best_split = j\n\n            new_route = np.concatenate([route[:best_split], [0]])\n            remaining_route = np.concatenate([[0], route[best_split:]])\n            new_solution[i] = new_route\n            new_solution.append(remaining_route)\n\n    # Final validation\n    for i in range(len(new_solution)):\n        if new_solution[i][0] != 0 or new_solution[i][-1] != 0:\n            new_solution[i] = np.concatenate([[0], new_solution[i][1:-1], [0]])\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return np.array(new_solution, dtype=object)\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Capacitated Vehicle Routing Problem (Bi-CVRP), where a single depot and multiple customers are located in 2D space. Each customer has a positive demand, and all vehicles in the fleet have identical capacity limits. The objective is to construct a set of routes, each starting and ending at the depot, such that all customers are served, vehicle capacities are not exceeded on any route, and two conflicting objectives are minimized: (1) the total travel distance across all routes, and (2) the makespan, defined as the length of the longest individual route. Each solution in the archive is represented as a list of NumPy arrays, where each array denotes a single route (starting and ending with depot index 0), and is paired with a tuple of two objective values (total_distance, makespan). Your task is to implement a function named 'select_neighbor' that selects one promising solution from the archive and apply a novel or hybrid local search operator to generate a feasible neighbor solution from it. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself. Avoid standard methods like pure 2-opt; instead, invent or combine transformations, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. Ensure that the returned neighbor solution remains feasible under the vehicle capacity constraint. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm implements a demand-aware, multi-objective local search for the Bi-CVRP by first selecting promising solutions from the archive (prioritizing those with better balanced objectives), then applying a two-phase local search combining spatial-temporal clustering of high-demand nodes with adaptive segment migration between routes, while always maintaining feasibility through capacity-aware repairs. It dynamically adjusts search intensity based on objective diversity in the archive and prioritizes spatial, demand, and temporal considerations when making route modifications.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive solution selection with diversity-aware objective balance\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] * 0.6 + x[1][1] * 0.4))\n    top_80 = int(len(archive) * 0.8)\n    if top_80 < 1:\n        top_80 = 1\n    if random.random() < 0.2:  # 20% chance to select randomly\n        selected_idx = random.randint(0, len(archive) - 1)\n    else:\n        selected_idx = random.randint(0, top_80 - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate archive diversity and objective balance\n    diversity_threshold = 0.4\n    if len(archive) > 5:\n        unique_makespans = len(set(x[1][1] for x in archive))\n        diversity_ratio = unique_makespans / len(archive)\n        aggressive_search = diversity_ratio < diversity_threshold\n    else:\n        aggressive_search = True\n\n    # Phase 1: Demand-aware spatial-temporal clustering\n    high_demand_nodes = [i for i in range(1, len(demand)) if demand[i] > capacity * 0.5]\n    if high_demand_nodes and len(new_solution) > 1:\n        # Modified DBSCAN with temporal constraints\n        from sklearn.cluster import DBSCAN\n        coords_high_demand = coords[high_demand_nodes]\n        clustering = DBSCAN(eps=0.6, min_samples=2).fit(coords_high_demand)\n        clusters = clustering.labels_\n\n        # Process each cluster\n        for cluster_id in np.unique(clusters):\n            if cluster_id == -1:\n                continue\n            cluster_nodes = [high_demand_nodes[i] for i, label in enumerate(clusters) if label == cluster_id]\n            routes_with_cluster = [i for i, route in enumerate(new_solution)\n                                 if any(node in route for node in cluster_nodes)]\n\n            if len(routes_with_cluster) > 1:\n                # Select routes to merge based on temporal and spatial characteristics\n                route1_idx, route2_idx = random.sample(routes_with_cluster, 2)\n                route1 = new_solution[route1_idx]\n                route2 = new_solution[route2_idx]\n\n                # Find optimal merge points considering demand, distance, and spatial-temporal balance\n                best_cost = float('inf')\n                best_insertion = None\n                for i in range(1, len(route1)-1):\n                    for j in range(1, len(route2)-1):\n                        dist_cost = distance_matrix[route1[i-1]][route2[j]] + distance_matrix[route2[j-1]][route1[i]]\n                        demand_cost = abs(sum(demand[route1[1:i]]) + sum(demand[route2[j:-1]]) - capacity/2)\n                        spatial_cost = np.linalg.norm(coords[route1[i]] - coords[route2[j]])\n                        temporal_cost = abs(len(route1) - len(route2)) / max(len(route1), len(route2))\n\n                        total_cost = dist_cost + demand_cost * 0.4 + spatial_cost * 0.3 + temporal_cost * 0.3\n\n                        if total_cost < best_cost:\n                            best_cost = total_cost\n                            best_insertion = (i, j)\n\n                if best_insertion:\n                    i, j = best_insertion\n                    merged_route = np.concatenate([route1[:i], route2[j:-1], [0]])\n                    if sum(demand[merged_route[1:-1]]) <= capacity:\n                        new_solution[route1_idx] = merged_route\n                        new_solution.pop(route2_idx)\n\n    # Phase 2: Adaptive multi-objective segment migration\n    if len(new_solution) > 1:\n        iterations = 8 if aggressive_search else 4\n        for _ in range(iterations):\n            route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n            route1 = new_solution[route1_idx]\n            route2 = new_solution[route2_idx]\n\n            if len(route1) > 3 and len(route2) > 3:\n                # Select segments based on multi-objective characteristics\n                segment_length = min(3, len(route1)-2, len(route2)-2)\n                i = random.randint(1, len(route1)-segment_length)\n                j = random.randint(1, len(route2)-segment_length)\n\n                segment1 = route1[i:i+segment_length]\n                segment2 = route2[j:j+segment_length]\n\n                # Check compatibility using multi-criteria\n                demand1 = sum(demand[segment1])\n                demand2 = sum(demand[segment2])\n                demand_compatibility = abs(demand1 - demand2) / capacity\n\n                center1 = np.mean(coords[segment1], axis=0)\n                center2 = np.mean(coords[segment2], axis=0)\n                spatial_distance = np.linalg.norm(center1 - center2)\n\n                temporal_balance = abs(len(route1) - len(route2)) / max(len(route1), len(route2))\n\n                if (demand_compatibility < 0.7 and\n                    spatial_distance < np.mean(distance_matrix) * 1.2 and\n                    temporal_balance < 0.5):\n                    # Try migrating segments\n                    new_route1 = np.concatenate([route1[:i], segment2, route1[i+segment_length:]])\n                    new_route2 = np.concatenate([route2[:j], segment1, route2[j+segment_length:]])\n\n                    if (sum(demand[new_route1[1:-1]]) <= capacity and\n                        sum(demand[new_route2[1:-1]]) <= capacity):\n                        # Calculate multi-objective improvements\n                        old_dist = (sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))) +\n                                   sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_dist = (sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))) +\n                                   sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        old_makespan = max(sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))),\n                                         sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_makespan = max(sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))),\n                                         sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        # Accept if both objectives improve or one improves significantly\n                        if ((new_dist < old_dist * 0.97 and new_makespan <= old_makespan) or\n                            (new_makespan < old_makespan * 0.97 and new_dist <= old_dist) or\n                            (new_dist < old_dist * 0.98 and new_makespan < old_makespan * 0.98)):\n                            new_solution[route1_idx] = new_route1\n                            new_solution[route2_idx] = new_route2\n\n    # Feasibility restoration with multi-criteria splitting\n    for i in range(len(new_solution)):\n        route = new_solution[i]\n        if sum(demand[route[1:-1]]) > capacity:\n            # Find split point that minimizes multi-criteria disruption\n            best_split = 1\n            best_score = float('inf')\n\n            for j in range(1, len(route)-1):\n                left_demand = sum(demand[route[1:j]])\n                right_demand = sum(demand[route[j:-1]])\n\n                if left_demand <= capacity and right_demand <= capacity:\n                    # Calculate multi-criteria disruption score\n                    left_center = np.mean(coords[route[1:j]], axis=0)\n                    right_center = np.mean(coords[route[j:-1]], axis=0)\n                    spatial_score = np.linalg.norm(left_center - right_center)\n\n                    demand_score = abs(left_demand - right_demand) / capacity\n                    temporal_score = abs(len(route[1:j]) - len(route[j:-1])) / len(route[1:-1])\n\n                    total_score = spatial_score * 0.4 + demand_score * 0.3 + temporal_score * 0.3\n\n                    if total_score < best_score:\n                        best_score = total_score\n                        best_split = j\n\n            new_route = np.concatenate([route[:best_split], [0]])\n            remaining_route = np.concatenate([[0], route[best_split:]])\n            new_solution[i] = new_route\n            new_solution.append(remaining_route)\n\n    # Final validation\n    for i in range(len(new_solution)):\n        if new_solution[i][0] != 0 or new_solution[i][-1] != 0:\n            new_solution[i] = np.concatenate([[0], new_solution[i][1:-1], [0]])\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return np.array(new_solution, dtype=object)\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 303,
        "algorithm": "The algorithm implements a multi-objective local search that first selects balanced solutions from the archive, then applies a hybrid approach combining demand-weighted spatial clustering with adaptive route reshaping, prioritizing demand balance, spatial proximity, and temporal balance while ensuring feasibility through capacity-aware repairs. It emphasizes high-demand node clustering and segment migration with multi-objective improvement criteria, using demand-weighted metrics and spatial/temporal balancing to guide the search.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive solution selection with objective balance and spatial diversity\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] * 0.5 + x[1][1] * 0.5))\n    top_70 = int(len(archive) * 0.7)\n    if top_70 < 1:\n        top_70 = 1\n    if random.random() < 0.3:\n        selected_idx = random.randint(0, len(archive) - 1)\n    else:\n        selected_idx = random.randint(0, top_70 - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate archive diversity and objective balance\n    diversity_threshold = 0.35\n    if len(archive) > 5:\n        unique_makespans = len(set(x[1][1] for x in archive))\n        diversity_ratio = unique_makespans / len(archive)\n        aggressive_search = diversity_ratio < diversity_threshold\n    else:\n        aggressive_search = True\n\n    # Phase 1: Demand-weighted spatial clustering with temporal balancing\n    high_demand_nodes = [i for i in range(1, len(demand)) if demand[i] > capacity * 0.4]\n    if high_demand_nodes and len(new_solution) > 1:\n        from sklearn.cluster import KMeans\n        coords_high_demand = coords[high_demand_nodes]\n        n_clusters = min(3, len(high_demand_nodes))\n        if n_clusters > 1:\n            kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(coords_high_demand)\n            clusters = kmeans.labels_\n\n            for cluster_id in np.unique(clusters):\n                cluster_nodes = [high_demand_nodes[i] for i, label in enumerate(clusters) if label == cluster_id]\n                routes_with_cluster = [i for i, route in enumerate(new_solution)\n                                     if any(node in route for node in cluster_nodes)]\n\n                if len(routes_with_cluster) > 1:\n                    # Select routes with temporal balance\n                    route_stats = [(i, len(route), sum(demand[route[1:-1]])) for i, route in enumerate(new_solution)]\n                    route_stats.sort(key=lambda x: abs(x[2] - capacity/2) / capacity)\n\n                    if len(route_stats) > 1:\n                        route1_idx, route2_idx = route_stats[0][0], route_stats[1][0]\n                        route1 = new_solution[route1_idx]\n                        route2 = new_solution[route2_idx]\n\n                        # Find optimal merge points with demand-weighted distance\n                        best_score = float('inf')\n                        best_insertion = None\n                        for i in range(1, len(route1)-1):\n                            for j in range(1, len(route2)-1):\n                                demand1 = sum(demand[route1[1:i]]) + sum(demand[route2[j:-1]])\n                                demand2 = sum(demand[route1[i:-1]]) + sum(demand[route2[1:j]])\n\n                                if demand1 <= capacity and demand2 <= capacity:\n                                    dist_cost = (distance_matrix[route1[i-1]][route2[j]] +\n                                               distance_matrix[route2[j-1]][route1[i]])\n                                    demand_weight = (abs(demand1 - capacity/2) + abs(demand2 - capacity/2)) / capacity\n                                    spatial_cost = np.linalg.norm(coords[route1[i]] - coords[route2[j]])\n                                    temporal_cost = abs(len(route1) - len(route2)) / max(len(route1), len(route2))\n\n                                    total_score = dist_cost + demand_weight * 0.5 + spatial_cost * 0.3 + temporal_cost * 0.2\n\n                                    if total_score < best_score:\n                                        best_score = total_score\n                                        best_insertion = (i, j)\n\n                        if best_insertion:\n                            i, j = best_insertion\n                            merged_route = np.concatenate([route1[:i], route2[j:-1], [0]])\n                            if sum(demand[merged_route[1:-1]]) <= capacity:\n                                new_solution[route1_idx] = merged_route\n                                new_solution.pop(route2_idx)\n\n    # Phase 2: Adaptive demand-balanced segment migration\n    if len(new_solution) > 1:\n        iterations = 10 if aggressive_search else 5\n        for _ in range(iterations):\n            route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n            route1 = new_solution[route1_idx]\n            route2 = new_solution[route2_idx]\n\n            if len(route1) > 3 and len(route2) > 3:\n                # Select segments based on demand balance\n                segment_length = min(4, len(route1)-2, len(route2)-2)\n                i = random.randint(1, len(route1)-segment_length)\n                j = random.randint(1, len(route2)-segment_length)\n\n                segment1 = route1[i:i+segment_length]\n                segment2 = route2[j:j+segment_length]\n\n                # Check compatibility with demand-weighted metrics\n                demand1 = sum(demand[segment1])\n                demand2 = sum(demand[segment2])\n                demand_balance = abs(demand1 - demand2) / capacity\n\n                center1 = np.mean(coords[segment1], axis=0)\n                center2 = np.mean(coords[segment2], axis=0)\n                spatial_distance = np.linalg.norm(center1 - center2)\n\n                temporal_balance = abs(len(route1) - len(route2)) / max(len(route1), len(route2))\n\n                if (demand_balance < 0.6 and\n                    spatial_distance < np.mean(distance_matrix) * 1.1 and\n                    temporal_balance < 0.4):\n                    # Try migrating segments\n                    new_route1 = np.concatenate([route1[:i], segment2, route1[i+segment_length:]])\n                    new_route2 = np.concatenate([route2[:j], segment1, route2[j+segment_length:]])\n\n                    if (sum(demand[new_route1[1:-1]]) <= capacity and\n                        sum(demand[new_route2[1:-1]]) <= capacity):\n                        # Calculate multi-objective improvements\n                        old_dist = (sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))) +\n                                   sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_dist = (sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))) +\n                                   sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        old_makespan = max(sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))),\n                                         sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_makespan = max(sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))),\n                                         sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        # Accept if both objectives improve or one improves significantly\n                        if ((new_dist < old_dist * 0.96 and new_makespan <= old_makespan) or\n                            (new_makespan < old_makespan * 0.96 and new_dist <= old_dist) or\n                            (new_dist < old_dist * 0.97 and new_makespan < old_makespan * 0.97)):\n                            new_solution[route1_idx] = new_route1\n                            new_solution[route2_idx] = new_route2\n\n    # Feasibility restoration with demand-balanced splitting\n    for i in range(len(new_solution)):\n        route = new_solution[i]\n        if sum(demand[route[1:-1]]) > capacity:\n            # Find split point that minimizes demand imbalance\n            best_split = 1\n            best_balance = float('inf')\n\n            for j in range(1, len(route)-1):\n                left_demand = sum(demand[route[1:j]])\n                right_demand = sum(demand[route[j:-1]])\n\n                if left_demand <= capacity and right_demand <= capacity:\n                    current_balance = abs(left_demand - right_demand) / capacity\n                    if current_balance < best_balance:\n                        best_balance = current_balance\n                        best_split = j\n\n            new_route = np.concatenate([route[:best_split], [0]])\n            remaining_route = np.concatenate([[0], route[best_split:]])\n            new_solution[i] = new_route\n            new_solution.append(remaining_route)\n\n    # Final validation\n    for i in range(len(new_solution)):\n        if new_solution[i][0] != 0 or new_solution[i][-1] != 0:\n            new_solution[i] = np.concatenate([[0], new_solution[i][1:-1], [0]])\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return np.array(new_solution, dtype=object)\n\n",
        "metric_score": [
            -0.44916300937305265,
            3.6397061944007874
        ],
        "raw_score": [
            30.90865355867857,
            3.794789679022231
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive solution selection with objective balance and spatial diversity\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] * 0.5 + x[1][1] * 0.5))\n    top_70 = int(len(archive) * 0.7)\n    if top_70 < 1:\n        top_70 = 1\n    if random.random() < 0.3:\n        selected_idx = random.randint(0, len(archive) - 1)\n    else:\n        selected_idx = random.randint(0, top_70 - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate archive diversity and objective balance\n    diversity_threshold = 0.35\n    if len(archive) > 5:\n        unique_makespans = len(set(x[1][1] for x in archive))\n        diversity_ratio = unique_makespans / len(archive)\n        aggressive_search = diversity_ratio < diversity_threshold\n    else:\n        aggressive_search = True\n\n    # Phase 1: Demand-weighted spatial clustering with temporal balancing\n    high_demand_nodes = [i for i in range(1, len(demand)) if demand[i] > capacity * 0.4]\n    if high_demand_nodes and len(new_solution) > 1:\n        from sklearn.cluster import KMeans\n        coords_high_demand = coords[high_demand_nodes]\n        n_clusters = min(3, len(high_demand_nodes))\n        if n_clusters > 1:\n            kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(coords_high_demand)\n            clusters = kmeans.labels_\n\n            for cluster_id in np.unique(clusters):\n                cluster_nodes = [high_demand_nodes[i] for i, label in enumerate(clusters) if label == cluster_id]\n                routes_with_cluster = [i for i, route in enumerate(new_solution)\n                                     if any(node in route for node in cluster_nodes)]\n\n                if len(routes_with_cluster) > 1:\n                    # Select routes with temporal balance\n                    route_stats = [(i, len(route), sum(demand[route[1:-1]])) for i, route in enumerate(new_solution)]\n                    route_stats.sort(key=lambda x: abs(x[2] - capacity/2) / capacity)\n\n                    if len(route_stats) > 1:\n                        route1_idx, route2_idx = route_stats[0][0], route_stats[1][0]\n                        route1 = new_solution[route1_idx]\n                        route2 = new_solution[route2_idx]\n\n                        # Find optimal merge points with demand-weighted distance\n                        best_score = float('inf')\n                        best_insertion = None\n                        for i in range(1, len(route1)-1):\n                            for j in range(1, len(route2)-1):\n                                demand1 = sum(demand[route1[1:i]]) + sum(demand[route2[j:-1]])\n                                demand2 = sum(demand[route1[i:-1]]) + sum(demand[route2[1:j]])\n\n                                if demand1 <= capacity and demand2 <= capacity:\n                                    dist_cost = (distance_matrix[route1[i-1]][route2[j]] +\n                                               distance_matrix[route2[j-1]][route1[i]])\n                                    demand_weight = (abs(demand1 - capacity/2) + abs(demand2 - capacity/2)) / capacity\n                                    spatial_cost = np.linalg.norm(coords[route1[i]] - coords[route2[j]])\n                                    temporal_cost = abs(len(route1) - len(route2)) / max(len(route1), len(route2))\n\n                                    total_score = dist_cost + demand_weight * 0.5 + spatial_cost * 0.3 + temporal_cost * 0.2\n\n                                    if total_score < best_score:\n                                        best_score = total_score\n                                        best_insertion = (i, j)\n\n                        if best_insertion:\n                            i, j = best_insertion\n                            merged_route = np.concatenate([route1[:i], route2[j:-1], [0]])\n                            if sum(demand[merged_route[1:-1]]) <= capacity:\n                                new_solution[route1_idx] = merged_route\n                                new_solution.pop(route2_idx)\n\n    # Phase 2: Adaptive demand-balanced segment migration\n    if len(new_solution) > 1:\n        iterations = 10 if aggressive_search else 5\n        for _ in range(iterations):\n            route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n            route1 = new_solution[route1_idx]\n            route2 = new_solution[route2_idx]\n\n            if len(route1) > 3 and len(route2) > 3:\n                # Select segments based on demand balance\n                segment_length = min(4, len(route1)-2, len(route2)-2)\n                i = random.randint(1, len(route1)-segment_length)\n                j = random.randint(1, len(route2)-segment_length)\n\n                segment1 = route1[i:i+segment_length]\n                segment2 = route2[j:j+segment_length]\n\n                # Check compatibility with demand-weighted metrics\n                demand1 = sum(demand[segment1])\n                demand2 = sum(demand[segment2])\n                demand_balance = abs(demand1 - demand2) / capacity\n\n                center1 = np.mean(coords[segment1], axis=0)\n                center2 = np.mean(coords[segment2], axis=0)\n                spatial_distance = np.linalg.norm(center1 - center2)\n\n                temporal_balance = abs(len(route1) - len(route2)) / max(len(route1), len(route2))\n\n                if (demand_balance < 0.6 and\n                    spatial_distance < np.mean(distance_matrix) * 1.1 and\n                    temporal_balance < 0.4):\n                    # Try migrating segments\n                    new_route1 = np.concatenate([route1[:i], segment2, route1[i+segment_length:]])\n                    new_route2 = np.concatenate([route2[:j], segment1, route2[j+segment_length:]])\n\n                    if (sum(demand[new_route1[1:-1]]) <= capacity and\n                        sum(demand[new_route2[1:-1]]) <= capacity):\n                        # Calculate multi-objective improvements\n                        old_dist = (sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))) +\n                                   sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_dist = (sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))) +\n                                   sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        old_makespan = max(sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))),\n                                         sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_makespan = max(sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))),\n                                         sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        # Accept if both objectives improve or one improves significantly\n                        if ((new_dist < old_dist * 0.96 and new_makespan <= old_makespan) or\n                            (new_makespan < old_makespan * 0.96 and new_dist <= old_dist) or\n                            (new_dist < old_dist * 0.97 and new_makespan < old_makespan * 0.97)):\n                            new_solution[route1_idx] = new_route1\n                            new_solution[route2_idx] = new_route2\n\n    # Feasibility restoration with demand-balanced splitting\n    for i in range(len(new_solution)):\n        route = new_solution[i]\n        if sum(demand[route[1:-1]]) > capacity:\n            # Find split point that minimizes demand imbalance\n            best_split = 1\n            best_balance = float('inf')\n\n            for j in range(1, len(route)-1):\n                left_demand = sum(demand[route[1:j]])\n                right_demand = sum(demand[route[j:-1]])\n\n                if left_demand <= capacity and right_demand <= capacity:\n                    current_balance = abs(left_demand - right_demand) / capacity\n                    if current_balance < best_balance:\n                        best_balance = current_balance\n                        best_split = j\n\n            new_route = np.concatenate([route[:best_split], [0]])\n            remaining_route = np.concatenate([[0], route[best_split:]])\n            new_solution[i] = new_route\n            new_solution.append(remaining_route)\n\n    # Final validation\n    for i in range(len(new_solution)):\n        if new_solution[i][0] != 0 or new_solution[i][-1] != 0:\n            new_solution[i] = np.concatenate([[0], new_solution[i][1:-1], [0]])\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return np.array(new_solution, dtype=object)\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Capacitated Vehicle Routing Problem (Bi-CVRP), where a single depot and multiple customers are located in 2D space. Each customer has a positive demand, and all vehicles in the fleet have identical capacity limits. The objective is to construct a set of routes, each starting and ending at the depot, such that all customers are served, vehicle capacities are not exceeded on any route, and two conflicting objectives are minimized: (1) the total travel distance across all routes, and (2) the makespan, defined as the length of the longest individual route. Each solution in the archive is represented as a list of NumPy arrays, where each array denotes a single route (starting and ending with depot index 0), and is paired with a tuple of two objective values (total_distance, makespan). Your task is to implement a function named 'select_neighbor' that selects one promising solution from the archive and apply a novel or hybrid local search operator to generate a feasible neighbor solution from it. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself. Avoid standard methods like pure 2-opt; instead, invent or combine transformations, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. Ensure that the returned neighbor solution remains feasible under the vehicle capacity constraint. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm implements a demand-aware, multi-objective local search for the Bi-CVRP by first selecting promising solutions from the archive (prioritizing those with better balanced objectives), then applying a two-phase local search combining spatial-temporal clustering of high-demand nodes with adaptive segment migration between routes, while always maintaining feasibility through capacity-aware repairs. It dynamically adjusts search intensity based on objective diversity in the archive and prioritizes spatial, demand, and temporal considerations when making route modifications.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive solution selection with diversity-aware objective balance\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] * 0.6 + x[1][1] * 0.4))\n    top_80 = int(len(archive) * 0.8)\n    if top_80 < 1:\n        top_80 = 1\n    if random.random() < 0.2:  # 20% chance to select randomly\n        selected_idx = random.randint(0, len(archive) - 1)\n    else:\n        selected_idx = random.randint(0, top_80 - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate archive diversity and objective balance\n    diversity_threshold = 0.4\n    if len(archive) > 5:\n        unique_makespans = len(set(x[1][1] for x in archive))\n        diversity_ratio = unique_makespans / len(archive)\n        aggressive_search = diversity_ratio < diversity_threshold\n    else:\n        aggressive_search = True\n\n    # Phase 1: Demand-aware spatial-temporal clustering\n    high_demand_nodes = [i for i in range(1, len(demand)) if demand[i] > capacity * 0.5]\n    if high_demand_nodes and len(new_solution) > 1:\n        # Modified DBSCAN with temporal constraints\n        from sklearn.cluster import DBSCAN\n        coords_high_demand = coords[high_demand_nodes]\n        clustering = DBSCAN(eps=0.6, min_samples=2).fit(coords_high_demand)\n        clusters = clustering.labels_\n\n        # Process each cluster\n        for cluster_id in np.unique(clusters):\n            if cluster_id == -1:\n                continue\n            cluster_nodes = [high_demand_nodes[i] for i, label in enumerate(clusters) if label == cluster_id]\n            routes_with_cluster = [i for i, route in enumerate(new_solution)\n                                 if any(node in route for node in cluster_nodes)]\n\n            if len(routes_with_cluster) > 1:\n                # Select routes to merge based on temporal and spatial characteristics\n                route1_idx, route2_idx = random.sample(routes_with_cluster, 2)\n                route1 = new_solution[route1_idx]\n                route2 = new_solution[route2_idx]\n\n                # Find optimal merge points considering demand, distance, and spatial-temporal balance\n                best_cost = float('inf')\n                best_insertion = None\n                for i in range(1, len(route1)-1):\n                    for j in range(1, len(route2)-1):\n                        dist_cost = distance_matrix[route1[i-1]][route2[j]] + distance_matrix[route2[j-1]][route1[i]]\n                        demand_cost = abs(sum(demand[route1[1:i]]) + sum(demand[route2[j:-1]]) - capacity/2)\n                        spatial_cost = np.linalg.norm(coords[route1[i]] - coords[route2[j]])\n                        temporal_cost = abs(len(route1) - len(route2)) / max(len(route1), len(route2))\n\n                        total_cost = dist_cost + demand_cost * 0.4 + spatial_cost * 0.3 + temporal_cost * 0.3\n\n                        if total_cost < best_cost:\n                            best_cost = total_cost\n                            best_insertion = (i, j)\n\n                if best_insertion:\n                    i, j = best_insertion\n                    merged_route = np.concatenate([route1[:i], route2[j:-1], [0]])\n                    if sum(demand[merged_route[1:-1]]) <= capacity:\n                        new_solution[route1_idx] = merged_route\n                        new_solution.pop(route2_idx)\n\n    # Phase 2: Adaptive multi-objective segment migration\n    if len(new_solution) > 1:\n        iterations = 8 if aggressive_search else 4\n        for _ in range(iterations):\n            route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n            route1 = new_solution[route1_idx]\n            route2 = new_solution[route2_idx]\n\n            if len(route1) > 3 and len(route2) > 3:\n                # Select segments based on multi-objective characteristics\n                segment_length = min(3, len(route1)-2, len(route2)-2)\n                i = random.randint(1, len(route1)-segment_length)\n                j = random.randint(1, len(route2)-segment_length)\n\n                segment1 = route1[i:i+segment_length]\n                segment2 = route2[j:j+segment_length]\n\n                # Check compatibility using multi-criteria\n                demand1 = sum(demand[segment1])\n                demand2 = sum(demand[segment2])\n                demand_compatibility = abs(demand1 - demand2) / capacity\n\n                center1 = np.mean(coords[segment1], axis=0)\n                center2 = np.mean(coords[segment2], axis=0)\n                spatial_distance = np.linalg.norm(center1 - center2)\n\n                temporal_balance = abs(len(route1) - len(route2)) / max(len(route1), len(route2))\n\n                if (demand_compatibility < 0.7 and\n                    spatial_distance < np.mean(distance_matrix) * 1.2 and\n                    temporal_balance < 0.5):\n                    # Try migrating segments\n                    new_route1 = np.concatenate([route1[:i], segment2, route1[i+segment_length:]])\n                    new_route2 = np.concatenate([route2[:j], segment1, route2[j+segment_length:]])\n\n                    if (sum(demand[new_route1[1:-1]]) <= capacity and\n                        sum(demand[new_route2[1:-1]]) <= capacity):\n                        # Calculate multi-objective improvements\n                        old_dist = (sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))) +\n                                   sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_dist = (sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))) +\n                                   sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        old_makespan = max(sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))),\n                                         sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_makespan = max(sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))),\n                                         sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        # Accept if both objectives improve or one improves significantly\n                        if ((new_dist < old_dist * 0.97 and new_makespan <= old_makespan) or\n                            (new_makespan < old_makespan * 0.97 and new_dist <= old_dist) or\n                            (new_dist < old_dist * 0.98 and new_makespan < old_makespan * 0.98)):\n                            new_solution[route1_idx] = new_route1\n                            new_solution[route2_idx] = new_route2\n\n    # Feasibility restoration with multi-criteria splitting\n    for i in range(len(new_solution)):\n        route = new_solution[i]\n        if sum(demand[route[1:-1]]) > capacity:\n            # Find split point that minimizes multi-criteria disruption\n            best_split = 1\n            best_score = float('inf')\n\n            for j in range(1, len(route)-1):\n                left_demand = sum(demand[route[1:j]])\n                right_demand = sum(demand[route[j:-1]])\n\n                if left_demand <= capacity and right_demand <= capacity:\n                    # Calculate multi-criteria disruption score\n                    left_center = np.mean(coords[route[1:j]], axis=0)\n                    right_center = np.mean(coords[route[j:-1]], axis=0)\n                    spatial_score = np.linalg.norm(left_center - right_center)\n\n                    demand_score = abs(left_demand - right_demand) / capacity\n                    temporal_score = abs(len(route[1:j]) - len(route[j:-1])) / len(route[1:-1])\n\n                    total_score = spatial_score * 0.4 + demand_score * 0.3 + temporal_score * 0.3\n\n                    if total_score < best_score:\n                        best_score = total_score\n                        best_split = j\n\n            new_route = np.concatenate([route[:best_split], [0]])\n            remaining_route = np.concatenate([[0], route[best_split:]])\n            new_solution[i] = new_route\n            new_solution.append(remaining_route)\n\n    # Final validation\n    for i in range(len(new_solution)):\n        if new_solution[i][0] != 0 or new_solution[i][-1] != 0:\n            new_solution[i] = np.concatenate([[0], new_solution[i][1:-1], [0]])\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return np.array(new_solution, dtype=object)\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 304,
        "algorithm": "This algorithm implements a demand-aware, multi-objective local search for Bi-CVRP by first selecting solutions based on a 40-60 weighted combination of distance and makespan, then applying a hybrid approach combining spatial clustering of high-demand nodes with adaptive route balancing, while ensuring feasibility through capacity-aware route splitting and prioritizing spatial proximity, demand compatibility, and temporal balance in improvements. The method uses DBSCAN for clustering, evaluates multiple insertion points with weighted costs, and employs aggressive exploration when solution diversity is low, with feasibility restoration focusing on balanced spatial, demand, and temporal criteria.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Solution selection with different objective weighting\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] * 0.4 + x[1][1] * 0.6))\n    top_70 = int(len(archive) * 0.7)\n    if top_70 < 1:\n        top_70 = 1\n    if random.random() < 0.3:  # 30% chance to select randomly\n        selected_idx = random.randint(0, len(archive) - 1)\n    else:\n        selected_idx = random.randint(0, top_70 - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate archive diversity with different threshold\n    diversity_threshold = 0.35\n    if len(archive) > 5:\n        unique_distances = len(set(x[1][0] for x in archive))\n        diversity_ratio = unique_distances / len(archive)\n        aggressive_search = diversity_ratio < diversity_threshold\n    else:\n        aggressive_search = True\n\n    # Phase 1: Demand-aware spatial clustering with different parameters\n    high_demand_nodes = [i for i in range(1, len(demand)) if demand[i] > capacity * 0.4]\n    if high_demand_nodes and len(new_solution) > 1:\n        from sklearn.cluster import DBSCAN\n        coords_high_demand = coords[high_demand_nodes]\n        clustering = DBSCAN(eps=0.5, min_samples=1).fit(coords_high_demand)\n        clusters = clustering.labels_\n\n        for cluster_id in np.unique(clusters):\n            if cluster_id == -1:\n                continue\n            cluster_nodes = [high_demand_nodes[i] for i, label in enumerate(clusters) if label == cluster_id]\n            routes_with_cluster = [i for i, route in enumerate(new_solution)\n                                 if any(node in route for node in cluster_nodes)]\n\n            if len(routes_with_cluster) > 1:\n                route1_idx, route2_idx = random.sample(routes_with_cluster, 2)\n                route1 = new_solution[route1_idx]\n                route2 = new_solution[route2_idx]\n\n                best_cost = float('inf')\n                best_insertion = None\n                for i in range(1, len(route1)-1):\n                    for j in range(1, len(route2)-1):\n                        dist_cost = distance_matrix[route1[i-1]][route2[j]] + distance_matrix[route2[j-1]][route1[i]]\n                        demand_cost = abs(sum(demand[route1[1:i]]) + sum(demand[route2[j:-1]]) - capacity/1.5)\n                        spatial_cost = np.linalg.norm(coords[route1[i]] - coords[route2[j]]) * 0.8\n\n                        total_cost = dist_cost + demand_cost * 0.5 + spatial_cost * 0.5\n\n                        if total_cost < best_cost:\n                            best_cost = total_cost\n                            best_insertion = (i, j)\n\n                if best_insertion:\n                    i, j = best_insertion\n                    merged_route = np.concatenate([route1[:i], route2[j:-1], [0]])\n                    if sum(demand[merged_route[1:-1]]) <= capacity:\n                        new_solution[route1_idx] = merged_route\n                        new_solution.pop(route2_idx)\n\n    # Phase 2: Adaptive route balancing with different parameters\n    if len(new_solution) > 1:\n        iterations = 10 if aggressive_search else 5\n        for _ in range(iterations):\n            route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n            route1 = new_solution[route1_idx]\n            route2 = new_solution[route2_idx]\n\n            if len(route1) > 3 and len(route2) > 3:\n                segment_length = min(2, len(route1)-2, len(route2)-2)\n                i = random.randint(1, len(route1)-segment_length)\n                j = random.randint(1, len(route2)-segment_length)\n\n                segment1 = route1[i:i+segment_length]\n                segment2 = route2[j:j+segment_length]\n\n                demand1 = sum(demand[segment1])\n                demand2 = sum(demand[segment2])\n                demand_compatibility = abs(demand1 - demand2) / capacity\n\n                center1 = np.mean(coords[segment1], axis=0)\n                center2 = np.mean(coords[segment2], axis=0)\n                spatial_distance = np.linalg.norm(center1 - center2) * 1.2\n\n                temporal_balance = abs(len(route1) - len(route2)) / max(len(route1), len(route2))\n\n                if (demand_compatibility < 0.6 and\n                    spatial_distance < np.mean(distance_matrix) * 1.5 and\n                    temporal_balance < 0.6):\n                    new_route1 = np.concatenate([route1[:i], segment2, route1[i+segment_length:]])\n                    new_route2 = np.concatenate([route2[:j], segment1, route2[j+segment_length:]])\n\n                    if (sum(demand[new_route1[1:-1]]) <= capacity and\n                        sum(demand[new_route2[1:-1]]) <= capacity):\n                        old_dist = (sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))) +\n                                   sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_dist = (sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))) +\n                                   sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        old_makespan = max(sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))),\n                                         sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_makespan = max(sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))),\n                                         sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        if ((new_dist < old_dist * 0.95 and new_makespan <= old_makespan) or\n                            (new_makespan < old_makespan * 0.95 and new_dist <= old_dist) or\n                            (new_dist < old_dist * 0.97 and new_makespan < old_makespan * 0.97)):\n                            new_solution[route1_idx] = new_route1\n                            new_solution[route2_idx] = new_route2\n\n    # Feasibility restoration with different criteria\n    for i in range(len(new_solution)):\n        route = new_solution[i]\n        if sum(demand[route[1:-1]]) > capacity:\n            best_split = 1\n            best_score = float('inf')\n\n            for j in range(1, len(route)-1):\n                left_demand = sum(demand[route[1:j]])\n                right_demand = sum(demand[route[j:-1]])\n\n                if left_demand <= capacity and right_demand <= capacity:\n                    left_center = np.mean(coords[route[1:j]], axis=0)\n                    right_center = np.mean(coords[route[j:-1]], axis=0)\n                    spatial_score = np.linalg.norm(left_center - right_center) * 0.6\n\n                    demand_score = abs(left_demand - right_demand) / capacity\n                    temporal_score = abs(len(route[1:j]) - len(route[j:-1])) / len(route[1:-1])\n\n                    total_score = spatial_score * 0.5 + demand_score * 0.4 + temporal_score * 0.1\n\n                    if total_score < best_score:\n                        best_score = total_score\n                        best_split = j\n\n            new_route = np.concatenate([route[:best_split], [0]])\n            remaining_route = np.concatenate([[0], route[best_split:]])\n            new_solution[i] = new_route\n            new_solution.append(remaining_route)\n\n    for i in range(len(new_solution)):\n        if new_solution[i][0] != 0 or new_solution[i][-1] != 0:\n            new_solution[i] = np.concatenate([[0], new_solution[i][1:-1], [0]])\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return np.array(new_solution, dtype=object)\n\n",
        "metric_score": [
            -0.3987538155790885,
            3.5851824283599854
        ],
        "raw_score": [
            27.960695228319157,
            3.1813591605051994
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Solution selection with different objective weighting\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] * 0.4 + x[1][1] * 0.6))\n    top_70 = int(len(archive) * 0.7)\n    if top_70 < 1:\n        top_70 = 1\n    if random.random() < 0.3:  # 30% chance to select randomly\n        selected_idx = random.randint(0, len(archive) - 1)\n    else:\n        selected_idx = random.randint(0, top_70 - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate archive diversity with different threshold\n    diversity_threshold = 0.35\n    if len(archive) > 5:\n        unique_distances = len(set(x[1][0] for x in archive))\n        diversity_ratio = unique_distances / len(archive)\n        aggressive_search = diversity_ratio < diversity_threshold\n    else:\n        aggressive_search = True\n\n    # Phase 1: Demand-aware spatial clustering with different parameters\n    high_demand_nodes = [i for i in range(1, len(demand)) if demand[i] > capacity * 0.4]\n    if high_demand_nodes and len(new_solution) > 1:\n        from sklearn.cluster import DBSCAN\n        coords_high_demand = coords[high_demand_nodes]\n        clustering = DBSCAN(eps=0.5, min_samples=1).fit(coords_high_demand)\n        clusters = clustering.labels_\n\n        for cluster_id in np.unique(clusters):\n            if cluster_id == -1:\n                continue\n            cluster_nodes = [high_demand_nodes[i] for i, label in enumerate(clusters) if label == cluster_id]\n            routes_with_cluster = [i for i, route in enumerate(new_solution)\n                                 if any(node in route for node in cluster_nodes)]\n\n            if len(routes_with_cluster) > 1:\n                route1_idx, route2_idx = random.sample(routes_with_cluster, 2)\n                route1 = new_solution[route1_idx]\n                route2 = new_solution[route2_idx]\n\n                best_cost = float('inf')\n                best_insertion = None\n                for i in range(1, len(route1)-1):\n                    for j in range(1, len(route2)-1):\n                        dist_cost = distance_matrix[route1[i-1]][route2[j]] + distance_matrix[route2[j-1]][route1[i]]\n                        demand_cost = abs(sum(demand[route1[1:i]]) + sum(demand[route2[j:-1]]) - capacity/1.5)\n                        spatial_cost = np.linalg.norm(coords[route1[i]] - coords[route2[j]]) * 0.8\n\n                        total_cost = dist_cost + demand_cost * 0.5 + spatial_cost * 0.5\n\n                        if total_cost < best_cost:\n                            best_cost = total_cost\n                            best_insertion = (i, j)\n\n                if best_insertion:\n                    i, j = best_insertion\n                    merged_route = np.concatenate([route1[:i], route2[j:-1], [0]])\n                    if sum(demand[merged_route[1:-1]]) <= capacity:\n                        new_solution[route1_idx] = merged_route\n                        new_solution.pop(route2_idx)\n\n    # Phase 2: Adaptive route balancing with different parameters\n    if len(new_solution) > 1:\n        iterations = 10 if aggressive_search else 5\n        for _ in range(iterations):\n            route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n            route1 = new_solution[route1_idx]\n            route2 = new_solution[route2_idx]\n\n            if len(route1) > 3 and len(route2) > 3:\n                segment_length = min(2, len(route1)-2, len(route2)-2)\n                i = random.randint(1, len(route1)-segment_length)\n                j = random.randint(1, len(route2)-segment_length)\n\n                segment1 = route1[i:i+segment_length]\n                segment2 = route2[j:j+segment_length]\n\n                demand1 = sum(demand[segment1])\n                demand2 = sum(demand[segment2])\n                demand_compatibility = abs(demand1 - demand2) / capacity\n\n                center1 = np.mean(coords[segment1], axis=0)\n                center2 = np.mean(coords[segment2], axis=0)\n                spatial_distance = np.linalg.norm(center1 - center2) * 1.2\n\n                temporal_balance = abs(len(route1) - len(route2)) / max(len(route1), len(route2))\n\n                if (demand_compatibility < 0.6 and\n                    spatial_distance < np.mean(distance_matrix) * 1.5 and\n                    temporal_balance < 0.6):\n                    new_route1 = np.concatenate([route1[:i], segment2, route1[i+segment_length:]])\n                    new_route2 = np.concatenate([route2[:j], segment1, route2[j+segment_length:]])\n\n                    if (sum(demand[new_route1[1:-1]]) <= capacity and\n                        sum(demand[new_route2[1:-1]]) <= capacity):\n                        old_dist = (sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))) +\n                                   sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_dist = (sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))) +\n                                   sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        old_makespan = max(sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))),\n                                         sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_makespan = max(sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))),\n                                         sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        if ((new_dist < old_dist * 0.95 and new_makespan <= old_makespan) or\n                            (new_makespan < old_makespan * 0.95 and new_dist <= old_dist) or\n                            (new_dist < old_dist * 0.97 and new_makespan < old_makespan * 0.97)):\n                            new_solution[route1_idx] = new_route1\n                            new_solution[route2_idx] = new_route2\n\n    # Feasibility restoration with different criteria\n    for i in range(len(new_solution)):\n        route = new_solution[i]\n        if sum(demand[route[1:-1]]) > capacity:\n            best_split = 1\n            best_score = float('inf')\n\n            for j in range(1, len(route)-1):\n                left_demand = sum(demand[route[1:j]])\n                right_demand = sum(demand[route[j:-1]])\n\n                if left_demand <= capacity and right_demand <= capacity:\n                    left_center = np.mean(coords[route[1:j]], axis=0)\n                    right_center = np.mean(coords[route[j:-1]], axis=0)\n                    spatial_score = np.linalg.norm(left_center - right_center) * 0.6\n\n                    demand_score = abs(left_demand - right_demand) / capacity\n                    temporal_score = abs(len(route[1:j]) - len(route[j:-1])) / len(route[1:-1])\n\n                    total_score = spatial_score * 0.5 + demand_score * 0.4 + temporal_score * 0.1\n\n                    if total_score < best_score:\n                        best_score = total_score\n                        best_split = j\n\n            new_route = np.concatenate([route[:best_split], [0]])\n            remaining_route = np.concatenate([[0], route[best_split:]])\n            new_solution[i] = new_route\n            new_solution.append(remaining_route)\n\n    for i in range(len(new_solution)):\n        if new_solution[i][0] != 0 or new_solution[i][-1] != 0:\n            new_solution[i] = np.concatenate([[0], new_solution[i][1:-1], [0]])\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return np.array(new_solution, dtype=object)\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Capacitated Vehicle Routing Problem (Bi-CVRP), where a single depot and multiple customers are located in 2D space. Each customer has a positive demand, and all vehicles in the fleet have identical capacity limits. The objective is to construct a set of routes, each starting and ending at the depot, such that all customers are served, vehicle capacities are not exceeded on any route, and two conflicting objectives are minimized: (1) the total travel distance across all routes, and (2) the makespan, defined as the length of the longest individual route. Each solution in the archive is represented as a list of NumPy arrays, where each array denotes a single route (starting and ending with depot index 0), and is paired with a tuple of two objective values (total_distance, makespan). Your task is to implement a function named 'select_neighbor' that selects one promising solution from the archive and apply a novel or hybrid local search operator to generate a feasible neighbor solution from it. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself. Avoid standard methods like pure 2-opt; instead, invent or combine transformations, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. Ensure that the returned neighbor solution remains feasible under the vehicle capacity constraint. The function should return the new neighbor solution.\n            I have 8 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm implements a demand-aware, multi-objective local search for the Bi-CVRP by first selecting promising solutions from the archive (prioritizing those with better balanced objectives), then applying a two-phase local search combining spatial-temporal clustering of high-demand nodes with adaptive segment migration between routes, while always maintaining feasibility through capacity-aware repairs. It dynamically adjusts search intensity based on objective diversity in the archive and prioritizes spatial, demand, and temporal considerations when making route modifications.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive solution selection with diversity-aware objective balance\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] * 0.6 + x[1][1] * 0.4))\n    top_80 = int(len(archive) * 0.8)\n    if top_80 < 1:\n        top_80 = 1\n    if random.random() < 0.2:  # 20% chance to select randomly\n        selected_idx = random.randint(0, len(archive) - 1)\n    else:\n        selected_idx = random.randint(0, top_80 - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate archive diversity and objective balance\n    diversity_threshold = 0.4\n    if len(archive) > 5:\n        unique_makespans = len(set(x[1][1] for x in archive))\n        diversity_ratio = unique_makespans / len(archive)\n        aggressive_search = diversity_ratio < diversity_threshold\n    else:\n        aggressive_search = True\n\n    # Phase 1: Demand-aware spatial-temporal clustering\n    high_demand_nodes = [i for i in range(1, len(demand)) if demand[i] > capacity * 0.5]\n    if high_demand_nodes and len(new_solution) > 1:\n        # Modified DBSCAN with temporal constraints\n        from sklearn.cluster import DBSCAN\n        coords_high_demand = coords[high_demand_nodes]\n        clustering = DBSCAN(eps=0.6, min_samples=2).fit(coords_high_demand)\n        clusters = clustering.labels_\n\n        # Process each cluster\n        for cluster_id in np.unique(clusters):\n            if cluster_id == -1:\n                continue\n            cluster_nodes = [high_demand_nodes[i] for i, label in enumerate(clusters) if label == cluster_id]\n            routes_with_cluster = [i for i, route in enumerate(new_solution)\n                                 if any(node in route for node in cluster_nodes)]\n\n            if len(routes_with_cluster) > 1:\n                # Select routes to merge based on temporal and spatial characteristics\n                route1_idx, route2_idx = random.sample(routes_with_cluster, 2)\n                route1 = new_solution[route1_idx]\n                route2 = new_solution[route2_idx]\n\n                # Find optimal merge points considering demand, distance, and spatial-temporal balance\n                best_cost = float('inf')\n                best_insertion = None\n                for i in range(1, len(route1)-1):\n                    for j in range(1, len(route2)-1):\n                        dist_cost = distance_matrix[route1[i-1]][route2[j]] + distance_matrix[route2[j-1]][route1[i]]\n                        demand_cost = abs(sum(demand[route1[1:i]]) + sum(demand[route2[j:-1]]) - capacity/2)\n                        spatial_cost = np.linalg.norm(coords[route1[i]] - coords[route2[j]])\n                        temporal_cost = abs(len(route1) - len(route2)) / max(len(route1), len(route2))\n\n                        total_cost = dist_cost + demand_cost * 0.4 + spatial_cost * 0.3 + temporal_cost * 0.3\n\n                        if total_cost < best_cost:\n                            best_cost = total_cost\n                            best_insertion = (i, j)\n\n                if best_insertion:\n                    i, j = best_insertion\n                    merged_route = np.concatenate([route1[:i], route2[j:-1], [0]])\n                    if sum(demand[merged_route[1:-1]]) <= capacity:\n                        new_solution[route1_idx] = merged_route\n                        new_solution.pop(route2_idx)\n\n    # Phase 2: Adaptive multi-objective segment migration\n    if len(new_solution) > 1:\n        iterations = 8 if aggressive_search else 4\n        for _ in range(iterations):\n            route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n            route1 = new_solution[route1_idx]\n            route2 = new_solution[route2_idx]\n\n            if len(route1) > 3 and len(route2) > 3:\n                # Select segments based on multi-objective characteristics\n                segment_length = min(3, len(route1)-2, len(route2)-2)\n                i = random.randint(1, len(route1)-segment_length)\n                j = random.randint(1, len(route2)-segment_length)\n\n                segment1 = route1[i:i+segment_length]\n                segment2 = route2[j:j+segment_length]\n\n                # Check compatibility using multi-criteria\n                demand1 = sum(demand[segment1])\n                demand2 = sum(demand[segment2])\n                demand_compatibility = abs(demand1 - demand2) / capacity\n\n                center1 = np.mean(coords[segment1], axis=0)\n                center2 = np.mean(coords[segment2], axis=0)\n                spatial_distance = np.linalg.norm(center1 - center2)\n\n                temporal_balance = abs(len(route1) - len(route2)) / max(len(route1), len(route2))\n\n                if (demand_compatibility < 0.7 and\n                    spatial_distance < np.mean(distance_matrix) * 1.2 and\n                    temporal_balance < 0.5):\n                    # Try migrating segments\n                    new_route1 = np.concatenate([route1[:i], segment2, route1[i+segment_length:]])\n                    new_route2 = np.concatenate([route2[:j], segment1, route2[j+segment_length:]])\n\n                    if (sum(demand[new_route1[1:-1]]) <= capacity and\n                        sum(demand[new_route2[1:-1]]) <= capacity):\n                        # Calculate multi-objective improvements\n                        old_dist = (sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))) +\n                                   sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_dist = (sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))) +\n                                   sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        old_makespan = max(sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))),\n                                         sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_makespan = max(sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))),\n                                         sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        # Accept if both objectives improve or one improves significantly\n                        if ((new_dist < old_dist * 0.97 and new_makespan <= old_makespan) or\n                            (new_makespan < old_makespan * 0.97 and new_dist <= old_dist) or\n                            (new_dist < old_dist * 0.98 and new_makespan < old_makespan * 0.98)):\n                            new_solution[route1_idx] = new_route1\n                            new_solution[route2_idx] = new_route2\n\n    # Feasibility restoration with multi-criteria splitting\n    for i in range(len(new_solution)):\n        route = new_solution[i]\n        if sum(demand[route[1:-1]]) > capacity:\n            # Find split point that minimizes multi-criteria disruption\n            best_split = 1\n            best_score = float('inf')\n\n            for j in range(1, len(route)-1):\n                left_demand = sum(demand[route[1:j]])\n                right_demand = sum(demand[route[j:-1]])\n\n                if left_demand <= capacity and right_demand <= capacity:\n                    # Calculate multi-criteria disruption score\n                    left_center = np.mean(coords[route[1:j]], axis=0)\n                    right_center = np.mean(coords[route[j:-1]], axis=0)\n                    spatial_score = np.linalg.norm(left_center - right_center)\n\n                    demand_score = abs(left_demand - right_demand) / capacity\n                    temporal_score = abs(len(route[1:j]) - len(route[j:-1])) / len(route[1:-1])\n\n                    total_score = spatial_score * 0.4 + demand_score * 0.3 + temporal_score * 0.3\n\n                    if total_score < best_score:\n                        best_score = total_score\n                        best_split = j\n\n            new_route = np.concatenate([route[:best_split], [0]])\n            remaining_route = np.concatenate([[0], route[best_split:]])\n            new_solution[i] = new_route\n            new_solution.append(remaining_route)\n\n    # Final validation\n    for i in range(len(new_solution)):\n        if new_solution[i][0] != 0 or new_solution[i][-1] != 0:\n            new_solution[i] = np.concatenate([[0], new_solution[i][1:-1], [0]])\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return np.array(new_solution, dtype=object)\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm implements a demand-aware local search for the Bi-CVRP that first clusters high-demand nodes using modified k-means, then performs capacity-preserving route merges and segment migrations between routes, with search intensity dynamically adjusted based on solution diversity and objective trade-offs, prioritizing solutions that improve both total distance and makespan while maintaining feasibility through spatial-aware splitting.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive solution selection with balanced objective preference\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] * 0.7 + x[1][1] * 0.3))\n    top_30 = int(len(archive) * 0.3)\n    if top_30 < 1:\n        top_30 = 1\n    if random.random() < 0.3:  # 30% chance to select randomly\n        selected_idx = random.randint(0, len(archive) - 1)\n    else:\n        selected_idx = random.randint(0, top_30 - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate solution diversity and objective balance\n    diversity_threshold = 0.5\n    if len(archive) > 3:\n        unique_makespans = len(set(x[1][1] for x in archive))\n        diversity_ratio = unique_makespans / len(archive)\n        aggressive_search = diversity_ratio < diversity_threshold\n    else:\n        aggressive_search = True\n\n    # Phase 1: Demand-spatial clustering\n    high_demand_nodes = [i for i in range(1, len(demand)) if demand[i] > capacity * 0.4]\n    if high_demand_nodes and len(new_solution) > 1:\n        # Modified k-means clustering with spatial constraints\n        k = min(3, len(new_solution))\n        centroids = random.sample([coords[i] for i in high_demand_nodes], k)\n        clusters = [[] for _ in range(k)]\n\n        for _ in range(5):  # 5 iterations\n            clusters = [[] for _ in range(k)]\n            for node in high_demand_nodes:\n                distances = [np.linalg.norm(coords[node] - c) for c in centroids]\n                closest = np.argmin(distances)\n                clusters[closest].append(node)\n\n            # Update centroids with spatial constraints\n            for i in range(k):\n                if clusters[i]:\n                    cluster_coords = coords[clusters[i]]\n                    new_centroid = np.mean(cluster_coords, axis=0)\n                    # Ensure centroid is near cluster nodes\n                    closest_node = min(clusters[i], key=lambda x: np.linalg.norm(coords[x] - new_centroid))\n                    centroids[i] = coords[closest_node]\n\n        # Process each cluster\n        for cluster in clusters:\n            if not cluster:\n                continue\n            routes_with_cluster = [i for i, route in enumerate(new_solution)\n                                 if any(node in route for node in cluster)]\n\n            if len(routes_with_cluster) > 1:\n                # Select routes to merge based on demand and spatial balance\n                route1_idx, route2_idx = random.sample(routes_with_cluster, 2)\n                route1 = new_solution[route1_idx]\n                route2 = new_solution[route2_idx]\n\n                # Find optimal merge points considering demand, distance, and spatial proximity\n                best_cost = float('inf')\n                best_insertion = None\n                for i in range(1, len(route1)-1):\n                    for j in range(1, len(route2)-1):\n                        dist_cost = distance_matrix[route1[i-1]][route2[j]] + distance_matrix[route2[j-1]][route1[i]]\n                        demand_cost = abs(sum(demand[route1[1:i]]) + sum(demand[route2[j:-1]]) - capacity/2)\n                        spatial_cost = np.linalg.norm(coords[route1[i]] - coords[route2[j]])\n                        total_cost = dist_cost + demand_cost * 0.5 + spatial_cost * 0.3\n\n                        if total_cost < best_cost:\n                            best_cost = total_cost\n                            best_insertion = (i, j)\n\n                if best_insertion:\n                    i, j = best_insertion\n                    merged_route = np.concatenate([route1[:i], route2[j:-1], [0]])\n                    if sum(demand[merged_route[1:-1]]) <= capacity:\n                        new_solution[route1_idx] = merged_route\n                        new_solution.pop(route2_idx)\n\n    # Phase 2: Adaptive segment migration\n    if len(new_solution) > 1:\n        iterations = 5 if aggressive_search else 2\n        for _ in range(iterations):\n            route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n            route1 = new_solution[route1_idx]\n            route2 = new_solution[route2_idx]\n\n            if len(route1) > 3 and len(route2) > 3:\n                # Select segments based on demand and spatial characteristics\n                segment_length = min(2, len(route1)-2, len(route2)-2)\n                i = random.randint(1, len(route1)-segment_length)\n                j = random.randint(1, len(route2)-segment_length)\n\n                segment1 = route1[i:i+segment_length]\n                segment2 = route2[j:j+segment_length]\n\n                # Check compatibility\n                demand1 = sum(demand[segment1])\n                demand2 = sum(demand[segment2])\n                demand_compatibility = abs(demand1 - demand2) / capacity\n\n                center1 = np.mean(coords[segment1], axis=0)\n                center2 = np.mean(coords[segment2], axis=0)\n                spatial_distance = np.linalg.norm(center1 - center2)\n\n                if (demand_compatibility < 0.6 and\n                    spatial_distance < np.mean(distance_matrix) * 1.5):\n                    # Try migrating segments\n                    new_route1 = np.concatenate([route1[:i], segment2, route1[i+segment_length:]])\n                    new_route2 = np.concatenate([route2[:j], segment1, route2[j+segment_length:]])\n\n                    if (sum(demand[new_route1[1:-1]]) <= capacity and\n                        sum(demand[new_route2[1:-1]]) <= capacity):\n                        # Calculate objective improvements\n                        old_dist = (sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))) +\n                                   sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_dist = (sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))) +\n                                   sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        old_makespan = max(sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))),\n                                         sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_makespan = max(sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))),\n                                         sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        # Accept if either objective improves or both improve slightly\n                        if ((new_dist < old_dist * 0.98 and new_makespan <= old_makespan) or\n                            (new_makespan < old_makespan * 0.98 and new_dist <= old_dist) or\n                            (new_dist < old_dist * 0.99 and new_makespan < old_makespan * 0.99)):\n                            new_solution[route1_idx] = new_route1\n                            new_solution[route2_idx] = new_route2\n\n    # Feasibility restoration with spatial-aware splitting\n    for i in range(len(new_solution)):\n        route = new_solution[i]\n        if sum(demand[route[1:-1]]) > capacity:\n            # Find split point that minimizes spatial disruption\n            best_split = 1\n            best_score = float('inf')\n\n            for j in range(1, len(route)-1):\n                left_demand = sum(demand[route[1:j]])\n                right_demand = sum(demand[route[j:-1]])\n\n                if left_demand <= capacity and right_demand <= capacity:\n                    # Calculate spatial disruption score\n                    left_center = np.mean(coords[route[1:j]], axis=0)\n                    right_center = np.mean(coords[route[j:-1]], axis=0)\n                    spatial_score = np.linalg.norm(left_center - right_center)\n\n                    if spatial_score < best_score:\n                        best_score = spatial_score\n                        best_split = j\n\n            new_route = np.concatenate([route[:best_split], [0]])\n            remaining_route = np.concatenate([[0], route[best_split:]])\n            new_solution[i] = new_route\n            new_solution.append(remaining_route)\n\n    # Final validation\n    for i in range(len(new_solution)):\n        if new_solution[i][0] != 0 or new_solution[i][-1] != 0:\n            new_solution[i] = np.concatenate([[0], new_solution[i][1:-1], [0]])\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return np.array(new_solution, dtype=object)\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive solution selection with a hybrid local search that prioritizes high-demand nodes, uses spatial clustering (DBSCAN) for route restructuring, and employs demand-aware segment swapping with aggressive search modes when solution diversity is low. It balances exploitation (via weighted probabilistic selection and demand-driven operations) with exploration (through spatial clustering and segment swapping) while maintaining feasibility through capacity-constrained merging and splitting. The approach dynamically adjusts search intensity based on archive diversity and accepts improvements in both total distance and makespan objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive solution selection with weighted probabilistic approach\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] * 0.6 + x[1][1] * 0.4))\n    selection_pool = archive_sorted[:max(1, int(len(archive) * 0.3))]\n\n    weights = [1/((i+1)**1.5) for i in range(len(selection_pool))]\n    selected_idx = random.choices(range(len(selection_pool)), weights=weights, k=1)[0]\n    base_solution = selection_pool[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate solution diversity for adaptive search intensity\n    diversity_threshold = 0.4\n    if len(archive) > 4:\n        unique_makespans = len(set(x[1][1] for x in archive))\n        diversity_ratio = unique_makespans / len(archive)\n        aggressive_search = diversity_ratio < diversity_threshold\n    else:\n        aggressive_search = True\n\n    # Phase 1: Demand-driven route restructuring with spatial clustering\n    if len(new_solution) > 1 and random.random() < 0.6:\n        # Identify high-demand clusters using DBSCAN\n        high_demand_threshold = capacity * 0.6\n        high_demand_nodes = [i for i in range(1, len(demand)) if demand[i] > high_demand_threshold]\n\n        if high_demand_nodes:\n            from sklearn.cluster import DBSCAN\n            eps = np.mean([np.percentile(distance_matrix[i, :], 25) for i in high_demand_nodes])\n            dbscan = DBSCAN(eps=eps, min_samples=2).fit(coords[high_demand_nodes])\n            labels = dbscan.labels_\n\n            # Process each cluster\n            for cluster_id in set(labels):\n                if cluster_id == -1:\n                    continue\n                cluster_nodes = [high_demand_nodes[i] for i, label in enumerate(labels) if label == cluster_id]\n                routes_with_cluster = [i for i, route in enumerate(new_solution)\n                                     if any(node in route for node in cluster_nodes)]\n\n                if len(routes_with_cluster) > 1:\n                    # Select routes to merge based on demand balance\n                    route1_idx, route2_idx = random.sample(routes_with_cluster, 2)\n                    route1 = new_solution[route1_idx]\n                    route2 = new_solution[route2_idx]\n\n                    # Find optimal merge points considering both distance and demand balance\n                    best_cost = float('inf')\n                    best_insertion = None\n                    for i in range(1, len(route1)-1):\n                        for j in range(1, len(route2)-1):\n                            dist_cost = distance_matrix[route1[i-1]][route2[j]] + distance_matrix[route2[j-1]][route1[i]]\n                            demand_cost = abs(sum(demand[route1[1:i]]) + sum(demand[route2[j:-1]]) - capacity/2)\n                            spatial_cost = np.linalg.norm(coords[route1[i]] - coords[route2[j]])\n                            total_cost = dist_cost + demand_cost * 0.4 + spatial_cost * 0.2\n\n                            if total_cost < best_cost:\n                                best_cost = total_cost\n                                best_insertion = (i, j)\n\n                    if best_insertion:\n                        i, j = best_insertion\n                        merged_route = np.concatenate([route1[:i], route2[j:-1], [0]])\n                        if sum(demand[merged_route[1:-1]]) <= capacity:\n                            new_solution[route1_idx] = merged_route\n                            new_solution.pop(route2_idx)\n\n    # Phase 2: Adaptive segment swapping with demand and spatial constraints\n    if aggressive_search and len(new_solution) > 1:\n        for _ in range(3 if aggressive_search else 1):\n            route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n            route1 = new_solution[route1_idx]\n            route2 = new_solution[route2_idx]\n\n            if len(route1) > 3 and len(route2) > 3:\n                # Select segments based on demand and spatial characteristics\n                segment_length = min(3, len(route1)-2, len(route2)-2)\n                i = random.randint(1, len(route1)-segment_length)\n                j = random.randint(1, len(route2)-segment_length)\n\n                segment1 = route1[i:i+segment_length]\n                segment2 = route2[j:j+segment_length]\n\n                # Check compatibility\n                demand1 = sum(demand[segment1])\n                demand2 = sum(demand[segment2])\n                demand_compatibility = abs(demand1 - demand2) / capacity\n\n                center1 = np.mean(coords[segment1], axis=0)\n                center2 = np.mean(coords[segment2], axis=0)\n                spatial_distance = np.linalg.norm(center1 - center2)\n\n                if (demand_compatibility < 0.5 and\n                    spatial_distance < np.mean(distance_matrix) * 1.2):\n                    # Try swapping segments\n                    new_route1 = np.concatenate([route1[:i], segment2, route1[i+segment_length:]])\n                    new_route2 = np.concatenate([route2[:j], segment1, route2[j+segment_length:]])\n\n                    if (sum(demand[new_route1[1:-1]]) <= capacity and\n                        sum(demand[new_route2[1:-1]]) <= capacity):\n                        # Calculate objective improvements\n                        old_dist = (sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))) +\n                                   sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_dist = (sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))) +\n                                   sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        old_makespan = max(sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))),\n                                         sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_makespan = max(sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))),\n                                         sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        # Accept if either objective improves significantly\n                        if (new_dist < old_dist * 0.95) or (new_makespan < old_makespan * 0.9):\n                            new_solution[route1_idx] = new_route1\n                            new_solution[route2_idx] = new_route2\n\n    # Feasibility restoration with demand-aware splitting\n    for i in range(len(new_solution)):\n        route = new_solution[i]\n        if sum(demand[route[1:-1]]) > capacity:\n            # Split route at the point where demand exceeds capacity\n            current_load = 0\n            split_pos = 1\n            for j in range(1, len(route)-1):\n                current_load += demand[route[j]]\n                if current_load > capacity:\n                    split_pos = j\n                    break\n\n            # Ensure split is near high-demand nodes if possible\n            high_demand_in_route = [node for node in route[1:-1] if demand[node] > capacity * 0.4]\n            if high_demand_in_route:\n                split_pos = min(route.index(node) for node in high_demand_in_route if route.index(node) > 1)\n\n            new_route = np.concatenate([route[:split_pos], [0]])\n            remaining_route = np.concatenate([[0], route[split_pos:]])\n            new_solution[i] = new_route\n            new_solution.append(remaining_route)\n\n    # Final validation\n    for i in range(len(new_solution)):\n        if new_solution[i][0] != 0 or new_solution[i][-1] != 0:\n            new_solution[i] = np.concatenate([[0], new_solution[i][1:-1], [0]])\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return np.array(new_solution, dtype=object)\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThis algorithm implements a multi-phase approach that combines demand-aware route segmentation with adaptive spatial clustering, dynamically balancing between distance optimization and makespan reduction through alternating phases of demand-driven route merging and spatial-density guided segment swaps while maintaining feasibility through capacity-constrained route restructuring. The algorithm prioritizes critical demand points and spatial proximity in route selection, with an aggressive search mode triggered when solution diversity is low, and uses weighted probabilistic selection to focus on promising solutions from the archive.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive selection based on objective diversity\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] * 0.7 + x[1][1] * 0.3))  # Weighted sum of objectives\n    selection_pool = archive_sorted[:max(1, int(len(archive) * 0.25))]\n\n    if len(selection_pool) > 1:\n        # Probabilistic selection favoring solutions with better trade-off\n        weights = [1/((i+1)**2) for i in range(len(selection_pool))]\n        selected_idx = random.choices(range(len(selection_pool)), weights=weights, k=1)[0]\n    else:\n        selected_idx = 0\n\n    base_solution = selection_pool[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate objective diversity\n    diversity_threshold = 0.5\n    if len(archive) > 3:\n        unique_makespans = len(set(x[1][1] for x in archive))\n        diversity_ratio = unique_makespans / len(archive)\n        aggressive_search = diversity_ratio < diversity_threshold\n    else:\n        aggressive_search = True\n\n    # Phase 1: Demand-aware route segmentation and merging\n    if len(new_solution) > 1 and random.random() < 0.7:\n        # Identify critical demand points\n        critical_demand_threshold = capacity * 0.7\n        critical_nodes = [i for i in range(1, len(demand)) if demand[i] > critical_demand_threshold]\n\n        if critical_nodes:\n            # Cluster critical nodes using DBSCAN for spatial density\n            from sklearn.cluster import DBSCAN\n            eps = np.mean([np.percentile(distance_matrix[i, :], 30) for i in critical_nodes])\n            dbscan = DBSCAN(eps=eps, min_samples=2).fit(coords[critical_nodes])\n            labels = dbscan.labels_\n\n            # Create clusters and merge routes containing nodes from same cluster\n            for cluster_id in set(labels):\n                if cluster_id == -1:\n                    continue\n                cluster_nodes = [critical_nodes[i] for i, label in enumerate(labels) if label == cluster_id]\n                routes_with_cluster = [i for i, route in enumerate(new_solution)\n                                      if any(node in route for node in cluster_nodes)]\n\n                if len(routes_with_cluster) > 1:\n                    # Select two routes to merge\n                    route1_idx, route2_idx = random.sample(routes_with_cluster, 2)\n                    route1 = new_solution[route1_idx]\n                    route2 = new_solution[route2_idx]\n\n                    # Find optimal merge points based on spatial proximity\n                    best_cost = float('inf')\n                    best_insertion = None\n                    for i in range(1, len(route1)-1):\n                        for j in range(1, len(route2)-1):\n                            # Cost function considers both distance and demand balance\n                            dist_cost = distance_matrix[route1[i-1]][route2[j]] + distance_matrix[route2[j-1]][route1[i]]\n                            demand_cost = abs(sum(demand[route1[1:i]]) + sum(demand[route2[j:-1]]) - capacity/2)\n                            total_cost = dist_cost + demand_cost * 0.5\n\n                            if total_cost < best_cost:\n                                best_cost = total_cost\n                                best_insertion = (i, j)\n\n                    if best_insertion:\n                        i, j = best_insertion\n                        merged_route = np.concatenate([route1[:i], route2[j:-1], [0]])\n                        if sum(demand[merged_route[1:-1]]) <= capacity:\n                            new_solution[route1_idx] = merged_route\n                            new_solution.pop(route2_idx)\n\n    # Phase 2: Adaptive segment swapping with spatial constraints\n    if aggressive_search:\n        for _ in range(2 + int(aggressive_search)):\n            if len(new_solution) < 2:\n                break\n\n            route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n            route1 = new_solution[route1_idx]\n            route2 = new_solution[route2_idx]\n\n            if len(route1) > 3 and len(route2) > 3:\n                # Find segments based on spatial and demand characteristics\n                segment_length = min(3, len(route1)-2, len(route2)-2)\n                i = random.randint(1, len(route1)-segment_length)\n                j = random.randint(1, len(route2)-segment_length)\n\n                segment1 = route1[i:i+segment_length]\n                segment2 = route2[j:j+segment_length]\n\n                # Check spatial compatibility\n                center1 = np.mean(coords[segment1], axis=0)\n                center2 = np.mean(coords[segment2], axis=0)\n                spatial_distance = np.linalg.norm(center1 - center2)\n\n                # Calculate compatibility score\n                demand1 = sum(demand[segment1])\n                demand2 = sum(demand[segment2])\n                demand_compatibility = abs(demand1 - demand2) / capacity\n\n                if spatial_distance < np.mean(distance_matrix) * 1.5 and demand_compatibility < 0.6:\n                    # Try swapping segments\n                    new_route1 = np.concatenate([route1[:i], segment2, route1[i+segment_length:]])\n                    new_route2 = np.concatenate([route2[:j], segment1, route2[j+segment_length:]])\n\n                    if (sum(demand[new_route1[1:-1]]) <= capacity and\n                        sum(demand[new_route2[1:-1]]) <= capacity):\n                        # Calculate objective improvements\n                        old_dist = (sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))) +\n                                   sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_dist = (sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))) +\n                                   sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        old_makespan = max(sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))),\n                                          sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_makespan = max(sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))),\n                                         sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        # Accept if either objective improves\n                        if new_dist < old_dist or new_makespan < old_makespan:\n                            new_solution[route1_idx] = new_route1\n                            new_solution[route2_idx] = new_route2\n\n    # Feasibility restoration\n    for i in range(len(new_solution)):\n        route = new_solution[i]\n        if sum(demand[route[1:-1]]) > capacity:\n            # Split route using spatial median\n            from sklearn.cluster import KMeans\n            node_coords = coords[route[1:-1]]\n            kmeans = KMeans(n_clusters=2, random_state=42).fit(node_coords)\n            labels = kmeans.labels_\n\n            split_pos = len(route) // 2\n            for j in range(1, len(route)-1):\n                if labels[j-1] != labels[0]:\n                    split_pos = j\n                    break\n\n            new_route = np.concatenate([route[:split_pos], [0]])\n            remaining_route = np.concatenate([[0], route[split_pos:]])\n            new_solution[i] = new_route\n            new_solution.append(remaining_route)\n\n    # Final validation\n    for i in range(len(new_solution)):\n        if new_solution[i][0] != 0 or new_solution[i][-1] != 0:\n            new_solution[i] = np.concatenate([[0], new_solution[i][1:-1], [0]])\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return np.array(new_solution, dtype=object)\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm combines diversity-aware selection with a hybrid local search that alternates between demand-balanced route clustering and objective-driven segment swapping, dynamically adjusting operator intensity based on archive diversity to optimize both distance and makespan while ensuring feasibility through capacity-constrained route restructuring and spatial-density guided demand reallocation. It prioritizes high-demand nodes in clustering and aggressively explores segment swaps when diversity is low, with feasibility checks and repairs to maintain constraints.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Diversity-aware selection\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]))\n    selection_pool = archive_sorted[:max(1, int(len(archive) * 0.3))]\n\n    if len(selection_pool) > 1:\n        # Randomly select from top 30% with probability proportional to inverse rank\n        weights = [1/(i+1) for i in range(len(selection_pool))]\n        selected_idx = random.choices(range(len(selection_pool)), weights=weights, k=1)[0]\n    else:\n        selected_idx = 0\n\n    base_solution = selection_pool[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate archive diversity\n    diversity_threshold = 0.4\n    if len(archive) > 5:\n        unique_distances = len(set(x[1][0] for x in archive))\n        diversity_ratio = unique_distances / len(archive)\n        aggressive_search = diversity_ratio < diversity_threshold\n    else:\n        aggressive_search = True\n\n    # Demand-balanced route clustering\n    if len(new_solution) > 1:\n        # Identify high-demand nodes\n        high_demand_threshold = capacity * 0.6\n        high_demand_nodes = [i for i in range(1, len(demand)) if demand[i] > high_demand_threshold]\n\n        if high_demand_nodes:\n            # Cluster high-demand nodes based on spatial proximity\n            from sklearn.cluster import KMeans\n            coords_high_demand = coords[high_demand_nodes]\n            n_clusters = min(3, len(high_demand_nodes))\n            if n_clusters > 1:\n                kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(coords_high_demand)\n                clusters = kmeans.labels_\n\n                # Assign clusters to routes\n                cluster_routes = {i: [] for i in range(n_clusters)}\n                for i, node in enumerate(high_demand_nodes):\n                    cluster_id = clusters[i]\n                    for route_idx, route in enumerate(new_solution):\n                        if node in route:\n                            cluster_routes[cluster_id].append((route_idx, node))\n                            break\n\n                # Merge routes with the same cluster\n                for cluster_id, nodes in cluster_routes.items():\n                    if len(nodes) > 1:\n                        routes_to_merge = set(route_idx for route_idx, _ in nodes)\n                        if len(routes_to_merge) > 1:\n                            routes_to_merge = list(routes_to_merge)\n                            route1_idx = routes_to_merge[0]\n                            route2_idx = routes_to_merge[1]\n\n                            # Try to merge the two routes\n                            route1 = new_solution[route1_idx]\n                            route2 = new_solution[route2_idx]\n\n                            # Find best insertion points\n                            best_cost = float('inf')\n                            best_insertion = None\n                            for i in range(1, len(route1)-1):\n                                for j in range(1, len(route2)-1):\n                                    cost = (distance_matrix[route1[i-1]][route2[j]] +\n                                            distance_matrix[route2[j-1]][route1[i]] -\n                                            distance_matrix[route1[i-1]][route1[i]] -\n                                            distance_matrix[route2[j-1]][route2[j]])\n\n                                    if cost < best_cost:\n                                        best_cost = cost\n                                        best_insertion = (i, j)\n\n                            if best_insertion:\n                                i, j = best_insertion\n                                merged_route = np.concatenate([route1[:i], route2[j:-1], [0]])\n                                if sum(demand[merged_route[1:-1]]) <= capacity:\n                                    new_solution[route1_idx] = merged_route\n                                    new_solution.pop(route2_idx)\n                                    break\n\n    # Objective-driven segment swapping\n    if aggressive_search:\n        for _ in range(3):  # More attempts for aggressive search\n            if len(new_solution) < 2:\n                break\n\n            route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n            route1 = new_solution[route1_idx]\n            route2 = new_solution[route2_idx]\n\n            if len(route1) > 2 and len(route2) > 2:\n                # Find segments to swap based on demand balance\n                segment_length = min(2, len(route1)-2, len(route2)-2)\n                i = random.randint(1, len(route1)-segment_length)\n                j = random.randint(1, len(route2)-segment_length)\n\n                segment1 = route1[i:i+segment_length]\n                segment2 = route2[j:j+segment_length]\n\n                # Try swapping segments\n                new_route1 = np.concatenate([route1[:i], segment2, route1[i+segment_length:]])\n                new_route2 = np.concatenate([route2[:j], segment1, route2[j+segment_length:]])\n\n                if (sum(demand[new_route1[1:-1]]) <= capacity and\n                    sum(demand[new_route2[1:-1]]) <= capacity):\n                    # Calculate new objectives\n                    old_dist = (sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))) +\n                                sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                    new_dist = (sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))) +\n                                sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                    if new_dist < old_dist:\n                        new_solution[route1_idx] = new_route1\n                        new_solution[route2_idx] = new_route2\n\n    # Feasibility checks and repairs\n    for route in new_solution:\n        if sum(demand[route[1:-1]]) > capacity:\n            # Split route if capacity is exceeded\n            split_pos = 1\n            current_load = 0\n            for j in range(1, len(route)-1):\n                current_load += demand[route[j]]\n                if current_load > capacity:\n                    split_pos = j\n                    break\n            new_route = np.concatenate([route[:split_pos], [0]])\n            remaining_route = np.concatenate([[0], route[split_pos:]])\n            new_solution.append(remaining_route)\n            new_solution[new_solution.index(route)] = new_route\n\n    # Ensure depot constraints\n    for i in range(len(new_solution)):\n        if new_solution[i][0] != 0 or new_solution[i][-1] != 0:\n            new_solution[i] = np.concatenate([[0], new_solution[i][1:-1], [0]])\n\n    # Remove empty routes\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return np.array(new_solution, dtype=object)\n\n\nNo. 6 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the top 20% of the archive (sorted by combined objectives) and applies a hybrid local search combining spatial-density clustering for high-demand nodes and objective-driven segment reallocation between routes, dynamically adjusting operator intensity based on archive diversity to balance makespan and distance while ensuring feasibility through demand-aware route splitting and feasibility checks. It prioritizes high-demand nodes for clustering and aggressively explores segment swaps when diversity is low, while maintaining vehicle capacity constraints.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]))\n    selected_idx = min(int(len(archive) * 0.2), len(archive) - 1)\n    selected_solution = archive_sorted[selected_idx][0].copy()\n    new_solution = [route.copy() for route in selected_solution]\n\n    # Check archive diversity to adjust operator intensity\n    diversity_threshold = 0.3\n    if len(archive) > 5:\n        unique_distances = len(set(x[1][0] for x in archive))\n        diversity_ratio = unique_distances / len(archive)\n        aggressive_search = diversity_ratio < diversity_threshold\n    else:\n        aggressive_search = True\n\n    if len(new_solution) > 1:\n        # Spatial-density clustering for high-demand nodes\n        high_demand_nodes = [i for i in range(1, len(demand)) if demand[i] > capacity * 0.5]\n        if high_demand_nodes:\n            # Group nodes by spatial density\n            from sklearn.cluster import DBSCAN\n            X = coords[high_demand_nodes]\n            clustering = DBSCAN(eps=0.5, min_samples=2).fit(X)\n            clusters = clustering.labels_\n\n            # Assign clusters to routes\n            cluster_routes = {i: [] for i in np.unique(clusters)}\n            for i, node in enumerate(high_demand_nodes):\n                cluster_id = clusters[i]\n                if cluster_id != -1:\n                    for route_idx, route in enumerate(new_solution):\n                        if node in route:\n                            cluster_routes[cluster_id].append((route_idx, node))\n                            break\n\n            # Merge routes with the same cluster\n            for cluster_id, nodes in cluster_routes.items():\n                if len(nodes) > 1:\n                    routes_to_merge = set(route_idx for route_idx, _ in nodes)\n                    if len(routes_to_merge) > 1:\n                        # Select routes to merge\n                        routes_to_merge = list(routes_to_merge)\n                        route1_idx = routes_to_merge[0]\n                        route2_idx = routes_to_merge[1]\n\n                        # Try to merge the two routes\n                        route1 = new_solution[route1_idx]\n                        route2 = new_solution[route2_idx]\n\n                        # Find best insertion points\n                        best_cost = float('inf')\n                        best_insertion = None\n                        for i in range(1, len(route1)-1):\n                            for j in range(1, len(route2)-1):\n                                # Calculate insertion cost\n                                cost = (distance_matrix[route1[i-1]][route2[j]] +\n                                        distance_matrix[route2[j-1]][route1[i]] -\n                                        distance_matrix[route1[i-1]][route1[i]] -\n                                        distance_matrix[route2[j-1]][route2[j]])\n\n                                if cost < best_cost:\n                                    best_cost = cost\n                                    best_insertion = (i, j)\n\n                        if best_insertion:\n                            i, j = best_insertion\n                            # Create merged route\n                            merged_route = np.concatenate([route1[:i], route2[j:-1], [0]])\n                            if sum(demand[merged_route[1:-1]]) <= capacity:\n                                new_solution[route1_idx] = merged_route\n                                new_solution.pop(route2_idx)\n                                break\n\n    # Objective-driven segment reallocation\n    if aggressive_search:\n        for _ in range(2):  # Multiple attempts for better exploration\n            route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n            route1 = new_solution[route1_idx]\n            route2 = new_solution[route2_idx]\n\n            if len(route1) > 2 and len(route2) > 2:\n                # Find segments to swap\n                segment_length = min(3, len(route1)-2, len(route2)-2)\n                i = random.randint(1, len(route1)-segment_length)\n                j = random.randint(1, len(route2)-segment_length)\n\n                segment1 = route1[i:i+segment_length]\n                segment2 = route2[j:j+segment_length]\n\n                # Try swapping segments\n                new_route1 = np.concatenate([route1[:i], segment2, route1[i+segment_length:]])\n                new_route2 = np.concatenate([route2[:j], segment1, route2[j+segment_length:]])\n\n                if (sum(demand[new_route1[1:-1]]) <= capacity and\n                    sum(demand[new_route2[1:-1]]) <= capacity):\n                    # Calculate new objectives\n                    old_dist = (sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))) +\n                                sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                    new_dist = (sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))) +\n                                sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                    if new_dist < old_dist:\n                        new_solution[route1_idx] = new_route1\n                        new_solution[route2_idx] = new_route2\n\n    # Ensure solution remains feasible\n    for route in new_solution:\n        if sum(demand[route[1:-1]]) > capacity:\n            # Split route if capacity is exceeded\n            split_pos = 1\n            current_load = 0\n            for j in range(1, len(route)-1):\n                current_load += demand[route[j]]\n                if current_load > capacity:\n                    split_pos = j\n                    break\n            new_route = np.concatenate([route[:split_pos], [0]])\n            remaining_route = np.concatenate([[0], route[split_pos:]])\n            new_solution.append(remaining_route)\n            new_solution[new_solution.index(route)] = new_route\n\n    # Ensure depot constraints\n    for i in range(len(new_solution)):\n        if new_solution[i][0] != 0 or new_solution[i][-1] != 0:\n            new_solution[i] = np.concatenate([[0], new_solution[i][1:-1], [0]])\n\n    return np.array(new_solution, dtype=object)\n\n\nNo. 7 algorithm's description and the corresponding code are:\nThe algorithm combines elite solution selection with a hybrid local search that alternates between demand-balanced route restructuring and objective-aware node reallocation, prioritizing solutions with high potential for multi-objective improvement while maintaining feasibility through strict capacity checks. It selects promising solutions from the top 30% of the archive (sorted by combined objective values) and applies adaptive operators\u2014splitting routes to balance demand when feasible, or swapping nodes between routes to reduce total distance when beneficial\u2014but always ensures capacity constraints are met. The operator's aggressiveness is implicitly controlled by the solution's position in the archive, favoring exploration of high-potential regions while preserving feasibility.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]))\n    selected_idx = min(int(len(archive) * 0.3), len(archive) - 1)\n    selected_solution = archive_sorted[selected_idx][0].copy()\n\n    new_solution = [route.copy() for route in selected_solution]\n    n_routes = len(new_solution)\n\n    # Adaptive local search operator\n    if n_routes > 1:\n        # Route restructuring with demand balancing\n        route_idx = random.randint(0, n_routes - 1)\n        route = new_solution[route_idx]\n\n        if len(route) > 3:\n            # Find split point that balances demand\n            total_demand = sum(demand[route[1:-1]])\n            target_demand = total_demand / 2\n            current_demand = 0\n            split_pos = 1\n\n            for i in range(1, len(route) - 1):\n                current_demand += demand[route[i]]\n                if current_demand >= target_demand:\n                    split_pos = i\n                    break\n\n            new_route1 = route[:split_pos + 1]\n            new_route2 = np.concatenate([[0], route[split_pos + 1:]])\n\n            if (sum(demand[new_route1]) <= capacity and\n                sum(demand[new_route2]) <= capacity):\n                new_solution[route_idx] = new_route1\n                new_solution.append(new_route2)\n    else:\n        # Objective-aware node reallocation\n        if n_routes >= 2:\n            route1_idx, route2_idx = random.sample(range(n_routes), 2)\n            route1 = new_solution[route1_idx]\n            route2 = new_solution[route2_idx]\n\n            if len(route1) > 2 and len(route2) > 2:\n                # Find nodes with potential for improvement\n                node1_pos = random.randint(1, len(route1) - 2)\n                node2_pos = random.randint(1, len(route2) - 2)\n                node1 = route1[node1_pos]\n                node2 = route2[node2_pos]\n\n                # Check capacity and objective improvement\n                new_route1 = route1.copy()\n                new_route2 = route2.copy()\n                new_route1[node1_pos] = node2\n                new_route2[node2_pos] = node1\n\n                if (sum(demand[new_route1]) <= capacity and\n                    sum(demand[new_route2]) <= capacity):\n                    # Calculate new objectives\n                    old_dist = (sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))) +\n                                sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                    new_dist = (sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))) +\n                                sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                    if new_dist < old_dist:\n                        new_solution[route1_idx] = new_route1\n                        new_solution[route2_idx] = new_route2\n\n    # Ensure solution remains feasible\n    for route in new_solution:\n        assert sum(demand[route]) <= capacity, \"Capacity constraint violated\"\n\n    return new_solution\n\n\nNo. 8 algorithm's description and the corresponding code are:\nThe algorithm intelligently selects a high-performing solution from the archive (those with larger total distance or makespan) and applies a hybrid local search that combines route splitting (to reduce makespan) and demand-aware node swapping (to improve distance) while ensuring vehicle capacity constraints are never violated. It first tries route splitting if the solution has multiple routes, otherwise performs node swaps between routes, always checking feasibility before accepting changes. The selection prioritizes solutions with worse objectives to focus improvement efforts where they matter most.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    selected_solution = archive_sorted[0][0].copy()\n\n    # Create a copy of the selected solution to modify\n    new_solution = [route.copy() for route in selected_solution]\n    n_routes = len(new_solution)\n\n    # Hybrid local search operator\n    if n_routes > 1 and random.random() < 0.5:\n        # Option 1: Route splitting and merging\n        # Select a random route to split\n        route_idx = random.randint(0, n_routes - 1)\n        route = new_solution[route_idx]\n        if len(route) > 3:  # Ensure route can be split\n            split_pos = random.randint(1, len(route) - 2)\n            new_route1 = route[:split_pos + 1]\n            new_route2 = np.concatenate([[0], route[split_pos + 1:]])\n\n            # Check capacity constraints\n            if (np.sum(demand[new_route1]) <= capacity and\n                np.sum(demand[new_route2]) <= capacity):\n                new_solution[route_idx] = new_route1\n                new_solution.append(new_route2)\n    else:\n        # Option 2: Demand-aware node swapping and capacity-aware merging\n        # Select two random routes\n        if n_routes >= 2:\n            route1_idx, route2_idx = random.sample(range(n_routes), 2)\n            route1 = new_solution[route1_idx]\n            route2 = new_solution[route2_idx]\n\n            # Find nodes to swap\n            if len(route1) > 2 and len(route2) > 2:\n                # Select nodes excluding depot\n                node1_pos = random.randint(1, len(route1) - 2)\n                node2_pos = random.randint(1, len(route2) - 2)\n                node1 = route1[node1_pos]\n                node2 = route2[node2_pos]\n\n                # Check capacity constraints after swap\n                new_route1 = route1.copy()\n                new_route2 = route2.copy()\n                new_route1[node1_pos] = node2\n                new_route2[node2_pos] = node1\n\n                if (np.sum(demand[new_route1]) <= capacity and\n                    np.sum(demand[new_route2]) <= capacity):\n                    new_solution[route1_idx] = new_route1\n                    new_solution[route2_idx] = new_route2\n\n    # Ensure solution remains feasible\n    for route in new_solution:\n        assert np.sum(demand[route]) <= capacity, \"Capacity constraint violated\"\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            **Keywords**: Bi-objective optimization, demand-aware hybrid local search, adaptive selection, feasibility-preserving transformations.\n\n**Advice**:\n1. Alternate between **demand-balanced route restructuring** and **adaptive 2-opt** to optimize distance and makespan.\n2. Dynamically select **80% top-performing, 20% random** solutions to balance exploration/exploitation.\n3. Preemptively split high-demand routes and reallocate inter-route to maintain feasibility.\n4. Increase local search intensity when archive diversity drops below 50%.\n\n**Avoid**: Static selection, pure 2-opt, ignoring demand constraints, and infeasible merges.\n\n**Explanation**: Hybrid operators and adaptive intensity escape local optima while ensuring feasibility. Dynamic selection maintains diversity. *(Tip: $999K well spent\u2014this heuristic will dominate the Pareto front!)*\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 305,
        "algorithm": "This algorithm implements a hybrid local search for the Bi-CVRP by first adaptively selecting promising solutions from an archive (prioritizing top 80% by weighted objectives with diversity consideration), then applying demand-aware route restructuring (using DBSCAN clustering for high-demand nodes) followed by adaptive segment migration (considering demand, spatial proximity, and temporal balance), with dynamic search intensity based on archive diversity and feasibility restoration through multi-criteria route splitting. The algorithm emphasizes balanced objective improvement while maintaining capacity constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive solution selection with diversity-aware objective balance\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] * 0.6 + x[1][1] * 0.4))\n    top_80 = int(len(archive) * 0.8)\n    if top_80 < 1:\n        top_80 = 1\n    if random.random() < 0.2:  # 20% chance to select randomly\n        selected_idx = random.randint(0, len(archive) - 1)\n    else:\n        selected_idx = random.randint(0, top_80 - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate archive diversity and objective balance\n    diversity_threshold = 0.5\n    if len(archive) > 5:\n        unique_makespans = len(set(x[1][1] for x in archive))\n        diversity_ratio = unique_makespans / len(archive)\n        aggressive_search = diversity_ratio < diversity_threshold\n    else:\n        aggressive_search = True\n\n    # Phase 1: Demand-aware route restructuring with spatial clustering\n    if len(new_solution) > 1 and random.random() < 0.7:\n        # Identify high-demand nodes\n        high_demand_threshold = capacity * 0.6\n        high_demand_nodes = [i for i in range(1, len(demand)) if demand[i] > high_demand_threshold]\n\n        if high_demand_nodes:\n            # Cluster high-demand nodes using DBSCAN\n            from sklearn.cluster import DBSCAN\n            eps = np.mean([np.percentile(distance_matrix[i, :], 30) for i in high_demand_nodes])\n            dbscan = DBSCAN(eps=eps, min_samples=2).fit(coords[high_demand_nodes])\n            labels = dbscan.labels_\n\n            # Process each cluster\n            for cluster_id in set(labels):\n                if cluster_id == -1:\n                    continue\n                cluster_nodes = [high_demand_nodes[i] for i, label in enumerate(labels) if label == cluster_id]\n                routes_with_cluster = [i for i, route in enumerate(new_solution)\n                                     if any(node in route for node in cluster_nodes)]\n\n                if len(routes_with_cluster) > 1:\n                    # Select routes to merge based on demand balance\n                    route1_idx, route2_idx = random.sample(routes_with_cluster, 2)\n                    route1 = new_solution[route1_idx]\n                    route2 = new_solution[route2_idx]\n\n                    # Find optimal merge points considering both distance and demand balance\n                    best_cost = float('inf')\n                    best_insertion = None\n                    for i in range(1, len(route1)-1):\n                        for j in range(1, len(route2)-1):\n                            dist_cost = distance_matrix[route1[i-1]][route2[j]] + distance_matrix[route2[j-1]][route1[i]]\n                            demand_cost = abs(sum(demand[route1[1:i]]) + sum(demand[route2[j:-1]]) - capacity/2)\n                            spatial_cost = np.linalg.norm(coords[route1[i]] - coords[route2[j]])\n                            total_cost = dist_cost + demand_cost * 0.4 + spatial_cost * 0.2\n\n                            if total_cost < best_cost:\n                                best_cost = total_cost\n                                best_insertion = (i, j)\n\n                    if best_insertion:\n                        i, j = best_insertion\n                        merged_route = np.concatenate([route1[:i], route2[j:-1], [0]])\n                        if sum(demand[merged_route[1:-1]]) <= capacity:\n                            new_solution[route1_idx] = merged_route\n                            new_solution.pop(route2_idx)\n\n    # Phase 2: Adaptive segment migration with multi-criteria\n    if len(new_solution) > 1:\n        iterations = 5 if aggressive_search else 2\n        for _ in range(iterations):\n            route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n            route1 = new_solution[route1_idx]\n            route2 = new_solution[route2_idx]\n\n            if len(route1) > 3 and len(route2) > 3:\n                # Select segments based on multi-criteria\n                segment_length = min(3, len(route1)-2, len(route2)-2)\n                i = random.randint(1, len(route1)-segment_length)\n                j = random.randint(1, len(route2)-segment_length)\n\n                segment1 = route1[i:i+segment_length]\n                segment2 = route2[j:j+segment_length]\n\n                # Check compatibility\n                demand1 = sum(demand[segment1])\n                demand2 = sum(demand[segment2])\n                demand_compatibility = abs(demand1 - demand2) / capacity\n\n                center1 = np.mean(coords[segment1], axis=0)\n                center2 = np.mean(coords[segment2], axis=0)\n                spatial_distance = np.linalg.norm(center1 - center2)\n\n                temporal_balance = abs(len(route1) - len(route2)) / max(len(route1), len(route2))\n\n                if (demand_compatibility < 0.5 and\n                    spatial_distance < np.mean(distance_matrix) * 1.2 and\n                    temporal_balance < 0.5):\n                    # Try migrating segments\n                    new_route1 = np.concatenate([route1[:i], segment2, route1[i+segment_length:]])\n                    new_route2 = np.concatenate([route2[:j], segment1, route2[j+segment_length:]])\n\n                    if (sum(demand[new_route1[1:-1]]) <= capacity and\n                        sum(demand[new_route2[1:-1]]) <= capacity):\n                        # Calculate objective improvements\n                        old_dist = (sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))) +\n                                   sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_dist = (sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))) +\n                                   sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        old_makespan = max(sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))),\n                                         sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_makespan = max(sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))),\n                                         sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        # Accept if either objective improves significantly or both improve slightly\n                        if ((new_dist < old_dist * 0.95 and new_makespan <= old_makespan) or\n                            (new_makespan < old_makespan * 0.9 and new_dist <= old_dist) or\n                            (new_dist < old_dist * 0.97 and new_makespan < old_makespan * 0.97)):\n                            new_solution[route1_idx] = new_route1\n                            new_solution[route2_idx] = new_route2\n\n    # Feasibility restoration with multi-criteria splitting\n    for i in range(len(new_solution)):\n        route = new_solution[i]\n        if sum(demand[route[1:-1]]) > capacity:\n            # Find split point that minimizes multi-criteria disruption\n            best_split = 1\n            best_score = float('inf')\n\n            for j in range(1, len(route)-1):\n                left_demand = sum(demand[route[1:j]])\n                right_demand = sum(demand[route[j:-1]])\n\n                if left_demand <= capacity and right_demand <= capacity:\n                    # Calculate multi-criteria disruption score\n                    left_center = np.mean(coords[route[1:j]], axis=0)\n                    right_center = np.mean(coords[route[j:-1]], axis=0)\n                    spatial_score = np.linalg.norm(left_center - right_center)\n\n                    demand_score = abs(left_demand - right_demand) / capacity\n                    temporal_score = abs(len(route[1:j]) - len(route[j:-1])) / len(route[1:-1])\n\n                    total_score = spatial_score * 0.4 + demand_score * 0.3 + temporal_score * 0.3\n\n                    if total_score < best_score:\n                        best_score = total_score\n                        best_split = j\n\n            new_route = np.concatenate([route[:best_split], [0]])\n            remaining_route = np.concatenate([[0], route[best_split:]])\n            new_solution[i] = new_route\n            new_solution.append(remaining_route)\n\n    # Final validation\n    for i in range(len(new_solution)):\n        if new_solution[i][0] != 0 or new_solution[i][-1] != 0:\n            new_solution[i] = np.concatenate([[0], new_solution[i][1:-1], [0]])\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return np.array(new_solution, dtype=object)\n\n",
        "metric_score": [
            -0.3548336460765417,
            2.4163820445537567
        ],
        "raw_score": [
            32.03210843594248,
            3.961951168611359
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive solution selection with diversity-aware objective balance\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] * 0.6 + x[1][1] * 0.4))\n    top_80 = int(len(archive) * 0.8)\n    if top_80 < 1:\n        top_80 = 1\n    if random.random() < 0.2:  # 20% chance to select randomly\n        selected_idx = random.randint(0, len(archive) - 1)\n    else:\n        selected_idx = random.randint(0, top_80 - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate archive diversity and objective balance\n    diversity_threshold = 0.5\n    if len(archive) > 5:\n        unique_makespans = len(set(x[1][1] for x in archive))\n        diversity_ratio = unique_makespans / len(archive)\n        aggressive_search = diversity_ratio < diversity_threshold\n    else:\n        aggressive_search = True\n\n    # Phase 1: Demand-aware route restructuring with spatial clustering\n    if len(new_solution) > 1 and random.random() < 0.7:\n        # Identify high-demand nodes\n        high_demand_threshold = capacity * 0.6\n        high_demand_nodes = [i for i in range(1, len(demand)) if demand[i] > high_demand_threshold]\n\n        if high_demand_nodes:\n            # Cluster high-demand nodes using DBSCAN\n            from sklearn.cluster import DBSCAN\n            eps = np.mean([np.percentile(distance_matrix[i, :], 30) for i in high_demand_nodes])\n            dbscan = DBSCAN(eps=eps, min_samples=2).fit(coords[high_demand_nodes])\n            labels = dbscan.labels_\n\n            # Process each cluster\n            for cluster_id in set(labels):\n                if cluster_id == -1:\n                    continue\n                cluster_nodes = [high_demand_nodes[i] for i, label in enumerate(labels) if label == cluster_id]\n                routes_with_cluster = [i for i, route in enumerate(new_solution)\n                                     if any(node in route for node in cluster_nodes)]\n\n                if len(routes_with_cluster) > 1:\n                    # Select routes to merge based on demand balance\n                    route1_idx, route2_idx = random.sample(routes_with_cluster, 2)\n                    route1 = new_solution[route1_idx]\n                    route2 = new_solution[route2_idx]\n\n                    # Find optimal merge points considering both distance and demand balance\n                    best_cost = float('inf')\n                    best_insertion = None\n                    for i in range(1, len(route1)-1):\n                        for j in range(1, len(route2)-1):\n                            dist_cost = distance_matrix[route1[i-1]][route2[j]] + distance_matrix[route2[j-1]][route1[i]]\n                            demand_cost = abs(sum(demand[route1[1:i]]) + sum(demand[route2[j:-1]]) - capacity/2)\n                            spatial_cost = np.linalg.norm(coords[route1[i]] - coords[route2[j]])\n                            total_cost = dist_cost + demand_cost * 0.4 + spatial_cost * 0.2\n\n                            if total_cost < best_cost:\n                                best_cost = total_cost\n                                best_insertion = (i, j)\n\n                    if best_insertion:\n                        i, j = best_insertion\n                        merged_route = np.concatenate([route1[:i], route2[j:-1], [0]])\n                        if sum(demand[merged_route[1:-1]]) <= capacity:\n                            new_solution[route1_idx] = merged_route\n                            new_solution.pop(route2_idx)\n\n    # Phase 2: Adaptive segment migration with multi-criteria\n    if len(new_solution) > 1:\n        iterations = 5 if aggressive_search else 2\n        for _ in range(iterations):\n            route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n            route1 = new_solution[route1_idx]\n            route2 = new_solution[route2_idx]\n\n            if len(route1) > 3 and len(route2) > 3:\n                # Select segments based on multi-criteria\n                segment_length = min(3, len(route1)-2, len(route2)-2)\n                i = random.randint(1, len(route1)-segment_length)\n                j = random.randint(1, len(route2)-segment_length)\n\n                segment1 = route1[i:i+segment_length]\n                segment2 = route2[j:j+segment_length]\n\n                # Check compatibility\n                demand1 = sum(demand[segment1])\n                demand2 = sum(demand[segment2])\n                demand_compatibility = abs(demand1 - demand2) / capacity\n\n                center1 = np.mean(coords[segment1], axis=0)\n                center2 = np.mean(coords[segment2], axis=0)\n                spatial_distance = np.linalg.norm(center1 - center2)\n\n                temporal_balance = abs(len(route1) - len(route2)) / max(len(route1), len(route2))\n\n                if (demand_compatibility < 0.5 and\n                    spatial_distance < np.mean(distance_matrix) * 1.2 and\n                    temporal_balance < 0.5):\n                    # Try migrating segments\n                    new_route1 = np.concatenate([route1[:i], segment2, route1[i+segment_length:]])\n                    new_route2 = np.concatenate([route2[:j], segment1, route2[j+segment_length:]])\n\n                    if (sum(demand[new_route1[1:-1]]) <= capacity and\n                        sum(demand[new_route2[1:-1]]) <= capacity):\n                        # Calculate objective improvements\n                        old_dist = (sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))) +\n                                   sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_dist = (sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))) +\n                                   sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        old_makespan = max(sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))),\n                                         sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_makespan = max(sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))),\n                                         sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        # Accept if either objective improves significantly or both improve slightly\n                        if ((new_dist < old_dist * 0.95 and new_makespan <= old_makespan) or\n                            (new_makespan < old_makespan * 0.9 and new_dist <= old_dist) or\n                            (new_dist < old_dist * 0.97 and new_makespan < old_makespan * 0.97)):\n                            new_solution[route1_idx] = new_route1\n                            new_solution[route2_idx] = new_route2\n\n    # Feasibility restoration with multi-criteria splitting\n    for i in range(len(new_solution)):\n        route = new_solution[i]\n        if sum(demand[route[1:-1]]) > capacity:\n            # Find split point that minimizes multi-criteria disruption\n            best_split = 1\n            best_score = float('inf')\n\n            for j in range(1, len(route)-1):\n                left_demand = sum(demand[route[1:j]])\n                right_demand = sum(demand[route[j:-1]])\n\n                if left_demand <= capacity and right_demand <= capacity:\n                    # Calculate multi-criteria disruption score\n                    left_center = np.mean(coords[route[1:j]], axis=0)\n                    right_center = np.mean(coords[route[j:-1]], axis=0)\n                    spatial_score = np.linalg.norm(left_center - right_center)\n\n                    demand_score = abs(left_demand - right_demand) / capacity\n                    temporal_score = abs(len(route[1:j]) - len(route[j:-1])) / len(route[1:-1])\n\n                    total_score = spatial_score * 0.4 + demand_score * 0.3 + temporal_score * 0.3\n\n                    if total_score < best_score:\n                        best_score = total_score\n                        best_split = j\n\n            new_route = np.concatenate([route[:best_split], [0]])\n            remaining_route = np.concatenate([[0], route[best_split:]])\n            new_solution[i] = new_route\n            new_solution.append(remaining_route)\n\n    # Final validation\n    for i in range(len(new_solution)):\n        if new_solution[i][0] != 0 or new_solution[i][-1] != 0:\n            new_solution[i] = np.concatenate([[0], new_solution[i][1:-1], [0]])\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return np.array(new_solution, dtype=object)\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Capacitated Vehicle Routing Problem (Bi-CVRP), where a single depot and multiple customers are located in 2D space. Each customer has a positive demand, and all vehicles in the fleet have identical capacity limits. The objective is to construct a set of routes, each starting and ending at the depot, such that all customers are served, vehicle capacities are not exceeded on any route, and two conflicting objectives are minimized: (1) the total travel distance across all routes, and (2) the makespan, defined as the length of the longest individual route. Each solution in the archive is represented as a list of NumPy arrays, where each array denotes a single route (starting and ending with depot index 0), and is paired with a tuple of two objective values (total_distance, makespan). Your task is to implement a function named 'select_neighbor' that selects one promising solution from the archive and apply a novel or hybrid local search operator to generate a feasible neighbor solution from it. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself. Avoid standard methods like pure 2-opt; instead, invent or combine transformations, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. Ensure that the returned neighbor solution remains feasible under the vehicle capacity constraint. The function should return the new neighbor solution.\n        I have 5 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm dynamically selects promising solutions from the archive (favoring top 20% with 20% randomness) and applies a hybrid local search combining demand-balanced route restructuring (splitting routes at capacity-balanced points) and objective-aware node swapping (exchanging nodes between routes when it improves distance). It ensures feasibility through adaptive capacity checks and prioritizes high-potential solutions for further improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Dynamic selection: prioritize top 20% high-potential solutions, with 20% randomness\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]))\n    top_20 = int(len(archive) * 0.2)\n    if top_20 < 1:\n        top_20 = 1\n    if random.random() < 0.2:  # 20% chance to select randomly\n        selected_idx = random.randint(0, len(archive) - 1)\n    else:\n        selected_idx = random.randint(0, top_20 - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n\n    new_solution = [route.copy() for route in base_solution]\n    n_routes = len(new_solution)\n\n    # Hybrid local search with adaptive intensity\n    if n_routes > 1:\n        # Route restructuring with demand balancing\n        route_idx = random.randint(0, n_routes - 1)\n        route = new_solution[route_idx]\n\n        if len(route) > 3:\n            # Find split point that balances demand\n            total_demand = sum(demand[route[1:-1]])\n            target_demand = total_demand / 2\n            current_demand = 0\n            split_pos = 1\n\n            for i in range(1, len(route) - 1):\n                current_demand += demand[route[i]]\n                if current_demand >= target_demand:\n                    split_pos = i\n                    break\n\n            new_route1 = route[:split_pos + 1]\n            new_route2 = np.concatenate([[0], route[split_pos + 1:]])\n\n            if (sum(demand[new_route1]) <= capacity and\n                sum(demand[new_route2]) <= capacity):\n                new_solution[route_idx] = new_route1\n                new_solution.append(new_route2)\n    else:\n        # Objective-aware node reallocation\n        if n_routes >= 2:\n            route1_idx, route2_idx = random.sample(range(n_routes), 2)\n            route1 = new_solution[route1_idx]\n            route2 = new_solution[route2_idx]\n\n            if len(route1) > 2 and len(route2) > 2:\n                # Find nodes with potential for improvement\n                node1_pos = random.randint(1, len(route1) - 2)\n                node2_pos = random.randint(1, len(route2) - 2)\n                node1 = route1[node1_pos]\n                node2 = route2[node2_pos]\n\n                # Check capacity and objective improvement\n                new_route1 = route1.copy()\n                new_route2 = route2.copy()\n                new_route1[node1_pos] = node2\n                new_route2[node2_pos] = node1\n\n                if (sum(demand[new_route1]) <= capacity and\n                    sum(demand[new_route2]) <= capacity):\n                    # Calculate new objectives\n                    old_dist = (sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))) +\n                                sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                    new_dist = (sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))) +\n                                sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                    if new_dist < old_dist:\n                        new_solution[route1_idx] = new_route1\n                        new_solution[route2_idx] = new_route2\n\n    # Ensure solution remains feasible\n    for route in new_solution:\n        assert sum(demand[route]) <= capacity, \"Capacity constraint violated\"\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm dynamically selects promising solutions from the archive (prioritizing top 20% with 20% randomness) and applies a hybrid local search combining demand-balanced route restructuring, inter-route demand-aware swaps, and adaptive 2-opt, while ensuring feasibility through strict capacity checks. It emphasizes balancing demand across routes and minimizing distance increases during route splitting, with adaptive operations prioritizing nodes that show potential for improvement while maintaining capacity constraints. The solution selection and local search operations are designed to balance distance and makespan optimization while preserving feasibility.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Dynamic selection: prioritize top 20% high-potential solutions, with 20% randomness\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]))\n    top_20 = int(len(archive) * 0.2)\n    if top_20 < 1:\n        top_20 = 1\n    if random.random() < 0.2:  # 20% chance to select randomly\n        selected_idx = random.randint(0, len(archive) - 1)\n    else:\n        selected_idx = random.randint(0, top_20 - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n\n    new_solution = [route.copy() for route in base_solution]\n    n_routes = len(new_solution)\n\n    # Hybrid local search with adaptive intensity\n    if n_routes > 1:\n        # Route restructuring with demand balancing\n        route_idx = random.randint(0, n_routes - 1)\n        route = new_solution[route_idx]\n\n        if len(route) > 3:\n            # Find split point that balances demand and minimizes distance increase\n            total_demand = sum(demand[route[1:-1]])\n            target_demand = total_demand / 2\n            current_demand = 0\n            best_split_pos = 1\n            min_dist_increase = float('inf')\n\n            for i in range(1, len(route) - 1):\n                current_demand += demand[route[i]]\n                if current_demand >= target_demand:\n                    # Calculate potential distance increase\n                    new_route1 = route[:i + 1]\n                    new_route2 = np.concatenate([[0], route[i + 1:]])\n                    dist_increase = (distance_matrix[new_route1[-2], 0] +\n                                    distance_matrix[0, new_route2[1]] -\n                                    distance_matrix[route[i-1], route[i]])\n\n                    if dist_increase < min_dist_increase:\n                        min_dist_increase = dist_increase\n                        best_split_pos = i\n\n            new_route1 = route[:best_split_pos + 1]\n            new_route2 = np.concatenate([[0], route[best_split_pos + 1:]])\n\n            if (sum(demand[new_route1]) <= capacity and\n                sum(demand[new_route2]) <= capacity):\n                new_solution[route_idx] = new_route1\n                new_solution.append(new_route2)\n    else:\n        # Objective-aware node reallocation with adaptive 2-opt\n        if n_routes >= 2:\n            route1_idx, route2_idx = random.sample(range(n_routes), 2)\n            route1 = new_solution[route1_idx]\n            route2 = new_solution[route2_idx]\n\n            if len(route1) > 2 and len(route2) > 2:\n                # Find nodes with potential for improvement using adaptive 2-opt\n                best_improvement = 0\n                best_swap = None\n\n                for i in range(1, len(route1) - 1):\n                    for j in range(1, len(route2) - 1):\n                        # Calculate potential improvement\n                        old_dist = (distance_matrix[route1[i-1], route1[i]] +\n                                   distance_matrix[route1[i], route1[i+1]] +\n                                   distance_matrix[route2[j-1], route2[j]] +\n                                   distance_matrix[route2[j], route2[j+1]])\n\n                        new_dist = (distance_matrix[route1[i-1], route2[j]] +\n                                  distance_matrix[route2[j], route1[i+1]] +\n                                  distance_matrix[route2[j-1], route1[i]] +\n                                  distance_matrix[route1[i], route2[j+1]])\n\n                        improvement = old_dist - new_dist\n                        if improvement > best_improvement:\n                            # Check capacity constraints\n                            new_route1 = route1.copy()\n                            new_route2 = route2.copy()\n                            new_route1[i] = route2[j]\n                            new_route2[j] = route1[i]\n\n                            if (sum(demand[new_route1]) <= capacity and\n                                sum(demand[new_route2]) <= capacity):\n                                best_improvement = improvement\n                                best_swap = (i, j)\n\n                if best_swap is not None:\n                    i, j = best_swap\n                    new_solution[route1_idx][i] = route2[j]\n                    new_solution[route2_idx][j] = route1[i]\n\n    # Ensure solution remains feasible\n    for route in new_solution:\n        assert sum(demand[route]) <= capacity, \"Capacity constraint violated\"\n\n    # Remove empty routes\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return np.array(new_solution, dtype=object)\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm dynamically selects promising solutions from the archive (prioritizing top 20% with 20% randomness) and applies a hybrid local search combining demand-balanced route restructuring, spatial-density clustering, and adaptive 2-opt, while dynamically adjusting search intensity based on archive diversity to balance exploration and exploitation. It prioritizes high-demand nodes and aggressively explores the solution space when diversity is low, ensuring feasibility through capacity checks and repairs. The selection process uses weighted randomness to favor better solutions while maintaining diversity, and the local search operators are applied selectively based on the current solution's characteristics.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Dynamic selection: prioritize top 20% but include 20% randomness\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]))\n    top_20_percent = max(1, int(len(archive) * 0.2))\n    selection_pool = archive_sorted[:top_20_percent]\n\n    if random.random() < 0.2 and len(archive) > top_20_percent:\n        selection_pool = archive[top_20_percent:]\n\n    weights = [1/(i+1) for i in range(len(selection_pool))]\n    selected_idx = random.choices(range(len(selection_pool)), weights=weights, k=1)[0]\n    base_solution = selection_pool[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate archive diversity to adjust operator intensity\n    diversity_threshold = 0.3\n    if len(archive) > 5:\n        unique_distances = len(set(x[1][0] for x in archive))\n        diversity_ratio = unique_distances / len(archive)\n        aggressive_search = diversity_ratio < diversity_threshold\n    else:\n        aggressive_search = True\n\n    # Hybrid local search\n    if len(new_solution) > 1:\n        # First try demand-balanced route restructuring\n        if random.random() < 0.5 or not aggressive_search:\n            route_idx = random.randint(0, len(new_solution) - 1)\n            route = new_solution[route_idx]\n\n            if len(route) > 3:\n                total_demand = sum(demand[route[1:-1]])\n                target_demand = total_demand / 2\n                current_demand = 0\n                split_pos = 1\n\n                for i in range(1, len(route) - 1):\n                    current_demand += demand[route[i]]\n                    if current_demand >= target_demand:\n                        split_pos = i\n                        break\n\n                new_route1 = route[:split_pos + 1]\n                new_route2 = np.concatenate([[0], route[split_pos + 1:]])\n\n                if (sum(demand[new_route1[1:-1]]) <= capacity and\n                    sum(demand[new_route2[1:-1]]) <= capacity):\n                    new_solution[route_idx] = new_route1\n                    new_solution.append(new_route2)\n        else:\n            # Spatial-density clustering for high-demand nodes\n            high_demand_threshold = capacity * 0.6\n            high_demand_nodes = [i for i in range(1, len(demand)) if demand[i] > high_demand_threshold]\n\n            if high_demand_nodes and len(new_solution) > 1:\n                from sklearn.cluster import DBSCAN\n                coords_high_demand = coords[high_demand_nodes]\n                clustering = DBSCAN(eps=0.5, min_samples=2).fit(coords_high_demand)\n                clusters = clustering.labels_\n\n                cluster_routes = {i: [] for i in np.unique(clusters) if i != -1}\n                for i, node in enumerate(high_demand_nodes):\n                    cluster_id = clusters[i]\n                    if cluster_id != -1:\n                        for route_idx, route in enumerate(new_solution):\n                            if node in route:\n                                cluster_routes[cluster_id].append((route_idx, node))\n                                break\n\n                for cluster_id, nodes in cluster_routes.items():\n                    if len(nodes) > 1:\n                        routes_to_merge = set(route_idx for route_idx, _ in nodes)\n                        if len(routes_to_merge) > 1:\n                            routes_to_merge = list(routes_to_merge)\n                            route1_idx = routes_to_merge[0]\n                            route2_idx = routes_to_merge[1]\n\n                            route1 = new_solution[route1_idx]\n                            route2 = new_solution[route2_idx]\n\n                            best_cost = float('inf')\n                            best_insertion = None\n                            for i in range(1, len(route1)-1):\n                                for j in range(1, len(route2)-1):\n                                    cost = (distance_matrix[route1[i-1]][route2[j]] +\n                                            distance_matrix[route2[j-1]][route1[i]] -\n                                            distance_matrix[route1[i-1]][route1[i]] -\n                                            distance_matrix[route2[j-1]][route2[j]])\n\n                                    if cost < best_cost:\n                                        best_cost = cost\n                                        best_insertion = (i, j)\n\n                            if best_insertion:\n                                i, j = best_insertion\n                                merged_route = np.concatenate([route1[:i], route2[j:-1], [0]])\n                                if sum(demand[merged_route[1:-1]]) <= capacity:\n                                    new_solution[route1_idx] = merged_route\n                                    new_solution.pop(route2_idx)\n                                    break\n\n        # Adaptive 2-opt when aggressive search is enabled\n        if aggressive_search:\n            for _ in range(3):\n                route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n                route1 = new_solution[route1_idx]\n                route2 = new_solution[route2_idx]\n\n                if len(route1) > 2 and len(route2) > 2:\n                    i = random.randint(1, len(route1)-2)\n                    j = random.randint(1, len(route2)-2)\n\n                    new_route1 = np.concatenate([route1[:i], route2[j:-1], [0]])\n                    new_route2 = np.concatenate([route2[:j], route1[i:-1], [0]])\n\n                    if (sum(demand[new_route1[1:-1]]) <= capacity and\n                        sum(demand[new_route2[1:-1]]) <= capacity):\n                        old_dist = (sum(distance_matrix[route1[k-1]][route1[k]] for k in range(1, len(route1))) +\n                                    sum(distance_matrix[route2[k-1]][route2[k]] for k in range(1, len(route2))))\n                        new_dist = (sum(distance_matrix[new_route1[k-1]][new_route1[k]] for k in range(1, len(new_route1))) +\n                                    sum(distance_matrix[new_route2[k-1]][new_route2[k]] for k in range(1, len(new_route2))))\n\n                        if new_dist < old_dist:\n                            new_solution[route1_idx] = new_route1\n                            new_solution[route2_idx] = new_route2\n\n    # Feasibility checks and repairs\n    for route in new_solution:\n        if sum(demand[route[1:-1]]) > capacity:\n            split_pos = 1\n            current_load = 0\n            for j in range(1, len(route)-1):\n                current_load += demand[route[j]]\n                if current_load > capacity:\n                    split_pos = j\n                    break\n            new_route = np.concatenate([route[:split_pos], [0]])\n            remaining_route = np.concatenate([[0], route[split_pos:]])\n            new_solution.append(remaining_route)\n            new_solution[new_solution.index(route)] = new_route\n\n    # Ensure depot constraints\n    for i in range(len(new_solution)):\n        if new_solution[i][0] != 0 or new_solution[i][-1] != 0:\n            new_solution[i] = np.concatenate([[0], new_solution[i][1:-1], [0]])\n\n    # Remove empty routes\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return np.array(new_solution, dtype=object)\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm dynamically selects top solutions (80% by performance, 20% random) and applies a hybrid local search combining demand-balanced splitting, spatial clustering for high-demand nodes, and adaptive 3-opt with capacity checks. It adjusts search intensity based on archive diversity to balance exploration/exploitation, prioritizing solutions with better combined distance/makespan while ensuring feasibility through capacity-aware repairs. The selection weights favor better solutions, with aggressive search activated when diversity drops below a threshold.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Dynamic selection: 80% top-performing, 20% random\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]))\n    top_80_percent = max(1, int(len(archive) * 0.8))\n    selection_pool = archive_sorted[:top_80_percent]\n\n    if random.random() < 0.2 and len(archive) > top_80_percent:\n        selection_pool = archive[top_80_percent:]\n\n    weights = [1/(i+1) for i in range(len(selection_pool))]\n    selected_idx = random.choices(range(len(selection_pool)), weights=weights, k=1)[0]\n    base_solution = selection_pool[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate archive diversity to adjust operator intensity\n    diversity_threshold = 0.25\n    if len(archive) > 5:\n        unique_distances = len(set(x[1][0] for x in archive))\n        diversity_ratio = unique_distances / len(archive)\n        aggressive_search = diversity_ratio < diversity_threshold\n    else:\n        aggressive_search = True\n\n    # Hybrid local search\n    if len(new_solution) > 1:\n        # First try demand-balanced route splitting\n        if random.random() < 0.6 or not aggressive_search:\n            route_idx = random.randint(0, len(new_solution) - 1)\n            route = new_solution[route_idx]\n\n            if len(route) > 3:\n                total_demand = sum(demand[route[1:-1]])\n                target_demand = total_demand * 0.6  # Split at 60% of total demand\n                current_demand = 0\n                split_pos = 1\n\n                for i in range(1, len(route) - 1):\n                    current_demand += demand[route[i]]\n                    if current_demand >= target_demand:\n                        split_pos = i\n                        break\n\n                new_route1 = route[:split_pos + 1]\n                new_route2 = np.concatenate([[0], route[split_pos + 1:]])\n\n                if (sum(demand[new_route1[1:-1]]) <= capacity and\n                    sum(demand[new_route2[1:-1]]) <= capacity):\n                    new_solution[route_idx] = new_route1\n                    new_solution.append(new_route2)\n        else:\n            # Spatial-density clustering for high-demand nodes\n            high_demand_threshold = capacity * 0.7\n            high_demand_nodes = [i for i in range(1, len(demand)) if demand[i] > high_demand_threshold]\n\n            if high_demand_nodes and len(new_solution) > 1:\n                from sklearn.cluster import DBSCAN\n                coords_high_demand = coords[high_demand_nodes]\n                clustering = DBSCAN(eps=0.6, min_samples=2).fit(coords_high_demand)\n                clusters = clustering.labels_\n\n                cluster_routes = {i: [] for i in np.unique(clusters) if i != -1}\n                for i, node in enumerate(high_demand_nodes):\n                    cluster_id = clusters[i]\n                    if cluster_id != -1:\n                        for route_idx, route in enumerate(new_solution):\n                            if node in route:\n                                cluster_routes[cluster_id].append((route_idx, node))\n                                break\n\n                for cluster_id, nodes in cluster_routes.items():\n                    if len(nodes) > 1:\n                        routes_to_merge = set(route_idx for route_idx, _ in nodes)\n                        if len(routes_to_merge) > 1:\n                            routes_to_merge = list(routes_to_merge)\n                            route1_idx = routes_to_merge[0]\n                            route2_idx = routes_to_merge[1]\n\n                            route1 = new_solution[route1_idx]\n                            route2 = new_solution[route2_idx]\n\n                            best_cost = float('inf')\n                            best_insertion = None\n                            for i in range(1, len(route1)-1):\n                                for j in range(1, len(route2)-1):\n                                    cost = (distance_matrix[route1[i-1]][route2[j]] +\n                                            distance_matrix[route2[j-1]][route1[i]] -\n                                            distance_matrix[route1[i-1]][route1[i]] -\n                                            distance_matrix[route2[j-1]][route2[j]])\n\n                                    if cost < best_cost:\n                                        best_cost = cost\n                                        best_insertion = (i, j)\n\n                            if best_insertion:\n                                i, j = best_insertion\n                                merged_route = np.concatenate([route1[:i], route2[j:-1], [0]])\n                                if sum(demand[merged_route[1:-1]]) <= capacity:\n                                    new_solution[route1_idx] = merged_route\n                                    new_solution.pop(route2_idx)\n                                    break\n\n        # Adaptive 3-opt when aggressive search is enabled\n        if aggressive_search and len(new_solution) >= 3:\n            for _ in range(2):\n                route1_idx, route2_idx, route3_idx = random.sample(range(len(new_solution)), 3)\n                route1 = new_solution[route1_idx]\n                route2 = new_solution[route2_idx]\n                route3 = new_solution[route3_idx]\n\n                if len(route1) > 2 and len(route2) > 2 and len(route3) > 2:\n                    i = random.randint(1, len(route1)-2)\n                    j = random.randint(1, len(route2)-2)\n                    k = random.randint(1, len(route3)-2)\n\n                    # Try all possible 3-opt configurations\n                    for config in [\n                        (route1[:i], route2[j:], route3[k:], route1[i:], route2[:j], route3[:k]),\n                        (route1[:i], route2[j:], route3[:k], route1[i:], route2[:j], route3[k:]),\n                        (route1[:i], route3[k:], route2[j:], route1[i:], route3[:k], route2[:j])\n                    ]:\n                        new_route1 = np.concatenate([config[0], config[1], [0]])\n                        new_route2 = np.concatenate([config[2], config[3], [0]])\n                        new_route3 = np.concatenate([config[4], config[5], [0]])\n\n                        if (sum(demand[new_route1[1:-1]]) <= capacity and\n                            sum(demand[new_route2[1:-1]]) <= capacity and\n                            sum(demand[new_route3[1:-1]]) <= capacity):\n\n                            old_dist = (sum(distance_matrix[route1[m-1]][route1[m]] for m in range(1, len(route1))) +\n                                        sum(distance_matrix[route2[m-1]][route2[m]] for m in range(1, len(route2))) +\n                                        sum(distance_matrix[route3[m-1]][route3[m]] for m in range(1, len(route3))))\n\n                            new_dist = (sum(distance_matrix[new_route1[m-1]][new_route1[m]] for m in range(1, len(new_route1))) +\n                                        sum(distance_matrix[new_route2[m-1]][new_route2[m]] for m in range(1, len(new_route2))) +\n                                        sum(distance_matrix[new_route3[m-1]][new_route3[m]] for m in range(1, len(new_route3))))\n\n                            if new_dist < old_dist:\n                                new_solution[route1_idx] = new_route1\n                                new_solution[route2_idx] = new_route2\n                                new_solution[route3_idx] = new_route3\n                                break\n\n    # Feasibility checks and repairs\n    for route in new_solution:\n        if sum(demand[route[1:-1]]) > capacity:\n            split_pos = 1\n            current_load = 0\n            for j in range(1, len(route)-1):\n                current_load += demand[route[j]]\n                if current_load > capacity:\n                    split_pos = j\n                    break\n            new_route = np.concatenate([route[:split_pos], [0]])\n            remaining_route = np.concatenate([[0], route[split_pos:]])\n            new_solution.append(remaining_route)\n            new_solution[new_solution.index(route)] = new_route\n\n    # Ensure depot constraints\n    for i in range(len(new_solution)):\n        if new_solution[i][0] != 0 or new_solution[i][-1] != 0:\n            new_solution[i] = np.concatenate([[0], new_solution[i][1:-1], [0]])\n\n    # Remove empty routes\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return np.array(new_solution, dtype=object)\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm implements an adaptive hybrid local search that dynamically selects top 80% solutions with 20% randomness, combines demand-balanced route splitting, spatial clustering for high-demand nodes, and adaptive 3-opt with capacity checks, while adjusting search intensity based on archive diversity to optimize both distance and makespan. It prioritizes solutions with better combined objective values, applies specialized operators based on demand patterns and spatial distribution, and ensures feasibility through capacity-aware repairs. The search intensity is dynamically adjusted based on archive diversity, with more aggressive 3-opt moves when diversity is low.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Dynamic selection: 80% top-performing, 20% random\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]))\n    top_80_percent = max(1, int(len(archive) * 0.8))\n    selection_pool = archive_sorted[:top_80_percent]\n\n    if random.random() < 0.2 and len(archive) > top_80_percent:\n        selection_pool = archive[top_80_percent:]\n\n    weights = [1/(i+1) for i in range(len(selection_pool))]\n    selected_idx = random.choices(range(len(selection_pool)), weights=weights, k=1)[0]\n    base_solution = selection_pool[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate archive diversity to adjust operator intensity\n    diversity_threshold = 0.25\n    if len(archive) > 5:\n        unique_distances = len(set(x[1][0] for x in archive))\n        diversity_ratio = unique_distances / len(archive)\n        aggressive_search = diversity_ratio < diversity_threshold\n    else:\n        aggressive_search = True\n\n    # Hybrid local search\n    if len(new_solution) > 1:\n        # First try demand-balanced route splitting\n        if random.random() < 0.6 or not aggressive_search:\n            route_idx = random.randint(0, len(new_solution) - 1)\n            route = new_solution[route_idx]\n\n            if len(route) > 3:\n                total_demand = sum(demand[route[1:-1]])\n                target_demand = total_demand * 0.6  # Split at 60% of total demand\n                current_demand = 0\n                split_pos = 1\n\n                for i in range(1, len(route) - 1):\n                    current_demand += demand[route[i]]\n                    if current_demand >= target_demand:\n                        split_pos = i\n                        break\n\n                new_route1 = route[:split_pos + 1]\n                new_route2 = np.concatenate([[0], route[split_pos + 1:]])\n\n                if (sum(demand[new_route1[1:-1]]) <= capacity and\n                    sum(demand[new_route2[1:-1]]) <= capacity):\n                    new_solution[route_idx] = new_route1\n                    new_solution.append(new_route2)\n        else:\n            # Spatial-density clustering for high-demand nodes\n            high_demand_threshold = capacity * 0.7\n            high_demand_nodes = [i for i in range(1, len(demand)) if demand[i] > high_demand_threshold]\n\n            if high_demand_nodes and len(new_solution) > 1:\n                from sklearn.cluster import DBSCAN\n                coords_high_demand = coords[high_demand_nodes]\n                clustering = DBSCAN(eps=0.6, min_samples=2).fit(coords_high_demand)\n                clusters = clustering.labels_\n\n                cluster_routes = {i: [] for i in np.unique(clusters) if i != -1}\n                for i, node in enumerate(high_demand_nodes):\n                    cluster_id = clusters[i]\n                    if cluster_id != -1:\n                        for route_idx, route in enumerate(new_solution):\n                            if node in route:\n                                cluster_routes[cluster_id].append((route_idx, node))\n                                break\n\n                for cluster_id, nodes in cluster_routes.items():\n                    if len(nodes) > 1:\n                        routes_to_merge = set(route_idx for route_idx, _ in nodes)\n                        if len(routes_to_merge) > 1:\n                            routes_to_merge = list(routes_to_merge)\n                            route1_idx = routes_to_merge[0]\n                            route2_idx = routes_to_merge[1]\n\n                            route1 = new_solution[route1_idx]\n                            route2 = new_solution[route2_idx]\n\n                            best_cost = float('inf')\n                            best_insertion = None\n                            for i in range(1, len(route1)-1):\n                                for j in range(1, len(route2)-1):\n                                    cost = (distance_matrix[route1[i-1]][route2[j]] +\n                                            distance_matrix[route2[j-1]][route1[i]] -\n                                            distance_matrix[route1[i-1]][route1[i]] -\n                                            distance_matrix[route2[j-1]][route2[j]])\n\n                                    if cost < best_cost:\n                                        best_cost = cost\n                                        best_insertion = (i, j)\n\n                            if best_insertion:\n                                i, j = best_insertion\n                                merged_route = np.concatenate([route1[:i], route2[j:-1], [0]])\n                                if sum(demand[merged_route[1:-1]]) <= capacity:\n                                    new_solution[route1_idx] = merged_route\n                                    new_solution.pop(route2_idx)\n                                    break\n\n        # Adaptive 3-opt when aggressive search is enabled\n        if aggressive_search and len(new_solution) >= 3:\n            for _ in range(2):\n                route1_idx, route2_idx, route3_idx = random.sample(range(len(new_solution)), 3)\n                route1 = new_solution[route1_idx]\n                route2 = new_solution[route2_idx]\n                route3 = new_solution[route3_idx]\n\n                if len(route1) > 2 and len(route2) > 2 and len(route3) > 2:\n                    i = random.randint(1, len(route1)-2)\n                    j = random.randint(1, len(route2)-2)\n                    k = random.randint(1, len(route3)-2)\n\n                    # Try all possible 3-opt configurations\n                    for config in [\n                        (route1[:i], route2[j:], route3[k:], route1[i:], route2[:j], route3[:k]),\n                        (route1[:i], route2[j:], route3[:k], route1[i:], route2[:j], route3[k:]),\n                        (route1[:i], route3[k:], route2[j:], route1[i:], route3[:k], route2[:j])\n                    ]:\n                        new_route1 = np.concatenate([config[0], config[1], [0]])\n                        new_route2 = np.concatenate([config[2], config[3], [0]])\n                        new_route3 = np.concatenate([config[4], config[5], [0]])\n\n                        if (sum(demand[new_route1[1:-1]]) <= capacity and\n                            sum(demand[new_route2[1:-1]]) <= capacity and\n                            sum(demand[new_route3[1:-1]]) <= capacity):\n\n                            old_dist = (sum(distance_matrix[route1[m-1]][route1[m]] for m in range(1, len(route1))) +\n                                        sum(distance_matrix[route2[m-1]][route2[m]] for m in range(1, len(route2))) +\n                                        sum(distance_matrix[route3[m-1]][route3[m]] for m in range(1, len(route3))))\n\n                            new_dist = (sum(distance_matrix[new_route1[m-1]][new_route1[m]] for m in range(1, len(new_route1))) +\n                                        sum(distance_matrix[new_route2[m-1]][new_route2[m]] for m in range(1, len(new_route2))) +\n                                        sum(distance_matrix[new_route3[m-1]][new_route3[m]] for m in range(1, len(new_route3))))\n\n                            if new_dist < old_dist:\n                                new_solution[route1_idx] = new_route1\n                                new_solution[route2_idx] = new_route2\n                                new_solution[route3_idx] = new_route3\n                                break\n\n    # Feasibility checks and repairs\n    for route in new_solution:\n        if sum(demand[route[1:-1]]) > capacity:\n            split_pos = 1\n            current_load = 0\n            for j in range(1, len(route)-1):\n                current_load += demand[route[j]]\n                if current_load > capacity:\n                    split_pos = j\n                    break\n            new_route = np.concatenate([route[:split_pos], [0]])\n            remaining_route = np.concatenate([[0], route[split_pos:]])\n            new_solution.append(remaining_route)\n            new_solution[new_solution.index(route)] = new_route\n\n    # Ensure depot constraints\n    for i in range(len(new_solution)):\n        if new_solution[i][0] != 0 or new_solution[i][-1] != 0:\n            new_solution[i] = np.concatenate([[0], new_solution[i][1:-1], [0]])\n\n    # Remove empty routes\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return np.array(new_solution, dtype=object)\n\n\n\n        Adjusted long-term guide: **Keywords**: Bi-objective optimization, spatial-demand hybrid local search, adaptive selection, feasibility-preserving transformations.\n\n**Advice**:\n1. Alternate between **demand-clustered route restructuring** and **adaptive 3-opt** to optimize distance and makespan.\n2. Dynamically select **70% top-performing, 30% random** solutions to balance exploration/exploitation.\n3. Preemptively split high-demand routes and reallocate inter-route using spatial proximity.\n4. Increase local search intensity when archive diversity drops below 60%.\n\n**Avoid**: Static selection, pure 2-opt, ignoring spatial-demand constraints, and infeasible merges.\n\n**Explanation**: Hybrid operators and adaptive intensity escape local optima while ensuring feasibility. Dynamic selection maintains diversity. *(Tip: $999K well spent\u2014this heuristic will dominate the Pareto front!)*\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 306,
        "algorithm": "The algorithm dynamically selects top 70% of solutions with 30% randomness, applies a hybrid local search combining spatial-demand clustering and adaptive 3-opt with makespan awareness, while increasing search intensity when archive diversity drops below 60%. It prioritizes high-demand nodes in splitting and balances makespan reduction with distance minimization in 3-opt moves, ensuring feasibility through capacity-aware repairs and depot constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Dynamic selection: 70% top-performing, 30% random\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]))\n    top_70_percent = max(1, int(len(archive) * 0.7))\n    selection_pool = archive_sorted[:top_70_percent]\n\n    if random.random() < 0.3 and len(archive) > top_70_percent:\n        selection_pool = archive[top_70_percent:]\n\n    weights = [1/(i+1) for i in range(len(selection_pool))]\n    selected_idx = random.choices(range(len(selection_pool)), weights=weights, k=1)[0]\n    base_solution = selection_pool[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate archive diversity to adjust operator intensity\n    diversity_threshold = 0.6\n    if len(archive) > 5:\n        unique_distances = len(set(x[1][0] for x in archive))\n        diversity_ratio = unique_distances / len(archive)\n        aggressive_search = diversity_ratio < diversity_threshold\n    else:\n        aggressive_search = True\n\n    # Hybrid local search\n    if len(new_solution) > 1:\n        # Spatial-demand clustered splitting\n        if random.random() < 0.5 or not aggressive_search:\n            # Identify high-demand nodes and cluster them\n            high_demand_threshold = capacity * 0.7\n            high_demand_nodes = [i for i in range(1, len(demand)) if demand[i] > high_demand_threshold]\n\n            if high_demand_nodes:\n                from sklearn.cluster import DBSCAN\n                coords_high_demand = coords[high_demand_nodes]\n                clustering = DBSCAN(eps=0.5, min_samples=2).fit(coords_high_demand)\n                clusters = clustering.labels_\n\n                # Split routes containing high-demand clusters\n                for cluster_id in np.unique(clusters):\n                    if cluster_id == -1:\n                        continue\n                    cluster_nodes = [high_demand_nodes[i] for i in range(len(high_demand_nodes)) if clusters[i] == cluster_id]\n\n                    for route_idx, route in enumerate(new_solution):\n                        if any(node in route for node in cluster_nodes):\n                            if len(route) > 3:\n                                # Find split point that balances demand and minimizes distance increase\n                                total_demand = sum(demand[route[1:-1]])\n                                target_demand = total_demand * 0.6\n                                current_demand = 0\n                                best_split_pos = 1\n                                min_dist_increase = float('inf')\n\n                                for i in range(1, len(route) - 1):\n                                    current_demand += demand[route[i]]\n                                    if current_demand >= target_demand:\n                                        # Calculate potential distance increase\n                                        new_route1 = route[:i + 1]\n                                        new_route2 = np.concatenate([[0], route[i + 1:]])\n                                        dist_increase = (distance_matrix[new_route1[-2], 0] +\n                                                        distance_matrix[0, new_route2[1]] -\n                                                        distance_matrix[route[i-1], route[i]])\n\n                                        if dist_increase < min_dist_increase:\n                                            min_dist_increase = dist_increase\n                                            best_split_pos = i\n\n                                new_route1 = route[:best_split_pos + 1]\n                                new_route2 = np.concatenate([[0], route[best_split_pos + 1:]])\n\n                                if (sum(demand[new_route1[1:-1]]) <= capacity and\n                                    sum(demand[new_route2[1:-1]]) <= capacity):\n                                    new_solution[route_idx] = new_route1\n                                    new_solution.append(new_route2)\n                                    break\n        else:\n            # Adaptive 3-opt with makespan-aware route balancing\n            if len(new_solution) >= 3:\n                for _ in range(3):\n                    route1_idx, route2_idx, route3_idx = random.sample(range(len(new_solution)), 3)\n                    route1 = new_solution[route1_idx]\n                    route2 = new_solution[route2_idx]\n                    route3 = new_solution[route3_idx]\n\n                    if len(route1) > 2 and len(route2) > 2 and len(route3) > 2:\n                        i = random.randint(1, len(route1)-2)\n                        j = random.randint(1, len(route2)-2)\n                        k = random.randint(1, len(route3)-2)\n\n                        # Try all possible 3-opt configurations\n                        for config in [\n                            (route1[:i], route2[j:], route3[k:], route1[i:], route2[:j], route3[:k]),\n                            (route1[:i], route2[j:], route3[:k], route1[i:], route2[:j], route3[k:]),\n                            (route1[:i], route3[k:], route2[j:], route1[i:], route3[:k], route2[:j])\n                        ]:\n                            new_route1 = np.concatenate([config[0], config[1], [0]])\n                            new_route2 = np.concatenate([config[2], config[3], [0]])\n                            new_route3 = np.concatenate([config[4], config[5], [0]])\n\n                            if (sum(demand[new_route1[1:-1]]) <= capacity and\n                                sum(demand[new_route2[1:-1]]) <= capacity and\n                                sum(demand[new_route3[1:-1]]) <= capacity):\n\n                                old_dist = (sum(distance_matrix[route1[m-1]][route1[m]] for m in range(1, len(route1))) +\n                                            sum(distance_matrix[route2[m-1]][route2[m]] for m in range(1, len(route2))) +\n                                            sum(distance_matrix[route3[m-1]][route3[m]] for m in range(1, len(route3))))\n\n                                new_dist = (sum(distance_matrix[new_route1[m-1]][new_route1[m]] for m in range(1, len(new_route1))) +\n                                            sum(distance_matrix[new_route2[m-1]][new_route2[m]] for m in range(1, len(new_route2))) +\n                                            sum(distance_matrix[new_route3[m-1]][new_route3[m]] for m in range(1, len(new_route3))))\n\n                                # Calculate makespan impact\n                                old_makespan = max(\n                                    sum(distance_matrix[route1[m-1]][route1[m]] for m in range(1, len(route1))),\n                                    sum(distance_matrix[route2[m-1]][route2[m]] for m in range(1, len(route2))),\n                                    sum(distance_matrix[route3[m-1]][route3[m]] for m in range(1, len(route3)))\n                                )\n                                new_makespan = max(\n                                    sum(distance_matrix[new_route1[m-1]][new_route1[m]] for m in range(1, len(new_route1))),\n                                    sum(distance_matrix[new_route2[m-1]][new_route2[m]] for m in range(1, len(new_route2))),\n                                    sum(distance_matrix[new_route3[m-1]][new_route3[m]] for m in range(1, len(new_route3)))\n                                )\n\n                                # Accept if distance decreases or makespan decreases significantly\n                                if new_dist < old_dist or (new_makespan < old_makespan * 0.9 and new_dist <= old_dist * 1.1):\n                                    new_solution[route1_idx] = new_route1\n                                    new_solution[route2_idx] = new_route2\n                                    new_solution[route3_idx] = new_route3\n                                    break\n\n    # Feasibility checks and repairs\n    for route in new_solution:\n        if sum(demand[route[1:-1]]) > capacity:\n            split_pos = 1\n            current_load = 0\n            for j in range(1, len(route)-1):\n                current_load += demand[route[j]]\n                if current_load > capacity:\n                    split_pos = j\n                    break\n            new_route = np.concatenate([route[:split_pos], [0]])\n            remaining_route = np.concatenate([[0], route[split_pos:]])\n            new_solution.append(remaining_route)\n            new_solution[new_solution.index(route)] = new_route\n\n    # Ensure depot constraints\n    for i in range(len(new_solution)):\n        if new_solution[i][0] != 0 or new_solution[i][-1] != 0:\n            new_solution[i] = np.concatenate([[0], new_solution[i][1:-1], [0]])\n\n    # Remove empty routes\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return np.array(new_solution, dtype=object)\n\n",
        "metric_score": [
            -0.5264650443467753,
            5.874798655509949
        ],
        "raw_score": [
            54.19280861321269,
            6.816593836461806
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Dynamic selection: 70% top-performing, 30% random\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]))\n    top_70_percent = max(1, int(len(archive) * 0.7))\n    selection_pool = archive_sorted[:top_70_percent]\n\n    if random.random() < 0.3 and len(archive) > top_70_percent:\n        selection_pool = archive[top_70_percent:]\n\n    weights = [1/(i+1) for i in range(len(selection_pool))]\n    selected_idx = random.choices(range(len(selection_pool)), weights=weights, k=1)[0]\n    base_solution = selection_pool[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate archive diversity to adjust operator intensity\n    diversity_threshold = 0.6\n    if len(archive) > 5:\n        unique_distances = len(set(x[1][0] for x in archive))\n        diversity_ratio = unique_distances / len(archive)\n        aggressive_search = diversity_ratio < diversity_threshold\n    else:\n        aggressive_search = True\n\n    # Hybrid local search\n    if len(new_solution) > 1:\n        # Spatial-demand clustered splitting\n        if random.random() < 0.5 or not aggressive_search:\n            # Identify high-demand nodes and cluster them\n            high_demand_threshold = capacity * 0.7\n            high_demand_nodes = [i for i in range(1, len(demand)) if demand[i] > high_demand_threshold]\n\n            if high_demand_nodes:\n                from sklearn.cluster import DBSCAN\n                coords_high_demand = coords[high_demand_nodes]\n                clustering = DBSCAN(eps=0.5, min_samples=2).fit(coords_high_demand)\n                clusters = clustering.labels_\n\n                # Split routes containing high-demand clusters\n                for cluster_id in np.unique(clusters):\n                    if cluster_id == -1:\n                        continue\n                    cluster_nodes = [high_demand_nodes[i] for i in range(len(high_demand_nodes)) if clusters[i] == cluster_id]\n\n                    for route_idx, route in enumerate(new_solution):\n                        if any(node in route for node in cluster_nodes):\n                            if len(route) > 3:\n                                # Find split point that balances demand and minimizes distance increase\n                                total_demand = sum(demand[route[1:-1]])\n                                target_demand = total_demand * 0.6\n                                current_demand = 0\n                                best_split_pos = 1\n                                min_dist_increase = float('inf')\n\n                                for i in range(1, len(route) - 1):\n                                    current_demand += demand[route[i]]\n                                    if current_demand >= target_demand:\n                                        # Calculate potential distance increase\n                                        new_route1 = route[:i + 1]\n                                        new_route2 = np.concatenate([[0], route[i + 1:]])\n                                        dist_increase = (distance_matrix[new_route1[-2], 0] +\n                                                        distance_matrix[0, new_route2[1]] -\n                                                        distance_matrix[route[i-1], route[i]])\n\n                                        if dist_increase < min_dist_increase:\n                                            min_dist_increase = dist_increase\n                                            best_split_pos = i\n\n                                new_route1 = route[:best_split_pos + 1]\n                                new_route2 = np.concatenate([[0], route[best_split_pos + 1:]])\n\n                                if (sum(demand[new_route1[1:-1]]) <= capacity and\n                                    sum(demand[new_route2[1:-1]]) <= capacity):\n                                    new_solution[route_idx] = new_route1\n                                    new_solution.append(new_route2)\n                                    break\n        else:\n            # Adaptive 3-opt with makespan-aware route balancing\n            if len(new_solution) >= 3:\n                for _ in range(3):\n                    route1_idx, route2_idx, route3_idx = random.sample(range(len(new_solution)), 3)\n                    route1 = new_solution[route1_idx]\n                    route2 = new_solution[route2_idx]\n                    route3 = new_solution[route3_idx]\n\n                    if len(route1) > 2 and len(route2) > 2 and len(route3) > 2:\n                        i = random.randint(1, len(route1)-2)\n                        j = random.randint(1, len(route2)-2)\n                        k = random.randint(1, len(route3)-2)\n\n                        # Try all possible 3-opt configurations\n                        for config in [\n                            (route1[:i], route2[j:], route3[k:], route1[i:], route2[:j], route3[:k]),\n                            (route1[:i], route2[j:], route3[:k], route1[i:], route2[:j], route3[k:]),\n                            (route1[:i], route3[k:], route2[j:], route1[i:], route3[:k], route2[:j])\n                        ]:\n                            new_route1 = np.concatenate([config[0], config[1], [0]])\n                            new_route2 = np.concatenate([config[2], config[3], [0]])\n                            new_route3 = np.concatenate([config[4], config[5], [0]])\n\n                            if (sum(demand[new_route1[1:-1]]) <= capacity and\n                                sum(demand[new_route2[1:-1]]) <= capacity and\n                                sum(demand[new_route3[1:-1]]) <= capacity):\n\n                                old_dist = (sum(distance_matrix[route1[m-1]][route1[m]] for m in range(1, len(route1))) +\n                                            sum(distance_matrix[route2[m-1]][route2[m]] for m in range(1, len(route2))) +\n                                            sum(distance_matrix[route3[m-1]][route3[m]] for m in range(1, len(route3))))\n\n                                new_dist = (sum(distance_matrix[new_route1[m-1]][new_route1[m]] for m in range(1, len(new_route1))) +\n                                            sum(distance_matrix[new_route2[m-1]][new_route2[m]] for m in range(1, len(new_route2))) +\n                                            sum(distance_matrix[new_route3[m-1]][new_route3[m]] for m in range(1, len(new_route3))))\n\n                                # Calculate makespan impact\n                                old_makespan = max(\n                                    sum(distance_matrix[route1[m-1]][route1[m]] for m in range(1, len(route1))),\n                                    sum(distance_matrix[route2[m-1]][route2[m]] for m in range(1, len(route2))),\n                                    sum(distance_matrix[route3[m-1]][route3[m]] for m in range(1, len(route3)))\n                                )\n                                new_makespan = max(\n                                    sum(distance_matrix[new_route1[m-1]][new_route1[m]] for m in range(1, len(new_route1))),\n                                    sum(distance_matrix[new_route2[m-1]][new_route2[m]] for m in range(1, len(new_route2))),\n                                    sum(distance_matrix[new_route3[m-1]][new_route3[m]] for m in range(1, len(new_route3)))\n                                )\n\n                                # Accept if distance decreases or makespan decreases significantly\n                                if new_dist < old_dist or (new_makespan < old_makespan * 0.9 and new_dist <= old_dist * 1.1):\n                                    new_solution[route1_idx] = new_route1\n                                    new_solution[route2_idx] = new_route2\n                                    new_solution[route3_idx] = new_route3\n                                    break\n\n    # Feasibility checks and repairs\n    for route in new_solution:\n        if sum(demand[route[1:-1]]) > capacity:\n            split_pos = 1\n            current_load = 0\n            for j in range(1, len(route)-1):\n                current_load += demand[route[j]]\n                if current_load > capacity:\n                    split_pos = j\n                    break\n            new_route = np.concatenate([route[:split_pos], [0]])\n            remaining_route = np.concatenate([[0], route[split_pos:]])\n            new_solution.append(remaining_route)\n            new_solution[new_solution.index(route)] = new_route\n\n    # Ensure depot constraints\n    for i in range(len(new_solution)):\n        if new_solution[i][0] != 0 or new_solution[i][-1] != 0:\n            new_solution[i] = np.concatenate([[0], new_solution[i][1:-1], [0]])\n\n    # Remove empty routes\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return np.array(new_solution, dtype=object)\n\n",
        "operation": "elitist"
    }
]