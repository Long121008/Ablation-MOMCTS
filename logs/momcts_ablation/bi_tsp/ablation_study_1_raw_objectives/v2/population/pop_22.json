[
    {
        "algorithm": "The algorithm selects the most promising solution from the archive (based on the highest sum of normalized objectives) and applies a hybrid local search: either a random edge swap or node reinsertion to generate a neighbor solution while ensuring feasibility. The selection prioritizes solutions with higher combined costs, while the local search explores neighborhoods through randomized edge swaps or node reinsertions. The approach balances exploration and exploitation by combining simple but effective perturbations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    max_sum = -1\n    selected_solution = None\n    for sol, obj in archive:\n        normalized_obj = (obj[0] + obj[1]) / 2  # Simple normalization\n        if normalized_obj > max_sum:\n            max_sum = normalized_obj\n            selected_solution = sol.copy()\n\n    new_solution = selected_solution.copy()\n\n    # Hybrid local search: random edge swap or node reinsertion\n    n = len(new_solution)\n    if np.random.rand() < 0.5:  # Edge swap\n        i = np.random.randint(0, n)\n        j = np.random.randint(0, n)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n    else:  # Node reinsertion\n        i = np.random.randint(0, n)\n        node = new_solution[i]\n        new_solution = np.delete(new_solution, i)\n        j = np.random.randint(0, n-1)\n        new_solution = np.insert(new_solution, j, node)\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9263534306788621,
            0.2028200626373291
        ],
        "raw_score": [
            10.527134484715972,
            10.564929956806642
        ]
    },
    {
        "algorithm": "The algorithm selects a Pareto-dominated solution from the archive (prioritizing non-dominated or randomly choosing from dominated solutions) and applies a hybrid local search: it first attempts a segment reversal (2-opt-like) if it improves either objective, otherwise performs a random node reinsertion to maintain feasibility. The method ensures solution validity by checking node uniqueness and preserves the tour structure while exploring multi-objective improvements.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a Pareto-dominated solution\n    dominated_counts = [0] * len(archive)\n    for i, (sol_i, obj_i) in enumerate(archive):\n        for j, (sol_j, obj_j) in enumerate(archive):\n            if i != j and (obj_j[0] <= obj_i[0] and obj_j[1] <= obj_i[1]) and (obj_j[0] < obj_i[0] or obj_j[1] < obj_i[1]):\n                dominated_counts[i] += 1\n\n    non_dominated_indices = [i for i, count in enumerate(dominated_counts) if count == 0]\n    if not non_dominated_indices:\n        non_dominated_indices = range(len(archive))\n\n    selected_index = random.choice(non_dominated_indices)\n    base_solution = archive[selected_index][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n\n    # Hybrid local search: segment reversal if beneficial, else node reinsertion\n    if n >= 4:\n        i, j = sorted(random.sample(range(n), 2))\n        a, b, c, d = base_solution[i], base_solution[i+1], base_solution[j], base_solution[j+1] if j+1 < n else base_solution[0]\n        delta1 = (distance_matrix_1[a, c] + distance_matrix_1[b, d]) - (distance_matrix_1[a, b] + distance_matrix_1[c, d])\n        delta2 = (distance_matrix_2[a, c] + distance_matrix_2[b, d]) - (distance_matrix_2[a, b] + distance_matrix_2[c, d])\n\n        if delta1 < 0 or delta2 < 0:\n            new_solution[i+1:j+1] = np.flip(new_solution[i+1:j+1])\n        else:\n            k = random.randint(0, n-1)\n            node = new_solution[k]\n            new_solution = np.delete(new_solution, k)\n            l = random.randint(0, n-2)\n            new_solution = np.insert(new_solution, l, node)\n    else:\n        # For small instances, perform a simple swap\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure feasibility\n    assert len(new_solution) == n\n    assert len(np.unique(new_solution)) == n\n    assert set(new_solution) == set(base_solution)\n\n    return new_solution\n\n",
        "metric_score": [
            -1.0259954099517012,
            0.38352054357528687
        ],
        "raw_score": [
            5.699175348104417,
            7.028717067597253
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive based on a weighted combination of normalized objective scores, then applies a hybrid local search combining 3-opt edge exchanges with adaptive node reinsertion to generate a neighbor solution while ensuring feasibility. It prioritizes solutions with better combined objective performance and intelligently balances exploration (random selection) and exploitation (targeted improvements) through weighted edge exchanges and adaptive insertions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if len(archive) == 0:\n        return np.random.permutation(len(instance))\n\n    # Calculate normalized objective scores for selection\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        weights = [0.5, 0.5]\n    else:\n        weights = [1/max_obj1, 1/max_obj2]\n    scores = [weights[0]*obj[0] + weights[1]*obj[1] for _, obj in archive]\n\n    # Select solution with highest combined score (higher score = better potential)\n    selected_index = np.argmax(scores)\n    base_solution = archive[selected_index][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 5:\n        # For small instances, perform a random swap\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n    else:\n        # Hybrid local search: 3-opt edge exchange with adaptive insertion\n        # Step 1: Select three edges to exchange (3-opt)\n        i, j, k = sorted(random.sample(range(n), 3))\n\n        # Step 2: Calculate potential improvement\n        a, b, c, d, e, f = base_solution[i], base_solution[(i+1)%n], base_solution[j], base_solution[(j+1)%n], base_solution[k], base_solution[(k+1)%n]\n\n        # Calculate changes for both objectives\n        delta1 = (distance_matrix_1[a,d] + distance_matrix_1[b,e] + distance_matrix_1[c,f]) - \\\n                 (distance_matrix_1[a,b] + distance_matrix_1[c,d] + distance_matrix_1[e,f])\n        delta2 = (distance_matrix_2[a,d] + distance_matrix_2[b,e] + distance_matrix_2[c,f]) - \\\n                 (distance_matrix_2[a,b] + distance_matrix_2[c,d] + distance_matrix_2[e,f])\n\n        if delta1 < 0 or delta2 < 0:\n            # If 3-opt improves at least one objective, perform it\n            new_solution[(i+1):(j+1)] = np.flip(new_solution[(i+1):(j+1)])\n            new_solution[(j+1):(k+1)] = np.flip(new_solution[(j+1):(k+1)])\n        else:\n            # Adaptive node reinsertion\n            # Select a node to remove and reinsert\n            remove_pos = random.randint(0, n-1)\n            node = new_solution[remove_pos]\n\n            # Calculate insertion positions based on both objectives\n            obj1_costs = [distance_matrix_1[new_solution[i], node] + distance_matrix_1[node, new_solution[(i+1)%n]] for i in range(n-1)]\n            obj2_costs = [distance_matrix_2[new_solution[i], node] + distance_matrix_2[node, new_solution[(i+1)%n]] for i in range(n-1)]\n\n            # Weighted insertion score\n            insertion_scores = [weights[0]*obj1_costs[i] + weights[1]*obj2_costs[i] for i in range(n-1)]\n            insert_pos = np.argmin(insertion_scores)\n\n            # Perform insertion\n            new_solution = np.concatenate([new_solution[:remove_pos], new_solution[remove_pos+1:]])\n            new_solution = np.insert(new_solution, insert_pos, node)\n\n    return new_solution\n\n",
        "metric_score": [
            -1.0082527092395177,
            0.22302573919296265
        ],
        "raw_score": [
            10.40473316868271,
            10.656387013563487
        ]
    },
    {
        "algorithm": "The algorithm combines Pareto-based selection with a novel multi-segment reversal strategy that prioritizes non-dominated solutions and dynamically adapts segment reversal based on solution quality and instance size, while ensuring feasibility through a constraint-aware repair mechanism that preserves high-quality edges. It intelligently selects segments with high edge diversity in both objective spaces and uses probabilistic segment selection, falling back to node insertion or swapping for smaller instances or dominated solutions. The repair mechanism guarantees feasibility by reconstructing solutions while preserving the most promising edges from the original solution.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate dominance ranks for each solution\n    dominance_ranks = []\n    for i, (sol_i, obj_i) in enumerate(archive):\n        rank = 0\n        for j, (sol_j, obj_j) in enumerate(archive):\n            if i != j and (obj_j[0] <= obj_i[0] and obj_j[1] <= obj_i[1]) and (obj_j[0] < obj_i[0] or obj_j[1] < obj_i[1]):\n                rank += 1\n        dominance_ranks.append(rank)\n\n    # Select a solution with probability inversely proportional to its dominance rank\n    max_rank = max(dominance_ranks)\n    selection_probs = [(max_rank - rank + 1) / sum(max_rank - r + 1 for r in dominance_ranks) for rank in dominance_ranks]\n    selected_index = np.random.choice(len(archive), p=selection_probs)\n    base_solution = archive[selected_index][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n\n    # Determine the number of segments to reverse based on solution quality and instance size\n    if dominance_ranks[selected_index] == 0 and n >= 8:\n        # For non-dominated solutions in large instances, use multi-segment reversal\n        num_segments = min(3, n // 4)\n        segment_lengths = [random.randint(2, n // num_segments) for _ in range(num_segments)]\n        total_length = sum(segment_lengths)\n\n        while total_length > n:\n            segment_lengths = [max(2, l - 1) for l in segment_lengths]\n            total_length = sum(segment_lengths)\n\n        # Select segments with high edge diversity\n        segment_scores = []\n        for i in range(num_segments):\n            start = random.randint(0, n - segment_lengths[i])\n            end = start + segment_lengths[i]\n            score = 0\n            for j in range(start, end - 1):\n                a, b = base_solution[j], base_solution[j+1]\n                score += distance_matrix_1[a, b] + distance_matrix_2[a, b]\n            segment_scores.append((start, end, score))\n\n        # Sort segments by score (descending) to prioritize high diversity\n        segment_scores.sort(key=lambda x: -x[2])\n\n        # Reverse the selected segments\n        for start, end, _ in segment_scores:\n            new_solution[start:end] = np.flip(new_solution[start:end])\n    else:\n        # For dominated solutions or small instances, use a combination of node insertion and swap\n        if n >= 6:\n            # Node insertion with objective-aware selection\n            k = random.randint(0, n-1)\n            node = new_solution[k]\n            new_solution = np.delete(new_solution, k)\n\n            # Find best insertion point based on both objectives\n            best_pos = 0\n            min_cost = float('inf')\n\n            for pos in range(n-1):\n                cost1 = distance_matrix_1[new_solution[pos], node] + distance_matrix_1[node, new_solution[(pos+1)%(n-1)]] - distance_matrix_1[new_solution[pos], new_solution[(pos+1)%(n-1)]]\n                cost2 = distance_matrix_2[new_solution[pos], node] + distance_matrix_2[node, new_solution[(pos+1)%(n-1)]] - distance_matrix_2[new_solution[pos], new_solution[(pos+1)%(n-1)]]\n\n                if abs(cost1) + abs(cost2) < min_cost:\n                    min_cost = abs(cost1) + abs(cost2)\n                    best_pos = pos\n\n            new_solution = np.insert(new_solution, best_pos, node)\n        else:\n            # Node swap with objective-aware selection\n            i, j = random.sample(range(n), 2)\n            delta1 = (distance_matrix_1[base_solution[i-1], base_solution[j]] + distance_matrix_1[base_solution[j], base_solution[(i+1)%n]] +\n                      distance_matrix_1[base_solution[j-1], base_solution[i]] + distance_matrix_1[base_solution[i], base_solution[(j+1)%n]]) - \\\n                     (distance_matrix_1[base_solution[i-1], base_solution[i]] + distance_matrix_1[base_solution[i], base_solution[(i+1)%n]] +\n                      distance_matrix_1[base_solution[j-1], base_solution[j]] + distance_matrix_1[base_solution[j], base_solution[(j+1)%n]])\n            delta2 = (distance_matrix_2[base_solution[i-1], base_solution[j]] + distance_matrix_2[base_solution[j], base_solution[(i+1)%n]] +\n                      distance_matrix_2[base_solution[j-1], base_solution[i]] + distance_matrix_2[base_solution[i], base_solution[(j+1)%n]]) - \\\n                     (distance_matrix_2[base_solution[i-1], base_solution[i]] + distance_matrix_2[base_solution[i], base_solution[(i+1)%n]] +\n                      distance_matrix_2[base_solution[j-1], base_solution[j]] + distance_matrix_2[base_solution[j], base_solution[(j+1)%n]])\n\n            if delta1 < 0 or delta2 < 0:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Feasibility check and repair\n    if len(new_solution) != n or len(np.unique(new_solution)) != n or set(new_solution) != set(base_solution):\n        # Repair mechanism: build a new solution while preserving the most promising edges\n        edge_scores = []\n        for i in range(n):\n            a, b = base_solution[i], base_solution[(i+1)%n]\n            score = distance_matrix_1[a, b] + distance_matrix_2[a, b]\n            edge_scores.append((a, b, score))\n\n        # Sort edges by score (ascending) to prioritize better edges\n        edge_scores.sort(key=lambda x: x[2])\n\n        # Build a new solution using the best edges\n        remaining_nodes = set(range(n))\n        new_solution = []\n        current_node = edge_scores[0][0]\n        new_solution.append(current_node)\n        remaining_nodes.remove(current_node)\n\n        while remaining_nodes:\n            candidates = []\n            for a, b, _ in edge_scores:\n                if a == current_node and b in remaining_nodes:\n                    candidates.append(b)\n                elif b == current_node and a in remaining_nodes:\n                    candidates.append(a)\n\n            if candidates:\n                next_node = candidates[0]\n            else:\n                # If no preserved edges available, choose randomly\n                next_node = random.choice(list(remaining_nodes))\n\n            new_solution.append(next_node)\n            remaining_nodes.remove(next_node)\n            current_node = next_node\n\n        new_solution = np.array(new_solution)\n\n    # Final feasibility check\n    assert len(new_solution) == n\n    assert len(np.unique(new_solution)) == n\n    assert set(new_solution) == set(base_solution)\n\n    return new_solution\n\n",
        "metric_score": [
            -1.0110876109646503,
            0.30217015743255615
        ],
        "raw_score": [
            6.935908396060273,
            7.443704727419918
        ]
    },
    {
        "algorithm": "The algorithm employs a multi-objective clustering approach to select promising solutions from an archive, followed by a hybrid local search combining segment reversal and edge swapping, with a dynamic repair mechanism prioritizing edge quality based on both objectives' trade-offs. It balances exploration and exploitation by adaptively weighting improvements in each objective space and ensures feasibility through a reconstruction process that preserves high-quality edges. The selection process prioritizes Pareto front membership and trade-off balance, while the local search dynamically adjusts weights based on improvement potential.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Objective-aware clustering and selection\n    objectives = np.array([obj for _, obj in archive])\n    min_obj = np.min(objectives, axis=0)\n    max_obj = np.max(objectives, axis=0)\n\n    # Normalize objectives for clustering\n    normalized = (objectives - min_obj) / (max_obj - min_obj + 1e-10)\n\n    # Cluster solutions using k-means (k=3 for Pareto front, middle, and dominated)\n    from sklearn.cluster import KMeans\n    kmeans = KMeans(n_clusters=min(3, len(archive)), random_state=42)\n    clusters = kmeans.fit_predict(normalized)\n\n    # Select cluster with best average trade-off\n    cluster_scores = []\n    for c in range(len(kmeans.cluster_centers_)):\n        cluster_mask = (clusters == c)\n        cluster_obj = objectives[cluster_mask]\n        if len(cluster_obj) == 0:\n            cluster_scores.append(0)\n            continue\n        avg_obj = np.mean(cluster_obj, axis=0)\n        tradeoff = np.sum(avg_obj) / (1 + np.abs(avg_obj[0] - avg_obj[1]))\n        cluster_scores.append(tradeoff)\n\n    selected_cluster = np.argmax(cluster_scores)\n    cluster_indices = [i for i, c in enumerate(clusters) if c == selected_cluster]\n\n    # Select best solution in cluster based on dominance and trade-off\n    best_idx = cluster_indices[0]\n    best_obj = archive[best_idx][1]\n    for idx in cluster_indices[1:]:\n        obj = archive[idx][1]\n        # Check if better in both objectives or better trade-off\n        if ((obj[0] <= best_obj[0] and obj[1] <= best_obj[1]) and (obj[0] < best_obj[0] or obj[1] < best_obj[1])) or \\\n           ((obj[0] + obj[1]) / (1 + abs(obj[0] - obj[1])) > (best_obj[0] + best_obj[1]) / (1 + abs(best_obj[0] - best_obj[1]))):\n            best_idx = idx\n            best_obj = obj\n\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(base_solution)\n\n    # Hybrid local search operator\n    if n >= 10:\n        # Multi-objective segment reversal with edge preservation\n        a, b = sorted(random.sample(range(n), 2))\n        segment = base_solution[a:b+1]\n\n        # Calculate potential improvement for both objectives\n        original_cost1 = sum(distance_matrix_1[segment[i], segment[(i+1)%len(segment)]] for i in range(len(segment)))\n        reversed_cost1 = sum(distance_matrix_1[segment[(i+1)%len(segment)], segment[i]] for i in range(len(segment)))\n        original_cost2 = sum(distance_matrix_2[segment[i], segment[(i+1)%len(segment)]] for i in range(len(segment)))\n        reversed_cost2 = sum(distance_matrix_2[segment[(i+1)%len(segment)], segment[i]] for i in range(len(segment)))\n\n        # Weighted improvement considering trade-offs\n        weight1 = 0.5 + 0.5 * (1 - abs(original_cost1 - reversed_cost1) / (original_cost1 + reversed_cost1 + 1e-10))\n        weight2 = 0.5 + 0.5 * (1 - abs(original_cost2 - reversed_cost2) / (original_cost2 + reversed_cost2 + 1e-10))\n\n        if (weight1 * reversed_cost1 + weight2 * reversed_cost2) < (weight1 * original_cost1 + weight2 * original_cost2):\n            new_solution[a:b+1] = new_solution[a:b+1][::-1]\n    else:\n        # Adaptive edge swapping for smaller instances\n        for _ in range(3):\n            i, j = sorted(random.sample(range(n), 2))\n            a, b, c, d = base_solution[i], base_solution[(i+1)%n], base_solution[j], base_solution[(j+1)%n]\n\n            # Calculate improvement potential for both objectives\n            delta1 = (distance_matrix_1[a, c] + distance_matrix_1[b, d]) - (distance_matrix_1[a, b] + distance_matrix_1[c, d])\n            delta2 = (distance_matrix_2[a, c] + distance_matrix_2[b, d]) - (distance_matrix_2[a, b] + distance_matrix_2[c, d])\n\n            # Weighted decision based on trade-offs\n            if (0.6 * delta1 + 0.4 * delta2 < 0) or (0.4 * delta1 + 0.6 * delta2 < 0):\n                new_solution[i+1:j+1] = np.flip(new_solution[i+1:j+1])\n                break\n\n    # Dynamic repair mechanism\n    if len(new_solution) != n or len(np.unique(new_solution)) != n or set(new_solution) != set(base_solution):\n        # Edge preservation based on multi-objective quality\n        edge_quality = {}\n        for i in range(n):\n            a, b = base_solution[i], base_solution[(i+1)%n]\n            cost1 = distance_matrix_1[a, b]\n            cost2 = distance_matrix_2[a, b]\n            quality = (cost1 + cost2) / (1 + np.abs(cost1 - cost2))\n            edge_quality[(min(a, b), max(a, b))] = quality\n\n        # Rebuild solution prioritizing high-quality edges\n        remaining_nodes = set(range(n))\n        new_solution = []\n        current_node = random.choice(list(remaining_nodes))\n        new_solution.append(current_node)\n        remaining_nodes.remove(current_node)\n\n        while remaining_nodes:\n            candidates = []\n            for neighbor in remaining_nodes:\n                edge = (min(current_node, neighbor), max(current_node, neighbor))\n                if edge in edge_quality:\n                    candidates.append((neighbor, edge_quality[edge]))\n                else:\n                    cost1 = distance_matrix_1[current_node, neighbor]\n                    cost2 = distance_matrix_2[current_node, neighbor]\n                    quality = (cost1 + cost2) / (1 + np.abs(cost1 - cost2))\n                    candidates.append((neighbor, quality))\n\n            candidates.sort(key=lambda x: x[1])\n            next_node = candidates[0][0]\n            new_solution.append(next_node)\n            remaining_nodes.remove(next_node)\n            current_node = next_node\n\n        new_solution = np.array(new_solution)\n\n    # Final feasibility check\n    assert len(new_solution) == n\n    assert len(np.unique(new_solution)) == n\n    assert set(new_solution) == set(base_solution)\n\n    return new_solution\n\n",
        "metric_score": [
            -1.0285467593920086,
            2.0839322209358215
        ],
        "raw_score": [
            10.393590681206373,
            10.577353726535412
        ]
    },
    {
        "algorithm": "The algorithm selects the worst solution from the archive (based on the maximum objective value) and applies a hybrid local search combining random segment reversal and 2-opt moves to generate a neighbor solution. It prioritizes exploration of less-explored regions by focusing on the worst-performing solution and ensures feasibility by maintaining valid TSP tours. The approach balances diversity and local improvement while avoiding standard 2-opt-only strategies.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    selected_solution = max(archive, key=lambda x: max(x[1]))[0].copy()\n\n    # Hybrid local search: combine random 2-opt with a novel segment reversal\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    # Randomly select a segment to reverse (novel segment reversal)\n    a, b = sorted(random.sample(range(n), 2))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Apply a random 2-opt move to ensure diversity\n    i, j = sorted(random.sample(range(n), 2))\n    new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.7627709071663467,
            0.20366013050079346
        ],
        "raw_score": [
            9.049800417335923,
            10.417538166894719
        ]
    },
    {
        "algorithm": "The algorithm combines Pareto-front selection with a novel hybrid move that inverts a segment of the tour while intelligently reallocating nodes based on their combined contribution to both objectives, prioritizing balanced improvements through a weighted scoring system while ensuring feasibility through rigorous validation. It selects non-dominated solutions with equal probability and applies segment inversion followed by node reallocation based on a weighted combination of distance improvements in both objective spaces. For small instances, it falls back to a conditional random swap that improves at least one objective.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto selection: choose a non-dominated solution\n    dominated_counts = [0] * len(archive)\n    for i, (sol_i, obj_i) in enumerate(archive):\n        for j, (sol_j, obj_j) in enumerate(archive):\n            if i != j and (obj_j[0] <= obj_i[0] and obj_j[1] <= obj_i[1]) and (obj_j[0] < obj_i[0] or obj_j[1] < obj_i[1]):\n                dominated_counts[i] += 1\n\n    non_dominated_indices = [i for i, count in enumerate(dominated_counts) if count == 0]\n    if not non_dominated_indices:\n        non_dominated_indices = range(len(archive))\n\n    selected_index = random.choice(non_dominated_indices)\n    base_solution = archive[selected_index][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n\n    # Hybrid segment inversion and node reallocation\n    if n >= 4:\n        # Select a segment to invert\n        segment_size = random.randint(2, min(5, n - 2))\n        start_pos = random.randint(0, n - segment_size)\n        end_pos = start_pos + segment_size\n\n        # Invert the segment\n        new_solution[start_pos:end_pos] = np.flip(new_solution[start_pos:end_pos])\n\n        # Reallocate nodes based on their contribution to both objectives\n        for i in range(start_pos, end_pos):\n            node = new_solution[i]\n            # Calculate insertion scores for each possible position\n            insertion_scores = []\n            for j in range(n):\n                if j >= start_pos and j < end_pos:\n                    continue  # Skip current segment\n                prev_node = new_solution[j - 1]\n                next_node = new_solution[j % n]\n                # Weighted score for both objectives\n                score = (distance_matrix_1[prev_node, node] + distance_matrix_1[node, next_node]) * 0.5 + \\\n                        (distance_matrix_2[prev_node, node] + distance_matrix_2[node, next_node]) * 0.5\n                insertion_scores.append(score)\n\n            # Find best insertion position outside the current segment\n            best_pos = np.argmin(insertion_scores)\n            if best_pos >= start_pos:\n                best_pos += segment_size  # Adjust for removed segment\n\n            # Remove node and insert at best position\n            node = new_solution[i]\n            new_solution = np.delete(new_solution, i)\n            new_solution = np.insert(new_solution, best_pos, node)\n    else:\n        # For small instances, perform a random swap if it improves at least one objective\n        i, j = random.sample(range(n), 2)\n        a, b = base_solution[i], base_solution[j]\n        delta1 = (distance_matrix_1[a, base_solution[i-1]] + distance_matrix_1[a, base_solution[(i+1)%n]] +\n                  distance_matrix_1[b, base_solution[j-1]] + distance_matrix_1[b, base_solution[(j+1)%n]]) - \\\n                 (distance_matrix_1[b, base_solution[i-1]] + distance_matrix_1[b, base_solution[(i+1)%n]] +\n                  distance_matrix_1[a, base_solution[j-1]] + distance_matrix_1[a, base_solution[(j+1)%n]])\n\n        delta2 = (distance_matrix_2[a, base_solution[i-1]] + distance_matrix_2[a, base_solution[(i+1)%n]] +\n                  distance_matrix_2[b, base_solution[j-1]] + distance_matrix_2[b, base_solution[(j+1)%n]]) - \\\n                 (distance_matrix_2[b, base_solution[i-1]] + distance_matrix_2[b, base_solution[(j+1)%n]] +\n                  distance_matrix_2[a, base_solution[j-1]] + distance_matrix_2[a, base_solution[(j+1)%n]])\n\n        if delta1 < 0 or delta2 < 0:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure feasibility\n    assert len(new_solution) == n\n    assert len(np.unique(new_solution)) == n\n    assert set(new_solution) == set(base_solution)\n\n    return new_solution\n\n",
        "metric_score": [
            -1.0118871919742838,
            3.170640230178833
        ],
        "raw_score": [
            6.400236137840049,
            5.927239624244716
        ]
    },
    {
        "algorithm": "The algorithm selects a Pareto-optimal solution from the archive with probability inversely proportional to its dominance rank, then applies a hybrid local search combining edge exchange and adaptive node reinsertion to generate a neighbor solution, prioritizing improvements in both objective spaces while ensuring feasibility through constraint-aware validation. The method intelligently balances exploration and exploitation by considering both objectives during insertion and edge exchanges, with special handling for small instances.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate dominance ranks for each solution\n    dominance_ranks = []\n    for i, (sol_i, obj_i) in enumerate(archive):\n        rank = 0\n        for j, (sol_j, obj_j) in enumerate(archive):\n            if i != j and (obj_j[0] <= obj_i[0] and obj_j[1] <= obj_i[1]) and (obj_j[0] < obj_i[0] or obj_j[1] < obj_i[1]):\n                rank += 1\n        dominance_ranks.append(rank)\n\n    # Select a solution with probability inversely proportional to its dominance rank\n    max_rank = max(dominance_ranks)\n    selection_probs = [(max_rank - rank + 1) / sum(max_rank - r + 1 for r in dominance_ranks) for rank in dominance_ranks]\n    selected_index = np.random.choice(len(archive), p=selection_probs)\n    base_solution = archive[selected_index][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n\n    # Hybrid local search: edge exchange with adaptive node reinsertion\n    if n >= 6:\n        # Select two random segments and exchange edges\n        i, j = sorted(random.sample(range(1, n-1), 2))\n        a, b = base_solution[i], base_solution[j]\n\n        # Calculate potential improvement\n        delta1 = (distance_matrix_1[base_solution[i-1], b] + distance_matrix_1[b, base_solution[(i+1)%n]] +\n                  distance_matrix_1[base_solution[j-1], a] + distance_matrix_1[a, base_solution[(j+1)%n]]) - \\\n                 (distance_matrix_1[base_solution[i-1], a] + distance_matrix_1[a, base_solution[(i+1)%n]] +\n                  distance_matrix_1[base_solution[j-1], b] + distance_matrix_1[b, base_solution[(j+1)%n]])\n        delta2 = (distance_matrix_2[base_solution[i-1], b] + distance_matrix_2[b, base_solution[(i+1)%n]] +\n                  distance_matrix_2[base_solution[j-1], a] + distance_matrix_2[a, base_solution[(j+1)%n]]) - \\\n                 (distance_matrix_2[base_solution[i-1], a] + distance_matrix_2[a, base_solution[(i+1)%n]] +\n                  distance_matrix_2[base_solution[j-1], b] + distance_matrix_2[b, base_solution[(j+1)%n]])\n\n        if delta1 < 0 or delta2 < 0:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        else:\n            # Adaptive node reinsertion\n            k = random.randint(0, n-1)\n            node = new_solution[k]\n            new_solution = np.delete(new_solution, k)\n\n            # Calculate insertion positions based on both objectives\n            insertion_scores = []\n            for pos in range(n-1):\n                cost1 = distance_matrix_1[new_solution[pos], node] + distance_matrix_1[node, new_solution[(pos+1)%(n-1)]] - distance_matrix_1[new_solution[pos], new_solution[(pos+1)%(n-1)]]\n                cost2 = distance_matrix_2[new_solution[pos], node] + distance_matrix_2[node, new_solution[(pos+1)%(n-1)]] - distance_matrix_2[new_solution[pos], new_solution[(pos+1)%(n-1)]]\n                insertion_scores.append(abs(cost1) + abs(cost2))\n\n            best_pos = np.argmin(insertion_scores)\n            new_solution = np.insert(new_solution, best_pos, node)\n    else:\n        # For small instances, perform a simple swap\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Feasibility check\n    assert len(new_solution) == n\n    assert len(np.unique(new_solution)) == n\n    assert set(new_solution) == set(base_solution)\n\n    return new_solution\n\n",
        "metric_score": [
            -0.996514866588731,
            0.6320064663887024
        ],
        "raw_score": [
            6.997478247045124,
            6.245322255899307
        ]
    },
    {
        "algorithm": "The algorithm selects a Pareto-dominated solution from the archive and applies a hybrid local search combining multi-segment reversal with adaptive edge swapping, prioritizing segments and edges with high diversity in both objective spaces while ensuring feasibility through a dynamic repair mechanism that rebuilds solutions based on edge quality. The method emphasizes multi-objective trade-offs by weighting improvements in each objective space (60%/40% and 40%/60%) and selectively applies local search operators (segment reversal, node insertion, or node swap) based on instance size.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a Pareto-dominated solution\n    dominated_counts = [0] * len(archive)\n    for i, (sol_i, obj_i) in enumerate(archive):\n        for j, (sol_j, obj_j) in enumerate(archive):\n            if i != j and (obj_j[0] <= obj_i[0] and obj_j[1] <= obj_i[1]) and (obj_j[0] < obj_i[0] or obj_j[1] < obj_i[1]):\n                dominated_counts[i] += 1\n\n    non_dominated_indices = [i for i, count in enumerate(dominated_counts) if count == 0]\n    if not non_dominated_indices:\n        non_dominated_indices = range(len(archive))\n\n    selected_index = random.choice(non_dominated_indices)\n    base_solution = archive[selected_index][0].copy()\n    new_solution = base_solution.copy()\n    n = len(base_solution)\n\n    # Hybrid local search: multi-segment reversal with adaptive edge swapping\n    if n >= 8:\n        # Multi-segment reversal\n        num_segments = min(3, n // 4)\n        segment_lengths = [random.randint(2, n // num_segments) for _ in range(num_segments)]\n        total_length = sum(segment_lengths)\n\n        while total_length > n:\n            segment_lengths = [max(2, l - 1) for l in segment_lengths]\n            total_length = sum(segment_lengths)\n\n        # Select segments with high edge diversity\n        segment_scores = []\n        for i in range(num_segments):\n            start = random.randint(0, n - segment_lengths[i])\n            end = start + segment_lengths[i]\n            score = 0\n            for j in range(start, end - 1):\n                a, b = base_solution[j], base_solution[j+1]\n                score += distance_matrix_1[a, b] + distance_matrix_2[a, b]\n            segment_scores.append((start, end, score))\n\n        # Sort segments by score (descending) to prioritize high diversity\n        segment_scores.sort(key=lambda x: -x[2])\n\n        # Reverse the selected segments\n        for start, end, _ in segment_scores:\n            new_solution[start:end] = np.flip(new_solution[start:end])\n\n        # Adaptive edge swapping\n        for _ in range(2):\n            i, j = sorted(random.sample(range(n), 2))\n            a, b, c, d = base_solution[i], base_solution[(i+1)%n], base_solution[j], base_solution[(j+1)%n]\n\n            # Calculate improvement potential for both objectives\n            delta1 = (distance_matrix_1[a, c] + distance_matrix_1[b, d]) - (distance_matrix_1[a, b] + distance_matrix_1[c, d])\n            delta2 = (distance_matrix_2[a, c] + distance_matrix_2[b, d]) - (distance_matrix_2[a, b] + distance_matrix_2[c, d])\n\n            # Weighted decision based on trade-offs\n            if (0.6 * delta1 + 0.4 * delta2 < 0) or (0.4 * delta1 + 0.6 * delta2 < 0):\n                new_solution[i+1:j+1] = np.flip(new_solution[i+1:j+1])\n                break\n    else:\n        # For smaller instances, use a combination of node insertion and swap\n        if n >= 5:\n            # Node insertion with objective-aware selection\n            k = random.randint(0, n-1)\n            node = new_solution[k]\n            new_solution = np.delete(new_solution, k)\n\n            # Find best insertion point based on both objectives\n            best_pos = 0\n            min_cost = float('inf')\n\n            for pos in range(n-1):\n                cost1 = distance_matrix_1[new_solution[pos], node] + distance_matrix_1[node, new_solution[(pos+1)%(n-1)]] - distance_matrix_1[new_solution[pos], new_solution[(pos+1)%(n-1)]]\n                cost2 = distance_matrix_2[new_solution[pos], node] + distance_matrix_2[node, new_solution[(pos+1)%(n-1)]] - distance_matrix_2[new_solution[pos], new_solution[(pos+1)%(n-1)]]\n\n                if abs(cost1) + abs(cost2) < min_cost:\n                    min_cost = abs(cost1) + abs(cost2)\n                    best_pos = pos\n\n            new_solution = np.insert(new_solution, best_pos, node)\n        else:\n            # Node swap with objective-aware selection\n            i, j = random.sample(range(n), 2)\n            delta1 = (distance_matrix_1[base_solution[i-1], base_solution[j]] + distance_matrix_1[base_solution[j], base_solution[(i+1)%n]] +\n                      distance_matrix_1[base_solution[j-1], base_solution[i]] + distance_matrix_1[base_solution[i], base_solution[(j+1)%n]]) - \\\n                     (distance_matrix_1[base_solution[i-1], base_solution[i]] + distance_matrix_1[base_solution[i], base_solution[(i+1)%n]] +\n                      distance_matrix_1[base_solution[j-1], base_solution[j]] + distance_matrix_1[base_solution[j], base_solution[(j+1)%n]])\n            delta2 = (distance_matrix_2[base_solution[i-1], base_solution[j]] + distance_matrix_2[base_solution[j], base_solution[(i+1)%n]] +\n                      distance_matrix_2[base_solution[j-1], base_solution[i]] + distance_matrix_2[base_solution[i], base_solution[(j+1)%n]]) - \\\n                     (distance_matrix_2[base_solution[i-1], base_solution[i]] + distance_matrix_2[base_solution[i], base_solution[(i+1)%n]] +\n                      distance_matrix_2[base_solution[j-1], base_solution[j]] + distance_matrix_2[base_solution[j], base_solution[(j+1)%n]])\n\n            if delta1 < 0 or delta2 < 0:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Dynamic repair mechanism\n    if len(new_solution) != n or len(np.unique(new_solution)) != n or set(new_solution) != set(base_solution):\n        # Edge preservation based on multi-objective quality\n        edge_quality = {}\n        for i in range(n):\n            a, b = base_solution[i], base_solution[(i+1)%n]\n            cost1 = distance_matrix_1[a, b]\n            cost2 = distance_matrix_2[a, b]\n            quality = (cost1 + cost2) / (1 + np.abs(cost1 - cost2))\n            edge_quality[(min(a, b), max(a, b))] = quality\n\n        # Rebuild solution prioritizing high-quality edges\n        remaining_nodes = set(range(n))\n        new_solution = []\n        current_node = random.choice(list(remaining_nodes))\n        new_solution.append(current_node)\n        remaining_nodes.remove(current_node)\n\n        while remaining_nodes:\n            candidates = []\n            for neighbor in remaining_nodes:\n                edge = (min(current_node, neighbor), max(current_node, neighbor))\n                if edge in edge_quality:\n                    candidates.append((neighbor, edge_quality[edge]))\n                else:\n                    cost1 = distance_matrix_1[current_node, neighbor]\n                    cost2 = distance_matrix_2[current_node, neighbor]\n                    quality = (cost1 + cost2) / (1 + np.abs(cost1 - cost2))\n                    candidates.append((neighbor, quality))\n\n            candidates.sort(key=lambda x: x[1])\n            next_node = candidates[0][0]\n            new_solution.append(next_node)\n            remaining_nodes.remove(next_node)\n            current_node = next_node\n\n        new_solution = np.array(new_solution)\n\n    # Final feasibility check\n    assert len(new_solution) == n\n    assert len(np.unique(new_solution)) == n\n    assert set(new_solution) == set(base_solution)\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9217867124072832,
            0.24362683296203613
        ],
        "raw_score": [
            6.946136011035707,
            7.053710203346592
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive based on a weighted combination of objective values and random diversity, then applies a hybrid local search combining 2.5-opt (a segment reversal) and node insertion to generate a neighbor, ensuring feasibility by validating no duplicates or missing nodes. The selection prioritizes lower objectives with added randomness, while the local search focuses on segment reversal and node repositioning for potential multi-objective improvement.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high diversity and potential for improvement\n    def selection_score(solution, objective):\n        # Prefer solutions with lower objectives but also consider diversity\n        return (objective[0] + objective[1]) * (1 + np.random.uniform(0.5, 1.5))\n\n    scored_solutions = [(solution, objective, selection_score(solution, objective))\n                       for solution, objective in archive]\n    scored_solutions.sort(key=lambda x: x[2])\n    selected_solution = scored_solutions[0][0].copy()\n\n    # Hybrid local search: 2.5-opt + node insertion\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    # Apply 2.5-opt (generalized 2-opt)\n    i, j = np.random.choice(n, 2, replace=False)\n    if i > j:\n        i, j = j, i\n    # Reverse the segment between i and j\n    new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Apply node insertion (move a random node to a new position)\n    k = np.random.randint(0, n)\n    node = new_solution[k]\n    new_solution = np.delete(new_solution, k)\n    new_pos = np.random.randint(0, n-1)\n    new_solution = np.insert(new_solution, new_pos, node)\n\n    # Ensure solution remains feasible (no duplicates and all nodes visited)\n    assert len(new_solution) == n\n    assert len(np.unique(new_solution)) == n\n    assert set(new_solution) == set(selected_solution)\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9672586246322147,
            0.250504732131958
        ],
        "raw_score": [
            6.691336365610633,
            6.575647727482992
        ]
    }
]