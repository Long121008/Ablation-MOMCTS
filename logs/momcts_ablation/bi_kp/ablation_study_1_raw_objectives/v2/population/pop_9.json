[
    {
        "algorithm": "The heuristic selects a near-capacity solution from the archive, then applies a hybrid local search combining item swapping and random flipping, with targeted replacement for feasibility, prioritizing solutions with high potential for multi-objective improvement while ensuring all generated neighbors remain feasible. It intelligently handles infeasibility by undoing operations and adding/removing the most valuable items, with a focus on balancing both objectives through weighted value considerations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to first solution if no candidates\n\n    # Select a solution with high potential (e.g., near-capacity but not fully packed)\n    selected_sol = max(candidates, key=lambda x: np.sum(weight_lst * x))\n    new_solution = selected_sol.copy()\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Randomly swap two items\n    idx1, idx2 = np.random.choice(n_items, size=2, replace=False)\n    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Ensure feasibility after swap\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If swap violates capacity, undo it and try another approach\n        new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n        # Step 2: Randomly flip one item\n        flip_idx = np.random.choice(n_items)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Ensure feasibility after flip\n        total_weight = np.sum(weight_lst * new_solution)\n        if total_weight > capacity:\n            # If flip violates capacity, remove the most expensive item\n            if new_solution[flip_idx] == 1:\n                new_solution[flip_idx] = 0\n            else:\n                # Find the most expensive item to add\n                available_items = np.where(new_solution == 0)[0]\n                if len(available_items) > 0:\n                    expensive_item = available_items[np.argmax(value1_lst[available_items] + value2_lst[available_items])]\n                    if np.sum(weight_lst * new_solution) + weight_lst[expensive_item] <= capacity:\n                        new_solution[expensive_item] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9035397066548494,
            0.47091394662857056
        ],
        "raw_score": [
            27.34055461589349,
            28.03176024888062
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives using a novelty-aware selection\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive objective weighting with novelty factor\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / total_value1) * (1 - (current_value1 / total_value1)) if total_value1 > 0 else 0.5\n    weight2 = (current_value2 / total_value2) * (1 - (current_value2 / total_value2)) if total_value2 > 0 else 0.5\n\n    # Novelty-driven item selection: prioritize items that create \"novel\" value combinations\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate novelty scores based on value ratios and current solution's coverage\n        novelty_scores = []\n        for item in potential_items:\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            novelty = abs(ratio1 - ratio2) * (1 - min(ratio1, ratio2))\n            novelty_scores.append(novelty)\n\n        # Select top items with highest novelty and feasible addition\n        novelty_scores = np.array(novelty_scores)\n        top_items = potential_items[np.argsort(novelty_scores)[-3:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Context-aware swapping: swap items that create better value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select items with worst trade-offs for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:2]]\n        if len(worst_items) == 2:\n            idx1, idx2 = worst_items\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Dynamic exploration: probabilistic flip with novelty-based probability\n    flip_prob = 0.2 + 0.6 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with high novelty for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            novelty_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                novelty_scores.append(abs(ratio1 - ratio2))\n\n            flip_idx = flip_candidates[np.argmax(novelty_scores)]\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9117416583656477,
            0.6331888437271118
        ],
        "raw_score": [
            27.47455128805673,
            28.37877368886923
        ]
    },
    {
        "algorithm": "The algorithm selects a balanced solution from the archive (prioritizing those with high combined objective product) and applies a hybrid local search combining weighted item addition, adaptive swapping, and probabilistic flipping, while dynamically adjusting weights based on solution quality and ensuring feasibility through capacity checks. It emphasizes objective-aware selection (using weighted value metrics) and diversity maintenance (through probabilistic flips), creating a balance between exploration and exploitation. The key design focuses on adaptive weights, combined value metrics, and solution quality-aware operations to improve multi-objective performance.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] * x[1][1]))  # Sort by product of objectives\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate dynamic weights based on current solution quality\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: weighted item addition\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate combined value metric with adaptive weights\n        combined_values = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / weight_lst[potential_items]\n        top_items = potential_items[np.argsort(combined_values)[-2:]]  # Select top 2 items\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping based on objective contributions\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate relative importance of items\n        importance = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        sorted_items = in_solution[np.argsort(importance)]\n\n        # Swap least important with most promising excluded items\n        if len(sorted_items) >= 2:\n            least_important = sorted_items[0]\n            most_promising = np.argmax(combined_values) if len(potential_items) > 0 else -1\n\n            if most_promising != -1 and most_promising in potential_items:\n                temp_weight = current_weight - weight_lst[least_important] + weight_lst[most_promising]\n                if temp_weight <= capacity:\n                    new_solution[least_important] = 0\n                    new_solution[most_promising] = 1\n\n    # Probabilistic flip based on solution quality and diversity\n    flip_prob = 0.4 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.6 else 0.8\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8522696808180721,
            0.22630241513252258
        ],
        "raw_score": [
            27.121475374476667,
            27.863057367568054
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using a hybrid of dominance ranking and crowding distance, then applies a novel local search operator that combines adaptive item selection with probabilistic swaps and dynamic mutation to generate neighbors while ensuring feasibility. It prioritizes items with high combined efficiency scores (normalized by both objective values and weight) and uses probabilistic selection based on relative utility for swaps and mutations. The mutation rate adapts dynamically based on the solution's overall quality, balancing exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine dominance ranking with crowding distance\n    archive.sort(key=lambda x: (x[1][0] + x[1][1], -np.linalg.norm(np.array(x[1]) - np.array([np.mean([v[0] for v in archive]), np.mean([v[1] for v in archive])]))))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current metrics\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate normalized objective weights\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    norm_value1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    norm_value2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Adaptive item selection: consider both value and weight efficiency\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate combined efficiency score\n        efficiency_scores = (norm_value1 * value1_lst[potential_items] + norm_value2 * value2_lst[potential_items]) / (weight_lst[potential_items] + 1e-6)\n        top_items = potential_items[np.argsort(efficiency_scores)[-2:]]\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Probabilistic swap with adaptive temperature\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate swap probabilities based on relative utility\n        swap_utils = norm_value1 * value1_lst[in_solution] + norm_value2 * value2_lst[in_solution]\n        swap_probs = np.exp(swap_utils / (np.sum(swap_utils) + 1e-6))\n        swap_probs = swap_probs / np.sum(swap_probs)\n\n        # Select two items to swap\n        idx1, idx2 = np.random.choice(in_solution, size=2, p=swap_probs, replace=False)\n        temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n        if temp_weight <= capacity:\n            new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Dynamic mutation rate based on solution quality\n    mutation_rate = 0.4 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.6 else 0.8\n    if np.random.random() < mutation_rate and len(new_solution) > 0:\n        # Select mutation candidates based on both value and weight\n        mutation_scores = (norm_value1 * value1_lst + norm_value2 * value2_lst) / (weight_lst + 1e-6)\n        mutation_probs = np.exp(mutation_scores / (np.sum(mutation_scores) + 1e-6))\n        mutation_probs = mutation_probs / np.sum(mutation_probs)\n\n        mutation_idx = np.random.choice(len(new_solution), p=mutation_probs)\n        if new_solution[mutation_idx] == 1:\n            if current_weight - weight_lst[mutation_idx] <= capacity:\n                new_solution[mutation_idx] = 0\n        else:\n            if current_weight + weight_lst[mutation_idx] <= capacity:\n                new_solution[mutation_idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8533480310861542,
            1.2029791176319122
        ],
        "raw_score": [
            27.01697369534874,
            27.770754145074644
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 2, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Identify promising items to consider\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate weighted values for potential items\n        weighted_values = weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]\n        # Select top 3 items with highest weighted value\n        top_items = potential_items[np.argsort(weighted_values)[-3:]]\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Perform targeted swapping with items in solution\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Select two items to swap based on their contribution to both objectives\n        swap_candidates = sorted(in_solution, key=lambda x: -(weight1 * value1_lst[x] + weight2 * value2_lst[x]))[:2]\n        if len(swap_candidates) == 2:\n            idx1, idx2 = swap_candidates\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Perform random flip with probability based on current solution quality\n    flip_prob = 0.3 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.7 else 0.7\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8179565713407433,
            0.27593129873275757
        ],
        "raw_score": [
            27.604553890686965,
            28.184297658157398
        ]
    },
    {
        "algorithm": "The heuristic selects a balanced solution from the archive, then applies a hybrid local search combining targeted swaps (prioritizing high-value items), probabilistic flips, feasibility checks, and greedy additions of valuable items. It dynamically adjusts weights based on current solution quality and ensures feasibility through intelligent item removals and additions. The approach balances exploration and exploitation while maintaining Pareto optimality potential.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 2, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Targeted swapping based on adaptive weights\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        swap_candidates = sorted(in_solution, key=lambda x: -(weight1 * value1_lst[x] + weight2 * value2_lst[x]))[:2]\n        if len(swap_candidates) == 2:\n            idx1, idx2 = swap_candidates\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                current_weight = temp_weight\n\n    # Step 2: Random flip with probability based on solution quality\n    flip_prob = 0.3 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.7 else 0.7\n    if np.random.random() < flip_prob and n_items > 0:\n        flip_idx = np.random.choice(n_items)\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n                current_weight -= weight_lst[flip_idx]\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n                current_weight += weight_lst[flip_idx]\n\n    # Step 3: Ensure feasibility by removing the least valuable items if needed\n    while current_weight > capacity and len(in_solution) > 0:\n        remove_idx = in_solution[np.argmin(weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution])]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n        in_solution = np.where(new_solution == 1)[0]\n\n    # Step 4: Add the most valuable available items if there's remaining capacity\n    available_items = np.where(new_solution == 0)[0]\n    while len(available_items) > 0 and current_weight < capacity:\n        add_idx = available_items[np.argmax(weight1 * value1_lst[available_items] + weight2 * value2_lst[available_items])]\n        if current_weight + weight_lst[add_idx] <= capacity:\n            new_solution[add_idx] = 1\n            current_weight += weight_lst[add_idx]\n            available_items = np.where(new_solution == 0)[0]\n        else:\n            break\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8073380266351767,
            0.2613680064678192
        ],
        "raw_score": [
            27.274817832427832,
            28.08075458475086
        ]
    },
    {
        "algorithm": "The algorithm selects the most promising solution from the archive based on a weighted value metric balancing both objectives (60% value1, 40% value2) and capacity utilization, then applies a hybrid local search that first adds high-value-density items and occasionally removes low-value-density items to create a feasible neighbor solution. It prioritizes items with higher combined value-to-weight ratios while ensuring feasibility through targeted removals when necessary.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate weighted value metric for each solution\n    def weighted_value(sol):\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            return -np.inf\n        value1 = np.sum(value1_lst * sol)\n        value2 = np.sum(value2_lst * sol)\n        # Weighted value metric combining both objectives and capacity utilization\n        return (0.6 * value1 + 0.4 * value2) * (1 - (total_weight / capacity))\n\n    # Select solution with highest weighted value\n    selected_sol, _ = max(archive, key=lambda x: weighted_value(x[0]))\n    new_solution = selected_sol.copy()\n\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Hybrid local search operator\n    # Step 1: Replace low-value items with high-value alternatives\n    total_weight = np.sum(weight_lst * new_solution)\n    available_weight = capacity - total_weight\n\n    # Calculate value density (value per weight) for all items\n    value_density = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(-value_density)  # Highest density first\n\n    # Try to add high-value items that fit\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and weight_lst[idx] <= available_weight:\n            new_solution[idx] = 1\n            available_weight -= weight_lst[idx]\n\n    # Step 2: Randomly perturb by removing items with low value density\n    if np.random.rand() < 0.3:  # 30% chance to perturb\n        low_density_items = np.where(new_solution == 1)[0]\n        if len(low_density_items) > 0:\n            # Remove items with lowest value density\n            low_density_items_sorted = sorted(low_density_items, key=lambda x: value_density[x])\n            for idx in low_density_items_sorted[:max(1, len(low_density_items)//3)]:\n                new_solution[idx] = 0\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items until feasible\n        while total_weight > capacity:\n            # Find the item with lowest value density in the solution\n            in_solution = np.where(new_solution == 1)[0]\n            if len(in_solution) == 0:\n                break\n            remove_idx = in_solution[np.argmin(value_density[in_solution])]\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8243948490542945,
            10.670056641101837
        ],
        "raw_score": [
            28.23516013650488,
            28.37749093126734
        ]
    },
    {
        "algorithm": "The algorithm intelligently selects a non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search operator that combines item swaps, random flips, and feasibility checks to generate diverse high-quality neighbors. It balances exploration (via random swaps and flips) with exploitation (by focusing on high-potential solutions) while ensuring all generated neighbors remain feasible. The selection prioritizes solutions with higher normalized objective sums, and the local search includes targeted item removals/additions, swaps between items, and probabilistic flips to maintain diversity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select the solution with the highest sum of normalized objectives\n    normalized_objectives = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue  # Skip infeasible solutions\n        normalized_obj = (obj[0] / (np.sum(value1_lst) + 1e-8), obj[1] / (np.sum(value2_lst) + 1e-8))\n        normalized_objectives.append((sol, normalized_obj))\n\n    if not normalized_objectives:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by sum of normalized objectives (prioritize solutions with higher potential)\n    normalized_objectives.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = normalized_objectives[0][0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly select an item to flip (basic local search)\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        idx = random.choice(candidates)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        else:\n            # If cannot remove, try adding a new item\n            candidates = np.where(new_solution == 0)[0]\n            for idx in candidates:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    break\n\n    # Apply a random swap between two items (exploration)\n    if np.sum(new_solution) > 1:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap is feasible\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Apply a random flip with probability 0.3 (diversification)\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.6616908732258407,
            0.4831783175468445
        ],
        "raw_score": [
            28.48375171154526,
            28.74721189525877
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (near-capacity but not fully packed)\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to first solution if no candidates\n\n    selected_sol = max(candidates, key=lambda x: np.sum(weight_lst * x))\n    new_solution = selected_sol.copy()\n\n    # Novel local search operator: Weighted Value-Based Greedy Swap\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Calculate weighted values for both objectives (balance exploration and exploitation)\n    alpha = 0.6  # Weight for objective 1\n    beta = 0.4   # Weight for objective 2\n    weighted_values = alpha * value1_lst + beta * value2_lst\n\n    # Find the most valuable item currently in the knapsack\n    in_knapsack = np.where(new_solution == 1)[0]\n    if len(in_knapsack) > 0:\n        most_valuable_in = in_knapsack[np.argmax(weighted_values[in_knapsack])]\n\n        # Find the best candidate to replace it (consider both in and out of knapsack)\n        all_items = np.arange(n_items)\n        exclude_most_valuable = np.delete(all_items, most_valuable_in)\n        candidates = exclude_most_valuable\n\n        # Calculate potential new weights\n        current_weight = np.sum(weight_lst * new_solution)\n        potential_weights = current_weight - weight_lst[most_valuable_in] + weight_lst[candidates]\n\n        # Filter feasible candidates\n        feasible_mask = potential_weights <= capacity\n        feasible_candidates = candidates[feasible_mask]\n\n        if len(feasible_candidates) > 0:\n            # Select the candidate with highest weighted value\n            best_candidate = feasible_candidates[np.argmax(weighted_values[feasible_candidates])]\n\n            # Perform the swap\n            new_solution[most_valuable_in] = 0\n            new_solution[best_candidate] = 1\n\n    # Additional diversification: With probability 0.2, perform a random flip\n    if random.random() < 0.2:\n        flip_idx = random.randint(0, n_items - 1)\n        if new_solution[flip_idx] == 1 and np.sum(weight_lst * new_solution) - weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 0\n        elif new_solution[flip_idx] == 0 and np.sum(weight_lst * new_solution) + weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.6276822021074377,
            0.44365832209587097
        ],
        "raw_score": [
            28.295263699328505,
            29.17602913160117
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high Pareto front potential using adaptive weighting\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Phase 1: Structured item addition based on weighted value\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate weighted values for potential items\n        weighted_values = weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]\n        # Select top 2 items with highest weighted value\n        top_items = potential_items[np.argsort(weighted_values)[-2:]]\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Phase 2: Targeted item replacement based on marginal utility\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        # Calculate marginal utility of each item\n        marginal_utils = []\n        for item in in_solution:\n            temp_sol = new_solution.copy()\n            temp_sol[item] = 0\n            temp_weight = np.sum(weight_lst * temp_sol)\n            if temp_weight <= capacity:\n                # Calculate potential improvement if we remove this item\n                potential_items = np.where(temp_sol == 0)[0]\n                if len(potential_items) > 0:\n                    weighted_values = weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]\n                    best_candidate = potential_items[np.argmax(weighted_values)]\n                    if temp_weight + weight_lst[best_candidate] <= capacity:\n                        marginal_util = (value1_lst[best_candidate] + value2_lst[best_candidate]) - (value1_lst[item] + value2_lst[item])\n                        marginal_utils.append((item, marginal_util))\n                    else:\n                        marginal_utils.append((item, 0))\n                else:\n                    marginal_utils.append((item, 0))\n            else:\n                marginal_utils.append((item, 0))\n\n        # Remove item with highest positive marginal utility\n        if marginal_utils:\n            best_item, best_util = max(marginal_utils, key=lambda x: x[1])\n            if best_util > 0:\n                new_solution[best_item] = 0\n                current_weight = np.sum(weight_lst * new_solution)\n                # Add the best candidate item\n                potential_items = np.where(new_solution == 0)[0]\n                if len(potential_items) > 0:\n                    weighted_values = weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]\n                    best_candidate = potential_items[np.argmax(weighted_values)]\n                    if current_weight + weight_lst[best_candidate] <= capacity:\n                        new_solution[best_candidate] = 1\n\n    # Phase 3: Controlled randomness with quality-based probability\n    flip_prob = 0.2 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.6 else 0.4\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select item based on its marginal utility\n        in_solution = np.where(new_solution == 1)[0]\n        out_solution = np.where(new_solution == 0)[0]\n\n        if len(in_solution) > 0 and len(out_solution) > 0:\n            # Calculate marginal utility for removal\n            remove_utils = []\n            for item in in_solution:\n                temp_sol = new_solution.copy()\n                temp_sol[item] = 0\n                temp_weight = np.sum(weight_lst * temp_sol)\n                if temp_weight <= capacity:\n                    potential_items = np.where(temp_sol == 0)[0]\n                    if len(potential_items) > 0:\n                        weighted_values = weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]\n                        best_candidate = potential_items[np.argmax(weighted_values)]\n                        if temp_weight + weight_lst[best_candidate] <= capacity:\n                            marginal_util = (value1_lst[best_candidate] + value2_lst[best_candidate]) - (value1_lst[item] + value2_lst[item])\n                            remove_utils.append((item, marginal_util))\n                        else:\n                            remove_utils.append((item, 0))\n                    else:\n                        remove_utils.append((item, 0))\n                else:\n                    remove_utils.append((item, 0))\n\n            if remove_utils:\n                # Select item with highest positive marginal utility for removal\n                best_remove, best_util = max(remove_utils, key=lambda x: x[1])\n                if best_util > 0:\n                    new_solution[best_remove] = 0\n                    current_weight = np.sum(weight_lst * new_solution)\n                    # Add the best candidate item\n                    potential_items = np.where(new_solution == 0)[0]\n                    if len(potential_items) > 0:\n                        weighted_values = weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]\n                        best_candidate = potential_items[np.argmax(weighted_values)]\n                        if current_weight + weight_lst[best_candidate] <= capacity:\n                            new_solution[best_candidate] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.6945480478781478,
            5.413287431001663
        ],
        "raw_score": [
            31.545589337522134,
            31.729615934250702
        ]
    }
]