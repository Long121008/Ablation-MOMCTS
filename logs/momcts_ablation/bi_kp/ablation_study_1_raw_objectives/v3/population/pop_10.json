[
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution using a weighted random choice\n    weights = [obj[0] + obj[1] for (sol, obj) in archive]\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Calculate marginal contributions for both objectives\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = marginal1 + marginal2\n\n    # Step 4: Identify candidate items to flip\n    candidate_indices = np.where((base_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) == 0:\n        # If no items can be added, try removing low-value items\n        candidate_indices = np.where(base_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            return base_solution  # No change possible\n\n    # Step 5: Select top-k items based on combined marginal contributions\n    k = max(1, min(5, len(candidate_indices) // 2))\n    top_indices = np.argsort(combined_marginal[candidate_indices])[-k:][::-1]\n\n    # Step 6: Create new solution by flipping selected items\n    new_solution = base_solution.copy()\n    for idx in candidate_indices[top_indices]:\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 7: Dynamic weight adjustment phase\n    while current_weight > capacity:\n        # Identify items to remove based on least combined marginal value\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8379839795366024,
            0.18839186429977417
        ],
        "raw_score": [
            27.127153134971913,
            27.930397004202053
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive with a weighted random choice prioritizing solutions with higher combined objective values (70% weight for value1, 30% for value2), then employs a dynamic flipping strategy that considers both addition and removal of items based on their normalized marginal contributions (60% weight for value1, 40% for value2), while ensuring feasibility through capacity-aware adjustments and occasional random perturbations to escape local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution using a weighted random choice\n    weights = [obj[0] * 0.7 + obj[1] * 0.3 for (sol, obj) in archive]\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Calculate normalized marginal contributions for both objectives\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = 0.6 * marginal1 + 0.4 * marginal2\n\n    # Step 4: Identify candidate items to flip\n    candidate_indices = np.where((base_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) == 0:\n        candidate_indices = np.where(base_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            return base_solution\n\n    # Step 5: Select top items based on combined marginal contributions\n    k = max(1, min(3, len(candidate_indices) // 3))\n    top_indices = np.argsort(combined_marginal[candidate_indices])[-k:][::-1]\n\n    # Step 6: Create new solution by flipping selected items\n    new_solution = base_solution.copy()\n    for idx in candidate_indices[top_indices]:\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 7: Adaptive adjustment phase\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    # Step 8: Random perturbation to escape local optima\n    if random.random() < 0.3:\n        perturb_idx = np.random.choice(np.where(base_solution != new_solution)[0])\n        new_solution[perturb_idx] = 1 - new_solution[perturb_idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9067608502595553,
            0.1949823498725891
        ],
        "raw_score": [
            27.17264943660627,
            27.61900648416579
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using a weighted random choice based on a combined objective score, then applies a hybrid local search strategy combining item swaps, flips, and adaptive perturbations with dynamic perturbation sizes and objective-aware selection to generate a feasible neighbor solution while exploring the solution space effectively. The strategy prioritizes value1 (70% weight) over value2 (30% weight) in selection and uses adaptive mechanisms like dynamic perturbation sizes and feasibility checks to ensure high-quality solutions across multiple objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution using a weighted random choice\n    combined_scores = [obj[0] * 0.7 + obj[1] * 0.3 for (sol, obj) in archive]  # Weighted sum of objectives\n    selected_idx = random.choices(range(len(archive)), weights=combined_scores, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Hybrid local search with novel mechanisms\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Dynamic perturbation size based on solution quality\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    max_perturb_size = min(5, n_items // 5)  # Adaptive based on problem size\n    perturb_size = random.randint(1, max_perturb_size)\n\n    # Objective-aware selection for perturbation\n    if random.random() < 0.6:  # Higher chance for value1-focused perturbation\n        candidate_indices = np.argsort(value1_lst)[-n_items//2:]  # Top 50% value1 items\n    else:\n        candidate_indices = np.argsort(value2_lst)[-n_items//2:]  # Top 50% value2 items\n\n    # Apply hybrid strategy\n    strategy = random.choice([\"swap\", \"flip\", \"perturb\", \"adaptive_flip\"])\n\n    if strategy == \"swap\":\n        # Enhanced swap with objective-aware selection\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Select items with high value ratio\n            value_ratios = (value1_lst + value2_lst) / weight_lst\n            swap_in = random.choice(in_items)\n            swap_out = random.choice(out_items)\n\n            # Check feasibility\n            new_weight = current_weight - weight_lst[swap_in] + weight_lst[swap_out]\n            if new_weight <= capacity:\n                new_solution[swap_in] = 0\n                new_solution[swap_out] = 1\n\n    elif strategy == \"flip\":\n        # Value-based flip with multiple attempts\n        for _ in range(3):  # Try multiple flips\n            flip_idx = random.choice(candidate_indices)\n            if new_solution[flip_idx] == 1:\n                new_weight = current_weight - weight_lst[flip_idx]\n                if new_weight <= capacity:\n                    new_solution[flip_idx] = 0\n                    break\n            else:\n                new_weight = current_weight + weight_lst[flip_idx]\n                if new_weight <= capacity:\n                    new_solution[flip_idx] = 1\n                    break\n\n    elif strategy == \"perturb\":\n        # Dynamic perturbation with multiple attempts\n        perturb_indices = random.sample(list(candidate_indices), min(perturb_size, len(candidate_indices)))\n        for idx in perturb_indices:\n            if new_solution[idx] == 1:\n                new_weight = current_weight - weight_lst[idx]\n                if new_weight <= capacity:\n                    new_solution[idx] = 0\n            else:\n                new_weight = current_weight + weight_lst[idx]\n                if new_weight <= capacity:\n                    new_solution[idx] = 1\n\n    elif strategy == \"adaptive_flip\":\n        # Adaptive flip based on remaining capacity\n        flip_candidates = []\n        for idx in candidate_indices:\n            if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                flip_candidates.append(idx)\n            elif new_solution[idx] == 1 and (current_weight - weight_lst[idx]) <= capacity:\n                flip_candidates.append(idx)\n\n        if flip_candidates:\n            flip_idx = random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.2619377052959229,
            0.27632978558540344
        ],
        "raw_score": [
            49.21545254802683,
            48.10415543548359
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution with high potential for improvement using a combination of randomness and quality metrics\n    quality_scores = [obj[0] * 0.7 + obj[1] * 0.3 for (sol, obj) in archive]  # Bias towards value1\n    selected_idx = random.choices(range(len(archive)), weights=quality_scores, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Calculate current state and remaining capacity\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Calculate normalized marginal contributions for both objectives\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    norm_marginal1 = (marginal1 - np.min(marginal1)) / (np.max(marginal1) - np.min(marginal1) + 1e-6)\n    norm_marginal2 = (marginal2 - np.min(marginal2)) / (np.max(marginal2) - np.min(marginal2) + 1e-6)\n    combined_marginal = 0.6 * norm_marginal1 + 0.4 * norm_marginal2  # Weighted combination\n\n    # Step 4: Identify candidate items for flip with adaptive selection pressure\n    candidate_indices = np.where((base_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) == 0:\n        candidate_indices = np.where(base_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            return base_solution\n\n    # Step 5: Select items based on combined marginal with probabilistic acceptance\n    new_solution = base_solution.copy()\n    for idx in candidate_indices:\n        if new_solution[idx] == 0:\n            if random.random() < combined_marginal[idx] * 0.8:  # Higher probability for better items\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n        else:\n            if random.random() < (1 - combined_marginal[idx]) * 0.3:  # Lower probability to remove worse items\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Step 6: Feasibility enforcement with dynamic weight adjustment\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    # Step 7: Additional diversification with random flips\n    if random.random() < 0.3:  # 30% chance for diversification\n        flip_candidates = np.where((base_solution != new_solution) & (weight_lst <= remaining_capacity))[0]\n        if len(flip_candidates) > 0:\n            flip_idx = random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.746434209281546,
            0.2783259451389313
        ],
        "raw_score": [
            27.30265413212179,
            27.813117844786174
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution with high item density and near-capacity weight\n    selected_solution = max(archive, key=lambda x: sum(x[0]) * (1 - (sum(weight_lst[x[0] == 1]) / capacity)) if sum(weight_lst[x[0] == 1]) <= capacity else -np.inf)[0].copy()\n\n    # Step 2: Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst[selected_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Calculate marginal contributions for both objectives\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = marginal1 + marginal2\n\n    # Step 4: Identify candidate items to flip (both add and remove)\n    candidate_indices = np.where((selected_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) == 0:\n        candidate_indices = np.where(selected_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            return selected_solution\n\n    # Step 5: Dynamic perturbation based on solution quality\n    k = max(1, min(5, len(candidate_indices) // 2))\n    top_indices = np.argsort(combined_marginal[candidate_indices])[-k:][::-1]\n\n    # Step 6: Create new solution by flipping selected items\n    new_solution = selected_solution.copy()\n    for idx in candidate_indices[top_indices]:\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 7: Adaptive feasibility check\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    # Step 8: Optional: Apply a small random flip for exploration\n    if random.random() < 0.2:\n        flip_idx = random.choice(np.where(new_solution == 1)[0])\n        new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8683980147815417,
            1.454035073518753
        ],
        "raw_score": [
            27.39215448558377,
            28.23606300124422
        ]
    },
    {
        "algorithm": "The algorithm selects the most promising solution from the archive based on a weighted combination of its objectives and item density, then applies a dynamic local search that flips items using a trade-off factor between the two objectives while ensuring feasibility through probabilistic weight adjustments. It prioritizes items with high combined marginal value (adjusted by the trade-off factor) and dynamically determines how many items to flip, with a fallback mechanism to remove excess weight if needed.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected = max(archive, key=lambda x: (x[1][0] + x[1][1]) * (sum(x[0]) / (sum(weight_lst[x[0] == 1]) + 1e-6)))[0].copy()\n    new_solution = selected.copy()\n\n    # Calculate dynamic trade-off factor based on current solution's objective balance\n    total_v1 = sum(value1_lst[new_solution == 1])\n    total_v2 = sum(value2_lst[new_solution == 1])\n    tradeoff = 0.5 if total_v1 == 0 or total_v2 == 0 else total_v1 / (total_v1 + total_v2)\n\n    # Calculate weighted marginal contributions\n    marginal_v1 = value1_lst / (weight_lst + 1e-6)\n    marginal_v2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = (tradeoff * marginal_v1) + ((1 - tradeoff) * marginal_v2)\n\n    # Flip items with highest combined marginal value\n    sorted_indices = np.argsort(combined_marginal)[::-1]\n    flip_count = min(3, len(new_solution) // 5)  # Dynamic flip count\n\n    for idx in sorted_indices[:flip_count]:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            current_weight = sum(weight_lst[new_solution == 1])\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Probabilistic weight adjustment for feasibility\n    current_weight = sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        heavy_items = np.where(new_solution == 1)[0]\n        for idx in heavy_items:\n            if excess <= 0:\n                break\n            if np.random.rand() < 0.7 and weight_lst[idx] <= excess:\n                new_solution[idx] = 0\n                excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8466784613051457,
            1.1704210042953491
        ],
        "raw_score": [
            27.25861347233308,
            27.800354429493918
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive (prioritizing those with high item density and near-capacity weight) and applies a hybrid local search by flipping items with the highest marginal contributions (balancing both objectives) while ensuring feasibility through a final weight-checking step. It intelligently flips a subset of items based on their combined value-to-weight ratio, with a fallback to remove heaviest items if needed.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_solution = max(archive, key=lambda x: sum(x[0]) * (1 - (sum(weight_lst[x[0] == 1]) / capacity)) if sum(weight_lst[x[0] == 1]) <= capacity else -np.inf)[0].copy()\n\n    # Apply a hybrid local search operator: flip a subset of items based on their marginal contributions\n    new_solution = selected_solution.copy()\n    marginal_contributions = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(marginal_contributions)[::-1]\n\n    # Flip the top-k items with the highest marginal contributions\n    k = max(1, len(new_solution) // 10)\n    for idx in sorted_indices[:k]:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            if sum(weight_lst[new_solution == 1]) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Ensure feasibility (redundant but safe)\n    total_weight = sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # If infeasible, flip the heaviest items until feasible\n        sorted_heavy = np.argsort(weight_lst[new_solution == 1])[::-1]\n        for idx in sorted_heavy:\n            if total_weight <= capacity:\n                break\n            new_solution[idx] = 0\n            total_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8267687850791628,
            1.6086755692958832
        ],
        "raw_score": [
            27.502875572787605,
            28.1224251595386
        ]
    },
    {
        "algorithm": "The heuristic selects a promising solution from the archive by weighting choices based on combined objective values, then applies a hybrid local search combining swaps, flips, and adaptive perturbations to explore the solution space while ensuring feasibility through strict weight constraint checks. The strategy is randomly chosen among three options, with perturbations adaptively sized for exploration, prioritizing solutions with higher combined objective values while maintaining feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution (prioritize high-value or diverse solutions)\n    selected_idx = random.choices(range(len(archive)), weights=[obj[0] + obj[1] for (sol, obj) in archive], k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Hybrid local search (swaps, flips, and adaptive perturbations)\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Randomly choose one of three local search strategies\n    strategy = random.choice([\"swap\", \"flip\", \"perturb\"])\n\n    if strategy == \"swap\":\n        # Swap two items (one in, one out)\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            swap_in = random.choice(in_items)\n            swap_out = random.choice(out_items)\n\n            # Check feasibility after swap\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            new_weight = current_weight - weight_lst[swap_in] + weight_lst[swap_out]\n\n            if new_weight <= capacity:\n                new_solution[swap_in] = 0\n                new_solution[swap_out] = 1\n\n    elif strategy == \"flip\":\n        # Flip a random item (0 to 1 or 1 to 0)\n        flip_idx = random.randint(0, n_items - 1)\n\n        if new_solution[flip_idx] == 1:\n            # Check feasibility if removing the item\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            new_weight = current_weight - weight_lst[flip_idx]\n\n            if new_weight <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            # Check feasibility if adding the item\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            new_weight = current_weight + weight_lst[flip_idx]\n\n            if new_weight <= capacity:\n                new_solution[flip_idx] = 1\n\n    elif strategy == \"perturb\":\n        # Perturb a subset of items (adaptive based on objective values)\n        perturb_size = max(1, min(5, n_items // 10))  # Adaptive size\n        perturb_indices = random.sample(range(n_items), perturb_size)\n\n        for idx in perturb_indices:\n            if new_solution[idx] == 1:\n                # Check feasibility if removing the item\n                current_weight = np.sum(weight_lst[new_solution == 1])\n                new_weight = current_weight - weight_lst[idx]\n\n                if new_weight <= capacity:\n                    new_solution[idx] = 0\n            else:\n                # Check feasibility if adding the item\n                current_weight = np.sum(weight_lst[new_solution == 1])\n                new_weight = current_weight + weight_lst[idx]\n\n                if new_weight <= capacity:\n                    new_solution[idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.34147716771420633,
            0.3407798707485199
        ],
        "raw_score": [
            49.672216305965385,
            49.76474444776558
        ]
    },
    {
        "algorithm": "The algorithm combines weighted random selection of high-value solutions with a hybrid local search that first performs objective-aware flips (prioritizing items with high combined marginal value) and then ensures feasibility by removing the least valuable items if capacity is exceeded, while occasionally applying a diversity-aware perturbation to explore under-explored regions. It dynamically adjusts perturbation sizes and balances exploration/exploitation through adaptive flip sizes and probabilistic perturbations. The key design priorities are maximizing combined objective value, maintaining feasibility, and promoting diversity through selective flips.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution (prioritize high-value or diverse solutions)\n    selected_idx = random.choices(range(len(archive)), weights=[obj[0] + obj[1] for (sol, obj) in archive], k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Hybrid local search with objective-aware perturbations\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Calculate combined marginal contributions for both objectives\n    combined_marginal = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(combined_marginal)[::-1]\n\n    # Phase 1: Objective-aware flips\n    k = max(1, min(5, n_items // 10))  # Adaptive flip size\n    for idx in sorted_indices[:k]:\n        if new_solution[idx] == 1:\n            # Check feasibility if removing the item\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            new_weight = current_weight - weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 0\n        else:\n            # Check feasibility if adding the item\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            new_weight = current_weight + weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 2: Ensure feasibility by removing least valuable items if needed\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Calculate combined value for items in the solution\n        combined_value = value1_lst + value2_lst\n        in_items = np.where(new_solution == 1)[0]\n        sorted_in_items = in_items[np.argsort(combined_value[in_items])]\n\n        # Remove items until feasible\n        for idx in sorted_in_items:\n            if total_weight <= capacity:\n                break\n            new_solution[idx] = 0\n            total_weight -= weight_lst[idx]\n\n    # Step 3: Diversity-aware perturbation (selectively flip items based on their potential)\n    if random.random() < 0.3:  # 30% chance for perturbation\n        perturb_size = max(1, min(3, n_items // 20))  # Smaller perturbation size\n        # Select items with potential to improve both objectives\n        potential_items = np.where(new_solution == 0)[0]\n        if len(potential_items) > 0:\n            potential_marginal = combined_marginal[potential_items]\n            top_potential = potential_items[np.argsort(potential_marginal)[-perturb_size:]]\n            for idx in top_potential:\n                if np.sum(weight_lst[new_solution == 1]) + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.5136497458757898,
            0.8684941232204437
        ],
        "raw_score": [
            29.769692878818198,
            30.18329336301939
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive prioritizing those with high item diversity (measured by standard deviation) and near-capacity weight (measured by weight utilization), then applies a hybrid local search by flipping items with the highest marginal contributions (product of value1 and value2 per unit weight) while ensuring feasibility through dynamic weight adjustment by removing least valuable items first. The selection criteria emphasize solutions with balanced item diversity and tight capacity utilization, while the local search focuses on high-impact items and maintains feasibility through a greedy removal strategy.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_solution = max(archive, key=lambda x: np.sum(x[0]) * (1 - (np.sum(weight_lst[x[0] == 1]) / capacity)) * np.std(x[0]))[0].copy()\n\n    new_solution = selected_solution.copy()\n    marginal_contributions = (value1_lst * value2_lst) / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(marginal_contributions)[::-1]\n\n    # Flip the top-k items with the highest marginal contributions\n    k = max(1, len(new_solution) // 5)\n    for idx in sorted_indices[:k]:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            if np.sum(weight_lst[new_solution == 1]) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Dynamic weight adjustment: remove least valuable items first\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        included_indices = np.where(new_solution == 1)[0]\n        value_ratios = (value1_lst[included_indices] + value2_lst[included_indices]) / weight_lst[included_indices]\n        sorted_least_val = included_indices[np.argsort(value_ratios)]\n        for idx in sorted_least_val:\n            if total_weight <= capacity:\n                break\n            new_solution[idx] = 0\n            total_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8209043653975697,
            1.4694936871528625
        ],
        "raw_score": [
            27.624562268793362,
            28.101367990253614
        ]
    }
]