[
    {
        "algorithm": "The algorithm selects a promising solution from the archive based on combined potential improvement in both objectives, then applies a hybrid local search: first performing random bit flips to escape local optima, followed by a directed search for items with high combined value-to-weight ratios for both objectives, ensuring feasibility by dynamically tracking remaining capacity. The selection prioritizes solutions with the highest normalized potential improvement, while the neighbor generation balances exploration (random flips) with exploitation (directed selection).",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate potential improvement for each solution\n    potentials = []\n    for sol, obj in archive:\n        current_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - current_weight\n        # Potential items to add (not currently in solution)\n        not_in_sol = np.where(sol == 0)[0]\n        # Potential improvement in objective 1\n        potential_value1 = np.sum(value1_lst[not_in_sol] * (weight_lst[not_in_sol] <= remaining_capacity))\n        # Potential improvement in objective 2\n        potential_value2 = np.sum(value2_lst[not_in_sol] * (weight_lst[not_in_sol] <= remaining_capacity))\n        # Combined potential (normalized to avoid bias)\n        combined_potential = (potential_value1 + potential_value2) / (1 + obj[0] + obj[1])\n        potentials.append(combined_potential)\n\n    # Select solution with highest potential\n    selected_idx = np.argmax(potentials)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Generate neighbor solution\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random flip with directed selection\n    # Step 1: Randomly flip a few bits (to escape local optima)\n    num_flips = min(3, len(new_solution))\n    flip_indices = random.sample(range(len(new_solution)), num_flips)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            # Only add if it doesn't exceed capacity\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    # Step 2: Directed search for items that could improve either objective\n    # Consider items not in current solution\n    not_in_sol = np.where(new_solution == 0)[0]\n    if len(not_in_sol) > 0:\n        # Calculate value-to-weight ratios for both objectives\n        ratio1 = value1_lst[not_in_sol] / weight_lst[not_in_sol]\n        ratio2 = value2_lst[not_in_sol] / weight_lst[not_in_sol]\n\n        # Select items with highest combined ratio that fit in remaining capacity\n        combined_ratios = ratio1 + ratio2\n        sorted_indices = np.argsort(combined_ratios)[::-1]\n\n        for idx in sorted_indices:\n            global_idx = not_in_sol[idx]\n            if weight_lst[global_idx] <= remaining_capacity:\n                new_solution[global_idx] = 1\n                remaining_capacity -= weight_lst[global_idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9079633024147904,
            1.0491748750209808
        ],
        "raw_score": [
            27.36814387336429,
            27.95142773130081
        ]
    },
    {
        "algorithm": "The algorithm combines a weighted selection strategy (prioritizing solutions with high potential improvement based on normalized value and remaining capacity scores) with a hybrid local search that first probabilistically perturbs items based on their combined value-to-weight ratios and then greedily refines the solution by iteratively adding the most promising items until no further feasible improvements can be made. The selection emphasizes both objectives and capacity awareness, while the local search balances exploration (via probabilistic flips) with exploitation (via directed capacity-aware additions).",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate potential improvement scores\n    total_weights = np.array([np.sum(weight_lst[s[0] == 1]) for s in archive])\n    total_value1 = np.array([s[1][0] for s in archive])\n    total_value2 = np.array([s[1][1] for s in archive])\n\n    # Normalize scores\n    weight_scores = (capacity - total_weights) / capacity\n    value1_scores = (total_value1 - np.min(total_value1)) / (np.max(total_value1) - np.min(total_value1) + 1e-8)\n    value2_scores = (total_value2 - np.min(total_value2)) / (np.max(total_value2) - np.min(total_value2) + 1e-8)\n\n    # Combined selection score\n    scores = weight_scores * 0.4 + value1_scores * 0.3 + value2_scores * 0.3\n    selected_idx = np.random.choice(len(archive), p=scores/scores.sum())\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate remaining capacity\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Value-aware perturbation phase\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Probability to remove based on value density\n            if random.random() < 0.2 * (value1_lst[i] + value2_lst[i]) / (weight_lst[i] + 1e-8):\n                new_solution[i] = 0\n                remaining_capacity += weight_lst[i]\n        else:\n            # Probability to add based on value density\n            if (remaining_capacity >= weight_lst[i]) and \\\n               (random.random() < 0.2 * (value1_lst[i] + value2_lst[i]) / (weight_lst[i] + 1e-8)):\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n\n    # Capacity-aware refinement phase\n    added_items = []\n    while True:\n        # Calculate value-to-weight ratios for items not in solution\n        not_in_sol = np.where(new_solution == 0)[0]\n        if len(not_in_sol) == 0:\n            break\n\n        # Filter items that fit in remaining capacity\n        feasible_items = not_in_sol[weight_lst[not_in_sol] <= remaining_capacity]\n        if len(feasible_items) == 0:\n            break\n\n        # Select item with highest combined value-to-weight ratio\n        combined_ratios = (value1_lst[feasible_items] + value2_lst[feasible_items]) / weight_lst[feasible_items]\n        best_item = feasible_items[np.argmax(combined_ratios)]\n\n        # Add the best item\n        new_solution[best_item] = 1\n        remaining_capacity -= weight_lst[best_item]\n        added_items.append(best_item)\n\n        # Check if adding more items is beneficial\n        if len(added_items) > 3:  # Limit to prevent excessive computation\n            break\n\n    return new_solution\n\n",
        "metric_score": [
            -0.3888242975453579,
            0.6292133629322052
        ],
        "raw_score": [
            36.7724156200035,
            37.5580101790531
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive by balancing potential objective improvements and diversity, then generates a neighbor through a hybrid local search combining probabilistic bit flips and value-to-weight ratio-based directed additions, ensuring feasibility by dynamically tracking remaining capacity. It prioritizes solutions with higher combined potential scores (70% improvement, 30% diversity) and refines the solution with adaptive flips and capacity-aware high-ratio item additions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate potential improvement and diversity for each solution\n    potentials = []\n    for sol, obj in archive:\n        current_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - current_weight\n        not_in_sol = np.where(sol == 0)[0]\n\n        # Calculate potential improvements\n        potential_value1 = np.sum(value1_lst[not_in_sol] * (weight_lst[not_in_sol] <= remaining_capacity))\n        potential_value2 = np.sum(value2_lst[not_in_sol] * (weight_lst[not_in_sol] <= remaining_capacity))\n\n        # Calculate diversity (number of unique items not in solution)\n        diversity = len(not_in_sol)\n\n        # Combined score with adaptive weighting\n        alpha = 0.7  # Weight for improvement\n        beta = 0.3   # Weight for diversity\n        combined_score = (alpha * (potential_value1 + potential_value2) + beta * diversity) / (1 + obj[0] + obj[1])\n        potentials.append(combined_score)\n\n    # Select solution with highest potential\n    selected_idx = np.argmax(potentials)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Generate neighbor solution\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: probabilistic flip with adaptive intensity\n    flip_prob = 0.3  # Base flip probability\n    for i in range(len(new_solution)):\n        if random.random() < flip_prob:\n            if new_solution[i] == 1:\n                new_solution[i] = 0\n            else:\n                if weight_lst[i] <= remaining_capacity:\n                    new_solution[i] = 1\n                    remaining_capacity -= weight_lst[i]\n\n    # Directed search for items with high combined value-to-weight ratio\n    not_in_sol = np.where(new_solution == 0)[0]\n    if len(not_in_sol) > 0:\n        # Calculate normalized value-to-weight ratios\n        ratio1 = value1_lst[not_in_sol] / (weight_lst[not_in_sol] + 1e-6)\n        ratio2 = value2_lst[not_in_sol] / (weight_lst[not_in_sol] + 1e-6)\n        combined_ratios = ratio1 + ratio2\n\n        # Select top candidates and filter by capacity\n        candidate_indices = np.argsort(combined_ratios)[-min(5, len(not_in_sol)):][::-1]\n        for idx in candidate_indices:\n            global_idx = not_in_sol[idx]\n            if weight_lst[global_idx] <= remaining_capacity:\n                new_solution[global_idx] = 1\n                remaining_capacity -= weight_lst[global_idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8240901047809942,
            1.0695575177669525
        ],
        "raw_score": [
            27.25824576339125,
            27.480145508309896
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate dominance-based scores and potential improvement\n    dominance_scores = []\n    for sol, obj in archive:\n        current_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - current_weight\n        not_in_sol = np.where(sol == 0)[0]\n        potential_value1 = np.sum(value1_lst[not_in_sol] * (weight_lst[not_in_sol] <= remaining_capacity))\n        potential_value2 = np.sum(value2_lst[not_in_sol] * (weight_lst[not_in_sol] <= remaining_capacity))\n        combined_potential = (potential_value1 + potential_value2) / (1 + obj[0] + obj[1])\n\n        # Calculate dominance score (number of solutions this one dominates)\n        dominates = 0\n        for _, other_obj in archive:\n            if (obj[0] >= other_obj[0] and obj[1] > other_obj[1]) or (obj[0] > other_obj[0] and obj[1] >= other_obj[1]):\n                dominates += 1\n\n        dominance_scores.append(dominates * combined_potential)\n\n    # Select solution with highest combined score\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: value-density clustering with dynamic capacity management\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Step 1: Cluster items by value-to-weight ratio and select representative items\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0:\n        # Calculate value-to-weight ratios for included items\n        included_ratios = (value1_lst[included] + value2_lst[included]) / weight_lst[included]\n        # Find items with highest ratios to potentially remove\n        remove_candidates = included[np.argsort(included_ratios)][:max(1, len(included)//3)]\n\n        for item in remove_candidates:\n            if random.random() < 0.3:  # 30% chance to remove\n                new_solution[item] = 0\n                remaining_capacity += weight_lst[item]\n\n    # Step 2: Add items with high value-to-weight ratios from excluded items\n    if len(excluded) > 0 and remaining_capacity > 0:\n        excluded_ratios = (value1_lst[excluded] + value2_lst[excluded]) / weight_lst[excluded]\n        sorted_indices = np.argsort(excluded_ratios)[::-1]\n\n        for idx in sorted_indices:\n            global_idx = excluded[idx]\n            if weight_lst[global_idx] <= remaining_capacity:\n                new_solution[global_idx] = 1\n                remaining_capacity -= weight_lst[global_idx]\n\n    # Step 3: Randomly adjust a few items for diversity\n    num_adjustments = min(2, len(new_solution))\n    adjust_indices = random.sample(range(len(new_solution)), num_adjustments)\n    for idx in adjust_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.3532309495545469,
            0.8453739583492279
        ],
        "raw_score": [
            54.60717630449767,
            53.96161022416238
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive by balancing diversity and potential improvement, then applies a hybrid local search that combines probabilistic bit flips (with higher probability for items with lower value-to-weight ratios) and a greedy selection of items with the highest normalized combined value-to-weight ratios, ensuring feasibility through dynamic capacity tracking. The selection prioritizes solutions with higher diversity and potential improvement, while the local search strategically explores the solution space by probabilistically flipping bits and greedily adding high-value items.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate diversity and potential improvement for each solution\n    diversity_scores = []\n    potential_scores = []\n    for sol, obj in archive:\n        # Diversity: count of items not in other solutions\n        diversity = sum(1 for s, _ in archive if not np.array_equal(s, sol))\n        diversity_scores.append(diversity)\n\n        # Potential improvement\n        current_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - current_weight\n        not_in_sol = np.where(sol == 0)[0]\n        potential_value1 = np.sum(value1_lst[not_in_sol] * (weight_lst[not_in_sol] <= remaining_capacity))\n        potential_value2 = np.sum(value2_lst[not_in_sol] * (weight_lst[not_in_sol] <= remaining_capacity))\n        potential_scores.append((potential_value1 + potential_value2) / (1 + np.sum(obj)))\n\n    # Combine diversity and potential scores (weighted)\n    combined_scores = [0.7 * d + 0.3 * p for d, p in zip(diversity_scores, potential_scores)]\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Hybrid local search\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic bit flips (higher probability for worse items)\n    for i in range(len(new_solution)):\n        if random.random() < 0.3:  # Base probability\n            if new_solution[i] == 1:\n                new_solution[i] = 0\n                remaining_capacity += weight_lst[i]\n            else:\n                if weight_lst[i] <= remaining_capacity:\n                    # Higher probability to add items with lower combined ratio\n                    ratio1 = value1_lst[i] / weight_lst[i]\n                    ratio2 = value2_lst[i] / weight_lst[i]\n                    combined_ratio = ratio1 + ratio2\n                    if random.random() < 1 / (1 + combined_ratio):  # Inverse probability\n                        new_solution[i] = 1\n                        remaining_capacity -= weight_lst[i]\n\n    # Step 2: Greedy selection of items with highest normalized combined ratio\n    not_in_sol = np.where(new_solution == 0)[0]\n    if len(not_in_sol) > 0:\n        normalized_ratio1 = (value1_lst[not_in_sol] / weight_lst[not_in_sol]) / (1 + np.sum(value1_lst))\n        normalized_ratio2 = (value2_lst[not_in_sol] / weight_lst[not_in_sol]) / (1 + np.sum(value2_lst))\n        combined_ratios = normalized_ratio1 + normalized_ratio2\n        sorted_indices = np.argsort(combined_ratios)[::-1]\n\n        for idx in sorted_indices:\n            global_idx = not_in_sol[idx]\n            if weight_lst[global_idx] <= remaining_capacity:\n                new_solution[global_idx] = 1\n                remaining_capacity -= weight_lst[global_idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.3426667545408827,
            0.7310943007469177
        ],
        "raw_score": [
            52.0280329321086,
            52.01414403529617
        ]
    },
    {
        "algorithm": "The algorithm intelligently selects a base solution from the archive using a weighted probability that prioritizes solutions with higher potential improvement (valuing both objective values and remaining capacity), then applies a hybrid local search combining item swaps and value-density-based probabilistic flips to generate a feasible neighbor solution. The selection emphasizes solutions with better normalized objective scores, while the local search balances exploration (random swaps) and exploitation (value-driven flips) to maintain feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with probability proportional to its potential improvement\n    total_weights = np.array([np.sum(weight_lst[s[0] == 1]) for s in archive])\n    total_value1 = np.array([s[1][0] for s in archive])\n    total_value2 = np.array([s[1][1] for s in archive])\n\n    # Calculate potential improvement scores (normalized)\n    weight_scores = (capacity - total_weights) / capacity\n    value1_scores = (total_value1 - np.min(total_value1)) / (np.max(total_value1) - np.min(total_value1) + 1e-8)\n    value2_scores = (total_value2 - np.min(total_value2)) / (np.max(total_value2) - np.min(total_value2) + 1e-8)\n\n    scores = weight_scores * 0.4 + value1_scores * 0.3 + value2_scores * 0.3\n    selected_idx = np.random.choice(len(archive), p=scores/scores.sum())\n    base_solution = archive[selected_idx][0].copy()\n\n    # Create a copy of the base solution\n    new_solution = base_solution.copy()\n\n    # Hybrid local search operator\n    # Step 1: Item swapping (swap items between included and excluded)\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Randomly select items to swap\n        swap_in = random.choice(included)\n        swap_out = random.choice(excluded)\n\n        # Check feasibility of swap\n        current_weight = np.sum(weight_lst[new_solution == 1])\n        new_weight = current_weight - weight_lst[swap_in] + weight_lst[swap_out]\n\n        if new_weight <= capacity:\n            new_solution[swap_in] = 0\n            new_solution[swap_out] = 1\n\n    # Step 2: Probabilistic flipping (flip items with probability based on value density)\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Probability to remove based on value density\n            if random.random() < 0.1 * (value1_lst[i] + value2_lst[i]) / (weight_lst[i] + 1e-8):\n                new_solution[i] = 0\n        else:\n            # Probability to add based on value density\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            if (current_weight + weight_lst[i] <= capacity) and \\\n               (random.random() < 0.1 * (value1_lst[i] + value2_lst[i]) / (weight_lst[i] + 1e-8)):\n                new_solution[i] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.5807389084963747,
            1.9469241797924042
        ],
        "raw_score": [
            37.42782793116257,
            37.34662950259658
        ]
    },
    {
        "algorithm": "The heuristic selects a promising solution from the archive and applies a hybrid local search combining probabilistic item flips (prioritizing low-marginal-contribution items) and item swaps, ensuring feasibility by dynamically checking weight constraints. It iteratively improves the solution by flipping items based on their marginal contribution and swapping items between objectives, maintaining feasibility throughout the process. The algorithm balances exploration and exploitation by adjusting flip probabilities and dynamically updating values during swaps.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = np.random.choice(len(archive))\n    base_solution, base_objective = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Hybrid local search: probabilistic flip and item swap\n    for _ in range(10):  # Number of local search iterations\n        # Probabilistic flip: flip items with low marginal contribution\n        marginal_contrib1 = value1_lst / (weight_lst + 1e-6)\n        marginal_contrib2 = value2_lst / (weight_lst + 1e-6)\n        flip_prob = 0.3 * (1 - base_solution) + 0.1 * base_solution  # Higher probability for 0s\n\n        for i in range(len(base_solution)):\n            if np.random.rand() < flip_prob[i]:\n                if base_solution[i] == 1:\n                    # Try removing the item\n                    if current_weight - weight_lst[i] <= capacity:\n                        new_solution[i] = 0\n                        current_weight -= weight_lst[i]\n                        current_value1 -= value1_lst[i]\n                        current_value2 -= value2_lst[i]\n                else:\n                    # Try adding the item\n                    if current_weight + weight_lst[i] <= capacity:\n                        new_solution[i] = 1\n                        current_weight += weight_lst[i]\n                        current_value1 += value1_lst[i]\n                        current_value2 += value2_lst[i]\n\n        # Item swap: swap items between different objectives\n        if len(base_solution) >= 2:\n            i, j = np.random.choice(len(base_solution), 2, replace=False)\n            if base_solution[i] != base_solution[j]:\n                # Calculate potential new weight\n                new_weight = current_weight\n                if base_solution[i] == 1:\n                    new_weight -= weight_lst[i]\n                else:\n                    new_weight += weight_lst[i]\n                if base_solution[j] == 1:\n                    new_weight -= weight_lst[j]\n                else:\n                    new_weight += weight_lst[j]\n\n                if new_weight <= capacity:\n                    # Perform the swap\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                    current_weight = new_weight\n                    current_value1 = np.sum(value1_lst * new_solution)\n                    current_value2 = np.sum(value2_lst * new_solution)\n\n    return new_solution\n\n",
        "metric_score": [
            -0.3344743256096279,
            3.114544779062271
        ],
        "raw_score": [
            39.12367072835973,
            39.283556186309546
        ]
    },
    {
        "algorithm": "The algorithm intelligently selects a high-potential solution from the archive (based on combined objective values) and applies a hybrid local search combining random swaps and targeted flips to improve both objectives while ensuring feasibility. It prioritizes solutions with high combined objective values, then performs random swaps (10 iterations) followed by targeted flips (removing or adding items that improve both objectives), always checking weight constraints. The selection and local search are designed to balance exploration and exploitation for multi-objective optimization.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., high objective values)\n    selected_idx = np.argmax([obj[0] + obj[1] for _, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random swaps + targeted flips\n    for _ in range(10):  # Number of local search steps\n        # Randomly select two items to swap\n        swap_indices = np.random.choice(len(weight_lst), size=2, replace=False)\n        i, j = swap_indices\n\n        # Compute new weight after swap\n        new_weight = current_weight - weight_lst[i] * base_solution[i] + weight_lst[i] * (1 - base_solution[i]) \\\n                     - weight_lst[j] * base_solution[j] + weight_lst[j] * (1 - base_solution[j])\n\n        if new_weight <= capacity:\n            # Perform swap\n            new_solution[i], new_solution[j] = 1 - new_solution[i], 1 - new_solution[j]\n            current_weight = new_weight\n            base_solution = new_solution.copy()\n\n    # Targeted flips: flip items that improve both objectives\n    for i in range(len(weight_lst)):\n        if base_solution[i] == 1:\n            # Try removing item i\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_value1 = np.sum(value1_lst * new_solution) - value1_lst[i]\n                new_value2 = np.sum(value2_lst * new_solution) - value2_lst[i]\n                if (new_value1 >= np.sum(value1_lst * base_solution) - value1_lst[i] and\n                    new_value2 >= np.sum(value2_lst * base_solution) - value2_lst[i]):\n                    new_solution[i] = 0\n                    current_weight = new_weight\n        else:\n            # Try adding item i\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                new_value1 = np.sum(value1_lst * new_solution) + value1_lst[i]\n                new_value2 = np.sum(value2_lst * new_solution) + value2_lst[i]\n                if (new_value1 >= np.sum(value1_lst * base_solution) and\n                    new_value2 >= np.sum(value2_lst * base_solution)):\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    return new_solution\n\n",
        "metric_score": [
            -0.3612321602309515,
            3.558704376220703
        ],
        "raw_score": [
            48.96186624020501,
            49.02423043245761
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive by normalizing and scoring objectives, then generates a neighbor by intelligently flipping items to improve both objectives while ensuring feasibility. If no improvement is found, it performs a random flip to maintain diversity. The method prioritizes solutions with higher combined normalized scores and employs a heuristic local search that balances objective improvement with feasibility constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    objectives = np.array([obj for _, obj in archive])\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0))\n    scores = normalized.sum(axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Create a neighbor by flipping items that improve both objectives\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Identify items to flip (remove or add)\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Try removing item i\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                temp_value1 = np.sum(value1_lst * new_solution) - value1_lst[i]\n                temp_value2 = np.sum(value2_lst * new_solution) - value2_lst[i]\n                if temp_value1 >= np.sum(value1_lst * base_solution) and temp_value2 >= np.sum(value2_lst * base_solution):\n                    new_solution[i] = 0\n                    current_weight = temp_weight\n        else:\n            # Try adding item i\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # If no improvement, perform a random flip\n    if np.array_equal(new_solution, base_solution):\n        flip_indices = np.where(base_solution == 1)[0]\n        if len(flip_indices) > 0:\n            i = np.random.choice(flip_indices)\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n            # Add a random item not in the solution\n            available_indices = np.where((base_solution == 0) & (weight_lst <= (capacity - current_weight)))[0]\n            if len(available_indices) > 0:\n                j = np.random.choice(available_indices)\n                new_solution[j] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.31370817514337257,
            2.5185199975967407
        ],
        "raw_score": [
            54.36253091997847,
            53.625964955191336
        ]
    }
]