[
    {
        "algorithm": "The algorithm selects a promising solution from the archive based on combined potential improvement in both objectives, then applies a hybrid local search: first performing random bit flips to escape local optima, followed by a directed search for items with high combined value-to-weight ratios for both objectives, ensuring feasibility by dynamically tracking remaining capacity. The selection prioritizes solutions with the highest normalized potential improvement, while the neighbor generation balances exploration (random flips) with exploitation (directed selection).",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate potential improvement for each solution\n    potentials = []\n    for sol, obj in archive:\n        current_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - current_weight\n        # Potential items to add (not currently in solution)\n        not_in_sol = np.where(sol == 0)[0]\n        # Potential improvement in objective 1\n        potential_value1 = np.sum(value1_lst[not_in_sol] * (weight_lst[not_in_sol] <= remaining_capacity))\n        # Potential improvement in objective 2\n        potential_value2 = np.sum(value2_lst[not_in_sol] * (weight_lst[not_in_sol] <= remaining_capacity))\n        # Combined potential (normalized to avoid bias)\n        combined_potential = (potential_value1 + potential_value2) / (1 + obj[0] + obj[1])\n        potentials.append(combined_potential)\n\n    # Select solution with highest potential\n    selected_idx = np.argmax(potentials)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Generate neighbor solution\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random flip with directed selection\n    # Step 1: Randomly flip a few bits (to escape local optima)\n    num_flips = min(3, len(new_solution))\n    flip_indices = random.sample(range(len(new_solution)), num_flips)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            # Only add if it doesn't exceed capacity\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    # Step 2: Directed search for items that could improve either objective\n    # Consider items not in current solution\n    not_in_sol = np.where(new_solution == 0)[0]\n    if len(not_in_sol) > 0:\n        # Calculate value-to-weight ratios for both objectives\n        ratio1 = value1_lst[not_in_sol] / weight_lst[not_in_sol]\n        ratio2 = value2_lst[not_in_sol] / weight_lst[not_in_sol]\n\n        # Select items with highest combined ratio that fit in remaining capacity\n        combined_ratios = ratio1 + ratio2\n        sorted_indices = np.argsort(combined_ratios)[::-1]\n\n        for idx in sorted_indices:\n            global_idx = not_in_sol[idx]\n            if weight_lst[global_idx] <= remaining_capacity:\n                new_solution[global_idx] = 1\n                remaining_capacity -= weight_lst[global_idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9079633024147904,
            1.0491748750209808
        ],
        "raw_score": [
            27.36814387336429,
            27.95142773130081
        ]
    },
    {
        "algorithm": "The algorithm combines a weighted selection strategy (prioritizing solutions with high potential improvement based on normalized value and remaining capacity scores) with a hybrid local search that first probabilistically perturbs items based on their combined value-to-weight ratios and then greedily refines the solution by iteratively adding the most promising items until no further feasible improvements can be made. The selection emphasizes both objectives and capacity awareness, while the local search balances exploration (via probabilistic flips) with exploitation (via directed capacity-aware additions).",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate potential improvement scores\n    total_weights = np.array([np.sum(weight_lst[s[0] == 1]) for s in archive])\n    total_value1 = np.array([s[1][0] for s in archive])\n    total_value2 = np.array([s[1][1] for s in archive])\n\n    # Normalize scores\n    weight_scores = (capacity - total_weights) / capacity\n    value1_scores = (total_value1 - np.min(total_value1)) / (np.max(total_value1) - np.min(total_value1) + 1e-8)\n    value2_scores = (total_value2 - np.min(total_value2)) / (np.max(total_value2) - np.min(total_value2) + 1e-8)\n\n    # Combined selection score\n    scores = weight_scores * 0.4 + value1_scores * 0.3 + value2_scores * 0.3\n    selected_idx = np.random.choice(len(archive), p=scores/scores.sum())\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate remaining capacity\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Value-aware perturbation phase\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Probability to remove based on value density\n            if random.random() < 0.2 * (value1_lst[i] + value2_lst[i]) / (weight_lst[i] + 1e-8):\n                new_solution[i] = 0\n                remaining_capacity += weight_lst[i]\n        else:\n            # Probability to add based on value density\n            if (remaining_capacity >= weight_lst[i]) and \\\n               (random.random() < 0.2 * (value1_lst[i] + value2_lst[i]) / (weight_lst[i] + 1e-8)):\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n\n    # Capacity-aware refinement phase\n    added_items = []\n    while True:\n        # Calculate value-to-weight ratios for items not in solution\n        not_in_sol = np.where(new_solution == 0)[0]\n        if len(not_in_sol) == 0:\n            break\n\n        # Filter items that fit in remaining capacity\n        feasible_items = not_in_sol[weight_lst[not_in_sol] <= remaining_capacity]\n        if len(feasible_items) == 0:\n            break\n\n        # Select item with highest combined value-to-weight ratio\n        combined_ratios = (value1_lst[feasible_items] + value2_lst[feasible_items]) / weight_lst[feasible_items]\n        best_item = feasible_items[np.argmax(combined_ratios)]\n\n        # Add the best item\n        new_solution[best_item] = 1\n        remaining_capacity -= weight_lst[best_item]\n        added_items.append(best_item)\n\n        # Check if adding more items is beneficial\n        if len(added_items) > 3:  # Limit to prevent excessive computation\n            break\n\n    return new_solution\n\n",
        "metric_score": [
            -0.3888242975453579,
            0.6292133629322052
        ],
        "raw_score": [
            36.7724156200035,
            37.5580101790531
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate selection scores based on both objectives and capacity utilization\n    total_weights = np.array([np.sum(weight_lst[s[0] == 1]) for s in archive])\n    total_value1 = np.array([s[1][0] for s in archive])\n    total_value2 = np.array([s[1][1] for s in archive])\n\n    # Normalize scores\n    weight_scores = (capacity - total_weights) / capacity\n    value1_scores = (total_value1 - np.min(total_value1)) / (np.max(total_value1) - np.min(total_value1) + 1e-8)\n    value2_scores = (total_value2 - np.min(total_value2)) / (np.max(total_value2) - np.min(total_value2) + 1e-8)\n\n    # Combined selection score\n    scores = weight_scores * 0.5 + value1_scores * 0.25 + value2_scores * 0.25\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Phase 1: Value-driven selection with capacity constraint\n    excluded = np.where(new_solution == 0)[0]\n    if len(excluded) > 0:\n        # Calculate combined value-to-weight ratios\n        ratios = (value1_lst[excluded] + value2_lst[excluded]) / weight_lst[excluded]\n        sorted_indices = np.argsort(ratios)[::-1]\n\n        for idx in sorted_indices:\n            global_idx = excluded[idx]\n            if weight_lst[global_idx] <= remaining_capacity:\n                new_solution[global_idx] = 1\n                remaining_capacity -= weight_lst[global_idx]\n\n    # Phase 2: Capacity-aware swaps\n    included = np.where(new_solution == 1)[0]\n    if len(included) > 0 and len(excluded) > 0:\n        # Find best swap candidates\n        for in_idx in included:\n            for out_idx in excluded:\n                if weight_lst[out_idx] <= remaining_capacity + weight_lst[in_idx]:\n                    new_weight = current_weight - weight_lst[in_idx] + weight_lst[out_idx]\n                    if new_weight <= capacity:\n                        if (value1_lst[out_idx] + value2_lst[out_idx]) > (value1_lst[in_idx] + value2_lst[in_idx]):\n                            new_solution[in_idx] = 0\n                            new_solution[out_idx] = 1\n                            current_weight = new_weight\n                            remaining_capacity = capacity - current_weight\n                            break\n\n    # Phase 3: Probabilistic diversification\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Higher probability to remove low-value items\n            if random.random() < 0.15 * (1 - (value1_lst[i] + value2_lst[i]) / (np.max(value1_lst) + np.max(value2_lst))):\n                new_solution[i] = 0\n        else:\n            # Higher probability to add high-value items\n            if weight_lst[i] <= remaining_capacity:\n                if random.random() < 0.15 * (value1_lst[i] + value2_lst[i]) / (np.max(value1_lst) + np.max(value2_lst)):\n                    new_solution[i] = 1\n                    remaining_capacity -= weight_lst[i]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.971754987227483,
            3.0680152773857117
        ],
        "raw_score": [
            27.532413913689474,
            28.212249960363902
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate potential improvement scores\n    total_weights = np.array([np.sum(weight_lst[s[0] == 1]) for s in archive])\n    total_value1 = np.array([s[1][0] for s in archive])\n    total_value2 = np.array([s[1][1] for s in archive])\n\n    # Normalize scores\n    weight_scores = (capacity - total_weights) / capacity\n    value1_scores = (total_value1 - np.min(total_value1)) / (np.max(total_value1) - np.min(total_value1) + 1e-8)\n    value2_scores = (total_value2 - np.min(total_value2)) / (np.max(total_value2) - np.min(total_value2) + 1e-8)\n\n    # Combined selection score with emphasis on both objectives and capacity\n    scores = weight_scores * 0.5 + value1_scores * 0.25 + value2_scores * 0.25\n    selected_idx = np.random.choice(len(archive), p=scores/scores.sum())\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate remaining capacity\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Novel hybrid local search: Value-aware cluster swapping with probabilistic refinement\n    # Step 1: Identify value clusters and swap between them\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 1 and len(excluded) > 1:\n        # Create value clusters based on combined value-to-weight ratios\n        included_ratios = (value1_lst[included] + value2_lst[included]) / weight_lst[included]\n        excluded_ratios = (value1_lst[excluded] + value2_lst[excluded]) / weight_lst[excluded]\n\n        # Sort items in each cluster by their value-to-weight ratio\n        high_included = included[np.argsort(included_ratios)[-min(3, len(included)):]]\n        low_excluded = excluded[np.argsort(excluded_ratios)[:min(3, len(excluded))]]\n\n        # Attempt swaps between high-value included and low-value excluded items\n        for hi in high_included:\n            for lo in low_excluded:\n                new_weight = current_weight - weight_lst[hi] + weight_lst[lo]\n                if new_weight <= capacity:\n                    new_solution[hi] = 0\n                    new_solution[lo] = 1\n                    current_weight = new_weight\n                    remaining_capacity = capacity - current_weight\n                    break\n\n    # Step 2: Probabilistic refinement with value-aware flips and capacity-aware additions\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Probability to remove based on value density and capacity pressure\n            remove_prob = 0.1 * (value1_lst[i] + value2_lst[i]) / (weight_lst[i] + 1e-8) * (1 - remaining_capacity/capacity)\n            if random.random() < remove_prob:\n                new_solution[i] = 0\n                remaining_capacity += weight_lst[i]\n        else:\n            # Probability to add based on value density and capacity availability\n            add_prob = 0.1 * (value1_lst[i] + value2_lst[i]) / (weight_lst[i] + 1e-8) * (remaining_capacity/weight_lst[i])\n            if (remaining_capacity >= weight_lst[i]) and (random.random() < add_prob):\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n\n    # Step 3: Greedy capacity-aware refinement\n    while True:\n        # Calculate value-to-weight ratios for items not in solution\n        not_in_sol = np.where(new_solution == 0)[0]\n        if len(not_in_sol) == 0:\n            break\n\n        # Filter items that fit in remaining capacity\n        feasible_items = not_in_sol[weight_lst[not_in_sol] <= remaining_capacity]\n        if len(feasible_items) == 0:\n            break\n\n        # Select item with highest combined value-to-weight ratio\n        combined_ratios = (value1_lst[feasible_items] + value2_lst[feasible_items]) / weight_lst[feasible_items]\n        best_item = feasible_items[np.argmax(combined_ratios)]\n\n        # Add the best item\n        new_solution[best_item] = 1\n        remaining_capacity -= weight_lst[best_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.43483846301394125,
            0.9316346347332001
        ],
        "raw_score": [
            43.37854733532269,
            43.24897827956235
        ]
    },
    {
        "algorithm": "The algorithm dynamically selects a base solution from the archive by balancing Pareto dominance (60% weight) and capacity utilization (40% weight), then applies a hybrid local search combining value-weighted swaps and adaptive flipping, ensuring feasibility by prioritizing items with higher value-to-weight ratios and adjusting probabilities based on remaining capacity. The selection favors non-dominated solutions with better capacity use, while the local search intelligently explores neighbors by probabilistically swapping and flipping items, with higher probabilities for items offering better value density and tighter capacity constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Dynamic solution selection based on Pareto dominance and capacity\n    total_weights = np.array([np.sum(weight_lst[s[0] == 1]) for s in archive])\n    total_value1 = np.array([s[1][0] for s in archive])\n    total_value2 = np.array([s[1][1] for s in archive])\n\n    # Calculate dominance scores (1 if non-dominated, 0 otherwise)\n    dominance = np.ones(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (total_value1[i] <= total_value1[j] and total_value2[i] <= total_value2[j] and\n                    (total_value1[i] < total_value1[j] or total_value2[i] < total_value2[j])):\n                    dominance[i] = 0\n                    break\n\n    # Calculate capacity utilization scores\n    capacity_scores = (capacity - total_weights) / capacity\n\n    # Combine dominance and capacity scores for selection\n    combined_scores = dominance * 0.6 + capacity_scores * 0.4\n    selected_idx = np.random.choice(len(archive), p=combined_scores/combined_scores.sum())\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search with adaptive probabilities\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    # Step 1: Value-weighted probabilistic swap\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value densities\n        included_densities = (value1_lst[included] + value2_lst[included]) / weight_lst[included]\n        excluded_densities = (value1_lst[excluded] + value2_lst[excluded]) / weight_lst[excluded]\n\n        # Select items to swap with probability proportional to value density\n        swap_in = np.random.choice(included, p=included_densities/included_densities.sum())\n        swap_out = np.random.choice(excluded, p=excluded_densities/excluded_densities.sum())\n\n        # Check feasibility\n        current_weight = np.sum(weight_lst[new_solution == 1])\n        new_weight = current_weight - weight_lst[swap_in] + weight_lst[swap_out]\n\n        if new_weight <= capacity:\n            new_solution[swap_in] = 0\n            new_solution[swap_out] = 1\n\n    # Step 2: Adaptive flipping based on value and capacity\n    for i in range(len(new_solution)):\n        current_weight = np.sum(weight_lst[new_solution == 1])\n        remaining_capacity = capacity - current_weight\n\n        if new_solution[i] == 1:\n            # Probability to remove based on value density and remaining capacity\n            flip_prob = 0.2 * (value1_lst[i] + value2_lst[i]) / (weight_lst[i] + 1e-8) * (1 - remaining_capacity/capacity)\n            if random.random() < flip_prob:\n                new_solution[i] = 0\n        else:\n            # Probability to add based on value density and capacity\n            if weight_lst[i] <= remaining_capacity:\n                flip_prob = 0.2 * (value1_lst[i] + value2_lst[i]) / (weight_lst[i] + 1e-8) * (remaining_capacity/capacity)\n                if random.random() < flip_prob:\n                    new_solution[i] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9309139264047235,
            3.033954620361328
        ],
        "raw_score": [
            27.608625485677514,
            28.167711895727706
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive by balancing potential objective improvements and diversity, then generates a neighbor through a hybrid local search combining probabilistic bit flips and value-to-weight ratio-based directed additions, ensuring feasibility by dynamically tracking remaining capacity. It prioritizes solutions with higher combined potential scores (70% improvement, 30% diversity) and refines the solution with adaptive flips and capacity-aware high-ratio item additions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate potential improvement and diversity for each solution\n    potentials = []\n    for sol, obj in archive:\n        current_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - current_weight\n        not_in_sol = np.where(sol == 0)[0]\n\n        # Calculate potential improvements\n        potential_value1 = np.sum(value1_lst[not_in_sol] * (weight_lst[not_in_sol] <= remaining_capacity))\n        potential_value2 = np.sum(value2_lst[not_in_sol] * (weight_lst[not_in_sol] <= remaining_capacity))\n\n        # Calculate diversity (number of unique items not in solution)\n        diversity = len(not_in_sol)\n\n        # Combined score with adaptive weighting\n        alpha = 0.7  # Weight for improvement\n        beta = 0.3   # Weight for diversity\n        combined_score = (alpha * (potential_value1 + potential_value2) + beta * diversity) / (1 + obj[0] + obj[1])\n        potentials.append(combined_score)\n\n    # Select solution with highest potential\n    selected_idx = np.argmax(potentials)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Generate neighbor solution\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: probabilistic flip with adaptive intensity\n    flip_prob = 0.3  # Base flip probability\n    for i in range(len(new_solution)):\n        if random.random() < flip_prob:\n            if new_solution[i] == 1:\n                new_solution[i] = 0\n            else:\n                if weight_lst[i] <= remaining_capacity:\n                    new_solution[i] = 1\n                    remaining_capacity -= weight_lst[i]\n\n    # Directed search for items with high combined value-to-weight ratio\n    not_in_sol = np.where(new_solution == 0)[0]\n    if len(not_in_sol) > 0:\n        # Calculate normalized value-to-weight ratios\n        ratio1 = value1_lst[not_in_sol] / (weight_lst[not_in_sol] + 1e-6)\n        ratio2 = value2_lst[not_in_sol] / (weight_lst[not_in_sol] + 1e-6)\n        combined_ratios = ratio1 + ratio2\n\n        # Select top candidates and filter by capacity\n        candidate_indices = np.argsort(combined_ratios)[-min(5, len(not_in_sol)):][::-1]\n        for idx in candidate_indices:\n            global_idx = not_in_sol[idx]\n            if weight_lst[global_idx] <= remaining_capacity:\n                new_solution[global_idx] = 1\n                remaining_capacity -= weight_lst[global_idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8240901047809942,
            1.0695575177669525
        ],
        "raw_score": [
            27.25824576339125,
            27.480145508309896
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate dominance-based scores and potential improvement\n    dominance_scores = []\n    for sol, obj in archive:\n        current_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - current_weight\n        not_in_sol = np.where(sol == 0)[0]\n        potential_value1 = np.sum(value1_lst[not_in_sol] * (weight_lst[not_in_sol] <= remaining_capacity))\n        potential_value2 = np.sum(value2_lst[not_in_sol] * (weight_lst[not_in_sol] <= remaining_capacity))\n        combined_potential = (potential_value1 + potential_value2) / (1 + obj[0] + obj[1])\n\n        # Calculate dominance score (number of solutions this one dominates)\n        dominates = 0\n        for _, other_obj in archive:\n            if (obj[0] >= other_obj[0] and obj[1] > other_obj[1]) or (obj[0] > other_obj[0] and obj[1] >= other_obj[1]):\n                dominates += 1\n\n        dominance_scores.append(dominates * combined_potential)\n\n    # Select solution with highest combined score\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: value-density clustering with dynamic capacity management\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Step 1: Cluster items by value-to-weight ratio and select representative items\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0:\n        # Calculate value-to-weight ratios for included items\n        included_ratios = (value1_lst[included] + value2_lst[included]) / weight_lst[included]\n        # Find items with highest ratios to potentially remove\n        remove_candidates = included[np.argsort(included_ratios)][:max(1, len(included)//3)]\n\n        for item in remove_candidates:\n            if random.random() < 0.3:  # 30% chance to remove\n                new_solution[item] = 0\n                remaining_capacity += weight_lst[item]\n\n    # Step 2: Add items with high value-to-weight ratios from excluded items\n    if len(excluded) > 0 and remaining_capacity > 0:\n        excluded_ratios = (value1_lst[excluded] + value2_lst[excluded]) / weight_lst[excluded]\n        sorted_indices = np.argsort(excluded_ratios)[::-1]\n\n        for idx in sorted_indices:\n            global_idx = excluded[idx]\n            if weight_lst[global_idx] <= remaining_capacity:\n                new_solution[global_idx] = 1\n                remaining_capacity -= weight_lst[global_idx]\n\n    # Step 3: Randomly adjust a few items for diversity\n    num_adjustments = min(2, len(new_solution))\n    adjust_indices = random.sample(range(len(new_solution)), num_adjustments)\n    for idx in adjust_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.3532309495545469,
            0.8453739583492279
        ],
        "raw_score": [
            54.60717630449767,
            53.96161022416238
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive by balancing diversity and potential improvement, then applies a hybrid local search that combines probabilistic bit flips (with higher probability for items with lower value-to-weight ratios) and a greedy selection of items with the highest normalized combined value-to-weight ratios, ensuring feasibility through dynamic capacity tracking. The selection prioritizes solutions with higher diversity and potential improvement, while the local search strategically explores the solution space by probabilistically flipping bits and greedily adding high-value items.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate diversity and potential improvement for each solution\n    diversity_scores = []\n    potential_scores = []\n    for sol, obj in archive:\n        # Diversity: count of items not in other solutions\n        diversity = sum(1 for s, _ in archive if not np.array_equal(s, sol))\n        diversity_scores.append(diversity)\n\n        # Potential improvement\n        current_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - current_weight\n        not_in_sol = np.where(sol == 0)[0]\n        potential_value1 = np.sum(value1_lst[not_in_sol] * (weight_lst[not_in_sol] <= remaining_capacity))\n        potential_value2 = np.sum(value2_lst[not_in_sol] * (weight_lst[not_in_sol] <= remaining_capacity))\n        potential_scores.append((potential_value1 + potential_value2) / (1 + np.sum(obj)))\n\n    # Combine diversity and potential scores (weighted)\n    combined_scores = [0.7 * d + 0.3 * p for d, p in zip(diversity_scores, potential_scores)]\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Hybrid local search\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic bit flips (higher probability for worse items)\n    for i in range(len(new_solution)):\n        if random.random() < 0.3:  # Base probability\n            if new_solution[i] == 1:\n                new_solution[i] = 0\n                remaining_capacity += weight_lst[i]\n            else:\n                if weight_lst[i] <= remaining_capacity:\n                    # Higher probability to add items with lower combined ratio\n                    ratio1 = value1_lst[i] / weight_lst[i]\n                    ratio2 = value2_lst[i] / weight_lst[i]\n                    combined_ratio = ratio1 + ratio2\n                    if random.random() < 1 / (1 + combined_ratio):  # Inverse probability\n                        new_solution[i] = 1\n                        remaining_capacity -= weight_lst[i]\n\n    # Step 2: Greedy selection of items with highest normalized combined ratio\n    not_in_sol = np.where(new_solution == 0)[0]\n    if len(not_in_sol) > 0:\n        normalized_ratio1 = (value1_lst[not_in_sol] / weight_lst[not_in_sol]) / (1 + np.sum(value1_lst))\n        normalized_ratio2 = (value2_lst[not_in_sol] / weight_lst[not_in_sol]) / (1 + np.sum(value2_lst))\n        combined_ratios = normalized_ratio1 + normalized_ratio2\n        sorted_indices = np.argsort(combined_ratios)[::-1]\n\n        for idx in sorted_indices:\n            global_idx = not_in_sol[idx]\n            if weight_lst[global_idx] <= remaining_capacity:\n                new_solution[global_idx] = 1\n                remaining_capacity -= weight_lst[global_idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.3426667545408827,
            0.7310943007469177
        ],
        "raw_score": [
            52.0280329321086,
            52.01414403529617
        ]
    },
    {
        "algorithm": "The algorithm intelligently selects a base solution from the archive using a weighted probability that prioritizes solutions with higher potential improvement (valuing both objective values and remaining capacity), then applies a hybrid local search combining item swaps and value-density-based probabilistic flips to generate a feasible neighbor solution. The selection emphasizes solutions with better normalized objective scores, while the local search balances exploration (random swaps) and exploitation (value-driven flips) to maintain feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with probability proportional to its potential improvement\n    total_weights = np.array([np.sum(weight_lst[s[0] == 1]) for s in archive])\n    total_value1 = np.array([s[1][0] for s in archive])\n    total_value2 = np.array([s[1][1] for s in archive])\n\n    # Calculate potential improvement scores (normalized)\n    weight_scores = (capacity - total_weights) / capacity\n    value1_scores = (total_value1 - np.min(total_value1)) / (np.max(total_value1) - np.min(total_value1) + 1e-8)\n    value2_scores = (total_value2 - np.min(total_value2)) / (np.max(total_value2) - np.min(total_value2) + 1e-8)\n\n    scores = weight_scores * 0.4 + value1_scores * 0.3 + value2_scores * 0.3\n    selected_idx = np.random.choice(len(archive), p=scores/scores.sum())\n    base_solution = archive[selected_idx][0].copy()\n\n    # Create a copy of the base solution\n    new_solution = base_solution.copy()\n\n    # Hybrid local search operator\n    # Step 1: Item swapping (swap items between included and excluded)\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Randomly select items to swap\n        swap_in = random.choice(included)\n        swap_out = random.choice(excluded)\n\n        # Check feasibility of swap\n        current_weight = np.sum(weight_lst[new_solution == 1])\n        new_weight = current_weight - weight_lst[swap_in] + weight_lst[swap_out]\n\n        if new_weight <= capacity:\n            new_solution[swap_in] = 0\n            new_solution[swap_out] = 1\n\n    # Step 2: Probabilistic flipping (flip items with probability based on value density)\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Probability to remove based on value density\n            if random.random() < 0.1 * (value1_lst[i] + value2_lst[i]) / (weight_lst[i] + 1e-8):\n                new_solution[i] = 0\n        else:\n            # Probability to add based on value density\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            if (current_weight + weight_lst[i] <= capacity) and \\\n               (random.random() < 0.1 * (value1_lst[i] + value2_lst[i]) / (weight_lst[i] + 1e-8)):\n                new_solution[i] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.5807389084963747,
            1.9469241797924042
        ],
        "raw_score": [
            37.42782793116257,
            37.34662950259658
        ]
    },
    {
        "algorithm": "The algorithm selects a base solution from the archive with probability weighted by its potential improvement (prioritizing solutions with higher value scores and lower weight utilization), then applies a hybrid local search combining adaptive item swaps (favoring high-value-density items), probabilistic flips (biased toward balanced items), and a novel value-balanced insertion strategy (greedily adding items with strong combined value) while ensuring feasibility. The method balances exploration and exploitation through adaptive weighting and value-based selection criteria.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with probability proportional to its potential improvement\n    total_weights = np.array([np.sum(weight_lst[s[0] == 1]) for s in archive])\n    total_value1 = np.array([s[1][0] for s in archive])\n    total_value2 = np.array([s[1][1] for s in archive])\n\n    # Calculate potential improvement scores (weighted differently)\n    weight_scores = (capacity - total_weights) / capacity\n    value1_scores = (total_value1 - np.min(total_value1)) / (np.max(total_value1) - np.min(total_value1) + 1e-8)\n    value2_scores = (total_value2 - np.min(total_value2)) / (np.max(total_value2) - np.min(total_value2) + 1e-8)\n\n    # Adaptive weighting based on current archive diversity\n    diversity_factor = np.std(total_value1) / np.mean(total_value1) + np.std(total_value2) / np.mean(total_value2)\n    weight_factor = 0.5 if diversity_factor > 0.3 else 0.2\n    scores = weight_scores * weight_factor + value1_scores * 0.4 + value2_scores * 0.4\n    selected_idx = np.random.choice(len(archive), p=scores/scores.sum())\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search with adaptive components\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    # Step 1: Adaptive item swapping\n    if len(included) > 0 and len(excluded) > 0:\n        # Select items with higher value density first\n        included_densities = (value1_lst[included] + value2_lst[included]) / weight_lst[included]\n        excluded_densities = (value1_lst[excluded] + value2_lst[excluded]) / weight_lst[excluded]\n\n        if np.random.random() < 0.7:  # Higher probability for density-based selection\n            swap_in = included[np.argmax(included_densities)]\n            swap_out = excluded[np.argmin(excluded_densities)]\n        else:\n            swap_in = random.choice(included)\n            swap_out = random.choice(excluded)\n\n        current_weight = np.sum(weight_lst[new_solution == 1])\n        new_weight = current_weight - weight_lst[swap_in] + weight_lst[swap_out]\n\n        if new_weight <= capacity:\n            new_solution[swap_in] = 0\n            new_solution[swap_out] = 1\n\n    # Step 2: Value-balanced probabilistic flipping\n    for i in range(len(new_solution)):\n        value_balance = (value1_lst[i] + value2_lst[i]) / (np.max(value1_lst) + np.max(value2_lst) + 1e-8)\n        if new_solution[i] == 1:\n            if random.random() < 0.2 * value_balance:\n                new_solution[i] = 0\n        else:\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            if (current_weight + weight_lst[i] <= capacity) and (random.random() < 0.3 * value_balance):\n                new_solution[i] = 1\n\n    # Step 3: Novel value-balanced insertion\n    if len(excluded) > 0 and np.sum(weight_lst[new_solution == 1]) < 0.9 * capacity:\n        # Sort excluded items by value balance\n        excluded_balances = (value1_lst[excluded] + value2_lst[excluded]) / (np.max(value1_lst) + np.max(value2_lst) + 1e-8)\n        sorted_excluded = excluded[np.argsort(-excluded_balances)]\n\n        for i in sorted_excluded:\n            if np.sum(weight_lst[new_solution == 1]) + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n            else:\n                break\n\n    return new_solution\n\n",
        "metric_score": [
            -0.3838246572838927,
            4.004135936498642
        ],
        "raw_score": [
            47.17059388266437,
            47.310502050670436
        ]
    }
]