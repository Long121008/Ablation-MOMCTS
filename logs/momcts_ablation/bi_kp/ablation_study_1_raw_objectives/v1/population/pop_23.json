[
    {
        "algorithm": "The algorithm selects a solution from the archive with the highest objective diversity (difference between value1 and value2), then performs a hybrid local search by flipping items based on their normalized marginal contributions to both objectives, prioritizing those with the highest combined marginal value while ensuring feasibility. It sorts items by their normalized marginal value and iteratively flips items to maximize combined objective gains without exceeding capacity. The key design ideas are prioritizing objective diversity for selection and using normalized marginal contributions for intelligent flipping.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select the solution with the highest objective diversity (difference between value1 and value2)\n    best_idx = max(range(len(archive)), key=lambda i: abs(archive[i][1][0] - archive[i][1][1]))\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate normalized marginal contributions for each item\n    marginal_value1 = value1_lst - (base_solution * value1_lst)\n    marginal_value2 = value2_lst - (base_solution * value2_lst)\n    marginal_combined = marginal_value1 + marginal_value2\n\n    # Normalize marginal contributions\n    max_marginal = np.max(marginal_combined)\n    if max_marginal > 0:\n        normalized_marginal = marginal_combined / max_marginal\n    else:\n        normalized_marginal = marginal_combined\n\n    # Sort items by normalized marginal contribution (descending)\n    sorted_indices = np.argsort(-normalized_marginal)\n\n    # Try to flip items with high normalized marginal contribution\n    for idx in sorted_indices:\n        if base_solution[idx] == 1:\n            # If item is in the solution, try to remove it\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # If item is not in the solution, try to add it\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9101876645710116,
            0.3497251272201538
        ],
        "raw_score": [
            27.004661735141276,
            27.688360888346264
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive by prioritizing those with high marginal gains in both objectives, then applies a hybrid local search that probabilistically adds, removes, or swaps items based on their marginal contributions, ensuring feasibility through adaptive weight checks. It balances exploration/exploitation by favoring diverse marginal gains and intelligently navigating the Pareto front through probabilistic operations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high marginal gains in both objectives\n    selected_idx = 0\n    max_marginal_product = -1\n\n    for i, (solution, objective) in enumerate(archive):\n        current_weight = np.sum(weight_lst[solution == 1])\n        excluded_items = np.where(solution == 0)[0]\n        included_items = np.where(solution == 1)[0]\n\n        if len(excluded_items) == 0 or len(included_items) == 0:\n            continue\n\n        # Calculate marginal gains for excluded items\n        marginal_gains1 = value1_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        marginal_gains2 = value2_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        marginal_product = np.mean(marginal_gains1) * np.mean(marginal_gains2)\n\n        if marginal_product > max_marginal_product:\n            max_marginal_product = marginal_product\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate marginal contributions for all items\n    marginal_value1 = value1_lst - (base_solution * value1_lst)\n    marginal_value2 = value2_lst - (base_solution * value2_lst)\n    marginal_combined = marginal_value1 + marginal_value2\n\n    # Sort items by marginal contribution (descending)\n    sorted_indices = np.argsort(-marginal_combined)\n\n    # Hybrid local search: probabilistic decision between add, remove, or swap\n    excluded_items = np.where(new_solution == 0)[0]\n    included_items = np.where(new_solution == 1)[0]\n\n    if len(excluded_items) > 0 and len(included_items) > 0:\n        decision = random.choices(['add', 'remove', 'swap'], weights=[0.4, 0.3, 0.3])[0]\n\n        if decision == 'add':\n            # Add the best excluded item based on combined marginal gain\n            excluded_sorted = sorted(excluded_items, key=lambda x: marginal_combined[x], reverse=True)\n            for item in excluded_sorted:\n                if np.sum(weight_lst[new_solution == 1]) + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                    break\n\n        elif decision == 'remove':\n            # Remove the least marginal item in either objective\n            included_sorted = sorted(included_items, key=lambda x: min(marginal_value1[x], marginal_value2[x]))\n            for item in included_sorted:\n                if np.sum(weight_lst[new_solution == 1]) - weight_lst[item] >= 0:\n                    new_solution[item] = 0\n                    break\n\n        elif decision == 'swap':\n            # Swap one excluded with one included item\n            swap_excluded = random.choice(excluded_items)\n            swap_included = random.choice(included_items)\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            new_weight = current_weight - weight_lst[swap_included] + weight_lst[swap_excluded]\n            if new_weight <= capacity:\n                new_solution[swap_included] = 0\n                new_solution[swap_excluded] = 1\n\n    # If no swap possible, try to add the best excluded item\n    else:\n        excluded_items = np.where(new_solution == 0)[0]\n        if len(excluded_items) > 0:\n            excluded_sorted = sorted(excluded_items, key=lambda x: marginal_combined[x], reverse=True)\n            for item in excluded_sorted:\n                if np.sum(weight_lst[new_solution == 1]) + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                    break\n\n    return new_solution\n\n",
        "metric_score": [
            -1.002058205017338,
            1.9492744207382202
        ],
        "raw_score": [
            27.19939705469744,
            27.641547598415023
        ]
    },
    {
        "algorithm": "The algorithm selects the most promising solution from the archive using a hypervolume-aware metric, then applies a multi-phase local search combining Pareto frontier exploration (60% chance) with frontier-aware flips and marginal contribution analysis, or diversity-aware perturbation (40% chance) with adaptive neighborhood swaps, ensuring feasibility through weight checks. If no improvement is found, it intensifies search by removing the least valuable included items. The approach balances exploration and exploitation while prioritizing solutions with high hypervolume contributions and marginal value improvements.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hypervolume-aware solution selection\n    def hypervolume(obj1, obj2, ref_point):\n        return (ref_point[0] - obj1) * (ref_point[1] - obj2)\n\n    max_hv = -1\n    best_idx = 0\n    ref_point = (np.max([obj[0] for _, obj in archive]), np.max([obj[1] for _, obj in archive]))\n\n    for i, (solution, obj) in enumerate(archive):\n        hv = hypervolume(obj[0], obj[1], ref_point)\n        if hv > max_hv:\n            max_hv = hv\n            best_idx = i\n\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Multi-phase local search\n    if random.random() < 0.6:  # 60% chance for frontier exploration\n        # Pareto frontier-aware flips\n        frontier_items = np.where(new_solution == 1)[0]\n        non_frontier_items = np.where(new_solution == 0)[0]\n\n        if len(frontier_items) > 0 and len(non_frontier_items) > 0:\n            # Calculate marginal contributions\n            frontier_marginal = (value1_lst[frontier_items] + value2_lst[frontier_items]) / weight_lst[frontier_items]\n            non_frontier_marginal = (value1_lst[non_frontier_items] + value2_lst[non_frontier_items]) / weight_lst[non_frontier_items]\n\n            # Find best swaps\n            best_frontier = frontier_items[np.argmin(frontier_marginal)]\n            best_non_frontier = non_frontier_items[np.argmax(non_frontier_marginal)]\n\n            # Check feasibility\n            new_weight = current_weight - weight_lst[best_frontier] + weight_lst[best_non_frontier]\n            if new_weight <= capacity:\n                new_solution[best_frontier] = 0\n                new_solution[best_non_frontier] = 1\n                current_weight = new_weight\n    else:  # 40% chance for diversity-aware perturbation\n        # Adaptive neighborhood search\n        num_perturbations = min(2, len(weight_lst) // 10)\n        perturb_indices = np.random.choice(len(weight_lst), size=num_perturbations, replace=False)\n\n        for idx in perturb_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Fallback mechanism: Pareto-aware intensification\n    if np.array_equal(new_solution, base_solution):\n        # Intensify search around current solution\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Find least valuable included item\n            included_marginal = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n            least_val_item = included_items[np.argmin(included_marginal)]\n\n            # Try to remove it\n            if current_weight - weight_lst[least_val_item] >= 0:\n                new_solution[least_val_item] = 0\n                current_weight -= weight_lst[least_val_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8962181579365913,
            0.19705554842948914
        ],
        "raw_score": [
            26.959826063541488,
            27.544373065968784
        ]
    },
    {
        "algorithm": "The algorithm selects the most promising solution from the archive (based on normalized marginal gains) and applies a hybrid local search (60% flips, 40% swaps) with adaptive weights (higher priority to the weaker objective). It ensures feasibility by removing least marginal items if no improvement is found, prioritizing balanced improvements across both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest normalized sum of marginal gains\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    best_idx = max(range(len(archive)), key=lambda i: (archive[i][1][0] + archive[i][1][1]) / (max_obj1 + max_obj2 + 1e-10))\n\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate marginal contributions with adaptive weights\n    marginal_value1 = value1_lst - (base_solution * value1_lst)\n    marginal_value2 = value2_lst - (base_solution * value2_lst)\n\n    # Adaptive weights based on objective dominance\n    total_value1 = np.sum(value1_lst[base_solution == 1])\n    total_value2 = np.sum(value2_lst[base_solution == 1])\n    weight_obj1 = 1.0 if total_value1 < total_value2 else 0.7\n    weight_obj2 = 1.0 if total_value2 < total_value1 else 0.7\n\n    marginal_combined = weight_obj1 * marginal_value1 + weight_obj2 * marginal_value2\n\n    # Hybrid local search with probabilistic operations\n    decision = random.choices(['flip', 'swap'], weights=[0.6, 0.4])[0]\n\n    if decision == 'flip':\n        # Flip items with highest marginal gain while maintaining feasibility\n        sorted_indices = np.argsort(-marginal_combined)\n        for idx in sorted_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    else:  # swap\n        # Swap items with high and low marginal gains\n        high_marginal = np.argsort(-marginal_combined)[:len(weight_lst)//3]\n        low_marginal = np.argsort(marginal_combined)[:len(weight_lst)//3]\n\n        for h in high_marginal:\n            for l in low_marginal:\n                if new_solution[h] == 1 and new_solution[l] == 0:\n                    new_weight = current_weight - weight_lst[h] + weight_lst[l]\n                    if new_weight <= capacity:\n                        new_solution[h], new_solution[l] = 0, 1\n                        current_weight = new_weight\n                        break\n            else:\n                continue\n            break\n\n    # If no improvement, remove least marginal items to ensure feasibility\n    if np.array_equal(new_solution, base_solution):\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            sorted_items = sorted(included_items, key=lambda x: marginal_value1[x] + marginal_value2[x])\n            for item in sorted_items:\n                if current_weight - weight_lst[item] >= 0:\n                    new_solution[item] = 0\n                    current_weight -= weight_lst[item]\n                    break\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9514271204468423,
            0.9768357276916504
        ],
        "raw_score": [
            27.865390153322615,
            28.203870181276848
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive based on a weighted combination of normalized objectives, then performs a hybrid local search by iteratively flipping items with the highest marginal contribution to both objectives, while dynamically adjusting weights to prioritize underperforming objectives and ensuring feasibility. It also includes a diversification step to escape local optima by randomly flipping an item if no improvement is found. The key design ideas are adaptive objective weighting, marginal contribution-based flipping, and a diversification mechanism to enhance solution quality.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest weighted sum of objectives (adaptive weights)\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        best_idx = 0\n    else:\n        best_idx = max(range(len(archive)), key=lambda i: (archive[i][1][0]/max_obj1 + archive[i][1][1]/max_obj2))\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Calculate normalized marginal contributions\n    marginal_value1 = value1_lst - (base_solution * value1_lst)\n    marginal_value2 = value2_lst - (base_solution * value2_lst)\n    marginal_norm1 = marginal_value1 / (np.max(marginal_value1) + 1e-10)\n    marginal_norm2 = marginal_value2 / (np.max(marginal_value2) + 1e-10)\n\n    # Adaptive weight based on current solution's performance\n    weight_obj1 = 1.0 if current_value1 < 0.5 * max_obj1 else 0.7\n    weight_obj2 = 1.0 if current_value2 < 0.5 * max_obj2 else 0.7\n    marginal_combined = weight_obj1 * marginal_norm1 + weight_obj2 * marginal_norm2\n\n    # Sort items by combined marginal contribution\n    sorted_indices = np.argsort(-marginal_combined)\n\n    # Try to flip items with high marginal contribution\n    for idx in sorted_indices:\n        if base_solution[idx] == 1:\n            # Try to remove item\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try to add item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Additional diversification: flip one random item if no improvement\n    if np.array_equal(new_solution, base_solution):\n        candidates = [i for i in range(len(weight_lst)) if (base_solution[i] == 1 and current_weight - weight_lst[i] >= 0) or\n                     (base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if candidates:\n            idx = np.random.choice(candidates)\n            new_solution[idx] = 1 - new_solution[idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9034034519201828,
            0.4050176739692688
        ],
        "raw_score": [
            27.177010817087208,
            27.878927497500193
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest normalized objective product (balancing both objectives)\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        best_idx = 0\n    else:\n        best_idx = max(range(len(archive)), key=lambda i: (archive[i][1][0] * archive[i][1][1]) / (max_obj1 * max_obj2))\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate normalized marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    marginal_norm1 = marginal_gain1 / (np.max(marginal_gain1) + 1e-10)\n    marginal_norm2 = marginal_gain2 / (np.max(marginal_gain2) + 1e-10)\n\n    # Combine marginal gains with adaptive weights based on solution's current performance\n    weight_obj1 = 1.0 if np.sum(value1_lst[base_solution == 1]) < 0.7 * max_obj1 else 0.5\n    weight_obj2 = 1.0 if np.sum(value2_lst[base_solution == 1]) < 0.7 * max_obj2 else 0.5\n    combined_marginal = weight_obj1 * marginal_norm1 + weight_obj2 * marginal_norm2\n\n    # Sort items by combined marginal gain and attempt to flip top candidates\n    sorted_indices = np.argsort(-combined_marginal)\n    for idx in sorted_indices[:max(1, len(weight_lst)//10)]:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # If no improvement, perform a targeted swap between high-marginal and low-marginal items\n    if np.array_equal(new_solution, base_solution):\n        high_marginal = np.argsort(-combined_marginal)[:len(weight_lst)//2]\n        low_marginal = np.argsort(combined_marginal)[:len(weight_lst)//2]\n\n        for h in high_marginal:\n            for l in low_marginal:\n                if new_solution[h] == 1 and new_solution[l] == 0:\n                    new_weight = current_weight - weight_lst[h] + weight_lst[l]\n                    if new_weight <= capacity:\n                        new_solution[h], new_solution[l] = 0, 1\n                        current_weight = new_weight\n                        break\n            else:\n                continue\n            break\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8522335976313615,
            0.24278834462165833
        ],
        "raw_score": [
            27.69394350063845,
            28.12451233846662
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with high marginal gains in both objectives, then applies a hybrid local search that intelligently swaps items based on a diversity-aware value-to-weight ratio, ensuring feasibility through dynamic adjustments. It focuses on maximizing combined objective gains while considering both excluded and included items, with randomness added to promote exploration. The selection prioritizes solutions with high potential for improvement, while the local search balances exploitation of high-value items with exploration of diverse options.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with high marginal gains in each objective)\n    selected_idx = 0\n    max_marginal_gain = -1\n\n    for i, (solution, objective) in enumerate(archive):\n        excluded_items = np.where(solution == 0)[0]\n        included_items = np.where(solution == 1)[0]\n\n        # Calculate marginal gains for excluded items in each objective\n        marginal_gains1 = value1_lst[excluded_items] / weight_lst[excluded_items]\n        marginal_gains2 = value2_lst[excluded_items] / weight_lst[excluded_items]\n\n        # Calculate diversity-aware combined gain\n        combined_gain = np.sum(marginal_gains1) + np.sum(marginal_gains2) + 0.1 * len(excluded_items)\n\n        # Calculate marginal gains for included items\n        marginal_gains_included1 = value1_lst[included_items] / weight_lst[included_items]\n        marginal_gains_included2 = value2_lst[included_items] / weight_lst[included_items]\n        combined_included_gain = np.sum(marginal_gains_included1) + np.sum(marginal_gains_included2)\n\n        total_gain = combined_gain + 0.5 * combined_included_gain\n\n        if total_gain > max_marginal_gain:\n            max_marginal_gain = total_gain\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search with diversity-aware selection\n    excluded_items = np.where(new_solution == 0)[0]\n    included_items = np.where(new_solution == 1)[0]\n\n    if len(excluded_items) > 0 and len(included_items) > 0:\n        # Calculate diversity-aware value-to-weight ratio for excluded items\n        excluded_weights = weight_lst[excluded_items]\n        excluded_values = value1_lst[excluded_items] + value2_lst[excluded_items] + 0.1 * np.random.random(len(excluded_items))\n        excluded_ratios = excluded_values / excluded_weights\n\n        # Calculate value-to-weight ratio for included items\n        included_weights = weight_lst[included_items]\n        included_values = value1_lst[included_items] + value2_lst[included_items]\n        included_ratios = included_values / included_weights\n\n        # Find the best excluded item to add (considering diversity)\n        best_excluded_idx = np.argmax(excluded_ratios)\n        best_excluded = excluded_items[best_excluded_idx]\n\n        # Find the worst included item to remove (considering diversity)\n        worst_included_idx = np.argmin(included_ratios)\n        worst_included = included_items[worst_included_idx]\n\n        # Check feasibility\n        current_weight = np.sum(weight_lst[new_solution == 1])\n        new_weight = current_weight - weight_lst[worst_included] + weight_lst[best_excluded]\n\n        if new_weight <= capacity:\n            new_solution[worst_included] = 0\n            new_solution[best_excluded] = 1\n        else:\n            # If swap is infeasible, try to add the best excluded item with diversity consideration\n            excluded_sorted = sorted(excluded_items, key=lambda x: (value1_lst[x] + value2_lst[x] + 0.1 * np.random.random()) / weight_lst[x], reverse=True)\n            for item in excluded_sorted:\n                if np.sum(weight_lst[new_solution == 1]) + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                    break\n    else:\n        # If no swap possible, try to add the best excluded item with diversity consideration\n        excluded_items = np.where(new_solution == 0)[0]\n        if len(excluded_items) > 0:\n            excluded_sorted = sorted(excluded_items, key=lambda x: (value1_lst[x] + value2_lst[x] + 0.1 * np.random.random()) / weight_lst[x], reverse=True)\n            for item in excluded_sorted:\n                if np.sum(weight_lst[new_solution == 1]) + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                    break\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9513079002105604,
            1.0578568875789642
        ],
        "raw_score": [
            27.393628448397536,
            28.16672067104176
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive prioritizing those with high marginal gains in both objectives, then applies a hybrid local search that probabilistically adds, removes, or swaps items based on their marginal contributions to either objective, ensuring feasibility by checking weight constraints. It balances exploration and exploitation by favoring solutions with diverse marginal gains and intelligently navigates the Pareto front by leveraging both objectives' trade-offs.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high marginal gains in both objectives\n    selected_idx = 0\n    max_marginal_product = -1\n\n    for i, (solution, objective) in enumerate(archive):\n        current_weight = np.sum(weight_lst[solution == 1])\n        excluded_items = np.where(solution == 0)[0]\n        included_items = np.where(solution == 1)[0]\n\n        if len(excluded_items) == 0 or len(included_items) == 0:\n            continue\n\n        # Calculate marginal gains for excluded items\n        marginal_gains1 = value1_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        marginal_gains2 = value2_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        marginal_product = np.mean(marginal_gains1) * np.mean(marginal_gains2)\n\n        if marginal_product > max_marginal_product:\n            max_marginal_product = marginal_product\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: probabilistic decision between add, remove, or swap\n    excluded_items = np.where(new_solution == 0)[0]\n    included_items = np.where(new_solution == 1)[0]\n\n    if len(excluded_items) > 0 and len(included_items) > 0:\n        # Probabilistic decision: 0.4 for add, 0.3 for remove, 0.3 for swap\n        decision = random.choices(['add', 'remove', 'swap'], weights=[0.4, 0.3, 0.3])[0]\n\n        if decision == 'add':\n            # Add the best excluded item based on combined marginal gain\n            excluded_sorted = sorted(excluded_items, key=lambda x: (value1_lst[x] / (weight_lst[x] + 1e-6)) + (value2_lst[x] / (weight_lst[x] + 1e-6)), reverse=True)\n            for item in excluded_sorted:\n                if np.sum(weight_lst[new_solution == 1]) + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                    break\n\n        elif decision == 'remove':\n            # Remove the least marginal item in either objective\n            included_sorted = sorted(included_items, key=lambda x: min(value1_lst[x] / (weight_lst[x] + 1e-6), value2_lst[x] / (weight_lst[x] + 1e-6)))\n            for item in included_sorted:\n                if np.sum(weight_lst[new_solution == 1]) - weight_lst[item] >= 0:\n                    new_solution[item] = 0\n                    break\n\n        elif decision == 'swap':\n            # Swap one excluded with one included item\n            swap_excluded = random.choice(excluded_items)\n            swap_included = random.choice(included_items)\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            new_weight = current_weight - weight_lst[swap_included] + weight_lst[swap_excluded]\n            if new_weight <= capacity:\n                new_solution[swap_included] = 0\n                new_solution[swap_excluded] = 1\n\n    # If no swap possible, try to add the best excluded item\n    else:\n        excluded_items = np.where(new_solution == 0)[0]\n        if len(excluded_items) > 0:\n            excluded_sorted = sorted(excluded_items, key=lambda x: (value1_lst[x] / (weight_lst[x] + 1e-6)) + (value2_lst[x] / (weight_lst[x] + 1e-6)), reverse=True)\n            for item in excluded_sorted:\n                if np.sum(weight_lst[new_solution == 1]) + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                    break\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9510446561453485,
            1.9513874053955078
        ],
        "raw_score": [
            27.300142368173844,
            27.834733828952686
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high marginal potential by considering both objectives' gains\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate marginal gains for both objectives\n    marginal_value1 = value1_lst - (base_solution * value1_lst)\n    marginal_value2 = value2_lst - (base_solution * value2_lst)\n\n    # Adaptive weighting based on current performance\n    weight_obj1 = 1.0 if np.sum(value1_lst[base_solution == 1]) < 0.8 * max_obj1 else 0.5\n    weight_obj2 = 1.0 if np.sum(value2_lst[base_solution == 1]) < 0.8 * max_obj2 else 0.5\n\n    # Combined marginal gain with adaptive weights\n    marginal_combined = weight_obj1 * marginal_value1 + weight_obj2 * marginal_value2\n\n    # Select top 20% items with highest marginal gains\n    top_percentile = max(1, int(0.2 * len(marginal_combined)))\n    top_indices = np.argsort(-marginal_combined)[:top_percentile]\n\n    # Hybrid local search with 80% flip and 20% swap\n    if random.random() < 0.8:\n        # Flip operation: add/remove items with high marginal gains\n        for idx in top_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n    else:\n        # Swap operation: swap high marginal gain items with low marginal gain items\n        low_indices = np.argsort(marginal_combined)[:top_percentile]\n        for h in top_indices:\n            for l in low_indices:\n                if new_solution[h] == 1 and new_solution[l] == 0:\n                    new_weight = current_weight - weight_lst[h] + weight_lst[l]\n                    if new_weight <= capacity:\n                        new_solution[h], new_solution[l] = 0, 1\n                        current_weight = new_weight\n                        break\n\n    # Feasibility check: remove heaviest items if capacity exceeded\n    if np.sum(weight_lst[new_solution == 1]) > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        sorted_items = sorted(included_items, key=lambda x: -weight_lst[x])\n        for item in sorted_items:\n            if current_weight - weight_lst[item] >= 0:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n                if current_weight <= capacity:\n                    break\n\n    # Diversification: randomly flip 1-2 items to escape local optima\n    if random.random() < 0.3:\n        num_flips = random.randint(1, 2)\n        flip_indices = random.sample(range(len(new_solution)), num_flips)\n        for idx in flip_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.7882597650339057,
            0.6714142858982086
        ],
        "raw_score": [
            30.316774029950313,
            31.09020752908851
        ]
    },
    {
        "algorithm": "The algorithm selects the most promising solution from the archive using a hypervolume-based criterion (prioritizing solutions with high combined objective values), then applies a guided local search with three operations (flip, swap, and guided_flip) weighted probabilistically. It dynamically adjusts selection probabilities based on marginal contributions to each objective and ensures feasibility by always checking weight constraints. The method prioritizes high-marginal items for flips and swaps, with objective-specific adjustments in the guided_flip operation, and falls back to removing least marginal items if no improvement is found.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest hypervolume contribution\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    best_idx = max(range(len(archive)), key=lambda i: (archive[i][1][0] * archive[i][1][1]) / (max_obj1 * max_obj2 + 1e-10))\n\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate normalized marginal contributions\n    marginal_value1 = value1_lst - (base_solution * value1_lst)\n    marginal_value2 = value2_lst - (base_solution * value2_lst)\n\n    # Dynamic weight adjustment based on solution quality\n    weight_obj1 = 1.2 if np.sum(value1_lst[base_solution == 1]) < 0.7 * max_obj1 else 0.8\n    weight_obj2 = 1.2 if np.sum(value2_lst[base_solution == 1]) < 0.7 * max_obj2 else 0.8\n\n    # Combined marginal score with adaptive weights\n    marginal_combined = (weight_obj1 * marginal_value1 + weight_obj2 * marginal_value2) / (weight_obj1 + weight_obj2)\n\n    # Guided local search with probabilistic operations\n    decision = random.choices(['flip', 'swap', 'guided_flip'], weights=[0.4, 0.3, 0.3])[0]\n\n    if decision == 'flip':\n        # Flip items with highest marginal gain while maintaining feasibility\n        sorted_indices = np.argsort(-marginal_combined)\n        for idx in sorted_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    elif decision == 'swap':\n        # Swap items with high and low marginal gains\n        high_marginal = np.argsort(-marginal_combined)[:len(weight_lst)//3]\n        low_marginal = np.argsort(marginal_combined)[:len(weight_lst)//3]\n\n        for h in high_marginal:\n            for l in low_marginal:\n                if new_solution[h] == 1 and new_solution[l] == 0:\n                    new_weight = current_weight - weight_lst[h] + weight_lst[l]\n                    if new_weight <= capacity:\n                        new_solution[h], new_solution[l] = 0, 1\n                        current_weight = new_weight\n                        break\n            else:\n                continue\n            break\n\n    else:  # guided_flip\n        # Flip items based on objective-specific marginal gains\n        obj1_candidates = np.argsort(-marginal_value1)[:len(weight_lst)//4]\n        obj2_candidates = np.argsort(-marginal_value2)[:len(weight_lst)//4]\n\n        for idx in np.concatenate([obj1_candidates, obj2_candidates]):\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # If no improvement, remove least marginal items to ensure feasibility\n    if np.array_equal(new_solution, base_solution):\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            sorted_items = sorted(included_items, key=lambda x: min(marginal_value1[x], marginal_value2[x]))\n            for item in sorted_items:\n                if current_weight - weight_lst[item] >= 0:\n                    new_solution[item] = 0\n                    current_weight -= weight_lst[item]\n                    break\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8617243089804432,
            0.820658415555954
        ],
        "raw_score": [
            27.337848235038035,
            28.164325090675362
        ]
    }
]