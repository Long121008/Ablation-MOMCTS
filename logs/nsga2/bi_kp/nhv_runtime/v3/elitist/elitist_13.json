[
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a novel combination of objective contribution and solution sparsity, then applies a multi-stage local search that alternates between value-aware item swaps and capacity-constrained diversification, while dynamically balancing the exploration of both objective spaces.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Selection based on objective contribution and sparsity\n    selection_scores = []\n    for sol, obj in archive:\n        # Calculate objective contributions\n        contrib1 = obj[0] / np.sum(value1_lst * sol) if np.sum(sol) > 0 else 0\n        contrib2 = obj[1] / np.sum(value2_lst * sol) if np.sum(sol) > 0 else 0\n        # Calculate sparsity (proportion of excluded items)\n        sparsity = np.sum(sol == 0) / len(sol)\n        # Combined score\n        selection_scores.append((contrib1 + contrib2) * sparsity)\n\n    selected_idx = np.argmax(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-stage local search\n    n_items = len(weight_lst)\n\n    # Stage 1: Value-aware swaps\n    for _ in range(3):\n        # Calculate combined value-to-weight ratios\n        ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        # Find top and bottom items\n        top_items = np.argsort(ratios)[-min(3, n_items):]\n        bottom_items = np.argsort(ratios)[:min(3, n_items)]\n\n        for i in top_items:\n            for j in bottom_items:\n                if new_solution[i] == 1 and new_solution[j] == 0:\n                    delta_weight = weight_lst[j] - weight_lst[i]\n                    if current_weight + delta_weight <= capacity:\n                        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                        current_weight += delta_weight\n                        break\n\n    # Stage 2: Capacity-constrained diversification\n    if current_weight < capacity * 0.7:\n        # Add low-weight items with high potential\n        candidate_items = np.where(new_solution == 0)[0]\n        candidate_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        candidate_ratios[candidate_items] *= (capacity - current_weight) / capacity\n        top_candidates = np.argsort(-candidate_ratios)[:min(5, len(candidate_items))]\n\n        for i in top_candidates:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Stage 3: Objective-balanced adjustments\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n\n    if abs(total_value1 - total_value2) > 0.1 * (total_value1 + total_value2):\n        # Balance objectives by swapping items\n        if total_value1 > total_value2:\n            # Replace high-value1 items with better value2 alternatives\n            high_value1_items = np.where((new_solution == 1) & (value1_lst > value2_lst))[0]\n            if len(high_value1_items) > 0:\n                best_candidate = None\n                max_improvement = 0\n                for i in high_value1_items:\n                    for j in np.where(new_solution == 0)[0]:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            improvement = (value2_lst[j] - value1_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-6)\n                            if improvement > max_improvement:\n                                max_improvement = improvement\n                                best_candidate = (i, j)\n                if best_candidate:\n                    i, j = best_candidate\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        else:\n            # Replace high-value2 items with better value1 alternatives\n            high_value2_items = np.where((new_solution == 1) & (value2_lst > value1_lst))[0]\n            if len(high_value2_items) > 0:\n                best_candidate = None\n                max_improvement = 0\n                for i in high_value2_items:\n                    for j in np.where(new_solution == 0)[0]:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            improvement = (value1_lst[j] - value2_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-6)\n                            if improvement > max_improvement:\n                                max_improvement = improvement\n                                best_candidate = (i, j)\n                if best_candidate:\n                    i, j = best_candidate\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.9824145934822279,
            10.431624859571457
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a novel combination of objective contribution and solution sparsity, then applies a multi-stage local search that alternates between value-aware item swaps and capacity-constrained diversification, while dynamically balancing the exploration of both objective spaces.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Selection based on objective contribution and sparsity\n    selection_scores = []\n    for sol, obj in archive:\n        # Calculate objective contributions\n        contrib1 = obj[0] / np.sum(value1_lst * sol) if np.sum(sol) > 0 else 0\n        contrib2 = obj[1] / np.sum(value2_lst * sol) if np.sum(sol) > 0 else 0\n        # Calculate sparsity (proportion of excluded items)\n        sparsity = np.sum(sol == 0) / len(sol)\n        # Combined score\n        selection_scores.append((contrib1 + contrib2) * sparsity)\n\n    selected_idx = np.argmax(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-stage local search\n    n_items = len(weight_lst)\n\n    # Stage 1: Value-aware swaps\n    for _ in range(3):\n        # Calculate combined value-to-weight ratios\n        ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        # Find top and bottom items\n        top_items = np.argsort(ratios)[-min(3, n_items):]\n        bottom_items = np.argsort(ratios)[:min(3, n_items)]\n\n        for i in top_items:\n            for j in bottom_items:\n                if new_solution[i] == 1 and new_solution[j] == 0:\n                    delta_weight = weight_lst[j] - weight_lst[i]\n                    if current_weight + delta_weight <= capacity:\n                        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                        current_weight += delta_weight\n                        break\n\n    # Stage 2: Capacity-constrained diversification\n    if current_weight < capacity * 0.7:\n        # Add low-weight items with high potential\n        candidate_items = np.where(new_solution == 0)[0]\n        candidate_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        candidate_ratios[candidate_items] *= (capacity - current_weight) / capacity\n        top_candidates = np.argsort(-candidate_ratios)[:min(5, len(candidate_items))]\n\n        for i in top_candidates:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Stage 3: Objective-balanced adjustments\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n\n    if abs(total_value1 - total_value2) > 0.1 * (total_value1 + total_value2):\n        # Balance objectives by swapping items\n        if total_value1 > total_value2:\n            # Replace high-value1 items with better value2 alternatives\n            high_value1_items = np.where((new_solution == 1) & (value1_lst > value2_lst))[0]\n            if len(high_value1_items) > 0:\n                best_candidate = None\n                max_improvement = 0\n                for i in high_value1_items:\n                    for j in np.where(new_solution == 0)[0]:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            improvement = (value2_lst[j] - value1_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-6)\n                            if improvement > max_improvement:\n                                max_improvement = improvement\n                                best_candidate = (i, j)\n                if best_candidate:\n                    i, j = best_candidate\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        else:\n            # Replace high-value2 items with better value1 alternatives\n            high_value2_items = np.where((new_solution == 1) & (value2_lst > value1_lst))[0]\n            if len(high_value2_items) > 0:\n                best_candidate = None\n                max_improvement = 0\n                for i in high_value2_items:\n                    for j in np.where(new_solution == 0)[0]:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            improvement = (value1_lst[j] - value2_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-6)\n                            if improvement > max_improvement:\n                                max_improvement = improvement\n                                best_candidate = (i, j)\n                if best_candidate:\n                    i, j = best_candidate\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.9824145934822279,
            10.431624859571457
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a novel combination of objective balance and solution diversity, then applies a multi-phase local search that alternates between value-aware item additions/removals and capacity-constrained diversification, while dynamically balancing the exploration of both objective spaces through probabilistic selection and value-weighted adjustments.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Selection based on objective balance and diversity\n    balance_scores = []\n    for sol, obj in archive:\n        balance = abs(obj[0] - obj[1]) / (obj[0] + obj[1] + 1e-6)\n        diversity = np.sum(sol) / len(sol)\n        balance_scores.append(balance * (1 - diversity))\n\n    selected_idx = np.argmax(balance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Value-aware item additions\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        value_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        sorted_additions = np.argsort(-value_ratios[excluded_items])\n        for i in sorted_additions[:min(5, len(excluded_items))]:\n            if (current_weight + weight_lst[excluded_items[i]]) <= capacity:\n                new_solution[excluded_items[i]] = 1\n                current_weight += weight_lst[excluded_items[i]]\n\n    # Phase 2: Capacity-constrained diversification\n    if current_weight < capacity * 0.8:\n        candidate_items = np.where(new_solution == 0)[0]\n        if len(candidate_items) > 0:\n            probs = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            probs = probs[candidate_items] * ((capacity - current_weight) / capacity)\n            probs = probs / np.sum(probs)\n            selected_items = np.random.choice(candidate_items, size=min(3, len(candidate_items)), p=probs, replace=False)\n            for i in selected_items:\n                if (current_weight + weight_lst[i]) <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Phase 3: Objective-balanced removals\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n    if abs(total_value1 - total_value2) > 0.2 * (total_value1 + total_value2):\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 1:\n            if total_value1 > total_value2:\n                # Remove items with highest value1 contribution\n                value1_contribs = value1_lst[included_items] / (weight_lst[included_items] + 1e-6)\n                sorted_removals = np.argsort(-value1_contribs)\n                for i in sorted_removals[:min(2, len(included_items))]:\n                    new_solution[included_items[i]] = 0\n            else:\n                # Remove items with highest value2 contribution\n                value2_contribs = value2_lst[included_items] / (weight_lst[included_items] + 1e-6)\n                sorted_removals = np.argsort(-value2_contribs)\n                for i in sorted_removals[:min(2, len(included_items))]:\n                    new_solution[included_items[i]] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9049372858478895,
            2.932841807603836
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a novel combination of objective contribution and solution sparsity, then applies a multi-stage local search that alternates between value-aware item swaps and capacity-constrained diversification, while dynamically balancing the exploration of both objective spaces.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Selection based on objective contribution and sparsity\n    selection_scores = []\n    for sol, obj in archive:\n        # Calculate objective contributions\n        contrib1 = obj[0] / np.sum(value1_lst * sol) if np.sum(sol) > 0 else 0\n        contrib2 = obj[1] / np.sum(value2_lst * sol) if np.sum(sol) > 0 else 0\n        # Calculate sparsity (proportion of excluded items)\n        sparsity = np.sum(sol == 0) / len(sol)\n        # Combined score\n        selection_scores.append((contrib1 + contrib2) * sparsity)\n\n    selected_idx = np.argmax(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-stage local search\n    n_items = len(weight_lst)\n\n    # Stage 1: Value-aware swaps\n    for _ in range(3):\n        # Calculate combined value-to-weight ratios\n        ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        # Find top and bottom items\n        top_items = np.argsort(ratios)[-min(3, n_items):]\n        bottom_items = np.argsort(ratios)[:min(3, n_items)]\n\n        for i in top_items:\n            for j in bottom_items:\n                if new_solution[i] == 1 and new_solution[j] == 0:\n                    delta_weight = weight_lst[j] - weight_lst[i]\n                    if current_weight + delta_weight <= capacity:\n                        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                        current_weight += delta_weight\n                        break\n\n    # Stage 2: Capacity-constrained diversification\n    if current_weight < capacity * 0.7:\n        # Add low-weight items with high potential\n        candidate_items = np.where(new_solution == 0)[0]\n        candidate_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        candidate_ratios[candidate_items] *= (capacity - current_weight) / capacity\n        top_candidates = np.argsort(-candidate_ratios)[:min(5, len(candidate_items))]\n\n        for i in top_candidates:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Stage 3: Objective-balanced adjustments\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n\n    if abs(total_value1 - total_value2) > 0.1 * (total_value1 + total_value2):\n        # Balance objectives by swapping items\n        if total_value1 > total_value2:\n            # Replace high-value1 items with better value2 alternatives\n            high_value1_items = np.where((new_solution == 1) & (value1_lst > value2_lst))[0]\n            if len(high_value1_items) > 0:\n                best_candidate = None\n                max_improvement = 0\n                for i in high_value1_items:\n                    for j in np.where(new_solution == 0)[0]:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            improvement = (value2_lst[j] - value1_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-6)\n                            if improvement > max_improvement:\n                                max_improvement = improvement\n                                best_candidate = (i, j)\n                if best_candidate:\n                    i, j = best_candidate\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        else:\n            # Replace high-value2 items with better value1 alternatives\n            high_value2_items = np.where((new_solution == 1) & (value2_lst > value1_lst))[0]\n            if len(high_value2_items) > 0:\n                best_candidate = None\n                max_improvement = 0\n                for i in high_value2_items:\n                    for j in np.where(new_solution == 0)[0]:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            improvement = (value1_lst[j] - value2_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-6)\n                            if improvement > max_improvement:\n                                max_improvement = improvement\n                                best_candidate = (i, j)\n                if best_candidate:\n                    i, j = best_candidate\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.9824145934822279,
            10.431624859571457
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a dynamic combination of objective dominance and solution density, then applies a hybrid local search that combines value-weighted item swaps with capacity-aware diversification, while adaptively balancing the exploration of both objective spaces through a novel two-phase optimization process.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Selection based on objective dominance and solution density\n    selection_scores = []\n    for sol, obj in archive:\n        # Calculate objective dominance\n        dominance_score = (obj[0] + obj[1]) / (np.sum(value1_lst * sol) + np.sum(value2_lst * sol) + 1e-6)\n        # Calculate solution density\n        density = np.sum(sol) / len(sol)\n        # Combined score\n        selection_scores.append(dominance_score * (1 - density))\n\n    selected_idx = np.argmax(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Value-weighted item swaps\n    for _ in range(2):\n        # Calculate weighted value ratios\n        weighted_ratios = (0.6 * value1_lst + 0.4 * value2_lst) / (weight_lst + 1e-6)\n        # Find top and bottom items\n        top_items = np.argsort(weighted_ratios)[-min(4, len(weight_lst)):]\n        bottom_items = np.argsort(weighted_ratios)[:min(4, len(weight_lst))]\n\n        for i in top_items:\n            for j in bottom_items:\n                if new_solution[i] == 1 and new_solution[j] == 0:\n                    delta_weight = weight_lst[j] - weight_lst[i]\n                    if current_weight + delta_weight <= capacity:\n                        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                        current_weight += delta_weight\n                        break\n\n    # Phase 2: Capacity-aware diversification\n    if current_weight < capacity * 0.8:\n        # Add items with high value-weight ratio and low correlation\n        candidate_items = np.where(new_solution == 0)[0]\n        if len(candidate_items) > 0:\n            # Calculate value-weight ratio\n            ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            # Calculate correlation with current solution\n            current_vector = np.concatenate([value1_lst * new_solution, value2_lst * new_solution])\n            candidate_vectors = np.array([np.concatenate([value1_lst[i] * np.ones_like(new_solution),\n                                                         value2_lst[i] * np.ones_like(new_solution)])\n                                        for i in candidate_items])\n            correlations = np.array([np.corrcoef(current_vector, vec)[0,1] if len(np.unique(vec)) > 1 else 0\n                                   for vec in candidate_vectors])\n            # Combine metrics\n            combined_scores = ratios[candidate_items] * (1 - np.abs(correlations))\n            top_candidates = np.argsort(-combined_scores)[:min(3, len(candidate_items))]\n\n            for i in candidate_items[top_candidates]:\n                if (current_weight + weight_lst[i]) <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Final adjustment for objective balance\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n\n    if abs(total_value1 - total_value2) > 0.15 * (total_value1 + total_value2):\n        # Swap items to balance objectives\n        if total_value1 > total_value2:\n            # Find items that can improve value2\n            candidate_items = np.where((new_solution == 0) &\n                                     ((value2_lst - value1_lst) > 0))[0]\n        else:\n            # Find items that can improve value1\n            candidate_items = np.where((new_solution == 0) &\n                                     ((value1_lst - value2_lst) > 0))[0]\n\n        if len(candidate_items) > 0:\n            # Select best candidate based on potential improvement\n            improvements = (value1_lst[candidate_items] - value2_lst[candidate_items]) if total_value1 > total_value2 else (value2_lst[candidate_items] - value1_lst[candidate_items])\n            best_candidate = candidate_items[np.argmax(improvements)]\n\n            # Find item to remove to make space\n            current_items = np.where(new_solution == 1)[0]\n            if len(current_items) > 0:\n                # Prefer removing items that least contribute to the weaker objective\n                if total_value1 > total_value2:\n                    remove_scores = value2_lst[current_items]\n                else:\n                    remove_scores = value1_lst[current_items]\n                item_to_remove = current_items[np.argmin(remove_scores)]\n\n                if (current_weight - weight_lst[item_to_remove] + weight_lst[best_candidate]) <= capacity:\n                    new_solution[item_to_remove] = 0\n                    new_solution[best_candidate] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.9349455846426595,
            6.8422587513923645
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a novel combination of objective contribution and solution sparsity, then applies a multi-stage local search that alternates between value-aware item swaps and capacity-constrained diversification, while dynamically balancing the exploration of both objective spaces.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Selection based on objective contribution and sparsity\n    selection_scores = []\n    for sol, obj in archive:\n        # Calculate objective contributions\n        contrib1 = obj[0] / (np.sum(value1_lst * sol) + 1e-6)\n        contrib2 = obj[1] / (np.sum(value2_lst * sol) + 1e-6)\n        # Calculate sparsity (proportion of excluded items)\n        sparsity = np.sum(sol == 0) / len(sol)\n        # Combined score\n        selection_scores.append((contrib1 + contrib2) * sparsity)\n\n    selected_idx = np.argmax(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-stage local search\n    n_items = len(weight_lst)\n\n    # Stage 1: Adaptive item selection based on value and weight balance\n    for _ in range(5):\n        # Calculate combined value-to-weight ratios with adaptive weights\n        alpha = np.random.uniform(0.3, 0.7)  # Random weight for objective balance\n        ratios = (alpha * value1_lst + (1 - alpha) * value2_lst) / (weight_lst + 1e-6)\n\n        # Find top and bottom items with adaptive selection\n        top_items = np.argsort(ratios)[-min(5, n_items):]\n        bottom_items = np.argsort(ratios)[:min(5, n_items)]\n\n        for i in top_items:\n            for j in bottom_items:\n                if new_solution[i] == 1 and new_solution[j] == 0:\n                    delta_weight = weight_lst[j] - weight_lst[i]\n                    if current_weight + delta_weight <= capacity:\n                        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                        current_weight += delta_weight\n                        break\n\n    # Stage 2: Capacity-aware item addition with diversity\n    if current_weight < capacity * 0.8:\n        # Calculate diversity scores for excluded items\n        diversity_scores = np.zeros(n_items)\n        for i in range(n_items):\n            if new_solution[i] == 0:\n                # Measure how different this item is from current solution\n                diversity = np.sum(np.abs(new_solution - (base_solution == 1)))\n                diversity_scores[i] = diversity * (value1_lst[i] + value2_lst[i]) / (weight_lst[i] + 1e-6)\n\n        top_diverse = np.argsort(-diversity_scores)[:min(3, n_items)]\n        for i in top_diverse:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Stage 3: Objective-balanced fine-tuning\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n\n    if abs(total_value1 - total_value2) > 0.15 * (total_value1 + total_value2):\n        # Balance objectives by considering both value improvements and weight changes\n        if total_value1 > total_value2:\n            # Look for items that improve value2 more than they reduce value1\n            improvement_scores = np.zeros(n_items)\n            for i in range(n_items):\n                if new_solution[i] == 1:\n                    # Potential improvement if removed\n                    improvement_scores[i] = (value2_lst[i] - value1_lst[i]) / (weight_lst[i] + 1e-6)\n                else:\n                    # Potential improvement if added\n                    if (current_weight + weight_lst[i]) <= capacity:\n                        improvement_scores[i] = (value1_lst[i] - value2_lst[i]) / (weight_lst[i] + 1e-6)\n\n            # Find best candidates for swap or addition\n            candidates = np.argsort(-improvement_scores)[:min(3, n_items)]\n            for i in candidates:\n                if new_solution[i] == 1:\n                    # Try to remove this item\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                else:\n                    # Try to add this item\n                    if (current_weight + weight_lst[i]) <= capacity:\n                        new_solution[i] = 1\n                        current_weight += weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.962897846355743,
            10.018062800168991
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a novel combination of objective contribution and solution sparsity, then applies a multi-stage local search that alternates between value-aware item swaps and capacity-constrained diversification, while dynamically balancing the exploration of both objective spaces.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Selection based on objective contribution and sparsity\n    selection_scores = []\n    for sol, obj in archive:\n        # Calculate objective contributions\n        contrib1 = obj[0] / np.sum(value1_lst * sol) if np.sum(sol) > 0 else 0\n        contrib2 = obj[1] / np.sum(value2_lst * sol) if np.sum(sol) > 0 else 0\n        # Calculate sparsity (proportion of excluded items)\n        sparsity = np.sum(sol == 0) / len(sol)\n        # Combined score\n        selection_scores.append((contrib1 + contrib2) * sparsity)\n\n    selected_idx = np.argmax(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-stage local search\n    n_items = len(weight_lst)\n\n    # Stage 1: Value-aware swaps\n    for _ in range(3):\n        # Calculate combined value-to-weight ratios\n        ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        # Find top and bottom items\n        top_items = np.argsort(ratios)[-min(3, n_items):]\n        bottom_items = np.argsort(ratios)[:min(3, n_items)]\n\n        for i in top_items:\n            for j in bottom_items:\n                if new_solution[i] == 1 and new_solution[j] == 0:\n                    delta_weight = weight_lst[j] - weight_lst[i]\n                    if current_weight + delta_weight <= capacity:\n                        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                        current_weight += delta_weight\n                        break\n\n    # Stage 2: Capacity-constrained diversification\n    if current_weight < capacity * 0.7:\n        # Add low-weight items with high potential\n        candidate_items = np.where(new_solution == 0)[0]\n        candidate_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        candidate_ratios[candidate_items] *= (capacity - current_weight) / capacity\n        top_candidates = np.argsort(-candidate_ratios)[:min(5, len(candidate_items))]\n\n        for i in top_candidates:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Stage 3: Objective-balanced adjustments\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n\n    if abs(total_value1 - total_value2) > 0.1 * (total_value1 + total_value2):\n        # Balance objectives by swapping items\n        if total_value1 > total_value2:\n            # Replace high-value1 items with better value2 alternatives\n            high_value1_items = np.where((new_solution == 1) & (value1_lst > value2_lst))[0]\n            if len(high_value1_items) > 0:\n                best_candidate = None\n                max_improvement = 0\n                for i in high_value1_items:\n                    for j in np.where(new_solution == 0)[0]:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            improvement = (value2_lst[j] - value1_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-6)\n                            if improvement > max_improvement:\n                                max_improvement = improvement\n                                best_candidate = (i, j)\n                if best_candidate:\n                    i, j = best_candidate\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        else:\n            # Replace high-value2 items with better value1 alternatives\n            high_value2_items = np.where((new_solution == 1) & (value2_lst > value1_lst))[0]\n            if len(high_value2_items) > 0:\n                best_candidate = None\n                max_improvement = 0\n                for i in high_value2_items:\n                    for j in np.where(new_solution == 0)[0]:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            improvement = (value1_lst[j] - value2_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-6)\n                            if improvement > max_improvement:\n                                max_improvement = improvement\n                                best_candidate = (i, j)\n                if best_candidate:\n                    i, j = best_candidate\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.9824145934822279,
            10.431624859571457
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a novel combination of objective dominance and solution density, then applies a hybrid local search that combines value-aware clustering and capacity-constrained path optimization, while dynamically balancing the exploration of both objective spaces through a multi-phase neighborhood exploration strategy.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Selection based on objective dominance and density\n    selection_scores = []\n    for sol, obj in archive:\n        # Calculate objective dominance\n        dominance = (obj[0] * obj[1]) / (np.sum(value1_lst * sol) * np.sum(value2_lst * sol) + 1e-6) if np.sum(sol) > 0 else 0\n        # Calculate density (proportion of included items)\n        density = np.sum(sol) / len(sol)\n        # Combined score\n        selection_scores.append(dominance * (1 - density))\n\n    selected_idx = np.argmax(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search\n    n_items = len(weight_lst)\n\n    # Phase 1: Value-aware clustering\n    cluster_centers = []\n    for _ in range(3):\n        # Select random items as cluster centers\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) == 0:\n            break\n        center = np.random.choice(candidates)\n        cluster_centers.append(center)\n\n    for center in cluster_centers:\n        # Find items similar to the cluster center\n        value_similarity = (value1_lst * value1_lst[center] + value2_lst * value2_lst[center]) / (value1_lst[center]**2 + value2_lst[center]**2 + 1e-6)\n        similar_items = np.argsort(-value_similarity)[:min(5, n_items)]\n\n        for i in similar_items:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Phase 2: Capacity-constrained path optimization\n    if current_weight < capacity * 0.9:\n        # Find the most efficient path for remaining capacity\n        remaining_capacity = capacity - current_weight\n        efficiency = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        sorted_indices = np.argsort(-efficiency)\n\n        for i in sorted_indices:\n            if new_solution[i] == 0 and weight_lst[i] <= remaining_capacity:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n                if remaining_capacity <= 0:\n                    break\n\n    # Phase 3: Objective-balanced refinement\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n\n    if abs(total_value1 - total_value2) > 0.2 * (total_value1 + total_value2):\n        # Balance objectives by adjusting item selection\n        if total_value1 > total_value2:\n            # Remove items that contribute more to value1\n            excess_items = np.where((new_solution == 1) & (value1_lst > value2_lst))[0]\n            if len(excess_items) > 0:\n                for i in np.random.permutation(excess_items):\n                    if np.sum(weight_lst * new_solution) - weight_lst[i] >= 0:\n                        new_solution[i] = 0\n                        break\n        else:\n            # Remove items that contribute more to value2\n            excess_items = np.where((new_solution == 1) & (value2_lst > value1_lst))[0]\n            if len(excess_items) > 0:\n                for i in np.random.permutation(excess_items):\n                    if np.sum(weight_lst * new_solution) - weight_lst[i] >= 0:\n                        new_solution[i] = 0\n                        break\n\n    return new_solution\n\n",
        "score": [
            -0.9498231759238386,
            9.89250361919403
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a combination of objective dominance and solution density, then applies a hybrid local search that alternates between value-aware flips and capacity-aware diversification, while dynamically adjusting the search focus between the two objectives.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Selection based on objective dominance and solution density\n    selection_scores = []\n    for sol, obj in archive:\n        # Calculate objective dominance\n        dom_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] > obj[0] and other_obj[1] >= obj[1]) or (other_obj[0] >= obj[0] and other_obj[1] > obj[1]):\n                dom_count += 1\n        # Calculate solution density\n        density = np.sum(sol) / len(sol)\n        # Combined score\n        selection_scores.append(dom_count / (density + 1e-6))\n\n    selected_idx = np.argmax(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search\n    n_items = len(weight_lst)\n\n    # Stage 1: Value-aware flips\n    for _ in range(2):\n        # Calculate combined value-to-weight ratios\n        ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        # Find top items to flip\n        top_items = np.argsort(ratios)[-min(5, n_items):]\n\n        for i in top_items:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n            elif new_solution[i] == 1 and (current_weight - weight_lst[i]) >= 0:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n\n    # Stage 2: Capacity-aware diversification\n    if current_weight < capacity * 0.8:\n        # Add low-weight items with high potential\n        candidate_items = np.where(new_solution == 0)[0]\n        candidate_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        candidate_ratios[candidate_items] *= (capacity - current_weight) / capacity\n        top_candidates = np.argsort(-candidate_ratios)[:min(3, len(candidate_items))]\n\n        for i in top_candidates:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Stage 3: Objective-balanced flips\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n\n    if abs(total_value1 - total_value2) > 0.2 * (total_value1 + total_value2):\n        # Flip items to balance objectives\n        if total_value1 > total_value2:\n            # Remove high-value1 items and add high-value2 items\n            high_value1_items = np.where((new_solution == 1) & (value1_lst > value2_lst))[0]\n            low_value1_items = np.where((new_solution == 0) & (value2_lst > value1_lst))[0]\n\n            if len(high_value1_items) > 0 and len(low_value1_items) > 0:\n                best_candidate = None\n                max_improvement = 0\n                for i in high_value1_items:\n                    for j in low_value1_items:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            improvement = (value2_lst[j] - value1_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-6)\n                            if improvement > max_improvement:\n                                max_improvement = improvement\n                                best_candidate = (i, j)\n                if best_candidate:\n                    i, j = best_candidate\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        else:\n            # Remove high-value2 items and add high-value1 items\n            high_value2_items = np.where((new_solution == 1) & (value2_lst > value1_lst))[0]\n            low_value2_items = np.where((new_solution == 0) & (value1_lst > value2_lst))[0]\n\n            if len(high_value2_items) > 0 and len(low_value2_items) > 0:\n                best_candidate = None\n                max_improvement = 0\n                for i in high_value2_items:\n                    for j in low_value2_items:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            improvement = (value1_lst[j] - value2_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-6)\n                            if improvement > max_improvement:\n                                max_improvement = improvement\n                                best_candidate = (i, j)\n                if best_candidate:\n                    i, j = best_candidate\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.9063153774559203,
            3.568933665752411
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a novel combination of objective contribution and solution sparsity, then applies a multi-stage local search that alternates between value-aware item swaps and capacity-constrained diversification, while dynamically balancing the exploration of both objective spaces.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Selection based on objective contribution and sparsity\n    selection_scores = []\n    for sol, obj in archive:\n        # Calculate objective contributions\n        contrib1 = obj[0] / np.sum(value1_lst * sol) if np.sum(sol) > 0 else 0\n        contrib2 = obj[1] / np.sum(value2_lst * sol) if np.sum(sol) > 0 else 0\n        # Calculate sparsity (proportion of excluded items)\n        sparsity = np.sum(sol == 0) / len(sol)\n        # Combined score\n        selection_scores.append((contrib1 + contrib2) * sparsity)\n\n    selected_idx = np.argmax(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-stage local search\n    n_items = len(weight_lst)\n\n    # Stage 1: Value-aware swaps\n    for _ in range(3):\n        # Calculate combined value-to-weight ratios\n        ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        # Find top and bottom items\n        top_items = np.argsort(ratios)[-min(3, n_items):]\n        bottom_items = np.argsort(ratios)[:min(3, n_items)]\n\n        for i in top_items:\n            for j in bottom_items:\n                if new_solution[i] == 1 and new_solution[j] == 0:\n                    delta_weight = weight_lst[j] - weight_lst[i]\n                    if current_weight + delta_weight <= capacity:\n                        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                        current_weight += delta_weight\n                        break\n\n    # Stage 2: Capacity-constrained diversification\n    if current_weight < capacity * 0.7:\n        # Add low-weight items with high potential\n        candidate_items = np.where(new_solution == 0)[0]\n        candidate_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        candidate_ratios[candidate_items] *= (capacity - current_weight) / capacity\n        top_candidates = np.argsort(-candidate_ratios)[:min(5, len(candidate_items))]\n\n        for i in top_candidates:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Stage 3: Objective-balanced adjustments\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n\n    if abs(total_value1 - total_value2) > 0.1 * (total_value1 + total_value2):\n        # Balance objectives by swapping items\n        if total_value1 > total_value2:\n            # Replace high-value1 items with better value2 alternatives\n            high_value1_items = np.where((new_solution == 1) & (value1_lst > value2_lst))[0]\n            if len(high_value1_items) > 0:\n                best_candidate = None\n                max_improvement = 0\n                for i in high_value1_items:\n                    for j in np.where(new_solution == 0)[0]:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            improvement = (value2_lst[j] - value1_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-6)\n                            if improvement > max_improvement:\n                                max_improvement = improvement\n                                best_candidate = (i, j)\n                if best_candidate:\n                    i, j = best_candidate\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        else:\n            # Replace high-value2 items with better value1 alternatives\n            high_value2_items = np.where((new_solution == 1) & (value2_lst > value1_lst))[0]\n            if len(high_value2_items) > 0:\n                best_candidate = None\n                max_improvement = 0\n                for i in high_value2_items:\n                    for j in np.where(new_solution == 0)[0]:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            improvement = (value1_lst[j] - value2_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-6)\n                            if improvement > max_improvement:\n                                max_improvement = improvement\n                                best_candidate = (i, j)\n                if best_candidate:\n                    i, j = best_candidate\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.9824145934822279,
            10.431624859571457
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a novel combination of objective contribution and solution sparsity, then applies a multi-stage local search that alternates between value-aware item swaps and capacity-constrained diversification, while dynamically balancing the exploration of both objective spaces.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Selection based on objective contribution and sparsity\n    selection_scores = []\n    for sol, obj in archive:\n        # Calculate objective contributions\n        contrib1 = obj[0] / np.sum(value1_lst * sol) if np.sum(sol) > 0 else 0\n        contrib2 = obj[1] / np.sum(value2_lst * sol) if np.sum(sol) > 0 else 0\n        # Calculate sparsity (proportion of excluded items)\n        sparsity = np.sum(sol == 0) / len(sol)\n        # Combined score\n        selection_scores.append((contrib1 + contrib2) * sparsity)\n\n    selected_idx = np.argmax(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-stage local search\n    n_items = len(weight_lst)\n\n    # Stage 1: Value-aware swaps\n    for _ in range(3):\n        # Calculate combined value-to-weight ratios\n        ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        # Find top and bottom items\n        top_items = np.argsort(ratios)[-min(3, n_items):]\n        bottom_items = np.argsort(ratios)[:min(3, n_items)]\n\n        for i in top_items:\n            for j in bottom_items:\n                if new_solution[i] == 1 and new_solution[j] == 0:\n                    delta_weight = weight_lst[j] - weight_lst[i]\n                    if current_weight + delta_weight <= capacity:\n                        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                        current_weight += delta_weight\n                        break\n\n    # Stage 2: Capacity-constrained diversification\n    if current_weight < capacity * 0.7:\n        # Add low-weight items with high potential\n        candidate_items = np.where(new_solution == 0)[0]\n        candidate_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        candidate_ratios[candidate_items] *= (capacity - current_weight) / capacity\n        top_candidates = np.argsort(-candidate_ratios)[:min(5, len(candidate_items))]\n\n        for i in top_candidates:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Stage 3: Objective-balanced adjustments\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n\n    if abs(total_value1 - total_value2) > 0.1 * (total_value1 + total_value2):\n        # Balance objectives by swapping items\n        if total_value1 > total_value2:\n            # Replace high-value1 items with better value2 alternatives\n            high_value1_items = np.where((new_solution == 1) & (value1_lst > value2_lst))[0]\n            if len(high_value1_items) > 0:\n                best_candidate = None\n                max_improvement = 0\n                for i in high_value1_items:\n                    for j in np.where(new_solution == 0)[0]:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            improvement = (value2_lst[j] - value1_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-6)\n                            if improvement > max_improvement:\n                                max_improvement = improvement\n                                best_candidate = (i, j)\n                if best_candidate:\n                    i, j = best_candidate\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        else:\n            # Replace high-value2 items with better value1 alternatives\n            high_value2_items = np.where((new_solution == 1) & (value2_lst > value1_lst))[0]\n            if len(high_value2_items) > 0:\n                best_candidate = None\n                max_improvement = 0\n                for i in high_value2_items:\n                    for j in np.where(new_solution == 0)[0]:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            improvement = (value1_lst[j] - value2_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-6)\n                            if improvement > max_improvement:\n                                max_improvement = improvement\n                                best_candidate = (i, j)\n                if best_candidate:\n                    i, j = best_candidate\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.9824145934822279,
            10.431624859571457
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a novel combination of objective contribution and solution sparsity, then applies a multi-stage local search that alternates between value-aware item swaps and capacity-constrained diversification, while dynamically balancing the exploration of both objective spaces.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Selection based on objective contribution and sparsity\n    selection_scores = []\n    for sol, obj in archive:\n        # Calculate objective contributions\n        contrib1 = obj[0] / np.sum(value1_lst * sol) if np.sum(sol) > 0 else 0\n        contrib2 = obj[1] / np.sum(value2_lst * sol) if np.sum(sol) > 0 else 0\n        # Calculate sparsity (proportion of excluded items)\n        sparsity = np.sum(sol == 0) / len(sol)\n        # Combined score\n        selection_scores.append((contrib1 + contrib2) * sparsity)\n\n    selected_idx = np.argmax(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-stage local search\n    n_items = len(weight_lst)\n\n    # Stage 1: Value-aware swaps\n    for _ in range(3):\n        # Calculate combined value-to-weight ratios\n        ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        # Find top and bottom items\n        top_items = np.argsort(ratios)[-min(3, n_items):]\n        bottom_items = np.argsort(ratios)[:min(3, n_items)]\n\n        for i in top_items:\n            for j in bottom_items:\n                if new_solution[i] == 1 and new_solution[j] == 0:\n                    delta_weight = weight_lst[j] - weight_lst[i]\n                    if current_weight + delta_weight <= capacity:\n                        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                        current_weight += delta_weight\n                        break\n\n    # Stage 2: Capacity-constrained diversification\n    if current_weight < capacity * 0.7:\n        # Add low-weight items with high potential\n        candidate_items = np.where(new_solution == 0)[0]\n        candidate_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        candidate_ratios[candidate_items] *= (capacity - current_weight) / capacity\n        top_candidates = np.argsort(-candidate_ratios)[:min(5, len(candidate_items))]\n\n        for i in top_candidates:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Stage 3: Objective-balanced adjustments\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n\n    if abs(total_value1 - total_value2) > 0.1 * (total_value1 + total_value2):\n        # Balance objectives by swapping items\n        if total_value1 > total_value2:\n            # Replace high-value1 items with better value2 alternatives\n            high_value1_items = np.where((new_solution == 1) & (value1_lst > value2_lst))[0]\n            if len(high_value1_items) > 0:\n                best_candidate = None\n                max_improvement = 0\n                for i in high_value1_items:\n                    for j in np.where(new_solution == 0)[0]:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            improvement = (value2_lst[j] - value1_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-6)\n                            if improvement > max_improvement:\n                                max_improvement = improvement\n                                best_candidate = (i, j)\n                if best_candidate:\n                    i, j = best_candidate\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        else:\n            # Replace high-value2 items with better value1 alternatives\n            high_value2_items = np.where((new_solution == 1) & (value2_lst > value1_lst))[0]\n            if len(high_value2_items) > 0:\n                best_candidate = None\n                max_improvement = 0\n                for i in high_value2_items:\n                    for j in np.where(new_solution == 0)[0]:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            improvement = (value1_lst[j] - value2_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-6)\n                            if improvement > max_improvement:\n                                max_improvement = improvement\n                                best_candidate = (i, j)\n                if best_candidate:\n                    i, j = best_candidate\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.9824145934822279,
            10.431624859571457
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a novel combination of objective diversity and solution density, then applies a multi-stage local search that alternates between objective-specific item swaps and capacity-aware intensification, while dynamically balancing the exploration of both objective spaces using adaptive weights.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Selection based on objective diversity and density\n    selection_scores = []\n    for sol, obj in archive:\n        # Calculate objective diversity\n        diversity = abs(obj[0] - obj[1]) / (obj[0] + obj[1] + 1e-6)\n        # Calculate solution density\n        density = np.sum(sol) / len(sol)\n        # Combined score with adaptive weights\n        selection_scores.append(0.6 * diversity + 0.4 * density)\n\n    selected_idx = np.argmax(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-stage local search\n    n_items = len(weight_lst)\n\n    # Stage 1: Objective-specific swaps\n    for _ in range(2):\n        # Value1-focused swaps\n        value1_ratios = value1_lst / (weight_lst + 1e-6)\n        top_value1 = np.argsort(-value1_ratios)[:min(2, n_items)]\n        bottom_value1 = np.argsort(value1_ratios)[:min(2, n_items)]\n\n        for i in top_value1:\n            for j in bottom_value1:\n                if new_solution[i] == 1 and new_solution[j] == 0:\n                    delta_weight = weight_lst[j] - weight_lst[i]\n                    if current_weight + delta_weight <= capacity:\n                        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                        current_weight += delta_weight\n                        break\n\n        # Value2-focused swaps\n        value2_ratios = value2_lst / (weight_lst + 1e-6)\n        top_value2 = np.argsort(-value2_ratios)[:min(2, n_items)]\n        bottom_value2 = np.argsort(value2_ratios)[:min(2, n_items)]\n\n        for i in top_value2:\n            for j in bottom_value2:\n                if new_solution[i] == 1 and new_solution[j] == 0:\n                    delta_weight = weight_lst[j] - weight_lst[i]\n                    if current_weight + delta_weight <= capacity:\n                        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                        current_weight += delta_weight\n                        break\n\n    # Stage 2: Capacity-aware intensification\n    if current_weight < capacity * 0.8:\n        # Add high-value items with balanced objectives\n        candidate_items = np.where(new_solution == 0)[0]\n        candidate_scores = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        candidate_scores[candidate_items] *= (capacity - current_weight) / capacity\n        top_candidates = np.argsort(-candidate_scores)[:min(3, len(candidate_items))]\n\n        for i in top_candidates:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Stage 3: Objective-balanced adjustments\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n\n    imbalance = abs(total_value1 - total_value2) / (total_value1 + total_value2 + 1e-6)\n    if imbalance > 0.2:\n        # Balance objectives by swapping items\n        if total_value1 > total_value2:\n            # Replace high-value1 items with better value2 alternatives\n            high_value1_items = np.where((new_solution == 1) & (value1_lst > value2_lst))[0]\n            if len(high_value1_items) > 0:\n                best_candidate = None\n                max_improvement = 0\n                for i in high_value1_items:\n                    for j in np.where(new_solution == 0)[0]:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            improvement = (value2_lst[j] - value1_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-6)\n                            if improvement > max_improvement:\n                                max_improvement = improvement\n                                best_candidate = (i, j)\n                if best_candidate:\n                    i, j = best_candidate\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        else:\n            # Replace high-value2 items with better value1 alternatives\n            high_value2_items = np.where((new_solution == 1) & (value2_lst > value1_lst))[0]\n            if len(high_value2_items) > 0:\n                best_candidate = None\n                max_improvement = 0\n                for i in high_value2_items:\n                    for j in np.where(new_solution == 0)[0]:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            improvement = (value1_lst[j] - value2_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-6)\n                            if improvement > max_improvement:\n                                max_improvement = improvement\n                                best_candidate = (i, j)\n                if best_candidate:\n                    i, j = best_candidate\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.9309408829729591,
            3.9082659482955933
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.5629710212465731,
            1.259714663028717
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a novel combination of objective contribution and solution sparsity, then applies a multi-stage local search that alternates between value-aware item swaps and capacity-constrained diversification, while dynamically balancing the exploration of both objective spaces.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Selection based on objective contribution and sparsity\n    selection_scores = []\n    for sol, obj in archive:\n        # Calculate objective contributions\n        contrib1 = obj[0] / np.sum(value1_lst * sol) if np.sum(sol) > 0 else 0\n        contrib2 = obj[1] / np.sum(value2_lst * sol) if np.sum(sol) > 0 else 0\n        # Calculate sparsity (proportion of excluded items)\n        sparsity = np.sum(sol == 0) / len(sol)\n        # Combined score\n        selection_scores.append((contrib1 + contrib2) * sparsity)\n\n    selected_idx = np.argmax(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-stage local search\n    n_items = len(weight_lst)\n\n    # Stage 1: Value-aware swaps\n    for _ in range(3):\n        # Calculate combined value-to-weight ratios\n        ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        # Find top and bottom items\n        top_items = np.argsort(ratios)[-min(3, n_items):]\n        bottom_items = np.argsort(ratios)[:min(3, n_items)]\n\n        for i in top_items:\n            for j in bottom_items:\n                if new_solution[i] == 1 and new_solution[j] == 0:\n                    delta_weight = weight_lst[j] - weight_lst[i]\n                    if current_weight + delta_weight <= capacity:\n                        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                        current_weight += delta_weight\n                        break\n\n    # Stage 2: Capacity-constrained diversification\n    if current_weight < capacity * 0.7:\n        # Add low-weight items with high potential\n        candidate_items = np.where(new_solution == 0)[0]\n        candidate_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        candidate_ratios[candidate_items] *= (capacity - current_weight) / capacity\n        top_candidates = np.argsort(-candidate_ratios)[:min(5, len(candidate_items))]\n\n        for i in top_candidates:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Stage 3: Objective-balanced adjustments\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n\n    if abs(total_value1 - total_value2) > 0.1 * (total_value1 + total_value2):\n        # Balance objectives by swapping items\n        if total_value1 > total_value2:\n            # Replace high-value1 items with better value2 alternatives\n            high_value1_items = np.where((new_solution == 1) & (value1_lst > value2_lst))[0]\n            if len(high_value1_items) > 0:\n                best_candidate = None\n                max_improvement = 0\n                for i in high_value1_items:\n                    for j in np.where(new_solution == 0)[0]:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            improvement = (value2_lst[j] - value1_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-6)\n                            if improvement > max_improvement:\n                                max_improvement = improvement\n                                best_candidate = (i, j)\n                if best_candidate:\n                    i, j = best_candidate\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        else:\n            # Replace high-value2 items with better value1 alternatives\n            high_value2_items = np.where((new_solution == 1) & (value2_lst > value1_lst))[0]\n            if len(high_value2_items) > 0:\n                best_candidate = None\n                max_improvement = 0\n                for i in high_value2_items:\n                    for j in np.where(new_solution == 0)[0]:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            improvement = (value1_lst[j] - value2_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-6)\n                            if improvement > max_improvement:\n                                max_improvement = improvement\n                                best_candidate = (i, j)\n                if best_candidate:\n                    i, j = best_candidate\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.9824145934822279,
            10.431624859571457
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This new algorithm selects a solution from the archive based on a Pareto-frontier dominance score and item diversity, then applies a hybrid local search that combines value-aware item swaps with a probabilistic exploration of high-potential item combinations while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on Pareto dominance and diversity\n    scores = []\n    for sol, obj in archive:\n        dominance_score = 0\n        for other_sol, other_obj in archive:\n            if other_obj[0] > obj[0] and other_obj[1] > obj[1]:\n                dominance_score += 1\n        diversity_score = np.sum(sol != archive[0][0]) / len(sol)\n        total_score = (1 - dominance_score / len(archive)) + diversity_score\n        scores.append(total_score)\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search with value-aware swaps\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate value efficiency for each objective\n    eff1 = value1_lst / (weight_lst + 1e-6)\n    eff2 = value2_lst / (weight_lst + 1e-6)\n    combined_eff = 0.3 * eff1 + 0.7 * eff2\n\n    # Perform strategic swaps between high-efficiency items\n    sorted_indices = np.argsort(-combined_eff)\n    for i in sorted_indices[:min(15, n_items)]:\n        if random.random() < 0.8:\n            if new_solution[i] == 0:\n                # Try adding item if it fits\n                new_weight = current_weight + weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n            else:\n                # Try removing item to make space for better items\n                new_weight = current_weight - weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i] = 0\n                    current_weight = new_weight\n\n    # Probabilistic exploration of high-potential item combinations\n    if n_items >= 4:\n        candidates = random.sample(range(n_items), min(8, n_items))\n        for i in candidates:\n            if random.random() < 0.4:\n                if new_solution[i] == 0:\n                    # Try adding item with probability based on its efficiency\n                    prob = min(0.8, combined_eff[i] / (max(combined_eff) + 1e-6))\n                    if random.random() < prob:\n                        new_weight = current_weight + weight_lst[i]\n                        if new_weight <= capacity:\n                            new_solution[i] = 1\n                            current_weight = new_weight\n\n    return new_solution\n\n",
        "score": [
            -0.6163810059126986,
            1.4421277940273285
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution diversity, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and diversity\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        diversity = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + diversity))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement with value-aware selection\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration with capacity-aware probability\n    value_weights = value1_lst * 0.7 + value2_lst * 0.3  # Weighted combination of objectives\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(15, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment with value-to-weight ratio optimization\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.5207255385596417,
            1.0074024200439453
        ]
    },
    {
        "algorithm": "{This new algorithm selects a solution from the archive based on a weighted combination of objective values and weight efficiency, then applies a hybrid local search that combines value-aware item swaps with a probabilistic exploration of high-potential item combinations while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on weighted objective combination\n    scores = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        score = (0.4 * obj[0] + 0.6 * obj[1]) / (total_weight + 1e-6)\n        scores.append(score)\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search with value-aware swaps\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate value efficiency for each objective\n    eff1 = value1_lst / (weight_lst + 1e-6)\n    eff2 = value2_lst / (weight_lst + 1e-6)\n    combined_eff = 0.5 * eff1 + 0.5 * eff2\n    sorted_indices = np.argsort(-combined_eff)\n\n    # Perform strategic swaps between high-efficiency items\n    for i in sorted_indices[:min(10, n_items)]:\n        if random.random() < 0.7:\n            if new_solution[i] == 0:\n                # Try adding item if it fits\n                new_weight = current_weight + weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n            else:\n                # Try removing item to make space for better items\n                new_weight = current_weight - weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i] = 0\n                    current_weight = new_weight\n\n    # Probabilistic exploration of high-potential item combinations\n    if n_items >= 3:\n        candidates = random.sample(range(n_items), min(5, n_items))\n        for i in candidates:\n            if random.random() < 0.3:\n                if new_solution[i] == 0:\n                    # Try adding item with probability based on its efficiency\n                    prob = min(0.9, combined_eff[i] / (max(combined_eff) + 1e-6))\n                    if random.random() < prob:\n                        new_weight = current_weight + weight_lst[i]\n                        if new_weight <= capacity:\n                            new_solution[i] = 1\n                            current_weight = new_weight\n\n    return new_solution\n\n",
        "score": [
            -0.5451975623412475,
            1.1356434226036072
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This new algorithm selects a solution from the archive based on a weighted combination of objective values and weight efficiency, then applies a hybrid local search that combines value-aware item swaps with a probabilistic exploration of high-potential item combinations while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on weighted objective combination\n    scores = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        score = (0.4 * obj[0] + 0.6 * obj[1]) / (total_weight + 1e-6)\n        scores.append(score)\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search with value-aware swaps\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate value efficiency for each objective\n    eff1 = value1_lst / (weight_lst + 1e-6)\n    eff2 = value2_lst / (weight_lst + 1e-6)\n    combined_eff = 0.5 * eff1 + 0.5 * eff2\n    sorted_indices = np.argsort(-combined_eff)\n\n    # Perform strategic swaps between high-efficiency items\n    for i in sorted_indices[:min(10, n_items)]:\n        if random.random() < 0.7:\n            if new_solution[i] == 0:\n                # Try adding item if it fits\n                new_weight = current_weight + weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n            else:\n                # Try removing item to make space for better items\n                new_weight = current_weight - weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i] = 0\n                    current_weight = new_weight\n\n    # Probabilistic exploration of high-potential item combinations\n    if n_items >= 3:\n        candidates = random.sample(range(n_items), min(5, n_items))\n        for i in candidates:\n            if random.random() < 0.3:\n                if new_solution[i] == 0:\n                    # Try adding item with probability based on its efficiency\n                    prob = min(0.9, combined_eff[i] / (max(combined_eff) + 1e-6))\n                    if random.random() < prob:\n                        new_weight = current_weight + weight_lst[i]\n                        if new_weight <= capacity:\n                            new_solution[i] = 1\n                            current_weight = new_weight\n\n    return new_solution\n\n",
        "score": [
            -0.5451975623412475,
            1.1356434226036072
        ]
    },
    {
        "algorithm": "{My new algorithm selects a solution from the archive based on a combination of objective dominance and solution density, then applies a hybrid local search that combines strategic item insertions with a probabilistic neighborhood exploration to generate high-quality neighbors while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on objective dominance and density\n    dominance_counts = []\n    for sol, obj in archive:\n        dominated = 0\n        for other_sol, other_obj in archive:\n            if other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1]):\n                dominated += 1\n        dominance_counts.append(dominated)\n\n    selected_idx = np.argmin(dominance_counts)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Dynamic neighborhood exploration with probabilistic insertions\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Consider both high-value and low-weight items first\n    value_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(-value_ratios)\n\n    # Perform targeted insertions with probability based on value ratio\n    for i in sorted_indices[:min(15, n_items)]:\n        if random.random() < 0.6:  # Higher probability for better items\n            if new_solution[i] == 0:\n                new_weight = current_weight + weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Additional probabilistic removal of low-value items\n    for i in range(n_items):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    return new_solution\n\n",
        "score": [
            -0.8517583988017057,
            1.496477872133255
        ]
    },
    {
        "algorithm": "{My algorithm selects a solution from the archive based on a combination of objective diversity and solution density, then applies a novel local search that combines adaptive item grouping with a probabilistic neighborhood exploration using a dynamic value-weight balance metric to generate high-quality neighbors while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on objective diversity and solution density\n    diversity_scores = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        density = (obj[0] + obj[1]) / (total_weight + 1e-6)\n        diversity = abs(obj[0] - obj[1]) / (obj[0] + obj[1] + 1e-6)\n        score = density * diversity\n        diversity_scores.append(score)\n\n    selected_idx = np.argmax(diversity_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Adaptive item grouping based on value-weight balance\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Create groups of items with similar value-weight ratios\n    value_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(value_ratios)\n    groups = []\n    group_size = max(1, n_items // 5)\n    for i in range(0, n_items, group_size):\n        groups.append(sorted_indices[i:i+group_size])\n\n    # Dynamic neighborhood exploration with probabilistic group swaps\n    for group in groups:\n        if random.random() < 0.6:  # Higher probability for groups\n            # Try to add or remove entire group\n            group_weight = np.sum(weight_lst[group])\n            if np.all(new_solution[group] == 1):\n                new_weight = current_weight - group_weight\n                if new_weight <= capacity:\n                    new_solution[group] = 0\n                    current_weight = new_weight\n            else:\n                new_weight = current_weight + group_weight\n                if new_weight <= capacity:\n                    new_solution[group] = 1\n                    current_weight = new_weight\n\n    # Additional probabilistic intra-group swaps\n    if n_items >= 2:\n        group = random.choice(groups)\n        i, j = random.sample(range(len(group)), 2)\n        i, j = group[i], group[j]\n        if new_solution[i] != new_solution[j]:\n            if new_solution[i] == 1:\n                new_weight = current_weight - weight_lst[i] + weight_lst[j]\n                if new_weight <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            else:\n                new_weight = current_weight + weight_lst[i] - weight_lst[j]\n                if new_weight <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.8785454361089735,
            2.0242074728012085
        ]
    }
]