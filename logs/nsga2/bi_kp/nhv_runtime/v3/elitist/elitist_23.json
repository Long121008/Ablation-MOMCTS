[
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a novel combination of objective balance and solution diversity, then applies a multi-phase local search that alternates between value-aware item additions, capacity-constrained item removals, and objective-balancing swaps, while dynamically adjusting the exploration intensity based on the current solution's performance in both objective spaces.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Selection based on objective balance and diversity\n    balance_scores = []\n    for sol, obj in archive:\n        balance = min(obj[0], obj[1]) / (max(obj[0], obj[1]) + 1e-6)\n        diversity = np.sum(sol) / len(sol)\n        balance_scores.append(balance * (1 - diversity))\n\n    selected_idx = np.argmax(balance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n\n    # Phase 1: Value-aware additions with dynamic selection\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate combined value-to-weight ratio with objective balance consideration\n        value_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        objective_balance = np.abs(value1_lst - value2_lst) / (np.maximum(value1_lst, value2_lst) + 1e-6)\n        combined_scores = value_ratios * (1 - objective_balance)\n        candidate_items = excluded_items[np.argsort(-combined_scores[excluded_items])[:min(5, len(excluded_items))]]\n\n        for i in candidate_items:\n            if (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n                total_value1 += value1_lst[i]\n                total_value2 += value2_lst[i]\n\n    # Phase 2: Capacity-constrained removals with value preservation\n    if current_weight > capacity * 0.9:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Prioritize removals that preserve value more effectively\n            value_preservation = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            candidate_removals = included_items[np.argsort(value_preservation[included_items])[:min(3, len(included_items))]]\n\n            for i in candidate_removals:\n                if (current_weight - weight_lst[i]) >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    total_value1 -= value1_lst[i]\n                    total_value2 -= value2_lst[i]\n\n    # Phase 3: Objective-balancing swaps with dynamic intensity\n    imbalance_ratio = abs(total_value1 - total_value2) / (total_value1 + total_value2 + 1e-6)\n    if imbalance_ratio > 0.15:\n        # Calculate swap potential based on objective balance improvement\n        swap_potential = []\n        for i in np.where(new_solution == 1)[0]:\n            for j in np.where(new_solution == 0)[0]:\n                if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                    new_balance = (total_value1 - value1_lst[i] + value1_lst[j] + total_value2 - value2_lst[i] + value2_lst[j])\n                    swap_potential.append((i, j, new_balance))\n\n        if swap_potential:\n            # Select the swap that most improves balance\n            best_swap = max(swap_potential, key=lambda x: x[2])\n            new_solution[best_swap[0]], new_solution[best_swap[1]] = new_solution[best_swap[1]], new_solution[best_swap[0]]\n\n    return new_solution\n\n",
        "score": [
            -0.9922388742212646,
            3.3693877160549164
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a novel combination of objective balance and solution diversity, then applies a multi-phase local search that alternates between value-aware item additions, capacity-constrained item removals, and objective-balancing swaps, while dynamically adjusting the exploration intensity based on the current solution's performance in both objective spaces.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Selection based on objective balance and diversity\n    balance_scores = []\n    for sol, obj in archive:\n        balance = min(obj[0], obj[1]) / (max(obj[0], obj[1]) + 1e-6)\n        diversity = np.sum(sol) / len(sol)\n        balance_scores.append(balance * (1 - diversity))\n\n    selected_idx = np.argmax(balance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n\n    # Phase 1: Value-aware additions with dynamic selection\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate combined value-to-weight ratio with objective balance consideration\n        value_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        objective_balance = np.abs(value1_lst - value2_lst) / (np.maximum(value1_lst, value2_lst) + 1e-6)\n        combined_scores = value_ratios * (1 - objective_balance)\n        candidate_items = excluded_items[np.argsort(-combined_scores[excluded_items])[:min(5, len(excluded_items))]]\n\n        for i in candidate_items:\n            if (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n                total_value1 += value1_lst[i]\n                total_value2 += value2_lst[i]\n\n    # Phase 2: Capacity-constrained removals with value preservation\n    if current_weight > capacity * 0.9:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Prioritize removals that preserve value more effectively\n            value_preservation = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            candidate_removals = included_items[np.argsort(value_preservation[included_items])[:min(3, len(included_items))]]\n\n            for i in candidate_removals:\n                if (current_weight - weight_lst[i]) >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    total_value1 -= value1_lst[i]\n                    total_value2 -= value2_lst[i]\n\n    # Phase 3: Objective-balancing swaps with dynamic intensity\n    imbalance_ratio = abs(total_value1 - total_value2) / (total_value1 + total_value2 + 1e-6)\n    if imbalance_ratio > 0.15:\n        # Calculate swap potential based on objective balance improvement\n        swap_potential = []\n        for i in np.where(new_solution == 1)[0]:\n            for j in np.where(new_solution == 0)[0]:\n                if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                    new_balance = (total_value1 - value1_lst[i] + value1_lst[j] + total_value2 - value2_lst[i] + value2_lst[j])\n                    swap_potential.append((i, j, new_balance))\n\n        if swap_potential:\n            # Select the swap that most improves balance\n            best_swap = max(swap_potential, key=lambda x: x[2])\n            new_solution[best_swap[0]], new_solution[best_swap[1]] = new_solution[best_swap[1]], new_solution[best_swap[0]]\n\n    return new_solution\n\n",
        "score": [
            -0.9922388742212646,
            3.3693877160549164
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a novel combination of objective balance and solution diversity, then applies a multi-phase local search that alternates between value-aware item additions, capacity-constrained item removals, and objective-balancing swaps, while dynamically adjusting the exploration intensity based on the current solution's performance in both objective spaces.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Selection based on objective balance and diversity\n    balance_scores = []\n    for sol, obj in archive:\n        balance = min(obj[0], obj[1]) / (max(obj[0], obj[1]) + 1e-6)\n        diversity = np.sum(sol) / len(sol)\n        balance_scores.append(balance * (1 - diversity))\n\n    selected_idx = np.argmax(balance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n\n    # Phase 1: Value-aware additions with dynamic selection\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate combined value-to-weight ratio with objective balance consideration\n        value_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        objective_balance = np.abs(value1_lst - value2_lst) / (np.maximum(value1_lst, value2_lst) + 1e-6)\n        combined_scores = value_ratios * (1 - objective_balance)\n        candidate_items = excluded_items[np.argsort(-combined_scores[excluded_items])[:min(5, len(excluded_items))]]\n\n        for i in candidate_items:\n            if (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n                total_value1 += value1_lst[i]\n                total_value2 += value2_lst[i]\n\n    # Phase 2: Capacity-constrained removals with value preservation\n    if current_weight > capacity * 0.9:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Prioritize removals that preserve value more effectively\n            value_preservation = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            candidate_removals = included_items[np.argsort(value_preservation[included_items])[:min(3, len(included_items))]]\n\n            for i in candidate_removals:\n                if (current_weight - weight_lst[i]) >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    total_value1 -= value1_lst[i]\n                    total_value2 -= value2_lst[i]\n\n    # Phase 3: Objective-balancing swaps with dynamic intensity\n    imbalance_ratio = abs(total_value1 - total_value2) / (total_value1 + total_value2 + 1e-6)\n    if imbalance_ratio > 0.15:\n        # Calculate swap potential based on objective balance improvement\n        swap_potential = []\n        for i in np.where(new_solution == 1)[0]:\n            for j in np.where(new_solution == 0)[0]:\n                if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                    new_balance = (total_value1 - value1_lst[i] + value1_lst[j] + total_value2 - value2_lst[i] + value2_lst[j])\n                    swap_potential.append((i, j, new_balance))\n\n        if swap_potential:\n            # Select the swap that most improves balance\n            best_swap = max(swap_potential, key=lambda x: x[2])\n            new_solution[best_swap[0]], new_solution[best_swap[1]] = new_solution[best_swap[1]], new_solution[best_swap[0]]\n\n    return new_solution\n\n",
        "score": [
            -0.9922388742212646,
            3.3693877160549164
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a novel combination of objective balance and solution diversity, then applies a multi-phase local search that alternates between value-aware item additions, capacity-constrained item removals, and objective-balancing swaps, while dynamically adjusting the exploration intensity based on the current solution's performance in both objective spaces.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Selection based on objective balance and diversity\n    balance_scores = []\n    for sol, obj in archive:\n        balance = min(obj[0], obj[1]) / (max(obj[0], obj[1]) + 1e-6)\n        diversity = np.sum(sol) / len(sol)\n        balance_scores.append(balance * (1 - diversity))\n\n    selected_idx = np.argmax(balance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n\n    # Phase 1: Value-aware additions with dynamic selection\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate combined value-to-weight ratio with objective balance consideration\n        value_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        objective_balance = np.abs(value1_lst - value2_lst) / (np.maximum(value1_lst, value2_lst) + 1e-6)\n        combined_scores = value_ratios * (1 - objective_balance)\n        candidate_items = excluded_items[np.argsort(-combined_scores[excluded_items])[:min(5, len(excluded_items))]]\n\n        for i in candidate_items:\n            if (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n                total_value1 += value1_lst[i]\n                total_value2 += value2_lst[i]\n\n    # Phase 2: Capacity-constrained removals with value preservation\n    if current_weight > capacity * 0.9:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Prioritize removals that preserve value more effectively\n            value_preservation = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            candidate_removals = included_items[np.argsort(value_preservation[included_items])[:min(3, len(included_items))]]\n\n            for i in candidate_removals:\n                if (current_weight - weight_lst[i]) >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    total_value1 -= value1_lst[i]\n                    total_value2 -= value2_lst[i]\n\n    # Phase 3: Objective-balancing swaps with dynamic intensity\n    imbalance_ratio = abs(total_value1 - total_value2) / (total_value1 + total_value2 + 1e-6)\n    if imbalance_ratio > 0.15:\n        # Calculate swap potential based on objective balance improvement\n        swap_potential = []\n        for i in np.where(new_solution == 1)[0]:\n            for j in np.where(new_solution == 0)[0]:\n                if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                    new_balance = (total_value1 - value1_lst[i] + value1_lst[j] + total_value2 - value2_lst[i] + value2_lst[j])\n                    swap_potential.append((i, j, new_balance))\n\n        if swap_potential:\n            # Select the swap that most improves balance\n            best_swap = max(swap_potential, key=lambda x: x[2])\n            new_solution[best_swap[0]], new_solution[best_swap[1]] = new_solution[best_swap[1]], new_solution[best_swap[0]]\n\n    return new_solution\n\n",
        "score": [
            -0.9922388742212646,
            3.3693877160549164
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a novel combination of objective balance and solution diversity, then applies a multi-phase local search that alternates between value-aware item additions, capacity-constrained item removals, and objective-balancing swaps, while dynamically adjusting the exploration intensity based on the current solution's performance in both objective spaces.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Selection based on objective balance and diversity\n    balance_scores = []\n    for sol, obj in archive:\n        balance = min(obj[0], obj[1]) / (max(obj[0], obj[1]) + 1e-6)\n        diversity = np.sum(sol) / len(sol)\n        balance_scores.append(balance * (1 - diversity))\n\n    selected_idx = np.argmax(balance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n\n    # Phase 1: Value-aware additions with dynamic selection\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate combined value-to-weight ratio with objective balance consideration\n        value_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        objective_balance = np.abs(value1_lst - value2_lst) / (np.maximum(value1_lst, value2_lst) + 1e-6)\n        combined_scores = value_ratios * (1 - objective_balance)\n        candidate_items = excluded_items[np.argsort(-combined_scores[excluded_items])[:min(5, len(excluded_items))]]\n\n        for i in candidate_items:\n            if (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n                total_value1 += value1_lst[i]\n                total_value2 += value2_lst[i]\n\n    # Phase 2: Capacity-constrained removals with value preservation\n    if current_weight > capacity * 0.9:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Prioritize removals that preserve value more effectively\n            value_preservation = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            candidate_removals = included_items[np.argsort(value_preservation[included_items])[:min(3, len(included_items))]]\n\n            for i in candidate_removals:\n                if (current_weight - weight_lst[i]) >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    total_value1 -= value1_lst[i]\n                    total_value2 -= value2_lst[i]\n\n    # Phase 3: Objective-balancing swaps with dynamic intensity\n    imbalance_ratio = abs(total_value1 - total_value2) / (total_value1 + total_value2 + 1e-6)\n    if imbalance_ratio > 0.15:\n        # Calculate swap potential based on objective balance improvement\n        swap_potential = []\n        for i in np.where(new_solution == 1)[0]:\n            for j in np.where(new_solution == 0)[0]:\n                if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                    new_balance = (total_value1 - value1_lst[i] + value1_lst[j] + total_value2 - value2_lst[i] + value2_lst[j])\n                    swap_potential.append((i, j, new_balance))\n\n        if swap_potential:\n            # Select the swap that most improves balance\n            best_swap = max(swap_potential, key=lambda x: x[2])\n            new_solution[best_swap[0]], new_solution[best_swap[1]] = new_solution[best_swap[1]], new_solution[best_swap[0]]\n\n    return new_solution\n\n",
        "score": [
            -0.9922388742212646,
            3.3693877160549164
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a novel combination of objective dominance and solution density, then applies a multi-stage local search that alternates between value-aware additions, capacity-constrained removals, and objective-balancing swaps, while dynamically adjusting the exploration intensity based on the current solution's performance in both objective spaces and the archive's Pareto front characteristics.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Selection based on objective dominance and solution density\n    dominance_scores = []\n    for sol, obj in archive:\n        # Calculate dominance score based on non-dominated solutions in archive\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] > obj[1]) or (other_obj[0] > obj[0] and other_obj[1] >= obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            density = np.sum(sol) / len(sol)\n            dominance_scores.append((obj[0] + obj[1]) * (1 - density))\n\n    if dominance_scores:\n        selected_idx = np.argmax(dominance_scores)\n    else:\n        selected_idx = np.random.randint(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n\n    # Phase 1: Value-aware additions with dynamic selection\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate combined value-to-weight ratio with objective dominance consideration\n        value_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        objective_dominance = np.maximum(value1_lst, value2_lst) / (np.minimum(value1_lst, value2_lst) + 1e-6)\n        combined_scores = value_ratios * objective_dominance\n        candidate_items = excluded_items[np.argsort(-combined_scores[excluded_items])[:min(5, len(excluded_items))]]\n\n        for i in candidate_items:\n            if (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n                total_value1 += value1_lst[i]\n                total_value2 += value2_lst[i]\n\n    # Phase 2: Capacity-constrained removals with value preservation\n    if current_weight > capacity * 0.9:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Prioritize removals that preserve value more effectively\n            value_preservation = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            candidate_removals = included_items[np.argsort(value_preservation[included_items])[:min(3, len(included_items))]]\n\n            for i in candidate_removals:\n                if (current_weight - weight_lst[i]) >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    total_value1 -= value1_lst[i]\n                    total_value2 -= value2_lst[i]\n\n    # Phase 3: Objective-balancing swaps with dynamic intensity\n    imbalance_ratio = abs(total_value1 - total_value2) / (total_value1 + total_value2 + 1e-6)\n    if imbalance_ratio > 0.15:\n        # Calculate swap potential based on objective balance improvement\n        swap_potential = []\n        for i in np.where(new_solution == 1)[0]:\n            for j in np.where(new_solution == 0)[0]:\n                if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                    new_balance = (total_value1 - value1_lst[i] + value1_lst[j] + total_value2 - value2_lst[i] + value2_lst[j])\n                    swap_potential.append((i, j, new_balance))\n\n        if swap_potential:\n            # Select the swap that most improves balance\n            best_swap = max(swap_potential, key=lambda x: x[2])\n            new_solution[best_swap[0]], new_solution[best_swap[1]] = new_solution[best_swap[1]], new_solution[best_swap[0]]\n\n    return new_solution\n\n",
        "score": [
            -0.8633223152533229,
            1.3703964352607727
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a novel combination of objective dominance and solution quality, then applies a multi-phase local search that alternates between value-aware item additions, capacity-constrained item removals, and objective-balancing swaps, while dynamically adjusting the exploration intensity based on the current solution's performance in both objective spaces.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Selection based on objective dominance and solution quality\n    dominance_scores = []\n    for sol, obj in archive:\n        dominance = (obj[0] * obj[1]) / (np.sum(weight_lst * sol) + 1e-6)\n        quality = np.sum(sol) / len(sol)\n        dominance_scores.append(dominance * quality)\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n\n    # Phase 1: Value-aware additions with dynamic selection\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate combined value-to-weight ratio with objective dominance consideration\n        value_ratios = (value1_lst * value2_lst) / (weight_lst + 1e-6)\n        objective_dominance = np.maximum(value1_lst, value2_lst) / (np.minimum(value1_lst, value2_lst) + 1e-6)\n        combined_scores = value_ratios * objective_dominance\n        candidate_items = excluded_items[np.argsort(-combined_scores[excluded_items])[:min(5, len(excluded_items))]]\n\n        for i in candidate_items:\n            if (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n                total_value1 += value1_lst[i]\n                total_value2 += value2_lst[i]\n\n    # Phase 2: Capacity-constrained removals with value preservation\n    if current_weight > capacity * 0.85:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Prioritize removals that preserve value more effectively\n            value_preservation = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            candidate_removals = included_items[np.argsort(-value_preservation[included_items])[:min(3, len(included_items))]]\n\n            for i in candidate_removals:\n                if (current_weight - weight_lst[i]) >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    total_value1 -= value1_lst[i]\n                    total_value2 -= value2_lst[i]\n\n    # Phase 3: Objective-balancing swaps with dynamic intensity\n    imbalance_ratio = abs(total_value1 - total_value2) / (total_value1 + total_value2 + 1e-6)\n    if imbalance_ratio > 0.2:\n        # Calculate swap potential based on objective dominance improvement\n        swap_potential = []\n        for i in np.where(new_solution == 1)[0]:\n            for j in np.where(new_solution == 0)[0]:\n                if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                    new_value1 = total_value1 - value1_lst[i] + value1_lst[j]\n                    new_value2 = total_value2 - value2_lst[i] + value2_lst[j]\n                    new_dominance = min(new_value1, new_value2) / (max(new_value1, new_value2) + 1e-6)\n                    swap_potential.append((i, j, new_dominance))\n\n        if swap_potential:\n            # Select the swap that most improves dominance\n            best_swap = max(swap_potential, key=lambda x: x[2])\n            new_solution[best_swap[0]], new_solution[best_swap[1]] = new_solution[best_swap[1]], new_solution[best_swap[0]]\n\n    return new_solution\n\n",
        "score": [
            -0.9448007484115335,
            2.8374485969543457
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a novel combination of objective balance and solution diversity, then applies a multi-phase local search that alternates between value-aware item additions, capacity-constrained item removals, and objective-balancing swaps, while dynamically adjusting the exploration intensity based on the current solution's performance in both objective spaces.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Selection based on objective balance and diversity\n    balance_scores = []\n    for sol, obj in archive:\n        balance = min(obj[0], obj[1]) / (max(obj[0], obj[1]) + 1e-6)\n        diversity = np.sum(sol) / len(sol)\n        balance_scores.append(balance * (1 - diversity))\n\n    selected_idx = np.argmax(balance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n\n    # Phase 1: Value-aware additions\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        value_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        candidate_items = excluded_items[np.argsort(-value_ratios[excluded_items])[:min(5, len(excluded_items))]]\n\n        for i in candidate_items:\n            if (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n                total_value1 += value1_lst[i]\n                total_value2 += value2_lst[i]\n\n    # Phase 2: Capacity-constrained removals\n    if current_weight > capacity * 0.9:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            removal_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            candidate_removals = included_items[np.argsort(removal_ratios[included_items])[:min(3, len(included_items))]]\n\n            for i in candidate_removals:\n                if (current_weight - weight_lst[i]) >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    total_value1 -= value1_lst[i]\n                    total_value2 -= value2_lst[i]\n\n    # Phase 3: Objective-balancing swaps\n    if abs(total_value1 - total_value2) > 0.2 * (total_value1 + total_value2):\n        if total_value1 > total_value2:\n            high_value1_items = np.where((new_solution == 1) & (value1_lst > value2_lst))[0]\n            if len(high_value1_items) > 0:\n                for i in high_value1_items:\n                    for j in np.where(new_solution == 0)[0]:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            if (value2_lst[j] - value1_lst[i]) > 0:\n                                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                                break\n        else:\n            high_value2_items = np.where((new_solution == 1) & (value2_lst > value1_lst))[0]\n            if len(high_value2_items) > 0:\n                for i in high_value2_items:\n                    for j in np.where(new_solution == 0)[0]:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            if (value1_lst[j] - value2_lst[i]) > 0:\n                                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                                break\n\n    return new_solution\n\n",
        "score": [
            -0.9878416333917808,
            2.8447465002536774
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a novel combination of objective balance and solution diversity, then applies a multi-phase local search that alternates between value-aware item additions, capacity-constrained item removals, and objective-balancing swaps, while dynamically adjusting the exploration intensity based on the current solution's performance in both objective spaces.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Selection based on objective balance and diversity\n    balance_scores = []\n    for sol, obj in archive:\n        balance = min(obj[0], obj[1]) / (max(obj[0], obj[1]) + 1e-6)\n        diversity = np.sum(sol) / len(sol)\n        balance_scores.append(balance * (1 - diversity))\n\n    selected_idx = np.argmax(balance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n\n    # Phase 1: Value-aware additions with dynamic selection\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate combined value-to-weight ratio with objective balance consideration\n        value_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        objective_balance = np.abs(value1_lst - value2_lst) / (np.maximum(value1_lst, value2_lst) + 1e-6)\n        combined_scores = value_ratios * (1 - objective_balance)\n        candidate_items = excluded_items[np.argsort(-combined_scores[excluded_items])[:min(5, len(excluded_items))]]\n\n        for i in candidate_items:\n            if (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n                total_value1 += value1_lst[i]\n                total_value2 += value2_lst[i]\n\n    # Phase 2: Capacity-constrained removals with value preservation\n    if current_weight > capacity * 0.9:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Prioritize removals that preserve value more effectively\n            value_preservation = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            candidate_removals = included_items[np.argsort(value_preservation[included_items])[:min(3, len(included_items))]]\n\n            for i in candidate_removals:\n                if (current_weight - weight_lst[i]) >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    total_value1 -= value1_lst[i]\n                    total_value2 -= value2_lst[i]\n\n    # Phase 3: Objective-balancing swaps with dynamic intensity\n    imbalance_ratio = abs(total_value1 - total_value2) / (total_value1 + total_value2 + 1e-6)\n    if imbalance_ratio > 0.15:\n        # Calculate swap potential based on objective balance improvement\n        swap_potential = []\n        for i in np.where(new_solution == 1)[0]:\n            for j in np.where(new_solution == 0)[0]:\n                if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                    new_balance = (total_value1 - value1_lst[i] + value1_lst[j] + total_value2 - value2_lst[i] + value2_lst[j])\n                    swap_potential.append((i, j, new_balance))\n\n        if swap_potential:\n            # Select the swap that most improves balance\n            best_swap = max(swap_potential, key=lambda x: x[2])\n            new_solution[best_swap[0]], new_solution[best_swap[1]] = new_solution[best_swap[1]], new_solution[best_swap[0]]\n\n    return new_solution\n\n",
        "score": [
            -0.9922388742212646,
            3.3693877160549164
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a novel combination of objective balance and solution diversity, then applies a multi-phase local search that alternates between value-aware item additions, capacity-constrained item removals, and objective-balancing swaps, while dynamically adjusting the exploration intensity based on the current solution's performance in both objective spaces.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Selection based on objective balance and diversity\n    balance_scores = []\n    for sol, obj in archive:\n        balance = min(obj[0], obj[1]) / (max(obj[0], obj[1]) + 1e-6)\n        diversity = np.sum(sol) / len(sol)\n        balance_scores.append(balance * (1 - diversity))\n\n    selected_idx = np.argmax(balance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n\n    # Phase 1: Value-aware additions\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        value_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        candidate_items = excluded_items[np.argsort(-value_ratios[excluded_items])[:min(5, len(excluded_items))]]\n\n        for i in candidate_items:\n            if (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n                total_value1 += value1_lst[i]\n                total_value2 += value2_lst[i]\n\n    # Phase 2: Capacity-constrained removals\n    if current_weight > capacity * 0.9:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            removal_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            candidate_removals = included_items[np.argsort(removal_ratios[included_items])[:min(3, len(included_items))]]\n\n            for i in candidate_removals:\n                if (current_weight - weight_lst[i]) >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    total_value1 -= value1_lst[i]\n                    total_value2 -= value2_lst[i]\n\n    # Phase 3: Objective-balancing swaps\n    if abs(total_value1 - total_value2) > 0.2 * (total_value1 + total_value2):\n        if total_value1 > total_value2:\n            high_value1_items = np.where((new_solution == 1) & (value1_lst > value2_lst))[0]\n            if len(high_value1_items) > 0:\n                for i in high_value1_items:\n                    for j in np.where(new_solution == 0)[0]:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            if (value2_lst[j] - value1_lst[i]) > 0:\n                                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                                break\n        else:\n            high_value2_items = np.where((new_solution == 1) & (value2_lst > value1_lst))[0]\n            if len(high_value2_items) > 0:\n                for i in high_value2_items:\n                    for j in np.where(new_solution == 0)[0]:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            if (value1_lst[j] - value2_lst[i]) > 0:\n                                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                                break\n\n    return new_solution\n\n",
        "score": [
            -0.9878416333917808,
            2.8447465002536774
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a combination of objective balance and solution diversity, then applies a novel multi-phase local search that dynamically balances objective improvements through adaptive item prioritization and capacity-aware diversification, while ensuring feasibility through probabilistic capacity adjustment and value-weighted neighborhood exploration.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Selection based on objective balance and diversity\n    balance_scores = []\n    for sol, obj in archive:\n        balance = 1 - abs(obj[0] - obj[1]) / (obj[0] + obj[1] + 1e-6)\n        diversity = np.sum(sol != archive[0][0]) / len(sol)\n        balance_scores.append(balance * diversity)\n\n    selected_idx = np.argmax(balance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Adaptive item prioritization\n    value_ratios = value1_lst / (value2_lst + 1e-6)\n    sorted_indices = np.argsort(-value_ratios)\n\n    for i in sorted_indices[:min(5, len(weight_lst))]:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    # Phase 2: Capacity-aware diversification\n    if current_weight < capacity * 0.9:\n        candidate_items = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidate_items]\n        candidate_values = value1_lst[candidate_items] + value2_lst[candidate_items]\n\n        # Select items with high value-to-weight ratio and low weight\n        selection_prob = candidate_values / (candidate_weights + 1e-6)\n        selection_prob *= (capacity - current_weight) / capacity\n\n        for i in np.argsort(-selection_prob)[:min(3, len(candidate_items))]:\n            if new_solution[candidate_items[i]] == 0 and (current_weight + weight_lst[candidate_items[i]]) <= capacity:\n                new_solution[candidate_items[i]] = 1\n                current_weight += weight_lst[candidate_items[i]]\n\n    # Phase 3: Probabilistic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            removal_prob = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            removal_prob[included_items] *= weight_lst[included_items] / excess\n\n            for i in np.argsort(-removal_prob[included_items])[:min(2, len(included_items))]:\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.9143893338037108,
            2.467582881450653
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.5629710212465731,
            1.259714663028717
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution diversity, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and diversity\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        diversity = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + diversity))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement with value-aware selection\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration with capacity-aware probability\n    value_weights = value1_lst * 0.7 + value2_lst * 0.3  # Weighted combination of objectives\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(15, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment with value-to-weight ratio optimization\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.5207255385596417,
            1.0074024200439453
        ]
    },
    {
        "algorithm": "{This new algorithm selects a solution from the archive based on a weighted combination of objective values and weight efficiency, then applies a hybrid local search that combines value-aware item swaps with a probabilistic exploration of high-potential item combinations while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on weighted objective combination\n    scores = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        score = (0.4 * obj[0] + 0.6 * obj[1]) / (total_weight + 1e-6)\n        scores.append(score)\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search with value-aware swaps\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate value efficiency for each objective\n    eff1 = value1_lst / (weight_lst + 1e-6)\n    eff2 = value2_lst / (weight_lst + 1e-6)\n    combined_eff = 0.5 * eff1 + 0.5 * eff2\n    sorted_indices = np.argsort(-combined_eff)\n\n    # Perform strategic swaps between high-efficiency items\n    for i in sorted_indices[:min(10, n_items)]:\n        if random.random() < 0.7:\n            if new_solution[i] == 0:\n                # Try adding item if it fits\n                new_weight = current_weight + weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n            else:\n                # Try removing item to make space for better items\n                new_weight = current_weight - weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i] = 0\n                    current_weight = new_weight\n\n    # Probabilistic exploration of high-potential item combinations\n    if n_items >= 3:\n        candidates = random.sample(range(n_items), min(5, n_items))\n        for i in candidates:\n            if random.random() < 0.3:\n                if new_solution[i] == 0:\n                    # Try adding item with probability based on its efficiency\n                    prob = min(0.9, combined_eff[i] / (max(combined_eff) + 1e-6))\n                    if random.random() < prob:\n                        new_weight = current_weight + weight_lst[i]\n                        if new_weight <= capacity:\n                            new_solution[i] = 1\n                            current_weight = new_weight\n\n    return new_solution\n\n",
        "score": [
            -0.5451975623412475,
            1.1356434226036072
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This new algorithm selects a solution from the archive based on a weighted combination of objective values and weight efficiency, then applies a hybrid local search that combines value-aware item swaps with a probabilistic exploration of high-potential item combinations while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on weighted objective combination\n    scores = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        score = (0.4 * obj[0] + 0.6 * obj[1]) / (total_weight + 1e-6)\n        scores.append(score)\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search with value-aware swaps\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate value efficiency for each objective\n    eff1 = value1_lst / (weight_lst + 1e-6)\n    eff2 = value2_lst / (weight_lst + 1e-6)\n    combined_eff = 0.5 * eff1 + 0.5 * eff2\n    sorted_indices = np.argsort(-combined_eff)\n\n    # Perform strategic swaps between high-efficiency items\n    for i in sorted_indices[:min(10, n_items)]:\n        if random.random() < 0.7:\n            if new_solution[i] == 0:\n                # Try adding item if it fits\n                new_weight = current_weight + weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n            else:\n                # Try removing item to make space for better items\n                new_weight = current_weight - weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i] = 0\n                    current_weight = new_weight\n\n    # Probabilistic exploration of high-potential item combinations\n    if n_items >= 3:\n        candidates = random.sample(range(n_items), min(5, n_items))\n        for i in candidates:\n            if random.random() < 0.3:\n                if new_solution[i] == 0:\n                    # Try adding item with probability based on its efficiency\n                    prob = min(0.9, combined_eff[i] / (max(combined_eff) + 1e-6))\n                    if random.random() < prob:\n                        new_weight = current_weight + weight_lst[i]\n                        if new_weight <= capacity:\n                            new_solution[i] = 1\n                            current_weight = new_weight\n\n    return new_solution\n\n",
        "score": [
            -0.5451975623412475,
            1.1356434226036072
        ]
    },
    {
        "algorithm": "{My algorithm selects a solution from the archive based on a combination of objective diversity and solution density, then applies a novel local search that combines adaptive item grouping with a probabilistic neighborhood exploration using a dynamic value-weight balance metric to generate high-quality neighbors while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on objective diversity and solution density\n    diversity_scores = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        density = (obj[0] + obj[1]) / (total_weight + 1e-6)\n        diversity = abs(obj[0] - obj[1]) / (obj[0] + obj[1] + 1e-6)\n        score = density * diversity\n        diversity_scores.append(score)\n\n    selected_idx = np.argmax(diversity_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Adaptive item grouping based on value-weight balance\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Create groups of items with similar value-weight ratios\n    value_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(value_ratios)\n    groups = []\n    group_size = max(1, n_items // 5)\n    for i in range(0, n_items, group_size):\n        groups.append(sorted_indices[i:i+group_size])\n\n    # Dynamic neighborhood exploration with probabilistic group swaps\n    for group in groups:\n        if random.random() < 0.6:  # Higher probability for groups\n            # Try to add or remove entire group\n            group_weight = np.sum(weight_lst[group])\n            if np.all(new_solution[group] == 1):\n                new_weight = current_weight - group_weight\n                if new_weight <= capacity:\n                    new_solution[group] = 0\n                    current_weight = new_weight\n            else:\n                new_weight = current_weight + group_weight\n                if new_weight <= capacity:\n                    new_solution[group] = 1\n                    current_weight = new_weight\n\n    # Additional probabilistic intra-group swaps\n    if n_items >= 2:\n        group = random.choice(groups)\n        i, j = random.sample(range(len(group)), 2)\n        i, j = group[i], group[j]\n        if new_solution[i] != new_solution[j]:\n            if new_solution[i] == 1:\n                new_weight = current_weight - weight_lst[i] + weight_lst[j]\n                if new_weight <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            else:\n                new_weight = current_weight + weight_lst[i] - weight_lst[j]\n                if new_weight <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.8785454361089735,
            2.0242074728012085
        ]
    }
]