[
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a novel combination of objective contribution and solution sparsity, then applies a multi-stage local search that alternates between value-aware item swaps and capacity-constrained diversification, while dynamically balancing the exploration of both objective spaces.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Selection based on objective contribution and sparsity\n    selection_scores = []\n    for sol, obj in archive:\n        # Calculate objective contributions\n        contrib1 = obj[0] / np.sum(value1_lst * sol) if np.sum(sol) > 0 else 0\n        contrib2 = obj[1] / np.sum(value2_lst * sol) if np.sum(sol) > 0 else 0\n        # Calculate sparsity (proportion of excluded items)\n        sparsity = np.sum(sol == 0) / len(sol)\n        # Combined score\n        selection_scores.append((contrib1 + contrib2) * sparsity)\n\n    selected_idx = np.argmax(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-stage local search\n    n_items = len(weight_lst)\n\n    # Stage 1: Value-aware swaps\n    for _ in range(3):\n        # Calculate combined value-to-weight ratios\n        ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        # Find top and bottom items\n        top_items = np.argsort(ratios)[-min(3, n_items):]\n        bottom_items = np.argsort(ratios)[:min(3, n_items)]\n\n        for i in top_items:\n            for j in bottom_items:\n                if new_solution[i] == 1 and new_solution[j] == 0:\n                    delta_weight = weight_lst[j] - weight_lst[i]\n                    if current_weight + delta_weight <= capacity:\n                        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                        current_weight += delta_weight\n                        break\n\n    # Stage 2: Capacity-constrained diversification\n    if current_weight < capacity * 0.7:\n        # Add low-weight items with high potential\n        candidate_items = np.where(new_solution == 0)[0]\n        candidate_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        candidate_ratios[candidate_items] *= (capacity - current_weight) / capacity\n        top_candidates = np.argsort(-candidate_ratios)[:min(5, len(candidate_items))]\n\n        for i in top_candidates:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Stage 3: Objective-balanced adjustments\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n\n    if abs(total_value1 - total_value2) > 0.1 * (total_value1 + total_value2):\n        # Balance objectives by swapping items\n        if total_value1 > total_value2:\n            # Replace high-value1 items with better value2 alternatives\n            high_value1_items = np.where((new_solution == 1) & (value1_lst > value2_lst))[0]\n            if len(high_value1_items) > 0:\n                best_candidate = None\n                max_improvement = 0\n                for i in high_value1_items:\n                    for j in np.where(new_solution == 0)[0]:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            improvement = (value2_lst[j] - value1_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-6)\n                            if improvement > max_improvement:\n                                max_improvement = improvement\n                                best_candidate = (i, j)\n                if best_candidate:\n                    i, j = best_candidate\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        else:\n            # Replace high-value2 items with better value1 alternatives\n            high_value2_items = np.where((new_solution == 1) & (value2_lst > value1_lst))[0]\n            if len(high_value2_items) > 0:\n                best_candidate = None\n                max_improvement = 0\n                for i in high_value2_items:\n                    for j in np.where(new_solution == 0)[0]:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            improvement = (value1_lst[j] - value2_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-6)\n                            if improvement > max_improvement:\n                                max_improvement = improvement\n                                best_candidate = (i, j)\n                if best_candidate:\n                    i, j = best_candidate\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.9824145934822279,
            10.431624859571457
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a novel combination of objective contribution and solution sparsity, then applies a multi-stage local search that alternates between value-aware item swaps and capacity-constrained diversification, while dynamically balancing the exploration of both objective spaces.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Selection based on objective contribution and sparsity\n    selection_scores = []\n    for sol, obj in archive:\n        # Calculate objective contributions\n        contrib1 = obj[0] / np.sum(value1_lst * sol) if np.sum(sol) > 0 else 0\n        contrib2 = obj[1] / np.sum(value2_lst * sol) if np.sum(sol) > 0 else 0\n        # Calculate sparsity (proportion of excluded items)\n        sparsity = np.sum(sol == 0) / len(sol)\n        # Combined score\n        selection_scores.append((contrib1 + contrib2) * sparsity)\n\n    selected_idx = np.argmax(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-stage local search\n    n_items = len(weight_lst)\n\n    # Stage 1: Value-aware swaps\n    for _ in range(3):\n        # Calculate combined value-to-weight ratios\n        ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        # Find top and bottom items\n        top_items = np.argsort(ratios)[-min(3, n_items):]\n        bottom_items = np.argsort(ratios)[:min(3, n_items)]\n\n        for i in top_items:\n            for j in bottom_items:\n                if new_solution[i] == 1 and new_solution[j] == 0:\n                    delta_weight = weight_lst[j] - weight_lst[i]\n                    if current_weight + delta_weight <= capacity:\n                        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                        current_weight += delta_weight\n                        break\n\n    # Stage 2: Capacity-constrained diversification\n    if current_weight < capacity * 0.7:\n        # Add low-weight items with high potential\n        candidate_items = np.where(new_solution == 0)[0]\n        candidate_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        candidate_ratios[candidate_items] *= (capacity - current_weight) / capacity\n        top_candidates = np.argsort(-candidate_ratios)[:min(5, len(candidate_items))]\n\n        for i in top_candidates:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Stage 3: Objective-balanced adjustments\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n\n    if abs(total_value1 - total_value2) > 0.1 * (total_value1 + total_value2):\n        # Balance objectives by swapping items\n        if total_value1 > total_value2:\n            # Replace high-value1 items with better value2 alternatives\n            high_value1_items = np.where((new_solution == 1) & (value1_lst > value2_lst))[0]\n            if len(high_value1_items) > 0:\n                best_candidate = None\n                max_improvement = 0\n                for i in high_value1_items:\n                    for j in np.where(new_solution == 0)[0]:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            improvement = (value2_lst[j] - value1_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-6)\n                            if improvement > max_improvement:\n                                max_improvement = improvement\n                                best_candidate = (i, j)\n                if best_candidate:\n                    i, j = best_candidate\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        else:\n            # Replace high-value2 items with better value1 alternatives\n            high_value2_items = np.where((new_solution == 1) & (value2_lst > value1_lst))[0]\n            if len(high_value2_items) > 0:\n                best_candidate = None\n                max_improvement = 0\n                for i in high_value2_items:\n                    for j in np.where(new_solution == 0)[0]:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            improvement = (value1_lst[j] - value2_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-6)\n                            if improvement > max_improvement:\n                                max_improvement = improvement\n                                best_candidate = (i, j)\n                if best_candidate:\n                    i, j = best_candidate\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.9824145934822279,
            10.431624859571457
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a novel combination of objective diversity and solution density, then applies a multi-stage local search that alternates between objective-specific item swaps and capacity-aware intensification, while dynamically balancing the exploration of both objective spaces using adaptive weights.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Selection based on objective diversity and density\n    selection_scores = []\n    for sol, obj in archive:\n        # Calculate objective diversity\n        diversity = abs(obj[0] - obj[1]) / (obj[0] + obj[1] + 1e-6)\n        # Calculate solution density\n        density = np.sum(sol) / len(sol)\n        # Combined score with adaptive weights\n        selection_scores.append(0.6 * diversity + 0.4 * density)\n\n    selected_idx = np.argmax(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-stage local search\n    n_items = len(weight_lst)\n\n    # Stage 1: Objective-specific swaps\n    for _ in range(2):\n        # Value1-focused swaps\n        value1_ratios = value1_lst / (weight_lst + 1e-6)\n        top_value1 = np.argsort(-value1_ratios)[:min(2, n_items)]\n        bottom_value1 = np.argsort(value1_ratios)[:min(2, n_items)]\n\n        for i in top_value1:\n            for j in bottom_value1:\n                if new_solution[i] == 1 and new_solution[j] == 0:\n                    delta_weight = weight_lst[j] - weight_lst[i]\n                    if current_weight + delta_weight <= capacity:\n                        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                        current_weight += delta_weight\n                        break\n\n        # Value2-focused swaps\n        value2_ratios = value2_lst / (weight_lst + 1e-6)\n        top_value2 = np.argsort(-value2_ratios)[:min(2, n_items)]\n        bottom_value2 = np.argsort(value2_ratios)[:min(2, n_items)]\n\n        for i in top_value2:\n            for j in bottom_value2:\n                if new_solution[i] == 1 and new_solution[j] == 0:\n                    delta_weight = weight_lst[j] - weight_lst[i]\n                    if current_weight + delta_weight <= capacity:\n                        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                        current_weight += delta_weight\n                        break\n\n    # Stage 2: Capacity-aware intensification\n    if current_weight < capacity * 0.8:\n        # Add high-value items with balanced objectives\n        candidate_items = np.where(new_solution == 0)[0]\n        candidate_scores = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        candidate_scores[candidate_items] *= (capacity - current_weight) / capacity\n        top_candidates = np.argsort(-candidate_scores)[:min(3, len(candidate_items))]\n\n        for i in top_candidates:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Stage 3: Objective-balanced adjustments\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n\n    imbalance = abs(total_value1 - total_value2) / (total_value1 + total_value2 + 1e-6)\n    if imbalance > 0.2:\n        # Balance objectives by swapping items\n        if total_value1 > total_value2:\n            # Replace high-value1 items with better value2 alternatives\n            high_value1_items = np.where((new_solution == 1) & (value1_lst > value2_lst))[0]\n            if len(high_value1_items) > 0:\n                best_candidate = None\n                max_improvement = 0\n                for i in high_value1_items:\n                    for j in np.where(new_solution == 0)[0]:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            improvement = (value2_lst[j] - value1_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-6)\n                            if improvement > max_improvement:\n                                max_improvement = improvement\n                                best_candidate = (i, j)\n                if best_candidate:\n                    i, j = best_candidate\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        else:\n            # Replace high-value2 items with better value1 alternatives\n            high_value2_items = np.where((new_solution == 1) & (value2_lst > value1_lst))[0]\n            if len(high_value2_items) > 0:\n                best_candidate = None\n                max_improvement = 0\n                for i in high_value2_items:\n                    for j in np.where(new_solution == 0)[0]:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            improvement = (value1_lst[j] - value2_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-6)\n                            if improvement > max_improvement:\n                                max_improvement = improvement\n                                best_candidate = (i, j)\n                if best_candidate:\n                    i, j = best_candidate\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.9309408829729591,
            3.9082659482955933
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.5629710212465731,
            1.259714663028717
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a novel combination of objective contribution and solution sparsity, then applies a multi-stage local search that alternates between value-aware item swaps and capacity-constrained diversification, while dynamically balancing the exploration of both objective spaces.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Selection based on objective contribution and sparsity\n    selection_scores = []\n    for sol, obj in archive:\n        # Calculate objective contributions\n        contrib1 = obj[0] / np.sum(value1_lst * sol) if np.sum(sol) > 0 else 0\n        contrib2 = obj[1] / np.sum(value2_lst * sol) if np.sum(sol) > 0 else 0\n        # Calculate sparsity (proportion of excluded items)\n        sparsity = np.sum(sol == 0) / len(sol)\n        # Combined score\n        selection_scores.append((contrib1 + contrib2) * sparsity)\n\n    selected_idx = np.argmax(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-stage local search\n    n_items = len(weight_lst)\n\n    # Stage 1: Value-aware swaps\n    for _ in range(3):\n        # Calculate combined value-to-weight ratios\n        ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        # Find top and bottom items\n        top_items = np.argsort(ratios)[-min(3, n_items):]\n        bottom_items = np.argsort(ratios)[:min(3, n_items)]\n\n        for i in top_items:\n            for j in bottom_items:\n                if new_solution[i] == 1 and new_solution[j] == 0:\n                    delta_weight = weight_lst[j] - weight_lst[i]\n                    if current_weight + delta_weight <= capacity:\n                        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                        current_weight += delta_weight\n                        break\n\n    # Stage 2: Capacity-constrained diversification\n    if current_weight < capacity * 0.7:\n        # Add low-weight items with high potential\n        candidate_items = np.where(new_solution == 0)[0]\n        candidate_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        candidate_ratios[candidate_items] *= (capacity - current_weight) / capacity\n        top_candidates = np.argsort(-candidate_ratios)[:min(5, len(candidate_items))]\n\n        for i in top_candidates:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Stage 3: Objective-balanced adjustments\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n\n    if abs(total_value1 - total_value2) > 0.1 * (total_value1 + total_value2):\n        # Balance objectives by swapping items\n        if total_value1 > total_value2:\n            # Replace high-value1 items with better value2 alternatives\n            high_value1_items = np.where((new_solution == 1) & (value1_lst > value2_lst))[0]\n            if len(high_value1_items) > 0:\n                best_candidate = None\n                max_improvement = 0\n                for i in high_value1_items:\n                    for j in np.where(new_solution == 0)[0]:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            improvement = (value2_lst[j] - value1_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-6)\n                            if improvement > max_improvement:\n                                max_improvement = improvement\n                                best_candidate = (i, j)\n                if best_candidate:\n                    i, j = best_candidate\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        else:\n            # Replace high-value2 items with better value1 alternatives\n            high_value2_items = np.where((new_solution == 1) & (value2_lst > value1_lst))[0]\n            if len(high_value2_items) > 0:\n                best_candidate = None\n                max_improvement = 0\n                for i in high_value2_items:\n                    for j in np.where(new_solution == 0)[0]:\n                        if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                            improvement = (value1_lst[j] - value2_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-6)\n                            if improvement > max_improvement:\n                                max_improvement = improvement\n                                best_candidate = (i, j)\n                if best_candidate:\n                    i, j = best_candidate\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.9824145934822279,
            10.431624859571457
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This new algorithm selects a solution from the archive based on a Pareto-frontier dominance score and item diversity, then applies a hybrid local search that combines value-aware item swaps with a probabilistic exploration of high-potential item combinations while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on Pareto dominance and diversity\n    scores = []\n    for sol, obj in archive:\n        dominance_score = 0\n        for other_sol, other_obj in archive:\n            if other_obj[0] > obj[0] and other_obj[1] > obj[1]:\n                dominance_score += 1\n        diversity_score = np.sum(sol != archive[0][0]) / len(sol)\n        total_score = (1 - dominance_score / len(archive)) + diversity_score\n        scores.append(total_score)\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search with value-aware swaps\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate value efficiency for each objective\n    eff1 = value1_lst / (weight_lst + 1e-6)\n    eff2 = value2_lst / (weight_lst + 1e-6)\n    combined_eff = 0.3 * eff1 + 0.7 * eff2\n\n    # Perform strategic swaps between high-efficiency items\n    sorted_indices = np.argsort(-combined_eff)\n    for i in sorted_indices[:min(15, n_items)]:\n        if random.random() < 0.8:\n            if new_solution[i] == 0:\n                # Try adding item if it fits\n                new_weight = current_weight + weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n            else:\n                # Try removing item to make space for better items\n                new_weight = current_weight - weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i] = 0\n                    current_weight = new_weight\n\n    # Probabilistic exploration of high-potential item combinations\n    if n_items >= 4:\n        candidates = random.sample(range(n_items), min(8, n_items))\n        for i in candidates:\n            if random.random() < 0.4:\n                if new_solution[i] == 0:\n                    # Try adding item with probability based on its efficiency\n                    prob = min(0.8, combined_eff[i] / (max(combined_eff) + 1e-6))\n                    if random.random() < prob:\n                        new_weight = current_weight + weight_lst[i]\n                        if new_weight <= capacity:\n                            new_solution[i] = 1\n                            current_weight = new_weight\n\n    return new_solution\n\n",
        "score": [
            -0.6163810059126986,
            1.4421277940273285
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution diversity, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and diversity\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        diversity = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + diversity))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement with value-aware selection\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration with capacity-aware probability\n    value_weights = value1_lst * 0.7 + value2_lst * 0.3  # Weighted combination of objectives\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(15, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment with value-to-weight ratio optimization\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.5207255385596417,
            1.0074024200439453
        ]
    },
    {
        "algorithm": "{This new algorithm selects a solution from the archive based on a weighted combination of objective values and weight efficiency, then applies a hybrid local search that combines value-aware item swaps with a probabilistic exploration of high-potential item combinations while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on weighted objective combination\n    scores = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        score = (0.4 * obj[0] + 0.6 * obj[1]) / (total_weight + 1e-6)\n        scores.append(score)\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search with value-aware swaps\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate value efficiency for each objective\n    eff1 = value1_lst / (weight_lst + 1e-6)\n    eff2 = value2_lst / (weight_lst + 1e-6)\n    combined_eff = 0.5 * eff1 + 0.5 * eff2\n    sorted_indices = np.argsort(-combined_eff)\n\n    # Perform strategic swaps between high-efficiency items\n    for i in sorted_indices[:min(10, n_items)]:\n        if random.random() < 0.7:\n            if new_solution[i] == 0:\n                # Try adding item if it fits\n                new_weight = current_weight + weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n            else:\n                # Try removing item to make space for better items\n                new_weight = current_weight - weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i] = 0\n                    current_weight = new_weight\n\n    # Probabilistic exploration of high-potential item combinations\n    if n_items >= 3:\n        candidates = random.sample(range(n_items), min(5, n_items))\n        for i in candidates:\n            if random.random() < 0.3:\n                if new_solution[i] == 0:\n                    # Try adding item with probability based on its efficiency\n                    prob = min(0.9, combined_eff[i] / (max(combined_eff) + 1e-6))\n                    if random.random() < prob:\n                        new_weight = current_weight + weight_lst[i]\n                        if new_weight <= capacity:\n                            new_solution[i] = 1\n                            current_weight = new_weight\n\n    return new_solution\n\n",
        "score": [
            -0.5451975623412475,
            1.1356434226036072
        ]
    },
    {
        "algorithm": "{My new algorithm selects a solution from the archive based on a value-aware selection metric that prioritizes items with high marginal value improvements, then applies a hybrid local search strategy that combines greedy item swaps with probabilistic diversification to explore the solution space while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Calculate value-aware selection metric\n    selection_metrics = []\n    for sol, obj in archive:\n        # Metric combines current objective values and marginal improvement potential\n        marginal1 = np.sum(value1_lst * (1 - sol))\n        marginal2 = np.sum(value2_lst * (1 - sol))\n        selection_metrics.append(obj[0] + obj[1] + 0.5 * (marginal1 + marginal2))\n\n    # Select solution with highest metric\n    selected_idx = np.argmax(selection_metrics)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search with greedy swaps and probabilistic diversification\n    current_weight = np.sum(weight_lst * new_solution)\n    n_items = len(weight_lst)\n\n    # First phase: greedy swaps for high-value items\n    item_scores = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n    sorted_items = np.argsort(item_scores)[::-1]\n\n    for i in sorted_items[:min(10, n_items)]:\n        if new_solution[i] == 1:\n            # Try removing item if it's not critical\n            if current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n        else:\n            # Try adding item if it fits\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Second phase: probabilistic diversification\n    for _ in range(3):\n        # Randomly select an item to flip\n        candidate_items = np.where(new_solution == 1)[0]\n        if len(candidate_items) == 0:\n            break\n        i = random.choice(candidate_items)\n\n        # Probability to remove based on weight and value\n        prob_remove = (weight_lst[i] / (value1_lst[i] + value2_lst[i] + 1e-6)) * 0.3\n        if random.random() < prob_remove:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.8977825424592201,
            3.0030709505081177
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and solution density, then applies a novel multi-phase local search that combines probabilistic item replacement with value-weighted neighborhood exploration, ensuring feasibility through dynamic capacity adjustment and always prioritizing Pareto-optimal improvements.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on hybrid of dominance and density\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated_count = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated_count += 1\n        density = np.sum(np.abs(sol - archive[0][0]))\n        dominance_scores.append((len(archive) - dominated_count) * (1 + density))\n\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic item replacement\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    # Phase 2: Value-weighted neighborhood exploration\n    value_weights = value1_lst + value2_lst\n    sorted_indices = np.argsort(-value_weights)\n\n    for i in sorted_indices[:min(10, len(weight_lst))]:\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on value and remaining capacity\n                prob = (value_weights[i] / (weight_lst[i] + 1e-6)) * ((capacity - current_weight) / capacity)\n                if random.random() < prob:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Phase 3: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest value-to-weight ratio until feasible\n            item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_removals = np.argsort(item_ratios[included_items])\n            for i in sorted_removals:\n                if excess <= 0:\n                    break\n                if weight_lst[included_items[i]] <= excess:\n                    new_solution[included_items[i]] = 0\n                    excess -= weight_lst[included_items[i]]\n\n    return new_solution\n\n",
        "score": [
            -0.4217740555113979,
            0.7323683500289917
        ]
    },
    {
        "algorithm": "{This new algorithm selects a solution from the archive based on a weighted combination of objective values and weight efficiency, then applies a hybrid local search that combines value-aware item swaps with a probabilistic exploration of high-potential item combinations while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on weighted objective combination\n    scores = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        score = (0.4 * obj[0] + 0.6 * obj[1]) / (total_weight + 1e-6)\n        scores.append(score)\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search with value-aware swaps\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate value efficiency for each objective\n    eff1 = value1_lst / (weight_lst + 1e-6)\n    eff2 = value2_lst / (weight_lst + 1e-6)\n    combined_eff = 0.5 * eff1 + 0.5 * eff2\n    sorted_indices = np.argsort(-combined_eff)\n\n    # Perform strategic swaps between high-efficiency items\n    for i in sorted_indices[:min(10, n_items)]:\n        if random.random() < 0.7:\n            if new_solution[i] == 0:\n                # Try adding item if it fits\n                new_weight = current_weight + weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n            else:\n                # Try removing item to make space for better items\n                new_weight = current_weight - weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i] = 0\n                    current_weight = new_weight\n\n    # Probabilistic exploration of high-potential item combinations\n    if n_items >= 3:\n        candidates = random.sample(range(n_items), min(5, n_items))\n        for i in candidates:\n            if random.random() < 0.3:\n                if new_solution[i] == 0:\n                    # Try adding item with probability based on its efficiency\n                    prob = min(0.9, combined_eff[i] / (max(combined_eff) + 1e-6))\n                    if random.random() < prob:\n                        new_weight = current_weight + weight_lst[i]\n                        if new_weight <= capacity:\n                            new_solution[i] = 1\n                            current_weight = new_weight\n\n    return new_solution\n\n",
        "score": [
            -0.5451975623412475,
            1.1356434226036072
        ]
    },
    {
        "algorithm": "{My new algorithm selects a solution from the archive based on a combination of objective dominance and solution density, then applies a hybrid local search that combines strategic item insertions with a probabilistic neighborhood exploration to generate high-quality neighbors while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on objective dominance and density\n    dominance_counts = []\n    for sol, obj in archive:\n        dominated = 0\n        for other_sol, other_obj in archive:\n            if other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1]):\n                dominated += 1\n        dominance_counts.append(dominated)\n\n    selected_idx = np.argmin(dominance_counts)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Dynamic neighborhood exploration with probabilistic insertions\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Consider both high-value and low-weight items first\n    value_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(-value_ratios)\n\n    # Perform targeted insertions with probability based on value ratio\n    for i in sorted_indices[:min(15, n_items)]:\n        if random.random() < 0.6:  # Higher probability for better items\n            if new_solution[i] == 0:\n                new_weight = current_weight + weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n\n    # Additional probabilistic removal of low-value items\n    for i in range(n_items):\n        if new_solution[i] == 1 and random.random() < 0.3:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    return new_solution\n\n",
        "score": [
            -0.8517583988017057,
            1.496477872133255
        ]
    },
    {
        "algorithm": "{My algorithm selects a solution from the archive based on a combination of objective diversity and solution density, then applies a novel local search that combines adaptive item grouping with a probabilistic neighborhood exploration using a dynamic value-weight balance metric to generate high-quality neighbors while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution based on objective diversity and solution density\n    diversity_scores = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        density = (obj[0] + obj[1]) / (total_weight + 1e-6)\n        diversity = abs(obj[0] - obj[1]) / (obj[0] + obj[1] + 1e-6)\n        score = density * diversity\n        diversity_scores.append(score)\n\n    selected_idx = np.argmax(diversity_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Adaptive item grouping based on value-weight balance\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Create groups of items with similar value-weight ratios\n    value_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(value_ratios)\n    groups = []\n    group_size = max(1, n_items // 5)\n    for i in range(0, n_items, group_size):\n        groups.append(sorted_indices[i:i+group_size])\n\n    # Dynamic neighborhood exploration with probabilistic group swaps\n    for group in groups:\n        if random.random() < 0.6:  # Higher probability for groups\n            # Try to add or remove entire group\n            group_weight = np.sum(weight_lst[group])\n            if np.all(new_solution[group] == 1):\n                new_weight = current_weight - group_weight\n                if new_weight <= capacity:\n                    new_solution[group] = 0\n                    current_weight = new_weight\n            else:\n                new_weight = current_weight + group_weight\n                if new_weight <= capacity:\n                    new_solution[group] = 1\n                    current_weight = new_weight\n\n    # Additional probabilistic intra-group swaps\n    if n_items >= 2:\n        group = random.choice(groups)\n        i, j = random.sample(range(len(group)), 2)\n        i, j = group[i], group[j]\n        if new_solution[i] != new_solution[j]:\n            if new_solution[i] == 1:\n                new_weight = current_weight - weight_lst[i] + weight_lst[j]\n                if new_weight <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            else:\n                new_weight = current_weight + weight_lst[i] - weight_lst[j]\n                if new_weight <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.8785454361089735,
            2.0242074728012085
        ]
    }
]