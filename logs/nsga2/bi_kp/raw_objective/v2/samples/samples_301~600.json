[
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{This new algorithm selects a solution from the archive by prioritizing those with high normalized objective values and low weight, then applies a novel local search operator that intelligently combines features from the selected solution with a randomly generated solution by flipping subsets of items while ensuring feasibility, but uses a different scoring function that weights each objective based on their relative importance determined by the archive's diversity, and additionally employs a probabilistic acceptance criterion to balance exploration and exploitation during the local search process, and also considers the correlation between objectives to guide the flip decisions.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on normalized objectives and weight efficiency\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([sol for sol, _ in archive])\n    total_weights = np.sum(weight_lst * weights, axis=1)\n    min_obj = objectives.min(axis=0)\n    max_obj = objectives.max(axis=0)\n    normalized_obj = (objectives - min_obj) / (max_obj - min_obj + 1e-10)\n    normalized_weights = (total_weights - np.min(total_weights)) / (np.max(total_weights) - np.min(total_weights) + 1e-10)\n\n    # Calculate correlation between objectives\n    obj_corr = np.corrcoef(objectives[:, 0], objectives[:, 1])[0, 1]\n    obj_weight = 0.5 + 0.4 * obj_corr  # Higher correlation means more balanced weighting\n\n    scores = obj_weight * normalized_obj[:, 0] + (1 - obj_weight) * normalized_obj[:, 1] - 0.2 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a random solution for comparison\n    random_solution = np.random.randint(0, 2, size=len(base_solution))\n    random_weight = np.sum(weight_lst * random_solution)\n    while random_weight > capacity:\n        random_solution = np.random.randint(0, 2, size=len(base_solution))\n        random_weight = np.sum(weight_lst * random_solution)\n\n    # Hybrid local search with probabilistic acceptance and adaptive flip size\n    new_solution = base_solution.copy()\n    flip_size = max(1, min(5, len(base_solution) // 3))\n    flip_indices = np.random.choice(len(base_solution), size=flip_size, replace=False)\n\n    for idx in flip_indices:\n        # Try flipping the item\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n        temp_weight = np.sum(weight_lst * temp_solution)\n\n        if temp_weight <= capacity:\n            # Accept the flip with probability based on improvement in both objectives\n            current_value1 = np.sum(value1_lst * new_solution)\n            current_value2 = np.sum(value2_lst * new_solution)\n            new_value1 = np.sum(value1_lst * temp_solution)\n            new_value2 = np.sum(value2_lst * temp_solution)\n\n            improvement1 = new_value1 - current_value1\n            improvement2 = new_value2 - current_value2\n\n            # Probability of acceptance is higher if both objectives improve or one improves significantly\n            # Also consider objective correlation in acceptance probability\n            prob_accept = 0.5 + 0.3 * (improvement1 > 0 and improvement2 > 0) + 0.2 * (improvement1 > 0 or improvement2 > 0)\n            prob_accept = prob_accept * (1 + 0.1 * obj_corr)  # Higher correlation increases acceptance probability\n\n            if random.random() < prob_accept:\n                new_solution = temp_solution\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{This new algorithm selects a solution from the archive by prioritizing those with high normalized objective values and low weight, then applies a novel local search operator that intelligently combines features from the selected solution with a randomly generated solution by flipping subsets of items while ensuring feasibility, but uses a different scoring function that weights each objective based on their relative importance determined by the archive's diversity, and additionally employs a probabilistic acceptance criterion to balance exploration and exploitation during the local search process, and also considers the correlation between objectives to guide the flip decisions.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on normalized objectives and weight efficiency\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([sol for sol, _ in archive])\n    total_weights = np.sum(weight_lst * weights, axis=1)\n    min_obj = objectives.min(axis=0)\n    max_obj = objectives.max(axis=0)\n    normalized_obj = (objectives - min_obj) / (max_obj - min_obj + 1e-10)\n    normalized_weights = (total_weights - np.min(total_weights)) / (np.max(total_weights) - np.min(total_weights) + 1e-10)\n\n    # Calculate correlation between objectives\n    obj_corr = np.corrcoef(objectives[:, 0], objectives[:, 1])[0, 1]\n    obj_weight = 0.5 + 0.4 * obj_corr  # Higher correlation means more balanced weighting\n\n    scores = obj_weight * normalized_obj[:, 0] + (1 - obj_weight) * normalized_obj[:, 1] - 0.2 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a random solution for comparison\n    random_solution = np.random.randint(0, 2, size=len(base_solution))\n    random_weight = np.sum(weight_lst * random_solution)\n    while random_weight > capacity:\n        random_solution = np.random.randint(0, 2, size=len(base_solution))\n        random_weight = np.sum(weight_lst * random_solution)\n\n    # Hybrid local search with probabilistic acceptance and adaptive flip size\n    new_solution = base_solution.copy()\n    flip_size = max(1, min(5, len(base_solution) // 3))\n    flip_indices = np.random.choice(len(base_solution), size=flip_size, replace=False)\n\n    for idx in flip_indices:\n        # Try flipping the item\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n        temp_weight = np.sum(weight_lst * temp_solution)\n\n        if temp_weight <= capacity:\n            # Accept the flip with probability based on improvement in both objectives\n            current_value1 = np.sum(value1_lst * new_solution)\n            current_value2 = np.sum(value2_lst * new_solution)\n            new_value1 = np.sum(value1_lst * temp_solution)\n            new_value2 = np.sum(value2_lst * temp_solution)\n\n            improvement1 = new_value1 - current_value1\n            improvement2 = new_value2 - current_value2\n\n            # Probability of acceptance is higher if both objectives improve or one improves significantly\n            # Also consider objective correlation in acceptance probability\n            prob_accept = 0.5 + 0.3 * (improvement1 > 0 and improvement2 > 0) + 0.2 * (improvement1 > 0 or improvement2 > 0)\n            prob_accept = prob_accept * (1 + 0.1 * obj_corr)  # Higher correlation increases acceptance probability\n\n            if random.random() < prob_accept:\n                new_solution = temp_solution\n\n    return new_solution\n\n\nPlease help me create a new algorithm that has a totally different form from the given ones. \n1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nDo not give additional explanations.",
        "sample_order": 301,
        "algorithm": "{This new algorithm selects a solution from the archive by prioritizing those with high normalized objective values and low weight, then applies a novel local search operator that intelligently combines features from the selected solution with a randomly generated solution by flipping subsets of items while ensuring feasibility, but uses a different scoring function that weights each objective based on their relative importance determined by the archive's diversity, and additionally employs a probabilistic acceptance criterion to balance exploration and exploitation during the local search process, and also considers the correlation between objectives to guide the flip decisions.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on normalized objectives and weight efficiency\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([sol for sol, _ in archive])\n    total_weights = np.sum(weight_lst * weights, axis=1)\n    min_obj = objectives.min(axis=0)\n    max_obj = objectives.max(axis=0)\n    normalized_obj = (objectives - min_obj) / (max_obj - min_obj + 1e-10)\n    normalized_weights = (total_weights - np.min(total_weights)) / (np.max(total_weights) - np.min(total_weights) + 1e-10)\n\n    # Calculate correlation between objectives\n    obj_corr = np.corrcoef(objectives[:, 0], objectives[:, 1])[0, 1]\n    obj_weight = 0.5 + 0.4 * obj_corr  # Higher correlation means more balanced weighting\n\n    scores = obj_weight * normalized_obj[:, 0] + (1 - obj_weight) * normalized_obj[:, 1] - 0.2 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a random solution for comparison\n    random_solution = np.random.randint(0, 2, size=len(base_solution))\n    random_weight = np.sum(weight_lst * random_solution)\n    while random_weight > capacity:\n        random_solution = np.random.randint(0, 2, size=len(base_solution))\n        random_weight = np.sum(weight_lst * random_solution)\n\n    # Hybrid local search with probabilistic acceptance and adaptive flip size\n    new_solution = base_solution.copy()\n    flip_size = max(1, min(5, len(base_solution) // 3))\n    flip_indices = np.random.choice(len(base_solution), size=flip_size, replace=False)\n\n    for idx in flip_indices:\n        # Try flipping the item\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n        temp_weight = np.sum(weight_lst * temp_solution)\n\n        if temp_weight <= capacity:\n            # Accept the flip with probability based on improvement in both objectives\n            current_value1 = np.sum(value1_lst * new_solution)\n            current_value2 = np.sum(value2_lst * new_solution)\n            new_value1 = np.sum(value1_lst * temp_solution)\n            new_value2 = np.sum(value2_lst * temp_solution)\n\n            improvement1 = new_value1 - current_value1\n            improvement2 = new_value2 - current_value2\n\n            # Probability of acceptance is higher if both objectives improve or one improves significantly\n            # Also consider objective correlation in acceptance probability\n            prob_accept = 0.5 + 0.3 * (improvement1 > 0 and improvement2 > 0) + 0.2 * (improvement1 > 0 or improvement2 > 0)\n            prob_accept = prob_accept * (1 + 0.1 * obj_corr)  # Higher correlation increases acceptance probability\n\n            if random.random() < prob_accept:\n                new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -17.19383201751435,
            -19.654506183464242
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on normalized objectives and weight efficiency\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([sol for sol, _ in archive])\n    total_weights = np.sum(weight_lst * weights, axis=1)\n    min_obj = objectives.min(axis=0)\n    max_obj = objectives.max(axis=0)\n    normalized_obj = (objectives - min_obj) / (max_obj - min_obj + 1e-10)\n    normalized_weights = (total_weights - np.min(total_weights)) / (np.max(total_weights) - np.min(total_weights) + 1e-10)\n\n    # Calculate correlation between objectives\n    obj_corr = np.corrcoef(objectives[:, 0], objectives[:, 1])[0, 1]\n    obj_weight = 0.5 + 0.4 * obj_corr  # Higher correlation means more balanced weighting\n\n    scores = obj_weight * normalized_obj[:, 0] + (1 - obj_weight) * normalized_obj[:, 1] - 0.2 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a random solution for comparison\n    random_solution = np.random.randint(0, 2, size=len(base_solution))\n    random_weight = np.sum(weight_lst * random_solution)\n    while random_weight > capacity:\n        random_solution = np.random.randint(0, 2, size=len(base_solution))\n        random_weight = np.sum(weight_lst * random_solution)\n\n    # Hybrid local search with probabilistic acceptance and adaptive flip size\n    new_solution = base_solution.copy()\n    flip_size = max(1, min(5, len(base_solution) // 3))\n    flip_indices = np.random.choice(len(base_solution), size=flip_size, replace=False)\n\n    for idx in flip_indices:\n        # Try flipping the item\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n        temp_weight = np.sum(weight_lst * temp_solution)\n\n        if temp_weight <= capacity:\n            # Accept the flip with probability based on improvement in both objectives\n            current_value1 = np.sum(value1_lst * new_solution)\n            current_value2 = np.sum(value2_lst * new_solution)\n            new_value1 = np.sum(value1_lst * temp_solution)\n            new_value2 = np.sum(value2_lst * temp_solution)\n\n            improvement1 = new_value1 - current_value1\n            improvement2 = new_value2 - current_value2\n\n            # Probability of acceptance is higher if both objectives improve or one improves significantly\n            # Also consider objective correlation in acceptance probability\n            prob_accept = 0.5 + 0.3 * (improvement1 > 0 and improvement2 > 0) + 0.2 * (improvement1 > 0 or improvement2 > 0)\n            prob_accept = prob_accept * (1 + 0.1 * obj_corr)  # Higher correlation increases acceptance probability\n\n            if random.random() < prob_accept:\n                new_solution = temp_solution\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{This new algorithm selects a solution from the archive by prioritizing those with high normalized objective values and low weight, then applies a novel local search operator that intelligently combines features from the selected solution with a randomly generated solution by flipping subsets of items while ensuring feasibility, but uses a different scoring function that weights each objective based on their relative importance determined by the archive's diversity, and additionally employs a probabilistic acceptance criterion to balance exploration and exploitation during the local search process.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution (weighted sum of normalized objectives and weight efficiency)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([sol for sol, _ in archive])\n    total_weights = np.sum(weight_lst * weights, axis=1)\n    min_obj = objectives.min(axis=0)\n    max_obj = objectives.max(axis=0)\n    normalized_obj = (objectives - min_obj) / (max_obj - min_obj + 1e-10)\n    normalized_weights = (total_weights - np.min(total_weights)) / (np.max(total_weights) - np.min(total_weights) + 1e-10)\n    scores = 0.6 * normalized_obj[:, 0] + 0.3 * normalized_obj[:, 1] - 0.1 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a random solution for comparison\n    random_solution = np.random.randint(0, 2, size=len(base_solution))\n    random_weight = np.sum(weight_lst * random_solution)\n    while random_weight > capacity:\n        random_solution = np.random.randint(0, 2, size=len(base_solution))\n        random_weight = np.sum(weight_lst * random_solution)\n\n    # Hybrid local search with probabilistic acceptance and adaptive flip size\n    new_solution = base_solution.copy()\n    flip_size = max(1, min(5, len(base_solution) // 3))\n    flip_indices = np.random.choice(len(base_solution), size=flip_size, replace=False)\n\n    for idx in flip_indices:\n        # Try flipping the item\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n        temp_weight = np.sum(weight_lst * temp_solution)\n\n        if temp_weight <= capacity:\n            # Accept the flip with probability based on improvement in both objectives\n            current_value1 = np.sum(value1_lst * new_solution)\n            current_value2 = np.sum(value2_lst * new_solution)\n            new_value1 = np.sum(value1_lst * temp_solution)\n            new_value2 = np.sum(value2_lst * temp_solution)\n\n            improvement1 = new_value1 - current_value1\n            improvement2 = new_value2 - current_value2\n\n            # Probability of acceptance is higher if both objectives improve or one improves significantly\n            prob_accept = 0.5 + 0.3 * (improvement1 > 0 and improvement2 > 0) + 0.2 * (improvement1 > 0 or improvement2 > 0)\n            if random.random() < prob_accept:\n                new_solution = temp_solution\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{This new algorithm selects a solution from the archive by prioritizing those with high normalized objective values and low weight, then applies a novel local search operator that intelligently combines features from the selected solution with a randomly generated solution by flipping subsets of items while ensuring feasibility, but uses a different scoring function that weights each objective based on their relative importance determined by the archive's diversity, and additionally employs a probabilistic acceptance criterion to balance exploration and exploitation during the local search process.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution (weighted sum of normalized objectives and weight efficiency)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([sol for sol, _ in archive])\n    total_weights = np.sum(weight_lst * weights, axis=1)\n    min_obj = objectives.min(axis=0)\n    max_obj = objectives.max(axis=0)\n    normalized_obj = (objectives - min_obj) / (max_obj - min_obj + 1e-10)\n    normalized_weights = (total_weights - np.min(total_weights)) / (np.max(total_weights) - np.min(total_weights) + 1e-10)\n    scores = 0.6 * normalized_obj[:, 0] + 0.3 * normalized_obj[:, 1] - 0.1 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a random solution for comparison\n    random_solution = np.random.randint(0, 2, size=len(base_solution))\n    random_weight = np.sum(weight_lst * random_solution)\n    while random_weight > capacity:\n        random_solution = np.random.randint(0, 2, size=len(base_solution))\n        random_weight = np.sum(weight_lst * random_solution)\n\n    # Hybrid local search with probabilistic acceptance and adaptive flip size\n    new_solution = base_solution.copy()\n    flip_size = max(1, min(5, len(base_solution) // 3))\n    flip_indices = np.random.choice(len(base_solution), size=flip_size, replace=False)\n\n    for idx in flip_indices:\n        # Try flipping the item\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n        temp_weight = np.sum(weight_lst * temp_solution)\n\n        if temp_weight <= capacity:\n            # Accept the flip with probability based on improvement in both objectives\n            current_value1 = np.sum(value1_lst * new_solution)\n            current_value2 = np.sum(value2_lst * new_solution)\n            new_value1 = np.sum(value1_lst * temp_solution)\n            new_value2 = np.sum(value2_lst * temp_solution)\n\n            improvement1 = new_value1 - current_value1\n            improvement2 = new_value2 - current_value2\n\n            # Probability of acceptance is higher if both objectives improve or one improves significantly\n            prob_accept = 0.5 + 0.3 * (improvement1 > 0 and improvement2 > 0) + 0.2 * (improvement1 > 0 or improvement2 > 0)\n            if random.random() < prob_accept:\n                new_solution = temp_solution\n\n    return new_solution\n\n\nPlease help me create a new algorithm that has a totally different form from the given ones. \n1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nDo not give additional explanations.",
        "sample_order": 302,
        "algorithm": "{This new algorithm selects a solution from the archive by prioritizing those with high normalized objective values and low weight, then applies a novel local search operator that intelligently combines features from the selected solution with a randomly generated solution by flipping subsets of items while ensuring feasibility, but uses a different scoring function that weights each objective based on their relative importance determined by the archive's diversity, and additionally employs a probabilistic acceptance criterion to balance exploration and exploitation during the local search process.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on hypervolume contribution and weight efficiency\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([sol for sol, _ in archive])\n    total_weights = np.sum(weight_lst * weights, axis=1)\n\n    # Calculate hypervolume contribution as a proxy for solution quality\n    sorted_idx = np.lexsort((-objectives[:, 0], -objectives[:, 1]))\n    hypervolume = np.zeros(len(archive))\n    reference_point = objectives.max(axis=0) * 1.1  # Slightly above the maximum\n\n    for i, idx in enumerate(sorted_idx):\n        if i == 0:\n            hypervolume[idx] = (reference_point[0] - objectives[idx, 0]) * (reference_point[1] - objectives[idx, 1])\n        else:\n            prev_idx = sorted_idx[i-1]\n            hypervolume[idx] = (objectives[prev_idx, 0] - objectives[idx, 0]) * (objectives[prev_idx, 1] - objectives[idx, 1])\n\n    # Combine hypervolume and weight efficiency\n    normalized_hyper = (hypervolume - hypervolume.min()) / (hypervolume.max() - hypervolume.min() + 1e-10)\n    normalized_weights = (total_weights - total_weights.min()) / (total_weights.max() - total_weights.min() + 1e-10)\n    scores = 0.7 * normalized_hyper - 0.3 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a diverse solution by combining features from multiple archive solutions\n    new_solution = base_solution.copy()\n    num_combine = min(3, len(archive))\n    combine_indices = np.random.choice(len(archive), size=num_combine, replace=False)\n\n    for idx in combine_indices:\n        if idx != selected_idx:\n            other_solution = archive[idx][0]\n            # Randomly select items from other solutions with probability based on their presence\n            for i in range(len(new_solution)):\n                if random.random() < 0.3 and other_solution[i] == 1:\n                    temp_solution = new_solution.copy()\n                    temp_solution[i] = 1\n                    temp_weight = np.sum(weight_lst * temp_solution)\n                    if temp_weight <= capacity:\n                        new_solution = temp_solution\n\n    # Apply a targeted flip operation based on value-to-weight ratio\n    value_weight_ratio1 = value1_lst / (weight_lst + 1e-10)\n    value_weight_ratio2 = value2_lst / (weight_lst + 1e-10)\n    combined_ratio = 0.6 * value_weight_ratio1 + 0.4 * value_weight_ratio2\n\n    # Identify items to potentially flip based on high value-to-weight ratio\n    flip_candidates = np.argsort(combined_ratio)[-min(5, len(combined_ratio)):]\n\n    for idx in flip_candidates:\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n        temp_weight = np.sum(weight_lst * temp_solution)\n\n        if temp_weight <= capacity:\n            # Accept with probability based on improvement in both objectives\n            current_value1 = np.sum(value1_lst * new_solution)\n            current_value2 = np.sum(value2_lst * new_solution)\n            new_value1 = np.sum(value1_lst * temp_solution)\n            new_value2 = np.sum(value2_lst * temp_solution)\n\n            improvement1 = new_value1 - current_value1\n            improvement2 = new_value2 - current_value2\n\n            prob_accept = 0.4 + 0.4 * (improvement1 > 0 and improvement2 > 0) + 0.2 * (improvement1 > 0 or improvement2 > 0)\n            if random.random() < prob_accept:\n                new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -15.488008881781887,
            -15.851339872446614
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on hypervolume contribution and weight efficiency\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([sol for sol, _ in archive])\n    total_weights = np.sum(weight_lst * weights, axis=1)\n\n    # Calculate hypervolume contribution as a proxy for solution quality\n    sorted_idx = np.lexsort((-objectives[:, 0], -objectives[:, 1]))\n    hypervolume = np.zeros(len(archive))\n    reference_point = objectives.max(axis=0) * 1.1  # Slightly above the maximum\n\n    for i, idx in enumerate(sorted_idx):\n        if i == 0:\n            hypervolume[idx] = (reference_point[0] - objectives[idx, 0]) * (reference_point[1] - objectives[idx, 1])\n        else:\n            prev_idx = sorted_idx[i-1]\n            hypervolume[idx] = (objectives[prev_idx, 0] - objectives[idx, 0]) * (objectives[prev_idx, 1] - objectives[idx, 1])\n\n    # Combine hypervolume and weight efficiency\n    normalized_hyper = (hypervolume - hypervolume.min()) / (hypervolume.max() - hypervolume.min() + 1e-10)\n    normalized_weights = (total_weights - total_weights.min()) / (total_weights.max() - total_weights.min() + 1e-10)\n    scores = 0.7 * normalized_hyper - 0.3 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a diverse solution by combining features from multiple archive solutions\n    new_solution = base_solution.copy()\n    num_combine = min(3, len(archive))\n    combine_indices = np.random.choice(len(archive), size=num_combine, replace=False)\n\n    for idx in combine_indices:\n        if idx != selected_idx:\n            other_solution = archive[idx][0]\n            # Randomly select items from other solutions with probability based on their presence\n            for i in range(len(new_solution)):\n                if random.random() < 0.3 and other_solution[i] == 1:\n                    temp_solution = new_solution.copy()\n                    temp_solution[i] = 1\n                    temp_weight = np.sum(weight_lst * temp_solution)\n                    if temp_weight <= capacity:\n                        new_solution = temp_solution\n\n    # Apply a targeted flip operation based on value-to-weight ratio\n    value_weight_ratio1 = value1_lst / (weight_lst + 1e-10)\n    value_weight_ratio2 = value2_lst / (weight_lst + 1e-10)\n    combined_ratio = 0.6 * value_weight_ratio1 + 0.4 * value_weight_ratio2\n\n    # Identify items to potentially flip based on high value-to-weight ratio\n    flip_candidates = np.argsort(combined_ratio)[-min(5, len(combined_ratio)):]\n\n    for idx in flip_candidates:\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n        temp_weight = np.sum(weight_lst * temp_solution)\n\n        if temp_weight <= capacity:\n            # Accept with probability based on improvement in both objectives\n            current_value1 = np.sum(value1_lst * new_solution)\n            current_value2 = np.sum(value2_lst * new_solution)\n            new_value1 = np.sum(value1_lst * temp_solution)\n            new_value2 = np.sum(value2_lst * temp_solution)\n\n            improvement1 = new_value1 - current_value1\n            improvement2 = new_value2 - current_value2\n\n            prob_accept = 0.4 + 0.4 * (improvement1 > 0 and improvement2 > 0) + 0.2 * (improvement1 > 0 or improvement2 > 0)\n            if random.random() < prob_accept:\n                new_solution = temp_solution\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have one algorithm with its code as follows. Algorithm description:\n{This new algorithm selects a solution from the archive by prioritizing those with high normalized objective values and low weight, then applies a novel local search operator that intelligently combines features from the selected solution with a randomly generated solution by flipping subsets of items while ensuring feasibility, but uses a different scoring function that weights each objective based on their relative importance determined by the archive's diversity, and additionally employs a probabilistic acceptance criterion to balance exploration and exploitation during the local search process.}\nCode:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution (weighted sum of normalized objectives and weight efficiency)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([sol for sol, _ in archive])\n    total_weights = np.sum(weight_lst * weights, axis=1)\n    min_obj = objectives.min(axis=0)\n    max_obj = objectives.max(axis=0)\n    normalized_obj = (objectives - min_obj) / (max_obj - min_obj + 1e-10)\n    normalized_weights = (total_weights - np.min(total_weights)) / (np.max(total_weights) - np.min(total_weights) + 1e-10)\n    scores = 0.6 * normalized_obj[:, 0] + 0.3 * normalized_obj[:, 1] - 0.1 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a random solution for comparison\n    random_solution = np.random.randint(0, 2, size=len(base_solution))\n    random_weight = np.sum(weight_lst * random_solution)\n    while random_weight > capacity:\n        random_solution = np.random.randint(0, 2, size=len(base_solution))\n        random_weight = np.sum(weight_lst * random_solution)\n\n    # Hybrid local search with probabilistic acceptance and adaptive flip size\n    new_solution = base_solution.copy()\n    flip_size = max(1, min(5, len(base_solution) // 3))\n    flip_indices = np.random.choice(len(base_solution), size=flip_size, replace=False)\n\n    for idx in flip_indices:\n        # Try flipping the item\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n        temp_weight = np.sum(weight_lst * temp_solution)\n\n        if temp_weight <= capacity:\n            # Accept the flip with probability based on improvement in both objectives\n            current_value1 = np.sum(value1_lst * new_solution)\n            current_value2 = np.sum(value2_lst * new_solution)\n            new_value1 = np.sum(value1_lst * temp_solution)\n            new_value2 = np.sum(value2_lst * temp_solution)\n\n            improvement1 = new_value1 - current_value1\n            improvement2 = new_value2 - current_value2\n\n            # Probability of acceptance is higher if both objectives improve or one improves significantly\n            prob_accept = 0.5 + 0.3 * (improvement1 > 0 and improvement2 > 0) + 0.2 * (improvement1 > 0 or improvement2 > 0)\n            if random.random() < prob_accept:\n                new_solution = temp_solution\n\n    return new_solution\n\n\nPlease identify the main algorithm parameters and assist me in creating a new algorithm that has a different parameter settings of the score function provided.\n1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nDo not give additional explanations.",
        "sample_order": 303,
        "algorithm": "{This new algorithm selects a solution from the archive by prioritizing those with high normalized objective values and low weight, then applies a hybrid local search operator that intelligently combines features from the selected solution with a randomly generated solution by flipping subsets of items while ensuring feasibility, but uses a different scoring function that weights each objective based on their relative importance determined by the archive's diversity, and additionally employs a probabilistic acceptance criterion to balance exploration and exploitation during the local search process.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([sol for sol, _ in archive])\n    total_weights = np.sum(weight_lst * weights, axis=1)\n    min_obj = objectives.min(axis=0)\n    max_obj = objectives.max(axis=0)\n    normalized_obj = (objectives - min_obj) / (max_obj - min_obj + 1e-10)\n    normalized_weights = (total_weights - np.min(total_weights)) / (np.max(total_weights) - np.min(total_weights) + 1e-10)\n    scores = 0.4 * normalized_obj[:, 0] + 0.5 * normalized_obj[:, 1] - 0.2 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    random_solution = np.random.randint(0, 2, size=len(base_solution))\n    random_weight = np.sum(weight_lst * random_solution)\n    while random_weight > capacity:\n        random_solution = np.random.randint(0, 2, size=len(base_solution))\n        random_weight = np.sum(weight_lst * random_solution)\n\n    new_solution = base_solution.copy()\n    flip_size = max(1, min(5, len(base_solution) // 4))\n    flip_indices = np.random.choice(len(base_solution), size=flip_size, replace=False)\n\n    for idx in flip_indices:\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n        temp_weight = np.sum(weight_lst * temp_solution)\n\n        if temp_weight <= capacity:\n            current_value1 = np.sum(value1_lst * new_solution)\n            current_value2 = np.sum(value2_lst * new_solution)\n            new_value1 = np.sum(value1_lst * temp_solution)\n            new_value2 = np.sum(value2_lst * temp_solution)\n\n            improvement1 = new_value1 - current_value1\n            improvement2 = new_value2 - current_value2\n\n            prob_accept = 0.6 + 0.2 * (improvement1 > 0 and improvement2 > 0) + 0.1 * (improvement1 > 0 or improvement2 > 0)\n            if random.random() < prob_accept:\n                new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -18.497260664954748,
            -18.893363749367847
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([sol for sol, _ in archive])\n    total_weights = np.sum(weight_lst * weights, axis=1)\n    min_obj = objectives.min(axis=0)\n    max_obj = objectives.max(axis=0)\n    normalized_obj = (objectives - min_obj) / (max_obj - min_obj + 1e-10)\n    normalized_weights = (total_weights - np.min(total_weights)) / (np.max(total_weights) - np.min(total_weights) + 1e-10)\n    scores = 0.4 * normalized_obj[:, 0] + 0.5 * normalized_obj[:, 1] - 0.2 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    random_solution = np.random.randint(0, 2, size=len(base_solution))\n    random_weight = np.sum(weight_lst * random_solution)\n    while random_weight > capacity:\n        random_solution = np.random.randint(0, 2, size=len(base_solution))\n        random_weight = np.sum(weight_lst * random_solution)\n\n    new_solution = base_solution.copy()\n    flip_size = max(1, min(5, len(base_solution) // 4))\n    flip_indices = np.random.choice(len(base_solution), size=flip_size, replace=False)\n\n    for idx in flip_indices:\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n        temp_weight = np.sum(weight_lst * temp_solution)\n\n        if temp_weight <= capacity:\n            current_value1 = np.sum(value1_lst * new_solution)\n            current_value2 = np.sum(value2_lst * new_solution)\n            new_value1 = np.sum(value1_lst * temp_solution)\n            new_value2 = np.sum(value2_lst * temp_solution)\n\n            improvement1 = new_value1 - current_value1\n            improvement2 = new_value2 - current_value2\n\n            prob_accept = 0.6 + 0.2 * (improvement1 > 0 and improvement2 > 0) + 0.1 * (improvement1 > 0 or improvement2 > 0)\n            if random.random() < prob_accept:\n                new_solution = temp_solution\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{This new algorithm selects a solution from the archive by prioritizing those with high normalized objective values and low weight, then applies a novel local search operator that intelligently combines features from the selected solution with a randomly generated solution by flipping subsets of items while ensuring feasibility, but uses a different scoring function that weights each objective based on their relative importance determined by the archive's diversity, and additionally employs a probabilistic acceptance criterion to balance exploration and exploitation during the local search process.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution (weighted sum of normalized objectives and weight efficiency)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([sol for sol, _ in archive])\n    total_weights = np.sum(weight_lst * weights, axis=1)\n    min_obj = objectives.min(axis=0)\n    max_obj = objectives.max(axis=0)\n    normalized_obj = (objectives - min_obj) / (max_obj - min_obj + 1e-10)\n    normalized_weights = (total_weights - np.min(total_weights)) / (np.max(total_weights) - np.min(total_weights) + 1e-10)\n    scores = 0.6 * normalized_obj[:, 0] + 0.3 * normalized_obj[:, 1] - 0.1 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a random solution for comparison\n    random_solution = np.random.randint(0, 2, size=len(base_solution))\n    random_weight = np.sum(weight_lst * random_solution)\n    while random_weight > capacity:\n        random_solution = np.random.randint(0, 2, size=len(base_solution))\n        random_weight = np.sum(weight_lst * random_solution)\n\n    # Hybrid local search with probabilistic acceptance and adaptive flip size\n    new_solution = base_solution.copy()\n    flip_size = max(1, min(5, len(base_solution) // 3))\n    flip_indices = np.random.choice(len(base_solution), size=flip_size, replace=False)\n\n    for idx in flip_indices:\n        # Try flipping the item\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n        temp_weight = np.sum(weight_lst * temp_solution)\n\n        if temp_weight <= capacity:\n            # Accept the flip with probability based on improvement in both objectives\n            current_value1 = np.sum(value1_lst * new_solution)\n            current_value2 = np.sum(value2_lst * new_solution)\n            new_value1 = np.sum(value1_lst * temp_solution)\n            new_value2 = np.sum(value2_lst * temp_solution)\n\n            improvement1 = new_value1 - current_value1\n            improvement2 = new_value2 - current_value2\n\n            # Probability of acceptance is higher if both objectives improve or one improves significantly\n            prob_accept = 0.5 + 0.3 * (improvement1 > 0 and improvement2 > 0) + 0.2 * (improvement1 > 0 or improvement2 > 0)\n            if random.random() < prob_accept:\n                new_solution = temp_solution\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{This new algorithm selects a solution from the archive by prioritizing those with high normalized objective values and low weight, then applies a novel local search operator that intelligently combines features from the selected solution with a randomly generated solution by flipping subsets of items while ensuring feasibility, but uses a different scoring function that weights each objective based on their relative importance determined by the archive's diversity, and additionally employs a probabilistic acceptance criterion to balance exploration and exploitation during the local search process.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution (weighted sum of normalized objectives and weight efficiency)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([sol for sol, _ in archive])\n    total_weights = np.sum(weight_lst * weights, axis=1)\n    min_obj = objectives.min(axis=0)\n    max_obj = objectives.max(axis=0)\n    normalized_obj = (objectives - min_obj) / (max_obj - min_obj + 1e-10)\n    normalized_weights = (total_weights - np.min(total_weights)) / (np.max(total_weights) - np.min(total_weights) + 1e-10)\n    scores = 0.6 * normalized_obj[:, 0] + 0.3 * normalized_obj[:, 1] - 0.1 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a random solution for comparison\n    random_solution = np.random.randint(0, 2, size=len(base_solution))\n    random_weight = np.sum(weight_lst * random_solution)\n    while random_weight > capacity:\n        random_solution = np.random.randint(0, 2, size=len(base_solution))\n        random_weight = np.sum(weight_lst * random_solution)\n\n    # Hybrid local search with probabilistic acceptance and adaptive flip size\n    new_solution = base_solution.copy()\n    flip_size = max(1, min(5, len(base_solution) // 3))\n    flip_indices = np.random.choice(len(base_solution), size=flip_size, replace=False)\n\n    for idx in flip_indices:\n        # Try flipping the item\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n        temp_weight = np.sum(weight_lst * temp_solution)\n\n        if temp_weight <= capacity:\n            # Accept the flip with probability based on improvement in both objectives\n            current_value1 = np.sum(value1_lst * new_solution)\n            current_value2 = np.sum(value2_lst * new_solution)\n            new_value1 = np.sum(value1_lst * temp_solution)\n            new_value2 = np.sum(value2_lst * temp_solution)\n\n            improvement1 = new_value1 - current_value1\n            improvement2 = new_value2 - current_value2\n\n            # Probability of acceptance is higher if both objectives improve or one improves significantly\n            prob_accept = 0.5 + 0.3 * (improvement1 > 0 and improvement2 > 0) + 0.2 * (improvement1 > 0 or improvement2 > 0)\n            if random.random() < prob_accept:\n                new_solution = temp_solution\n\n    return new_solution\n\n\nPlease help me create a new algorithm that has a totally different form from the given ones but can be motivated from them.\n1. Firstly, identify the common backbone idea in the provided algorithms. \n2. Secondly, based on the backbone idea describe your new algorithm in one sentence. The description must be inside within boxed {}.\n3. Thirdly, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nDo not give additional explanations.",
        "sample_order": 304,
        "algorithm": "{This new algorithm selects a solution from the archive by prioritizing those with high normalized objective values and low weight, then applies a novel local search operator that intelligently combines features from the selected solution with a diverse set of reference solutions by flipping subsets of items while ensuring feasibility, but uses a different scoring function that weights each objective based on their relative importance determined by the archive's diversity, and additionally employs a probabilistic acceptance criterion to balance exploration and exploitation during the local search process, and further incorporates a dynamic flip size adjustment mechanism that adapts to the solution's current quality.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution (weighted sum of normalized objectives and weight efficiency)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([sol for sol, _ in archive])\n    total_weights = np.sum(weight_lst * weights, axis=1)\n    min_obj = objectives.min(axis=0)\n    max_obj = objectives.max(axis=0)\n    normalized_obj = (objectives - min_obj) / (max_obj - min_obj + 1e-10)\n    normalized_weights = (total_weights - np.min(total_weights)) / (np.max(total_weights) - np.min(total_weights) + 1e-10)\n    scores = 0.5 * normalized_obj[:, 0] + 0.4 * normalized_obj[:, 1] - 0.1 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate reference solutions for comparison\n    reference_solutions = []\n    for _ in range(3):\n        ref_solution = np.random.randint(0, 2, size=len(base_solution))\n        ref_weight = np.sum(weight_lst * ref_solution)\n        while ref_weight > capacity:\n            ref_solution = np.random.randint(0, 2, size=len(base_solution))\n            ref_weight = np.sum(weight_lst * ref_solution)\n        reference_solutions.append(ref_solution)\n\n    # Hybrid local search with probabilistic acceptance and dynamic flip size\n    new_solution = base_solution.copy()\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Determine flip size based on solution quality\n    flip_size = max(1, min(5, len(base_solution) // 4))\n    if current_weight < capacity * 0.7:\n        flip_size = max(1, min(8, len(base_solution) // 2))\n    elif current_weight > capacity * 0.9:\n        flip_size = max(1, min(3, len(base_solution) // 5))\n\n    flip_indices = np.random.choice(len(base_solution), size=flip_size, replace=False)\n\n    for idx in flip_indices:\n        # Try flipping the item\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n        temp_weight = np.sum(weight_lst * temp_solution)\n\n        if temp_weight <= capacity:\n            # Compare with reference solutions\n            temp_value1 = np.sum(value1_lst * temp_solution)\n            temp_value2 = np.sum(value2_lst * temp_solution)\n            improvement1 = temp_value1 - current_value1\n            improvement2 = temp_value2 - current_value2\n\n            # Calculate dominance probability\n            dominance_count = 0\n            for ref_sol in reference_solutions:\n                ref_value1 = np.sum(value1_lst * ref_sol)\n                ref_value2 = np.sum(value2_lst * ref_sol)\n                if (temp_value1 >= ref_value1 and temp_value2 >= ref_value2) and (temp_value1 > ref_value1 or temp_value2 > ref_value2):\n                    dominance_count += 1\n\n            # Probability of acceptance\n            prob_accept = 0.4 + 0.4 * (dominance_count / len(reference_solutions)) + 0.2 * (improvement1 > 0 or improvement2 > 0)\n            if random.random() < prob_accept:\n                new_solution = temp_solution\n                current_value1 = temp_value1\n                current_value2 = temp_value2\n\n    return new_solution\n\n",
        "score": [
            -19.74889499613228,
            -17.416247511328663
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution (weighted sum of normalized objectives and weight efficiency)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([sol for sol, _ in archive])\n    total_weights = np.sum(weight_lst * weights, axis=1)\n    min_obj = objectives.min(axis=0)\n    max_obj = objectives.max(axis=0)\n    normalized_obj = (objectives - min_obj) / (max_obj - min_obj + 1e-10)\n    normalized_weights = (total_weights - np.min(total_weights)) / (np.max(total_weights) - np.min(total_weights) + 1e-10)\n    scores = 0.5 * normalized_obj[:, 0] + 0.4 * normalized_obj[:, 1] - 0.1 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate reference solutions for comparison\n    reference_solutions = []\n    for _ in range(3):\n        ref_solution = np.random.randint(0, 2, size=len(base_solution))\n        ref_weight = np.sum(weight_lst * ref_solution)\n        while ref_weight > capacity:\n            ref_solution = np.random.randint(0, 2, size=len(base_solution))\n            ref_weight = np.sum(weight_lst * ref_solution)\n        reference_solutions.append(ref_solution)\n\n    # Hybrid local search with probabilistic acceptance and dynamic flip size\n    new_solution = base_solution.copy()\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Determine flip size based on solution quality\n    flip_size = max(1, min(5, len(base_solution) // 4))\n    if current_weight < capacity * 0.7:\n        flip_size = max(1, min(8, len(base_solution) // 2))\n    elif current_weight > capacity * 0.9:\n        flip_size = max(1, min(3, len(base_solution) // 5))\n\n    flip_indices = np.random.choice(len(base_solution), size=flip_size, replace=False)\n\n    for idx in flip_indices:\n        # Try flipping the item\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n        temp_weight = np.sum(weight_lst * temp_solution)\n\n        if temp_weight <= capacity:\n            # Compare with reference solutions\n            temp_value1 = np.sum(value1_lst * temp_solution)\n            temp_value2 = np.sum(value2_lst * temp_solution)\n            improvement1 = temp_value1 - current_value1\n            improvement2 = temp_value2 - current_value2\n\n            # Calculate dominance probability\n            dominance_count = 0\n            for ref_sol in reference_solutions:\n                ref_value1 = np.sum(value1_lst * ref_sol)\n                ref_value2 = np.sum(value2_lst * ref_sol)\n                if (temp_value1 >= ref_value1 and temp_value2 >= ref_value2) and (temp_value1 > ref_value1 or temp_value2 > ref_value2):\n                    dominance_count += 1\n\n            # Probability of acceptance\n            prob_accept = 0.4 + 0.4 * (dominance_count / len(reference_solutions)) + 0.2 * (improvement1 > 0 or improvement2 > 0)\n            if random.random() < prob_accept:\n                new_solution = temp_solution\n                current_value1 = temp_value1\n                current_value2 = temp_value2\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have one algorithm with its code as follows. Algorithm description:\n{This new algorithm selects a solution from the archive by prioritizing those with high normalized objective values and low weight, then applies a novel local search operator that intelligently combines features from the selected solution with a randomly generated solution by flipping subsets of items while ensuring feasibility, but uses a different scoring function that weights each objective based on their relative importance determined by the archive's diversity, and additionally employs a probabilistic acceptance criterion to balance exploration and exploitation during the local search process, and also considers the correlation between objectives to guide the flip decisions.}\nCode:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on normalized objectives and weight efficiency\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([sol for sol, _ in archive])\n    total_weights = np.sum(weight_lst * weights, axis=1)\n    min_obj = objectives.min(axis=0)\n    max_obj = objectives.max(axis=0)\n    normalized_obj = (objectives - min_obj) / (max_obj - min_obj + 1e-10)\n    normalized_weights = (total_weights - np.min(total_weights)) / (np.max(total_weights) - np.min(total_weights) + 1e-10)\n\n    # Calculate correlation between objectives\n    obj_corr = np.corrcoef(objectives[:, 0], objectives[:, 1])[0, 1]\n    obj_weight = 0.5 + 0.4 * obj_corr  # Higher correlation means more balanced weighting\n\n    scores = obj_weight * normalized_obj[:, 0] + (1 - obj_weight) * normalized_obj[:, 1] - 0.2 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a random solution for comparison\n    random_solution = np.random.randint(0, 2, size=len(base_solution))\n    random_weight = np.sum(weight_lst * random_solution)\n    while random_weight > capacity:\n        random_solution = np.random.randint(0, 2, size=len(base_solution))\n        random_weight = np.sum(weight_lst * random_solution)\n\n    # Hybrid local search with probabilistic acceptance and adaptive flip size\n    new_solution = base_solution.copy()\n    flip_size = max(1, min(5, len(base_solution) // 3))\n    flip_indices = np.random.choice(len(base_solution), size=flip_size, replace=False)\n\n    for idx in flip_indices:\n        # Try flipping the item\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n        temp_weight = np.sum(weight_lst * temp_solution)\n\n        if temp_weight <= capacity:\n            # Accept the flip with probability based on improvement in both objectives\n            current_value1 = np.sum(value1_lst * new_solution)\n            current_value2 = np.sum(value2_lst * new_solution)\n            new_value1 = np.sum(value1_lst * temp_solution)\n            new_value2 = np.sum(value2_lst * temp_solution)\n\n            improvement1 = new_value1 - current_value1\n            improvement2 = new_value2 - current_value2\n\n            # Probability of acceptance is higher if both objectives improve or one improves significantly\n            # Also consider objective correlation in acceptance probability\n            prob_accept = 0.5 + 0.3 * (improvement1 > 0 and improvement2 > 0) + 0.2 * (improvement1 > 0 or improvement2 > 0)\n            prob_accept = prob_accept * (1 + 0.1 * obj_corr)  # Higher correlation increases acceptance probability\n\n            if random.random() < prob_accept:\n                new_solution = temp_solution\n\n    return new_solution\n\n\nPlease assist me in creating a new algorithm that has a different form but can be a modified version of the algorithm provided.\n1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nDo not give additional explanations.",
        "sample_order": 305,
        "algorithm": "{This new algorithm selects a solution from the archive by prioritizing those with high normalized objective values and low weight, then applies a novel local search operator that intelligently combines features from the selected solution with a randomly generated solution by flipping subsets of items while ensuring feasibility, but uses a different scoring function that weights each objective based on their relative importance determined by the archive's diversity, and additionally employs a probabilistic acceptance criterion to balance exploration and exploitation during the local search process, and also considers the correlation between objectives to guide the flip decisions, and further incorporates a dynamic flip size adjustment based on the solution's current weight utilization.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on normalized objectives and weight efficiency\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([sol for sol, _ in archive])\n    total_weights = np.sum(weight_lst * weights, axis=1)\n    min_obj = objectives.min(axis=0)\n    max_obj = objectives.max(axis=0)\n    normalized_obj = (objectives - min_obj) / (max_obj - min_obj + 1e-10)\n    normalized_weights = (total_weights - np.min(total_weights)) / (np.max(total_weights) - np.min(total_weights) + 1e-10)\n\n    # Calculate correlation between objectives\n    obj_corr = np.corrcoef(objectives[:, 0], objectives[:, 1])[0, 1]\n    obj_weight = 0.5 + 0.4 * obj_corr  # Higher correlation means more balanced weighting\n\n    scores = obj_weight * normalized_obj[:, 0] + (1 - obj_weight) * normalized_obj[:, 1] - 0.2 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a random solution for comparison\n    random_solution = np.random.randint(0, 2, size=len(base_solution))\n    random_weight = np.sum(weight_lst * random_solution)\n    while random_weight > capacity:\n        random_solution = np.random.randint(0, 2, size=len(base_solution))\n        random_weight = np.sum(weight_lst * random_solution)\n\n    # Hybrid local search with probabilistic acceptance and dynamic flip size\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n    utilization_ratio = current_weight / capacity\n    flip_size = max(1, min(5, int(len(base_solution) * (0.3 + 0.7 * utilization_ratio))))\n\n    flip_indices = np.random.choice(len(base_solution), size=flip_size, replace=False)\n\n    for idx in flip_indices:\n        # Try flipping the item\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n        temp_weight = np.sum(weight_lst * temp_solution)\n\n        if temp_weight <= capacity:\n            # Accept the flip with probability based on improvement in both objectives\n            current_value1 = np.sum(value1_lst * new_solution)\n            current_value2 = np.sum(value2_lst * new_solution)\n            new_value1 = np.sum(value1_lst * temp_solution)\n            new_value2 = np.sum(value2_lst * temp_solution)\n\n            improvement1 = new_value1 - current_value1\n            improvement2 = new_value2 - current_value2\n\n            # Probability of acceptance is higher if both objectives improve or one improves significantly\n            # Also consider objective correlation in acceptance probability\n            prob_accept = 0.5 + 0.3 * (improvement1 > 0 and improvement2 > 0) + 0.2 * (improvement1 > 0 or improvement2 > 0)\n            prob_accept = prob_accept * (1 + 0.1 * obj_corr)  # Higher correlation increases acceptance probability\n\n            if random.random() < prob_accept:\n                new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -16.778269966566818,
            -19.81504170655122
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on normalized objectives and weight efficiency\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([sol for sol, _ in archive])\n    total_weights = np.sum(weight_lst * weights, axis=1)\n    min_obj = objectives.min(axis=0)\n    max_obj = objectives.max(axis=0)\n    normalized_obj = (objectives - min_obj) / (max_obj - min_obj + 1e-10)\n    normalized_weights = (total_weights - np.min(total_weights)) / (np.max(total_weights) - np.min(total_weights) + 1e-10)\n\n    # Calculate correlation between objectives\n    obj_corr = np.corrcoef(objectives[:, 0], objectives[:, 1])[0, 1]\n    obj_weight = 0.5 + 0.4 * obj_corr  # Higher correlation means more balanced weighting\n\n    scores = obj_weight * normalized_obj[:, 0] + (1 - obj_weight) * normalized_obj[:, 1] - 0.2 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a random solution for comparison\n    random_solution = np.random.randint(0, 2, size=len(base_solution))\n    random_weight = np.sum(weight_lst * random_solution)\n    while random_weight > capacity:\n        random_solution = np.random.randint(0, 2, size=len(base_solution))\n        random_weight = np.sum(weight_lst * random_solution)\n\n    # Hybrid local search with probabilistic acceptance and dynamic flip size\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n    utilization_ratio = current_weight / capacity\n    flip_size = max(1, min(5, int(len(base_solution) * (0.3 + 0.7 * utilization_ratio))))\n\n    flip_indices = np.random.choice(len(base_solution), size=flip_size, replace=False)\n\n    for idx in flip_indices:\n        # Try flipping the item\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n        temp_weight = np.sum(weight_lst * temp_solution)\n\n        if temp_weight <= capacity:\n            # Accept the flip with probability based on improvement in both objectives\n            current_value1 = np.sum(value1_lst * new_solution)\n            current_value2 = np.sum(value2_lst * new_solution)\n            new_value1 = np.sum(value1_lst * temp_solution)\n            new_value2 = np.sum(value2_lst * temp_solution)\n\n            improvement1 = new_value1 - current_value1\n            improvement2 = new_value2 - current_value2\n\n            # Probability of acceptance is higher if both objectives improve or one improves significantly\n            # Also consider objective correlation in acceptance probability\n            prob_accept = 0.5 + 0.3 * (improvement1 > 0 and improvement2 > 0) + 0.2 * (improvement1 > 0 or improvement2 > 0)\n            prob_accept = prob_accept * (1 + 0.1 * obj_corr)  # Higher correlation increases acceptance probability\n\n            if random.random() < prob_accept:\n                new_solution = temp_solution\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have one algorithm with its code as follows. Algorithm description:\n{This new algorithm selects a solution from the archive by prioritizing those with high normalized objective values and low weight, then applies a novel local search operator that intelligently combines features from the selected solution with a randomly generated solution by flipping subsets of items while ensuring feasibility, but uses a different scoring function that weights each objective based on their relative importance determined by the archive's diversity, and additionally employs a probabilistic acceptance criterion to balance exploration and exploitation during the local search process, and also considers the correlation between objectives to guide the flip decisions.}\nCode:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on normalized objectives and weight efficiency\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([sol for sol, _ in archive])\n    total_weights = np.sum(weight_lst * weights, axis=1)\n    min_obj = objectives.min(axis=0)\n    max_obj = objectives.max(axis=0)\n    normalized_obj = (objectives - min_obj) / (max_obj - min_obj + 1e-10)\n    normalized_weights = (total_weights - np.min(total_weights)) / (np.max(total_weights) - np.min(total_weights) + 1e-10)\n\n    # Calculate correlation between objectives\n    obj_corr = np.corrcoef(objectives[:, 0], objectives[:, 1])[0, 1]\n    obj_weight = 0.5 + 0.4 * obj_corr  # Higher correlation means more balanced weighting\n\n    scores = obj_weight * normalized_obj[:, 0] + (1 - obj_weight) * normalized_obj[:, 1] - 0.2 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a random solution for comparison\n    random_solution = np.random.randint(0, 2, size=len(base_solution))\n    random_weight = np.sum(weight_lst * random_solution)\n    while random_weight > capacity:\n        random_solution = np.random.randint(0, 2, size=len(base_solution))\n        random_weight = np.sum(weight_lst * random_solution)\n\n    # Hybrid local search with probabilistic acceptance and adaptive flip size\n    new_solution = base_solution.copy()\n    flip_size = max(1, min(5, len(base_solution) // 3))\n    flip_indices = np.random.choice(len(base_solution), size=flip_size, replace=False)\n\n    for idx in flip_indices:\n        # Try flipping the item\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n        temp_weight = np.sum(weight_lst * temp_solution)\n\n        if temp_weight <= capacity:\n            # Accept the flip with probability based on improvement in both objectives\n            current_value1 = np.sum(value1_lst * new_solution)\n            current_value2 = np.sum(value2_lst * new_solution)\n            new_value1 = np.sum(value1_lst * temp_solution)\n            new_value2 = np.sum(value2_lst * temp_solution)\n\n            improvement1 = new_value1 - current_value1\n            improvement2 = new_value2 - current_value2\n\n            # Probability of acceptance is higher if both objectives improve or one improves significantly\n            # Also consider objective correlation in acceptance probability\n            prob_accept = 0.5 + 0.3 * (improvement1 > 0 and improvement2 > 0) + 0.2 * (improvement1 > 0 or improvement2 > 0)\n            prob_accept = prob_accept * (1 + 0.1 * obj_corr)  # Higher correlation increases acceptance probability\n\n            if random.random() < prob_accept:\n                new_solution = temp_solution\n\n    return new_solution\n\n\nPlease assist me in creating a new algorithm that has a different form but can be a modified version of the algorithm provided.\n1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nDo not give additional explanations.",
        "sample_order": 305,
        "algorithm": "{This new algorithm selects a solution from the archive by prioritizing those with high normalized objective values and low weight, then applies a novel local search operator that intelligently combines features from the selected solution with a randomly generated solution by flipping subsets of items while ensuring feasibility, but uses a different scoring function that weights each objective based on their relative importance determined by the archive's diversity, and additionally employs a probabilistic acceptance criterion to balance exploration and exploitation during the local search process, and also considers the correlation between objectives to guide the flip decisions, and further incorporates a dynamic flip size adjustment based on the solution's current weight utilization.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on normalized objectives and weight efficiency\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([sol for sol, _ in archive])\n    total_weights = np.sum(weight_lst * weights, axis=1)\n    min_obj = objectives.min(axis=0)\n    max_obj = objectives.max(axis=0)\n    normalized_obj = (objectives - min_obj) / (max_obj - min_obj + 1e-10)\n    normalized_weights = (total_weights - np.min(total_weights)) / (np.max(total_weights) - np.min(total_weights) + 1e-10)\n\n    # Calculate correlation between objectives\n    obj_corr = np.corrcoef(objectives[:, 0], objectives[:, 1])[0, 1]\n    obj_weight = 0.5 + 0.4 * obj_corr  # Higher correlation means more balanced weighting\n\n    scores = obj_weight * normalized_obj[:, 0] + (1 - obj_weight) * normalized_obj[:, 1] - 0.2 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a random solution for comparison\n    random_solution = np.random.randint(0, 2, size=len(base_solution))\n    random_weight = np.sum(weight_lst * random_solution)\n    while random_weight > capacity:\n        random_solution = np.random.randint(0, 2, size=len(base_solution))\n        random_weight = np.sum(weight_lst * random_solution)\n\n    # Hybrid local search with probabilistic acceptance and dynamic flip size\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n    utilization_ratio = current_weight / capacity\n    flip_size = max(1, min(5, int(len(base_solution) * (0.3 + 0.7 * utilization_ratio))))\n\n    flip_indices = np.random.choice(len(base_solution), size=flip_size, replace=False)\n\n    for idx in flip_indices:\n        # Try flipping the item\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n        temp_weight = np.sum(weight_lst * temp_solution)\n\n        if temp_weight <= capacity:\n            # Accept the flip with probability based on improvement in both objectives\n            current_value1 = np.sum(value1_lst * new_solution)\n            current_value2 = np.sum(value2_lst * new_solution)\n            new_value1 = np.sum(value1_lst * temp_solution)\n            new_value2 = np.sum(value2_lst * temp_solution)\n\n            improvement1 = new_value1 - current_value1\n            improvement2 = new_value2 - current_value2\n\n            # Probability of acceptance is higher if both objectives improve or one improves significantly\n            # Also consider objective correlation in acceptance probability\n            prob_accept = 0.5 + 0.3 * (improvement1 > 0 and improvement2 > 0) + 0.2 * (improvement1 > 0 or improvement2 > 0)\n            prob_accept = prob_accept * (1 + 0.1 * obj_corr)  # Higher correlation increases acceptance probability\n\n            if random.random() < prob_accept:\n                new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -16.778269966566818,
            -19.81504170655122
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on normalized objectives and weight efficiency\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([sol for sol, _ in archive])\n    total_weights = np.sum(weight_lst * weights, axis=1)\n    min_obj = objectives.min(axis=0)\n    max_obj = objectives.max(axis=0)\n    normalized_obj = (objectives - min_obj) / (max_obj - min_obj + 1e-10)\n    normalized_weights = (total_weights - np.min(total_weights)) / (np.max(total_weights) - np.min(total_weights) + 1e-10)\n\n    # Calculate correlation between objectives\n    obj_corr = np.corrcoef(objectives[:, 0], objectives[:, 1])[0, 1]\n    obj_weight = 0.5 + 0.4 * obj_corr  # Higher correlation means more balanced weighting\n\n    scores = obj_weight * normalized_obj[:, 0] + (1 - obj_weight) * normalized_obj[:, 1] - 0.2 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a random solution for comparison\n    random_solution = np.random.randint(0, 2, size=len(base_solution))\n    random_weight = np.sum(weight_lst * random_solution)\n    while random_weight > capacity:\n        random_solution = np.random.randint(0, 2, size=len(base_solution))\n        random_weight = np.sum(weight_lst * random_solution)\n\n    # Hybrid local search with probabilistic acceptance and dynamic flip size\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n    utilization_ratio = current_weight / capacity\n    flip_size = max(1, min(5, int(len(base_solution) * (0.3 + 0.7 * utilization_ratio))))\n\n    flip_indices = np.random.choice(len(base_solution), size=flip_size, replace=False)\n\n    for idx in flip_indices:\n        # Try flipping the item\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n        temp_weight = np.sum(weight_lst * temp_solution)\n\n        if temp_weight <= capacity:\n            # Accept the flip with probability based on improvement in both objectives\n            current_value1 = np.sum(value1_lst * new_solution)\n            current_value2 = np.sum(value2_lst * new_solution)\n            new_value1 = np.sum(value1_lst * temp_solution)\n            new_value2 = np.sum(value2_lst * temp_solution)\n\n            improvement1 = new_value1 - current_value1\n            improvement2 = new_value2 - current_value2\n\n            # Probability of acceptance is higher if both objectives improve or one improves significantly\n            # Also consider objective correlation in acceptance probability\n            prob_accept = 0.5 + 0.3 * (improvement1 > 0 and improvement2 > 0) + 0.2 * (improvement1 > 0 or improvement2 > 0)\n            prob_accept = prob_accept * (1 + 0.1 * obj_corr)  # Higher correlation increases acceptance probability\n\n            if random.random() < prob_accept:\n                new_solution = temp_solution\n\n    return new_solution\n\n"
    }
]