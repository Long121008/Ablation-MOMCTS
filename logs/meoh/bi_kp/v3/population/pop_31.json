[
    {
        "algorithm": "{An adaptive density-balanced neighborhood search that dynamically prioritizes high-value items using a weighted combination of value-to-weight ratios and solution quality gradients, followed by a hybrid of targeted swaps and stochastic perturbations to explore the Pareto frontier while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    archive.sort(key=lambda x: -(x[1][0] * 0.7 + x[1][1] * 0.3))\n    selected_idx = min(2, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    value_density1 = value1_lst / (weight_lst + 1e-6)\n    value_density2 = value2_lst / (weight_lst + 1e-6)\n    combined_density = value_density1 * 0.3 + value_density2 * 0.7\n\n    new_solution = base_solution.copy()\n    for _ in range(4):\n        in_items = np.where(new_solution == 0)[0]\n        out_items = np.where(new_solution == 1)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            best_in = in_items[np.argmax(combined_density[in_items])]\n            worst_out = out_items[np.argmin(combined_density[out_items])]\n\n            if (current_weight - weight_lst[worst_out] + weight_lst[best_in]) <= capacity:\n                new_solution[worst_out] = 0\n                new_solution[best_in] = 1\n                current_weight = current_weight - weight_lst[worst_out] + weight_lst[best_in]\n\n    num_perturb = min(3, len(new_solution))\n    perturb_indices = np.random.choice(len(new_solution), size=num_perturb, replace=False)\n\n    for idx in perturb_indices:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -17.67891150990767,
            -19.521582483776108
        ]
    },
    {
        "algorithm": "{A novel hybrid local search operator that employs adaptive objective weighting with probabilistic swaps and dynamic neighborhood exploration, combining value-weighted replacements with simulated annealing-style perturbations to enhance solution quality while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    archive.sort(key=lambda x: -(x[1][0] * 0.7 + x[1][1] * 0.3))\n    selected_idx = np.random.choice(min(3, len(archive)))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Adaptive objective weighting with probabilistic swaps\n    for _ in range(5):\n        obj_weight = np.random.random()\n        in_items = np.where(new_solution == 0)[0]\n        out_items = np.where(new_solution == 1)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Calculate combined scores\n            in_scores = (value1_lst[in_items] * obj_weight + value2_lst[in_items] * (1 - obj_weight)) / weight_lst[in_items]\n            out_scores = (value1_lst[out_items] * obj_weight + value2_lst[out_items] * (1 - obj_weight)) / weight_lst[out_items]\n\n            best_in = in_items[np.argmax(in_scores)]\n            worst_out = out_items[np.argmin(out_scores)]\n\n            if (current_weight - weight_lst[worst_out] + weight_lst[best_in]) <= capacity:\n                new_solution[worst_out] = 0\n                new_solution[best_in] = 1\n                current_weight = current_weight - weight_lst[worst_out] + weight_lst[best_in]\n\n    # Phase 2: Simulated annealing-style perturbations\n    temperature = 1.0\n    cooling_rate = 0.95\n\n    for _ in range(3):\n        indices = np.random.choice(len(new_solution), size=min(5, len(new_solution)), replace=False)\n\n        for idx in indices:\n            if new_solution[idx] == 1:\n                if np.random.random() < temperature * 0.3:\n                    if current_weight - weight_lst[idx] <= capacity:\n                        new_solution[idx] = 0\n                        current_weight -= weight_lst[idx]\n            else:\n                if np.random.random() < temperature * 0.7 and (current_weight + weight_lst[idx]) <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        temperature *= cooling_rate\n\n    return new_solution\n\n",
        "score": [
            -19.33481180473102,
            -18.369501639292274
        ]
    },
    {
        "algorithm": "{A novel adaptive hybrid local search operator uses a weighted sum of normalized objective contributions with dynamic parameterization to guide item selection, combined with a probabilistic swap mechanism that considers both individual and combined objective impacts while maintaining feasibility through capacity-aware perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    base_solution, _ = max(archive, key=lambda x: sum(x[1]))\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and objective values\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Step 1: Dynamic neighborhood exploration - flip items based on adaptive weighted contribution\n    num_items = len(base_solution)\n    flip_indices = np.random.choice(num_items, size=min(4, num_items), replace=False)\n\n    # Normalize objective values\n    max_value1 = np.max(value1_lst) if np.max(value1_lst) != 0 else 1\n    max_value2 = np.max(value2_lst) if np.max(value2_lst) != 0 else 1\n\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            # Calculate potential new weight and objective values if we remove this item\n            new_weight = current_weight - weight_lst[idx]\n            new_value1 = current_value1 - value1_lst[idx]\n            new_value2 = current_value2 - value2_lst[idx]\n\n            # Only flip if it doesn't violate capacity and improves at least one objective\n            if new_weight <= capacity:\n                new_solution[idx] = 0\n                current_weight = new_weight\n                current_value1 = new_value1\n                current_value2 = new_value2\n        else:\n            # Calculate potential new weight and objective values if we add this item\n            new_weight = current_weight + weight_lst[idx]\n            new_value1 = current_value1 + value1_lst[idx]\n            new_value2 = current_value2 + value2_lst[idx]\n\n            # Only flip if it doesn't violate capacity and improves at least one objective\n            if new_weight <= capacity:\n                new_solution[idx] = 1\n                current_weight = new_weight\n                current_value1 = new_value1\n                current_value2 = new_value2\n\n    # Step 2: Probabilistic item swap - swap items based on adaptive weighted marginal contribution\n    for _ in range(3):  # Perform 3 swaps\n        in_items = np.where(new_solution == 0)[0]\n        out_items = np.where(new_solution == 1)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Calculate adaptive weighted marginal contribution scores for in-items\n            in_scores = (value1_lst[in_items] / max_value1 * 0.7 + value2_lst[in_items] / max_value2 * 0.3) / (weight_lst[in_items] + 1e-6)\n\n            # Calculate adaptive weighted marginal contribution scores for out-items\n            out_scores = (value1_lst[out_items] / max_value1 * 0.3 + value2_lst[out_items] / max_value2 * 0.7) / (weight_lst[out_items] + 1e-6)\n\n            # Select items to swap\n            best_in = in_items[np.argmax(in_scores)]\n            worst_out = out_items[np.argmin(out_scores)]\n\n            # Check if swap is feasible\n            if (current_weight - weight_lst[worst_out] + weight_lst[best_in]) <= capacity:\n                new_solution[worst_out] = 0\n                new_solution[best_in] = 1\n                current_weight = current_weight - weight_lst[worst_out] + weight_lst[best_in]\n\n    # Step 3: Final perturbation - flip items with low adaptive contribution\n    for idx in range(num_items):\n        if new_solution[idx] == 1:\n            # Calculate adaptive weighted contribution\n            contribution = (value1_lst[idx] / max_value1 * 0.6 + value2_lst[idx] / max_value2 * 0.4) / (weight_lst[idx] + 1e-6)\n\n            # Flip if contribution is below threshold and removal is feasible\n            if (contribution < 0.3 and current_weight - weight_lst[idx] <= capacity):\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -18.87393056072719,
            -18.77002733447549
        ]
    },
    {
        "algorithm": "{A hybrid local search operator that combines adaptive objective clustering with dynamic value-aware perturbations and feasibility-preserving swaps, using a three-stage strategy of cluster-based value optimization, probabilistic objective-balanced flips, and capacity-constrained item swaps to explore diverse non-dominated regions while maintaining solution quality across both objectives.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    archive.sort(key=lambda x: -(x[1][0] * 0.6 + x[1][1] * 0.4))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    current_weight = np.sum(weight_lst * new_solution)\n    num_items = len(new_solution)\n\n    # Stage 1: Adaptive objective clustering and value optimization\n    cluster_size = max(3, num_items // 5)\n    for _ in range(3):\n        indices = np.random.choice(num_items, size=cluster_size, replace=False)\n        cluster_in = indices[new_solution[indices] == 0]\n        cluster_out = indices[new_solution[indices] == 1]\n\n        if len(cluster_in) > 0 and len(cluster_out) > 0:\n            alpha = 0.5 + 0.3 * (current_weight / capacity)\n            in_scores = (value1_lst[cluster_in] * alpha + value2_lst[cluster_in] * (1-alpha)) / (weight_lst[cluster_in] ** 0.8)\n            out_scores = (value1_lst[cluster_out] * (1-alpha) + value2_lst[cluster_out] * alpha) / (weight_lst[cluster_out] ** 0.8)\n\n            best_in = cluster_in[np.argmax(in_scores)]\n            worst_out = cluster_out[np.argmin(out_scores)]\n\n            if (current_weight - weight_lst[worst_out] + weight_lst[best_in]) <= capacity:\n                new_solution[worst_out] = 0\n                new_solution[best_in] = 1\n                current_weight = current_weight - weight_lst[worst_out] + weight_lst[best_in]\n\n    # Stage 2: Probabilistic objective-balanced flips with diversity\n    for _ in range(4):\n        indices = np.random.choice(num_items, size=min(5, num_items), replace=False)\n        for idx in indices:\n            if new_solution[idx] == 1:\n                prob = 0.3 * (1 - (value1_lst[idx] + value2_lst[idx]) / (np.max(value1_lst) + np.max(value2_lst)))\n                if np.random.random() < prob:\n                    if current_weight - weight_lst[idx] <= capacity:\n                        new_solution[idx] = 0\n                        current_weight -= weight_lst[idx]\n            else:\n                prob = 0.6 * (value1_lst[idx] + value2_lst[idx]) / (np.max(value1_lst) + np.max(value2_lst))\n                if np.random.random() < prob and (current_weight + weight_lst[idx]) <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Stage 3: Feasibility-preserving capacity-constrained swaps with value prioritization\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        sorted_out_items = np.where(new_solution == 1)[0]\n        ratios = (value1_lst[sorted_out_items] * 0.6 + value2_lst[sorted_out_items] * 0.4) / (weight_lst[sorted_out_items] ** 0.8)\n        sorted_out_items = sorted_out_items[np.argsort(ratios)]\n\n        for idx in sorted_out_items:\n            if excess_weight <= 0:\n                break\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -19.558151070680466,
            -18.192327922695448
        ]
    },
    {
        "algorithm": "{A novel adaptive multi-objective local search operator that combines dynamic objective prioritization with value-aware clustering and probabilistic perturbations, using a four-stage strategy of cluster-based objective optimization, adaptive item flips, capacity-constrained swaps, and value-balanced perturbations to explore diverse non-dominated regions while maintaining solution quality across both objectives.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    max_value1 = np.max(value1_lst) if np.max(value1_lst) != 0 else 1\n    max_value2 = np.max(value2_lst) if np.max(value2_lst) != 0 else 1\n    archive.sort(key=lambda x: -(x[1][0]/max_value1 * 0.6 + x[1][1]/max_value2 * 0.4))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    current_weight = np.sum(weight_lst * new_solution)\n    num_items = len(new_solution)\n\n    # Stage 1: Dynamic objective prioritization clustering\n    cluster_size = max(3, num_items // 5)\n    for _ in range(3):\n        indices = np.random.choice(num_items, size=cluster_size, replace=False)\n        cluster_in = indices[new_solution[indices] == 0]\n        cluster_out = indices[new_solution[indices] == 1]\n\n        if len(cluster_in) > 0 and len(cluster_out) > 0:\n            # Dynamic objective weighting based on current solution\n            alpha = 0.5 + 0.3 * (current_weight / capacity)\n            in_scores = (value1_lst[cluster_in] * alpha + value2_lst[cluster_in] * (1-alpha)) / (weight_lst[cluster_in] ** 0.5)\n            out_scores = (value1_lst[cluster_out] * (1-alpha) + value2_lst[cluster_out] * alpha) / (weight_lst[cluster_out] ** 0.5)\n\n            best_in = cluster_in[np.argmax(in_scores)]\n            worst_out = cluster_out[np.argmin(out_scores)]\n\n            if (current_weight - weight_lst[worst_out] + weight_lst[best_in]) <= capacity:\n                new_solution[worst_out] = 0\n                new_solution[best_in] = 1\n                current_weight = current_weight - weight_lst[worst_out] + weight_lst[best_in]\n\n    # Stage 2: Adaptive value-aware flips\n    for idx in range(num_items):\n        if new_solution[idx] == 1:\n            prob = 0.3 * (1 - (value1_lst[idx]/max_value1 + value2_lst[idx]/max_value2) / 2)\n            if np.random.random() < prob:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n        else:\n            prob = 0.4 * (value1_lst[idx]/max_value1 + value2_lst[idx]/max_value2) / 2\n            if np.random.random() < prob and (current_weight + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Stage 3: Capacity-constrained value-balanced swaps\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        out_items = np.where(new_solution == 1)[0]\n        ratios = (value1_lst[out_items]/max_value1 * 0.6 + value2_lst[out_items]/max_value2 * 0.4) / (weight_lst[out_items] ** 0.6)\n        out_items = out_items[np.argsort(ratios)]\n\n        for idx in out_items:\n            if excess_weight <= 0:\n                break\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    # Stage 4: Final value-balanced perturbations\n    for _ in range(2):\n        indices = np.random.choice(num_items, size=min(5, num_items), replace=False)\n        for idx in indices:\n            if new_solution[idx] == 1:\n                contribution = (value1_lst[idx]/max_value1 * 0.5 + value2_lst[idx]/max_value2 * 0.5) / (weight_lst[idx] + 1e-6)\n                if contribution < 0.4 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                potential = (value1_lst[idx]/max_value1 * 0.5 + value2_lst[idx]/max_value2 * 0.5) / (weight_lst[idx] + 1e-6)\n                if potential > 0.5 and (current_weight + weight_lst[idx]) <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -19.39652475047609,
            -18.282498223371103
        ]
    },
    {
        "algorithm": "{An adaptive multi-objective local search operator that combines value-weighted clustering with probabilistic item reassignment, using dynamically adjusted objective weights and a three-phase strategy of cluster-based swaps, weighted perturbations, and feasibility-preserving flips to explore diverse non-dominated regions while maintaining solution quality across both objectives.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = np.random.choice(min(3, len(archive)))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    current_weight = np.sum(weight_lst * new_solution)\n    num_items = len(new_solution)\n\n    # Phase 1: Value-weighted clustering and swaps\n    cluster_size = max(2, num_items // 5)\n    for _ in range(3):\n        indices = np.random.choice(num_items, size=cluster_size, replace=False)\n        cluster_in = indices[new_solution[indices] == 0]\n        cluster_out = indices[new_solution[indices] == 1]\n\n        if len(cluster_in) > 0 and len(cluster_out) > 0:\n            alpha = np.random.uniform(0.3, 0.7)\n            in_scores = (value1_lst[cluster_in] * alpha + value2_lst[cluster_in] * (1-alpha)) / weight_lst[cluster_in]\n            out_scores = (value1_lst[cluster_out] * (1-alpha) + value2_lst[cluster_out] * alpha) / weight_lst[cluster_out]\n\n            best_in = cluster_in[np.argmax(in_scores)]\n            worst_out = cluster_out[np.argmin(out_scores)]\n\n            if (current_weight - weight_lst[worst_out] + weight_lst[best_in]) <= capacity:\n                new_solution[worst_out] = 0\n                new_solution[best_in] = 1\n                current_weight = current_weight - weight_lst[worst_out] + weight_lst[best_in]\n\n    # Phase 2: Weighted probabilistic reassignment\n    for _ in range(4):\n        indices = np.random.choice(num_items, size=min(5, num_items), replace=False)\n        for idx in indices:\n            if new_solution[idx] == 1:\n                prob = 0.3 * (1 - (value1_lst[idx] + value2_lst[idx]) / (np.max(value1_lst) + np.max(value2_lst)))\n                if np.random.random() < prob:\n                    if current_weight - weight_lst[idx] <= capacity:\n                        new_solution[idx] = 0\n            else:\n                prob = 0.6 * (value1_lst[idx] + value2_lst[idx]) / (np.max(value1_lst) + np.max(value2_lst))\n                if np.random.random() < prob and (current_weight + weight_lst[idx]) <= capacity:\n                    new_solution[idx] = 1\n\n    # Phase 3: Feasibility-preserving flips\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        sorted_out_items = np.where(new_solution == 1)[0]\n        sorted_out_items = sorted_out_items[np.argsort(weight_lst[sorted_out_items])]\n\n        for idx in sorted_out_items:\n            if excess_weight <= 0:\n                break\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -19.32700955270814,
            -18.48377564501786
        ]
    },
    {
        "algorithm": "{A novel hybrid local search operator combines a dynamic neighborhood exploration strategy with a probabilistic item swap mechanism to intelligently perturb solutions while ensuring feasibility, balancing exploration of promising regions and exploitation of high-value items.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    archive.sort(key=lambda x: -(x[1][0] * 0.7 + x[1][1] * 0.3))  # Sort by weighted total value\n    selected_idx = min(1, len(archive) - 1)  # Select from top 2 solutions\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Phase 1: Value-driven item replacement with different scoring\n    for _ in range(2):  # Perform 2 replacements\n        in_items = np.where(new_solution == 0)[0]\n        out_items = np.where(new_solution == 1)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Calculate value scores with different weights\n            in_scores = (value1_lst[in_items] * 0.5 + value2_lst[in_items] * 0.5) / weight_lst[in_items]\n            out_scores = (value1_lst[out_items] * 0.3 + value2_lst[out_items] * 0.7) / weight_lst[out_items]\n\n            best_in = in_items[np.argmax(in_scores)]\n            worst_out = out_items[np.argmin(out_scores)]\n\n            if (current_weight - weight_lst[worst_out] + weight_lst[best_in]) <= capacity:\n                new_solution[worst_out] = 0\n                new_solution[best_in] = 1\n                current_weight = current_weight - weight_lst[worst_out] + weight_lst[best_in]\n\n    # Phase 2: Randomized perturbation with different probability\n    num_items = len(base_solution)\n    perturb_indices = np.random.choice(num_items, size=min(3, num_items), replace=False)\n    for idx in perturb_indices:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.20505881486052,
            -19.23128181075814
        ]
    },
    {
        "algorithm": "{A novel hybrid local search operator that combines multi-objective gradient-based item selection with adaptive neighborhood exploration and probabilistic diversification, employing a dynamic value-weighted replacement strategy and a simulated annealing-inspired perturbation mechanism to balance exploration and exploitation while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    archive.sort(key=lambda x: -(x[1][0] * 0.6 + x[1][1] * 0.4))\n    selected_idx = np.random.choice(min(3, len(archive)))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Multi-objective gradient-based selection\n    for _ in range(4):\n        # Calculate gradient-based scores\n        gradient_scores = (value1_lst * 0.4 + value2_lst * 0.6) / (weight_lst + 1e-6)\n\n        # Find potential candidates\n        in_items = np.where(new_solution == 0)[0]\n        out_items = np.where(new_solution == 1)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Select best item to add and worst to remove\n            best_in = in_items[np.argmax(gradient_scores[in_items])]\n            worst_out = out_items[np.argmin(gradient_scores[out_items])]\n\n            # Check feasibility and perform swap\n            if (current_weight - weight_lst[worst_out] + weight_lst[best_in]) <= capacity:\n                new_solution[worst_out] = 0\n                new_solution[best_in] = 1\n                current_weight = current_weight - weight_lst[worst_out] + weight_lst[best_in]\n\n    # Phase 2: Adaptive neighborhood exploration\n    temperature = 1.0\n    cooling_rate = 0.9\n\n    for _ in range(3):\n        # Randomly select items for perturbation\n        indices = np.random.choice(len(new_solution), size=min(4, len(new_solution)), replace=False)\n\n        for idx in indices:\n            if new_solution[idx] == 1:\n                # Remove item with probability based on temperature and value\n                removal_prob = temperature * (0.5 + 0.5 * (value1_lst[idx] + value2_lst[idx]) / (np.sum(value1_lst) + np.sum(value2_lst) + 1e-6))\n                if np.random.random() < removal_prob and (current_weight - weight_lst[idx]) <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                # Add item with probability based on temperature and value\n                addition_prob = temperature * (0.3 + 0.7 * (value1_lst[idx] + value2_lst[idx]) / (np.sum(value1_lst) + np.sum(value2_lst) + 1e-6))\n                if np.random.random() < addition_prob and (current_weight + weight_lst[idx]) <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        temperature *= cooling_rate\n\n    return new_solution\n\n",
        "score": [
            -18.686838369222983,
            -18.87601496438693
        ]
    },
    {
        "algorithm": "{A novel hybrid local search operator that combines adaptive objective-driven clustering with dynamic value-aware perturbations and feasibility-preserving swaps, using a three-stage strategy of cluster-based value optimization, probabilistic objective-balanced flips, and capacity-constrained item swaps to explore diverse non-dominated regions while maintaining solution quality across both objectives.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    current_weight = np.sum(weight_lst * new_solution)\n    num_items = len(new_solution)\n\n    # Stage 1: Adaptive objective-driven clustering and value optimization\n    cluster_size = max(3, num_items // 5)\n    for _ in range(3):\n        indices = np.random.choice(num_items, size=cluster_size, replace=False)\n        cluster_in = indices[new_solution[indices] == 0]\n        cluster_out = indices[new_solution[indices] == 1]\n\n        if len(cluster_in) > 0 and len(cluster_out) > 0:\n            # Dynamic objective weighting based on current solution\n            alpha = 0.5 + 0.3 * (current_weight / capacity)\n            in_scores = (value1_lst[cluster_in] * alpha + value2_lst[cluster_in] * (1-alpha)) / weight_lst[cluster_in]\n            out_scores = (value1_lst[cluster_out] * (1-alpha) + value2_lst[cluster_out] * alpha) / weight_lst[cluster_out]\n\n            best_in = cluster_in[np.argmax(in_scores)]\n            worst_out = cluster_out[np.argmin(out_scores)]\n\n            if (current_weight - weight_lst[worst_out] + weight_lst[best_in]) <= capacity:\n                new_solution[worst_out] = 0\n                new_solution[best_in] = 1\n                current_weight = current_weight - weight_lst[worst_out] + weight_lst[best_in]\n\n    # Stage 2: Probabilistic objective-balanced flips\n    for _ in range(4):\n        indices = np.random.choice(num_items, size=min(5, num_items), replace=False)\n        for idx in indices:\n            if new_solution[idx] == 1:\n                # More likely to remove low-value items\n                prob = 0.3 * (1 - (value1_lst[idx] + value2_lst[idx]) / (np.max(value1_lst) + np.max(value2_lst)))\n                if np.random.random() < prob:\n                    if current_weight - weight_lst[idx] <= capacity:\n                        new_solution[idx] = 0\n                        current_weight -= weight_lst[idx]\n            else:\n                # More likely to add high-value items\n                prob = 0.6 * (value1_lst[idx] + value2_lst[idx]) / (np.max(value1_lst) + np.max(value2_lst))\n                if np.random.random() < prob and (current_weight + weight_lst[idx]) <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Stage 3: Feasibility-preserving capacity-constrained swaps\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        # Remove items with lowest value-to-weight ratio first\n        sorted_out_items = np.where(new_solution == 1)[0]\n        ratios = (value1_lst[sorted_out_items] + value2_lst[sorted_out_items]) / weight_lst[sorted_out_items]\n        sorted_out_items = sorted_out_items[np.argsort(ratios)]\n\n        for idx in sorted_out_items:\n            if excess_weight <= 0:\n                break\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -19.147291780676333,
            -18.67953653241325
        ]
    },
    {
        "algorithm": "{An advanced multi-objective local search operator that employs dynamic objective prioritization with adaptive weight scaling, cluster-based value-driven swaps, a novel \"profit-imbalance\" perturbation strategy, and an enhanced feasibility-preserving optimization phase to efficiently explore the Pareto front while maintaining solution diversity.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    archive.sort(key=lambda x: -(x[1][0] * 0.6 + x[1][1] * 0.4))\n    selected_idx = np.random.choice(min(4, len(archive)))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    current_weight = np.sum(weight_lst * new_solution)\n    num_items = len(new_solution)\n\n    alpha = np.random.uniform(0.3, 0.7)\n    cluster_size = max(2, num_items // 5)\n    for _ in range(3):\n        indices = np.random.choice(num_items, size=cluster_size, replace=False)\n        cluster_in = indices[new_solution[indices] == 0]\n        cluster_out = indices[new_solution[indices] == 1]\n\n        if len(cluster_in) > 0 and len(cluster_out) > 0:\n            in_scores = (value1_lst[cluster_in] * (1-alpha) + value2_lst[cluster_in] * alpha) / (weight_lst[cluster_in] ** 0.7)\n            out_scores = (value1_lst[cluster_out] * alpha + value2_lst[cluster_out] * (1-alpha)) / (weight_lst[cluster_out] ** 0.7)\n\n            best_in = cluster_in[np.argmax(in_scores)]\n            worst_out = cluster_out[np.argmin(out_scores)]\n\n            if (current_weight - weight_lst[worst_out] + weight_lst[best_in]) <= capacity:\n                new_solution[worst_out] = 0\n                new_solution[best_in] = 1\n                current_weight = current_weight - weight_lst[worst_out] + weight_lst[best_in]\n\n    for _ in range(6):\n        indices = np.random.choice(num_items, size=min(5, num_items), replace=False)\n        for idx in indices:\n            profit_diff = abs(value1_lst[idx] - value2_lst[idx]) / (np.max(value1_lst) + np.max(value2_lst))\n            if new_solution[idx] == 1 and profit_diff > 0.3 and np.random.random() < 0.5:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n            elif new_solution[idx] == 0 and profit_diff > 0.3 and np.random.random() < 0.6:\n                if (current_weight + weight_lst[idx]) <= capacity:\n                    new_solution[idx] = 1\n\n    for _ in range(4):\n        indices = np.random.choice(num_items, size=min(3, num_items), replace=False)\n        for idx in indices:\n            value_ratio = (value1_lst[idx] / np.max(value1_lst)) - (value2_lst[idx] / np.max(value2_lst))\n            if new_solution[idx] == 1 and value_ratio < -0.2 and np.random.random() < 0.4:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n            elif new_solution[idx] == 0 and value_ratio > 0.2 and np.random.random() < 0.5:\n                if (current_weight + weight_lst[idx]) <= capacity:\n                    new_solution[idx] = 1\n\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        sorted_out_items = np.where(new_solution == 1)[0]\n        sorted_out_items = sorted_out_items[np.argsort((value1_lst[sorted_out_items] + value2_lst[sorted_out_items]) / (weight_lst[sorted_out_items] ** 0.8))]\n\n        for idx in sorted_out_items:\n            if excess_weight <= 0:\n                break\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -19.626166031782404,
            -18.030714465045797
        ]
    }
]