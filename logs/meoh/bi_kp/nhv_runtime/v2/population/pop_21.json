[
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a diversity-aware objective ranking and applies a hybrid local search that combines value-weighted item swaps with adaptive capacity-sensitive perturbations to explore high-potential regions while ensuring feasibility through dynamic weight adjustment.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with diverse objective ranking\n    objectives = np.array([obj for _, obj in archive])\n    ranks = np.argsort(objectives[:, 0]) + np.argsort(objectives[:, 1])\n    selected_idx = np.argmin(ranks) if np.random.rand() < 0.6 else np.argmax(ranks)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: value-weighted swaps and adaptive perturbations\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Value-weighted item swaps\n    if len(items_in) > 0 and len(items_out) > 0:\n        swap_scores = (value1_lst[items_in] + value2_lst[items_in]) / (weight_lst[items_in] + 1e-6)\n        best_swap = np.argmax(swap_scores)\n        candidate_new = np.random.choice(items_out)\n\n        if weight_lst[candidate_new] <= weight_lst[items_in[best_swap]]:\n            delta_weight = weight_lst[candidate_new] - weight_lst[items_in[best_swap]]\n            if current_weight + delta_weight <= capacity:\n                new_solution[items_in[best_swap]] = 0\n                new_solution[candidate_new] = 1\n                current_weight += delta_weight\n\n    # Adaptive capacity-sensitive perturbations\n    if np.random.rand() < 0.3:\n        if current_weight < 0.8 * capacity and len(items_out) > 0:\n            candidate = np.random.choice(items_out)\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n        elif current_weight > 0.6 * capacity and len(items_in) > 0:\n            candidate = np.random.choice(items_in)\n            new_solution[candidate] = 0\n\n    # Ensure feasibility through dynamic adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        removal_order = np.argsort((value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6))\n        for idx in items_in_new[removal_order]:\n            if excess <= 0:\n                break\n            new_solution[idx] = 0\n            excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.898773143786561,
            0.7867339849472046
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search that combines adaptive item grouping with a biased random walk, where items are first clustered by their marginal gain ratios, and then explored within these clusters to identify high-potential regions for improvement while ensuring feasibility through weight-constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives with weight consideration)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    normalized_weights = (weights - np.min(weights)) / (np.max(weights) - np.min(weights) + 1e-6)\n    scores = 0.7 * np.sum(normalized_objectives, axis=1) - 0.3 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item grouping and biased random walk\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate marginal gain ratios for items not in solution with weight consideration\n    if len(items_out) > 0:\n        ratio1 = value1_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        ratio2 = value2_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        combined_ratio = ratio1 + ratio2\n        weight_ratio = combined_ratio / (weight_lst[items_out] + 1e-6)\n\n        # Cluster items by weight-adjusted marginal gain ratio\n        sorted_indices = np.argsort(weight_ratio)[::-1]\n        top_cluster = items_out[sorted_indices[:max(1, len(items_out)//2)]]\n\n        # Randomly select from top cluster with higher probability\n        if len(top_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(top_cluster)\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Biased random walk: remove low-contribution items with weight consideration\n    if len(items_in) > 0:\n        # Calculate contribution of each item in solution with weight consideration\n        contribution1 = value1_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        contribution2 = value2_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        combined_contribution = contribution1 + contribution2\n        weight_contribution = combined_contribution / (weight_lst[items_in] + 1e-6)\n\n        # Remove items with lowest weight-adjusted contribution\n        sorted_indices = np.argsort(weight_contribution)\n        bottom_cluster = items_in[sorted_indices[:max(1, len(items_in)//4)]]\n\n        if len(bottom_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(bottom_cluster)\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            # Remove items with smallest weight to contribution ratio\n            contribution_ratio = (value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6)\n            sorted_indices = np.argsort(contribution_ratio)\n            for idx in items_in_new[sorted_indices]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9929539344021545,
            3.763106882572174
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a diversity-aware objective ranking, then applies a novel local search that combines adaptive item substitution with a probabilistic marginal gain analysis, where items are first evaluated based on their combined marginal gain and diversity contribution, and then explored through a substitution process that prioritizes high-marginal-gain items while maintaining feasibility through dynamic weight constraints.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution based on diversity-aware objective ranking\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_weights = weights / capacity\n    diversity_scores = np.std(objectives, axis=0) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    weighted_scores = 0.5 * objectives[:, 0] + 0.5 * objectives[:, 1] + 0.2 * diversity_scores[0] + 0.2 * diversity_scores[1] - 0.3 * normalized_weights\n    selected_idx = np.argmax(weighted_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item substitution with probabilistic marginal gain analysis\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate combined marginal gain and diversity contribution\n    if len(items_out) > 0:\n        marginal_gain = (value1_lst[items_out] + value2_lst[items_out]) / (weight_lst[items_out] + 1e-6)\n        diversity_contribution = np.abs(value1_lst[items_out] - value2_lst[items_out]) / (weight_lst[items_out] + 1e-6)\n        combined_score = 0.7 * marginal_gain + 0.3 * diversity_contribution\n        sorted_indices = np.argsort(combined_score)[::-1]\n        top_items = items_out[sorted_indices[:max(1, len(items_out)//4)]]\n\n        # Substitute items with probability proportional to their score\n        for idx in top_items:\n            if np.random.rand() < 0.6 and current_weight + weight_lst[idx] <= capacity:\n                # Find an item to remove to make space\n                if len(items_in) > 0:\n                    removal_scores = (value1_lst[items_in] + value2_lst[items_in]) / (weight_lst[items_in] + 1e-6)\n                    remove_idx = items_in[np.argmin(removal_scores)]\n                    new_solution[remove_idx] = 0\n                    current_weight -= weight_lst[remove_idx]\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Probabilistic removal of low-contribution items\n    if len(items_in) > 0:\n        removal_scores = (value1_lst[items_in] + value2_lst[items_in]) / (weight_lst[items_in] + 1e-6)\n        sorted_indices = np.argsort(removal_scores)\n        bottom_items = items_in[sorted_indices[:max(1, len(items_in)//3)]]\n\n        for idx in bottom_items:\n            if np.random.rand() < 0.4:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Dynamic weight constraint enforcement\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            removal_order = np.argsort((value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6))\n            for idx in items_in_new[removal_order]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9564848801450054,
            3.4543945491313934
        ]
    },
    {
        "algorithm": "{The algorithm selects a promising solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search strategy that combines weight-balanced flips and objective-driven additions to explore the solution space while ensuring feasibility through adaptive capacity management.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution using a hybrid selection criterion (objective dominance and weight balance)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_weights = weights / capacity\n    scores = (objectives[:, 0] + objectives[:, 1]) / (1 + normalized_weights)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight and remaining capacity\n    current_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Novel local search strategy: objective-driven flips and weight-balanced additions\n    new_solution = base_solution.copy()\n    items = np.where(new_solution == 1)[0]\n    non_items = np.where(new_solution == 0)[0]\n\n    # Calculate value-to-weight ratios for non-included items\n    if len(non_items) > 0:\n        value1_ratio = value1_lst[non_items] / weight_lst[non_items]\n        value2_ratio = value2_lst[non_items] / weight_lst[non_items]\n\n        # Select top 3 items with highest combined value-to-weight ratios\n        combined_ratio = value1_ratio + value2_ratio\n        top_indices = np.argsort(combined_ratio)[-min(3, len(combined_ratio)):][::-1]\n        for idx in top_indices:\n            item_idx = non_items[idx]\n            if weight_lst[item_idx] <= remaining_capacity:\n                new_solution[item_idx] = 1\n                remaining_capacity -= weight_lst[item_idx]\n\n    # Adaptive capacity management: remove items with lowest ratio if still over capacity\n    if remaining_capacity < 0:\n        items_in_solution = np.where(new_solution == 1)[0]\n        if len(items_in_solution) > 0:\n            value1_ratio = value1_lst[items_in_solution] / weight_lst[items_in_solution]\n            value2_ratio = value2_lst[items_in_solution] / weight_lst[items_in_solution]\n            combined_ratio = value1_ratio + value2_ratio\n            sorted_indices = np.argsort(combined_ratio)\n\n            for idx in sorted_indices:\n                item_idx = items_in_solution[idx]\n                new_solution[item_idx] = 0\n                remaining_capacity += weight_lst[item_idx]\n                if remaining_capacity >= 0:\n                    break\n\n    # Weight-balanced flips: flip items that create a balanced weight distribution\n    if len(items) > 0:\n        flip_candidates = [i for i in items if abs(weight_lst[i] - remaining_capacity * 0.3) < 0.15 * capacity]\n        if len(flip_candidates) > 0:\n            flip_indices = random.sample(flip_candidates, min(1, len(flip_candidates)))\n            for idx in flip_indices:\n                new_solution[idx] = 0\n                remaining_capacity += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.95070882303056,
            2.1341150104999542
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its diversity and objective balance, then applies a novel path-based local search that explores item sequences by considering both profit ratios and weight distribution, ensuring feasibility through iterative adjustments and adaptive capacity management.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high diversity and balanced objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    diversity_scores = np.std(normalized_objectives, axis=1)\n    combined_scores = np.sum(normalized_objectives, axis=1) * diversity_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Path-based local search: explore item sequences\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate value-to-weight ratios and sort items\n    value1_ratio = value1_lst / weight_lst\n    value2_ratio = value2_lst / weight_lst\n    combined_ratio = value1_ratio + value2_ratio\n    sorted_indices = np.argsort(combined_ratio)[::-1]\n\n    # Explore paths by considering both high-ratio and weight-distribution\n    for i in range(min(10, n_items)):\n        item_idx = sorted_indices[i]\n        if new_solution[item_idx] == 0 and current_weight + weight_lst[item_idx] <= capacity:\n            new_solution[item_idx] = 1\n            current_weight += weight_lst[item_idx]\n        elif new_solution[item_idx] == 1:\n            # Check if removing improves balance\n            if np.sum(weight_lst * new_solution) - weight_lst[item_idx] <= capacity:\n                new_solution[item_idx] = 0\n                current_weight -= weight_lst[item_idx]\n\n    # Adaptive capacity management: adjust if over capacity\n    if current_weight > capacity:\n        # Remove items with lowest combined ratio until feasible\n        items_in_solution = np.where(new_solution == 1)[0]\n        sorted_items = items_in_solution[np.argsort(combined_ratio[items_in_solution])]\n        for item_idx in sorted_items:\n            if current_weight <= capacity:\n                break\n            new_solution[item_idx] = 0\n            current_weight -= weight_lst[item_idx]\n\n    # Ensure at least one item remains if solution is not empty\n    if np.sum(new_solution) == 0 and n_items > 0:\n        # Add the item with highest combined ratio\n        best_item = sorted_indices[0]\n        if weight_lst[best_item] <= capacity:\n            new_solution[best_item] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.9073684361272066,
            1.9762572944164276
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a weighted combination of objective values and weight utilization, then applies a novel local search that uses dynamic item prioritization and probabilistic perturbation to explore high-potential regions while maintaining feasibility through adaptive weight constraints.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (weighted combination of objectives and weight utilization)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_weights = weights / capacity\n    weighted_scores = 0.6 * objectives[:, 0] + 0.4 * objectives[:, 1] - 0.3 * normalized_weights\n    selected_idx = np.argmax(weighted_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dynamic item prioritization and probabilistic perturbation\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate dynamic priorities for items not in solution\n    if len(items_out) > 0:\n        priority_scores = (value1_lst[items_out] + value2_lst[items_out]) / (weight_lst[items_out] + 1e-6)\n        sorted_indices = np.argsort(priority_scores)[::-1]\n        top_items = items_out[sorted_indices[:max(1, len(items_out)//4)]]\n\n        # Add items with probability proportional to their priority\n        for idx in top_items:\n            if np.random.rand() < 0.7 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Probabilistic removal of low-priority items\n    if len(items_in) > 0:\n        removal_scores = (value1_lst[items_in] + value2_lst[items_in]) / (weight_lst[items_in] + 1e-6)\n        sorted_indices = np.argsort(removal_scores)\n        bottom_items = items_in[sorted_indices[:max(1, len(items_in)//3)]]\n\n        for idx in bottom_items:\n            if np.random.rand() < 0.5:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Adaptive weight constraint enforcement\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            removal_order = np.argsort((value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6))\n            for idx in items_in_new[removal_order]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.951269370000086,
            2.5577997267246246
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a combination of objective dominance and diversity, then applies a novel local search that uses adaptive item grouping and probabilistic swaps to explore high-potential regions while maintaining feasibility through dynamic capacity constraints.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution based on objective dominance and diversity\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.zeros(len(archive))\n    for i in range(2):\n        sorted_idx = np.argsort(objectives[:, i])\n        crowding_distances[sorted_idx[0]] = np.inf\n        crowding_distances[sorted_idx[-1]] = np.inf\n        for j in range(1, len(archive)-1):\n            crowding_distances[sorted_idx[j]] += (objectives[sorted_idx[j+1], i] - objectives[sorted_idx[j-1], i]) / (objectives[sorted_idx[-1], i] - objectives[sorted_idx[0], i] + 1e-6)\n\n    combined_scores = 0.7 * objectives[:, 0] + 0.3 * objectives[:, 1] + 0.2 * crowding_distances\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item grouping and probabilistic swaps\n    new_solution = base_solution.copy()\n    items = np.arange(len(weight_lst))\n    groups = np.zeros(len(items), dtype=int)\n\n    # Create groups based on value/weight ratios\n    ratio1 = value1_lst / (weight_lst + 1e-6)\n    ratio2 = value2_lst / (weight_lst + 1e-6)\n    combined_ratio = 0.6 * ratio1 + 0.4 * ratio2\n\n    # Group items into 4 categories based on combined ratio\n    percentiles = np.percentile(combined_ratio, [33, 66])\n    groups[(combined_ratio <= percentiles[0])] = 0\n    groups[(combined_ratio > percentiles[0]) & (combined_ratio <= percentiles[1])] = 1\n    groups[(combined_ratio > percentiles[1])] = 2\n\n    # Perform probabilistic swaps within groups\n    for group in range(3):\n        group_items = items[groups == group]\n        in_group = group_items[new_solution[group_items] == 1]\n        out_group = group_items[new_solution[group_items] == 0]\n\n        if len(in_group) > 0 and len(out_group) > 0:\n            # Swap with probability based on group quality\n            swap_prob = 0.3 + 0.2 * (2 - group)  # Higher probability for better groups\n            if np.random.rand() < swap_prob:\n                # Select random items to swap\n                num_swaps = min(2, len(in_group), len(out_group))\n                swap_in = np.random.choice(in_group, size=num_swaps, replace=False)\n                swap_out = np.random.choice(out_group, size=num_swaps, replace=False)\n\n                # Check feasibility before swapping\n                total_add = np.sum(weight_lst[swap_out])\n                total_remove = np.sum(weight_lst[swap_in])\n                net_change = total_add - total_remove\n\n                if current_weight + net_change <= capacity:\n                    new_solution[swap_in] = 0\n                    new_solution[swap_out] = 1\n                    current_weight += net_change\n\n    # Dynamic capacity adjustment for overfilled solutions\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in = np.where(new_solution == 1)[0]\n        if len(items_in) > 0:\n            # Remove items in order of lowest combined ratio\n            removal_order = np.argsort(combined_ratio[items_in])\n            for idx in items_in[removal_order]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9773377334378451,
            7.768424540758133
        ]
    },
    {
        "algorithm": "{The algorithm selects a promising solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search strategy that combines weight-balanced flips and objective-driven additions to explore the solution space while ensuring feasibility through adaptive capacity management.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    scores = np.sum(normalized_objectives, axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight and remaining capacity\n    current_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Novel local search strategy: objective-driven flips and weight-balanced additions\n    new_solution = base_solution.copy()\n    items = np.where(new_solution == 1)[0]\n    non_items = np.where(new_solution == 0)[0]\n\n    # Calculate value-to-weight ratios for non-included items\n    if len(non_items) > 0:\n        value1_ratio = value1_lst[non_items] / weight_lst[non_items]\n        value2_ratio = value2_lst[non_items] / weight_lst[non_items]\n\n        # Select top 4 items with highest combined value-to-weight ratios\n        combined_ratio = value1_ratio + value2_ratio\n        top_indices = np.argsort(combined_ratio)[-min(4, len(combined_ratio)):][::-1]\n        for idx in top_indices:\n            item_idx = non_items[idx]\n            if weight_lst[item_idx] <= remaining_capacity:\n                new_solution[item_idx] = 1\n                remaining_capacity -= weight_lst[item_idx]\n\n    # Adaptive capacity management: remove items with lowest ratio if still over capacity\n    if remaining_capacity < 0:\n        items_in_solution = np.where(new_solution == 1)[0]\n        if len(items_in_solution) > 0:\n            value1_ratio = value1_lst[items_in_solution] / weight_lst[items_in_solution]\n            value2_ratio = value2_lst[items_in_solution] / weight_lst[items_in_solution]\n            combined_ratio = value1_ratio + value2_ratio\n            sorted_indices = np.argsort(combined_ratio)\n\n            for idx in sorted_indices:\n                item_idx = items_in_solution[idx]\n                new_solution[item_idx] = 0\n                remaining_capacity += weight_lst[item_idx]\n                if remaining_capacity >= 0:\n                    break\n\n    # Weight-balanced flips: flip items that create a balanced weight distribution\n    if len(items) > 0:\n        flip_candidates = [i for i in items if abs(weight_lst[i] - remaining_capacity * 0.5) < 0.2 * capacity]\n        if len(flip_candidates) > 0:\n            flip_indices = random.sample(flip_candidates, min(1, len(flip_candidates)))\n            for idx in flip_indices:\n                new_solution[idx] = 0\n                remaining_capacity += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7638336582425744,
            1.1615501642227173
        ]
    },
    {
        "algorithm": "{The algorithm selects a promising solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search strategy that combines weight-balanced flips and objective-driven additions to explore the solution space while ensuring feasibility through adaptive capacity management.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    scores = np.sum(normalized_objectives, axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight and remaining capacity\n    current_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Novel local search strategy: weight-balanced flips and objective-driven additions\n    new_solution = base_solution.copy()\n    items = np.where(new_solution == 1)[0]\n    non_items = np.where(new_solution == 0)[0]\n\n    # Calculate value-to-weight ratios for non-included items\n    if len(non_items) > 0:\n        value1_ratio = value1_lst[non_items] / weight_lst[non_items]\n        value2_ratio = value2_lst[non_items] / weight_lst[non_items]\n\n        # Select top 5 items with highest combined value-to-weight ratios\n        combined_ratio = value1_ratio + value2_ratio\n        top_indices = np.argsort(combined_ratio)[-min(5, len(combined_ratio)):][::-1]\n        for idx in top_indices:\n            item_idx = non_items[idx]\n            if weight_lst[item_idx] <= remaining_capacity:\n                new_solution[item_idx] = 1\n                remaining_capacity -= weight_lst[item_idx]\n\n    # Adaptive capacity management: remove items with lowest ratio if still over capacity\n    if remaining_capacity < 0:\n        items_in_solution = np.where(new_solution == 1)[0]\n        if len(items_in_solution) > 0:\n            value1_ratio = value1_lst[items_in_solution] / weight_lst[items_in_solution]\n            value2_ratio = value2_lst[items_in_solution] / weight_lst[items_in_solution]\n            combined_ratio = value1_ratio + value2_ratio\n            sorted_indices = np.argsort(combined_ratio)\n\n            for idx in sorted_indices:\n                item_idx = items_in_solution[idx]\n                new_solution[item_idx] = 0\n                remaining_capacity += weight_lst[item_idx]\n                if remaining_capacity >= 0:\n                    break\n\n    # Weight-balanced flips: randomly flip 2 items with weight close to remaining capacity\n    if len(items) > 0:\n        flip_candidates = [i for i in items if abs(weight_lst[i] - remaining_capacity) < 0.1 * capacity]\n        if len(flip_candidates) > 0:\n            flip_indices = random.sample(flip_candidates, min(2, len(flip_candidates)))\n            for idx in flip_indices:\n                new_solution[idx] = 0\n                remaining_capacity += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.887089948480458,
            1.368062973022461
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a hybrid of objective dominance and weight efficiency, then applies a novel local search that combines greedy value-to-weight prioritization with probabilistic item swaps to explore diverse high-value regions while maintaining feasibility through adaptive constraint relaxation.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced objective dominance and weight efficiency\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_weights = weights / capacity\n    dominance_scores = objectives[:, 0] * objectives[:, 1] / (1 + normalized_weights)\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate value-to-weight ratios for all items\n    v1w_ratio = value1_lst / (weight_lst + 1e-6)\n    v2w_ratio = value2_lst / (weight_lst + 1e-6)\n    combined_ratio = (v1w_ratio + v2w_ratio) / 2\n\n    # Greedy addition of top items not in solution\n    items_out = np.where(new_solution == 0)[0]\n    if len(items_out) > 0:\n        sorted_indices = np.argsort(combined_ratio[items_out])[::-1]\n        top_items = items_out[sorted_indices[:max(1, len(items_out)//5)]]\n        for idx in top_items:\n            if np.random.rand() < 0.6 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Probabilistic item swaps between objectives\n    items_in = np.where(new_solution == 1)[0]\n    if len(items_in) > 0:\n        for idx in items_in:\n            if np.random.rand() < 0.3:\n                if value1_lst[idx] < value2_lst[idx] and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1  # Maintain or swap\n                else:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n\n    # Adaptive constraint relaxation if needed\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        items_to_remove = np.where(new_solution == 1)[0]\n        if len(items_to_remove) > 0:\n            sorted_indices = np.argsort(combined_ratio[items_to_remove])\n            for idx in items_to_remove[sorted_indices]:\n                if excess <= 0:\n                    break\n                new_solution[idx] = 0\n                excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9701185302932352,
            4.205201625823975
        ]
    }
]