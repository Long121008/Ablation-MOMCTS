[
    {
        "algorithm": "{The algorithm selects a promising solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search strategy that combines weight-balanced flips and objective-driven additions to explore the solution space while ensuring feasibility through adaptive capacity management.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    scores = np.sum(normalized_objectives, axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight and remaining capacity\n    current_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Novel local search strategy: weight-balanced flips and objective-driven additions\n    new_solution = base_solution.copy()\n    items = np.where(new_solution == 1)[0]\n    non_items = np.where(new_solution == 0)[0]\n\n    # Calculate value-to-weight ratios for non-included items\n    if len(non_items) > 0:\n        value1_ratio = value1_lst[non_items] / weight_lst[non_items]\n        value2_ratio = value2_lst[non_items] / weight_lst[non_items]\n\n        # Select top 5 items with highest combined value-to-weight ratios\n        combined_ratio = value1_ratio + value2_ratio\n        top_indices = np.argsort(combined_ratio)[-min(5, len(combined_ratio)):][::-1]\n        for idx in top_indices:\n            item_idx = non_items[idx]\n            if weight_lst[item_idx] <= remaining_capacity:\n                new_solution[item_idx] = 1\n                remaining_capacity -= weight_lst[item_idx]\n\n    # Adaptive capacity management: remove items with lowest ratio if still over capacity\n    if remaining_capacity < 0:\n        items_in_solution = np.where(new_solution == 1)[0]\n        if len(items_in_solution) > 0:\n            value1_ratio = value1_lst[items_in_solution] / weight_lst[items_in_solution]\n            value2_ratio = value2_lst[items_in_solution] / weight_lst[items_in_solution]\n            combined_ratio = value1_ratio + value2_ratio\n            sorted_indices = np.argsort(combined_ratio)\n\n            for idx in sorted_indices:\n                item_idx = items_in_solution[idx]\n                new_solution[item_idx] = 0\n                remaining_capacity += weight_lst[item_idx]\n                if remaining_capacity >= 0:\n                    break\n\n    # Weight-balanced flips: randomly flip 2 items with weight close to remaining capacity\n    if len(items) > 0:\n        flip_candidates = [i for i in items if abs(weight_lst[i] - remaining_capacity) < 0.1 * capacity]\n        if len(flip_candidates) > 0:\n            flip_indices = random.sample(flip_candidates, min(2, len(flip_candidates)))\n            for idx in flip_indices:\n                new_solution[idx] = 0\n                remaining_capacity += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.887089948480458,
            1.368062973022461
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its diversity and objective balance, then applies a novel path-based local search that explores item sequences by considering both profit ratios and weight distribution, ensuring feasibility through iterative adjustments and adaptive capacity management.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high diversity and balanced objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    diversity_scores = np.std(normalized_objectives, axis=1)\n    combined_scores = np.sum(normalized_objectives, axis=1) * diversity_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Path-based local search: explore item sequences\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate value-to-weight ratios and sort items\n    value1_ratio = value1_lst / weight_lst\n    value2_ratio = value2_lst / weight_lst\n    combined_ratio = value1_ratio + value2_ratio\n    sorted_indices = np.argsort(combined_ratio)[::-1]\n\n    # Explore paths by considering both high-ratio and weight-distribution\n    for i in range(min(10, n_items)):\n        item_idx = sorted_indices[i]\n        if new_solution[item_idx] == 0 and current_weight + weight_lst[item_idx] <= capacity:\n            new_solution[item_idx] = 1\n            current_weight += weight_lst[item_idx]\n        elif new_solution[item_idx] == 1:\n            # Check if removing improves balance\n            if np.sum(weight_lst * new_solution) - weight_lst[item_idx] <= capacity:\n                new_solution[item_idx] = 0\n                current_weight -= weight_lst[item_idx]\n\n    # Adaptive capacity management: adjust if over capacity\n    if current_weight > capacity:\n        # Remove items with lowest combined ratio until feasible\n        items_in_solution = np.where(new_solution == 1)[0]\n        sorted_items = items_in_solution[np.argsort(combined_ratio[items_in_solution])]\n        for item_idx in sorted_items:\n            if current_weight <= capacity:\n                break\n            new_solution[item_idx] = 0\n            current_weight -= weight_lst[item_idx]\n\n    # Ensure at least one item remains if solution is not empty\n    if np.sum(new_solution) == 0 and n_items > 0:\n        # Add the item with highest combined ratio\n        best_item = sorted_indices[0]\n        if weight_lst[best_item] <= capacity:\n            new_solution[best_item] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.9073684361272066,
            1.9762572944164276
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a weighted combination of objective values and weight utilization, then applies a novel local search that uses dynamic item prioritization and probabilistic perturbation to explore high-potential regions while maintaining feasibility through adaptive weight constraints.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (weighted combination of objectives and weight utilization)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_weights = weights / capacity\n    weighted_scores = 0.6 * objectives[:, 0] + 0.4 * objectives[:, 1] - 0.3 * normalized_weights\n    selected_idx = np.argmax(weighted_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dynamic item prioritization and probabilistic perturbation\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate dynamic priorities for items not in solution\n    if len(items_out) > 0:\n        priority_scores = (value1_lst[items_out] + value2_lst[items_out]) / (weight_lst[items_out] + 1e-6)\n        sorted_indices = np.argsort(priority_scores)[::-1]\n        top_items = items_out[sorted_indices[:max(1, len(items_out)//4)]]\n\n        # Add items with probability proportional to their priority\n        for idx in top_items:\n            if np.random.rand() < 0.7 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Probabilistic removal of low-priority items\n    if len(items_in) > 0:\n        removal_scores = (value1_lst[items_in] + value2_lst[items_in]) / (weight_lst[items_in] + 1e-6)\n        sorted_indices = np.argsort(removal_scores)\n        bottom_items = items_in[sorted_indices[:max(1, len(items_in)//3)]]\n\n        for idx in bottom_items:\n            if np.random.rand() < 0.5:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Adaptive weight constraint enforcement\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            removal_order = np.argsort((value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6))\n            for idx in items_in_new[removal_order]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.951269370000086,
            2.5577997267246246
        ]
    },
    {
        "algorithm": "{This algorithm intelligently selects a solution from the archive with high potential for improvement by evaluating the solution's \"frontier\" status (non-dominated but close to the Pareto front) and applies a hybrid local search operator that combines item swaps with adaptive perturbation to explore the solution space while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution (non-dominated with high potential)\n    # We prioritize solutions that are on the frontier (non-dominated but close to the Pareto front)\n    # and have not been fully explored (i.e., not all bits are 1 or 0)\n    frontier_solutions = []\n    for sol, _ in archive:\n        if np.sum(sol) > 0 and np.sum(sol) < len(sol):\n            frontier_solutions.append(sol)\n\n    if not frontier_solutions:\n        frontier_solutions = [sol for sol, _ in archive]\n\n    # Randomly select a solution from the frontier\n    base_solution = random.choice(frontier_solutions).copy()\n\n    # Step 2: Generate a neighbor using a hybrid local search operator\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Hybrid operator: Randomly select a subset of items to flip (swap 0s and 1s)\n    # with adaptive size based on the current solution's density\n    density = np.sum(base_solution) / n_items\n    flip_size = max(1, int(0.1 * n_items * (1 - density)))  # More flips for sparse solutions\n\n    # Randomly select flip_size items to flip\n    flip_indices = random.sample(range(n_items), flip_size)\n\n    # Flip the selected items\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            # If removing the item keeps the solution feasible, do it\n            if np.sum(weight_lst * base_solution) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            # If adding the item keeps the solution feasible, do it\n            if np.sum(weight_lst * base_solution) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Ensure feasibility (should not be needed due to checks above, but just in case)\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove items randomly until feasible\n        excess = np.sum(weight_lst * new_solution) - capacity\n        current_weight = np.sum(weight_lst * new_solution)\n        while current_weight > capacity:\n            # Remove the heaviest item that can be removed without making the solution empty\n            if np.sum(new_solution) == 1:\n                break  # Cannot remove more items\n            heavy_items = np.where(new_solution == 1)[0]\n            heaviest_idx = heavy_items[np.argmax(weight_lst[heavy_items])]\n            new_solution[heaviest_idx] = 0\n            current_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n",
        "score": [
            -0.578022104383614,
            1.7531713843345642
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on a hybrid of objective diversity and weight distribution, then applies a novel multi-phase local search that first explores high-value items, then refines the solution through adaptive swaps and finally performs a targeted weight-balancing phase while always maintaining feasibility through dynamic capacity checks.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution based on hybrid of objective diversity and weight distribution\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    diversity_scores = np.std(objectives, axis=0)\n    weight_scores = (capacity - weights) / capacity\n    combined_scores = 0.6 * diversity_scores[0] + 0.4 * weight_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Phase 1: High-value item exploration\n    non_items = np.where(new_solution == 0)[0]\n    if len(non_items) > 0:\n        # Calculate normalized value scores\n        value1_scores = value1_lst[non_items] / np.max(value1_lst[non_items] + 1e-6)\n        value2_scores = value2_lst[non_items] / np.max(value2_lst[non_items] + 1e-6)\n        combined_scores = 0.7 * value1_scores + 0.3 * value2_scores\n\n        # Select top 3 items with highest combined scores\n        top_indices = np.argsort(combined_scores)[-min(3, len(combined_scores)):][::-1]\n        for idx in top_indices:\n            item_idx = non_items[idx]\n            if weight_lst[item_idx] <= remaining_capacity:\n                new_solution[item_idx] = 1\n                remaining_capacity -= weight_lst[item_idx]\n\n    # Phase 2: Adaptive swaps\n    items = np.where(new_solution == 1)[0]\n    if len(items) > 1 and len(non_items) > 0:\n        # Find items with low marginal contribution\n        marginal_value1 = value1_lst[items] / weight_lst[items]\n        marginal_value2 = value2_lst[items] / weight_lst[items]\n        low_contrib = np.argsort(marginal_value1 + marginal_value2)[:min(2, len(items))]\n\n        for i in low_contrib:\n            item_idx = items[i]\n            new_solution[item_idx] = 0\n            remaining_capacity += weight_lst[item_idx]\n\n            # Try to add better items\n            add_candidates = [idx for idx in non_items if weight_lst[idx] <= remaining_capacity]\n            if add_candidates:\n                best_candidate = max(add_candidates, key=lambda x: (value1_lst[x] + value2_lst[x]) / weight_lst[x])\n                new_solution[best_candidate] = 1\n                remaining_capacity -= weight_lst[best_candidate]\n\n    # Phase 3: Targeted weight balancing\n    if remaining_capacity > 0:\n        # Add items that best fill the remaining capacity\n        add_candidates = [idx for idx in non_items if weight_lst[idx] <= remaining_capacity]\n        if add_candidates:\n            best_candidate = max(add_candidates, key=lambda x: abs(weight_lst[x] - remaining_capacity))\n            new_solution[best_candidate] = 1\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        items = np.where(new_solution == 1)[0]\n        if len(items) > 0:\n            largest_items = np.argsort(weight_lst[items])[::-1]\n            for i in largest_items:\n                item_idx = items[i]\n                new_solution[item_idx] = 0\n                current_weight -= weight_lst[item_idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.9279519598685808,
            5.768968194723129
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search that combines adaptive item grouping with a biased random walk, where items are first clustered by their marginal gain ratios, and then explored within these clusters to identify high-potential regions for improvement while ensuring feasibility through weight-constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    scores = np.sum(normalized_objectives, axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item grouping and biased random walk\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate marginal gain ratios for items not in solution\n    if len(items_out) > 0:\n        ratio1 = value1_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        ratio2 = value2_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        combined_ratio = ratio1 + ratio2\n\n        # Cluster items by marginal gain ratio\n        sorted_indices = np.argsort(combined_ratio)[::-1]\n        top_cluster = items_out[sorted_indices[:max(1, len(items_out)//3)]]\n\n        # Randomly select from top cluster with higher probability\n        if len(top_cluster) > 0:\n            for _ in range(2):\n                candidate_idx = np.random.choice(top_cluster)\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Biased random walk: remove low-contribution items\n    if len(items_in) > 0:\n        # Calculate contribution of each item in solution\n        contribution1 = value1_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        contribution2 = value2_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        combined_contribution = contribution1 + contribution2\n\n        # Remove items with lowest contribution\n        sorted_indices = np.argsort(combined_contribution)\n        bottom_cluster = items_in[sorted_indices[:max(1, len(items_in)//3)]]\n\n        if len(bottom_cluster) > 0:\n            for _ in range(2):\n                candidate_idx = np.random.choice(bottom_cluster)\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            # Remove items with smallest weight to contribution ratio\n            contribution_ratio = (value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6)\n            sorted_indices = np.argsort(contribution_ratio)\n            for idx in items_in_new[sorted_indices]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8573593365299407,
            1.7612662315368652
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive by prioritizing those with high diversity in their objective values and low weight utilization, then applies a novel local search that combines adaptive item reallocation with a biased random walk, where items are first clustered by their weight-to-value ratios, and then explored within these clusters to identify high-potential regions for improvement while ensuring feasibility through weight-constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high diversity in objectives and low weight utilization\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    diversity = np.std(objectives, axis=0)\n    scores = diversity[0] + diversity[1] - weights / capacity\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item reallocation\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Cluster items by weight-to-value ratio\n    if len(items_out) > 0:\n        ratio1 = weight_lst[items_out] / (value1_lst[items_out] + 1e-6)\n        ratio2 = weight_lst[items_out] / (value2_lst[items_out] + 1e-6)\n        combined_ratio = ratio1 + ratio2\n        sorted_indices = np.argsort(combined_ratio)\n        top_cluster = items_out[sorted_indices[:max(1, len(items_out)//4)]]\n\n        # Randomly select from top cluster with higher probability\n        if len(top_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(top_cluster)\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Biased random walk: remove low-contribution items\n    if len(items_in) > 0:\n        contribution1 = value1_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        contribution2 = value2_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        combined_contribution = contribution1 + contribution2\n        sorted_indices = np.argsort(combined_contribution)\n        bottom_cluster = items_in[sorted_indices[:max(1, len(items_in)//4)]]\n\n        if len(bottom_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(bottom_cluster)\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            contribution_ratio = (value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6)\n            sorted_indices = np.argsort(contribution_ratio)\n            for idx in items_in_new[sorted_indices]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8991984430012842,
            3.4054389595985413
        ]
    },
    {
        "algorithm": "{The heuristic selects a promising solution from the archive based on a weighted random choice favoring solutions with higher objective values, then applies a hybrid local search operator that combines element-wise mutation with a greedy insertion of high-value items to generate a feasible neighbor solution.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with weighted random choice (higher objectives have higher probability)\n    objectives = np.array([obj for (sol, obj) in archive])\n    weights = objectives[:, 0] + objectives[:, 1]  # Sum of both objectives as weights\n    weights = weights / np.sum(weights)  # Normalize to probabilities\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: element-wise flip with probability and greedy insertion\n    for i in range(len(new_solution)):\n        if np.random.rand() < 0.2:  # Flip with 20% probability\n            if new_solution[i] == 1:\n                new_solution[i] = 0\n            else:\n                # Check if adding the item exceeds capacity\n                current_weight = np.sum(weight_lst[new_solution == 1])\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n\n    # Greedy insertion of high-value items not in the solution\n    remaining_items = np.where(new_solution == 0)[0]\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Sort remaining items by combined value (value1 + value2) in descending order\n    combined_values = value1_lst + value2_lst\n    sorted_items = sorted(remaining_items, key=lambda x: -combined_values[x])\n\n    for i in sorted_items:\n        if current_weight + weight_lst[i] <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.4055213825643438,
            2.4868115186691284
        ]
    },
    {
        "algorithm": "{A novel heuristic that combines diversity-aware solution selection with a multi-phase local search incorporating adaptive item clustering and objective-balanced perturbations to explore high-potential regions while maintaining feasibility through capacity-constrained operations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst)\n\n    # Phase 1: Diversity-aware selection\n    solutions = [s[0] for s in archive]\n    diversity_scores = np.array([np.sum(np.abs(s - solutions[i])) for i, s in enumerate(solutions)])\n    selected_idx = np.argmax(diversity_scores)\n    base_solution = solutions[selected_idx].copy()\n\n    # Phase 2: Adaptive item clustering\n    included = np.where(base_solution == 1)[0]\n    excluded = np.where(base_solution == 0)[0]\n\n    if len(included) > 0:\n        # Cluster items by objective correlation\n        obj_corr = np.corrcoef(value1_lst[included], value2_lst[included])[0,1]\n        if obj_corr > 0.5:  # Strong correlation\n            # Perturb high-value clusters\n            cluster_values = value1_lst[included] + value2_lst[included]\n            top_cluster = included[np.argsort(cluster_values)[-min(3, len(included)):]]\n            for idx in top_cluster:\n                base_solution[idx] = 0\n        else:  # Weak correlation\n            # Perturb low-value items\n            low_value_items = included[np.argsort(value1_lst[included] + value2_lst[included])[:min(2, len(included))]]\n            for idx in low_value_items:\n                base_solution[idx] = 0\n\n    # Phase 3: Objective-balanced perturbations\n    current_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Calculate objective ratios\n    obj1_ratio = np.sum(value1_lst * base_solution) / (np.sum(value1_lst) + 1e-6)\n    obj2_ratio = np.sum(value2_lst * base_solution) / (np.sum(value2_lst) + 1e-6)\n    balance_factor = 0.5 * (1 - abs(obj1_ratio - obj2_ratio))\n\n    # Add items with balanced objective impact\n    potential_items = excluded[weight_lst[excluded] <= remaining_capacity]\n    if len(potential_items) > 0:\n        item_scores = (value1_lst[potential_items] + value2_lst[potential_items]) * (1 + balance_factor)\n        selected_items = potential_items[np.argsort(item_scores)[-min(3, len(potential_items)):]]\n        for idx in selected_items:\n            base_solution[idx] = 1\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst * base_solution)\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        items_in_solution = np.where(base_solution == 1)[0]\n        remove_items = items_in_solution[np.argsort(value1_lst[items_in_solution] + value2_lst[items_in_solution])[:len(items_in_solution)]]\n        for idx in remove_items:\n            if excess <= 0:\n                break\n            base_solution[idx] = 0\n            excess -= weight_lst[idx]\n\n    return base_solution\n\n",
        "score": [
            -0.8257414462080568,
            2.705544173717499
        ]
    },
    {
        "algorithm": "{A novel hybrid local search algorithm that combines adaptive cluster-based mutation with a multi-objective-aware simulated annealing approach to explore the solution space by dynamically grouping and perturbing items based on their value-weight ratios while using a temperature-controlled acceptance criterion to balance exploration and exploitation.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst)\n\n    # Select a base solution with high potential for improvement\n    base_solution, _ = max(archive, key=lambda x: (x[1][0] + x[1][1]) / (np.sum(weight_lst[x[0] == 1]) + 1e-6))\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 1: Adaptive cluster-based mutation\n    # Calculate normalized value-weight ratios for both objectives\n    ratio1 = value1_lst / (weight_lst + 1e-6)\n    ratio2 = value2_lst / (weight_lst + 1e-6)\n    combined_ratio = (ratio1 + ratio2) / 2\n\n    # Cluster items into high, medium, and low value-weight groups\n    sorted_indices = np.argsort(combined_ratio)[::-1]\n    high_cluster = sorted_indices[:len(sorted_indices)//3]\n    medium_cluster = sorted_indices[len(sorted_indices)//3:2*len(sorted_indices)//3]\n    low_cluster = sorted_indices[2*len(sorted_indices)//3:]\n\n    # Select a cluster to perturb based on current solution state\n    if np.sum(new_solution[high_cluster]) < len(high_cluster) * 0.7:  # If high cluster underutilized\n        target_cluster = high_cluster\n    elif np.sum(new_solution[medium_cluster]) < len(medium_cluster) * 0.5:  # If medium cluster underutilized\n        target_cluster = medium_cluster\n    else:\n        target_cluster = low_cluster\n\n    # Perturb the selected cluster\n    for idx in target_cluster:\n        # With probability based on current state and value-weight ratio\n        prob = (combined_ratio[idx] * (1 - new_solution[idx]) * 0.8 +\n                combined_ratio[idx] * new_solution[idx] * 0.2)\n        if random.random() < prob:\n            if new_solution[idx] == 0 and remaining_capacity >= weight_lst[idx]:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n            elif new_solution[idx] == 1:\n                new_solution[idx] = 0\n                remaining_capacity += weight_lst[idx]\n\n    # Step 2: Multi-objective simulated annealing\n    temp = 1.0  # Initial temperature\n    cooling_rate = 0.95\n\n    for _ in range(5):\n        # Generate a candidate neighbor by flipping a random item\n        candidate_idx = random.randint(0, len(weight_lst) - 1)\n        candidate_solution = new_solution.copy()\n\n        if candidate_solution[candidate_idx] == 0 and remaining_capacity >= weight_lst[candidate_idx]:\n            candidate_solution[candidate_idx] = 1\n            candidate_weight = current_weight + weight_lst[candidate_idx]\n        elif candidate_solution[candidate_idx] == 1:\n            candidate_solution[candidate_idx] = 0\n            candidate_weight = current_weight - weight_lst[candidate_idx]\n        else:\n            continue\n\n        # Calculate objective values for candidate\n        candidate_value1 = np.sum(value1_lst[candidate_solution == 1])\n        candidate_value2 = np.sum(value2_lst[candidate_solution == 1])\n\n        # Calculate objective values for current solution\n        current_value1 = np.sum(value1_lst[new_solution == 1])\n        current_value2 = np.sum(value2_lst[new_solution == 1])\n\n        # Acceptance criterion (simulated annealing)\n        if (candidate_weight <= capacity and\n            ((candidate_value1 > current_value1 and candidate_value2 >= current_value2) or\n             (candidate_value1 >= current_value1 and candidate_value2 > current_value2) or\n             (random.random() < np.exp((candidate_value1 + candidate_value2 - current_value1 - current_value2) / temp)))):\n            new_solution = candidate_solution\n            current_weight = candidate_weight\n            remaining_capacity = capacity - current_weight\n\n        temp *= cooling_rate\n\n    return new_solution\n\n",
        "score": [
            -0.7347849809740947,
            3.3702951073646545
        ]
    }
]