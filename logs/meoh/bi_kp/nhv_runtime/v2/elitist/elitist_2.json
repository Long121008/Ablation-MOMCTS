[
    {
        "algorithm": "{The algorithm selects a promising solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search strategy that combines weight-balanced flips and objective-driven additions to explore the solution space while ensuring feasibility through adaptive capacity management.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    scores = np.sum(normalized_objectives, axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight and remaining capacity\n    current_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Novel local search strategy: weight-balanced flips and objective-driven additions\n    new_solution = base_solution.copy()\n    items = np.where(new_solution == 1)[0]\n    non_items = np.where(new_solution == 0)[0]\n\n    # Calculate value-to-weight ratios for non-included items\n    if len(non_items) > 0:\n        value1_ratio = value1_lst[non_items] / weight_lst[non_items]\n        value2_ratio = value2_lst[non_items] / weight_lst[non_items]\n\n        # Select top 5 items with highest combined value-to-weight ratios\n        combined_ratio = value1_ratio + value2_ratio\n        top_indices = np.argsort(combined_ratio)[-min(5, len(combined_ratio)):][::-1]\n        for idx in top_indices:\n            item_idx = non_items[idx]\n            if weight_lst[item_idx] <= remaining_capacity:\n                new_solution[item_idx] = 1\n                remaining_capacity -= weight_lst[item_idx]\n\n    # Adaptive capacity management: remove items with lowest ratio if still over capacity\n    if remaining_capacity < 0:\n        items_in_solution = np.where(new_solution == 1)[0]\n        if len(items_in_solution) > 0:\n            value1_ratio = value1_lst[items_in_solution] / weight_lst[items_in_solution]\n            value2_ratio = value2_lst[items_in_solution] / weight_lst[items_in_solution]\n            combined_ratio = value1_ratio + value2_ratio\n            sorted_indices = np.argsort(combined_ratio)\n\n            for idx in sorted_indices:\n                item_idx = items_in_solution[idx]\n                new_solution[item_idx] = 0\n                remaining_capacity += weight_lst[item_idx]\n                if remaining_capacity >= 0:\n                    break\n\n    # Weight-balanced flips: randomly flip 2 items with weight close to remaining capacity\n    if len(items) > 0:\n        flip_candidates = [i for i in items if abs(weight_lst[i] - remaining_capacity) < 0.1 * capacity]\n        if len(flip_candidates) > 0:\n            flip_indices = random.sample(flip_candidates, min(2, len(flip_candidates)))\n            for idx in flip_indices:\n                new_solution[idx] = 0\n                remaining_capacity += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.887089948480458,
            1.368062973022461
        ]
    },
    {
        "algorithm": "{This algorithm intelligently selects a solution from the archive with high potential for improvement by evaluating the solution's \"frontier\" status (non-dominated but close to the Pareto front) and applies a hybrid local search operator that combines item swaps with adaptive perturbation to explore the solution space while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution (non-dominated with high potential)\n    # We prioritize solutions that are on the frontier (non-dominated but close to the Pareto front)\n    # and have not been fully explored (i.e., not all bits are 1 or 0)\n    frontier_solutions = []\n    for sol, _ in archive:\n        if np.sum(sol) > 0 and np.sum(sol) < len(sol):\n            frontier_solutions.append(sol)\n\n    if not frontier_solutions:\n        frontier_solutions = [sol for sol, _ in archive]\n\n    # Randomly select a solution from the frontier\n    base_solution = random.choice(frontier_solutions).copy()\n\n    # Step 2: Generate a neighbor using a hybrid local search operator\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Hybrid operator: Randomly select a subset of items to flip (swap 0s and 1s)\n    # with adaptive size based on the current solution's density\n    density = np.sum(base_solution) / n_items\n    flip_size = max(1, int(0.1 * n_items * (1 - density)))  # More flips for sparse solutions\n\n    # Randomly select flip_size items to flip\n    flip_indices = random.sample(range(n_items), flip_size)\n\n    # Flip the selected items\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            # If removing the item keeps the solution feasible, do it\n            if np.sum(weight_lst * base_solution) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            # If adding the item keeps the solution feasible, do it\n            if np.sum(weight_lst * base_solution) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Ensure feasibility (should not be needed due to checks above, but just in case)\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove items randomly until feasible\n        excess = np.sum(weight_lst * new_solution) - capacity\n        current_weight = np.sum(weight_lst * new_solution)\n        while current_weight > capacity:\n            # Remove the heaviest item that can be removed without making the solution empty\n            if np.sum(new_solution) == 1:\n                break  # Cannot remove more items\n            heavy_items = np.where(new_solution == 1)[0]\n            heaviest_idx = heavy_items[np.argmax(weight_lst[heavy_items])]\n            new_solution[heaviest_idx] = 0\n            current_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n",
        "score": [
            -0.578022104383614,
            1.7531713843345642
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search that combines adaptive item grouping with a biased random walk, where items are first clustered by their marginal gain ratios, and then explored within these clusters to identify high-potential regions for improvement while ensuring feasibility through weight-constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    scores = np.sum(normalized_objectives, axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item grouping and biased random walk\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate marginal gain ratios for items not in solution\n    if len(items_out) > 0:\n        ratio1 = value1_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        ratio2 = value2_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        combined_ratio = ratio1 + ratio2\n\n        # Cluster items by marginal gain ratio\n        sorted_indices = np.argsort(combined_ratio)[::-1]\n        top_cluster = items_out[sorted_indices[:max(1, len(items_out)//3)]]\n\n        # Randomly select from top cluster with higher probability\n        if len(top_cluster) > 0:\n            for _ in range(2):\n                candidate_idx = np.random.choice(top_cluster)\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Biased random walk: remove low-contribution items\n    if len(items_in) > 0:\n        # Calculate contribution of each item in solution\n        contribution1 = value1_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        contribution2 = value2_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        combined_contribution = contribution1 + contribution2\n\n        # Remove items with lowest contribution\n        sorted_indices = np.argsort(combined_contribution)\n        bottom_cluster = items_in[sorted_indices[:max(1, len(items_in)//3)]]\n\n        if len(bottom_cluster) > 0:\n            for _ in range(2):\n                candidate_idx = np.random.choice(bottom_cluster)\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            # Remove items with smallest weight to contribution ratio\n            contribution_ratio = (value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6)\n            sorted_indices = np.argsort(contribution_ratio)\n            for idx in items_in_new[sorted_indices]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8573593365299407,
            1.7612662315368652
        ]
    },
    {
        "algorithm": "{A novel heuristic that combines diversity-aware solution selection with a multi-phase local search incorporating adaptive item clustering and objective-balanced perturbations to explore high-potential regions while maintaining feasibility through capacity-constrained operations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst)\n\n    # Phase 1: Diversity-aware selection\n    solutions = [s[0] for s in archive]\n    diversity_scores = np.array([np.sum(np.abs(s - solutions[i])) for i, s in enumerate(solutions)])\n    selected_idx = np.argmax(diversity_scores)\n    base_solution = solutions[selected_idx].copy()\n\n    # Phase 2: Adaptive item clustering\n    included = np.where(base_solution == 1)[0]\n    excluded = np.where(base_solution == 0)[0]\n\n    if len(included) > 0:\n        # Cluster items by objective correlation\n        obj_corr = np.corrcoef(value1_lst[included], value2_lst[included])[0,1]\n        if obj_corr > 0.5:  # Strong correlation\n            # Perturb high-value clusters\n            cluster_values = value1_lst[included] + value2_lst[included]\n            top_cluster = included[np.argsort(cluster_values)[-min(3, len(included)):]]\n            for idx in top_cluster:\n                base_solution[idx] = 0\n        else:  # Weak correlation\n            # Perturb low-value items\n            low_value_items = included[np.argsort(value1_lst[included] + value2_lst[included])[:min(2, len(included))]]\n            for idx in low_value_items:\n                base_solution[idx] = 0\n\n    # Phase 3: Objective-balanced perturbations\n    current_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Calculate objective ratios\n    obj1_ratio = np.sum(value1_lst * base_solution) / (np.sum(value1_lst) + 1e-6)\n    obj2_ratio = np.sum(value2_lst * base_solution) / (np.sum(value2_lst) + 1e-6)\n    balance_factor = 0.5 * (1 - abs(obj1_ratio - obj2_ratio))\n\n    # Add items with balanced objective impact\n    potential_items = excluded[weight_lst[excluded] <= remaining_capacity]\n    if len(potential_items) > 0:\n        item_scores = (value1_lst[potential_items] + value2_lst[potential_items]) * (1 + balance_factor)\n        selected_items = potential_items[np.argsort(item_scores)[-min(3, len(potential_items)):]]\n        for idx in selected_items:\n            base_solution[idx] = 1\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst * base_solution)\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        items_in_solution = np.where(base_solution == 1)[0]\n        remove_items = items_in_solution[np.argsort(value1_lst[items_in_solution] + value2_lst[items_in_solution])[:len(items_in_solution)]]\n        for idx in remove_items:\n            if excess <= 0:\n                break\n            base_solution[idx] = 0\n            excess -= weight_lst[idx]\n\n    return base_solution\n\n",
        "score": [
            -0.8257414462080568,
            2.705544173717499
        ]
    },
    {
        "algorithm": "{A novel hybrid local search algorithm that combines adaptive cluster-based mutation with a multi-objective-aware simulated annealing approach to explore the solution space by dynamically grouping and perturbing items based on their value-weight ratios while using a temperature-controlled acceptance criterion to balance exploration and exploitation.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst)\n\n    # Select a base solution with high potential for improvement\n    base_solution, _ = max(archive, key=lambda x: (x[1][0] + x[1][1]) / (np.sum(weight_lst[x[0] == 1]) + 1e-6))\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 1: Adaptive cluster-based mutation\n    # Calculate normalized value-weight ratios for both objectives\n    ratio1 = value1_lst / (weight_lst + 1e-6)\n    ratio2 = value2_lst / (weight_lst + 1e-6)\n    combined_ratio = (ratio1 + ratio2) / 2\n\n    # Cluster items into high, medium, and low value-weight groups\n    sorted_indices = np.argsort(combined_ratio)[::-1]\n    high_cluster = sorted_indices[:len(sorted_indices)//3]\n    medium_cluster = sorted_indices[len(sorted_indices)//3:2*len(sorted_indices)//3]\n    low_cluster = sorted_indices[2*len(sorted_indices)//3:]\n\n    # Select a cluster to perturb based on current solution state\n    if np.sum(new_solution[high_cluster]) < len(high_cluster) * 0.7:  # If high cluster underutilized\n        target_cluster = high_cluster\n    elif np.sum(new_solution[medium_cluster]) < len(medium_cluster) * 0.5:  # If medium cluster underutilized\n        target_cluster = medium_cluster\n    else:\n        target_cluster = low_cluster\n\n    # Perturb the selected cluster\n    for idx in target_cluster:\n        # With probability based on current state and value-weight ratio\n        prob = (combined_ratio[idx] * (1 - new_solution[idx]) * 0.8 +\n                combined_ratio[idx] * new_solution[idx] * 0.2)\n        if random.random() < prob:\n            if new_solution[idx] == 0 and remaining_capacity >= weight_lst[idx]:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n            elif new_solution[idx] == 1:\n                new_solution[idx] = 0\n                remaining_capacity += weight_lst[idx]\n\n    # Step 2: Multi-objective simulated annealing\n    temp = 1.0  # Initial temperature\n    cooling_rate = 0.95\n\n    for _ in range(5):\n        # Generate a candidate neighbor by flipping a random item\n        candidate_idx = random.randint(0, len(weight_lst) - 1)\n        candidate_solution = new_solution.copy()\n\n        if candidate_solution[candidate_idx] == 0 and remaining_capacity >= weight_lst[candidate_idx]:\n            candidate_solution[candidate_idx] = 1\n            candidate_weight = current_weight + weight_lst[candidate_idx]\n        elif candidate_solution[candidate_idx] == 1:\n            candidate_solution[candidate_idx] = 0\n            candidate_weight = current_weight - weight_lst[candidate_idx]\n        else:\n            continue\n\n        # Calculate objective values for candidate\n        candidate_value1 = np.sum(value1_lst[candidate_solution == 1])\n        candidate_value2 = np.sum(value2_lst[candidate_solution == 1])\n\n        # Calculate objective values for current solution\n        current_value1 = np.sum(value1_lst[new_solution == 1])\n        current_value2 = np.sum(value2_lst[new_solution == 1])\n\n        # Acceptance criterion (simulated annealing)\n        if (candidate_weight <= capacity and\n            ((candidate_value1 > current_value1 and candidate_value2 >= current_value2) or\n             (candidate_value1 >= current_value1 and candidate_value2 > current_value2) or\n             (random.random() < np.exp((candidate_value1 + candidate_value2 - current_value1 - current_value2) / temp)))):\n            new_solution = candidate_solution\n            current_weight = candidate_weight\n            remaining_capacity = capacity - current_weight\n\n        temp *= cooling_rate\n\n    return new_solution\n\n",
        "score": [
            -0.7347849809740947,
            3.3702951073646545
        ]
    },
    {
        "algorithm": "{The heuristic selects a promising solution from the archive based on a weighted random choice favoring solutions with higher objective values, then applies a hybrid local search operator that combines element-wise mutation with a greedy insertion of high-value items to generate a feasible neighbor solution.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with weighted random choice (higher objectives have higher probability)\n    objectives = np.array([obj for (sol, obj) in archive])\n    weights = objectives[:, 0] + objectives[:, 1]  # Sum of both objectives as weights\n    weights = weights / np.sum(weights)  # Normalize to probabilities\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: element-wise flip with probability and greedy insertion\n    for i in range(len(new_solution)):\n        if np.random.rand() < 0.2:  # Flip with 20% probability\n            if new_solution[i] == 1:\n                new_solution[i] = 0\n            else:\n                # Check if adding the item exceeds capacity\n                current_weight = np.sum(weight_lst[new_solution == 1])\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n\n    # Greedy insertion of high-value items not in the solution\n    remaining_items = np.where(new_solution == 0)[0]\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Sort remaining items by combined value (value1 + value2) in descending order\n    combined_values = value1_lst + value2_lst\n    sorted_items = sorted(remaining_items, key=lambda x: -combined_values[x])\n\n    for i in sorted_items:\n        if current_weight + weight_lst[i] <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.4055213825643438,
            2.4868115186691284
        ]
    },
    {
        "algorithm": "{A novel hybrid local search strategy combines adaptive item swapping with probabilistic diversification, where items are selected based on their marginal contribution to both objectives, ensuring feasibility while promoting exploration of high-potential regions in the solution space.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate total weight of each solution\n    solution_weights = [np.sum(weight_lst * sol[0]) for sol in archive]\n    feasible_solutions = [(sol, obj, sw) for (sol, obj), sw in zip(archive, solution_weights) if sw <= capacity]\n\n    if not feasible_solutions:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select the solution with the highest sum of normalized objectives\n    objectives = np.array([obj for (_, obj, _) in feasible_solutions])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    scores = np.sum(normalized_obj, axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution, base_obj, base_weight = feasible_solutions[selected_idx]\n\n    # Generate a neighbor solution\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Adaptive item selection based on marginal contribution\n    candidates = []\n    for i in range(n_items):\n        if new_solution[i] == 1:\n            # Consider removing item i\n            new_weight = base_weight - weight_lst[i]\n            if new_weight <= capacity:\n                candidates.append((i, -1, new_weight))\n        else:\n            # Consider adding item i\n            new_weight = base_weight + weight_lst[i]\n            if new_weight <= capacity:\n                candidates.append((i, 1, new_weight))\n\n    if not candidates:\n        # No feasible moves, return base solution\n        return base_solution\n\n    # Select item with highest marginal contribution to both objectives\n    best_item = None\n    best_score = -float('inf')\n    for i, delta, new_weight in candidates:\n        if delta == -1:\n            # Removing item i\n            contrib1 = -value1_lst[i]\n            contrib2 = -value2_lst[i]\n        else:\n            # Adding item i\n            contrib1 = value1_lst[i]\n            contrib2 = value2_lst[i]\n\n        # Score based on both objectives\n        score = contrib1 + contrib2\n        if score > best_score:\n            best_score = score\n            best_item = i\n\n    if best_item is not None:\n        new_solution[best_item] = 1 - new_solution[best_item]\n\n    # Probabilistic diversification: with 20% chance, perform a random feasible move\n    if random.random() < 0.2:\n        random.shuffle(candidates)\n        for i, delta, new_weight in candidates:\n            if new_weight <= capacity:\n                new_solution[i] = 1 - new_solution[i]\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.5245835063734805,
            3.0432948768138885
        ]
    },
    {
        "algorithm": "{The algorithm selects a promising solution from the archive by prioritizing those with high Pareto dominance and then applies a novel multi-objective local search that combines item grouping and targeted swaps, ensuring feasibility through a dynamic capacity adjustment mechanism.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution using Pareto dominance and crowding distance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate Pareto dominance counts\n    dominance = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j and (objectives[i][0] >= objectives[j][0] and objectives[i][1] >= objectives[j][1]):\n                if objectives[i][0] > objectives[j][0] or objectives[i][1] > objectives[j][1]:\n                    dominance[i] += 1\n\n    # Combine Pareto dominance and crowding distance for selection\n    if np.max(dominance) > 0:\n        selected_idx = np.argmax(dominance)\n    else:\n        # If no dominant solutions, select the one with highest sum of normalized objectives\n        normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n        scores = np.sum(normalized_objectives, axis=1)\n        selected_idx = np.argmax(scores)\n\n    base_solution = solutions[selected_idx].copy()\n\n    # Multi-objective local search: item grouping and targeted swaps\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Group items by similar value ratios\n    value_ratios = value1_lst / (value2_lst + 1e-6)\n    sorted_indices = np.argsort(value_ratios)\n\n    # Perform targeted swaps between groups\n    for i in range(0, len(sorted_indices), max(1, len(sorted_indices)//10)):\n        group = sorted_indices[i:i+max(1, len(sorted_indices)//10)]\n        in_group = [idx for idx in group if new_solution[idx] == 1]\n        out_group = [idx for idx in group if new_solution[idx] == 0]\n\n        if len(in_group) > 0 and len(out_group) > 0:\n            # Try to swap one item in and one out\n            in_idx = random.choice(in_group)\n            out_idx = random.choice(out_group)\n\n            if current_weight - weight_lst[in_idx] + weight_lst[out_idx] <= capacity:\n                new_solution[in_idx] = 0\n                new_solution[out_idx] = 1\n                current_weight = current_weight - weight_lst[in_idx] + weight_lst[out_idx]\n\n    # Dynamic capacity adjustment if still feasible\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        items_in_solution = np.where(new_solution == 1)[0]\n        np.random.shuffle(items_in_solution)\n\n        for idx in items_in_solution:\n            if excess <= 0:\n                break\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.22071093360491673,
            2.2224737405776978
        ]
    },
    {
        "algorithm": "{The algorithm selects a promising solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a hybrid local search that combines random item swaps and targeted flips to explore the solution space while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    scores = np.sum(normalized_objectives, axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: random swaps and targeted flips\n    new_solution = base_solution.copy()\n    items = np.where(new_solution == 1)[0]\n    non_items = np.where(new_solution == 0)[0]\n\n    # Randomly select a subset of items to flip\n    if len(items) > 0:\n        flip_indices = random.sample(list(items), min(3, len(items)))\n        for idx in flip_indices:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Randomly add items if capacity allows\n    random.shuffle(non_items)\n    for idx in non_items:\n        if current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Ensure feasibility (fallback if needed)\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_solution = np.where(new_solution == 1)[0]\n        if len(items_in_solution) > 0:\n            for idx in items_in_solution:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.35682452083347693,
            3.1650768518447876
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for multi-objective improvement, then applies a novel hybrid local search that combines adaptive item selection with a dynamic neighborhood exploration strategy, ensuring feasibility through weight-aware perturbations and objective-driven diversification.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst)\n\n    # Select a base solution with high potential for improvement\n    base_solution, _ = max(archive, key=lambda x: (x[1][0] + x[1][1]) / (np.sum(weight_lst[x[0] == 1]) + 1e-6))\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and remaining capacity\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Hybrid local search: adaptive item selection with dynamic neighborhood\n    for _ in range(5):\n        # Calculate dynamic objective weights based on current solution\n        obj1_weight = 1.0 if current_weight < capacity * 0.5 else 0.7\n        obj2_weight = 1.0 if current_weight < capacity * 0.5 else 0.7\n\n        # Calculate weighted marginal gains\n        weighted_gain1 = value1_lst * obj1_weight / (weight_lst + 1e-6)\n        weighted_gain2 = value2_lst * obj2_weight / (weight_lst + 1e-6)\n        combined_gain = weighted_gain1 + weighted_gain2\n\n        # Select items to flip with probability proportional to gain\n        flip_probs = combined_gain * (1 - new_solution)  # Prefer adding items\n        flip_probs[new_solution == 1] = combined_gain[new_solution == 1] * 0.3  # Lower chance to remove\n\n        if np.sum(flip_probs) > 0:\n            flip_probs = flip_probs / np.sum(flip_probs)\n            candidate_idx = np.random.choice(len(weight_lst), p=flip_probs)\n\n            if new_solution[candidate_idx] == 0 and remaining_capacity >= weight_lst[candidate_idx]:\n                new_solution[candidate_idx] = 1\n                remaining_capacity -= weight_lst[candidate_idx]\n                current_weight += weight_lst[candidate_idx]\n            elif new_solution[candidate_idx] == 1:\n                new_solution[candidate_idx] = 0\n                remaining_capacity += weight_lst[candidate_idx]\n                current_weight -= weight_lst[candidate_idx]\n\n    # Dynamic neighborhood exploration\n    for _ in range(3):\n        # Select a random subset of items to flip\n        subset_size = min(3, len(weight_lst))\n        candidate_indices = np.random.choice(len(weight_lst), size=subset_size, replace=False)\n\n        for idx in candidate_indices:\n            if new_solution[idx] == 0 and remaining_capacity >= weight_lst[idx]:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n                current_weight += weight_lst[idx]\n            elif new_solution[idx] == 1:\n                new_solution[idx] = 0\n                remaining_capacity += weight_lst[idx]\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3503873365417642,
            4.950888574123383
        ]
    },
    {
        "algorithm": "{The algorithm selects a promising solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search strategy that combines weight-balanced flips and objective-driven additions to explore the solution space while ensuring feasibility through adaptive capacity management.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    scores = np.sum(normalized_objectives, axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight and remaining capacity\n    current_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Novel local search strategy: weight-balanced flips and objective-driven additions\n    new_solution = base_solution.copy()\n    items = np.where(new_solution == 1)[0]\n    non_items = np.where(new_solution == 0)[0]\n\n    # Calculate value-to-weight ratios for non-included items\n    if len(non_items) > 0:\n        value1_ratio = value1_lst[non_items] / weight_lst[non_items]\n        value2_ratio = value2_lst[non_items] / weight_lst[non_items]\n\n        # Select top 5 items with highest combined value-to-weight ratios\n        combined_ratio = value1_ratio + value2_ratio\n        top_indices = np.argsort(combined_ratio)[-min(5, len(combined_ratio)):][::-1]\n        for idx in top_indices:\n            item_idx = non_items[idx]\n            if weight_lst[item_idx] <= remaining_capacity:\n                new_solution[item_idx] = 1\n                remaining_capacity -= weight_lst[item_idx]\n\n    # Adaptive capacity management: remove items with lowest ratio if still over capacity\n    if remaining_capacity < 0:\n        items_in_solution = np.where(new_solution == 1)[0]\n        if len(items_in_solution) > 0:\n            value1_ratio = value1_lst[items_in_solution] / weight_lst[items_in_solution]\n            value2_ratio = value2_lst[items_in_solution] / weight_lst[items_in_solution]\n            combined_ratio = value1_ratio + value2_ratio\n            sorted_indices = np.argsort(combined_ratio)\n\n            for idx in sorted_indices:\n                item_idx = items_in_solution[idx]\n                new_solution[item_idx] = 0\n                remaining_capacity += weight_lst[item_idx]\n                if remaining_capacity >= 0:\n                    break\n\n    # Weight-balanced flips: randomly flip 2 items with weight close to remaining capacity\n    if len(items) > 0:\n        flip_candidates = [i for i in items if abs(weight_lst[i] - remaining_capacity) < 0.1 * capacity]\n        if len(flip_candidates) > 0:\n            flip_indices = random.sample(flip_candidates, min(2, len(flip_candidates)))\n            for idx in flip_indices:\n                new_solution[idx] = 0\n                remaining_capacity += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.887089948480458,
            1.368062973022461
        ]
    }
]