[
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a diversity-aware objective ranking and applies a hybrid local search that combines value-weighted item swaps with adaptive capacity-sensitive perturbations to explore high-potential regions while ensuring feasibility through dynamic weight adjustment.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with diverse objective ranking\n    objectives = np.array([obj for _, obj in archive])\n    ranks = np.argsort(objectives[:, 0]) + np.argsort(objectives[:, 1])\n    selected_idx = np.argmin(ranks) if np.random.rand() < 0.6 else np.argmax(ranks)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: value-weighted swaps and adaptive perturbations\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Value-weighted item swaps\n    if len(items_in) > 0 and len(items_out) > 0:\n        swap_scores = (value1_lst[items_in] + value2_lst[items_in]) / (weight_lst[items_in] + 1e-6)\n        best_swap = np.argmax(swap_scores)\n        candidate_new = np.random.choice(items_out)\n\n        if weight_lst[candidate_new] <= weight_lst[items_in[best_swap]]:\n            delta_weight = weight_lst[candidate_new] - weight_lst[items_in[best_swap]]\n            if current_weight + delta_weight <= capacity:\n                new_solution[items_in[best_swap]] = 0\n                new_solution[candidate_new] = 1\n                current_weight += delta_weight\n\n    # Adaptive capacity-sensitive perturbations\n    if np.random.rand() < 0.3:\n        if current_weight < 0.8 * capacity and len(items_out) > 0:\n            candidate = np.random.choice(items_out)\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n        elif current_weight > 0.6 * capacity and len(items_in) > 0:\n            candidate = np.random.choice(items_in)\n            new_solution[candidate] = 0\n\n    # Ensure feasibility through dynamic adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        removal_order = np.argsort((value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6))\n        for idx in items_in_new[removal_order]:\n            if excess <= 0:\n                break\n            new_solution[idx] = 0\n            excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.898773143786561,
            0.7867339849472046
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a Pareto-frontier proximity score and applies a hybrid local search that combines objective-specific item additions/removals with dynamic weight balancing to explore the solution space efficiently while maintaining feasibility through constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution based on Pareto-frontier proximity\n    objectives = np.array([obj for _, obj in archive])\n    pareto_scores = np.max(objectives, axis=0) - objectives\n    selected_idx = np.argmin(np.sum(pareto_scores, axis=1))\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: objective-specific operations with dynamic balancing\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Objective 1 focused operation\n    if len(items_out) > 0:\n        candidates = items_out[np.argsort(value1_lst[items_out])[-min(5, len(items_out)):]]\n        for candidate in candidates:\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n                current_weight += weight_lst[candidate]\n                break\n\n    # Objective 2 focused operation\n    if len(items_out) > 0:\n        candidates = items_out[np.argsort(value2_lst[items_out])[-min(5, len(items_out)):]]\n        for candidate in candidates:\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n                current_weight += weight_lst[candidate]\n                break\n\n    # Dynamic weight balancing\n    if len(items_in) > 0 and current_weight > 0.7 * capacity:\n        candidates = items_in[np.argsort(weight_lst[items_in])[:min(3, len(items_in))]]\n        for candidate in candidates:\n            new_solution[candidate] = 0\n            current_weight -= weight_lst[candidate]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        removal_order = np.argsort(weight_lst[items_in_new])\n        for idx in items_in_new[removal_order]:\n            if excess <= 0:\n                break\n            new_solution[idx] = 0\n            excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.977883289799175,
            0.8179505467414856
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search that combines adaptive item grouping with a biased random walk, where items are first clustered by their marginal gain ratios, and then explored within these clusters to identify high-potential regions for improvement while ensuring feasibility through weight-constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives with weight consideration)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    normalized_weights = (weights - np.min(weights)) / (np.max(weights) - np.min(weights) + 1e-6)\n    scores = 0.7 * np.sum(normalized_objectives, axis=1) - 0.3 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item grouping and biased random walk\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate marginal gain ratios for items not in solution with weight consideration\n    if len(items_out) > 0:\n        ratio1 = value1_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        ratio2 = value2_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        combined_ratio = ratio1 + ratio2\n        weight_ratio = combined_ratio / (weight_lst[items_out] + 1e-6)\n\n        # Cluster items by weight-adjusted marginal gain ratio\n        sorted_indices = np.argsort(weight_ratio)[::-1]\n        top_cluster = items_out[sorted_indices[:max(1, len(items_out)//2)]]\n\n        # Randomly select from top cluster with higher probability\n        if len(top_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(top_cluster)\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Biased random walk: remove low-contribution items with weight consideration\n    if len(items_in) > 0:\n        # Calculate contribution of each item in solution with weight consideration\n        contribution1 = value1_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        contribution2 = value2_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        combined_contribution = contribution1 + contribution2\n        weight_contribution = combined_contribution / (weight_lst[items_in] + 1e-6)\n\n        # Remove items with lowest weight-adjusted contribution\n        sorted_indices = np.argsort(weight_contribution)\n        bottom_cluster = items_in[sorted_indices[:max(1, len(items_in)//4)]]\n\n        if len(bottom_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(bottom_cluster)\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            # Remove items with smallest weight to contribution ratio\n            contribution_ratio = (value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6)\n            sorted_indices = np.argsort(contribution_ratio)\n            for idx in items_in_new[sorted_indices]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9929539344021545,
            3.763106882572174
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive by prioritizing those with high combined objective values and low weight utilization, then applies a novel local search that combines adaptive item selection with a diversity-aware perturbation strategy, where items are first clustered by their marginal gain ratios, and then explored through a dynamic substitution process that considers both objective improvements and solution diversity while maintaining feasibility through weight-constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution based on combined objective and weight utilization\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    combined_objectives = objectives[:, 0] + objectives[:, 1]\n    normalized_weights = weights / capacity\n    scores = 0.6 * combined_objectives - 0.4 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item clustering and diversity-aware perturbation\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate marginal gain ratios with diversity consideration\n    if len(items_out) > 0:\n        marginal_gain1 = value1_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        marginal_gain2 = value2_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        combined_gain = marginal_gain1 + marginal_gain2\n        diversity_factor = np.abs(value1_lst[items_out] - value2_lst[items_out]) / (weight_lst[items_out] + 1e-6)\n        weighted_gain = 0.7 * combined_gain + 0.3 * diversity_factor\n\n        # Cluster items by weighted gain\n        sorted_indices = np.argsort(weighted_gain)[::-1]\n        top_cluster = items_out[sorted_indices[:max(1, len(items_out)//3)]]\n\n        # Dynamic substitution process\n        if len(top_cluster) > 0:\n            for _ in range(2):\n                candidate_idx = np.random.choice(top_cluster)\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    # Find least impactful item to remove if needed\n                    if len(items_in) > 0:\n                        impact_scores = (value1_lst[items_in] + value2_lst[items_in]) / (weight_lst[items_in] + 1e-6)\n                        remove_idx = items_in[np.argmin(impact_scores)]\n                        new_solution[remove_idx] = 0\n                        current_weight -= weight_lst[remove_idx]\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Diversity-aware removal of low-contribution items\n    if len(items_in) > 0:\n        contribution1 = value1_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        contribution2 = value2_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        combined_contribution = contribution1 + contribution2\n        diversity_contribution = np.abs(value1_lst[items_in] - value2_lst[items_in]) / (weight_lst[items_in] + 1e-6)\n        weighted_contribution = 0.6 * combined_contribution + 0.4 * diversity_contribution\n\n        # Remove items with lowest weighted contribution\n        sorted_indices = np.argsort(weighted_contribution)\n        bottom_cluster = items_in[sorted_indices[:max(1, len(items_in)//4)]]\n\n        if len(bottom_cluster) > 0:\n            for _ in range(2):\n                candidate_idx = np.random.choice(bottom_cluster)\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            # Remove items with smallest contribution to weight ratio\n            contribution_ratio = (value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6)\n            sorted_indices = np.argsort(contribution_ratio)\n            for idx in items_in_new[sorted_indices]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.969205196766664,
            2.8865227103233337
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a weighted combination of objective values and weight utilization, then applies a novel local search that uses dynamic item prioritization and probabilistic perturbation to explore high-potential regions while maintaining feasibility through adaptive weight constraints.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (weighted combination of objectives and weight utilization)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_weights = weights / capacity\n    weighted_scores = 0.6 * objectives[:, 0] + 0.4 * objectives[:, 1] - 0.3 * normalized_weights\n    selected_idx = np.argmax(weighted_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dynamic item prioritization and probabilistic perturbation\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate dynamic priorities for items not in solution\n    if len(items_out) > 0:\n        priority_scores = (value1_lst[items_out] + value2_lst[items_out]) / (weight_lst[items_out] + 1e-6)\n        sorted_indices = np.argsort(priority_scores)[::-1]\n        top_items = items_out[sorted_indices[:max(1, len(items_out)//4)]]\n\n        # Add items with probability proportional to their priority\n        for idx in top_items:\n            if np.random.rand() < 0.7 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Probabilistic removal of low-priority items\n    if len(items_in) > 0:\n        removal_scores = (value1_lst[items_in] + value2_lst[items_in]) / (weight_lst[items_in] + 1e-6)\n        sorted_indices = np.argsort(removal_scores)\n        bottom_items = items_in[sorted_indices[:max(1, len(items_in)//3)]]\n\n        for idx in bottom_items:\n            if np.random.rand() < 0.5:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Adaptive weight constraint enforcement\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            removal_order = np.argsort((value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6))\n            for idx in items_in_new[removal_order]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.951269370000086,
            2.5577997267246246
        ]
    },
    {
        "algorithm": "{The algorithm selects a promising solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search strategy that combines weight-balanced flips and objective-driven additions to explore the solution space while ensuring feasibility through adaptive capacity management.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution using a hybrid selection criterion (objective dominance and weight balance)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_weights = weights / capacity\n    scores = (objectives[:, 0] + objectives[:, 1]) / (1 + normalized_weights)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight and remaining capacity\n    current_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Novel local search strategy: objective-driven flips and weight-balanced additions\n    new_solution = base_solution.copy()\n    items = np.where(new_solution == 1)[0]\n    non_items = np.where(new_solution == 0)[0]\n\n    # Calculate value-to-weight ratios for non-included items\n    if len(non_items) > 0:\n        value1_ratio = value1_lst[non_items] / weight_lst[non_items]\n        value2_ratio = value2_lst[non_items] / weight_lst[non_items]\n\n        # Select top 3 items with highest combined value-to-weight ratios\n        combined_ratio = value1_ratio + value2_ratio\n        top_indices = np.argsort(combined_ratio)[-min(3, len(combined_ratio)):][::-1]\n        for idx in top_indices:\n            item_idx = non_items[idx]\n            if weight_lst[item_idx] <= remaining_capacity:\n                new_solution[item_idx] = 1\n                remaining_capacity -= weight_lst[item_idx]\n\n    # Adaptive capacity management: remove items with lowest ratio if still over capacity\n    if remaining_capacity < 0:\n        items_in_solution = np.where(new_solution == 1)[0]\n        if len(items_in_solution) > 0:\n            value1_ratio = value1_lst[items_in_solution] / weight_lst[items_in_solution]\n            value2_ratio = value2_lst[items_in_solution] / weight_lst[items_in_solution]\n            combined_ratio = value1_ratio + value2_ratio\n            sorted_indices = np.argsort(combined_ratio)\n\n            for idx in sorted_indices:\n                item_idx = items_in_solution[idx]\n                new_solution[item_idx] = 0\n                remaining_capacity += weight_lst[item_idx]\n                if remaining_capacity >= 0:\n                    break\n\n    # Weight-balanced flips: flip items that create a balanced weight distribution\n    if len(items) > 0:\n        flip_candidates = [i for i in items if abs(weight_lst[i] - remaining_capacity * 0.3) < 0.15 * capacity]\n        if len(flip_candidates) > 0:\n            flip_indices = random.sample(flip_candidates, min(1, len(flip_candidates)))\n            for idx in flip_indices:\n                new_solution[idx] = 0\n                remaining_capacity += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.95070882303056,
            2.1341150104999542
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its objective diversity and weight distribution, then applies a correlation-aware local search that explores item swaps by considering both profit ratios and weight efficiency, ensuring feasibility through iterative adjustments and diversity-aware capacity management.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high diversity and weight distribution\n    objectives = np.array([obj for _, obj in archive])\n    diversity_scores = np.std(objectives, axis=0).mean()\n    weight_distribution = np.sum(weight_lst * archive[0][0]) / capacity\n    combined_scores = diversity_scores * (1 + weight_distribution)\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Correlation-aware local search: explore item swaps\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate value-to-weight ratios and diversity weights\n    value1_ratio = value1_lst / weight_lst\n    value2_ratio = value2_lst / weight_lst\n    diversity_weights = np.abs(value1_ratio - value2_ratio)\n    weighted_ratios = (value1_ratio + value2_ratio) * (1 + diversity_weights)\n    sorted_indices = np.argsort(weighted_ratios)[::-1]\n\n    # Explore swaps by considering both high-ratio and diversity\n    for i in range(min(10, n_items)):\n        item_idx = sorted_indices[i]\n        if new_solution[item_idx] == 0 and current_weight + weight_lst[item_idx] <= capacity:\n            new_solution[item_idx] = 1\n            current_weight += weight_lst[item_idx]\n        elif new_solution[item_idx] == 1:\n            # Check if swapping improves diversity\n            if np.sum(weight_lst * new_solution) - weight_lst[item_idx] <= capacity:\n                new_solution[item_idx] = 0\n                current_weight -= weight_lst[item_idx]\n\n    # Diversity-aware capacity management\n    if current_weight > capacity:\n        # Remove items with lowest weighted ratio until feasible\n        items_in_solution = np.where(new_solution == 1)[0]\n        sorted_items = items_in_solution[np.argsort(weighted_ratios[items_in_solution])]\n        for item_idx in sorted_items:\n            if current_weight <= capacity:\n                break\n            new_solution[item_idx] = 0\n            current_weight -= weight_lst[item_idx]\n\n    # Ensure at least one item remains if solution is not empty\n    if np.sum(new_solution) == 0 and n_items > 0:\n        # Add the item with highest weighted ratio\n        best_item = sorted_indices[0]\n        if weight_lst[best_item] <= capacity:\n            new_solution[best_item] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.9216994772468861,
            1.1824100613594055
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its dominance and objective correlation, then applies a novel value-weighted local search that explores item exchanges by considering both profit ratios and weight distribution, ensuring feasibility through iterative adjustments and correlation-aware capacity management.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high dominance and objective correlation\n    objectives = np.array([obj for _, obj in archive])\n    correlation = np.corrcoef(objectives.T)[0, 1]\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    dominance_scores = np.max(normalized_objectives, axis=1)\n    combined_scores = dominance_scores * (1 + correlation)\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Value-weighted local search: explore item exchanges\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate value-to-weight ratios and correlation weights\n    value1_ratio = value1_lst / weight_lst\n    value2_ratio = value2_lst / weight_lst\n    correlation_weights = np.abs(value1_ratio - value2_ratio)\n    weighted_ratios = (value1_ratio + value2_ratio) * (1 + correlation_weights)\n    sorted_indices = np.argsort(weighted_ratios)[::-1]\n\n    # Explore exchanges by considering both high-ratio and correlation\n    for i in range(min(10, n_items)):\n        item_idx = sorted_indices[i]\n        if new_solution[item_idx] == 0 and current_weight + weight_lst[item_idx] <= capacity:\n            new_solution[item_idx] = 1\n            current_weight += weight_lst[item_idx]\n        elif new_solution[item_idx] == 1:\n            # Check if removing improves correlation\n            if np.sum(weight_lst * new_solution) - weight_lst[item_idx] <= capacity:\n                new_solution[item_idx] = 0\n                current_weight -= weight_lst[item_idx]\n\n    # Correlation-aware capacity management\n    if current_weight > capacity:\n        # Remove items with lowest weighted ratio until feasible\n        items_in_solution = np.where(new_solution == 1)[0]\n        sorted_items = items_in_solution[np.argsort(weighted_ratios[items_in_solution])]\n        for item_idx in sorted_items:\n            if current_weight <= capacity:\n                break\n            new_solution[item_idx] = 0\n            current_weight -= weight_lst[item_idx]\n\n    # Ensure at least one item remains if solution is not empty\n    if np.sum(new_solution) == 0 and n_items > 0:\n        # Add the item with highest weighted ratio\n        best_item = sorted_indices[0]\n        if weight_lst[best_item] <= capacity:\n            new_solution[best_item] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.9538587956046637,
            2.6659638583660126
        ]
    },
    {
        "algorithm": "{This algorithm prioritizes solutions with high value diversity and low weight utilization, then applies a hybrid local search combining value-driven substitutions and weight-balanced perturbations to explore the solution space while maintaining feasibility through dynamic capacity adjustment and probabilistic item swaps.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest normalized value diversity\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    diversity_scores = np.abs(normalized_objectives[:, 0] - normalized_objectives[:, 1])\n    selected_idx = np.argmax(diversity_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current metrics\n    current_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - current_weight\n    included_items = np.where(base_solution == 1)[0]\n    excluded_items = np.where(base_solution == 0)[0]\n\n    # Hybrid local search\n    new_solution = base_solution.copy()\n\n    # Value-driven substitution: replace worst items with best available\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate value ratios for included items\n        included_v1_ratio = value1_lst[included_items] / weight_lst[included_items]\n        included_v2_ratio = value2_lst[included_items] / weight_lst[included_items]\n        worst_item_idx = np.argmin(included_v1_ratio + included_v2_ratio)\n        worst_item = included_items[worst_item_idx]\n\n        # Find best available item to replace\n        available_v1_ratio = value1_lst[excluded_items] / weight_lst[excluded_items]\n        available_v2_ratio = value2_lst[excluded_items] / weight_lst[excluded_items]\n        best_candidate_idx = np.argmax(available_v1_ratio + available_v2_ratio)\n        best_candidate = excluded_items[best_candidate_idx]\n\n        # Perform substitution if feasible\n        if weight_lst[best_candidate] - weight_lst[worst_item] <= remaining_capacity:\n            new_solution[worst_item] = 0\n            new_solution[best_candidate] = 1\n            remaining_capacity += weight_lst[worst_item] - weight_lst[best_candidate]\n\n    # Weight-balanced perturbations: probabilistic item swaps\n    if len(included_items) > 1 and len(excluded_items) > 0:\n        # Randomly select items for potential swap\n        swap_item_in = random.choice(included_items)\n        swap_item_out = random.choice(excluded_items)\n\n        # Calculate potential new weight\n        new_weight = current_weight - weight_lst[swap_item_in] + weight_lst[swap_item_out]\n\n        # Perform swap if feasible\n        if new_weight <= capacity:\n            new_solution[swap_item_in] = 0\n            new_solution[swap_item_out] = 1\n\n    # Dynamic capacity adjustment: remove random item if still over capacity\n    if np.sum(weight_lst * new_solution) > capacity:\n        items_to_remove = np.where(new_solution == 1)[0]\n        if len(items_to_remove) > 0:\n            item_to_remove = random.choice(items_to_remove)\n            new_solution[item_to_remove] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.7297830675401605,
            1.1105536222457886
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a combination of objective dominance and diversity, then applies a novel local search that uses adaptive item grouping and probabilistic swaps to explore high-potential regions while maintaining feasibility through dynamic capacity constraints.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution based on objective dominance and diversity\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.zeros(len(archive))\n    for i in range(2):\n        sorted_idx = np.argsort(objectives[:, i])\n        crowding_distances[sorted_idx[0]] = np.inf\n        crowding_distances[sorted_idx[-1]] = np.inf\n        for j in range(1, len(archive)-1):\n            crowding_distances[sorted_idx[j]] += (objectives[sorted_idx[j+1], i] - objectives[sorted_idx[j-1], i]) / (objectives[sorted_idx[-1], i] - objectives[sorted_idx[0], i] + 1e-6)\n\n    combined_scores = 0.7 * objectives[:, 0] + 0.3 * objectives[:, 1] + 0.2 * crowding_distances\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item grouping and probabilistic swaps\n    new_solution = base_solution.copy()\n    items = np.arange(len(weight_lst))\n    groups = np.zeros(len(items), dtype=int)\n\n    # Create groups based on value/weight ratios\n    ratio1 = value1_lst / (weight_lst + 1e-6)\n    ratio2 = value2_lst / (weight_lst + 1e-6)\n    combined_ratio = 0.6 * ratio1 + 0.4 * ratio2\n\n    # Group items into 4 categories based on combined ratio\n    percentiles = np.percentile(combined_ratio, [33, 66])\n    groups[(combined_ratio <= percentiles[0])] = 0\n    groups[(combined_ratio > percentiles[0]) & (combined_ratio <= percentiles[1])] = 1\n    groups[(combined_ratio > percentiles[1])] = 2\n\n    # Perform probabilistic swaps within groups\n    for group in range(3):\n        group_items = items[groups == group]\n        in_group = group_items[new_solution[group_items] == 1]\n        out_group = group_items[new_solution[group_items] == 0]\n\n        if len(in_group) > 0 and len(out_group) > 0:\n            # Swap with probability based on group quality\n            swap_prob = 0.3 + 0.2 * (2 - group)  # Higher probability for better groups\n            if np.random.rand() < swap_prob:\n                # Select random items to swap\n                num_swaps = min(2, len(in_group), len(out_group))\n                swap_in = np.random.choice(in_group, size=num_swaps, replace=False)\n                swap_out = np.random.choice(out_group, size=num_swaps, replace=False)\n\n                # Check feasibility before swapping\n                total_add = np.sum(weight_lst[swap_out])\n                total_remove = np.sum(weight_lst[swap_in])\n                net_change = total_add - total_remove\n\n                if current_weight + net_change <= capacity:\n                    new_solution[swap_in] = 0\n                    new_solution[swap_out] = 1\n                    current_weight += net_change\n\n    # Dynamic capacity adjustment for overfilled solutions\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in = np.where(new_solution == 1)[0]\n        if len(items_in) > 0:\n            # Remove items in order of lowest combined ratio\n            removal_order = np.argsort(combined_ratio[items_in])\n            for idx in items_in[removal_order]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9773377334378451,
            7.768424540758133
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a diversity-aware objective ranking and applies a hybrid local search that combines value-weighted item swaps with adaptive capacity-sensitive perturbations to explore high-potential regions while ensuring feasibility through dynamic weight adjustment.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with diverse objective ranking\n    objectives = np.array([obj for _, obj in archive])\n    ranks = np.argsort(objectives[:, 0]) + np.argsort(objectives[:, 1])\n    selected_idx = np.argmin(ranks) if np.random.rand() < 0.6 else np.argmax(ranks)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: value-weighted swaps and adaptive perturbations\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Value-weighted item swaps\n    if len(items_in) > 0 and len(items_out) > 0:\n        swap_scores = (value1_lst[items_in] + value2_lst[items_in]) / (weight_lst[items_in] + 1e-6)\n        best_swap = np.argmax(swap_scores)\n        candidate_new = np.random.choice(items_out)\n\n        if weight_lst[candidate_new] <= weight_lst[items_in[best_swap]]:\n            delta_weight = weight_lst[candidate_new] - weight_lst[items_in[best_swap]]\n            if current_weight + delta_weight <= capacity:\n                new_solution[items_in[best_swap]] = 0\n                new_solution[candidate_new] = 1\n                current_weight += delta_weight\n\n    # Adaptive capacity-sensitive perturbations\n    if np.random.rand() < 0.3:\n        if current_weight < 0.8 * capacity and len(items_out) > 0:\n            candidate = np.random.choice(items_out)\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n        elif current_weight > 0.6 * capacity and len(items_in) > 0:\n            candidate = np.random.choice(items_in)\n            new_solution[candidate] = 0\n\n    # Ensure feasibility through dynamic adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        removal_order = np.argsort((value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6))\n        for idx in items_in_new[removal_order]:\n            if excess <= 0:\n                break\n            new_solution[idx] = 0\n            excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.898773143786561,
            0.7867339849472046
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a Pareto-frontier proximity score and applies a hybrid local search that combines objective-specific item additions/removals with dynamic weight balancing to explore the solution space efficiently while maintaining feasibility through constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution based on Pareto-frontier proximity\n    objectives = np.array([obj for _, obj in archive])\n    pareto_scores = np.max(objectives, axis=0) - objectives\n    selected_idx = np.argmin(np.sum(pareto_scores, axis=1))\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: objective-specific operations with dynamic balancing\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Objective 1 focused operation\n    if len(items_out) > 0:\n        candidates = items_out[np.argsort(value1_lst[items_out])[-min(5, len(items_out)):]]\n        for candidate in candidates:\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n                current_weight += weight_lst[candidate]\n                break\n\n    # Objective 2 focused operation\n    if len(items_out) > 0:\n        candidates = items_out[np.argsort(value2_lst[items_out])[-min(5, len(items_out)):]]\n        for candidate in candidates:\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n                current_weight += weight_lst[candidate]\n                break\n\n    # Dynamic weight balancing\n    if len(items_in) > 0 and current_weight > 0.7 * capacity:\n        candidates = items_in[np.argsort(weight_lst[items_in])[:min(3, len(items_in))]]\n        for candidate in candidates:\n            new_solution[candidate] = 0\n            current_weight -= weight_lst[candidate]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        removal_order = np.argsort(weight_lst[items_in_new])\n        for idx in items_in_new[removal_order]:\n            if excess <= 0:\n                break\n            new_solution[idx] = 0\n            excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.977883289799175,
            0.8179505467414856
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search that combines adaptive item grouping with a biased random walk, where items are first clustered by their marginal gain ratios, and then explored within these clusters to identify high-potential regions for improvement while ensuring feasibility through weight-constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives with weight consideration)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    normalized_weights = (weights - np.min(weights)) / (np.max(weights) - np.min(weights) + 1e-6)\n    scores = 0.7 * np.sum(normalized_objectives, axis=1) - 0.3 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item grouping and biased random walk\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate marginal gain ratios for items not in solution with weight consideration\n    if len(items_out) > 0:\n        ratio1 = value1_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        ratio2 = value2_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        combined_ratio = ratio1 + ratio2\n        weight_ratio = combined_ratio / (weight_lst[items_out] + 1e-6)\n\n        # Cluster items by weight-adjusted marginal gain ratio\n        sorted_indices = np.argsort(weight_ratio)[::-1]\n        top_cluster = items_out[sorted_indices[:max(1, len(items_out)//2)]]\n\n        # Randomly select from top cluster with higher probability\n        if len(top_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(top_cluster)\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Biased random walk: remove low-contribution items with weight consideration\n    if len(items_in) > 0:\n        # Calculate contribution of each item in solution with weight consideration\n        contribution1 = value1_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        contribution2 = value2_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        combined_contribution = contribution1 + contribution2\n        weight_contribution = combined_contribution / (weight_lst[items_in] + 1e-6)\n\n        # Remove items with lowest weight-adjusted contribution\n        sorted_indices = np.argsort(weight_contribution)\n        bottom_cluster = items_in[sorted_indices[:max(1, len(items_in)//4)]]\n\n        if len(bottom_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(bottom_cluster)\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            # Remove items with smallest weight to contribution ratio\n            contribution_ratio = (value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6)\n            sorted_indices = np.argsort(contribution_ratio)\n            for idx in items_in_new[sorted_indices]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9929539344021545,
            3.763106882572174
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a diversity-aware objective ranking and applies a hybrid local search that combines value-weighted item swaps with adaptive capacity-sensitive perturbations to explore high-potential regions while ensuring feasibility through dynamic weight adjustment.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with diverse objective ranking\n    objectives = np.array([obj for _, obj in archive])\n    ranks = np.argsort(objectives[:, 0]) + np.argsort(objectives[:, 1])\n    selected_idx = np.argmin(ranks) if np.random.rand() < 0.6 else np.argmax(ranks)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: value-weighted swaps and adaptive perturbations\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Value-weighted item swaps\n    if len(items_in) > 0 and len(items_out) > 0:\n        swap_scores = (value1_lst[items_in] + value2_lst[items_in]) / (weight_lst[items_in] + 1e-6)\n        best_swap = np.argmax(swap_scores)\n        candidate_new = np.random.choice(items_out)\n\n        if weight_lst[candidate_new] <= weight_lst[items_in[best_swap]]:\n            delta_weight = weight_lst[candidate_new] - weight_lst[items_in[best_swap]]\n            if current_weight + delta_weight <= capacity:\n                new_solution[items_in[best_swap]] = 0\n                new_solution[candidate_new] = 1\n                current_weight += delta_weight\n\n    # Adaptive capacity-sensitive perturbations\n    if np.random.rand() < 0.3:\n        if current_weight < 0.8 * capacity and len(items_out) > 0:\n            candidate = np.random.choice(items_out)\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n        elif current_weight > 0.6 * capacity and len(items_in) > 0:\n            candidate = np.random.choice(items_in)\n            new_solution[candidate] = 0\n\n    # Ensure feasibility through dynamic adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        removal_order = np.argsort((value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6))\n        for idx in items_in_new[removal_order]:\n            if excess <= 0:\n                break\n            new_solution[idx] = 0\n            excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.898773143786561,
            0.7867339849472046
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search that combines adaptive item grouping with a biased random walk, where items are first clustered by their marginal gain ratios, and then explored within these clusters to identify high-potential regions for improvement while ensuring feasibility through weight-constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives with weight consideration)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    normalized_weights = (weights - np.min(weights)) / (np.max(weights) - np.min(weights) + 1e-6)\n    scores = 0.7 * np.sum(normalized_objectives, axis=1) - 0.3 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item grouping and biased random walk\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate marginal gain ratios for items not in solution with weight consideration\n    if len(items_out) > 0:\n        ratio1 = value1_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        ratio2 = value2_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        combined_ratio = ratio1 + ratio2\n        weight_ratio = combined_ratio / (weight_lst[items_out] + 1e-6)\n\n        # Cluster items by weight-adjusted marginal gain ratio\n        sorted_indices = np.argsort(weight_ratio)[::-1]\n        top_cluster = items_out[sorted_indices[:max(1, len(items_out)//2)]]\n\n        # Randomly select from top cluster with higher probability\n        if len(top_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(top_cluster)\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Biased random walk: remove low-contribution items with weight consideration\n    if len(items_in) > 0:\n        # Calculate contribution of each item in solution with weight consideration\n        contribution1 = value1_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        contribution2 = value2_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        combined_contribution = contribution1 + contribution2\n        weight_contribution = combined_contribution / (weight_lst[items_in] + 1e-6)\n\n        # Remove items with lowest weight-adjusted contribution\n        sorted_indices = np.argsort(weight_contribution)\n        bottom_cluster = items_in[sorted_indices[:max(1, len(items_in)//4)]]\n\n        if len(bottom_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(bottom_cluster)\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            # Remove items with smallest weight to contribution ratio\n            contribution_ratio = (value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6)\n            sorted_indices = np.argsort(contribution_ratio)\n            for idx in items_in_new[sorted_indices]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9929539344021545,
            3.763106882572174
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a Pareto-frontier proximity score and applies a hybrid local search that combines objective-specific item additions/removals with dynamic weight balancing to explore the solution space efficiently while maintaining feasibility through constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution based on Pareto-frontier proximity\n    objectives = np.array([obj for _, obj in archive])\n    pareto_scores = np.max(objectives, axis=0) - objectives\n    selected_idx = np.argmin(np.sum(pareto_scores, axis=1))\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: objective-specific operations with dynamic balancing\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Objective 1 focused operation\n    if len(items_out) > 0:\n        candidates = items_out[np.argsort(value1_lst[items_out])[-min(5, len(items_out)):]]\n        for candidate in candidates:\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n                current_weight += weight_lst[candidate]\n                break\n\n    # Objective 2 focused operation\n    if len(items_out) > 0:\n        candidates = items_out[np.argsort(value2_lst[items_out])[-min(5, len(items_out)):]]\n        for candidate in candidates:\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n                current_weight += weight_lst[candidate]\n                break\n\n    # Dynamic weight balancing\n    if len(items_in) > 0 and current_weight > 0.7 * capacity:\n        candidates = items_in[np.argsort(weight_lst[items_in])[:min(3, len(items_in))]]\n        for candidate in candidates:\n            new_solution[candidate] = 0\n            current_weight -= weight_lst[candidate]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        removal_order = np.argsort(weight_lst[items_in_new])\n        for idx in items_in_new[removal_order]:\n            if excess <= 0:\n                break\n            new_solution[idx] = 0\n            excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.977883289799175,
            0.8179505467414856
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a diversity-aware objective ranking and applies a hybrid local search that combines value-weighted item swaps with adaptive capacity-sensitive perturbations to explore high-potential regions while ensuring feasibility through dynamic weight adjustment.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with diverse objective ranking\n    objectives = np.array([obj for _, obj in archive])\n    ranks = np.argsort(objectives[:, 0]) + np.argsort(objectives[:, 1])\n    selected_idx = np.argmin(ranks) if np.random.rand() < 0.6 else np.argmax(ranks)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: value-weighted swaps and adaptive perturbations\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Value-weighted item swaps\n    if len(items_in) > 0 and len(items_out) > 0:\n        swap_scores = (value1_lst[items_in] + value2_lst[items_in]) / (weight_lst[items_in] + 1e-6)\n        best_swap = np.argmax(swap_scores)\n        candidate_new = np.random.choice(items_out)\n\n        if weight_lst[candidate_new] <= weight_lst[items_in[best_swap]]:\n            delta_weight = weight_lst[candidate_new] - weight_lst[items_in[best_swap]]\n            if current_weight + delta_weight <= capacity:\n                new_solution[items_in[best_swap]] = 0\n                new_solution[candidate_new] = 1\n                current_weight += delta_weight\n\n    # Adaptive capacity-sensitive perturbations\n    if np.random.rand() < 0.3:\n        if current_weight < 0.8 * capacity and len(items_out) > 0:\n            candidate = np.random.choice(items_out)\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n        elif current_weight > 0.6 * capacity and len(items_in) > 0:\n            candidate = np.random.choice(items_in)\n            new_solution[candidate] = 0\n\n    # Ensure feasibility through dynamic adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        removal_order = np.argsort((value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6))\n        for idx in items_in_new[removal_order]:\n            if excess <= 0:\n                break\n            new_solution[idx] = 0\n            excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.898773143786561,
            0.7867339849472046
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search that combines adaptive item grouping with a biased random walk, where items are first clustered by their marginal gain ratios, and then explored within these clusters to identify high-potential regions for improvement while ensuring feasibility through weight-constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives with weight consideration)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    normalized_weights = (weights - np.min(weights)) / (np.max(weights) - np.min(weights) + 1e-6)\n    scores = 0.7 * np.sum(normalized_objectives, axis=1) - 0.3 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item grouping and biased random walk\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate marginal gain ratios for items not in solution with weight consideration\n    if len(items_out) > 0:\n        ratio1 = value1_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        ratio2 = value2_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        combined_ratio = ratio1 + ratio2\n        weight_ratio = combined_ratio / (weight_lst[items_out] + 1e-6)\n\n        # Cluster items by weight-adjusted marginal gain ratio\n        sorted_indices = np.argsort(weight_ratio)[::-1]\n        top_cluster = items_out[sorted_indices[:max(1, len(items_out)//2)]]\n\n        # Randomly select from top cluster with higher probability\n        if len(top_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(top_cluster)\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Biased random walk: remove low-contribution items with weight consideration\n    if len(items_in) > 0:\n        # Calculate contribution of each item in solution with weight consideration\n        contribution1 = value1_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        contribution2 = value2_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        combined_contribution = contribution1 + contribution2\n        weight_contribution = combined_contribution / (weight_lst[items_in] + 1e-6)\n\n        # Remove items with lowest weight-adjusted contribution\n        sorted_indices = np.argsort(weight_contribution)\n        bottom_cluster = items_in[sorted_indices[:max(1, len(items_in)//4)]]\n\n        if len(bottom_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(bottom_cluster)\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            # Remove items with smallest weight to contribution ratio\n            contribution_ratio = (value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6)\n            sorted_indices = np.argsort(contribution_ratio)\n            for idx in items_in_new[sorted_indices]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9929539344021545,
            3.763106882572174
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a diversity-aware objective ranking and applies a hybrid local search that combines value-weighted item swaps with adaptive capacity-sensitive perturbations to explore high-potential regions while ensuring feasibility through dynamic weight adjustment.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with diverse objective ranking\n    objectives = np.array([obj for _, obj in archive])\n    ranks = np.argsort(objectives[:, 0]) + np.argsort(objectives[:, 1])\n    selected_idx = np.argmin(ranks) if np.random.rand() < 0.6 else np.argmax(ranks)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: value-weighted swaps and adaptive perturbations\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Value-weighted item swaps\n    if len(items_in) > 0 and len(items_out) > 0:\n        swap_scores = (value1_lst[items_in] + value2_lst[items_in]) / (weight_lst[items_in] + 1e-6)\n        best_swap = np.argmax(swap_scores)\n        candidate_new = np.random.choice(items_out)\n\n        if weight_lst[candidate_new] <= weight_lst[items_in[best_swap]]:\n            delta_weight = weight_lst[candidate_new] - weight_lst[items_in[best_swap]]\n            if current_weight + delta_weight <= capacity:\n                new_solution[items_in[best_swap]] = 0\n                new_solution[candidate_new] = 1\n                current_weight += delta_weight\n\n    # Adaptive capacity-sensitive perturbations\n    if np.random.rand() < 0.3:\n        if current_weight < 0.8 * capacity and len(items_out) > 0:\n            candidate = np.random.choice(items_out)\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n        elif current_weight > 0.6 * capacity and len(items_in) > 0:\n            candidate = np.random.choice(items_in)\n            new_solution[candidate] = 0\n\n    # Ensure feasibility through dynamic adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        removal_order = np.argsort((value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6))\n        for idx in items_in_new[removal_order]:\n            if excess <= 0:\n                break\n            new_solution[idx] = 0\n            excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.898773143786561,
            0.7867339849472046
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search that combines adaptive item grouping with a biased random walk, where items are first clustered by their marginal gain ratios, and then explored within these clusters to identify high-potential regions for improvement while ensuring feasibility through weight-constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives with weight consideration)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    normalized_weights = (weights - np.min(weights)) / (np.max(weights) - np.min(weights) + 1e-6)\n    scores = 0.7 * np.sum(normalized_objectives, axis=1) - 0.3 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item grouping and biased random walk\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate marginal gain ratios for items not in solution with weight consideration\n    if len(items_out) > 0:\n        ratio1 = value1_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        ratio2 = value2_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        combined_ratio = ratio1 + ratio2\n        weight_ratio = combined_ratio / (weight_lst[items_out] + 1e-6)\n\n        # Cluster items by weight-adjusted marginal gain ratio\n        sorted_indices = np.argsort(weight_ratio)[::-1]\n        top_cluster = items_out[sorted_indices[:max(1, len(items_out)//2)]]\n\n        # Randomly select from top cluster with higher probability\n        if len(top_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(top_cluster)\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Biased random walk: remove low-contribution items with weight consideration\n    if len(items_in) > 0:\n        # Calculate contribution of each item in solution with weight consideration\n        contribution1 = value1_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        contribution2 = value2_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        combined_contribution = contribution1 + contribution2\n        weight_contribution = combined_contribution / (weight_lst[items_in] + 1e-6)\n\n        # Remove items with lowest weight-adjusted contribution\n        sorted_indices = np.argsort(weight_contribution)\n        bottom_cluster = items_in[sorted_indices[:max(1, len(items_in)//4)]]\n\n        if len(bottom_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(bottom_cluster)\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            # Remove items with smallest weight to contribution ratio\n            contribution_ratio = (value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6)\n            sorted_indices = np.argsort(contribution_ratio)\n            for idx in items_in_new[sorted_indices]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9929539344021545,
            3.763106882572174
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a diversity-aware objective ranking and applies a hybrid local search that combines value-weighted item swaps with adaptive capacity-sensitive perturbations to explore high-potential regions while ensuring feasibility through dynamic weight adjustment.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with diverse objective ranking\n    objectives = np.array([obj for _, obj in archive])\n    ranks = np.argsort(objectives[:, 0]) + np.argsort(objectives[:, 1])\n    selected_idx = np.argmin(ranks) if np.random.rand() < 0.6 else np.argmax(ranks)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: value-weighted swaps and adaptive perturbations\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Value-weighted item swaps\n    if len(items_in) > 0 and len(items_out) > 0:\n        swap_scores = (value1_lst[items_in] + value2_lst[items_in]) / (weight_lst[items_in] + 1e-6)\n        best_swap = np.argmax(swap_scores)\n        candidate_new = np.random.choice(items_out)\n\n        if weight_lst[candidate_new] <= weight_lst[items_in[best_swap]]:\n            delta_weight = weight_lst[candidate_new] - weight_lst[items_in[best_swap]]\n            if current_weight + delta_weight <= capacity:\n                new_solution[items_in[best_swap]] = 0\n                new_solution[candidate_new] = 1\n                current_weight += delta_weight\n\n    # Adaptive capacity-sensitive perturbations\n    if np.random.rand() < 0.3:\n        if current_weight < 0.8 * capacity and len(items_out) > 0:\n            candidate = np.random.choice(items_out)\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n        elif current_weight > 0.6 * capacity and len(items_in) > 0:\n            candidate = np.random.choice(items_in)\n            new_solution[candidate] = 0\n\n    # Ensure feasibility through dynamic adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        removal_order = np.argsort((value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6))\n        for idx in items_in_new[removal_order]:\n            if excess <= 0:\n                break\n            new_solution[idx] = 0\n            excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.898773143786561,
            0.7867339849472046
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search that combines adaptive item grouping with a biased random walk, where items are first clustered by their marginal gain ratios, and then explored within these clusters to identify high-potential regions for improvement while ensuring feasibility through weight-constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives with weight consideration)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    normalized_weights = (weights - np.min(weights)) / (np.max(weights) - np.min(weights) + 1e-6)\n    scores = 0.7 * np.sum(normalized_objectives, axis=1) - 0.3 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item grouping and biased random walk\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate marginal gain ratios for items not in solution with weight consideration\n    if len(items_out) > 0:\n        ratio1 = value1_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        ratio2 = value2_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        combined_ratio = ratio1 + ratio2\n        weight_ratio = combined_ratio / (weight_lst[items_out] + 1e-6)\n\n        # Cluster items by weight-adjusted marginal gain ratio\n        sorted_indices = np.argsort(weight_ratio)[::-1]\n        top_cluster = items_out[sorted_indices[:max(1, len(items_out)//2)]]\n\n        # Randomly select from top cluster with higher probability\n        if len(top_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(top_cluster)\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Biased random walk: remove low-contribution items with weight consideration\n    if len(items_in) > 0:\n        # Calculate contribution of each item in solution with weight consideration\n        contribution1 = value1_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        contribution2 = value2_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        combined_contribution = contribution1 + contribution2\n        weight_contribution = combined_contribution / (weight_lst[items_in] + 1e-6)\n\n        # Remove items with lowest weight-adjusted contribution\n        sorted_indices = np.argsort(weight_contribution)\n        bottom_cluster = items_in[sorted_indices[:max(1, len(items_in)//4)]]\n\n        if len(bottom_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(bottom_cluster)\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            # Remove items with smallest weight to contribution ratio\n            contribution_ratio = (value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6)\n            sorted_indices = np.argsort(contribution_ratio)\n            for idx in items_in_new[sorted_indices]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9929539344021545,
            3.763106882572174
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a diversity-aware objective ranking and applies a hybrid local search that combines value-weighted item swaps with adaptive capacity-sensitive perturbations to explore high-potential regions while ensuring feasibility through dynamic weight adjustment.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with diverse objective ranking\n    objectives = np.array([obj for _, obj in archive])\n    ranks = np.argsort(objectives[:, 0]) + np.argsort(objectives[:, 1])\n    selected_idx = np.argmin(ranks) if np.random.rand() < 0.6 else np.argmax(ranks)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: value-weighted swaps and adaptive perturbations\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Value-weighted item swaps\n    if len(items_in) > 0 and len(items_out) > 0:\n        swap_scores = (value1_lst[items_in] + value2_lst[items_in]) / (weight_lst[items_in] + 1e-6)\n        best_swap = np.argmax(swap_scores)\n        candidate_new = np.random.choice(items_out)\n\n        if weight_lst[candidate_new] <= weight_lst[items_in[best_swap]]:\n            delta_weight = weight_lst[candidate_new] - weight_lst[items_in[best_swap]]\n            if current_weight + delta_weight <= capacity:\n                new_solution[items_in[best_swap]] = 0\n                new_solution[candidate_new] = 1\n                current_weight += delta_weight\n\n    # Adaptive capacity-sensitive perturbations\n    if np.random.rand() < 0.3:\n        if current_weight < 0.8 * capacity and len(items_out) > 0:\n            candidate = np.random.choice(items_out)\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n        elif current_weight > 0.6 * capacity and len(items_in) > 0:\n            candidate = np.random.choice(items_in)\n            new_solution[candidate] = 0\n\n    # Ensure feasibility through dynamic adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        removal_order = np.argsort((value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6))\n        for idx in items_in_new[removal_order]:\n            if excess <= 0:\n                break\n            new_solution[idx] = 0\n            excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.898773143786561,
            0.7867339849472046
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search that combines adaptive item grouping with a biased random walk, where items are first clustered by their marginal gain ratios, and then explored within these clusters to identify high-potential regions for improvement while ensuring feasibility through weight-constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives with weight consideration)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    normalized_weights = (weights - np.min(weights)) / (np.max(weights) - np.min(weights) + 1e-6)\n    scores = 0.7 * np.sum(normalized_objectives, axis=1) - 0.3 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item grouping and biased random walk\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate marginal gain ratios for items not in solution with weight consideration\n    if len(items_out) > 0:\n        ratio1 = value1_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        ratio2 = value2_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        combined_ratio = ratio1 + ratio2\n        weight_ratio = combined_ratio / (weight_lst[items_out] + 1e-6)\n\n        # Cluster items by weight-adjusted marginal gain ratio\n        sorted_indices = np.argsort(weight_ratio)[::-1]\n        top_cluster = items_out[sorted_indices[:max(1, len(items_out)//2)]]\n\n        # Randomly select from top cluster with higher probability\n        if len(top_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(top_cluster)\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Biased random walk: remove low-contribution items with weight consideration\n    if len(items_in) > 0:\n        # Calculate contribution of each item in solution with weight consideration\n        contribution1 = value1_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        contribution2 = value2_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        combined_contribution = contribution1 + contribution2\n        weight_contribution = combined_contribution / (weight_lst[items_in] + 1e-6)\n\n        # Remove items with lowest weight-adjusted contribution\n        sorted_indices = np.argsort(weight_contribution)\n        bottom_cluster = items_in[sorted_indices[:max(1, len(items_in)//4)]]\n\n        if len(bottom_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(bottom_cluster)\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            # Remove items with smallest weight to contribution ratio\n            contribution_ratio = (value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6)\n            sorted_indices = np.argsort(contribution_ratio)\n            for idx in items_in_new[sorted_indices]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9929539344021545,
            3.763106882572174
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a diversity-aware objective ranking and applies a hybrid local search that combines value-weighted item swaps with adaptive capacity-sensitive perturbations to explore high-potential regions while ensuring feasibility through dynamic weight adjustment.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with diverse objective ranking\n    objectives = np.array([obj for _, obj in archive])\n    ranks = np.argsort(objectives[:, 0]) + np.argsort(objectives[:, 1])\n    selected_idx = np.argmin(ranks) if np.random.rand() < 0.6 else np.argmax(ranks)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: value-weighted swaps and adaptive perturbations\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Value-weighted item swaps\n    if len(items_in) > 0 and len(items_out) > 0:\n        swap_scores = (value1_lst[items_in] + value2_lst[items_in]) / (weight_lst[items_in] + 1e-6)\n        best_swap = np.argmax(swap_scores)\n        candidate_new = np.random.choice(items_out)\n\n        if weight_lst[candidate_new] <= weight_lst[items_in[best_swap]]:\n            delta_weight = weight_lst[candidate_new] - weight_lst[items_in[best_swap]]\n            if current_weight + delta_weight <= capacity:\n                new_solution[items_in[best_swap]] = 0\n                new_solution[candidate_new] = 1\n                current_weight += delta_weight\n\n    # Adaptive capacity-sensitive perturbations\n    if np.random.rand() < 0.3:\n        if current_weight < 0.8 * capacity and len(items_out) > 0:\n            candidate = np.random.choice(items_out)\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n        elif current_weight > 0.6 * capacity and len(items_in) > 0:\n            candidate = np.random.choice(items_in)\n            new_solution[candidate] = 0\n\n    # Ensure feasibility through dynamic adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        removal_order = np.argsort((value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6))\n        for idx in items_in_new[removal_order]:\n            if excess <= 0:\n                break\n            new_solution[idx] = 0\n            excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.898773143786561,
            0.7867339849472046
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search that combines adaptive item grouping with a biased random walk, where items are first clustered by their marginal gain ratios, and then explored within these clusters to identify high-potential regions for improvement while ensuring feasibility through weight-constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives with weight consideration)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    normalized_weights = (weights - np.min(weights)) / (np.max(weights) - np.min(weights) + 1e-6)\n    scores = 0.7 * np.sum(normalized_objectives, axis=1) - 0.3 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item grouping and biased random walk\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate marginal gain ratios for items not in solution with weight consideration\n    if len(items_out) > 0:\n        ratio1 = value1_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        ratio2 = value2_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        combined_ratio = ratio1 + ratio2\n        weight_ratio = combined_ratio / (weight_lst[items_out] + 1e-6)\n\n        # Cluster items by weight-adjusted marginal gain ratio\n        sorted_indices = np.argsort(weight_ratio)[::-1]\n        top_cluster = items_out[sorted_indices[:max(1, len(items_out)//2)]]\n\n        # Randomly select from top cluster with higher probability\n        if len(top_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(top_cluster)\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Biased random walk: remove low-contribution items with weight consideration\n    if len(items_in) > 0:\n        # Calculate contribution of each item in solution with weight consideration\n        contribution1 = value1_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        contribution2 = value2_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        combined_contribution = contribution1 + contribution2\n        weight_contribution = combined_contribution / (weight_lst[items_in] + 1e-6)\n\n        # Remove items with lowest weight-adjusted contribution\n        sorted_indices = np.argsort(weight_contribution)\n        bottom_cluster = items_in[sorted_indices[:max(1, len(items_in)//4)]]\n\n        if len(bottom_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(bottom_cluster)\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            # Remove items with smallest weight to contribution ratio\n            contribution_ratio = (value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6)\n            sorted_indices = np.argsort(contribution_ratio)\n            for idx in items_in_new[sorted_indices]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9929539344021545,
            3.763106882572174
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a diversity-aware objective ranking and applies a hybrid local search that combines value-weighted item swaps with adaptive capacity-sensitive perturbations to explore high-potential regions while ensuring feasibility through dynamic weight adjustment.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with diverse objective ranking\n    objectives = np.array([obj for _, obj in archive])\n    ranks = np.argsort(objectives[:, 0]) + np.argsort(objectives[:, 1])\n    selected_idx = np.argmin(ranks) if np.random.rand() < 0.6 else np.argmax(ranks)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: value-weighted swaps and adaptive perturbations\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Value-weighted item swaps\n    if len(items_in) > 0 and len(items_out) > 0:\n        swap_scores = (value1_lst[items_in] + value2_lst[items_in]) / (weight_lst[items_in] + 1e-6)\n        best_swap = np.argmax(swap_scores)\n        candidate_new = np.random.choice(items_out)\n\n        if weight_lst[candidate_new] <= weight_lst[items_in[best_swap]]:\n            delta_weight = weight_lst[candidate_new] - weight_lst[items_in[best_swap]]\n            if current_weight + delta_weight <= capacity:\n                new_solution[items_in[best_swap]] = 0\n                new_solution[candidate_new] = 1\n                current_weight += delta_weight\n\n    # Adaptive capacity-sensitive perturbations\n    if np.random.rand() < 0.3:\n        if current_weight < 0.8 * capacity and len(items_out) > 0:\n            candidate = np.random.choice(items_out)\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n        elif current_weight > 0.6 * capacity and len(items_in) > 0:\n            candidate = np.random.choice(items_in)\n            new_solution[candidate] = 0\n\n    # Ensure feasibility through dynamic adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        removal_order = np.argsort((value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6))\n        for idx in items_in_new[removal_order]:\n            if excess <= 0:\n                break\n            new_solution[idx] = 0\n            excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.898773143786561,
            0.7867339849472046
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search that combines adaptive item grouping with a biased random walk, where items are first clustered by their marginal gain ratios, and then explored within these clusters to identify high-potential regions for improvement while ensuring feasibility through weight-constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives with weight consideration)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    normalized_weights = (weights - np.min(weights)) / (np.max(weights) - np.min(weights) + 1e-6)\n    scores = 0.7 * np.sum(normalized_objectives, axis=1) - 0.3 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item grouping and biased random walk\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate marginal gain ratios for items not in solution with weight consideration\n    if len(items_out) > 0:\n        ratio1 = value1_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        ratio2 = value2_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        combined_ratio = ratio1 + ratio2\n        weight_ratio = combined_ratio / (weight_lst[items_out] + 1e-6)\n\n        # Cluster items by weight-adjusted marginal gain ratio\n        sorted_indices = np.argsort(weight_ratio)[::-1]\n        top_cluster = items_out[sorted_indices[:max(1, len(items_out)//2)]]\n\n        # Randomly select from top cluster with higher probability\n        if len(top_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(top_cluster)\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Biased random walk: remove low-contribution items with weight consideration\n    if len(items_in) > 0:\n        # Calculate contribution of each item in solution with weight consideration\n        contribution1 = value1_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        contribution2 = value2_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        combined_contribution = contribution1 + contribution2\n        weight_contribution = combined_contribution / (weight_lst[items_in] + 1e-6)\n\n        # Remove items with lowest weight-adjusted contribution\n        sorted_indices = np.argsort(weight_contribution)\n        bottom_cluster = items_in[sorted_indices[:max(1, len(items_in)//4)]]\n\n        if len(bottom_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(bottom_cluster)\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            # Remove items with smallest weight to contribution ratio\n            contribution_ratio = (value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6)\n            sorted_indices = np.argsort(contribution_ratio)\n            for idx in items_in_new[sorted_indices]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9929539344021545,
            3.763106882572174
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a diversity-aware objective ranking and applies a hybrid local search that combines value-weighted item swaps with adaptive capacity-sensitive perturbations to explore high-potential regions while ensuring feasibility through dynamic weight adjustment.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with diverse objective ranking\n    objectives = np.array([obj for _, obj in archive])\n    ranks = np.argsort(objectives[:, 0]) + np.argsort(objectives[:, 1])\n    selected_idx = np.argmin(ranks) if np.random.rand() < 0.6 else np.argmax(ranks)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: value-weighted swaps and adaptive perturbations\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Value-weighted item swaps\n    if len(items_in) > 0 and len(items_out) > 0:\n        swap_scores = (value1_lst[items_in] + value2_lst[items_in]) / (weight_lst[items_in] + 1e-6)\n        best_swap = np.argmax(swap_scores)\n        candidate_new = np.random.choice(items_out)\n\n        if weight_lst[candidate_new] <= weight_lst[items_in[best_swap]]:\n            delta_weight = weight_lst[candidate_new] - weight_lst[items_in[best_swap]]\n            if current_weight + delta_weight <= capacity:\n                new_solution[items_in[best_swap]] = 0\n                new_solution[candidate_new] = 1\n                current_weight += delta_weight\n\n    # Adaptive capacity-sensitive perturbations\n    if np.random.rand() < 0.3:\n        if current_weight < 0.8 * capacity and len(items_out) > 0:\n            candidate = np.random.choice(items_out)\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n        elif current_weight > 0.6 * capacity and len(items_in) > 0:\n            candidate = np.random.choice(items_in)\n            new_solution[candidate] = 0\n\n    # Ensure feasibility through dynamic adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        removal_order = np.argsort((value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6))\n        for idx in items_in_new[removal_order]:\n            if excess <= 0:\n                break\n            new_solution[idx] = 0\n            excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.898773143786561,
            0.7867339849472046
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search that combines adaptive item grouping with a biased random walk, where items are first clustered by their marginal gain ratios, and then explored within these clusters to identify high-potential regions for improvement while ensuring feasibility through weight-constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives with weight consideration)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    normalized_weights = (weights - np.min(weights)) / (np.max(weights) - np.min(weights) + 1e-6)\n    scores = 0.7 * np.sum(normalized_objectives, axis=1) - 0.3 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item grouping and biased random walk\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate marginal gain ratios for items not in solution with weight consideration\n    if len(items_out) > 0:\n        ratio1 = value1_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        ratio2 = value2_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        combined_ratio = ratio1 + ratio2\n        weight_ratio = combined_ratio / (weight_lst[items_out] + 1e-6)\n\n        # Cluster items by weight-adjusted marginal gain ratio\n        sorted_indices = np.argsort(weight_ratio)[::-1]\n        top_cluster = items_out[sorted_indices[:max(1, len(items_out)//2)]]\n\n        # Randomly select from top cluster with higher probability\n        if len(top_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(top_cluster)\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Biased random walk: remove low-contribution items with weight consideration\n    if len(items_in) > 0:\n        # Calculate contribution of each item in solution with weight consideration\n        contribution1 = value1_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        contribution2 = value2_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        combined_contribution = contribution1 + contribution2\n        weight_contribution = combined_contribution / (weight_lst[items_in] + 1e-6)\n\n        # Remove items with lowest weight-adjusted contribution\n        sorted_indices = np.argsort(weight_contribution)\n        bottom_cluster = items_in[sorted_indices[:max(1, len(items_in)//4)]]\n\n        if len(bottom_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(bottom_cluster)\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            # Remove items with smallest weight to contribution ratio\n            contribution_ratio = (value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6)\n            sorted_indices = np.argsort(contribution_ratio)\n            for idx in items_in_new[sorted_indices]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9929539344021545,
            3.763106882572174
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a diversity-aware objective ranking and applies a hybrid local search that combines value-weighted item swaps with adaptive capacity-sensitive perturbations to explore high-potential regions while ensuring feasibility through dynamic weight adjustment.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with diverse objective ranking\n    objectives = np.array([obj for _, obj in archive])\n    ranks = np.argsort(objectives[:, 0]) + np.argsort(objectives[:, 1])\n    selected_idx = np.argmin(ranks) if np.random.rand() < 0.6 else np.argmax(ranks)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: value-weighted swaps and adaptive perturbations\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Value-weighted item swaps\n    if len(items_in) > 0 and len(items_out) > 0:\n        swap_scores = (value1_lst[items_in] + value2_lst[items_in]) / (weight_lst[items_in] + 1e-6)\n        best_swap = np.argmax(swap_scores)\n        candidate_new = np.random.choice(items_out)\n\n        if weight_lst[candidate_new] <= weight_lst[items_in[best_swap]]:\n            delta_weight = weight_lst[candidate_new] - weight_lst[items_in[best_swap]]\n            if current_weight + delta_weight <= capacity:\n                new_solution[items_in[best_swap]] = 0\n                new_solution[candidate_new] = 1\n                current_weight += delta_weight\n\n    # Adaptive capacity-sensitive perturbations\n    if np.random.rand() < 0.3:\n        if current_weight < 0.8 * capacity and len(items_out) > 0:\n            candidate = np.random.choice(items_out)\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n        elif current_weight > 0.6 * capacity and len(items_in) > 0:\n            candidate = np.random.choice(items_in)\n            new_solution[candidate] = 0\n\n    # Ensure feasibility through dynamic adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        removal_order = np.argsort((value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6))\n        for idx in items_in_new[removal_order]:\n            if excess <= 0:\n                break\n            new_solution[idx] = 0\n            excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.898773143786561,
            0.7867339849472046
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search that combines adaptive item grouping with a biased random walk, where items are first clustered by their marginal gain ratios, and then explored within these clusters to identify high-potential regions for improvement while ensuring feasibility through weight-constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives with weight consideration)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    normalized_weights = (weights - np.min(weights)) / (np.max(weights) - np.min(weights) + 1e-6)\n    scores = 0.7 * np.sum(normalized_objectives, axis=1) - 0.3 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item grouping and biased random walk\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate marginal gain ratios for items not in solution with weight consideration\n    if len(items_out) > 0:\n        ratio1 = value1_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        ratio2 = value2_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        combined_ratio = ratio1 + ratio2\n        weight_ratio = combined_ratio / (weight_lst[items_out] + 1e-6)\n\n        # Cluster items by weight-adjusted marginal gain ratio\n        sorted_indices = np.argsort(weight_ratio)[::-1]\n        top_cluster = items_out[sorted_indices[:max(1, len(items_out)//2)]]\n\n        # Randomly select from top cluster with higher probability\n        if len(top_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(top_cluster)\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Biased random walk: remove low-contribution items with weight consideration\n    if len(items_in) > 0:\n        # Calculate contribution of each item in solution with weight consideration\n        contribution1 = value1_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        contribution2 = value2_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        combined_contribution = contribution1 + contribution2\n        weight_contribution = combined_contribution / (weight_lst[items_in] + 1e-6)\n\n        # Remove items with lowest weight-adjusted contribution\n        sorted_indices = np.argsort(weight_contribution)\n        bottom_cluster = items_in[sorted_indices[:max(1, len(items_in)//4)]]\n\n        if len(bottom_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(bottom_cluster)\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            # Remove items with smallest weight to contribution ratio\n            contribution_ratio = (value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6)\n            sorted_indices = np.argsort(contribution_ratio)\n            for idx in items_in_new[sorted_indices]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9929539344021545,
            3.763106882572174
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a diversity-aware objective ranking and applies a hybrid local search that combines value-weighted item swaps with adaptive capacity-sensitive perturbations to explore high-potential regions while ensuring feasibility through dynamic weight adjustment.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with diverse objective ranking\n    objectives = np.array([obj for _, obj in archive])\n    ranks = np.argsort(objectives[:, 0]) + np.argsort(objectives[:, 1])\n    selected_idx = np.argmin(ranks) if np.random.rand() < 0.6 else np.argmax(ranks)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: value-weighted swaps and adaptive perturbations\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Value-weighted item swaps\n    if len(items_in) > 0 and len(items_out) > 0:\n        swap_scores = (value1_lst[items_in] + value2_lst[items_in]) / (weight_lst[items_in] + 1e-6)\n        best_swap = np.argmax(swap_scores)\n        candidate_new = np.random.choice(items_out)\n\n        if weight_lst[candidate_new] <= weight_lst[items_in[best_swap]]:\n            delta_weight = weight_lst[candidate_new] - weight_lst[items_in[best_swap]]\n            if current_weight + delta_weight <= capacity:\n                new_solution[items_in[best_swap]] = 0\n                new_solution[candidate_new] = 1\n                current_weight += delta_weight\n\n    # Adaptive capacity-sensitive perturbations\n    if np.random.rand() < 0.3:\n        if current_weight < 0.8 * capacity and len(items_out) > 0:\n            candidate = np.random.choice(items_out)\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n        elif current_weight > 0.6 * capacity and len(items_in) > 0:\n            candidate = np.random.choice(items_in)\n            new_solution[candidate] = 0\n\n    # Ensure feasibility through dynamic adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        removal_order = np.argsort((value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6))\n        for idx in items_in_new[removal_order]:\n            if excess <= 0:\n                break\n            new_solution[idx] = 0\n            excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.898773143786561,
            0.7867339849472046
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search that combines adaptive item grouping with a biased random walk, where items are first clustered by their marginal gain ratios, and then explored within these clusters to identify high-potential regions for improvement while ensuring feasibility through weight-constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives with weight consideration)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    normalized_weights = (weights - np.min(weights)) / (np.max(weights) - np.min(weights) + 1e-6)\n    scores = 0.7 * np.sum(normalized_objectives, axis=1) - 0.3 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item grouping and biased random walk\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate marginal gain ratios for items not in solution with weight consideration\n    if len(items_out) > 0:\n        ratio1 = value1_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        ratio2 = value2_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        combined_ratio = ratio1 + ratio2\n        weight_ratio = combined_ratio / (weight_lst[items_out] + 1e-6)\n\n        # Cluster items by weight-adjusted marginal gain ratio\n        sorted_indices = np.argsort(weight_ratio)[::-1]\n        top_cluster = items_out[sorted_indices[:max(1, len(items_out)//2)]]\n\n        # Randomly select from top cluster with higher probability\n        if len(top_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(top_cluster)\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Biased random walk: remove low-contribution items with weight consideration\n    if len(items_in) > 0:\n        # Calculate contribution of each item in solution with weight consideration\n        contribution1 = value1_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        contribution2 = value2_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        combined_contribution = contribution1 + contribution2\n        weight_contribution = combined_contribution / (weight_lst[items_in] + 1e-6)\n\n        # Remove items with lowest weight-adjusted contribution\n        sorted_indices = np.argsort(weight_contribution)\n        bottom_cluster = items_in[sorted_indices[:max(1, len(items_in)//4)]]\n\n        if len(bottom_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(bottom_cluster)\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            # Remove items with smallest weight to contribution ratio\n            contribution_ratio = (value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6)\n            sorted_indices = np.argsort(contribution_ratio)\n            for idx in items_in_new[sorted_indices]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9929539344021545,
            3.763106882572174
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search that combines adaptive item grouping with a biased random walk, where items are first clustered by their marginal gain ratios, and then explored within these clusters to identify high-potential regions for improvement while ensuring feasibility through weight-constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives with weight consideration)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    normalized_weights = (weights - np.min(weights)) / (np.max(weights) - np.min(weights) + 1e-6)\n    scores = 0.7 * np.sum(normalized_objectives, axis=1) - 0.3 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item grouping and biased random walk\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate marginal gain ratios for items not in solution with weight consideration\n    if len(items_out) > 0:\n        ratio1 = value1_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        ratio2 = value2_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        combined_ratio = ratio1 + ratio2\n        weight_ratio = combined_ratio / (weight_lst[items_out] + 1e-6)\n\n        # Cluster items by weight-adjusted marginal gain ratio\n        sorted_indices = np.argsort(weight_ratio)[::-1]\n        top_cluster = items_out[sorted_indices[:max(1, len(items_out)//2)]]\n\n        # Randomly select from top cluster with higher probability\n        if len(top_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(top_cluster)\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Biased random walk: remove low-contribution items with weight consideration\n    if len(items_in) > 0:\n        # Calculate contribution of each item in solution with weight consideration\n        contribution1 = value1_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        contribution2 = value2_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        combined_contribution = contribution1 + contribution2\n        weight_contribution = combined_contribution / (weight_lst[items_in] + 1e-6)\n\n        # Remove items with lowest weight-adjusted contribution\n        sorted_indices = np.argsort(weight_contribution)\n        bottom_cluster = items_in[sorted_indices[:max(1, len(items_in)//4)]]\n\n        if len(bottom_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(bottom_cluster)\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            # Remove items with smallest weight to contribution ratio\n            contribution_ratio = (value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6)\n            sorted_indices = np.argsort(contribution_ratio)\n            for idx in items_in_new[sorted_indices]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9929539344021545,
            3.763106882572174
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a diversity-aware objective ranking and applies a hybrid local search that combines value-weighted item swaps with adaptive capacity-sensitive perturbations to explore high-potential regions while ensuring feasibility through dynamic weight adjustment.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with diverse objective ranking\n    objectives = np.array([obj for _, obj in archive])\n    ranks = np.argsort(objectives[:, 0]) + np.argsort(objectives[:, 1])\n    selected_idx = np.argmin(ranks) if np.random.rand() < 0.6 else np.argmax(ranks)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: value-weighted swaps and adaptive perturbations\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Value-weighted item swaps\n    if len(items_in) > 0 and len(items_out) > 0:\n        swap_scores = (value1_lst[items_in] + value2_lst[items_in]) / (weight_lst[items_in] + 1e-6)\n        best_swap = np.argmax(swap_scores)\n        candidate_new = np.random.choice(items_out)\n\n        if weight_lst[candidate_new] <= weight_lst[items_in[best_swap]]:\n            delta_weight = weight_lst[candidate_new] - weight_lst[items_in[best_swap]]\n            if current_weight + delta_weight <= capacity:\n                new_solution[items_in[best_swap]] = 0\n                new_solution[candidate_new] = 1\n                current_weight += delta_weight\n\n    # Adaptive capacity-sensitive perturbations\n    if np.random.rand() < 0.3:\n        if current_weight < 0.8 * capacity and len(items_out) > 0:\n            candidate = np.random.choice(items_out)\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n        elif current_weight > 0.6 * capacity and len(items_in) > 0:\n            candidate = np.random.choice(items_in)\n            new_solution[candidate] = 0\n\n    # Ensure feasibility through dynamic adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        removal_order = np.argsort((value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6))\n        for idx in items_in_new[removal_order]:\n            if excess <= 0:\n                break\n            new_solution[idx] = 0\n            excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.898773143786561,
            0.7867339849472046
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search that combines adaptive item grouping with a biased random walk, where items are first clustered by their marginal gain ratios, and then explored within these clusters to identify high-potential regions for improvement while ensuring feasibility through weight-constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives with weight consideration)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    normalized_weights = (weights - np.min(weights)) / (np.max(weights) - np.min(weights) + 1e-6)\n    scores = 0.7 * np.sum(normalized_objectives, axis=1) - 0.3 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item grouping and biased random walk\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate marginal gain ratios for items not in solution with weight consideration\n    if len(items_out) > 0:\n        ratio1 = value1_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        ratio2 = value2_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        combined_ratio = ratio1 + ratio2\n        weight_ratio = combined_ratio / (weight_lst[items_out] + 1e-6)\n\n        # Cluster items by weight-adjusted marginal gain ratio\n        sorted_indices = np.argsort(weight_ratio)[::-1]\n        top_cluster = items_out[sorted_indices[:max(1, len(items_out)//2)]]\n\n        # Randomly select from top cluster with higher probability\n        if len(top_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(top_cluster)\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Biased random walk: remove low-contribution items with weight consideration\n    if len(items_in) > 0:\n        # Calculate contribution of each item in solution with weight consideration\n        contribution1 = value1_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        contribution2 = value2_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        combined_contribution = contribution1 + contribution2\n        weight_contribution = combined_contribution / (weight_lst[items_in] + 1e-6)\n\n        # Remove items with lowest weight-adjusted contribution\n        sorted_indices = np.argsort(weight_contribution)\n        bottom_cluster = items_in[sorted_indices[:max(1, len(items_in)//4)]]\n\n        if len(bottom_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(bottom_cluster)\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            # Remove items with smallest weight to contribution ratio\n            contribution_ratio = (value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6)\n            sorted_indices = np.argsort(contribution_ratio)\n            for idx in items_in_new[sorted_indices]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9929539344021545,
            3.763106882572174
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search that combines adaptive item grouping with a biased random walk, where items are first clustered by their marginal gain ratios, and then explored within these clusters to identify high-potential regions for improvement while ensuring feasibility through weight-constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives with weight consideration)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    normalized_weights = (weights - np.min(weights)) / (np.max(weights) - np.min(weights) + 1e-6)\n    scores = 0.7 * np.sum(normalized_objectives, axis=1) - 0.3 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item grouping and biased random walk\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate marginal gain ratios for items not in solution with weight consideration\n    if len(items_out) > 0:\n        ratio1 = value1_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        ratio2 = value2_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        combined_ratio = ratio1 + ratio2\n        weight_ratio = combined_ratio / (weight_lst[items_out] + 1e-6)\n\n        # Cluster items by weight-adjusted marginal gain ratio\n        sorted_indices = np.argsort(weight_ratio)[::-1]\n        top_cluster = items_out[sorted_indices[:max(1, len(items_out)//2)]]\n\n        # Randomly select from top cluster with higher probability\n        if len(top_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(top_cluster)\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Biased random walk: remove low-contribution items with weight consideration\n    if len(items_in) > 0:\n        # Calculate contribution of each item in solution with weight consideration\n        contribution1 = value1_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        contribution2 = value2_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        combined_contribution = contribution1 + contribution2\n        weight_contribution = combined_contribution / (weight_lst[items_in] + 1e-6)\n\n        # Remove items with lowest weight-adjusted contribution\n        sorted_indices = np.argsort(weight_contribution)\n        bottom_cluster = items_in[sorted_indices[:max(1, len(items_in)//4)]]\n\n        if len(bottom_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(bottom_cluster)\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            # Remove items with smallest weight to contribution ratio\n            contribution_ratio = (value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6)\n            sorted_indices = np.argsort(contribution_ratio)\n            for idx in items_in_new[sorted_indices]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9929539344021545,
            3.763106882572174
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search that combines adaptive item grouping with a biased random walk, where items are first clustered by their marginal gain ratios, and then explored within these clusters to identify high-potential regions for improvement while ensuring feasibility through weight-constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives with weight consideration)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    normalized_weights = (weights - np.min(weights)) / (np.max(weights) - np.min(weights) + 1e-6)\n    scores = 0.7 * np.sum(normalized_objectives, axis=1) - 0.3 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item grouping and biased random walk\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate marginal gain ratios for items not in solution with weight consideration\n    if len(items_out) > 0:\n        ratio1 = value1_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        ratio2 = value2_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        combined_ratio = ratio1 + ratio2\n        weight_ratio = combined_ratio / (weight_lst[items_out] + 1e-6)\n\n        # Cluster items by weight-adjusted marginal gain ratio\n        sorted_indices = np.argsort(weight_ratio)[::-1]\n        top_cluster = items_out[sorted_indices[:max(1, len(items_out)//2)]]\n\n        # Randomly select from top cluster with higher probability\n        if len(top_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(top_cluster)\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Biased random walk: remove low-contribution items with weight consideration\n    if len(items_in) > 0:\n        # Calculate contribution of each item in solution with weight consideration\n        contribution1 = value1_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        contribution2 = value2_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        combined_contribution = contribution1 + contribution2\n        weight_contribution = combined_contribution / (weight_lst[items_in] + 1e-6)\n\n        # Remove items with lowest weight-adjusted contribution\n        sorted_indices = np.argsort(weight_contribution)\n        bottom_cluster = items_in[sorted_indices[:max(1, len(items_in)//4)]]\n\n        if len(bottom_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(bottom_cluster)\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            # Remove items with smallest weight to contribution ratio\n            contribution_ratio = (value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6)\n            sorted_indices = np.argsort(contribution_ratio)\n            for idx in items_in_new[sorted_indices]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9929539344021545,
            3.763106882572174
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search that combines adaptive item grouping with a biased random walk, where items are first clustered by their marginal gain ratios, and then explored within these clusters to identify high-potential regions for improvement while ensuring feasibility through weight-constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives with weight consideration)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    normalized_weights = (weights - np.min(weights)) / (np.max(weights) - np.min(weights) + 1e-6)\n    scores = 0.7 * np.sum(normalized_objectives, axis=1) - 0.3 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item grouping and biased random walk\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate marginal gain ratios for items not in solution with weight consideration\n    if len(items_out) > 0:\n        ratio1 = value1_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        ratio2 = value2_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        combined_ratio = ratio1 + ratio2\n        weight_ratio = combined_ratio / (weight_lst[items_out] + 1e-6)\n\n        # Cluster items by weight-adjusted marginal gain ratio\n        sorted_indices = np.argsort(weight_ratio)[::-1]\n        top_cluster = items_out[sorted_indices[:max(1, len(items_out)//2)]]\n\n        # Randomly select from top cluster with higher probability\n        if len(top_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(top_cluster)\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Biased random walk: remove low-contribution items with weight consideration\n    if len(items_in) > 0:\n        # Calculate contribution of each item in solution with weight consideration\n        contribution1 = value1_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        contribution2 = value2_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        combined_contribution = contribution1 + contribution2\n        weight_contribution = combined_contribution / (weight_lst[items_in] + 1e-6)\n\n        # Remove items with lowest weight-adjusted contribution\n        sorted_indices = np.argsort(weight_contribution)\n        bottom_cluster = items_in[sorted_indices[:max(1, len(items_in)//4)]]\n\n        if len(bottom_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(bottom_cluster)\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            # Remove items with smallest weight to contribution ratio\n            contribution_ratio = (value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6)\n            sorted_indices = np.argsort(contribution_ratio)\n            for idx in items_in_new[sorted_indices]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9929539344021545,
            3.763106882572174
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search that combines adaptive item grouping with a biased random walk, where items are first clustered by their marginal gain ratios, and then explored within these clusters to identify high-potential regions for improvement while ensuring feasibility through weight-constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives with weight consideration)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    normalized_weights = (weights - np.min(weights)) / (np.max(weights) - np.min(weights) + 1e-6)\n    scores = 0.7 * np.sum(normalized_objectives, axis=1) - 0.3 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item grouping and biased random walk\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate marginal gain ratios for items not in solution with weight consideration\n    if len(items_out) > 0:\n        ratio1 = value1_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        ratio2 = value2_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        combined_ratio = ratio1 + ratio2\n        weight_ratio = combined_ratio / (weight_lst[items_out] + 1e-6)\n\n        # Cluster items by weight-adjusted marginal gain ratio\n        sorted_indices = np.argsort(weight_ratio)[::-1]\n        top_cluster = items_out[sorted_indices[:max(1, len(items_out)//2)]]\n\n        # Randomly select from top cluster with higher probability\n        if len(top_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(top_cluster)\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Biased random walk: remove low-contribution items with weight consideration\n    if len(items_in) > 0:\n        # Calculate contribution of each item in solution with weight consideration\n        contribution1 = value1_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        contribution2 = value2_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        combined_contribution = contribution1 + contribution2\n        weight_contribution = combined_contribution / (weight_lst[items_in] + 1e-6)\n\n        # Remove items with lowest weight-adjusted contribution\n        sorted_indices = np.argsort(weight_contribution)\n        bottom_cluster = items_in[sorted_indices[:max(1, len(items_in)//4)]]\n\n        if len(bottom_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(bottom_cluster)\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            # Remove items with smallest weight to contribution ratio\n            contribution_ratio = (value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6)\n            sorted_indices = np.argsort(contribution_ratio)\n            for idx in items_in_new[sorted_indices]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9929539344021545,
            3.763106882572174
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search that combines adaptive item grouping with a biased random walk, where items are first clustered by their marginal gain ratios, and then explored within these clusters to identify high-potential regions for improvement while ensuring feasibility through weight-constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives with weight consideration)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    normalized_weights = (weights - np.min(weights)) / (np.max(weights) - np.min(weights) + 1e-6)\n    scores = 0.7 * np.sum(normalized_objectives, axis=1) - 0.3 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item grouping and biased random walk\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate marginal gain ratios for items not in solution with weight consideration\n    if len(items_out) > 0:\n        ratio1 = value1_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        ratio2 = value2_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        combined_ratio = ratio1 + ratio2\n        weight_ratio = combined_ratio / (weight_lst[items_out] + 1e-6)\n\n        # Cluster items by weight-adjusted marginal gain ratio\n        sorted_indices = np.argsort(weight_ratio)[::-1]\n        top_cluster = items_out[sorted_indices[:max(1, len(items_out)//2)]]\n\n        # Randomly select from top cluster with higher probability\n        if len(top_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(top_cluster)\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Biased random walk: remove low-contribution items with weight consideration\n    if len(items_in) > 0:\n        # Calculate contribution of each item in solution with weight consideration\n        contribution1 = value1_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        contribution2 = value2_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        combined_contribution = contribution1 + contribution2\n        weight_contribution = combined_contribution / (weight_lst[items_in] + 1e-6)\n\n        # Remove items with lowest weight-adjusted contribution\n        sorted_indices = np.argsort(weight_contribution)\n        bottom_cluster = items_in[sorted_indices[:max(1, len(items_in)//4)]]\n\n        if len(bottom_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(bottom_cluster)\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            # Remove items with smallest weight to contribution ratio\n            contribution_ratio = (value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6)\n            sorted_indices = np.argsort(contribution_ratio)\n            for idx in items_in_new[sorted_indices]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9929539344021545,
            3.763106882572174
        ]
    }
]