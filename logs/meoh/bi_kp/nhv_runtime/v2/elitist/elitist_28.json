[
    {
        "algorithm": "{This algorithm selects a solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search that combines adaptive item grouping with a biased random walk, where items are first clustered by their marginal gain ratios, and then explored within these clusters to identify high-potential regions for improvement while ensuring feasibility through weight-constrained perturbations, but with a different implementation approach using a hybrid of greedy and random selection.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives with weight consideration)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    normalized_weights = (weights - np.min(weights)) / (np.max(weights) - np.min(weights) + 1e-6)\n    scores = 0.6 * np.sum(normalized_objectives, axis=1) - 0.4 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item grouping and biased random walk\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate marginal gain ratios for items not in solution with weight consideration\n    if len(items_out) > 0:\n        ratio1 = value1_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        ratio2 = value2_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        combined_ratio = ratio1 + ratio2\n        weight_ratio = combined_ratio / (weight_lst[items_out] + 1e-6)\n\n        # Cluster items by weight-adjusted marginal gain ratio\n        sorted_indices = np.argsort(weight_ratio)[::-1]\n        top_cluster = items_out[sorted_indices[:max(1, len(items_out)//3)]]\n\n        # Randomly select from top cluster with higher probability\n        if len(top_cluster) > 0:\n            for _ in range(2):\n                candidate_idx = np.random.choice(top_cluster)\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Biased random walk: remove low-contribution items with weight consideration\n    if len(items_in) > 0:\n        # Calculate contribution of each item in solution with weight consideration\n        contribution1 = value1_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        contribution2 = value2_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        combined_contribution = contribution1 + contribution2\n        weight_contribution = combined_contribution / (weight_lst[items_in] + 1e-6)\n\n        # Remove items with lowest weight-adjusted contribution\n        sorted_indices = np.argsort(weight_contribution)\n        bottom_cluster = items_in[sorted_indices[:max(1, len(items_in)//3)]]\n\n        if len(bottom_cluster) > 0:\n            for _ in range(2):\n                candidate_idx = np.random.choice(bottom_cluster)\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            # Remove items with smallest weight to contribution ratio\n            contribution_ratio = (value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6)\n            sorted_indices = np.argsort(contribution_ratio)\n            for idx in items_in_new[sorted_indices]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -1.028819091383601,
            2.9179683327674866
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a Pareto-frontier proximity score and applies a hybrid local search that combines objective-specific item additions/removals with dynamic weight balancing to explore the solution space efficiently while maintaining feasibility through constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution based on Pareto-frontier proximity\n    objectives = np.array([obj for _, obj in archive])\n    pareto_scores = np.max(objectives, axis=0) - objectives\n    selected_idx = np.argmin(np.sum(pareto_scores, axis=1))\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: objective-specific operations with dynamic balancing\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Objective 1 focused operation\n    if len(items_out) > 0:\n        candidates = items_out[np.argsort(value1_lst[items_out])[-min(5, len(items_out)):]]\n        for candidate in candidates:\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n                current_weight += weight_lst[candidate]\n                break\n\n    # Objective 2 focused operation\n    if len(items_out) > 0:\n        candidates = items_out[np.argsort(value2_lst[items_out])[-min(5, len(items_out)):]]\n        for candidate in candidates:\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n                current_weight += weight_lst[candidate]\n                break\n\n    # Dynamic weight balancing\n    if len(items_in) > 0 and current_weight > 0.7 * capacity:\n        candidates = items_in[np.argsort(weight_lst[items_in])[:min(3, len(items_in))]]\n        for candidate in candidates:\n            new_solution[candidate] = 0\n            current_weight -= weight_lst[candidate]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        removal_order = np.argsort(weight_lst[items_in_new])\n        for idx in items_in_new[removal_order]:\n            if excess <= 0:\n                break\n            new_solution[idx] = 0\n            excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.977883289799175,
            0.8179505467414856
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its objective balance and weight efficiency, then applies a novel multi-objective local search that explores item combinations by considering both profit ratios and weight distribution, ensuring feasibility through iterative adjustments and balance-aware capacity management.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high objective balance and weight efficiency\n    objectives = np.array([obj for _, obj in archive])\n    balance_scores = objectives[:, 0] / (objectives[:, 1] + 1e-6)\n    weight_efficiency = np.sum(weight_lst * archive[0][0]) / capacity\n    combined_scores = balance_scores * (1 + weight_efficiency)\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Multi-objective local search: explore item combinations\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate value-to-weight ratios and balance weights\n    value1_ratio = value1_lst / weight_lst\n    value2_ratio = value2_lst / weight_lst\n    balance_weights = np.abs(value1_ratio - value2_ratio)\n    weighted_ratios = (value1_ratio + value2_ratio) * (1 + balance_weights)\n    sorted_indices = np.argsort(weighted_ratios)[::-1]\n\n    # Explore combinations by considering both high-ratio and balance\n    for i in range(min(10, n_items)):\n        item_idx = sorted_indices[i]\n        if new_solution[item_idx] == 0 and current_weight + weight_lst[item_idx] <= capacity:\n            new_solution[item_idx] = 1\n            current_weight += weight_lst[item_idx]\n        elif new_solution[item_idx] == 1:\n            # Check if removing improves balance\n            if np.sum(weight_lst * new_solution) - weight_lst[item_idx] <= capacity:\n                new_solution[item_idx] = 0\n                current_weight -= weight_lst[item_idx]\n\n    # Balance-aware capacity management\n    if current_weight > capacity:\n        # Remove items with lowest weighted ratio until feasible\n        items_in_solution = np.where(new_solution == 1)[0]\n        sorted_items = items_in_solution[np.argsort(weighted_ratios[items_in_solution])]\n        for item_idx in sorted_items:\n            if current_weight <= capacity:\n                break\n            new_solution[item_idx] = 0\n            current_weight -= weight_lst[item_idx]\n\n    # Ensure at least one item remains if solution is not empty\n    if np.sum(new_solution) == 0 and n_items > 0:\n        # Add the item with highest weighted ratio\n        best_item = sorted_indices[0]\n        if weight_lst[best_item] <= capacity:\n            new_solution[best_item] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.9206211040861535,
            0.7854538857936859
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a diversity-aware objective ranking and applies a hybrid local search that combines value-weighted item swaps with adaptive capacity-sensitive perturbations to explore high-potential regions while ensuring feasibility through dynamic weight adjustment.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with diverse objective ranking\n    objectives = np.array([obj for _, obj in archive])\n    ranks = np.argsort(objectives[:, 0]) + np.argsort(objectives[:, 1])\n    selected_idx = np.argmin(ranks) if np.random.rand() < 0.6 else np.argmax(ranks)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: value-weighted swaps and adaptive perturbations\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Value-weighted item swaps\n    if len(items_in) > 0 and len(items_out) > 0:\n        swap_scores = (value1_lst[items_in] + value2_lst[items_in]) / (weight_lst[items_in] + 1e-6)\n        best_swap = np.argmax(swap_scores)\n        candidate_new = np.random.choice(items_out)\n\n        if weight_lst[candidate_new] <= weight_lst[items_in[best_swap]]:\n            delta_weight = weight_lst[candidate_new] - weight_lst[items_in[best_swap]]\n            if current_weight + delta_weight <= capacity:\n                new_solution[items_in[best_swap]] = 0\n                new_solution[candidate_new] = 1\n                current_weight += delta_weight\n\n    # Adaptive capacity-sensitive perturbations\n    if np.random.rand() < 0.3:\n        if current_weight < 0.8 * capacity and len(items_out) > 0:\n            candidate = np.random.choice(items_out)\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n        elif current_weight > 0.6 * capacity and len(items_in) > 0:\n            candidate = np.random.choice(items_in)\n            new_solution[candidate] = 0\n\n    # Ensure feasibility through dynamic adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        removal_order = np.argsort((value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6))\n        for idx in items_in_new[removal_order]:\n            if excess <= 0:\n                break\n            new_solution[idx] = 0\n            excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.898773143786561,
            0.7867339849472046
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive by prioritizing those with high combined objective values and low weight utilization, then applies a novel local search that combines adaptive item selection with a diversity-aware perturbation strategy, where items are first clustered by their marginal gain ratios, and then explored through a dynamic substitution process that considers both objective improvements and solution diversity while maintaining feasibility through weight-constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution based on combined objective and weight utilization\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    combined_objectives = objectives[:, 0] + objectives[:, 1]\n    normalized_weights = weights / capacity\n    scores = 0.6 * combined_objectives - 0.4 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item clustering and diversity-aware perturbation\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate marginal gain ratios with diversity consideration\n    if len(items_out) > 0:\n        marginal_gain1 = value1_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        marginal_gain2 = value2_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        combined_gain = marginal_gain1 + marginal_gain2\n        diversity_factor = np.abs(value1_lst[items_out] - value2_lst[items_out]) / (weight_lst[items_out] + 1e-6)\n        weighted_gain = 0.7 * combined_gain + 0.3 * diversity_factor\n\n        # Cluster items by weighted gain\n        sorted_indices = np.argsort(weighted_gain)[::-1]\n        top_cluster = items_out[sorted_indices[:max(1, len(items_out)//3)]]\n\n        # Dynamic substitution process\n        if len(top_cluster) > 0:\n            for _ in range(2):\n                candidate_idx = np.random.choice(top_cluster)\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    # Find least impactful item to remove if needed\n                    if len(items_in) > 0:\n                        impact_scores = (value1_lst[items_in] + value2_lst[items_in]) / (weight_lst[items_in] + 1e-6)\n                        remove_idx = items_in[np.argmin(impact_scores)]\n                        new_solution[remove_idx] = 0\n                        current_weight -= weight_lst[remove_idx]\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Diversity-aware removal of low-contribution items\n    if len(items_in) > 0:\n        contribution1 = value1_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        contribution2 = value2_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        combined_contribution = contribution1 + contribution2\n        diversity_contribution = np.abs(value1_lst[items_in] - value2_lst[items_in]) / (weight_lst[items_in] + 1e-6)\n        weighted_contribution = 0.6 * combined_contribution + 0.4 * diversity_contribution\n\n        # Remove items with lowest weighted contribution\n        sorted_indices = np.argsort(weighted_contribution)\n        bottom_cluster = items_in[sorted_indices[:max(1, len(items_in)//4)]]\n\n        if len(bottom_cluster) > 0:\n            for _ in range(2):\n                candidate_idx = np.random.choice(bottom_cluster)\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            # Remove items with smallest contribution to weight ratio\n            contribution_ratio = (value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6)\n            sorted_indices = np.argsort(contribution_ratio)\n            for idx in items_in_new[sorted_indices]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.969205196766664,
            2.8865227103233337
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a weighted combination of objective values and weight utilization, then applies a novel local search that uses dynamic item prioritization and probabilistic perturbation to explore high-potential regions while maintaining feasibility through adaptive weight constraints.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (weighted combination of objectives and weight utilization)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_weights = weights / capacity\n    weighted_scores = 0.6 * objectives[:, 0] + 0.4 * objectives[:, 1] - 0.3 * normalized_weights\n    selected_idx = np.argmax(weighted_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dynamic item prioritization and probabilistic perturbation\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate dynamic priorities for items not in solution\n    if len(items_out) > 0:\n        priority_scores = (value1_lst[items_out] + value2_lst[items_out]) / (weight_lst[items_out] + 1e-6)\n        sorted_indices = np.argsort(priority_scores)[::-1]\n        top_items = items_out[sorted_indices[:max(1, len(items_out)//4)]]\n\n        # Add items with probability proportional to their priority\n        for idx in top_items:\n            if np.random.rand() < 0.7 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Probabilistic removal of low-priority items\n    if len(items_in) > 0:\n        removal_scores = (value1_lst[items_in] + value2_lst[items_in]) / (weight_lst[items_in] + 1e-6)\n        sorted_indices = np.argsort(removal_scores)\n        bottom_items = items_in[sorted_indices[:max(1, len(items_in)//3)]]\n\n        for idx in bottom_items:\n            if np.random.rand() < 0.5:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Adaptive weight constraint enforcement\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            removal_order = np.argsort((value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6))\n            for idx in items_in_new[removal_order]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.951269370000086,
            2.5577997267246246
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a combination of objective dominance and solution density, then applies a novel two-phase local search strategy that first diversifies the solution by adding high-value items while maintaining feasibility, followed by a density-aware refinement phase that optimizes the solution by removing low-contribution items while preserving the diversity of the objectives.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high objective dominance and density\n    objectives = np.array([obj for _, obj in archive])\n    densities = np.array([np.sum(sol) for sol, _ in archive])\n    scores = (objectives[:, 0] + objectives[:, 1]) * densities\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Initialize new solution and calculate current metrics\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Phase 1: Diversification by adding high-value items\n    items_out = np.where(new_solution == 0)[0]\n    if len(items_out) > 0:\n        # Calculate value-to-weight ratios for non-included items\n        value1_ratio = value1_lst[items_out] / weight_lst[items_out]\n        value2_ratio = value2_lst[items_out] / weight_lst[items_out]\n        combined_ratio = value1_ratio + value2_ratio\n\n        # Select top 2 items with highest combined value-to-weight ratios\n        top_indices = np.argsort(combined_ratio)[-min(2, len(combined_ratio)):][::-1]\n        for idx in top_indices:\n            item_idx = items_out[idx]\n            if weight_lst[item_idx] <= remaining_capacity:\n                new_solution[item_idx] = 1\n                remaining_capacity -= weight_lst[item_idx]\n\n    # Phase 2: Density-aware refinement\n    items_in = np.where(new_solution == 1)[0]\n    if len(items_in) > 0:\n        # Calculate contribution scores (value-to-weight ratio weighted by solution density)\n        value1_ratio = value1_lst[items_in] / weight_lst[items_in]\n        value2_ratio = value2_lst[items_in] / weight_lst[items_in]\n        contribution = (value1_ratio + value2_ratio) / (1 + len(items_in)/len(weight_lst))\n\n        # Remove items with lowest contribution scores\n        sorted_indices = np.argsort(contribution)\n        for idx in sorted_indices[:min(1, len(sorted_indices))]:\n            item_idx = items_in[idx]\n            new_solution[item_idx] = 0\n            remaining_capacity += weight_lst[item_idx]\n\n    # Ensure feasibility if needed\n    if remaining_capacity < 0:\n        items_in = np.where(new_solution == 1)[0]\n        if len(items_in) > 0:\n            value1_ratio = value1_lst[items_in] / weight_lst[items_in]\n            value2_ratio = value2_lst[items_in] / weight_lst[items_in]\n            combined_ratio = value1_ratio + value2_ratio\n            sorted_indices = np.argsort(combined_ratio)\n\n            for idx in sorted_indices:\n                item_idx = items_in[idx]\n                new_solution[item_idx] = 0\n                remaining_capacity += weight_lst[item_idx]\n                if remaining_capacity >= 0:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.9263127467851553,
            1.7187164425849915
        ]
    },
    {
        "algorithm": "{The algorithm selects a promising solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search strategy that combines weight-balanced flips and objective-driven additions to explore the solution space while ensuring feasibility through adaptive capacity management.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution using a hybrid selection criterion (objective dominance and weight balance)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_weights = weights / capacity\n    scores = (objectives[:, 0] + objectives[:, 1]) / (1 + normalized_weights)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight and remaining capacity\n    current_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Novel local search strategy: objective-driven flips and weight-balanced additions\n    new_solution = base_solution.copy()\n    items = np.where(new_solution == 1)[0]\n    non_items = np.where(new_solution == 0)[0]\n\n    # Calculate value-to-weight ratios for non-included items\n    if len(non_items) > 0:\n        value1_ratio = value1_lst[non_items] / weight_lst[non_items]\n        value2_ratio = value2_lst[non_items] / weight_lst[non_items]\n\n        # Select top 3 items with highest combined value-to-weight ratios\n        combined_ratio = value1_ratio + value2_ratio\n        top_indices = np.argsort(combined_ratio)[-min(3, len(combined_ratio)):][::-1]\n        for idx in top_indices:\n            item_idx = non_items[idx]\n            if weight_lst[item_idx] <= remaining_capacity:\n                new_solution[item_idx] = 1\n                remaining_capacity -= weight_lst[item_idx]\n\n    # Adaptive capacity management: remove items with lowest ratio if still over capacity\n    if remaining_capacity < 0:\n        items_in_solution = np.where(new_solution == 1)[0]\n        if len(items_in_solution) > 0:\n            value1_ratio = value1_lst[items_in_solution] / weight_lst[items_in_solution]\n            value2_ratio = value2_lst[items_in_solution] / weight_lst[items_in_solution]\n            combined_ratio = value1_ratio + value2_ratio\n            sorted_indices = np.argsort(combined_ratio)\n\n            for idx in sorted_indices:\n                item_idx = items_in_solution[idx]\n                new_solution[item_idx] = 0\n                remaining_capacity += weight_lst[item_idx]\n                if remaining_capacity >= 0:\n                    break\n\n    # Weight-balanced flips: flip items that create a balanced weight distribution\n    if len(items) > 0:\n        flip_candidates = [i for i in items if abs(weight_lst[i] - remaining_capacity * 0.3) < 0.15 * capacity]\n        if len(flip_candidates) > 0:\n            flip_indices = random.sample(flip_candidates, min(1, len(flip_candidates)))\n            for idx in flip_indices:\n                new_solution[idx] = 0\n                remaining_capacity += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.95070882303056,
            2.1341150104999542
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its objective diversity and weight distribution, then applies a correlation-aware local search that explores item swaps by considering both profit ratios and weight efficiency, ensuring feasibility through iterative adjustments and diversity-aware capacity management.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high diversity and weight distribution\n    objectives = np.array([obj for _, obj in archive])\n    diversity_scores = np.std(objectives, axis=0).mean()\n    weight_distribution = np.sum(weight_lst * archive[0][0]) / capacity\n    combined_scores = diversity_scores * (1 + weight_distribution)\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Correlation-aware local search: explore item swaps\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate value-to-weight ratios and diversity weights\n    value1_ratio = value1_lst / weight_lst\n    value2_ratio = value2_lst / weight_lst\n    diversity_weights = np.abs(value1_ratio - value2_ratio)\n    weighted_ratios = (value1_ratio + value2_ratio) * (1 + diversity_weights)\n    sorted_indices = np.argsort(weighted_ratios)[::-1]\n\n    # Explore swaps by considering both high-ratio and diversity\n    for i in range(min(10, n_items)):\n        item_idx = sorted_indices[i]\n        if new_solution[item_idx] == 0 and current_weight + weight_lst[item_idx] <= capacity:\n            new_solution[item_idx] = 1\n            current_weight += weight_lst[item_idx]\n        elif new_solution[item_idx] == 1:\n            # Check if swapping improves diversity\n            if np.sum(weight_lst * new_solution) - weight_lst[item_idx] <= capacity:\n                new_solution[item_idx] = 0\n                current_weight -= weight_lst[item_idx]\n\n    # Diversity-aware capacity management\n    if current_weight > capacity:\n        # Remove items with lowest weighted ratio until feasible\n        items_in_solution = np.where(new_solution == 1)[0]\n        sorted_items = items_in_solution[np.argsort(weighted_ratios[items_in_solution])]\n        for item_idx in sorted_items:\n            if current_weight <= capacity:\n                break\n            new_solution[item_idx] = 0\n            current_weight -= weight_lst[item_idx]\n\n    # Ensure at least one item remains if solution is not empty\n    if np.sum(new_solution) == 0 and n_items > 0:\n        # Add the item with highest weighted ratio\n        best_item = sorted_indices[0]\n        if weight_lst[best_item] <= capacity:\n            new_solution[best_item] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.9216994772468861,
            1.1824100613594055
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its dominance and objective correlation, then applies a novel value-weighted local search that explores item exchanges by considering both profit ratios and weight distribution, ensuring feasibility through iterative adjustments and correlation-aware capacity management.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high dominance and objective correlation\n    objectives = np.array([obj for _, obj in archive])\n    correlation = np.corrcoef(objectives.T)[0, 1]\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    dominance_scores = np.max(normalized_objectives, axis=1)\n    combined_scores = dominance_scores * (1 + correlation)\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Value-weighted local search: explore item exchanges\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate value-to-weight ratios and correlation weights\n    value1_ratio = value1_lst / weight_lst\n    value2_ratio = value2_lst / weight_lst\n    correlation_weights = np.abs(value1_ratio - value2_ratio)\n    weighted_ratios = (value1_ratio + value2_ratio) * (1 + correlation_weights)\n    sorted_indices = np.argsort(weighted_ratios)[::-1]\n\n    # Explore exchanges by considering both high-ratio and correlation\n    for i in range(min(10, n_items)):\n        item_idx = sorted_indices[i]\n        if new_solution[item_idx] == 0 and current_weight + weight_lst[item_idx] <= capacity:\n            new_solution[item_idx] = 1\n            current_weight += weight_lst[item_idx]\n        elif new_solution[item_idx] == 1:\n            # Check if removing improves correlation\n            if np.sum(weight_lst * new_solution) - weight_lst[item_idx] <= capacity:\n                new_solution[item_idx] = 0\n                current_weight -= weight_lst[item_idx]\n\n    # Correlation-aware capacity management\n    if current_weight > capacity:\n        # Remove items with lowest weighted ratio until feasible\n        items_in_solution = np.where(new_solution == 1)[0]\n        sorted_items = items_in_solution[np.argsort(weighted_ratios[items_in_solution])]\n        for item_idx in sorted_items:\n            if current_weight <= capacity:\n                break\n            new_solution[item_idx] = 0\n            current_weight -= weight_lst[item_idx]\n\n    # Ensure at least one item remains if solution is not empty\n    if np.sum(new_solution) == 0 and n_items > 0:\n        # Add the item with highest weighted ratio\n        best_item = sorted_indices[0]\n        if weight_lst[best_item] <= capacity:\n            new_solution[best_item] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.9538587956046637,
            2.6659638583660126
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search that combines adaptive item grouping with a biased random walk, where items are first clustered by their marginal gain ratios, and then explored within these clusters to identify high-potential regions for improvement while ensuring feasibility through weight-constrained perturbations, but with a different implementation approach using a hybrid of greedy and random selection.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives with weight consideration)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    normalized_weights = (weights - np.min(weights)) / (np.max(weights) - np.min(weights) + 1e-6)\n    scores = 0.6 * np.sum(normalized_objectives, axis=1) - 0.4 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item grouping and biased random walk\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate marginal gain ratios for items not in solution with weight consideration\n    if len(items_out) > 0:\n        ratio1 = value1_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        ratio2 = value2_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        combined_ratio = ratio1 + ratio2\n        weight_ratio = combined_ratio / (weight_lst[items_out] + 1e-6)\n\n        # Cluster items by weight-adjusted marginal gain ratio\n        sorted_indices = np.argsort(weight_ratio)[::-1]\n        top_cluster = items_out[sorted_indices[:max(1, len(items_out)//3)]]\n\n        # Randomly select from top cluster with higher probability\n        if len(top_cluster) > 0:\n            for _ in range(2):\n                candidate_idx = np.random.choice(top_cluster)\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Biased random walk: remove low-contribution items with weight consideration\n    if len(items_in) > 0:\n        # Calculate contribution of each item in solution with weight consideration\n        contribution1 = value1_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        contribution2 = value2_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        combined_contribution = contribution1 + contribution2\n        weight_contribution = combined_contribution / (weight_lst[items_in] + 1e-6)\n\n        # Remove items with lowest weight-adjusted contribution\n        sorted_indices = np.argsort(weight_contribution)\n        bottom_cluster = items_in[sorted_indices[:max(1, len(items_in)//3)]]\n\n        if len(bottom_cluster) > 0:\n            for _ in range(2):\n                candidate_idx = np.random.choice(bottom_cluster)\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            # Remove items with smallest weight to contribution ratio\n            contribution_ratio = (value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6)\n            sorted_indices = np.argsort(contribution_ratio)\n            for idx in items_in_new[sorted_indices]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -1.028819091383601,
            2.9179683327674866
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a Pareto-frontier proximity score and applies a hybrid local search that combines objective-specific item additions/removals with dynamic weight balancing to explore the solution space efficiently while maintaining feasibility through constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution based on Pareto-frontier proximity\n    objectives = np.array([obj for _, obj in archive])\n    pareto_scores = np.max(objectives, axis=0) - objectives\n    selected_idx = np.argmin(np.sum(pareto_scores, axis=1))\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: objective-specific operations with dynamic balancing\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Objective 1 focused operation\n    if len(items_out) > 0:\n        candidates = items_out[np.argsort(value1_lst[items_out])[-min(5, len(items_out)):]]\n        for candidate in candidates:\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n                current_weight += weight_lst[candidate]\n                break\n\n    # Objective 2 focused operation\n    if len(items_out) > 0:\n        candidates = items_out[np.argsort(value2_lst[items_out])[-min(5, len(items_out)):]]\n        for candidate in candidates:\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n                current_weight += weight_lst[candidate]\n                break\n\n    # Dynamic weight balancing\n    if len(items_in) > 0 and current_weight > 0.7 * capacity:\n        candidates = items_in[np.argsort(weight_lst[items_in])[:min(3, len(items_in))]]\n        for candidate in candidates:\n            new_solution[candidate] = 0\n            current_weight -= weight_lst[candidate]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        removal_order = np.argsort(weight_lst[items_in_new])\n        for idx in items_in_new[removal_order]:\n            if excess <= 0:\n                break\n            new_solution[idx] = 0\n            excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.977883289799175,
            0.8179505467414856
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its objective balance and weight efficiency, then applies a novel multi-objective local search that explores item combinations by considering both profit ratios and weight distribution, ensuring feasibility through iterative adjustments and balance-aware capacity management.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high objective balance and weight efficiency\n    objectives = np.array([obj for _, obj in archive])\n    balance_scores = objectives[:, 0] / (objectives[:, 1] + 1e-6)\n    weight_efficiency = np.sum(weight_lst * archive[0][0]) / capacity\n    combined_scores = balance_scores * (1 + weight_efficiency)\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Multi-objective local search: explore item combinations\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate value-to-weight ratios and balance weights\n    value1_ratio = value1_lst / weight_lst\n    value2_ratio = value2_lst / weight_lst\n    balance_weights = np.abs(value1_ratio - value2_ratio)\n    weighted_ratios = (value1_ratio + value2_ratio) * (1 + balance_weights)\n    sorted_indices = np.argsort(weighted_ratios)[::-1]\n\n    # Explore combinations by considering both high-ratio and balance\n    for i in range(min(10, n_items)):\n        item_idx = sorted_indices[i]\n        if new_solution[item_idx] == 0 and current_weight + weight_lst[item_idx] <= capacity:\n            new_solution[item_idx] = 1\n            current_weight += weight_lst[item_idx]\n        elif new_solution[item_idx] == 1:\n            # Check if removing improves balance\n            if np.sum(weight_lst * new_solution) - weight_lst[item_idx] <= capacity:\n                new_solution[item_idx] = 0\n                current_weight -= weight_lst[item_idx]\n\n    # Balance-aware capacity management\n    if current_weight > capacity:\n        # Remove items with lowest weighted ratio until feasible\n        items_in_solution = np.where(new_solution == 1)[0]\n        sorted_items = items_in_solution[np.argsort(weighted_ratios[items_in_solution])]\n        for item_idx in sorted_items:\n            if current_weight <= capacity:\n                break\n            new_solution[item_idx] = 0\n            current_weight -= weight_lst[item_idx]\n\n    # Ensure at least one item remains if solution is not empty\n    if np.sum(new_solution) == 0 and n_items > 0:\n        # Add the item with highest weighted ratio\n        best_item = sorted_indices[0]\n        if weight_lst[best_item] <= capacity:\n            new_solution[best_item] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.9206211040861535,
            0.7854538857936859
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a Pareto-frontier proximity score and applies a hybrid local search that combines objective-specific item additions/removals with dynamic weight balancing to explore the solution space efficiently while maintaining feasibility through constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution based on Pareto-frontier proximity\n    objectives = np.array([obj for _, obj in archive])\n    pareto_scores = np.max(objectives, axis=0) - objectives\n    selected_idx = np.argmin(np.sum(pareto_scores, axis=1))\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: objective-specific operations with dynamic balancing\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Objective 1 focused operation\n    if len(items_out) > 0:\n        candidates = items_out[np.argsort(value1_lst[items_out])[-min(5, len(items_out)):]]\n        for candidate in candidates:\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n                current_weight += weight_lst[candidate]\n                break\n\n    # Objective 2 focused operation\n    if len(items_out) > 0:\n        candidates = items_out[np.argsort(value2_lst[items_out])[-min(5, len(items_out)):]]\n        for candidate in candidates:\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n                current_weight += weight_lst[candidate]\n                break\n\n    # Dynamic weight balancing\n    if len(items_in) > 0 and current_weight > 0.7 * capacity:\n        candidates = items_in[np.argsort(weight_lst[items_in])[:min(3, len(items_in))]]\n        for candidate in candidates:\n            new_solution[candidate] = 0\n            current_weight -= weight_lst[candidate]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        removal_order = np.argsort(weight_lst[items_in_new])\n        for idx in items_in_new[removal_order]:\n            if excess <= 0:\n                break\n            new_solution[idx] = 0\n            excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.977883289799175,
            0.8179505467414856
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search that combines adaptive item grouping with a biased random walk, where items are first clustered by their marginal gain ratios, and then explored within these clusters to identify high-potential regions for improvement while ensuring feasibility through weight-constrained perturbations, but with a different implementation approach using a hybrid of greedy and random selection.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives with weight consideration)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    normalized_weights = (weights - np.min(weights)) / (np.max(weights) - np.min(weights) + 1e-6)\n    scores = 0.6 * np.sum(normalized_objectives, axis=1) - 0.4 * normalized_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item grouping and biased random walk\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate marginal gain ratios for items not in solution with weight consideration\n    if len(items_out) > 0:\n        ratio1 = value1_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        ratio2 = value2_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        combined_ratio = ratio1 + ratio2\n        weight_ratio = combined_ratio / (weight_lst[items_out] + 1e-6)\n\n        # Cluster items by weight-adjusted marginal gain ratio\n        sorted_indices = np.argsort(weight_ratio)[::-1]\n        top_cluster = items_out[sorted_indices[:max(1, len(items_out)//3)]]\n\n        # Randomly select from top cluster with higher probability\n        if len(top_cluster) > 0:\n            for _ in range(2):\n                candidate_idx = np.random.choice(top_cluster)\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Biased random walk: remove low-contribution items with weight consideration\n    if len(items_in) > 0:\n        # Calculate contribution of each item in solution with weight consideration\n        contribution1 = value1_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        contribution2 = value2_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        combined_contribution = contribution1 + contribution2\n        weight_contribution = combined_contribution / (weight_lst[items_in] + 1e-6)\n\n        # Remove items with lowest weight-adjusted contribution\n        sorted_indices = np.argsort(weight_contribution)\n        bottom_cluster = items_in[sorted_indices[:max(1, len(items_in)//3)]]\n\n        if len(bottom_cluster) > 0:\n            for _ in range(2):\n                candidate_idx = np.random.choice(bottom_cluster)\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            # Remove items with smallest weight to contribution ratio\n            contribution_ratio = (value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6)\n            sorted_indices = np.argsort(contribution_ratio)\n            for idx in items_in_new[sorted_indices]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -1.028819091383601,
            2.9179683327674866
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a Pareto-frontier proximity score and applies a hybrid local search that combines objective-specific item additions/removals with dynamic weight balancing to explore the solution space efficiently while maintaining feasibility through constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution based on Pareto-frontier proximity\n    objectives = np.array([obj for _, obj in archive])\n    pareto_scores = np.max(objectives, axis=0) - objectives\n    selected_idx = np.argmin(np.sum(pareto_scores, axis=1))\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: objective-specific operations with dynamic balancing\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Objective 1 focused operation\n    if len(items_out) > 0:\n        candidates = items_out[np.argsort(value1_lst[items_out])[-min(5, len(items_out)):]]\n        for candidate in candidates:\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n                current_weight += weight_lst[candidate]\n                break\n\n    # Objective 2 focused operation\n    if len(items_out) > 0:\n        candidates = items_out[np.argsort(value2_lst[items_out])[-min(5, len(items_out)):]]\n        for candidate in candidates:\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n                current_weight += weight_lst[candidate]\n                break\n\n    # Dynamic weight balancing\n    if len(items_in) > 0 and current_weight > 0.7 * capacity:\n        candidates = items_in[np.argsort(weight_lst[items_in])[:min(3, len(items_in))]]\n        for candidate in candidates:\n            new_solution[candidate] = 0\n            current_weight -= weight_lst[candidate]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        removal_order = np.argsort(weight_lst[items_in_new])\n        for idx in items_in_new[removal_order]:\n            if excess <= 0:\n                break\n            new_solution[idx] = 0\n            excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.977883289799175,
            0.8179505467414856
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a Pareto-frontier proximity score and applies a hybrid local search that combines objective-specific item additions/removals with dynamic weight balancing to explore the solution space efficiently while maintaining feasibility through constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution based on Pareto-frontier proximity\n    objectives = np.array([obj for _, obj in archive])\n    pareto_scores = np.max(objectives, axis=0) - objectives\n    selected_idx = np.argmin(np.sum(pareto_scores, axis=1))\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: objective-specific operations with dynamic balancing\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Objective 1 focused operation\n    if len(items_out) > 0:\n        candidates = items_out[np.argsort(value1_lst[items_out])[-min(5, len(items_out)):]]\n        for candidate in candidates:\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n                current_weight += weight_lst[candidate]\n                break\n\n    # Objective 2 focused operation\n    if len(items_out) > 0:\n        candidates = items_out[np.argsort(value2_lst[items_out])[-min(5, len(items_out)):]]\n        for candidate in candidates:\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n                current_weight += weight_lst[candidate]\n                break\n\n    # Dynamic weight balancing\n    if len(items_in) > 0 and current_weight > 0.7 * capacity:\n        candidates = items_in[np.argsort(weight_lst[items_in])[:min(3, len(items_in))]]\n        for candidate in candidates:\n            new_solution[candidate] = 0\n            current_weight -= weight_lst[candidate]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        removal_order = np.argsort(weight_lst[items_in_new])\n        for idx in items_in_new[removal_order]:\n            if excess <= 0:\n                break\n            new_solution[idx] = 0\n            excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.977883289799175,
            0.8179505467414856
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a Pareto-frontier proximity score and applies a hybrid local search that combines objective-specific item additions/removals with dynamic weight balancing to explore the solution space efficiently while maintaining feasibility through constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution based on Pareto-frontier proximity\n    objectives = np.array([obj for _, obj in archive])\n    pareto_scores = np.max(objectives, axis=0) - objectives\n    selected_idx = np.argmin(np.sum(pareto_scores, axis=1))\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: objective-specific operations with dynamic balancing\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Objective 1 focused operation\n    if len(items_out) > 0:\n        candidates = items_out[np.argsort(value1_lst[items_out])[-min(5, len(items_out)):]]\n        for candidate in candidates:\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n                current_weight += weight_lst[candidate]\n                break\n\n    # Objective 2 focused operation\n    if len(items_out) > 0:\n        candidates = items_out[np.argsort(value2_lst[items_out])[-min(5, len(items_out)):]]\n        for candidate in candidates:\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n                current_weight += weight_lst[candidate]\n                break\n\n    # Dynamic weight balancing\n    if len(items_in) > 0 and current_weight > 0.7 * capacity:\n        candidates = items_in[np.argsort(weight_lst[items_in])[:min(3, len(items_in))]]\n        for candidate in candidates:\n            new_solution[candidate] = 0\n            current_weight -= weight_lst[candidate]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        removal_order = np.argsort(weight_lst[items_in_new])\n        for idx in items_in_new[removal_order]:\n            if excess <= 0:\n                break\n            new_solution[idx] = 0\n            excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.977883289799175,
            0.8179505467414856
        ]
    }
]