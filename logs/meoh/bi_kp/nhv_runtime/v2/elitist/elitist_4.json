[
    {
        "algorithm": "{The algorithm selects a promising solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search strategy that combines weight-balanced flips and objective-driven additions to explore the solution space while ensuring feasibility through adaptive capacity management.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    scores = np.sum(normalized_objectives, axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight and remaining capacity\n    current_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Novel local search strategy: weight-balanced flips and objective-driven additions\n    new_solution = base_solution.copy()\n    items = np.where(new_solution == 1)[0]\n    non_items = np.where(new_solution == 0)[0]\n\n    # Calculate value-to-weight ratios for non-included items\n    if len(non_items) > 0:\n        value1_ratio = value1_lst[non_items] / weight_lst[non_items]\n        value2_ratio = value2_lst[non_items] / weight_lst[non_items]\n\n        # Select top 5 items with highest combined value-to-weight ratios\n        combined_ratio = value1_ratio + value2_ratio\n        top_indices = np.argsort(combined_ratio)[-min(5, len(combined_ratio)):][::-1]\n        for idx in top_indices:\n            item_idx = non_items[idx]\n            if weight_lst[item_idx] <= remaining_capacity:\n                new_solution[item_idx] = 1\n                remaining_capacity -= weight_lst[item_idx]\n\n    # Adaptive capacity management: remove items with lowest ratio if still over capacity\n    if remaining_capacity < 0:\n        items_in_solution = np.where(new_solution == 1)[0]\n        if len(items_in_solution) > 0:\n            value1_ratio = value1_lst[items_in_solution] / weight_lst[items_in_solution]\n            value2_ratio = value2_lst[items_in_solution] / weight_lst[items_in_solution]\n            combined_ratio = value1_ratio + value2_ratio\n            sorted_indices = np.argsort(combined_ratio)\n\n            for idx in sorted_indices:\n                item_idx = items_in_solution[idx]\n                new_solution[item_idx] = 0\n                remaining_capacity += weight_lst[item_idx]\n                if remaining_capacity >= 0:\n                    break\n\n    # Weight-balanced flips: randomly flip 2 items with weight close to remaining capacity\n    if len(items) > 0:\n        flip_candidates = [i for i in items if abs(weight_lst[i] - remaining_capacity) < 0.1 * capacity]\n        if len(flip_candidates) > 0:\n            flip_indices = random.sample(flip_candidates, min(2, len(flip_candidates)))\n            for idx in flip_indices:\n                new_solution[idx] = 0\n                remaining_capacity += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.887089948480458,
            1.368062973022461
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its diversity and objective balance, then applies a novel path-based local search that explores item sequences by considering both profit ratios and weight distribution, ensuring feasibility through iterative adjustments and adaptive capacity management.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high diversity and balanced objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    diversity_scores = np.std(normalized_objectives, axis=1)\n    combined_scores = np.sum(normalized_objectives, axis=1) * diversity_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Path-based local search: explore item sequences\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate value-to-weight ratios and sort items\n    value1_ratio = value1_lst / weight_lst\n    value2_ratio = value2_lst / weight_lst\n    combined_ratio = value1_ratio + value2_ratio\n    sorted_indices = np.argsort(combined_ratio)[::-1]\n\n    # Explore paths by considering both high-ratio and weight-distribution\n    for i in range(min(10, n_items)):\n        item_idx = sorted_indices[i]\n        if new_solution[item_idx] == 0 and current_weight + weight_lst[item_idx] <= capacity:\n            new_solution[item_idx] = 1\n            current_weight += weight_lst[item_idx]\n        elif new_solution[item_idx] == 1:\n            # Check if removing improves balance\n            if np.sum(weight_lst * new_solution) - weight_lst[item_idx] <= capacity:\n                new_solution[item_idx] = 0\n                current_weight -= weight_lst[item_idx]\n\n    # Adaptive capacity management: adjust if over capacity\n    if current_weight > capacity:\n        # Remove items with lowest combined ratio until feasible\n        items_in_solution = np.where(new_solution == 1)[0]\n        sorted_items = items_in_solution[np.argsort(combined_ratio[items_in_solution])]\n        for item_idx in sorted_items:\n            if current_weight <= capacity:\n                break\n            new_solution[item_idx] = 0\n            current_weight -= weight_lst[item_idx]\n\n    # Ensure at least one item remains if solution is not empty\n    if np.sum(new_solution) == 0 and n_items > 0:\n        # Add the item with highest combined ratio\n        best_item = sorted_indices[0]\n        if weight_lst[best_item] <= capacity:\n            new_solution[best_item] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.9073684361272066,
            1.9762572944164276
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a weighted combination of objective values and weight utilization, then applies a novel local search that uses dynamic item prioritization and probabilistic perturbation to explore high-potential regions while maintaining feasibility through adaptive weight constraints.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (weighted combination of objectives and weight utilization)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_weights = weights / capacity\n    weighted_scores = 0.6 * objectives[:, 0] + 0.4 * objectives[:, 1] - 0.3 * normalized_weights\n    selected_idx = np.argmax(weighted_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dynamic item prioritization and probabilistic perturbation\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate dynamic priorities for items not in solution\n    if len(items_out) > 0:\n        priority_scores = (value1_lst[items_out] + value2_lst[items_out]) / (weight_lst[items_out] + 1e-6)\n        sorted_indices = np.argsort(priority_scores)[::-1]\n        top_items = items_out[sorted_indices[:max(1, len(items_out)//4)]]\n\n        # Add items with probability proportional to their priority\n        for idx in top_items:\n            if np.random.rand() < 0.7 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Probabilistic removal of low-priority items\n    if len(items_in) > 0:\n        removal_scores = (value1_lst[items_in] + value2_lst[items_in]) / (weight_lst[items_in] + 1e-6)\n        sorted_indices = np.argsort(removal_scores)\n        bottom_items = items_in[sorted_indices[:max(1, len(items_in)//3)]]\n\n        for idx in bottom_items:\n            if np.random.rand() < 0.5:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Adaptive weight constraint enforcement\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            removal_order = np.argsort((value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6))\n            for idx in items_in_new[removal_order]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.951269370000086,
            2.5577997267246246
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on a hybrid of objective diversity and weight distribution, then applies a novel multi-phase local search that first explores high-value items, then refines the solution through adaptive swaps and finally performs a targeted weight-balancing phase while always maintaining feasibility through dynamic capacity checks.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution based on hybrid of objective diversity and weight distribution\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    diversity_scores = np.std(objectives, axis=0)\n    weight_scores = (capacity - weights) / capacity\n    combined_scores = 0.6 * diversity_scores[0] + 0.4 * weight_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Phase 1: High-value item exploration\n    non_items = np.where(new_solution == 0)[0]\n    if len(non_items) > 0:\n        # Calculate normalized value scores\n        value1_scores = value1_lst[non_items] / np.max(value1_lst[non_items] + 1e-6)\n        value2_scores = value2_lst[non_items] / np.max(value2_lst[non_items] + 1e-6)\n        combined_scores = 0.7 * value1_scores + 0.3 * value2_scores\n\n        # Select top 3 items with highest combined scores\n        top_indices = np.argsort(combined_scores)[-min(3, len(combined_scores)):][::-1]\n        for idx in top_indices:\n            item_idx = non_items[idx]\n            if weight_lst[item_idx] <= remaining_capacity:\n                new_solution[item_idx] = 1\n                remaining_capacity -= weight_lst[item_idx]\n\n    # Phase 2: Adaptive swaps\n    items = np.where(new_solution == 1)[0]\n    if len(items) > 1 and len(non_items) > 0:\n        # Find items with low marginal contribution\n        marginal_value1 = value1_lst[items] / weight_lst[items]\n        marginal_value2 = value2_lst[items] / weight_lst[items]\n        low_contrib = np.argsort(marginal_value1 + marginal_value2)[:min(2, len(items))]\n\n        for i in low_contrib:\n            item_idx = items[i]\n            new_solution[item_idx] = 0\n            remaining_capacity += weight_lst[item_idx]\n\n            # Try to add better items\n            add_candidates = [idx for idx in non_items if weight_lst[idx] <= remaining_capacity]\n            if add_candidates:\n                best_candidate = max(add_candidates, key=lambda x: (value1_lst[x] + value2_lst[x]) / weight_lst[x])\n                new_solution[best_candidate] = 1\n                remaining_capacity -= weight_lst[best_candidate]\n\n    # Phase 3: Targeted weight balancing\n    if remaining_capacity > 0:\n        # Add items that best fill the remaining capacity\n        add_candidates = [idx for idx in non_items if weight_lst[idx] <= remaining_capacity]\n        if add_candidates:\n            best_candidate = max(add_candidates, key=lambda x: abs(weight_lst[x] - remaining_capacity))\n            new_solution[best_candidate] = 1\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        items = np.where(new_solution == 1)[0]\n        if len(items) > 0:\n            largest_items = np.argsort(weight_lst[items])[::-1]\n            for i in largest_items:\n                item_idx = items[i]\n                new_solution[item_idx] = 0\n                current_weight -= weight_lst[item_idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.9279519598685808,
            5.768968194723129
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its objective diversity and applies a novel \"objective-balanced perturbation\" strategy that dynamically adjusts item inclusion/exclusion based on both objective values and weight, while ensuring feasibility through a greedy repair mechanism.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high objective diversity (large difference between value1 and value2)\n    objectives = np.array([obj for _, obj in archive])\n    diversity = np.abs(objectives[:, 0] - objectives[:, 1])\n    selected_idx = np.argmax(diversity)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Objective-balanced perturbation: prioritize items that improve both objectives\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    # Calculate improvement potential for each objective\n    if len(excluded_items) > 0:\n        value1_improvement = value1_lst[excluded_items] / weight_lst[excluded_items]\n        value2_improvement = value2_lst[excluded_items] / weight_lst[excluded_items]\n        combined_improvement = value1_improvement + value2_improvement\n        best_candidates = np.argsort(combined_improvement)[-min(3, len(combined_improvement)):][::-1]\n\n        for idx in best_candidates:\n            item_idx = excluded_items[idx]\n            if current_weight + weight_lst[item_idx] <= capacity:\n                new_solution[item_idx] = 1\n                current_weight += weight_lst[item_idx]\n\n    # Remove items with the worst combined value-to-weight ratio if over capacity\n    if current_weight > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        value1_ratio = value1_lst[included_items] / weight_lst[included_items]\n        value2_ratio = value2_lst[included_items] / weight_lst[included_items]\n        combined_ratio = value1_ratio + value2_ratio\n        worst_idx = np.argmin(combined_ratio)\n        while current_weight > capacity and len(included_items) > 0:\n            item_idx = included_items[worst_idx]\n            new_solution[item_idx] = 0\n            current_weight -= weight_lst[item_idx]\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) > 0:\n                value1_ratio = value1_lst[included_items] / weight_lst[included_items]\n                value2_ratio = value2_lst[included_items] / weight_lst[included_items]\n                combined_ratio = value1_ratio + value2_ratio\n                worst_idx = np.argmin(combined_ratio)\n\n    # Randomly flip 1-2 items to maintain solution diversity\n    if len(included_items) > 0:\n        flip_indices = random.sample(range(n_items), min(2, n_items))\n        for idx in flip_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.6370963098749947,
            1.411782592535019
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search that combines adaptive item grouping with a biased random walk, where items are first clustered by their marginal gain ratios, and then explored within these clusters to identify high-potential regions for improvement while ensuring feasibility through weight-constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    scores = np.sum(normalized_objectives, axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item grouping and biased random walk\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate marginal gain ratios for items not in solution\n    if len(items_out) > 0:\n        ratio1 = value1_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        ratio2 = value2_lst[items_out] / (weight_lst[items_out] + 1e-6)\n        combined_ratio = ratio1 + ratio2\n\n        # Cluster items by marginal gain ratio\n        sorted_indices = np.argsort(combined_ratio)[::-1]\n        top_cluster = items_out[sorted_indices[:max(1, len(items_out)//3)]]\n\n        # Randomly select from top cluster with higher probability\n        if len(top_cluster) > 0:\n            for _ in range(2):\n                candidate_idx = np.random.choice(top_cluster)\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Biased random walk: remove low-contribution items\n    if len(items_in) > 0:\n        # Calculate contribution of each item in solution\n        contribution1 = value1_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        contribution2 = value2_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        combined_contribution = contribution1 + contribution2\n\n        # Remove items with lowest contribution\n        sorted_indices = np.argsort(combined_contribution)\n        bottom_cluster = items_in[sorted_indices[:max(1, len(items_in)//3)]]\n\n        if len(bottom_cluster) > 0:\n            for _ in range(2):\n                candidate_idx = np.random.choice(bottom_cluster)\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            # Remove items with smallest weight to contribution ratio\n            contribution_ratio = (value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6)\n            sorted_indices = np.argsort(contribution_ratio)\n            for idx in items_in_new[sorted_indices]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8573593365299407,
            1.7612662315368652
        ]
    },
    {
        "algorithm": "{This algorithm intelligently selects a solution from the archive with high potential for improvement by evaluating the solution's \"frontier\" status (non-dominated but close to the Pareto front) and applies a hybrid local search operator that combines item swaps with adaptive perturbation to explore the solution space while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution (non-dominated with high potential)\n    # We prioritize solutions that are on the frontier (non-dominated but close to the Pareto front)\n    # and have not been fully explored (i.e., not all bits are 1 or 0)\n    frontier_solutions = []\n    for sol, _ in archive:\n        if np.sum(sol) > 0 and np.sum(sol) < len(sol):\n            frontier_solutions.append(sol)\n\n    if not frontier_solutions:\n        frontier_solutions = [sol for sol, _ in archive]\n\n    # Randomly select a solution from the frontier\n    base_solution = random.choice(frontier_solutions).copy()\n\n    # Step 2: Generate a neighbor using a hybrid local search operator\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Hybrid operator: Randomly select a subset of items to flip (swap 0s and 1s)\n    # with adaptive size based on the current solution's density\n    density = np.sum(base_solution) / n_items\n    flip_size = max(1, int(0.1 * n_items * (1 - density)))  # More flips for sparse solutions\n\n    # Randomly select flip_size items to flip\n    flip_indices = random.sample(range(n_items), flip_size)\n\n    # Flip the selected items\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            # If removing the item keeps the solution feasible, do it\n            if np.sum(weight_lst * base_solution) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            # If adding the item keeps the solution feasible, do it\n            if np.sum(weight_lst * base_solution) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Ensure feasibility (should not be needed due to checks above, but just in case)\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove items randomly until feasible\n        excess = np.sum(weight_lst * new_solution) - capacity\n        current_weight = np.sum(weight_lst * new_solution)\n        while current_weight > capacity:\n            # Remove the heaviest item that can be removed without making the solution empty\n            if np.sum(new_solution) == 1:\n                break  # Cannot remove more items\n            heavy_items = np.where(new_solution == 1)[0]\n            heaviest_idx = heavy_items[np.argmax(weight_lst[heavy_items])]\n            new_solution[heaviest_idx] = 0\n            current_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n",
        "score": [
            -0.578022104383614,
            1.7531713843345642
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive by prioritizing those with high diversity in their objective values and low weight utilization, then applies a novel local search that combines adaptive item reallocation with a biased random walk, where items are first clustered by their weight-to-value ratios, and then explored within these clusters to identify high-potential regions for improvement while ensuring feasibility through weight-constrained perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high diversity in objectives and low weight utilization\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    diversity = np.std(objectives, axis=0)\n    scores = diversity[0] + diversity[1] - weights / capacity\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive item reallocation\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Cluster items by weight-to-value ratio\n    if len(items_out) > 0:\n        ratio1 = weight_lst[items_out] / (value1_lst[items_out] + 1e-6)\n        ratio2 = weight_lst[items_out] / (value2_lst[items_out] + 1e-6)\n        combined_ratio = ratio1 + ratio2\n        sorted_indices = np.argsort(combined_ratio)\n        top_cluster = items_out[sorted_indices[:max(1, len(items_out)//4)]]\n\n        # Randomly select from top cluster with higher probability\n        if len(top_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(top_cluster)\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Biased random walk: remove low-contribution items\n    if len(items_in) > 0:\n        contribution1 = value1_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        contribution2 = value2_lst[items_in] / (weight_lst[items_in] + 1e-6)\n        combined_contribution = contribution1 + contribution2\n        sorted_indices = np.argsort(combined_contribution)\n        bottom_cluster = items_in[sorted_indices[:max(1, len(items_in)//4)]]\n\n        if len(bottom_cluster) > 0:\n            for _ in range(3):\n                candidate_idx = np.random.choice(bottom_cluster)\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            contribution_ratio = (value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6)\n            sorted_indices = np.argsort(contribution_ratio)\n            for idx in items_in_new[sorted_indices]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8991984430012842,
            3.4054389595985413
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a combined score of objective values and diversity, then applies a novel \"value-driven perturbation\" strategy that intelligently removes low-value items and adds high-value items from different objective perspectives, while ensuring feasibility through a dynamic capacity adjustment mechanism.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high combined objective values and diversity\n    objectives = np.array([obj for _, obj in archive])\n    diversity_scores = np.array([np.sum(sol) / len(sol) for sol, _ in archive])\n    combined_scores = np.sum(objectives, axis=1) * (1 + diversity_scores)\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Value-driven perturbation strategy\n    # 1. Remove lowest-value items from both objectives\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate value ratios for both objectives\n        value1_ratio = value1_lst[included_items] / weight_lst[included_items]\n        value2_ratio = value2_lst[included_items] / weight_lst[included_items]\n\n        # Remove items with lowest combined value ratio\n        combined_ratio = value1_ratio + value2_ratio\n        sorted_indices = np.argsort(combined_ratio)\n        for idx in sorted_indices[:max(1, len(sorted_indices)//3)]:\n            item_idx = included_items[idx]\n            new_solution[item_idx] = 0\n            remaining_capacity += weight_lst[item_idx]\n\n    # 2. Add high-value items from both objectives\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value ratios for both objectives\n        value1_ratio = value1_lst[excluded_items] / weight_lst[excluded_items]\n        value2_ratio = value2_lst[excluded_items] / weight_lst[excluded_items]\n\n        # Consider items from both perspectives\n        top_value1 = np.argsort(value1_ratio)[-min(3, len(value1_ratio)):][::-1]\n        top_value2 = np.argsort(value2_ratio)[-min(3, len(value2_ratio)):][::-1]\n\n        # Combine and prioritize unique items\n        candidate_items = np.union1d(top_value1, top_value2)\n        for idx in candidate_items:\n            item_idx = excluded_items[idx]\n            if weight_lst[item_idx] <= remaining_capacity:\n                new_solution[item_idx] = 1\n                remaining_capacity -= weight_lst[item_idx]\n\n    # Dynamic capacity adjustment if still over capacity\n    if remaining_capacity < 0:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest combined value ratio\n            value1_ratio = value1_lst[included_items] / weight_lst[included_items]\n            value2_ratio = value2_lst[included_items] / weight_lst[included_items]\n            combined_ratio = value1_ratio + value2_ratio\n            sorted_indices = np.argsort(combined_ratio)\n\n            for idx in sorted_indices:\n                item_idx = included_items[idx]\n                new_solution[item_idx] = 0\n                remaining_capacity += weight_lst[item_idx]\n                if remaining_capacity >= 0:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.8741260514786036,
            2.3183581829071045
        ]
    },
    {
        "algorithm": "{This algorithm selects a promising solution from the archive by prioritizing those with high \"trade-off potential\" (items with significant differences in value1 and value2) and applies a novel \"value-balanced perturbation\" operator, which selectively flips items based on their marginal contribution to both objectives while ensuring feasibility through adaptive weight adjustment.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution with high trade-off potential\n    trade_off_scores = []\n    for sol, _ in archive:\n        selected_items = np.where(sol == 1)[0]\n        if len(selected_items) == 0:\n            trade_off_scores.append(0)\n            continue\n        # Calculate trade-off potential: average difference in value ratios\n        value1_ratios = value1_lst[selected_items] / weight_lst[selected_items]\n        value2_ratios = value2_lst[selected_items] / weight_lst[selected_items]\n        trade_off_scores.append(np.mean(np.abs(value1_ratios - value2_ratios)))\n\n    # Select solution with highest trade-off potential\n    base_solution = archive[np.argmax(trade_off_scores)][0].copy()\n\n    # Step 2: Generate neighbor using value-balanced perturbation\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Calculate marginal contributions for both objectives\n    marginal1 = value1_lst / weight_lst\n    marginal2 = value2_lst / weight_lst\n\n    # Calculate balance factor for each item\n    balance_factors = np.abs(marginal1 - marginal2)\n\n    # Select items to perturb based on balance factors and current selection\n    selected_items = np.where(base_solution == 1)[0]\n    unselected_items = np.where(base_solution == 0)[0]\n\n    # Perturbation size based on solution density\n    density = np.sum(base_solution) / n_items\n    perturb_size = max(1, int(0.2 * n_items * (1 - density)))\n\n    # Select items to flip based on highest balance factors\n    if len(selected_items) > 0:\n        # Consider flipping selected items with low balance factors\n        flip_candidates = np.concatenate([selected_items, unselected_items])\n        flip_scores = balance_factors[flip_candidates]\n        flip_indices = flip_candidates[np.argsort(flip_scores)[:perturb_size]]\n    else:\n        # If no items selected, pick from unselected items\n        flip_indices = random.sample(list(unselected_items), min(perturb_size, len(unselected_items)))\n\n    # Flip selected items while maintaining feasibility\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            # Remove item if it's not critical (weight <= capacity when removed)\n            if np.sum(weight_lst * base_solution) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            # Add item if it fits\n            if np.sum(weight_lst * base_solution) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Final feasibility check (shouldn't be needed due to checks above)\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items with lowest balance factors until feasible\n        while current_weight > capacity:\n            selected_items = np.where(new_solution == 1)[0]\n            if len(selected_items) == 0:\n                break\n            remove_idx = selected_items[np.argmin(balance_factors[selected_items])]\n            new_solution[remove_idx] = 0\n            current_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n",
        "score": [
            -0.8844218945973816,
            7.053120881319046
        ]
    },
    {
        "algorithm": "{The algorithm selects a promising solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search strategy that combines weight-balanced flips and objective-driven additions to explore the solution space while ensuring feasibility through adaptive capacity management.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    scores = np.sum(normalized_objectives, axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight and remaining capacity\n    current_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Novel local search strategy: weight-balanced flips and objective-driven additions\n    new_solution = base_solution.copy()\n    items = np.where(new_solution == 1)[0]\n    non_items = np.where(new_solution == 0)[0]\n\n    # Calculate value-to-weight ratios for non-included items\n    if len(non_items) > 0:\n        value1_ratio = value1_lst[non_items] / weight_lst[non_items]\n        value2_ratio = value2_lst[non_items] / weight_lst[non_items]\n\n        # Select top 5 items with highest combined value-to-weight ratios\n        combined_ratio = value1_ratio + value2_ratio\n        top_indices = np.argsort(combined_ratio)[-min(5, len(combined_ratio)):][::-1]\n        for idx in top_indices:\n            item_idx = non_items[idx]\n            if weight_lst[item_idx] <= remaining_capacity:\n                new_solution[item_idx] = 1\n                remaining_capacity -= weight_lst[item_idx]\n\n    # Adaptive capacity management: remove items with lowest ratio if still over capacity\n    if remaining_capacity < 0:\n        items_in_solution = np.where(new_solution == 1)[0]\n        if len(items_in_solution) > 0:\n            value1_ratio = value1_lst[items_in_solution] / weight_lst[items_in_solution]\n            value2_ratio = value2_lst[items_in_solution] / weight_lst[items_in_solution]\n            combined_ratio = value1_ratio + value2_ratio\n            sorted_indices = np.argsort(combined_ratio)\n\n            for idx in sorted_indices:\n                item_idx = items_in_solution[idx]\n                new_solution[item_idx] = 0\n                remaining_capacity += weight_lst[item_idx]\n                if remaining_capacity >= 0:\n                    break\n\n    # Weight-balanced flips: randomly flip 2 items with weight close to remaining capacity\n    if len(items) > 0:\n        flip_candidates = [i for i in items if abs(weight_lst[i] - remaining_capacity) < 0.1 * capacity]\n        if len(flip_candidates) > 0:\n            flip_indices = random.sample(flip_candidates, min(2, len(flip_candidates)))\n            for idx in flip_indices:\n                new_solution[idx] = 0\n                remaining_capacity += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.887089948480458,
            1.368062973022461
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its diversity and objective balance, then applies a novel path-based local search that explores item sequences by considering both profit ratios and weight distribution, ensuring feasibility through iterative adjustments and adaptive capacity management.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high diversity and balanced objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    diversity_scores = np.std(normalized_objectives, axis=1)\n    combined_scores = np.sum(normalized_objectives, axis=1) * diversity_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Path-based local search: explore item sequences\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate value-to-weight ratios and sort items\n    value1_ratio = value1_lst / weight_lst\n    value2_ratio = value2_lst / weight_lst\n    combined_ratio = value1_ratio + value2_ratio\n    sorted_indices = np.argsort(combined_ratio)[::-1]\n\n    # Explore paths by considering both high-ratio and weight-distribution\n    for i in range(min(10, n_items)):\n        item_idx = sorted_indices[i]\n        if new_solution[item_idx] == 0 and current_weight + weight_lst[item_idx] <= capacity:\n            new_solution[item_idx] = 1\n            current_weight += weight_lst[item_idx]\n        elif new_solution[item_idx] == 1:\n            # Check if removing improves balance\n            if np.sum(weight_lst * new_solution) - weight_lst[item_idx] <= capacity:\n                new_solution[item_idx] = 0\n                current_weight -= weight_lst[item_idx]\n\n    # Adaptive capacity management: adjust if over capacity\n    if current_weight > capacity:\n        # Remove items with lowest combined ratio until feasible\n        items_in_solution = np.where(new_solution == 1)[0]\n        sorted_items = items_in_solution[np.argsort(combined_ratio[items_in_solution])]\n        for item_idx in sorted_items:\n            if current_weight <= capacity:\n                break\n            new_solution[item_idx] = 0\n            current_weight -= weight_lst[item_idx]\n\n    # Ensure at least one item remains if solution is not empty\n    if np.sum(new_solution) == 0 and n_items > 0:\n        # Add the item with highest combined ratio\n        best_item = sorted_indices[0]\n        if weight_lst[best_item] <= capacity:\n            new_solution[best_item] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.9073684361272066,
            1.9762572944164276
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a weighted combination of objective values and weight utilization, then applies a novel local search that uses dynamic item prioritization and probabilistic perturbation to explore high-potential regions while maintaining feasibility through adaptive weight constraints.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (weighted combination of objectives and weight utilization)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_weights = weights / capacity\n    weighted_scores = 0.6 * objectives[:, 0] + 0.4 * objectives[:, 1] - 0.3 * normalized_weights\n    selected_idx = np.argmax(weighted_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dynamic item prioritization and probabilistic perturbation\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate dynamic priorities for items not in solution\n    if len(items_out) > 0:\n        priority_scores = (value1_lst[items_out] + value2_lst[items_out]) / (weight_lst[items_out] + 1e-6)\n        sorted_indices = np.argsort(priority_scores)[::-1]\n        top_items = items_out[sorted_indices[:max(1, len(items_out)//4)]]\n\n        # Add items with probability proportional to their priority\n        for idx in top_items:\n            if np.random.rand() < 0.7 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Probabilistic removal of low-priority items\n    if len(items_in) > 0:\n        removal_scores = (value1_lst[items_in] + value2_lst[items_in]) / (weight_lst[items_in] + 1e-6)\n        sorted_indices = np.argsort(removal_scores)\n        bottom_items = items_in[sorted_indices[:max(1, len(items_in)//3)]]\n\n        for idx in bottom_items:\n            if np.random.rand() < 0.5:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Adaptive weight constraint enforcement\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            removal_order = np.argsort((value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6))\n            for idx in items_in_new[removal_order]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.951269370000086,
            2.5577997267246246
        ]
    },
    {
        "algorithm": "{The algorithm selects a promising solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search strategy that combines weight-balanced flips and objective-driven additions to explore the solution space while ensuring feasibility through adaptive capacity management.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    scores = np.sum(normalized_objectives, axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight and remaining capacity\n    current_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Novel local search strategy: weight-balanced flips and objective-driven additions\n    new_solution = base_solution.copy()\n    items = np.where(new_solution == 1)[0]\n    non_items = np.where(new_solution == 0)[0]\n\n    # Calculate value-to-weight ratios for non-included items\n    if len(non_items) > 0:\n        value1_ratio = value1_lst[non_items] / weight_lst[non_items]\n        value2_ratio = value2_lst[non_items] / weight_lst[non_items]\n\n        # Select top 5 items with highest combined value-to-weight ratios\n        combined_ratio = value1_ratio + value2_ratio\n        top_indices = np.argsort(combined_ratio)[-min(5, len(combined_ratio)):][::-1]\n        for idx in top_indices:\n            item_idx = non_items[idx]\n            if weight_lst[item_idx] <= remaining_capacity:\n                new_solution[item_idx] = 1\n                remaining_capacity -= weight_lst[item_idx]\n\n    # Adaptive capacity management: remove items with lowest ratio if still over capacity\n    if remaining_capacity < 0:\n        items_in_solution = np.where(new_solution == 1)[0]\n        if len(items_in_solution) > 0:\n            value1_ratio = value1_lst[items_in_solution] / weight_lst[items_in_solution]\n            value2_ratio = value2_lst[items_in_solution] / weight_lst[items_in_solution]\n            combined_ratio = value1_ratio + value2_ratio\n            sorted_indices = np.argsort(combined_ratio)\n\n            for idx in sorted_indices:\n                item_idx = items_in_solution[idx]\n                new_solution[item_idx] = 0\n                remaining_capacity += weight_lst[item_idx]\n                if remaining_capacity >= 0:\n                    break\n\n    # Weight-balanced flips: randomly flip 2 items with weight close to remaining capacity\n    if len(items) > 0:\n        flip_candidates = [i for i in items if abs(weight_lst[i] - remaining_capacity) < 0.1 * capacity]\n        if len(flip_candidates) > 0:\n            flip_indices = random.sample(flip_candidates, min(2, len(flip_candidates)))\n            for idx in flip_indices:\n                new_solution[idx] = 0\n                remaining_capacity += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.887089948480458,
            1.368062973022461
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a weighted combination of objective values and weight utilization, then applies a novel local search that uses dynamic item prioritization and probabilistic perturbation to explore high-potential regions while maintaining feasibility through adaptive weight constraints.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (weighted combination of objectives and weight utilization)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.array([np.sum(weight_lst * sol) for sol, _ in archive])\n    normalized_weights = weights / capacity\n    weighted_scores = 0.6 * objectives[:, 0] + 0.4 * objectives[:, 1] - 0.3 * normalized_weights\n    selected_idx = np.argmax(weighted_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dynamic item prioritization and probabilistic perturbation\n    new_solution = base_solution.copy()\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    # Calculate dynamic priorities for items not in solution\n    if len(items_out) > 0:\n        priority_scores = (value1_lst[items_out] + value2_lst[items_out]) / (weight_lst[items_out] + 1e-6)\n        sorted_indices = np.argsort(priority_scores)[::-1]\n        top_items = items_out[sorted_indices[:max(1, len(items_out)//4)]]\n\n        # Add items with probability proportional to their priority\n        for idx in top_items:\n            if np.random.rand() < 0.7 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Probabilistic removal of low-priority items\n    if len(items_in) > 0:\n        removal_scores = (value1_lst[items_in] + value2_lst[items_in]) / (weight_lst[items_in] + 1e-6)\n        sorted_indices = np.argsort(removal_scores)\n        bottom_items = items_in[sorted_indices[:max(1, len(items_in)//3)]]\n\n        for idx in bottom_items:\n            if np.random.rand() < 0.5:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Adaptive weight constraint enforcement\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        items_in_new = np.where(new_solution == 1)[0]\n        if len(items_in_new) > 0:\n            removal_order = np.argsort((value1_lst[items_in_new] + value2_lst[items_in_new]) / (weight_lst[items_in_new] + 1e-6))\n            for idx in items_in_new[removal_order]:\n                if excess_weight <= 0:\n                    break\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.951269370000086,
            2.5577997267246246
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its diversity and objective balance, then applies a novel path-based local search that explores item sequences by considering both profit ratios and weight distribution, ensuring feasibility through iterative adjustments and adaptive capacity management.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high diversity and balanced objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    diversity_scores = np.std(normalized_objectives, axis=1)\n    combined_scores = np.sum(normalized_objectives, axis=1) * diversity_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Path-based local search: explore item sequences\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate value-to-weight ratios and sort items\n    value1_ratio = value1_lst / weight_lst\n    value2_ratio = value2_lst / weight_lst\n    combined_ratio = value1_ratio + value2_ratio\n    sorted_indices = np.argsort(combined_ratio)[::-1]\n\n    # Explore paths by considering both high-ratio and weight-distribution\n    for i in range(min(10, n_items)):\n        item_idx = sorted_indices[i]\n        if new_solution[item_idx] == 0 and current_weight + weight_lst[item_idx] <= capacity:\n            new_solution[item_idx] = 1\n            current_weight += weight_lst[item_idx]\n        elif new_solution[item_idx] == 1:\n            # Check if removing improves balance\n            if np.sum(weight_lst * new_solution) - weight_lst[item_idx] <= capacity:\n                new_solution[item_idx] = 0\n                current_weight -= weight_lst[item_idx]\n\n    # Adaptive capacity management: adjust if over capacity\n    if current_weight > capacity:\n        # Remove items with lowest combined ratio until feasible\n        items_in_solution = np.where(new_solution == 1)[0]\n        sorted_items = items_in_solution[np.argsort(combined_ratio[items_in_solution])]\n        for item_idx in sorted_items:\n            if current_weight <= capacity:\n                break\n            new_solution[item_idx] = 0\n            current_weight -= weight_lst[item_idx]\n\n    # Ensure at least one item remains if solution is not empty\n    if np.sum(new_solution) == 0 and n_items > 0:\n        # Add the item with highest combined ratio\n        best_item = sorted_indices[0]\n        if weight_lst[best_item] <= capacity:\n            new_solution[best_item] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.9073684361272066,
            1.9762572944164276
        ]
    },
    {
        "algorithm": "{The algorithm selects a promising solution from the archive by prioritizing those with high objective values and low weight utilization, then applies a novel local search strategy that combines weight-balanced flips and objective-driven additions to explore the solution space while ensuring feasibility through adaptive capacity management.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-6)\n    scores = np.sum(normalized_objectives, axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight and remaining capacity\n    current_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Novel local search strategy: weight-balanced flips and objective-driven additions\n    new_solution = base_solution.copy()\n    items = np.where(new_solution == 1)[0]\n    non_items = np.where(new_solution == 0)[0]\n\n    # Calculate value-to-weight ratios for non-included items\n    if len(non_items) > 0:\n        value1_ratio = value1_lst[non_items] / weight_lst[non_items]\n        value2_ratio = value2_lst[non_items] / weight_lst[non_items]\n\n        # Select top 5 items with highest combined value-to-weight ratios\n        combined_ratio = value1_ratio + value2_ratio\n        top_indices = np.argsort(combined_ratio)[-min(5, len(combined_ratio)):][::-1]\n        for idx in top_indices:\n            item_idx = non_items[idx]\n            if weight_lst[item_idx] <= remaining_capacity:\n                new_solution[item_idx] = 1\n                remaining_capacity -= weight_lst[item_idx]\n\n    # Adaptive capacity management: remove items with lowest ratio if still over capacity\n    if remaining_capacity < 0:\n        items_in_solution = np.where(new_solution == 1)[0]\n        if len(items_in_solution) > 0:\n            value1_ratio = value1_lst[items_in_solution] / weight_lst[items_in_solution]\n            value2_ratio = value2_lst[items_in_solution] / weight_lst[items_in_solution]\n            combined_ratio = value1_ratio + value2_ratio\n            sorted_indices = np.argsort(combined_ratio)\n\n            for idx in sorted_indices:\n                item_idx = items_in_solution[idx]\n                new_solution[item_idx] = 0\n                remaining_capacity += weight_lst[item_idx]\n                if remaining_capacity >= 0:\n                    break\n\n    # Weight-balanced flips: randomly flip 2 items with weight close to remaining capacity\n    if len(items) > 0:\n        flip_candidates = [i for i in items if abs(weight_lst[i] - remaining_capacity) < 0.1 * capacity]\n        if len(flip_candidates) > 0:\n            flip_indices = random.sample(flip_candidates, min(2, len(flip_candidates)))\n            for idx in flip_indices:\n                new_solution[idx] = 0\n                remaining_capacity += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.887089948480458,
            1.368062973022461
        ]
    }
]