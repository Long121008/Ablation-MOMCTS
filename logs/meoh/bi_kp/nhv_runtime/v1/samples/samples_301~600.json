[
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{The new algorithm selects a solution from the archive based on a normalized objective score that combines both value dimensions with a weight penalty, then applies a multi-phase local search combining value-balanced swaps, weight-aware flips, and capacity-constrained perturbations to generate a high-quality neighbor solution while maintaining feasibility.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution based on normalized objective score with weight penalty\n    scores = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        normalized_obj = (obj[0] / (np.max(value1_lst) + 1e-6), obj[1] / (np.max(value2_lst) + 1e-6))\n        score = (normalized_obj[0] + normalized_obj[1]) / 2 * (1 - (total_weight / capacity) ** 2)\n        scores.append(score)\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Apply multi-phase local search\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Phase 1: Value-balanced swaps\n    in_sol = np.where(new_solution == 1)[0]\n    out_sol = np.where(new_solution == 0)[0]\n    if len(in_sol) > 0 and len(out_sol) > 0:\n        value_balance = (value1_lst + value2_lst) / (np.max(value1_lst) + np.max(value2_lst) + 1e-6)\n        best_in = in_sol[np.argmin(value_balance[in_sol])]\n        best_out = out_sol[np.argmax(value_balance[out_sol])]\n        if current_weight - weight_lst[best_in] + weight_lst[best_out] <= capacity:\n            new_solution[best_in], new_solution[best_out] = new_solution[best_out], new_solution[best_in]\n            current_weight = current_weight - weight_lst[best_in] + weight_lst[best_out]\n\n    # Phase 2: Weight-aware flips\n    flip_candidates = np.argsort((value1_lst + value2_lst) / (weight_lst + 1e-6))[::-1]\n    for idx in flip_candidates[:min(5, len(flip_candidates))]:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 3: Capacity-constrained perturbations\n    perturb_size = min(3, n_items // 3)\n    perturb_indices = np.random.choice(n_items, size=perturb_size, replace=False)\n    for idx in perturb_indices:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity and (value1_lst[idx] > 0 or value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{This algorithm first selects a solution from the archive based on a novel objective-ratio selection criterion that prioritizes solutions with high potential for improvement in either objective, then applies a four-phase local search that includes objective-balanced item flips, capacity-aware neighborhood exploration, value-weighted diversification, and a final equilibrium adjustment phase to generate high-quality neighbor solutions while maintaining feasibility.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Objective-ratio solution selection\n    objectives = np.array([obj for _, obj in archive])\n    obj_ratios = objectives[:, 0] / (objectives[:, 1] + 1e-6)\n    selected_idx = np.argmax(obj_ratios)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 2: Four-phase local search\n    n_items = len(new_solution)\n    in_sol = np.where(new_solution == 1)[0]\n    out_sol = np.where(new_solution == 0)[0]\n\n    # Phase 1: Objective-balanced item flips\n    if len(in_sol) > 0:\n        in_v1 = value1_lst[in_sol]\n        in_v2 = value2_lst[in_sol]\n        in_weights = weight_lst[in_sol]\n\n        flip_scores = (in_v1 + in_v2) / (in_weights + 1e-6)\n        flip_order = np.argsort(flip_scores)[::-1]\n\n        for idx in flip_order[:min(3, len(flip_order))]:\n            if current_weight - in_weights[idx] <= capacity:\n                new_solution[in_sol[idx]] = 0\n                current_weight -= in_weights[idx]\n\n    # Phase 2: Capacity-aware neighborhood exploration\n    neighborhood_size = min(5, n_items // 3)\n    neighborhood = np.random.choice(n_items, size=neighborhood_size, replace=False)\n\n    for idx in neighborhood:\n        if new_solution[idx] == 0 and weight_lst[idx] <= capacity - current_weight:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 3: Value-weighted diversification\n    if random.random() < 0.4:\n        out_v1 = value1_lst[out_sol]\n        out_v2 = value2_lst[out_sol]\n        out_weights = weight_lst[out_sol]\n\n        combined_scores = (out_v1 + out_v2) / (out_weights + 1e-6)\n        valid_candidates = np.where(out_weights <= capacity - current_weight)[0]\n\n        if len(valid_candidates) > 0:\n            best_candidate = valid_candidates[np.argmax(combined_scores[valid_candidates])]\n            idx = out_sol[best_candidate]\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 4: Final equilibrium adjustment\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0 and len(out_sol) > 0:\n        out_v1 = value1_lst[out_sol]\n        out_v2 = value2_lst[out_sol]\n        out_weights = weight_lst[out_sol]\n\n        equilibrium_scores = (out_v1 * out_v2) / (out_weights + 1e-6)\n        valid_candidates = np.where(out_weights <= remaining_capacity)[0]\n\n        if len(valid_candidates) > 0:\n            best_candidate = valid_candidates[np.argmax(equilibrium_scores[valid_candidates])]\n            idx = out_sol[best_candidate]\n            new_solution[idx] = 1\n\n    return new_solution\n\n\nPlease help me create a new algorithm that has a totally different form from the given ones. \n1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nDo not give additional explanations.",
        "sample_order": 301,
        "algorithm": "{This algorithm selects a solution from the archive based on a diversity-aware objective score that combines both values and solution structure, then applies a hybrid local search that combines adaptive item selection with capacity-aware perturbations, followed by a value-weighted diversification phase to generate high-quality neighbor solutions while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution based on diversity-aware objective score\n    solutions = np.array([sol for sol, _ in archive])\n    objectives = np.array([obj for _, obj in archive])\n    n_solutions = len(solutions)\n\n    # Calculate diversity scores\n    diversity_scores = []\n    for i in range(n_solutions):\n        distances = np.sum(np.abs(solutions[i] - solutions), axis=1)\n        diversity_scores.append(np.mean(distances))\n\n    # Combine with objective scores\n    normalized_obj1 = objectives[:, 0] / (np.max(objectives[:, 0]) + 1e-6)\n    normalized_obj2 = objectives[:, 1] / (np.max(objectives[:, 1]) + 1e-6)\n    combined_scores = (normalized_obj1 + normalized_obj2) * np.array(diversity_scores)\n\n    selected_idx = np.argmax(combined_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 2: Hybrid local search\n    n_items = len(new_solution)\n    in_sol = np.where(new_solution == 1)[0]\n    out_sol = np.where(new_solution == 0)[0]\n\n    # Phase 1: Adaptive item selection\n    if len(in_sol) > 0 and len(out_sol) > 0:\n        # Calculate value-to-weight ratios\n        in_ratio = (value1_lst[in_sol] + value2_lst[in_sol]) / (weight_lst[in_sol] + 1e-6)\n        out_ratio = (value1_lst[out_sol] + value2_lst[out_sol]) / (weight_lst[out_sol] + 1e-6)\n\n        # Find best item to remove and best item to add\n        best_remove = in_sol[np.argmin(in_ratio)]\n        valid_add = np.where(weight_lst[out_sol] <= capacity - current_weight + weight_lst[best_remove])[0]\n\n        if len(valid_add) > 0:\n            best_add = out_sol[valid_add[np.argmax(out_ratio[valid_add])]]\n            new_solution[best_remove] = 0\n            new_solution[best_add] = 1\n            current_weight = current_weight - weight_lst[best_remove] + weight_lst[best_add]\n\n    # Phase 2: Capacity-aware perturbations\n    perturb_size = min(3, n_items // 4)\n    perturb_indices = np.random.choice(n_items, size=perturb_size, replace=False)\n\n    for idx in perturb_indices:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 3: Value-weighted diversification\n    if len(out_sol) > 0 and random.random() < 0.5:\n        out_v1 = value1_lst[out_sol]\n        out_v2 = value2_lst[out_sol]\n        out_weights = weight_lst[out_sol]\n\n        combined_scores = (out_v1 + out_v2) / (out_weights + 1e-6)\n        valid_candidates = np.where(out_weights <= capacity - current_weight)[0]\n\n        if len(valid_candidates) > 0:\n            best_candidate = valid_candidates[np.argmax(combined_scores[valid_candidates])]\n            idx = out_sol[best_candidate]\n            new_solution[idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.31307827602003746,
            8.260093778371811
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution based on diversity-aware objective score\n    solutions = np.array([sol for sol, _ in archive])\n    objectives = np.array([obj for _, obj in archive])\n    n_solutions = len(solutions)\n\n    # Calculate diversity scores\n    diversity_scores = []\n    for i in range(n_solutions):\n        distances = np.sum(np.abs(solutions[i] - solutions), axis=1)\n        diversity_scores.append(np.mean(distances))\n\n    # Combine with objective scores\n    normalized_obj1 = objectives[:, 0] / (np.max(objectives[:, 0]) + 1e-6)\n    normalized_obj2 = objectives[:, 1] / (np.max(objectives[:, 1]) + 1e-6)\n    combined_scores = (normalized_obj1 + normalized_obj2) * np.array(diversity_scores)\n\n    selected_idx = np.argmax(combined_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 2: Hybrid local search\n    n_items = len(new_solution)\n    in_sol = np.where(new_solution == 1)[0]\n    out_sol = np.where(new_solution == 0)[0]\n\n    # Phase 1: Adaptive item selection\n    if len(in_sol) > 0 and len(out_sol) > 0:\n        # Calculate value-to-weight ratios\n        in_ratio = (value1_lst[in_sol] + value2_lst[in_sol]) / (weight_lst[in_sol] + 1e-6)\n        out_ratio = (value1_lst[out_sol] + value2_lst[out_sol]) / (weight_lst[out_sol] + 1e-6)\n\n        # Find best item to remove and best item to add\n        best_remove = in_sol[np.argmin(in_ratio)]\n        valid_add = np.where(weight_lst[out_sol] <= capacity - current_weight + weight_lst[best_remove])[0]\n\n        if len(valid_add) > 0:\n            best_add = out_sol[valid_add[np.argmax(out_ratio[valid_add])]]\n            new_solution[best_remove] = 0\n            new_solution[best_add] = 1\n            current_weight = current_weight - weight_lst[best_remove] + weight_lst[best_add]\n\n    # Phase 2: Capacity-aware perturbations\n    perturb_size = min(3, n_items // 4)\n    perturb_indices = np.random.choice(n_items, size=perturb_size, replace=False)\n\n    for idx in perturb_indices:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 3: Value-weighted diversification\n    if len(out_sol) > 0 and random.random() < 0.5:\n        out_v1 = value1_lst[out_sol]\n        out_v2 = value2_lst[out_sol]\n        out_weights = weight_lst[out_sol]\n\n        combined_scores = (out_v1 + out_v2) / (out_weights + 1e-6)\n        valid_candidates = np.where(out_weights <= capacity - current_weight)[0]\n\n        if len(valid_candidates) > 0:\n            best_candidate = valid_candidates[np.argmax(combined_scores[valid_candidates])]\n            idx = out_sol[best_candidate]\n            new_solution[idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have one algorithm with its code as follows. Algorithm description:\n{The new algorithm selects a solution from the archive based on a combined objective score and weight efficiency, then applies a multi-phase local search combining value-ratio swaps, weight-balanced flips, and capacity-aware perturbations to generate a high-quality neighbor solution while maintaining feasibility.}\nCode:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution based on combined objective score and weight efficiency\n    scores = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        weight_efficiency = (obj[0] + obj[1]) / (total_weight + 1e-6)\n        score = weight_efficiency * (1 - (total_weight / capacity))\n        scores.append(score)\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Apply multi-phase local search\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Phase 1: Value-ratio swaps\n    in_sol = np.where(new_solution == 1)[0]\n    out_sol = np.where(new_solution == 0)[0]\n    if len(in_sol) > 0 and len(out_sol) > 0:\n        value_ratios = (value1_lst + value2_lst) / weight_lst\n        best_in = in_sol[np.argmin(value_ratios[in_sol])]\n        best_out = out_sol[np.argmax(value_ratios[out_sol])]\n        if current_weight - weight_lst[best_in] + weight_lst[best_out] <= capacity:\n            new_solution[best_in], new_solution[best_out] = new_solution[best_out], new_solution[best_in]\n            current_weight = current_weight - weight_lst[best_in] + weight_lst[best_out]\n\n    # Phase 2: Weight-balanced flips\n    flip_candidates = np.argsort((value1_lst + value2_lst) / (weight_lst + 1e-6))[::-1]\n    for idx in flip_candidates[:min(3, len(flip_candidates))]:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 3: Capacity-aware perturbations\n    perturb_size = min(2, n_items // 4)\n    perturb_indices = np.random.choice(n_items, size=perturb_size, replace=False)\n    for idx in perturb_indices:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity and (value1_lst[idx] > 0 or value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nPlease identify the main algorithm parameters and assist me in creating a new algorithm that has a different parameter settings of the score function provided.\n1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nDo not give additional explanations.",
        "sample_order": 302,
        "algorithm": "{The new algorithm selects a solution from the archive based on a normalized objective score and diversity-aware weight efficiency, then applies a multi-phase local search combining value-weighted swaps, diversity-preserving flips, and capacity-adaptive perturbations to generate a high-quality neighbor solution while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution based on normalized objective score and diversity-aware weight efficiency\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    scores = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        norm_obj1 = obj[0] / (max_obj1 + 1e-6)\n        norm_obj2 = obj[1] / (max_obj2 + 1e-6)\n        diversity_score = 1 - (np.sum(np.abs(sol - np.mean(sol))) / len(sol))\n        weight_efficiency = (norm_obj1 + norm_obj2) / (total_weight + 1e-6)\n        score = weight_efficiency * diversity_score * (1 - (total_weight / capacity))\n        scores.append(score)\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Apply multi-phase local search\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Phase 1: Value-weighted swaps\n    in_sol = np.where(new_solution == 1)[0]\n    out_sol = np.where(new_solution == 0)[0]\n    if len(in_sol) > 0 and len(out_sol) > 0:\n        value_weights = (value1_lst + value2_lst) * (1 / (weight_lst + 1e-6))\n        best_in = in_sol[np.argmin(value_weights[in_sol])]\n        best_out = out_sol[np.argmax(value_weights[out_sol])]\n        if current_weight - weight_lst[best_in] + weight_lst[best_out] <= capacity:\n            new_solution[best_in], new_solution[best_out] = new_solution[best_out], new_solution[best_in]\n            current_weight = current_weight - weight_lst[best_in] + weight_lst[best_out]\n\n    # Phase 2: Diversity-preserving flips\n    flip_candidates = np.argsort((value1_lst + value2_lst) * (1 / (weight_lst + 1e-6)))[::-1]\n    for idx in flip_candidates[:min(4, len(flip_candidates))]:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 3: Capacity-adaptive perturbations\n    perturb_size = min(3, n_items // 5)\n    perturb_indices = np.random.choice(n_items, size=perturb_size, replace=False)\n    for idx in perturb_indices:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity and (np.random.rand() < 0.7):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.5929303330380833,
            5.568697899580002
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution based on normalized objective score and diversity-aware weight efficiency\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    scores = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        norm_obj1 = obj[0] / (max_obj1 + 1e-6)\n        norm_obj2 = obj[1] / (max_obj2 + 1e-6)\n        diversity_score = 1 - (np.sum(np.abs(sol - np.mean(sol))) / len(sol))\n        weight_efficiency = (norm_obj1 + norm_obj2) / (total_weight + 1e-6)\n        score = weight_efficiency * diversity_score * (1 - (total_weight / capacity))\n        scores.append(score)\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Apply multi-phase local search\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Phase 1: Value-weighted swaps\n    in_sol = np.where(new_solution == 1)[0]\n    out_sol = np.where(new_solution == 0)[0]\n    if len(in_sol) > 0 and len(out_sol) > 0:\n        value_weights = (value1_lst + value2_lst) * (1 / (weight_lst + 1e-6))\n        best_in = in_sol[np.argmin(value_weights[in_sol])]\n        best_out = out_sol[np.argmax(value_weights[out_sol])]\n        if current_weight - weight_lst[best_in] + weight_lst[best_out] <= capacity:\n            new_solution[best_in], new_solution[best_out] = new_solution[best_out], new_solution[best_in]\n            current_weight = current_weight - weight_lst[best_in] + weight_lst[best_out]\n\n    # Phase 2: Diversity-preserving flips\n    flip_candidates = np.argsort((value1_lst + value2_lst) * (1 / (weight_lst + 1e-6)))[::-1]\n    for idx in flip_candidates[:min(4, len(flip_candidates))]:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 3: Capacity-adaptive perturbations\n    perturb_size = min(3, n_items // 5)\n    perturb_indices = np.random.choice(n_items, size=perturb_size, replace=False)\n    for idx in perturb_indices:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity and (np.random.rand() < 0.7):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{The new algorithm selects a solution from the archive based on a combined objective score and weight efficiency, then applies a multi-phase local search combining value-ratio swaps, weight-balanced flips, and capacity-aware perturbations to generate a high-quality neighbor solution while maintaining feasibility.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution based on combined objective score and weight efficiency\n    scores = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        weight_efficiency = (obj[0] + obj[1]) / (total_weight + 1e-6)\n        score = weight_efficiency * (1 - (total_weight / capacity))\n        scores.append(score)\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Apply multi-phase local search\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Phase 1: Value-ratio swaps\n    in_sol = np.where(new_solution == 1)[0]\n    out_sol = np.where(new_solution == 0)[0]\n    if len(in_sol) > 0 and len(out_sol) > 0:\n        value_ratios = (value1_lst + value2_lst) / weight_lst\n        best_in = in_sol[np.argmin(value_ratios[in_sol])]\n        best_out = out_sol[np.argmax(value_ratios[out_sol])]\n        if current_weight - weight_lst[best_in] + weight_lst[best_out] <= capacity:\n            new_solution[best_in], new_solution[best_out] = new_solution[best_out], new_solution[best_in]\n            current_weight = current_weight - weight_lst[best_in] + weight_lst[best_out]\n\n    # Phase 2: Weight-balanced flips\n    flip_candidates = np.argsort((value1_lst + value2_lst) / (weight_lst + 1e-6))[::-1]\n    for idx in flip_candidates[:min(3, len(flip_candidates))]:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 3: Capacity-aware perturbations\n    perturb_size = min(2, n_items // 4)\n    perturb_indices = np.random.choice(n_items, size=perturb_size, replace=False)\n    for idx in perturb_indices:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity and (value1_lst[idx] > 0 or value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{The new algorithm selects a solution from the archive based on a normalized objective score that combines both value dimensions with a weight penalty, then applies a multi-phase local search combining value-balanced swaps, weight-aware flips, and capacity-constrained perturbations to generate a high-quality neighbor solution while maintaining feasibility.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution based on normalized objective score with weight penalty\n    scores = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        normalized_obj = (obj[0] / (np.max(value1_lst) + 1e-6), obj[1] / (np.max(value2_lst) + 1e-6))\n        score = (normalized_obj[0] + normalized_obj[1]) / 2 * (1 - (total_weight / capacity) ** 2)\n        scores.append(score)\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Apply multi-phase local search\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Phase 1: Value-balanced swaps\n    in_sol = np.where(new_solution == 1)[0]\n    out_sol = np.where(new_solution == 0)[0]\n    if len(in_sol) > 0 and len(out_sol) > 0:\n        value_balance = (value1_lst + value2_lst) / (np.max(value1_lst) + np.max(value2_lst) + 1e-6)\n        best_in = in_sol[np.argmin(value_balance[in_sol])]\n        best_out = out_sol[np.argmax(value_balance[out_sol])]\n        if current_weight - weight_lst[best_in] + weight_lst[best_out] <= capacity:\n            new_solution[best_in], new_solution[best_out] = new_solution[best_out], new_solution[best_in]\n            current_weight = current_weight - weight_lst[best_in] + weight_lst[best_out]\n\n    # Phase 2: Weight-aware flips\n    flip_candidates = np.argsort((value1_lst + value2_lst) / (weight_lst + 1e-6))[::-1]\n    for idx in flip_candidates[:min(5, len(flip_candidates))]:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 3: Capacity-constrained perturbations\n    perturb_size = min(3, n_items // 3)\n    perturb_indices = np.random.choice(n_items, size=perturb_size, replace=False)\n    for idx in perturb_indices:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity and (value1_lst[idx] > 0 or value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nPlease help me create a new algorithm that has a totally different form from the given ones but can be motivated from them.\n1. Firstly, identify the common backbone idea in the provided algorithms. \n2. Secondly, based on the backbone idea describe your new algorithm in one sentence. The description must be inside within boxed {}.\n3. Thirdly, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nDo not give additional explanations.",
        "sample_order": 303,
        "algorithm": "{The new algorithm selects a solution from the archive based on a composite score combining objective dominance and weight efficiency, then applies a multi-phase local search combining objective-specific swaps, weight-constrained flips, and adaptive perturbations to generate a high-quality neighbor solution while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution based on composite score combining objective dominance and weight efficiency\n    scores = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        dominance_score = (obj[0] / (np.sum(value1_lst) + 1e-6) + obj[1] / (np.sum(value2_lst) + 1e-6)) / 2\n        weight_efficiency = (obj[0] + obj[1]) / (total_weight + 1e-6)\n        score = dominance_score * weight_efficiency * (1 - (total_weight / capacity) ** 1.5)\n        scores.append(score)\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Apply multi-phase local search\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Phase 1: Objective-specific swaps\n    in_sol = np.where(new_solution == 1)[0]\n    out_sol = np.where(new_solution == 0)[0]\n    if len(in_sol) > 0 and len(out_sol) > 0:\n        obj1_ratio = value1_lst / (weight_lst + 1e-6)\n        obj2_ratio = value2_lst / (weight_lst + 1e-6)\n        best_in = in_sol[np.argmin(obj1_ratio[in_sol] + obj2_ratio[in_sol])]\n        best_out = out_sol[np.argmax(obj1_ratio[out_sol] + obj2_ratio[out_sol])]\n        if current_weight - weight_lst[best_in] + weight_lst[best_out] <= capacity:\n            new_solution[best_in], new_solution[best_out] = new_solution[best_out], new_solution[best_in]\n            current_weight = current_weight - weight_lst[best_in] + weight_lst[best_out]\n\n    # Phase 2: Weight-constrained flips\n    flip_candidates = np.argsort((value1_lst + value2_lst) / (weight_lst + 1e-6))[::-1]\n    for idx in flip_candidates[:min(4, len(flip_candidates))]:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 3: Adaptive perturbations\n    perturb_size = min(3, n_items // 5)\n    perturb_indices = np.random.choice(n_items, size=perturb_size, replace=False)\n    for idx in perturb_indices:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity and (value1_lst[idx] > 0 or value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.6314526708661645,
            3.9875961542129517
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution based on composite score combining objective dominance and weight efficiency\n    scores = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        dominance_score = (obj[0] / (np.sum(value1_lst) + 1e-6) + obj[1] / (np.sum(value2_lst) + 1e-6)) / 2\n        weight_efficiency = (obj[0] + obj[1]) / (total_weight + 1e-6)\n        score = dominance_score * weight_efficiency * (1 - (total_weight / capacity) ** 1.5)\n        scores.append(score)\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Apply multi-phase local search\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Phase 1: Objective-specific swaps\n    in_sol = np.where(new_solution == 1)[0]\n    out_sol = np.where(new_solution == 0)[0]\n    if len(in_sol) > 0 and len(out_sol) > 0:\n        obj1_ratio = value1_lst / (weight_lst + 1e-6)\n        obj2_ratio = value2_lst / (weight_lst + 1e-6)\n        best_in = in_sol[np.argmin(obj1_ratio[in_sol] + obj2_ratio[in_sol])]\n        best_out = out_sol[np.argmax(obj1_ratio[out_sol] + obj2_ratio[out_sol])]\n        if current_weight - weight_lst[best_in] + weight_lst[best_out] <= capacity:\n            new_solution[best_in], new_solution[best_out] = new_solution[best_out], new_solution[best_in]\n            current_weight = current_weight - weight_lst[best_in] + weight_lst[best_out]\n\n    # Phase 2: Weight-constrained flips\n    flip_candidates = np.argsort((value1_lst + value2_lst) / (weight_lst + 1e-6))[::-1]\n    for idx in flip_candidates[:min(4, len(flip_candidates))]:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 3: Adaptive perturbations\n    perturb_size = min(3, n_items // 5)\n    perturb_indices = np.random.choice(n_items, size=perturb_size, replace=False)\n    for idx in perturb_indices:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity and (value1_lst[idx] > 0 or value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{The new algorithm selects a solution from the archive based on a normalized objective score that combines both value dimensions with a weight penalty, then applies a multi-phase local search combining value-balanced swaps, weight-aware flips, and capacity-constrained perturbations to generate a high-quality neighbor solution while maintaining feasibility.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution based on normalized objective score with weight penalty\n    scores = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        normalized_obj = (obj[0] / (np.max(value1_lst) + 1e-6), obj[1] / (np.max(value2_lst) + 1e-6))\n        score = (normalized_obj[0] + normalized_obj[1]) / 2 * (1 - (total_weight / capacity) ** 2)\n        scores.append(score)\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Apply multi-phase local search\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Phase 1: Value-balanced swaps\n    in_sol = np.where(new_solution == 1)[0]\n    out_sol = np.where(new_solution == 0)[0]\n    if len(in_sol) > 0 and len(out_sol) > 0:\n        value_balance = (value1_lst + value2_lst) / (np.max(value1_lst) + np.max(value2_lst) + 1e-6)\n        best_in = in_sol[np.argmin(value_balance[in_sol])]\n        best_out = out_sol[np.argmax(value_balance[out_sol])]\n        if current_weight - weight_lst[best_in] + weight_lst[best_out] <= capacity:\n            new_solution[best_in], new_solution[best_out] = new_solution[best_out], new_solution[best_in]\n            current_weight = current_weight - weight_lst[best_in] + weight_lst[best_out]\n\n    # Phase 2: Weight-aware flips\n    flip_candidates = np.argsort((value1_lst + value2_lst) / (weight_lst + 1e-6))[::-1]\n    for idx in flip_candidates[:min(5, len(flip_candidates))]:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 3: Capacity-constrained perturbations\n    perturb_size = min(3, n_items // 3)\n    perturb_indices = np.random.choice(n_items, size=perturb_size, replace=False)\n    for idx in perturb_indices:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity and (value1_lst[idx] > 0 or value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{This algorithm selects a solution from the archive using a hybrid selection criterion that combines dominance scores with item diversity metrics, then applies a two-phase local search that includes a multi-objective greedy insertion phase followed by a capacity-optimized diversification step to generate high-quality neighbor solutions while maintaining feasibility.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection criterion\n    objectives = np.array([obj for _, obj in archive])\n    max_obj = np.max(objectives, axis=0)\n    diversity_scores = np.sum(archive[0][0] != archive[1][0]) if len(archive) > 1 else 0\n    hybrid_scores = (max_obj[0] - objectives[:, 0]) + (max_obj[1] - objectives[:, 1]) + diversity_scores\n\n    selected_idx = np.argmax(hybrid_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Multi-objective greedy insertion\n    out_sol = np.where(new_solution == 0)[0]\n    if len(out_sol) > 0:\n        out_weights = weight_lst[out_sol]\n        out_v1 = value1_lst[out_sol]\n        out_v2 = value2_lst[out_sol]\n\n        # Calculate normalized scores for both objectives\n        v1_scores = out_v1 / (out_weights + 1e-6)\n        v2_scores = out_v2 / (out_weights + 1e-6)\n\n        # Combine scores with different weights\n        combined_scores = 0.6 * v1_scores + 0.4 * v2_scores\n\n        # Select top candidates\n        valid_candidates = np.where(out_weights <= capacity - current_weight)[0]\n        if len(valid_candidates) > 0:\n            top_candidates = valid_candidates[np.argsort(combined_scores[valid_candidates])[-min(3, len(valid_candidates)):]]\n            for j in top_candidates:\n                idx = out_sol[j]\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Phase 2: Capacity-optimized diversification\n    in_sol = np.where(new_solution == 1)[0]\n    if len(in_sol) > 0 and random.random() < 0.4:\n        # Calculate removal potential\n        removal_scores = (value1_lst[in_sol] + value2_lst[in_sol]) / (weight_lst[in_sol] + 1e-6)\n        worst_items = np.argsort(removal_scores)[:min(2, len(in_sol))]\n\n        for j in worst_items:\n            idx = in_sol[j]\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    return new_solution\n\n\nPlease help me create a new algorithm that has a totally different form from the given ones but can be motivated from them.\n1. Firstly, identify the common backbone idea in the provided algorithms. \n2. Secondly, based on the backbone idea describe your new algorithm in one sentence. The description must be inside within boxed {}.\n3. Thirdly, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nDo not give additional explanations.",
        "sample_order": 304,
        "algorithm": "{This algorithm selects a solution from the archive based on a combination of objective dominance and item criticality scores, then applies a three-phase local search that includes a value-aware expansion phase, a weight-balanced reduction phase, and a multi-objective perturbation phase to generate high-quality neighbor solutions while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select solution based on combined dominance and criticality\n    objectives = np.array([obj for _, obj in archive])\n    max_obj = np.max(objectives, axis=0)\n    dominance_scores = (max_obj[0] - objectives[:, 0]) + (max_obj[1] - objectives[:, 1])\n\n    criticality_scores = []\n    for sol, _ in archive:\n        in_items = np.where(sol == 1)[0]\n        if len(in_items) == 0:\n            criticality_scores.append(0)\n        else:\n            avg_value = np.mean(value1_lst[in_items] + value2_lst[in_items])\n            avg_weight = np.mean(weight_lst[in_items])\n            criticality_scores.append(avg_value / (avg_weight + 1e-6))\n\n    combined_scores = dominance_scores * 0.7 + np.array(criticality_scores) * 0.3\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Value-aware expansion\n    out_items = np.where(new_solution == 0)[0]\n    if len(out_items) > 0:\n        value_ratio = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        candidate_indices = np.argsort(value_ratio[out_items])[::-1][:min(5, len(out_items))]\n        for j in candidate_indices:\n            idx = out_items[j]\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Weight-balanced reduction\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        weight_ratio = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        worst_indices = np.argsort(weight_ratio[in_items])[:min(3, len(in_items))]\n        for j in worst_indices:\n            idx = in_items[j]\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Phase 3: Multi-objective perturbation\n    perturb_size = min(2, len(weight_lst) // 5)\n    perturb_indices = np.random.choice(len(weight_lst), size=perturb_size, replace=False)\n    for idx in perturb_indices:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity and (value1_lst[idx] > 0 or value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.889333750155229,
            6.177443444728851
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select solution based on combined dominance and criticality\n    objectives = np.array([obj for _, obj in archive])\n    max_obj = np.max(objectives, axis=0)\n    dominance_scores = (max_obj[0] - objectives[:, 0]) + (max_obj[1] - objectives[:, 1])\n\n    criticality_scores = []\n    for sol, _ in archive:\n        in_items = np.where(sol == 1)[0]\n        if len(in_items) == 0:\n            criticality_scores.append(0)\n        else:\n            avg_value = np.mean(value1_lst[in_items] + value2_lst[in_items])\n            avg_weight = np.mean(weight_lst[in_items])\n            criticality_scores.append(avg_value / (avg_weight + 1e-6))\n\n    combined_scores = dominance_scores * 0.7 + np.array(criticality_scores) * 0.3\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Value-aware expansion\n    out_items = np.where(new_solution == 0)[0]\n    if len(out_items) > 0:\n        value_ratio = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        candidate_indices = np.argsort(value_ratio[out_items])[::-1][:min(5, len(out_items))]\n        for j in candidate_indices:\n            idx = out_items[j]\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Weight-balanced reduction\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        weight_ratio = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        worst_indices = np.argsort(weight_ratio[in_items])[:min(3, len(in_items))]\n        for j in worst_indices:\n            idx = in_items[j]\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Phase 3: Multi-objective perturbation\n    perturb_size = min(2, len(weight_lst) // 5)\n    perturb_indices = np.random.choice(len(weight_lst), size=perturb_size, replace=False)\n    for idx in perturb_indices:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity and (value1_lst[idx] > 0 or value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    }
]