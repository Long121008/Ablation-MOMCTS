[
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a hybrid local search strategy that combines probabilistic item removal, value-to-weight ratio insertion, and adaptive crowding-aware exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = marginal_value1 + marginal_value2\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-to-weight ratio insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio1 = value1_lst[excluded_items] / weight_lst[excluded_items]\n        value_ratio2 = value2_lst[excluded_items] / weight_lst[excluded_items]\n        value_ratio = value_ratio1 + value_ratio2\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive crowding-aware exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.553997020849362,
            -18.850015607233225
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a novel local search strategy that combines probabilistic item removal, value-weighted insertion, and adaptive crowding-aware exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = marginal_value1 + marginal_value2\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-weighted insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive crowding-aware exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.007733320328047,
            -18.34183790052968
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a novel local search strategy that combines probabilistic item removal, value-weighted insertion, and adaptive crowding-aware exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = marginal_value1 + marginal_value2\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-weighted insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive crowding-aware exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.651000064831955,
            -18.571452259751904
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a novel local search strategy that combines probabilistic item removal, value-to-weight ratio insertion, and adaptive crowding-aware exploration, but with a focus on balancing the two objectives through a dynamic trade-off factor that evolves during the search process to generate high-quality neighbor solutions while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Dynamic trade-off factor based on archive diversity\n    if len(archive) > 1:\n        val1_range = max(obj[1][0] for obj in archive) - min(obj[1][0] for obj in archive)\n        val2_range = max(obj[1][1] for obj in archive) - min(obj[1][1] for obj in archive)\n        trade_off = val1_range / (val1_range + val2_range + 1e-6)\n    else:\n        trade_off = 0.5\n\n    # Step 1: Probabilistic item removal with dynamic trade-off\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = trade_off * marginal_value1 + (1 - trade_off) * marginal_value2\n\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-to-weight ratio insertion with dynamic trade-off\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        value_ratio1 = value1_lst[excluded_items] / weight_lst[excluded_items]\n        value_ratio2 = value2_lst[excluded_items] / weight_lst[excluded_items]\n        value_ratio = trade_off * value_ratio1 + (1 - trade_off) * value_ratio2\n\n        insertion_probs = value_ratio / np.sum(value_ratio)\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive crowding-aware exploration with trade-off adjustment\n    if len(archive) > 1:\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            # Adjust trade-off based on archive distribution\n            val1_mean = np.mean([obj[1][0] for obj in archive])\n            val2_mean = np.mean([obj[1][1] for obj in archive])\n            trade_off = (current_val1 - val1_mean) / ((current_val1 - val1_mean) + (current_val2 - val2_mean) + 1e-6)\n\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.087409982276544,
            -18.333686251170533
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its dominance rank and diversity, then applies a hybrid local search strategy that combines probabilistic item swapping, value-weighted replacement, and adaptive objective-balancing exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high dominance rank and diversity\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item swapping (swap items between included and excluded with high value-to-weight ratio)\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for included items (for potential removal)\n        value_ratio_included = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n        removal_probs = value_ratio_included / np.sum(value_ratio_included)\n\n        # Calculate value-to-weight ratio for excluded items (for potential insertion)\n        value_ratio_excluded = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n        insertion_probs = value_ratio_excluded / np.sum(value_ratio_excluded)\n\n        # Select items to swap\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n\n        # Perform swap if feasible\n        if current_weight - weight_lst[remove_idx] + weight_lst[insert_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            new_solution[insert_idx] = 1\n            current_weight = current_weight - weight_lst[remove_idx] + weight_lst[insert_idx]\n\n    # Step 2: Value-weighted replacement (replace included items with excluded ones based on objective balance)\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective balance for included items (for potential replacement)\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        balance_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Calculate replacement value for excluded items\n        replacement_value = (value1_lst[excluded_items] * (1 - balance_ratio) + value2_lst[excluded_items] * balance_ratio) / weight_lst[excluded_items]\n\n        # Select item to replace\n        replace_idx = np.random.choice(excluded_items, p=replacement_value / np.sum(replacement_value))\n\n        # Find the worst included item to replace\n        worst_idx = np.argmin((value1_lst[included_items] * (1 - balance_ratio) + value2_lst[included_items] * balance_ratio) / weight_lst[included_items])\n        worst_idx = included_items[worst_idx]\n\n        # Perform replacement if feasible\n        if current_weight - weight_lst[worst_idx] + weight_lst[replace_idx] <= capacity:\n            new_solution[worst_idx] = 0\n            new_solution[replace_idx] = 1\n\n    # Step 3: Adaptive objective-balancing exploration (flip bits based on objective balance)\n    if len(included_items) > 0:\n        # Calculate current objective balance\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        balance_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Flip bits based on balance (favor objective with lower current value)\n        flip_idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity and random.random() < balance_ratio:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.99625092721474,
            -18.55409318572922
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive, then applies a hybrid local search that combines probabilistic item removal, value-driven insertion, and adaptive Pareto front exploration, while ensuring feasibility by dynamically adjusting the solution based on both objective values and their trade-offs.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = (marginal_value1 + marginal_value2) / weight_lst[included_items]\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-driven insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive Pareto front exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.623404664973524,
            -18.7290951023424
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a novel local search strategy that combines probabilistic item removal, value-weighted insertion, and adaptive crowding-aware exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = marginal_value1 + marginal_value2\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-weighted insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive crowding-aware exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.289591987269574,
            -17.927642823018033
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a novel local search strategy that combines probabilistic item removal, value-weighted insertion, and adaptive crowding-aware exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = marginal_value1 + marginal_value2\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-weighted insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive crowding-aware exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.0294370552961,
            -18.28276485004043
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a hybrid local search strategy that combines probabilistic item removal, value-weighted insertion, and adaptive crowding-aware exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = marginal_value1 + marginal_value2\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-weighted insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive crowding-aware exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.8073190523624,
            -18.533990493588295
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a novel local search strategy that combines probabilistic item removal, value-weighted insertion, and adaptive crowding-aware exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = marginal_value1 + marginal_value2\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-weighted insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive crowding-aware exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.98086817454899,
            -18.417995894225676
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a hybrid local search strategy that combines probabilistic item removal, value-to-weight ratio insertion, and adaptive crowding-aware exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = marginal_value1 + marginal_value2\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-to-weight ratio insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio1 = value1_lst[excluded_items] / weight_lst[excluded_items]\n        value_ratio2 = value2_lst[excluded_items] / weight_lst[excluded_items]\n        value_ratio = value_ratio1 + value_ratio2\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive crowding-aware exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.553997020849362,
            -18.850015607233225
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a novel local search strategy that combines probabilistic item removal, value-weighted insertion, and adaptive crowding-aware exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = marginal_value1 + marginal_value2\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-weighted insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive crowding-aware exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.651000064831955,
            -18.571452259751904
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive, then applies a hybrid local search that combines probabilistic item removal, value-driven insertion, and adaptive Pareto front exploration, while ensuring feasibility by dynamically adjusting the solution based on both objective values and their trade-offs.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = (marginal_value1 + marginal_value2) / weight_lst[included_items]\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-driven insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive Pareto front exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.623404664973524,
            -18.7290951023424
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a novel local search strategy that combines probabilistic item removal, value-weighted insertion, and adaptive crowding-aware exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = marginal_value1 + marginal_value2\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-weighted insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive crowding-aware exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.289591987269574,
            -17.927642823018033
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its dominance rank and diversity, then applies a hybrid local search strategy that combines probabilistic item swapping, value-weighted replacement, and adaptive objective-balancing exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high dominance rank and diversity\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item swapping (swap items between included and excluded with high value-to-weight ratio)\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for included items (for potential removal)\n        value_ratio_included = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n        removal_probs = value_ratio_included / np.sum(value_ratio_included)\n\n        # Calculate value-to-weight ratio for excluded items (for potential insertion)\n        value_ratio_excluded = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n        insertion_probs = value_ratio_excluded / np.sum(value_ratio_excluded)\n\n        # Select items to swap\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n\n        # Perform swap if feasible\n        if current_weight - weight_lst[remove_idx] + weight_lst[insert_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            new_solution[insert_idx] = 1\n            current_weight = current_weight - weight_lst[remove_idx] + weight_lst[insert_idx]\n\n    # Step 2: Value-weighted replacement (replace included items with excluded ones based on objective balance)\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective balance for included items (for potential replacement)\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        balance_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Calculate replacement value for excluded items\n        replacement_value = (value1_lst[excluded_items] * (1 - balance_ratio) + value2_lst[excluded_items] * balance_ratio) / weight_lst[excluded_items]\n\n        # Select item to replace\n        replace_idx = np.random.choice(excluded_items, p=replacement_value / np.sum(replacement_value))\n\n        # Find the worst included item to replace\n        worst_idx = np.argmin((value1_lst[included_items] * (1 - balance_ratio) + value2_lst[included_items] * balance_ratio) / weight_lst[included_items])\n        worst_idx = included_items[worst_idx]\n\n        # Perform replacement if feasible\n        if current_weight - weight_lst[worst_idx] + weight_lst[replace_idx] <= capacity:\n            new_solution[worst_idx] = 0\n            new_solution[replace_idx] = 1\n\n    # Step 3: Adaptive objective-balancing exploration (flip bits based on objective balance)\n    if len(included_items) > 0:\n        # Calculate current objective balance\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        balance_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Flip bits based on balance (favor objective with lower current value)\n        flip_idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity and random.random() < balance_ratio:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.99625092721474,
            -18.55409318572922
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a novel local search strategy that combines probabilistic item removal, value-to-weight ratio insertion, and adaptive crowding-aware exploration, but with a focus on balancing the two objectives through a dynamic trade-off factor that evolves during the search process to generate high-quality neighbor solutions while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Dynamic trade-off factor based on archive diversity\n    if len(archive) > 1:\n        val1_range = max(obj[1][0] for obj in archive) - min(obj[1][0] for obj in archive)\n        val2_range = max(obj[1][1] for obj in archive) - min(obj[1][1] for obj in archive)\n        trade_off = val1_range / (val1_range + val2_range + 1e-6)\n    else:\n        trade_off = 0.5\n\n    # Step 1: Probabilistic item removal with dynamic trade-off\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = trade_off * marginal_value1 + (1 - trade_off) * marginal_value2\n\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-to-weight ratio insertion with dynamic trade-off\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        value_ratio1 = value1_lst[excluded_items] / weight_lst[excluded_items]\n        value_ratio2 = value2_lst[excluded_items] / weight_lst[excluded_items]\n        value_ratio = trade_off * value_ratio1 + (1 - trade_off) * value_ratio2\n\n        insertion_probs = value_ratio / np.sum(value_ratio)\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive crowding-aware exploration with trade-off adjustment\n    if len(archive) > 1:\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            # Adjust trade-off based on archive distribution\n            val1_mean = np.mean([obj[1][0] for obj in archive])\n            val2_mean = np.mean([obj[1][1] for obj in archive])\n            trade_off = (current_val1 - val1_mean) / ((current_val1 - val1_mean) + (current_val2 - val2_mean) + 1e-6)\n\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.087409982276544,
            -18.333686251170533
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a novel local search strategy that combines probabilistic item removal, value-weighted insertion, and adaptive crowding-aware exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = marginal_value1 + marginal_value2\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-weighted insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive crowding-aware exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.007733320328047,
            -18.34183790052968
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a novel local search strategy that combines probabilistic item removal, value-weighted insertion, and adaptive crowding-aware exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = marginal_value1 + marginal_value2\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-weighted insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive crowding-aware exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.651000064831955,
            -18.571452259751904
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a novel local search strategy that combines probabilistic item removal, value-weighted insertion, and adaptive crowding-aware exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = marginal_value1 + marginal_value2\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-weighted insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive crowding-aware exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.629058454554446,
            -18.63373950383197
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a novel local search strategy that combines probabilistic item removal, value-weighted insertion, and adaptive crowding-aware exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = marginal_value1 + marginal_value2\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-weighted insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive crowding-aware exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.623460475840023,
            -18.651252742408587
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive, then applies a hybrid local search that combines probabilistic item removal, value-driven insertion, and adaptive Pareto front exploration, while ensuring feasibility by dynamically adjusting the solution based on both objective values and their trade-offs.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = (marginal_value1 + marginal_value2) / weight_lst[included_items]\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-driven insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive Pareto front exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.623404664973524,
            -18.7290951023424
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a hybrid local search strategy that combines probabilistic item removal, value-to-weight ratio insertion, and adaptive crowding-aware exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = marginal_value1 + marginal_value2\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-to-weight ratio insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio1 = value1_lst[excluded_items] / weight_lst[excluded_items]\n        value_ratio2 = value2_lst[excluded_items] / weight_lst[excluded_items]\n        value_ratio = value_ratio1 + value_ratio2\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive crowding-aware exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.553997020849362,
            -18.850015607233225
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a novel local search strategy that combines probabilistic item removal, value-weighted insertion, and adaptive crowding-aware exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = marginal_value1 + marginal_value2\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-weighted insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive crowding-aware exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.651000064831955,
            -18.571452259751904
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a novel local search strategy that combines probabilistic item removal, value-weighted insertion, and adaptive crowding-aware exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = marginal_value1 + marginal_value2\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-weighted insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive crowding-aware exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.651000064831955,
            -18.571452259751904
        ]
    }
]