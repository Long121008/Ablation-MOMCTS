[
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective prioritization and diversity-aware perturbation with weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Novel objective-aware prioritization with weighted scoring\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with different weights\n        weighted_scores = (value1_lst * 0.5 + value2_lst * 0.5) / (weight_lst * 0.8 + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * 0.4 + value2_lst[included_items] * 0.6) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(4 * (1 - diversity) * random.uniform(0.7, 1.3)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with different weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with novel weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.5 + current_val2 * 0.5 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with novel scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.7 + 1e-6)\n        else:\n            # Focus on value1 improvement with novel scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.3 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with novel scoring\n            worst_scores = (value1_lst[included_items] * 0.5 + value2_lst[included_items] * 0.5) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.356773597723386,
            -19.210472051866034
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective weighting, diversity-aware exploration, and weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation while maintaining feasibility, using different parameter settings for the score function.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        weight_factor = 0.6 + 0.4 * (current_val1 / (current_val1 + current_val2 + 1e-6))\n\n        weighted_scores = (value1_lst * weight_factor + value2_lst * (1 - weight_factor)) / (weight_lst * 0.7 + 1e-6)\n\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n            worst_scores = (value1_lst[included_items] * (1 - weight_factor) + value2_lst[included_items] * weight_factor) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    if len(included_items) > 0:\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.6\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.6\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        exploration_intensity = max(1, int(3 * (1 - diversity) * random.uniform(0.7, 1.3)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.7 + current_val2 * 0.3 + 1e-6)\n\n        if ratio > 0.4:\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.7 + 1e-6)\n        else:\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            worst_scores = (value1_lst[included_items] * 0.5 + value2_lst[included_items] * 0.5) / (weight_lst[included_items] * 0.8 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.429360927582913,
            -19.090919246604173
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective prioritization and diversity-aware perturbation with weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Novel objective-aware prioritization with weighted scoring\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with different weights\n        weighted_scores = (value1_lst * 0.4 + value2_lst * 0.6) / (weight_lst * 0.7 + 1e-6)\n\n        # Select top items to consider\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * 0.3 + value2_lst[included_items] * 0.7) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(3 * (1 - diversity) * random.uniform(0.8, 1.2)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with different weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with novel weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.6 + current_val2 * 0.4 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with novel scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.6 + 1e-6)\n        else:\n            # Focus on value1 improvement with novel scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.4 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with novel scoring\n            worst_scores = (value1_lst[included_items] * 0.4 + value2_lst[included_items] * 0.6) / (weight_lst[included_items] * 0.5 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.10582703107761,
            -19.389330320689613
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for multi-objective improvement, then applies a novel local search strategy that combines objective-balanced item selection, adaptive objective prioritization, and diversity-aware perturbation to generate a high-quality neighbor solution while ensuring feasibility, using a creative approach that dynamically balances exploitation of high-value items with exploration of underrepresented objective regions.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Objective-balanced item selection (select items based on balanced objective contributions)\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective balance scores for excluded items\n        balance_scores = (value1_lst[excluded_items] / (np.sum(value1_lst[included_items]) + 1e-6) +\n                         value2_lst[excluded_items] / (np.sum(value2_lst[included_items]) + 1e-6)) / weight_lst[excluded_items]\n\n        # Select top k items to consider for selection\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(balance_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            select_idx = np.random.choice(top_indices)\n\n            # Find the least balanced item to replace based on current objective ratios\n            current_val1 = np.sum(value1_lst[included_items])\n            current_val2 = np.sum(value2_lst[included_items])\n            balance_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n            balance_scores_included = (value1_lst[included_items] * balance_ratio +\n                                      value2_lst[included_items] * (1 - balance_ratio)) / weight_lst[included_items]\n            replace_idx = np.argmin(balance_scores_included)\n            replace_idx = included_items[replace_idx]\n\n            # Perform selection if feasible\n            if current_weight - weight_lst[replace_idx] + weight_lst[select_idx] <= capacity:\n                new_solution[replace_idx] = 0\n                new_solution[select_idx] = 1\n\n    # Step 2: Adaptive objective prioritization (prioritize objectives based on solution state)\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective priorities based on current solution state\n        current_val1 = np.sum(value1_lst[included_items])\n        current_val2 = np.sum(value2_lst[included_items])\n        priority_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Calculate prioritization scores for excluded items\n        priority_scores = (value1_lst[excluded_items] * priority_ratio +\n                          value2_lst[excluded_items] * (1 - priority_ratio)) / weight_lst[excluded_items]\n\n        # Select top k items to consider for prioritization\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(priority_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            prioritize_idx = np.random.choice(top_indices)\n\n            # Find the worst item to replace based on current objective priorities\n            worst_scores = (value1_lst[included_items] * priority_ratio +\n                           value2_lst[included_items] * (1 - priority_ratio)) / weight_lst[included_items]\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform prioritization if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[prioritize_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[prioritize_idx] = 1\n\n    # Step 3: Diversity-aware perturbation (perturb solution based on objective diversity)\n    if len(included_items) > 0:\n        # Calculate objective diversity scores\n        obj1_diversity = len(np.unique(value1_lst[included_items])) / len(value1_lst)\n        obj2_diversity = len(np.unique(value2_lst[included_items])) / len(value2_lst)\n        diversity_score = min(obj1_diversity, obj2_diversity)\n\n        # Determine number of perturbations based on diversity (less diverse solutions get more changes)\n        num_perturb = max(1, int(4 * (1 - diversity_score)))\n\n        for _ in range(num_perturb):\n            # Select a random item to perturb\n            perturb_idx = random.randint(0, len(new_solution) - 1)\n\n            if new_solution[perturb_idx] == 1:\n                # Try to remove item if feasible\n                if current_weight - weight_lst[perturb_idx] <= capacity:\n                    new_solution[perturb_idx] = 0\n            else:\n                # Try to add item if feasible\n                if current_weight + weight_lst[perturb_idx] <= capacity:\n                    new_solution[perturb_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.230717983159106,
            -18.584336971242337
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective weighting and dynamic neighborhood exploration with item prioritization, using a combination of objective-aware scoring and diversity-sensitive perturbations to generate high-quality neighbors while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Adaptive objective weighting with novel scoring\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate dynamic weights based on current solution balance\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        obj1_weight = 0.5 + 0.3 * (current_val2 / (current_val1 + 1e-6))\n        obj2_weight = 0.5 + 0.3 * (current_val1 / (current_val2 + 1e-6))\n\n        # Novel scoring with dynamic weights\n        weighted_scores = (value1_lst * obj1_weight + value2_lst * obj2_weight) / (weight_lst * 0.6 + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * (1 - obj1_weight) + value2_lst[included_items] * (1 - obj2_weight)) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Dynamic neighborhood exploration with novel intensity\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(4 * (1 - diversity) * random.uniform(0.7, 1.3)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with dynamic weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with dynamic weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * obj1_weight + current_val2 * obj2_weight + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with novel scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n        else:\n            # Focus on value1 improvement with novel scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with novel scoring\n            worst_scores = (value1_lst[included_items] * obj1_weight + value2_lst[included_items] * obj2_weight) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.57056296382639,
            -19.073851764791637
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective prioritization and diversity-aware perturbation with weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement using novel selection criteria\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 1: Novel objective-aware prioritization with adaptive weights\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        weight_factor = 0.5 + 0.5 * (current_val1 / (current_val1 + current_val2 + 1e-6))\n\n        weighted_scores = (value1_lst * weight_factor + value2_lst * (1 - weight_factor)) / (weight_lst * 0.8 + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * (1 - weight_factor) + value2_lst[included_items] * weight_factor) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(4 * (1 - diversity) * random.uniform(0.7, 1.3)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with adaptive weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.7 + current_val2 * 0.3 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with adaptive scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.7 + 1e-6)\n        else:\n            # Focus on value1 improvement with adaptive scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with adaptive scoring\n            worst_scores = (value1_lst[included_items] * 0.5 + value2_lst[included_items] * 0.5) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.616111999506014,
            -19.002072254111845
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution with high potential for improvement by combining probabilistic item selection with objective-aware swaps, adaptive neighborhood exploration, and a novel score function that balances both objectives using a weighted sum approach to generate high-quality neighbor solutions while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic objective-aware selection with weighted score function\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate weighted combined objective scores\n        alpha = 0.7  # Weight for value1\n        beta = 0.3   # Weight for value2\n        combined_scores = (alpha * value1_lst + beta * value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(combined_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace based on weighted score\n            worst_scores = (alpha * value1_lst[included_items] + beta * value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with dynamic intensity\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(4 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Objective-specific fine-tuning with weighted replacement\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Adjust weights based on current balance\n        alpha = 0.6 if ratio > 0.5 else 0.4\n        beta = 1 - alpha\n\n        # Select items based on weighted improvement potential\n        improvement_scores = (alpha * value1_lst[excluded_items] + beta * value2_lst[excluded_items]) / (weight_lst[excluded_items] + 1e-6)\n\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace based on weighted score\n            worst_scores = (alpha * value1_lst[included_items] + beta * value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.486116593229788,
            -18.18120770566933
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for balanced objective improvement, then applies a hybrid local search strategy that combines probabilistic item prioritization, objective-aware replacement, and adaptive neighborhood diversification, while incorporating a novel item clustering technique to identify and exploit groups of items that contribute synergistically to both objectives.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for balanced improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Item clustering and prioritization\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate clustering scores for items (combining value and weight)\n        cluster_scores = (value1_lst * value2_lst) / (weight_lst + 1e-6)\n\n        # Find the most promising cluster to prioritize\n        cluster_indices = np.argsort(-cluster_scores[excluded_items])\n        cluster_size = min(5, len(cluster_indices))\n        cluster_indices = excluded_items[cluster_indices[:cluster_size]]\n\n        if len(cluster_indices) > 0:\n            prioritize_idx = np.random.choice(cluster_indices)\n\n            # Find the worst item in the current solution\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = included_items[np.argmin(worst_scores)]\n\n            # Perform prioritization if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[prioritize_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[prioritize_idx] = 1\n\n    # Step 2: Balanced objective replacement\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate replacement potential considering both objectives\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        balance_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        replacement_scores = (value1_lst[excluded_items] * (1 - balance_ratio) + value2_lst[excluded_items] * balance_ratio) / weight_lst[excluded_items]\n        replace_idx = np.random.choice(excluded_items, p=replacement_scores / np.sum(replacement_scores))\n\n        # Find the least balanced item to replace\n        balance_scores = (value1_lst[included_items] * (1 - balance_ratio) + value2_lst[included_items] * balance_ratio) / weight_lst[included_items]\n        least_balanced_idx = included_items[np.argmin(balance_scores)]\n\n        # Perform replacement if feasible\n        if current_weight - weight_lst[least_balanced_idx] + weight_lst[replace_idx] <= capacity:\n            new_solution[least_balanced_idx] = 0\n            new_solution[replace_idx] = 1\n\n    # Step 3: Adaptive neighborhood diversification with clustering awareness\n    if len(included_items) > 0:\n        # Calculate solution diversity using clustering information\n        cluster_diversity = len(np.unique(np.floor(value1_lst[included_items] / np.mean(value1_lst)))) * \\\n                           len(np.unique(np.floor(value2_lst[included_items] / np.mean(value2_lst))))\n\n        # Determine number of bits to flip based on cluster diversity\n        num_flips = max(1, int(3 * (1 - min(1, cluster_diversity / (len(included_items) + 1e-6)))))\n\n        for _ in range(num_flips):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.960380061248387,
            -18.694170138243813
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution with high potential for improvement in both objectives by combining probabilistic item selection with objective-aware swaps and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic objective-aware selection\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate combined objective scores\n        combined_scores = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(combined_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Objective-specific fine-tuning\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Select items based on objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        else:\n            # Focus on value1 improvement\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] * ratio + value2_lst[included_items] * (1 - ratio)) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.125194556064613,
            -18.64008991764989
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective prioritization and diversity-aware perturbation with weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement using novel selection criteria\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 1: Novel objective-aware prioritization with adaptive weights\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        weight_factor = 0.5 + 0.5 * (current_val1 / (current_val1 + current_val2 + 1e-6))\n\n        weighted_scores = (value1_lst * weight_factor + value2_lst * (1 - weight_factor)) / (weight_lst * 0.9 + 1e-6)\n\n        # Select top items to consider\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * (1 - weight_factor) + value2_lst[included_items] * weight_factor) / (weight_lst[included_items] * 0.8 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(5 * (1 - diversity) * random.uniform(0.6, 1.4)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with adaptive weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.8 + current_val2 * 0.2 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with adaptive scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.8 + 1e-6)\n        else:\n            # Focus on value1 improvement with adaptive scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.6 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with adaptive scoring\n            worst_scores = (value1_lst[included_items] * 0.6 + value2_lst[included_items] * 0.4) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.654494884729814,
            -18.99401824580087
        ]
    }
]