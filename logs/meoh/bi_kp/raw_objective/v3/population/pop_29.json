[
    {
        "algorithm": "{A novel hybrid local search operator combines a dynamic neighborhood exploration strategy with a probabilistic item swap mechanism using a different score function parameterization to intelligently perturb solutions while ensuring feasibility, balancing exploration of promising regions and exploitation of high-value items.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and objective values\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Step 1: Dynamic neighborhood exploration - flip items based on their contribution to objectives\n    num_items = len(base_solution)\n    flip_indices = np.random.choice(num_items, size=min(3, num_items), replace=False)\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            # Calculate potential new weight and objective values if we remove this item\n            new_weight = current_weight - weight_lst[idx]\n            new_value1 = current_value1 - value1_lst[idx]\n            new_value2 = current_value2 - value2_lst[idx]\n\n            # Only flip if it doesn't violate capacity and improves at least one objective\n            if new_weight <= capacity:\n                new_solution[idx] = 0\n                current_weight = new_weight\n                current_value1 = new_value1\n                current_value2 = new_value2\n        else:\n            # Calculate potential new weight and objective values if we add this item\n            new_weight = current_weight + weight_lst[idx]\n            new_value1 = current_value1 + value1_lst[idx]\n            new_value2 = current_value2 + value2_lst[idx]\n\n            # Only flip if it doesn't violate capacity and improves at least one objective\n            if new_weight <= capacity:\n                new_solution[idx] = 1\n                current_weight = new_weight\n                current_value1 = new_value1\n                current_value2 = new_value2\n\n    # Step 2: Probabilistic item swap - swap items based on their marginal contribution\n    for _ in range(2):  # Perform 2 swaps\n        in_items = np.where(new_solution == 0)[0]\n        out_items = np.where(new_solution == 1)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Calculate marginal contribution scores for in-items (potential additions)\n            in_scores = (value1_lst[in_items] * 0.4 + value2_lst[in_items] * 0.6) / (weight_lst[in_items] + 1e-6)\n\n            # Calculate marginal contribution scores for out-items (potential removals)\n            out_scores = (value1_lst[out_items] * 0.6 + value2_lst[out_items] * 0.4) / (weight_lst[out_items] + 1e-6)\n\n            # Select items to swap\n            best_in = in_items[np.argmax(in_scores)]\n            worst_out = out_items[np.argmin(out_scores)]\n\n            # Check if swap is feasible\n            if (current_weight - weight_lst[worst_out] + weight_lst[best_in]) <= capacity:\n                new_solution[worst_out] = 0\n                new_solution[best_in] = 1\n                current_weight = current_weight - weight_lst[worst_out] + weight_lst[best_in]\n\n    # Step 3: Final perturbation - flip items with low contribution\n    for idx in range(num_items):\n        if new_solution[idx] == 1:\n            # Calculate contribution of this item to both objectives\n            contribution1 = value1_lst[idx] / (weight_lst[idx] + 1e-6)\n            contribution2 = value2_lst[idx] / (weight_lst[idx] + 1e-6)\n\n            # Flip if contribution is below a threshold and removal is feasible\n            if (contribution1 < 0.1 and contribution2 < 0.1 and\n                current_weight - weight_lst[idx] <= capacity):\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -19.041812590657923,
            -18.706379783910265
        ]
    },
    {
        "algorithm": "{A novel hybrid local search operator combines a dynamic neighborhood exploration strategy with a probabilistic item swap mechanism to intelligently perturb solutions while ensuring feasibility, balancing exploration of promising regions and exploitation of high-value items.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    archive.sort(key=lambda x: -(x[1][0] * 0.7 + x[1][1] * 0.3))  # Sort by weighted total value\n    selected_idx = min(1, len(archive) - 1)  # Select from top 2 solutions\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Phase 1: Value-driven item replacement with different scoring\n    for _ in range(2):  # Perform 2 replacements\n        in_items = np.where(new_solution == 0)[0]\n        out_items = np.where(new_solution == 1)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Calculate value scores with different weights\n            in_scores = (value1_lst[in_items] * 0.5 + value2_lst[in_items] * 0.5) / weight_lst[in_items]\n            out_scores = (value1_lst[out_items] * 0.3 + value2_lst[out_items] * 0.7) / weight_lst[out_items]\n\n            best_in = in_items[np.argmax(in_scores)]\n            worst_out = out_items[np.argmin(out_scores)]\n\n            if (current_weight - weight_lst[worst_out] + weight_lst[best_in]) <= capacity:\n                new_solution[worst_out] = 0\n                new_solution[best_in] = 1\n                current_weight = current_weight - weight_lst[worst_out] + weight_lst[best_in]\n\n    # Phase 2: Randomized perturbation with different probability\n    num_items = len(base_solution)\n    perturb_indices = np.random.choice(num_items, size=min(3, num_items), replace=False)\n    for idx in perturb_indices:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.20505881486052,
            -19.23128181075814
        ]
    },
    {
        "algorithm": "{A novel hybrid local search operator that combines adaptive objective-driven clustering with dynamic value-aware perturbations and feasibility-preserving swaps, using a three-stage strategy of cluster-based value optimization, probabilistic objective-balanced flips, and capacity-constrained item swaps to explore diverse non-dominated regions while maintaining solution quality across both objectives.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    current_weight = np.sum(weight_lst * new_solution)\n    num_items = len(new_solution)\n\n    # Stage 1: Adaptive objective-driven clustering and value optimization\n    cluster_size = max(3, num_items // 5)\n    for _ in range(3):\n        indices = np.random.choice(num_items, size=cluster_size, replace=False)\n        cluster_in = indices[new_solution[indices] == 0]\n        cluster_out = indices[new_solution[indices] == 1]\n\n        if len(cluster_in) > 0 and len(cluster_out) > 0:\n            # Dynamic objective weighting based on current solution\n            alpha = 0.5 + 0.3 * (current_weight / capacity)\n            in_scores = (value1_lst[cluster_in] * alpha + value2_lst[cluster_in] * (1-alpha)) / weight_lst[cluster_in]\n            out_scores = (value1_lst[cluster_out] * (1-alpha) + value2_lst[cluster_out] * alpha) / weight_lst[cluster_out]\n\n            best_in = cluster_in[np.argmax(in_scores)]\n            worst_out = cluster_out[np.argmin(out_scores)]\n\n            if (current_weight - weight_lst[worst_out] + weight_lst[best_in]) <= capacity:\n                new_solution[worst_out] = 0\n                new_solution[best_in] = 1\n                current_weight = current_weight - weight_lst[worst_out] + weight_lst[best_in]\n\n    # Stage 2: Probabilistic objective-balanced flips\n    for _ in range(4):\n        indices = np.random.choice(num_items, size=min(5, num_items), replace=False)\n        for idx in indices:\n            if new_solution[idx] == 1:\n                # More likely to remove low-value items\n                prob = 0.3 * (1 - (value1_lst[idx] + value2_lst[idx]) / (np.max(value1_lst) + np.max(value2_lst)))\n                if np.random.random() < prob:\n                    if current_weight - weight_lst[idx] <= capacity:\n                        new_solution[idx] = 0\n                        current_weight -= weight_lst[idx]\n            else:\n                # More likely to add high-value items\n                prob = 0.6 * (value1_lst[idx] + value2_lst[idx]) / (np.max(value1_lst) + np.max(value2_lst))\n                if np.random.random() < prob and (current_weight + weight_lst[idx]) <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Stage 3: Feasibility-preserving capacity-constrained swaps\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        # Remove items with lowest value-to-weight ratio first\n        sorted_out_items = np.where(new_solution == 1)[0]\n        ratios = (value1_lst[sorted_out_items] + value2_lst[sorted_out_items]) / weight_lst[sorted_out_items]\n        sorted_out_items = sorted_out_items[np.argsort(ratios)]\n\n        for idx in sorted_out_items:\n            if excess_weight <= 0:\n                break\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -19.147291780676333,
            -18.67953653241325
        ]
    },
    {
        "algorithm": "{A novel hybrid local search operator that employs adaptive objective weighting with probabilistic swaps and dynamic neighborhood exploration, combining value-weighted replacements with simulated annealing-style perturbations to enhance solution quality while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    archive.sort(key=lambda x: -(x[1][0] * 0.7 + x[1][1] * 0.3))\n    selected_idx = np.random.choice(min(3, len(archive)))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Adaptive objective weighting with probabilistic swaps\n    for _ in range(5):\n        obj_weight = np.random.random()\n        in_items = np.where(new_solution == 0)[0]\n        out_items = np.where(new_solution == 1)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Calculate combined scores\n            in_scores = (value1_lst[in_items] * obj_weight + value2_lst[in_items] * (1 - obj_weight)) / weight_lst[in_items]\n            out_scores = (value1_lst[out_items] * obj_weight + value2_lst[out_items] * (1 - obj_weight)) / weight_lst[out_items]\n\n            best_in = in_items[np.argmax(in_scores)]\n            worst_out = out_items[np.argmin(out_scores)]\n\n            if (current_weight - weight_lst[worst_out] + weight_lst[best_in]) <= capacity:\n                new_solution[worst_out] = 0\n                new_solution[best_in] = 1\n                current_weight = current_weight - weight_lst[worst_out] + weight_lst[best_in]\n\n    # Phase 2: Simulated annealing-style perturbations\n    temperature = 1.0\n    cooling_rate = 0.95\n\n    for _ in range(3):\n        indices = np.random.choice(len(new_solution), size=min(5, len(new_solution)), replace=False)\n\n        for idx in indices:\n            if new_solution[idx] == 1:\n                if np.random.random() < temperature * 0.3:\n                    if current_weight - weight_lst[idx] <= capacity:\n                        new_solution[idx] = 0\n                        current_weight -= weight_lst[idx]\n            else:\n                if np.random.random() < temperature * 0.7 and (current_weight + weight_lst[idx]) <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        temperature *= cooling_rate\n\n    return new_solution\n\n",
        "score": [
            -19.33481180473102,
            -18.369501639292274
        ]
    },
    {
        "algorithm": "{An innovative local search operator that combines adaptive objective-driven clustering with probabilistic item reassignment and dynamic weight balancing, using a four-phase strategy of value-aware clustering, objective-balanced swaps, probabilistic perturbations, and feasibility-preserving flips to explore diverse non-dominated regions while maintaining solution quality across both objectives.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    archive.sort(key=lambda x: -(x[1][0] * 0.7 + x[1][1] * 0.3))\n    selected_idx = np.random.choice(min(3, len(archive)))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    current_weight = np.sum(weight_lst * new_solution)\n    num_items = len(new_solution)\n\n    # Phase 1: Value-aware clustering and swaps\n    cluster_size = max(2, num_items // 3)\n    for _ in range(5):\n        indices = np.random.choice(num_items, size=cluster_size, replace=False)\n        cluster_in = indices[new_solution[indices] == 0]\n        cluster_out = indices[new_solution[indices] == 1]\n\n        if len(cluster_in) > 0 and len(cluster_out) > 0:\n            # Dynamic objective weighting based on current solution\n            alpha = 0.4 + 0.3 * (current_weight / capacity)\n            in_scores = (value1_lst[cluster_in] * alpha + value2_lst[cluster_in] * (1-alpha)) / weight_lst[cluster_in]\n            out_scores = (value1_lst[cluster_out] * (1-alpha) + value2_lst[cluster_out] * alpha) / weight_lst[cluster_out]\n\n            best_in = cluster_in[np.argmax(in_scores)]\n            worst_out = cluster_out[np.argmin(out_scores)]\n\n            if (current_weight - weight_lst[worst_out] + weight_lst[best_in]) <= capacity:\n                new_solution[worst_out] = 0\n                new_solution[best_in] = 1\n                current_weight = current_weight - weight_lst[worst_out] + weight_lst[best_in]\n\n    # Phase 2: Objective-balanced probabilistic reassignment\n    for _ in range(4):\n        indices = np.random.choice(num_items, size=min(6, num_items), replace=False)\n        for idx in indices:\n            if new_solution[idx] == 1:\n                prob = 0.5 * (1 - (value1_lst[idx] + value2_lst[idx]) / (np.max(value1_lst) + np.max(value2_lst)))\n                if np.random.random() < prob:\n                    if current_weight - weight_lst[idx] <= capacity:\n                        new_solution[idx] = 0\n            else:\n                prob = 0.8 * (value1_lst[idx] + value2_lst[idx]) / (np.max(value1_lst) + np.max(value2_lst))\n                if np.random.random() < prob and (current_weight + weight_lst[idx]) <= capacity:\n                    new_solution[idx] = 1\n\n    # Phase 3: Dynamic weight balancing\n    if current_weight < capacity * 0.9:\n        available_weight = capacity - current_weight\n        potential_items = np.where(new_solution == 0)[0]\n        ratios = (value1_lst[potential_items] + value2_lst[potential_items]) / weight_lst[potential_items]\n        sorted_items = potential_items[np.argsort(ratios)[::-1]]\n\n        for idx in sorted_items:\n            if available_weight < weight_lst[idx]:\n                break\n            if np.random.random() < 0.6:\n                new_solution[idx] = 1\n                available_weight -= weight_lst[idx]\n\n    # Phase 4: Feasibility-preserving flips with objective-aware selection\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        sorted_out_items = np.where(new_solution == 1)[0]\n        ratios = (value1_lst[sorted_out_items] * 0.6 + value2_lst[sorted_out_items] * 0.4) / weight_lst[sorted_out_items]\n        sorted_out_items = sorted_out_items[np.argsort(ratios)]\n\n        for idx in sorted_out_items:\n            if excess_weight <= 0:\n                break\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -19.266871280476426,
            -18.375588943544614
        ]
    },
    {
        "algorithm": "{A novel hybrid local search operator combines a dynamic neighborhood exploration strategy with a probabilistic item swap mechanism using a different score function parameterization to intelligently perturb solutions while ensuring feasibility, balancing exploration of promising regions and exploitation of high-value items.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and objective values\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Step 1: Dynamic neighborhood exploration - flip items based on their contribution to objectives\n    num_items = len(base_solution)\n    flip_indices = np.random.choice(num_items, size=min(3, num_items), replace=False)\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            # Calculate potential new weight and objective values if we remove this item\n            new_weight = current_weight - weight_lst[idx]\n            new_value1 = current_value1 - value1_lst[idx]\n            new_value2 = current_value2 - value2_lst[idx]\n\n            # Only flip if it doesn't violate capacity and improves at least one objective\n            if new_weight <= capacity:\n                new_solution[idx] = 0\n                current_weight = new_weight\n                current_value1 = new_value1\n                current_value2 = new_value2\n        else:\n            # Calculate potential new weight and objective values if we add this item\n            new_weight = current_weight + weight_lst[idx]\n            new_value1 = current_value1 + value1_lst[idx]\n            new_value2 = current_value2 + value2_lst[idx]\n\n            # Only flip if it doesn't violate capacity and improves at least one objective\n            if new_weight <= capacity:\n                new_solution[idx] = 1\n                current_weight = new_weight\n                current_value1 = new_value1\n                current_value2 = new_value2\n\n    # Step 2: Probabilistic item swap - swap items based on their marginal contribution\n    for _ in range(2):  # Perform 2 swaps\n        in_items = np.where(new_solution == 0)[0]\n        out_items = np.where(new_solution == 1)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Calculate marginal contribution scores for in-items (potential additions)\n            in_scores = (value1_lst[in_items] * 0.4 + value2_lst[in_items] * 0.6) / (weight_lst[in_items] + 1e-6)\n\n            # Calculate marginal contribution scores for out-items (potential removals)\n            out_scores = (value1_lst[out_items] * 0.6 + value2_lst[out_items] * 0.4) / (weight_lst[out_items] + 1e-6)\n\n            # Select items to swap\n            best_in = in_items[np.argmax(in_scores)]\n            worst_out = out_items[np.argmin(out_scores)]\n\n            # Check if swap is feasible\n            if (current_weight - weight_lst[worst_out] + weight_lst[best_in]) <= capacity:\n                new_solution[worst_out] = 0\n                new_solution[best_in] = 1\n                current_weight = current_weight - weight_lst[worst_out] + weight_lst[best_in]\n\n    # Step 3: Final perturbation - flip items with low contribution\n    for idx in range(num_items):\n        if new_solution[idx] == 1:\n            # Calculate contribution of this item to both objectives\n            contribution1 = value1_lst[idx] / (weight_lst[idx] + 1e-6)\n            contribution2 = value2_lst[idx] / (weight_lst[idx] + 1e-6)\n\n            # Flip if contribution is below a threshold and removal is feasible\n            if (contribution1 < 0.1 and contribution2 < 0.1 and\n                current_weight - weight_lst[idx] <= capacity):\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -19.00183097183058,
            -18.72652047854329
        ]
    },
    {
        "algorithm": "{An adaptive multi-objective local search operator that combines value-weighted clustering with probabilistic item reassignment, using dynamically adjusted objective weights and a three-phase strategy of cluster-based swaps, weighted perturbations, and feasibility-preserving flips to explore diverse non-dominated regions while maintaining solution quality across both objectives.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = np.random.choice(min(3, len(archive)))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    current_weight = np.sum(weight_lst * new_solution)\n    num_items = len(new_solution)\n\n    # Phase 1: Value-weighted clustering and swaps\n    cluster_size = max(2, num_items // 5)\n    for _ in range(3):\n        indices = np.random.choice(num_items, size=cluster_size, replace=False)\n        cluster_in = indices[new_solution[indices] == 0]\n        cluster_out = indices[new_solution[indices] == 1]\n\n        if len(cluster_in) > 0 and len(cluster_out) > 0:\n            alpha = np.random.uniform(0.3, 0.7)\n            in_scores = (value1_lst[cluster_in] * alpha + value2_lst[cluster_in] * (1-alpha)) / weight_lst[cluster_in]\n            out_scores = (value1_lst[cluster_out] * (1-alpha) + value2_lst[cluster_out] * alpha) / weight_lst[cluster_out]\n\n            best_in = cluster_in[np.argmax(in_scores)]\n            worst_out = cluster_out[np.argmin(out_scores)]\n\n            if (current_weight - weight_lst[worst_out] + weight_lst[best_in]) <= capacity:\n                new_solution[worst_out] = 0\n                new_solution[best_in] = 1\n                current_weight = current_weight - weight_lst[worst_out] + weight_lst[best_in]\n\n    # Phase 2: Weighted probabilistic reassignment\n    for _ in range(4):\n        indices = np.random.choice(num_items, size=min(5, num_items), replace=False)\n        for idx in indices:\n            if new_solution[idx] == 1:\n                prob = 0.3 * (1 - (value1_lst[idx] + value2_lst[idx]) / (np.max(value1_lst) + np.max(value2_lst)))\n                if np.random.random() < prob:\n                    if current_weight - weight_lst[idx] <= capacity:\n                        new_solution[idx] = 0\n            else:\n                prob = 0.6 * (value1_lst[idx] + value2_lst[idx]) / (np.max(value1_lst) + np.max(value2_lst))\n                if np.random.random() < prob and (current_weight + weight_lst[idx]) <= capacity:\n                    new_solution[idx] = 1\n\n    # Phase 3: Feasibility-preserving flips\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        sorted_out_items = np.where(new_solution == 1)[0]\n        sorted_out_items = sorted_out_items[np.argsort(weight_lst[sorted_out_items])]\n\n        for idx in sorted_out_items:\n            if excess_weight <= 0:\n                break\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -19.199864642504828,
            -18.63046041440944
        ]
    },
    {
        "algorithm": "{An innovative multi-objective local search operator that combines adaptive objective weighting with dynamic cluster-based swaps and a novel \"value-balancing\" perturbation strategy, using a four-phase approach of weighted item clustering, probabilistic value-balancing swaps, adaptive objective-driven flips, and a feasibility-aware knapsack optimization phase to explore high-quality non-dominated regions while maintaining solution diversity.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = np.random.choice(min(3, len(archive)))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    current_weight = np.sum(weight_lst * new_solution)\n    num_items = len(new_solution)\n\n    # Phase 1: Adaptive objective weighting and clustering\n    alpha = np.random.uniform(0.4, 0.6)\n    cluster_size = max(3, num_items // 4)\n    for _ in range(4):\n        indices = np.random.choice(num_items, size=cluster_size, replace=False)\n        cluster_in = indices[new_solution[indices] == 0]\n        cluster_out = indices[new_solution[indices] == 1]\n\n        if len(cluster_in) > 0 and len(cluster_out) > 0:\n            in_scores = (value1_lst[cluster_in] * alpha + value2_lst[cluster_in] * (1-alpha)) / weight_lst[cluster_in]\n            out_scores = (value1_lst[cluster_out] * (1-alpha) + value2_lst[cluster_out] * alpha) / weight_lst[cluster_out]\n\n            best_in = cluster_in[np.argmax(in_scores)]\n            worst_out = cluster_out[np.argmin(out_scores)]\n\n            if (current_weight - weight_lst[worst_out] + weight_lst[best_in]) <= capacity:\n                new_solution[worst_out] = 0\n                new_solution[best_in] = 1\n                current_weight = current_weight - weight_lst[worst_out] + weight_lst[best_in]\n\n    # Phase 2: Value-balancing perturbation\n    for _ in range(5):\n        indices = np.random.choice(num_items, size=min(6, num_items), replace=False)\n        for idx in indices:\n            if new_solution[idx] == 1:\n                balance_factor = (value1_lst[idx] - value2_lst[idx]) / (np.max(value1_lst) + np.max(value2_lst))\n                if balance_factor > 0.4 and np.random.random() < 0.4:\n                    if current_weight - weight_lst[idx] <= capacity:\n                        new_solution[idx] = 0\n            else:\n                balance_factor = (value2_lst[idx] - value1_lst[idx]) / (np.max(value1_lst) + np.max(value2_lst))\n                if balance_factor > 0.4 and np.random.random() < 0.5 and (current_weight + weight_lst[idx]) <= capacity:\n                    new_solution[idx] = 1\n\n    # Phase 3: Adaptive objective-driven flips\n    for _ in range(3):\n        indices = np.random.choice(num_items, size=min(4, num_items), replace=False)\n        for idx in indices:\n            if new_solution[idx] == 1:\n                if (value1_lst[idx] + value2_lst[idx]) < (np.mean(value1_lst) + np.mean(value2_lst)) and np.random.random() < 0.3:\n                    if current_weight - weight_lst[idx] <= capacity:\n                        new_solution[idx] = 0\n            else:\n                if (value1_lst[idx] + value2_lst[idx]) > (np.mean(value1_lst) + np.mean(value2_lst)) and np.random.random() < 0.4:\n                    if (current_weight + weight_lst[idx]) <= capacity:\n                        new_solution[idx] = 1\n\n    # Phase 4: Feasibility-aware knapsack optimization\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        sorted_out_items = np.where(new_solution == 1)[0]\n        sorted_out_items = sorted_out_items[np.argsort((value1_lst[sorted_out_items] + value2_lst[sorted_out_items]) / weight_lst[sorted_out_items])]\n\n        for idx in sorted_out_items:\n            if excess_weight <= 0:\n                break\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -19.234178867351673,
            -18.59473921852168
        ]
    },
    {
        "algorithm": "{A novel adaptive hybrid local search operator uses a weighted sum of normalized objective contributions with dynamic parameterization to guide item selection, combined with a probabilistic swap mechanism that considers both individual and combined objective impacts while maintaining feasibility through capacity-aware perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    base_solution, _ = max(archive, key=lambda x: sum(x[1]))\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and objective values\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Step 1: Dynamic neighborhood exploration - flip items based on adaptive weighted contribution\n    num_items = len(base_solution)\n    flip_indices = np.random.choice(num_items, size=min(4, num_items), replace=False)\n\n    # Normalize objective values\n    max_value1 = np.max(value1_lst) if np.max(value1_lst) != 0 else 1\n    max_value2 = np.max(value2_lst) if np.max(value2_lst) != 0 else 1\n\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            # Calculate potential new weight and objective values if we remove this item\n            new_weight = current_weight - weight_lst[idx]\n            new_value1 = current_value1 - value1_lst[idx]\n            new_value2 = current_value2 - value2_lst[idx]\n\n            # Only flip if it doesn't violate capacity and improves at least one objective\n            if new_weight <= capacity:\n                new_solution[idx] = 0\n                current_weight = new_weight\n                current_value1 = new_value1\n                current_value2 = new_value2\n        else:\n            # Calculate potential new weight and objective values if we add this item\n            new_weight = current_weight + weight_lst[idx]\n            new_value1 = current_value1 + value1_lst[idx]\n            new_value2 = current_value2 + value2_lst[idx]\n\n            # Only flip if it doesn't violate capacity and improves at least one objective\n            if new_weight <= capacity:\n                new_solution[idx] = 1\n                current_weight = new_weight\n                current_value1 = new_value1\n                current_value2 = new_value2\n\n    # Step 2: Probabilistic item swap - swap items based on adaptive weighted marginal contribution\n    for _ in range(3):  # Perform 3 swaps\n        in_items = np.where(new_solution == 0)[0]\n        out_items = np.where(new_solution == 1)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Calculate adaptive weighted marginal contribution scores for in-items\n            in_scores = (value1_lst[in_items] / max_value1 * 0.7 + value2_lst[in_items] / max_value2 * 0.3) / (weight_lst[in_items] + 1e-6)\n\n            # Calculate adaptive weighted marginal contribution scores for out-items\n            out_scores = (value1_lst[out_items] / max_value1 * 0.3 + value2_lst[out_items] / max_value2 * 0.7) / (weight_lst[out_items] + 1e-6)\n\n            # Select items to swap\n            best_in = in_items[np.argmax(in_scores)]\n            worst_out = out_items[np.argmin(out_scores)]\n\n            # Check if swap is feasible\n            if (current_weight - weight_lst[worst_out] + weight_lst[best_in]) <= capacity:\n                new_solution[worst_out] = 0\n                new_solution[best_in] = 1\n                current_weight = current_weight - weight_lst[worst_out] + weight_lst[best_in]\n\n    # Step 3: Final perturbation - flip items with low adaptive contribution\n    for idx in range(num_items):\n        if new_solution[idx] == 1:\n            # Calculate adaptive weighted contribution\n            contribution = (value1_lst[idx] / max_value1 * 0.6 + value2_lst[idx] / max_value2 * 0.4) / (weight_lst[idx] + 1e-6)\n\n            # Flip if contribution is below threshold and removal is feasible\n            if (contribution < 0.3 and current_weight - weight_lst[idx] <= capacity):\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -18.87393056072719,
            -18.77002733447549
        ]
    },
    {
        "algorithm": "{An adaptive density-balanced neighborhood search that dynamically prioritizes high-value items using a weighted combination of value-to-weight ratios and solution quality gradients, followed by a hybrid of targeted swaps and stochastic perturbations to explore the Pareto frontier while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    archive.sort(key=lambda x: -(x[1][0] * 0.7 + x[1][1] * 0.3))\n    selected_idx = min(2, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    value_density1 = value1_lst / (weight_lst + 1e-6)\n    value_density2 = value2_lst / (weight_lst + 1e-6)\n    combined_density = value_density1 * 0.3 + value_density2 * 0.7\n\n    new_solution = base_solution.copy()\n    for _ in range(4):\n        in_items = np.where(new_solution == 0)[0]\n        out_items = np.where(new_solution == 1)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            best_in = in_items[np.argmax(combined_density[in_items])]\n            worst_out = out_items[np.argmin(combined_density[out_items])]\n\n            if (current_weight - weight_lst[worst_out] + weight_lst[best_in]) <= capacity:\n                new_solution[worst_out] = 0\n                new_solution[best_in] = 1\n                current_weight = current_weight - weight_lst[worst_out] + weight_lst[best_in]\n\n    num_perturb = min(3, len(new_solution))\n    perturb_indices = np.random.choice(len(new_solution), size=num_perturb, replace=False)\n\n    for idx in perturb_indices:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -17.67891150990767,
            -19.521582483776108
        ]
    }
]