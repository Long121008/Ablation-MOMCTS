[
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for objective-specific improvement, then applies a hybrid local search strategy that combines probabilistic item prioritization, objective-aware replacement, and adaptive neighborhood diversification to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for objective-specific improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item prioritization (select items based on objective-specific priorities)\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific priorities for included items\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        priority_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Calculate prioritization scores for excluded items\n        priority_scores = (value1_lst[excluded_items] * priority_ratio + value2_lst[excluded_items] * (1 - priority_ratio)) / (weight_lst[excluded_items] + 1e-6)\n\n        # Select top k items to consider for prioritization\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(priority_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            prioritize_idx = np.random.choice(top_indices)\n\n            # Find the worst item to replace based on current objective priorities\n            worst_scores = (value1_lst[included_items] * priority_ratio + value2_lst[included_items] * (1 - priority_ratio)) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform prioritization if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[prioritize_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[prioritize_idx] = 1\n\n    # Step 2: Objective-aware replacement (replace items based on their potential to improve both objectives)\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate potential improvement scores for excluded items\n        improvement_scores = (value1_lst[excluded_items] + value2_lst[excluded_items]) / (weight_lst[excluded_items] + 1e-6)\n\n        # Select top k items to consider for improvement\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(improvement_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            improve_idx = np.random.choice(top_indices)\n\n            # Find the least valuable item to replace based on combined objective values\n            least_val_idx = np.argmin((value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6))\n            least_val_idx = included_items[least_val_idx]\n\n            # Perform improvement if feasible\n            if current_weight - weight_lst[least_val_idx] + weight_lst[improve_idx] <= capacity:\n                new_solution[least_val_idx] = 0\n                new_solution[improve_idx] = 1\n\n    # Step 3: Adaptive neighborhood diversification (flip bits based on solution diversity)\n    if len(included_items) > 0:\n        # Calculate solution diversity as the ratio of unique objective contributions\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine number of bits to flip based on diversity (less diverse solutions get more changes)\n        num_flips = max(1, int(4 * (1 - diversity)))\n\n        for _ in range(num_flips):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.291897096912464,
            -18.514303412175323
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective weighting and dynamic neighborhood exploration with item prioritization, using a combination of objective-aware scoring and diversity-sensitive perturbations to generate high-quality neighbors while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Adaptive objective weighting with novel scoring\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate dynamic weights based on current solution balance\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        obj1_weight = 0.5 + 0.3 * (current_val2 / (current_val1 + 1e-6))\n        obj2_weight = 0.5 + 0.3 * (current_val1 / (current_val2 + 1e-6))\n\n        # Novel scoring with dynamic weights\n        weighted_scores = (value1_lst * obj1_weight + value2_lst * obj2_weight) / (weight_lst * 0.6 + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * (1 - obj1_weight) + value2_lst[included_items] * (1 - obj2_weight)) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Dynamic neighborhood exploration with novel intensity\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(4 * (1 - diversity) * random.uniform(0.7, 1.3)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with dynamic weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with dynamic weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * obj1_weight + current_val2 * obj2_weight + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with novel scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n        else:\n            # Focus on value1 improvement with novel scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with novel scoring\n            worst_scores = (value1_lst[included_items] * obj1_weight + value2_lst[included_items] * obj2_weight) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.57056296382639,
            -19.073851764791637
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective prioritization and diversity-aware perturbation with weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement using novel selection criteria\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 1: Novel objective-aware prioritization with adaptive weights\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        weight_factor = 0.5 + 0.5 * (current_val1 / (current_val1 + current_val2 + 1e-6))\n\n        weighted_scores = (value1_lst * weight_factor + value2_lst * (1 - weight_factor)) / (weight_lst * 0.8 + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * (1 - weight_factor) + value2_lst[included_items] * weight_factor) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(4 * (1 - diversity) * random.uniform(0.7, 1.3)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with adaptive weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.7 + current_val2 * 0.3 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with adaptive scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.7 + 1e-6)\n        else:\n            # Focus on value1 improvement with adaptive scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with adaptive scoring\n            worst_scores = (value1_lst[included_items] * 0.5 + value2_lst[included_items] * 0.5) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.616111999506014,
            -19.002072254111845
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution with high potential for improvement by combining probabilistic item selection with objective-aware swaps, adaptive neighborhood exploration, and a novel score function that balances both objectives using a weighted sum approach to generate high-quality neighbor solutions while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic objective-aware selection with weighted score function\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate weighted combined objective scores\n        alpha = 0.7  # Weight for value1\n        beta = 0.3   # Weight for value2\n        combined_scores = (alpha * value1_lst + beta * value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(combined_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace based on weighted score\n            worst_scores = (alpha * value1_lst[included_items] + beta * value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with dynamic intensity\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(4 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Objective-specific fine-tuning with weighted replacement\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Adjust weights based on current balance\n        alpha = 0.6 if ratio > 0.5 else 0.4\n        beta = 1 - alpha\n\n        # Select items based on weighted improvement potential\n        improvement_scores = (alpha * value1_lst[excluded_items] + beta * value2_lst[excluded_items]) / (weight_lst[excluded_items] + 1e-6)\n\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace based on weighted score\n            worst_scores = (alpha * value1_lst[included_items] + beta * value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.486116593229788,
            -18.18120770566933
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for balanced objective improvement, then applies a hybrid local search strategy that combines probabilistic item prioritization, objective-aware replacement, and adaptive neighborhood diversification, while incorporating a novel item clustering technique to identify and exploit groups of items that contribute synergistically to both objectives.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for balanced improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Item clustering and prioritization\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate clustering scores for items (combining value and weight)\n        cluster_scores = (value1_lst * value2_lst) / (weight_lst + 1e-6)\n\n        # Find the most promising cluster to prioritize\n        cluster_indices = np.argsort(-cluster_scores[excluded_items])\n        cluster_size = min(5, len(cluster_indices))\n        cluster_indices = excluded_items[cluster_indices[:cluster_size]]\n\n        if len(cluster_indices) > 0:\n            prioritize_idx = np.random.choice(cluster_indices)\n\n            # Find the worst item in the current solution\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = included_items[np.argmin(worst_scores)]\n\n            # Perform prioritization if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[prioritize_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[prioritize_idx] = 1\n\n    # Step 2: Balanced objective replacement\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate replacement potential considering both objectives\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        balance_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        replacement_scores = (value1_lst[excluded_items] * (1 - balance_ratio) + value2_lst[excluded_items] * balance_ratio) / weight_lst[excluded_items]\n        replace_idx = np.random.choice(excluded_items, p=replacement_scores / np.sum(replacement_scores))\n\n        # Find the least balanced item to replace\n        balance_scores = (value1_lst[included_items] * (1 - balance_ratio) + value2_lst[included_items] * balance_ratio) / weight_lst[included_items]\n        least_balanced_idx = included_items[np.argmin(balance_scores)]\n\n        # Perform replacement if feasible\n        if current_weight - weight_lst[least_balanced_idx] + weight_lst[replace_idx] <= capacity:\n            new_solution[least_balanced_idx] = 0\n            new_solution[replace_idx] = 1\n\n    # Step 3: Adaptive neighborhood diversification with clustering awareness\n    if len(included_items) > 0:\n        # Calculate solution diversity using clustering information\n        cluster_diversity = len(np.unique(np.floor(value1_lst[included_items] / np.mean(value1_lst)))) * \\\n                           len(np.unique(np.floor(value2_lst[included_items] / np.mean(value2_lst))))\n\n        # Determine number of bits to flip based on cluster diversity\n        num_flips = max(1, int(3 * (1 - min(1, cluster_diversity / (len(included_items) + 1e-6)))))\n\n        for _ in range(num_flips):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.960380061248387,
            -18.694170138243813
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution with high potential for improvement in both objectives by combining probabilistic item selection with objective-aware swaps and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic objective-aware selection\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate combined objective scores\n        combined_scores = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(combined_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Objective-specific fine-tuning\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Select items based on objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        else:\n            # Focus on value1 improvement\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] * ratio + value2_lst[included_items] * (1 - ratio)) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.125194556064613,
            -18.64008991764989
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for multi-objective improvement, then applies a hybrid local search strategy that combines probabilistic item prioritization, objective-aware replacement, and adaptive neighborhood diversification to generate a high-quality neighbor solution while ensuring feasibility, using a novel approach that balances exploration of the objective space with exploitation of high-potential regions.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item prioritization (select items based on objective-specific priorities)\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific priorities for included items\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        priority_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Calculate prioritization scores for excluded items\n        priority_scores = (value1_lst[excluded_items] * priority_ratio + value2_lst[excluded_items] * (1 - priority_ratio)) / weight_lst[excluded_items]\n\n        # Select top k items to consider for prioritization\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(priority_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            prioritize_idx = np.random.choice(top_indices)\n\n            # Find the worst item to replace based on current objective priorities\n            worst_scores = (value1_lst[included_items] * priority_ratio + value2_lst[included_items] * (1 - priority_ratio)) / weight_lst[included_items]\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform prioritization if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[prioritize_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[prioritize_idx] = 1\n\n    # Step 2: Objective-aware replacement (replace items based on their potential to improve both objectives)\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate potential improvement scores for excluded items\n        improvement_scores = (value1_lst[excluded_items] * value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Select top k items to consider for improvement\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(improvement_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            improve_idx = np.random.choice(top_indices)\n\n            # Find the least valuable item to replace based on combined objective values\n            least_val_idx = np.argmin((value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items])\n            least_val_idx = included_items[least_val_idx]\n\n            # Perform improvement if feasible\n            if current_weight - weight_lst[least_val_idx] + weight_lst[improve_idx] <= capacity:\n                new_solution[least_val_idx] = 0\n                new_solution[improve_idx] = 1\n\n    # Step 3: Adaptive neighborhood diversification (flip bits based on solution diversity)\n    if len(included_items) > 0:\n        # Calculate solution diversity as the ratio of unique objective contributions\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine number of bits to flip based on diversity (less diverse solutions get more changes)\n        num_flips = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(num_flips):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.193564737015997,
            -18.5791289379654
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive, applies a hybrid local search that combines probabilistic item swapping based on marginal contribution, value-driven insertion with an adaptive crowding-aware bit flip strategy that prioritizes items with high marginal contribution in both objectives, while dynamically adjusting the exploration-exploitation balance based on the archive's diversity.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Dynamic probabilistic item swapping (swap items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate marginal contribution for each item\n        marginal_value1 = value1_lst[included_items] / weight_lst[included_items]\n        marginal_value2 = value2_lst[included_items] / weight_lst[included_items]\n        marginal_contribution = marginal_value1 + marginal_value2\n\n        # Swap items with low marginal contribution with higher probability\n        swap_probs = 1 / (1 + marginal_contribution)\n        swap_probs = swap_probs / np.sum(swap_probs)\n\n        swap_idx = np.random.choice(included_items, p=swap_probs)\n        new_solution[swap_idx] = 0\n\n        # Select an excluded item to swap with based on normalized value-to-weight ratio\n        value_ratio = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n        norm_value_ratio = value_ratio / np.sum(value_ratio)\n        insert_idx = np.random.choice(excluded_items, p=norm_value_ratio)\n\n        if current_weight - weight_lst[swap_idx] + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight = current_weight - weight_lst[swap_idx] + weight_lst[insert_idx]\n\n    # Step 2: Adaptive value-driven insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate normalized value-to-weight ratio\n        value_ratio = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n        norm_value_ratio = value_ratio / np.sum(value_ratio)\n\n        # Adjust insertion probability based on archive diversity\n        diversity_factor = 1.0 - (len(archive) / (len(weight_lst) * 2))\n        insertion_probs = norm_value_ratio * diversity_factor\n\n        if np.sum(insertion_probs) > 0:\n            insertion_probs = insertion_probs / np.sum(insertion_probs)\n            insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n\n            if current_weight + weight_lst[insert_idx] <= capacity:\n                new_solution[insert_idx] = 1\n                current_weight += weight_lst[insert_idx]\n\n    # Step 3: Crowding-aware bit flip with dynamic exploration\n    if len(archive) > 1:\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            # Calculate crowding distances for each objective\n            val1_values = np.array([obj[0] for _, obj in archive])\n            val2_values = np.array([obj[1] for _, obj in archive])\n\n            crowding_dist1 = np.sort(val1_values)[-1] - np.sort(val1_values)[-2] if len(val1_values) > 1 else 0\n            crowding_dist2 = np.sort(val2_values)[-1] - np.sort(val2_values)[-2] if len(val2_values) > 1 else 0\n\n            # Flip bits based on crowding distances and marginal contribution\n            marginal_value = (value1_lst + value2_lst) / weight_lst\n            flip_probs = marginal_value * (crowding_dist1 + crowding_dist2)\n\n            if np.sum(flip_probs) > 0:\n                flip_probs = flip_probs / np.sum(flip_probs)\n                flip_idx = np.random.choice(len(new_solution), p=flip_probs)\n\n                if new_solution[flip_idx] == 1:\n                    if current_weight - weight_lst[flip_idx] <= capacity:\n                        new_solution[flip_idx] = 0\n                else:\n                    if current_weight + weight_lst[flip_idx] <= capacity:\n                        new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.81821790627548,
            -18.73388005295616
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for both objectives, then applies a novel hybrid local search strategy that combines probabilistic objective-weighted item selection, adaptive value-weighted swapping, and diversity-aware bit flipping to generate a high-quality neighbor solution while ensuring feasibility through a multi-phase approach that balances exploration and exploitation.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic objective-weighted item selection\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective weights based on current solution's balance\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        obj_weight1 = current_val1 / (current_val1 + current_val2 + 1e-6)\n        obj_weight2 = current_val2 / (current_val1 + current_val2 + 1e-6)\n\n        # Calculate selection probabilities for excluded items\n        selection_probs = (obj_weight1 * value1_lst[excluded_items] + obj_weight2 * value2_lst[excluded_items]) / weight_lst[excluded_items]\n        selection_probs = selection_probs / np.sum(selection_probs)\n\n        # Select an item to add\n        add_idx = np.random.choice(excluded_items, p=selection_probs)\n\n        # Select an item to remove based on its contribution to both objectives\n        removal_scores = (obj_weight1 * value1_lst[included_items] + obj_weight2 * value2_lst[included_items]) / weight_lst[included_items]\n        remove_idx = included_items[np.argmin(removal_scores)]\n\n        # Perform swap if feasible\n        if current_weight - weight_lst[remove_idx] + weight_lst[add_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            new_solution[add_idx] = 1\n            current_weight = current_weight - weight_lst[remove_idx] + weight_lst[add_idx]\n\n    # Step 2: Adaptive value-weighted swapping\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate value-weighted probabilities for included items\n        swap_probs = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n        swap_probs = swap_probs / np.sum(swap_probs)\n\n        # Select an item to potentially swap\n        swap_idx = np.random.choice(included_items, p=swap_probs)\n\n        # Find a suitable item to swap with from excluded items\n        potential_swaps = excluded_items[weight_lst[excluded_items] <= weight_lst[swap_idx]]\n        if len(potential_swaps) > 0:\n            # Select the best swap candidate based on combined value\n            swap_candidate = potential_swaps[np.argmax(value1_lst[potential_swaps] + value2_lst[potential_swaps])]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[swap_idx] + weight_lst[swap_candidate] <= capacity:\n                new_solution[swap_idx] = 0\n                new_solution[swap_candidate] = 1\n\n    # Step 3: Diversity-aware bit flipping\n    if len(included_items) > 0:\n        # Calculate solution diversity as the ratio of unique objective contributions\n        unique_val1 = len(np.unique(value1_lst[included_items]))\n        unique_val2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_val1, unique_val2) / max(unique_val1, unique_val2) if max(unique_val1, unique_val2) > 0 else 0.5\n\n        # Determine number of bits to flip based on diversity (less diverse solutions get more changes)\n        num_flips = max(1, int(2 * (1 - diversity)))\n\n        for _ in range(num_flips):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.937480718347008,
            -18.696077869537106
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective prioritization and diversity-aware perturbation with weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Novel objective-aware prioritization with weighted scoring\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with different weights\n        weighted_scores = (value1_lst * 0.4 + value2_lst * 0.6) / (weight_lst * 0.7 + 1e-6)\n\n        # Select top items to consider\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * 0.3 + value2_lst[included_items] * 0.7) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(3 * (1 - diversity) * random.uniform(0.8, 1.2)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with different weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with novel weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.6 + current_val2 * 0.4 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with novel scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.6 + 1e-6)\n        else:\n            # Focus on value1 improvement with novel scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.4 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with novel scoring\n            worst_scores = (value1_lst[included_items] * 0.4 + value2_lst[included_items] * 0.6) / (weight_lst[included_items] * 0.5 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.10582703107761,
            -19.389330320689613
        ]
    }
]