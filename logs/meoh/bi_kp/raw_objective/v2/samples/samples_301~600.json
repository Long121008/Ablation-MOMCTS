[
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have one algorithm with its code as follows. Algorithm description:\n{This algorithm employs a novel hybrid of adaptive objective prioritization and diversity-aware perturbation with weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}\nCode:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement using novel selection criteria\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 1: Novel objective-aware prioritization with adaptive weights\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        weight_factor = 0.5 + 0.5 * (current_val1 / (current_val1 + current_val2 + 1e-6))\n\n        weighted_scores = (value1_lst * weight_factor + value2_lst * (1 - weight_factor)) / (weight_lst * 0.9 + 1e-6)\n\n        # Select top items to consider\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * (1 - weight_factor) + value2_lst[included_items] * weight_factor) / (weight_lst[included_items] * 0.8 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(5 * (1 - diversity) * random.uniform(0.6, 1.4)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with adaptive weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.8 + current_val2 * 0.2 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with adaptive scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.8 + 1e-6)\n        else:\n            # Focus on value1 improvement with adaptive scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.6 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with adaptive scoring\n            worst_scores = (value1_lst[included_items] * 0.6 + value2_lst[included_items] * 0.4) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n\nPlease identify the main algorithm parameters and assist me in creating a new algorithm that has a different parameter settings of the score function provided.\n1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nDo not give additional explanations.",
        "sample_order": 301,
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective weighting, diversity-aware exploration, and weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation while maintaining feasibility, using different parameter settings for the score function.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        weight_factor = 0.6 + 0.4 * (current_val1 / (current_val1 + current_val2 + 1e-6))\n\n        weighted_scores = (value1_lst * weight_factor + value2_lst * (1 - weight_factor)) / (weight_lst * 0.7 + 1e-6)\n\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n            worst_scores = (value1_lst[included_items] * (1 - weight_factor) + value2_lst[included_items] * weight_factor) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    if len(included_items) > 0:\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.6\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.6\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        exploration_intensity = max(1, int(3 * (1 - diversity) * random.uniform(0.7, 1.3)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.7 + current_val2 * 0.3 + 1e-6)\n\n        if ratio > 0.4:\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.7 + 1e-6)\n        else:\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            worst_scores = (value1_lst[included_items] * 0.5 + value2_lst[included_items] * 0.5) / (weight_lst[included_items] * 0.8 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.429360927582913,
            -19.090919246604173
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        weight_factor = 0.6 + 0.4 * (current_val1 / (current_val1 + current_val2 + 1e-6))\n\n        weighted_scores = (value1_lst * weight_factor + value2_lst * (1 - weight_factor)) / (weight_lst * 0.7 + 1e-6)\n\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n            worst_scores = (value1_lst[included_items] * (1 - weight_factor) + value2_lst[included_items] * weight_factor) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    if len(included_items) > 0:\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.6\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.6\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        exploration_intensity = max(1, int(3 * (1 - diversity) * random.uniform(0.7, 1.3)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.7 + current_val2 * 0.3 + 1e-6)\n\n        if ratio > 0.4:\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.7 + 1e-6)\n        else:\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            worst_scores = (value1_lst[included_items] * 0.5 + value2_lst[included_items] * 0.5) / (weight_lst[included_items] * 0.8 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{This algorithm selects a solution with high potential for improvement by combining probabilistic item selection with objective-aware swaps, adaptive neighborhood exploration, and a novel score function that balances both objectives using a weighted sum approach to generate high-quality neighbor solutions while ensuring feasibility.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic objective-aware selection with weighted score function\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate weighted combined objective scores\n        alpha = 0.7  # Weight for value1\n        beta = 0.3   # Weight for value2\n        combined_scores = (alpha * value1_lst + beta * value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(combined_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace based on weighted score\n            worst_scores = (alpha * value1_lst[included_items] + beta * value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with dynamic intensity\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(4 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Objective-specific fine-tuning with weighted replacement\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Adjust weights based on current balance\n        alpha = 0.6 if ratio > 0.5 else 0.4\n        beta = 1 - alpha\n\n        # Select items based on weighted improvement potential\n        improvement_scores = (alpha * value1_lst[excluded_items] + beta * value2_lst[excluded_items]) / (weight_lst[excluded_items] + 1e-6)\n\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace based on weighted score\n            worst_scores = (alpha * value1_lst[included_items] + beta * value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{This algorithm selects a solution with high potential for improvement in both objectives by combining probabilistic item selection with objective-aware swaps and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic objective-aware selection\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate combined objective scores\n        combined_scores = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(combined_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Objective-specific fine-tuning\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Select items based on objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        else:\n            # Focus on value1 improvement\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] * ratio + value2_lst[included_items] * (1 - ratio)) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n\nPlease help me create a new algorithm that has a totally different form from the given ones. \n1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nDo not give additional explanations.",
        "sample_order": 302,
        "algorithm": "{This algorithm combines a novel objective-aware clustering approach with a hybrid local search operator that alternates between item-level perturbations and cluster-based swaps, using dynamic weight adaptation to balance both objectives and ensuring feasibility through constrained neighborhood exploration.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select solution with highest combined objective score\n    combined_scores = [obj[0] + obj[1] for _, obj in archive]\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 2: Cluster items based on objective correlation\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0:\n        # Calculate objective correlation\n        obj1_mean = np.mean(value1_lst[included_items])\n        obj2_mean = np.mean(value2_lst[included_items])\n        correlation = np.mean((value1_lst[included_items] - obj1_mean) * (value2_lst[included_items] - obj2_mean)) / \\\n                     (np.std(value1_lst[included_items]) * np.std(value2_lst[included_items]) + 1e-6)\n\n        # Step 3: Hybrid local search with dynamic weight adaptation\n        alpha = 0.5 + 0.5 * correlation  # Higher weight for value1 if objectives are correlated\n        beta = 1 - alpha\n\n        # Cluster-based swap\n        if len(excluded_items) > 0 and len(included_items) > 1:\n            # Find cluster with worst combined score\n            cluster_scores = (alpha * value1_lst[included_items] + beta * value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_cluster_idx = np.argmin(cluster_scores)\n            worst_cluster_item = included_items[worst_cluster_idx]\n\n            # Find best item to add from cluster\n            cluster_scores = (alpha * value1_lst[excluded_items] + beta * value2_lst[excluded_items]) / (weight_lst[excluded_items] + 1e-6)\n            best_cluster_idx = np.argmax(cluster_scores)\n            best_cluster_item = excluded_items[best_cluster_idx]\n\n            if current_weight - weight_lst[worst_cluster_item] + weight_lst[best_cluster_item] <= capacity:\n                new_solution[worst_cluster_item] = 0\n                new_solution[best_cluster_item] = 1\n                current_weight = current_weight - weight_lst[worst_cluster_item] + weight_lst[best_cluster_item]\n\n        # Step 4: Item-level perturbations with adaptive intensity\n        perturbation_intensity = max(1, int(3 * (1 - abs(correlation))))\n        for _ in range(perturbation_intensity):\n            if random.random() < 0.7:  # Higher chance for removal\n                if len(included_items) > 0:\n                    remove_idx = random.choice(included_items)\n                    if current_weight - weight_lst[remove_idx] <= capacity:\n                        new_solution[remove_idx] = 0\n                        current_weight -= weight_lst[remove_idx]\n            else:\n                if len(excluded_items) > 0:\n                    add_idx = random.choice(excluded_items)\n                    if current_weight + weight_lst[add_idx] <= capacity:\n                        new_solution[add_idx] = 1\n                        current_weight += weight_lst[add_idx]\n\n            included_items = np.where(new_solution == 1)[0]\n            excluded_items = np.where(new_solution == 0)[0]\n\n    return new_solution\n\n",
        "score": [
            -18.803045149172846,
            -18.78059822684344
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select solution with highest combined objective score\n    combined_scores = [obj[0] + obj[1] for _, obj in archive]\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 2: Cluster items based on objective correlation\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0:\n        # Calculate objective correlation\n        obj1_mean = np.mean(value1_lst[included_items])\n        obj2_mean = np.mean(value2_lst[included_items])\n        correlation = np.mean((value1_lst[included_items] - obj1_mean) * (value2_lst[included_items] - obj2_mean)) / \\\n                     (np.std(value1_lst[included_items]) * np.std(value2_lst[included_items]) + 1e-6)\n\n        # Step 3: Hybrid local search with dynamic weight adaptation\n        alpha = 0.5 + 0.5 * correlation  # Higher weight for value1 if objectives are correlated\n        beta = 1 - alpha\n\n        # Cluster-based swap\n        if len(excluded_items) > 0 and len(included_items) > 1:\n            # Find cluster with worst combined score\n            cluster_scores = (alpha * value1_lst[included_items] + beta * value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_cluster_idx = np.argmin(cluster_scores)\n            worst_cluster_item = included_items[worst_cluster_idx]\n\n            # Find best item to add from cluster\n            cluster_scores = (alpha * value1_lst[excluded_items] + beta * value2_lst[excluded_items]) / (weight_lst[excluded_items] + 1e-6)\n            best_cluster_idx = np.argmax(cluster_scores)\n            best_cluster_item = excluded_items[best_cluster_idx]\n\n            if current_weight - weight_lst[worst_cluster_item] + weight_lst[best_cluster_item] <= capacity:\n                new_solution[worst_cluster_item] = 0\n                new_solution[best_cluster_item] = 1\n                current_weight = current_weight - weight_lst[worst_cluster_item] + weight_lst[best_cluster_item]\n\n        # Step 4: Item-level perturbations with adaptive intensity\n        perturbation_intensity = max(1, int(3 * (1 - abs(correlation))))\n        for _ in range(perturbation_intensity):\n            if random.random() < 0.7:  # Higher chance for removal\n                if len(included_items) > 0:\n                    remove_idx = random.choice(included_items)\n                    if current_weight - weight_lst[remove_idx] <= capacity:\n                        new_solution[remove_idx] = 0\n                        current_weight -= weight_lst[remove_idx]\n            else:\n                if len(excluded_items) > 0:\n                    add_idx = random.choice(excluded_items)\n                    if current_weight + weight_lst[add_idx] <= capacity:\n                        new_solution[add_idx] = 1\n                        current_weight += weight_lst[add_idx]\n\n            included_items = np.where(new_solution == 1)[0]\n            excluded_items = np.where(new_solution == 0)[0]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{This algorithm employs a novel hybrid of adaptive objective prioritization and diversity-aware perturbation with weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Novel objective-aware prioritization with weighted scoring\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with different weights\n        weighted_scores = (value1_lst * 0.4 + value2_lst * 0.6) / (weight_lst * 0.7 + 1e-6)\n\n        # Select top items to consider\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * 0.3 + value2_lst[included_items] * 0.7) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(3 * (1 - diversity) * random.uniform(0.8, 1.2)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with different weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with novel weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.6 + current_val2 * 0.4 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with novel scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.6 + 1e-6)\n        else:\n            # Focus on value1 improvement with novel scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.4 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with novel scoring\n            worst_scores = (value1_lst[included_items] * 0.4 + value2_lst[included_items] * 0.6) / (weight_lst[included_items] * 0.5 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{This algorithm employs a novel hybrid of adaptive objective prioritization and diversity-aware perturbation with weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Novel objective-aware prioritization with weighted scoring\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with different weights\n        weighted_scores = (value1_lst * 0.4 + value2_lst * 0.6) / (weight_lst * 0.7 + 1e-6)\n\n        # Select top items to consider\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * 0.3 + value2_lst[included_items] * 0.7) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(3 * (1 - diversity) * random.uniform(0.8, 1.2)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with different weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with novel weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.6 + current_val2 * 0.4 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with novel scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.6 + 1e-6)\n        else:\n            # Focus on value1 improvement with novel scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.4 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with novel scoring\n            worst_scores = (value1_lst[included_items] * 0.4 + value2_lst[included_items] * 0.6) / (weight_lst[included_items] * 0.5 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n\nPlease help me create a new algorithm that has a totally different form from the given ones. \n1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nDo not give additional explanations.",
        "sample_order": 303,
        "algorithm": "{This algorithm employs a novel hybrid of objective-driven clustering and adaptive perturbation with dynamic weight adjustment to generate high-quality neighbors by intelligently combining local search with global exploration while maintaining feasibility through constraint-aware operations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Objective-driven clustering with dynamic weight adjustment\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate dynamic weights based on current solution's objective balance\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        total_val = current_val1 + current_val2\n\n        w1 = current_val1 / (total_val + 1e-6)\n        w2 = current_val2 / (total_val + 1e-6)\n\n        # Cluster items based on their normalized values\n        norm_val1 = value1_lst / (np.max(value1_lst) + 1e-6)\n        norm_val2 = value2_lst / (np.max(value2_lst) + 1e-6)\n        cluster_scores = w1 * norm_val1 + w2 * norm_val2\n\n        # Select top items to consider\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(cluster_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using dynamic scoring\n            worst_scores = (w1 * value1_lst[included_items] + w2 * value2_lst[included_items]) / (weight_lst[included_items] * 0.5 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive perturbation with dynamic intensity\n    if len(included_items) > 0:\n        # Calculate solution quality using novel metric\n        obj1_quality = np.sum(value1_lst[included_items]) / (np.max(value1_lst) * len(included_items) + 1e-6)\n        obj2_quality = np.sum(value2_lst[included_items]) / (np.max(value2_lst) * len(included_items) + 1e-6)\n        quality = (obj1_quality + obj2_quality) / 2\n\n        # Determine perturbation intensity based on quality\n        perturbation_intensity = max(1, int(5 * (1 - quality) * random.uniform(0.7, 1.3)))\n\n        for _ in range(perturbation_intensity):\n            # Select random item to flip\n            flip_idx = random.randint(0, len(new_solution) - 1)\n\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Constraint-aware fine-tuning with dynamic weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate remaining capacity\n        remaining_capacity = capacity - current_weight\n\n        # Select items that fit within remaining capacity\n        feasible_items = excluded_items[weight_lst[excluded_items] <= remaining_capacity]\n\n        if len(feasible_items) > 0:\n            # Calculate dynamic improvement scores\n            improvement_scores = (w1 * value1_lst[feasible_items] + w2 * value2_lst[feasible_items]) / (weight_lst[feasible_items] + 1e-6)\n\n            # Select best item for potential addition\n            best_idx = np.argmax(improvement_scores)\n            best_idx = feasible_items[best_idx]\n\n            # Find worst item to replace with dynamic scoring\n            worst_scores = (w1 * value1_lst[included_items] + w2 * value2_lst[included_items]) / (weight_lst[included_items] * 0.4 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.058268324266855,
            -18.59004241048232
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Objective-driven clustering with dynamic weight adjustment\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate dynamic weights based on current solution's objective balance\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        total_val = current_val1 + current_val2\n\n        w1 = current_val1 / (total_val + 1e-6)\n        w2 = current_val2 / (total_val + 1e-6)\n\n        # Cluster items based on their normalized values\n        norm_val1 = value1_lst / (np.max(value1_lst) + 1e-6)\n        norm_val2 = value2_lst / (np.max(value2_lst) + 1e-6)\n        cluster_scores = w1 * norm_val1 + w2 * norm_val2\n\n        # Select top items to consider\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(cluster_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using dynamic scoring\n            worst_scores = (w1 * value1_lst[included_items] + w2 * value2_lst[included_items]) / (weight_lst[included_items] * 0.5 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive perturbation with dynamic intensity\n    if len(included_items) > 0:\n        # Calculate solution quality using novel metric\n        obj1_quality = np.sum(value1_lst[included_items]) / (np.max(value1_lst) * len(included_items) + 1e-6)\n        obj2_quality = np.sum(value2_lst[included_items]) / (np.max(value2_lst) * len(included_items) + 1e-6)\n        quality = (obj1_quality + obj2_quality) / 2\n\n        # Determine perturbation intensity based on quality\n        perturbation_intensity = max(1, int(5 * (1 - quality) * random.uniform(0.7, 1.3)))\n\n        for _ in range(perturbation_intensity):\n            # Select random item to flip\n            flip_idx = random.randint(0, len(new_solution) - 1)\n\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Constraint-aware fine-tuning with dynamic weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate remaining capacity\n        remaining_capacity = capacity - current_weight\n\n        # Select items that fit within remaining capacity\n        feasible_items = excluded_items[weight_lst[excluded_items] <= remaining_capacity]\n\n        if len(feasible_items) > 0:\n            # Calculate dynamic improvement scores\n            improvement_scores = (w1 * value1_lst[feasible_items] + w2 * value2_lst[feasible_items]) / (weight_lst[feasible_items] + 1e-6)\n\n            # Select best item for potential addition\n            best_idx = np.argmax(improvement_scores)\n            best_idx = feasible_items[best_idx]\n\n            # Find worst item to replace with dynamic scoring\n            worst_scores = (w1 * value1_lst[included_items] + w2 * value2_lst[included_items]) / (weight_lst[included_items] * 0.4 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{This algorithm selects a solution with high potential for improvement by combining probabilistic item selection with objective-aware swaps, adaptive neighborhood exploration, and a novel score function that balances both objectives using a weighted sum approach to generate high-quality neighbor solutions while ensuring feasibility.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic objective-aware selection with weighted score function\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate weighted combined objective scores\n        alpha = 0.7  # Weight for value1\n        beta = 0.3   # Weight for value2\n        combined_scores = (alpha * value1_lst + beta * value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(combined_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace based on weighted score\n            worst_scores = (alpha * value1_lst[included_items] + beta * value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with dynamic intensity\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(4 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Objective-specific fine-tuning with weighted replacement\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Adjust weights based on current balance\n        alpha = 0.6 if ratio > 0.5 else 0.4\n        beta = 1 - alpha\n\n        # Select items based on weighted improvement potential\n        improvement_scores = (alpha * value1_lst[excluded_items] + beta * value2_lst[excluded_items]) / (weight_lst[excluded_items] + 1e-6)\n\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace based on weighted score\n            worst_scores = (alpha * value1_lst[included_items] + beta * value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{This algorithm selects a solution from the archive based on its potential for balanced objective improvement, then applies a hybrid local search strategy that combines probabilistic item prioritization, objective-aware replacement, and adaptive neighborhood diversification, while incorporating a novel item clustering technique to identify and exploit groups of items that contribute synergistically to both objectives.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for balanced improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Item clustering and prioritization\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate clustering scores for items (combining value and weight)\n        cluster_scores = (value1_lst * value2_lst) / (weight_lst + 1e-6)\n\n        # Find the most promising cluster to prioritize\n        cluster_indices = np.argsort(-cluster_scores[excluded_items])\n        cluster_size = min(5, len(cluster_indices))\n        cluster_indices = excluded_items[cluster_indices[:cluster_size]]\n\n        if len(cluster_indices) > 0:\n            prioritize_idx = np.random.choice(cluster_indices)\n\n            # Find the worst item in the current solution\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = included_items[np.argmin(worst_scores)]\n\n            # Perform prioritization if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[prioritize_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[prioritize_idx] = 1\n\n    # Step 2: Balanced objective replacement\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate replacement potential considering both objectives\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        balance_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        replacement_scores = (value1_lst[excluded_items] * (1 - balance_ratio) + value2_lst[excluded_items] * balance_ratio) / weight_lst[excluded_items]\n        replace_idx = np.random.choice(excluded_items, p=replacement_scores / np.sum(replacement_scores))\n\n        # Find the least balanced item to replace\n        balance_scores = (value1_lst[included_items] * (1 - balance_ratio) + value2_lst[included_items] * balance_ratio) / weight_lst[included_items]\n        least_balanced_idx = included_items[np.argmin(balance_scores)]\n\n        # Perform replacement if feasible\n        if current_weight - weight_lst[least_balanced_idx] + weight_lst[replace_idx] <= capacity:\n            new_solution[least_balanced_idx] = 0\n            new_solution[replace_idx] = 1\n\n    # Step 3: Adaptive neighborhood diversification with clustering awareness\n    if len(included_items) > 0:\n        # Calculate solution diversity using clustering information\n        cluster_diversity = len(np.unique(np.floor(value1_lst[included_items] / np.mean(value1_lst)))) * \\\n                           len(np.unique(np.floor(value2_lst[included_items] / np.mean(value2_lst))))\n\n        # Determine number of bits to flip based on cluster diversity\n        num_flips = max(1, int(3 * (1 - min(1, cluster_diversity / (len(included_items) + 1e-6)))))\n\n        for _ in range(num_flips):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n\nPlease help me create a new algorithm that has a totally different form from the given ones but can be motivated from them.\n1. Firstly, identify the common backbone idea in the provided algorithms. \n2. Secondly, based on the backbone idea describe your new algorithm in one sentence. The description must be inside within boxed {}.\n3. Thirdly, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nDo not give additional explanations.",
        "sample_order": 304,
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for multi-objective improvement, then applies a hybrid local search strategy that combines probabilistic item prioritization with a novel objective-aware clustering technique, adaptive neighborhood diversification using value-weight ratios, and a dynamic balance adjustment mechanism to generate high-quality neighbor solutions while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-aware clustering scores\n        obj_ratio = np.sum(value1_lst) / (np.sum(value2_lst) + 1e-6)\n        cluster_scores = (value1_lst * obj_ratio + value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(cluster_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace based on value-weight ratio\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = included_items[np.argmin(worst_scores)]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n\n    # Adaptive neighborhood diversification with dynamic flips\n    if len(included_items) > 0:\n        # Calculate solution balance\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        balance = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Determine number of flips based on balance\n        num_flips = max(1, int(3 * (1 - 2 * abs(balance - 0.5))))\n\n        for _ in range(num_flips):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    # Final objective-aware fine-tuning\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate improvement potential\n        improvement_scores = (value1_lst[excluded_items] + value2_lst[excluded_items]) / (weight_lst[excluded_items] + 1e-6)\n\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = included_items[np.argmin(worst_scores)]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.15692776529624,
            -18.613590795721056
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-aware clustering scores\n        obj_ratio = np.sum(value1_lst) / (np.sum(value2_lst) + 1e-6)\n        cluster_scores = (value1_lst * obj_ratio + value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(cluster_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace based on value-weight ratio\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = included_items[np.argmin(worst_scores)]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n\n    # Adaptive neighborhood diversification with dynamic flips\n    if len(included_items) > 0:\n        # Calculate solution balance\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        balance = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Determine number of flips based on balance\n        num_flips = max(1, int(3 * (1 - 2 * abs(balance - 0.5))))\n\n        for _ in range(num_flips):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    # Final objective-aware fine-tuning\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate improvement potential\n        improvement_scores = (value1_lst[excluded_items] + value2_lst[excluded_items]) / (weight_lst[excluded_items] + 1e-6)\n\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = included_items[np.argmin(worst_scores)]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have one algorithm with its code as follows. Algorithm description:\n{This algorithm employs a novel hybrid of adaptive objective prioritization and diversity-aware perturbation with weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}\nCode:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Novel objective-aware prioritization with weighted scoring\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with different weights\n        weighted_scores = (value1_lst * 0.5 + value2_lst * 0.5) / (weight_lst * 0.8 + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * 0.4 + value2_lst[included_items] * 0.6) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(4 * (1 - diversity) * random.uniform(0.7, 1.3)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with different weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with novel weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.5 + current_val2 * 0.5 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with novel scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.7 + 1e-6)\n        else:\n            # Focus on value1 improvement with novel scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.3 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with novel scoring\n            worst_scores = (value1_lst[included_items] * 0.5 + value2_lst[included_items] * 0.5) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n\nPlease assist me in creating a new algorithm that has a different form but can be a modified version of the algorithm provided.\n1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nDo not give additional explanations.",
        "sample_order": 305,
        "algorithm": "{This algorithm innovatively combines objective-driven item prioritization with adaptive neighborhood exploration, using novel scoring metrics to balance multi-objective trade-offs while ensuring feasibility through constrained item swaps and random perturbations.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 2: Novel objective-aware prioritization with adaptive weights\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        balance = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Dynamic weight adjustment based on current balance\n        w1 = 0.6 if balance < 0.4 else 0.4\n        w2 = 1 - w1\n\n        weighted_scores = (value1_lst * w1 + value2_lst * w2) / (weight_lst * 0.9 + 1e-6)\n\n        # Select top items to consider\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * w1 + value2_lst[included_items] * w2) / (weight_lst[included_items] * 0.8 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 3: Adaptive neighborhood exploration with novel intensity\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(5 * (1 - diversity) * random.uniform(0.6, 1.4)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 4: Novel objective-specific fine-tuning with dynamic weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with dynamic weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.6:\n            # Focus on value2 improvement with dynamic scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.8 + 1e-6)\n        else:\n            # Focus on value1 improvement with dynamic scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.4 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with dynamic scoring\n            worst_scores = (value1_lst[included_items] * 0.5 + value2_lst[included_items] * 0.5) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.919791532153276,
            -18.75647618754235
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 2: Novel objective-aware prioritization with adaptive weights\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        balance = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Dynamic weight adjustment based on current balance\n        w1 = 0.6 if balance < 0.4 else 0.4\n        w2 = 1 - w1\n\n        weighted_scores = (value1_lst * w1 + value2_lst * w2) / (weight_lst * 0.9 + 1e-6)\n\n        # Select top items to consider\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * w1 + value2_lst[included_items] * w2) / (weight_lst[included_items] * 0.8 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 3: Adaptive neighborhood exploration with novel intensity\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(5 * (1 - diversity) * random.uniform(0.6, 1.4)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 4: Novel objective-specific fine-tuning with dynamic weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with dynamic weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.6:\n            # Focus on value2 improvement with dynamic scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.8 + 1e-6)\n        else:\n            # Focus on value1 improvement with dynamic scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.4 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with dynamic scoring\n            worst_scores = (value1_lst[included_items] * 0.5 + value2_lst[included_items] * 0.5) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{This algorithm employs a novel hybrid of adaptive objective prioritization and diversity-aware perturbation with weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement using novel selection criteria\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 1: Novel objective-aware prioritization with adaptive weights\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        weight_factor = 0.5 + 0.5 * (current_val1 / (current_val1 + current_val2 + 1e-6))\n\n        weighted_scores = (value1_lst * weight_factor + value2_lst * (1 - weight_factor)) / (weight_lst * 0.8 + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * (1 - weight_factor) + value2_lst[included_items] * weight_factor) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(4 * (1 - diversity) * random.uniform(0.7, 1.3)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with adaptive weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.7 + current_val2 * 0.3 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with adaptive scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.7 + 1e-6)\n        else:\n            # Focus on value1 improvement with adaptive scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with adaptive scoring\n            worst_scores = (value1_lst[included_items] * 0.5 + value2_lst[included_items] * 0.5) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{This algorithm employs a novel hybrid of adaptive objective weighting and dynamic neighborhood exploration with item prioritization, using a combination of objective-aware scoring and diversity-sensitive perturbations to generate high-quality neighbors while maintaining feasibility.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Adaptive objective weighting with novel scoring\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate dynamic weights based on current solution balance\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        obj1_weight = 0.5 + 0.3 * (current_val2 / (current_val1 + 1e-6))\n        obj2_weight = 0.5 + 0.3 * (current_val1 / (current_val2 + 1e-6))\n\n        # Novel scoring with dynamic weights\n        weighted_scores = (value1_lst * obj1_weight + value2_lst * obj2_weight) / (weight_lst * 0.6 + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * (1 - obj1_weight) + value2_lst[included_items] * (1 - obj2_weight)) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Dynamic neighborhood exploration with novel intensity\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(4 * (1 - diversity) * random.uniform(0.7, 1.3)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with dynamic weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with dynamic weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * obj1_weight + current_val2 * obj2_weight + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with novel scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n        else:\n            # Focus on value1 improvement with novel scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with novel scoring\n            worst_scores = (value1_lst[included_items] * obj1_weight + value2_lst[included_items] * obj2_weight) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n\nPlease help me create a new algorithm that has a totally different form from the given ones but can be motivated from them.\n1. Firstly, identify the common backbone idea in the provided algorithms. \n2. Secondly, based on the backbone idea describe your new algorithm in one sentence. The description must be inside within boxed {}.\n3. Thirdly, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nDo not give additional explanations.",
        "sample_order": 306,
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective prioritization and diversity-aware perturbation with weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement using novel selection criteria\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 1: Novel objective-aware prioritization with adaptive weights\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        weight_factor = 0.5 + 0.5 * (current_val1 / (current_val1 + current_val2 + 1e-6))\n\n        weighted_scores = (value1_lst * weight_factor + value2_lst * (1 - weight_factor)) / (weight_lst * 0.8 + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * (1 - weight_factor) + value2_lst[included_items] * weight_factor) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(4 * (1 - diversity) * random.uniform(0.7, 1.3)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with adaptive weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.7 + current_val2 * 0.3 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with adaptive scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.7 + 1e-6)\n        else:\n            # Focus on value1 improvement with adaptive scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with adaptive scoring\n            worst_scores = (value1_lst[included_items] * 0.5 + value2_lst[included_items] * 0.5) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.362368238121043,
            -19.20145244701911
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement using novel selection criteria\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 1: Novel objective-aware prioritization with adaptive weights\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        weight_factor = 0.5 + 0.5 * (current_val1 / (current_val1 + current_val2 + 1e-6))\n\n        weighted_scores = (value1_lst * weight_factor + value2_lst * (1 - weight_factor)) / (weight_lst * 0.8 + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * (1 - weight_factor) + value2_lst[included_items] * weight_factor) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(4 * (1 - diversity) * random.uniform(0.7, 1.3)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with adaptive weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.7 + current_val2 * 0.3 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with adaptive scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.7 + 1e-6)\n        else:\n            # Focus on value1 improvement with adaptive scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with adaptive scoring\n            worst_scores = (value1_lst[included_items] * 0.5 + value2_lst[included_items] * 0.5) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{This algorithm selects a solution with high potential for improvement in both objectives by combining probabilistic item selection with objective-aware swaps and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic objective-aware selection\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate combined objective scores\n        combined_scores = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(combined_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Objective-specific fine-tuning\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Select items based on objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        else:\n            # Focus on value1 improvement\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] * ratio + value2_lst[included_items] * (1 - ratio)) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{This algorithm selects a solution with high potential for improvement by combining probabilistic item selection with objective-aware swaps, adaptive neighborhood exploration, and a novel score function that balances both objectives using a weighted sum approach to generate high-quality neighbor solutions while ensuring feasibility.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic objective-aware selection with weighted score function\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate weighted combined objective scores\n        alpha = 0.7  # Weight for value1\n        beta = 0.3   # Weight for value2\n        combined_scores = (alpha * value1_lst + beta * value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(combined_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace based on weighted score\n            worst_scores = (alpha * value1_lst[included_items] + beta * value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with dynamic intensity\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(4 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Objective-specific fine-tuning with weighted replacement\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Adjust weights based on current balance\n        alpha = 0.6 if ratio > 0.5 else 0.4\n        beta = 1 - alpha\n\n        # Select items based on weighted improvement potential\n        improvement_scores = (alpha * value1_lst[excluded_items] + beta * value2_lst[excluded_items]) / (weight_lst[excluded_items] + 1e-6)\n\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace based on weighted score\n            worst_scores = (alpha * value1_lst[included_items] + beta * value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n\nPlease help me create a new algorithm that has a totally different form from the given ones but can be motivated from them.\n1. Firstly, identify the common backbone idea in the provided algorithms. \n2. Secondly, based on the backbone idea describe your new algorithm in one sentence. The description must be inside within boxed {}.\n3. Thirdly, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nDo not give additional explanations.",
        "sample_order": 307,
        "algorithm": "{This algorithm selects a solution with high potential for improvement by combining probabilistic item selection with objective-aware swaps, adaptive neighborhood exploration, and a novel score function that balances both objectives using a weighted sum approach, while also incorporating a dynamic item grouping strategy to identify and exploit high-value item clusters for more effective local search.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Dynamic item grouping based on objective balance\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0:\n        # Calculate objective balance\n        current_val1 = np.sum(value1_lst[included_items])\n        current_val2 = np.sum(value2_lst[included_items])\n        balance = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Group items by objective dominance\n        obj1_dominant = (value1_lst > value2_lst)\n        obj2_dominant = (value2_lst > value1_lst)\n        balanced_items = ~(obj1_dominant | obj2_dominant)\n\n        # Adjust weights based on balance\n        alpha = 0.5 if balance > 0.5 else 0.3\n        beta = 1 - alpha\n\n        # Calculate weighted scores for all items\n        weighted_scores = (alpha * value1_lst + beta * value2_lst) / (weight_lst + 1e-6)\n\n        # Identify high-value clusters\n        if len(excluded_items) > 0:\n            # Find top items to consider\n            k = min(5, len(excluded_items))\n            top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n            top_indices = excluded_items[top_indices]\n\n            # Find worst items to replace\n            worst_scores = weighted_scores[included_items]\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform cluster-based swap\n            for candidate_idx in top_indices:\n                if current_weight - weight_lst[worst_idx] + weight_lst[candidate_idx] <= capacity:\n                    new_solution[worst_idx] = 0\n                    new_solution[candidate_idx] = 1\n                    current_weight = current_weight - weight_lst[worst_idx] + weight_lst[candidate_idx]\n                    break\n\n    # Step 2: Adaptive cluster-based exploration\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            # Select a random item from a high-value cluster\n            if len(excluded_items) > 0:\n                cluster_scores = weighted_scores[excluded_items]\n                cluster_idx = np.argmax(cluster_scores)\n                cluster_idx = excluded_items[cluster_idx]\n\n                if current_weight + weight_lst[cluster_idx] <= capacity:\n                    new_solution[cluster_idx] = 1\n                    current_weight += weight_lst[cluster_idx]\n                    included_items = np.where(new_solution == 1)[0]\n                    excluded_items = np.where(new_solution == 0)[0]\n\n    # Step 3: Objective-specific fine-tuning with cluster-based replacement\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Adjust weights based on current balance\n        alpha = 0.6 if ratio > 0.5 else 0.4\n        beta = 1 - alpha\n\n        # Select items from high-value clusters\n        cluster_scores = (alpha * value1_lst[excluded_items] + beta * value2_lst[excluded_items]) / (weight_lst[excluded_items] + 1e-6)\n        best_idx = np.argmax(cluster_scores)\n        best_idx = excluded_items[best_idx]\n\n        # Find worst item in the solution\n        worst_scores = (alpha * value1_lst[included_items] + beta * value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n        worst_idx = np.argmin(worst_scores)\n        worst_idx = included_items[worst_idx]\n\n        # Perform swap if feasible\n        if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n            new_solution[worst_idx] = 0\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.322481584617197,
            -17.906595434576467
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Dynamic item grouping based on objective balance\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0:\n        # Calculate objective balance\n        current_val1 = np.sum(value1_lst[included_items])\n        current_val2 = np.sum(value2_lst[included_items])\n        balance = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Group items by objective dominance\n        obj1_dominant = (value1_lst > value2_lst)\n        obj2_dominant = (value2_lst > value1_lst)\n        balanced_items = ~(obj1_dominant | obj2_dominant)\n\n        # Adjust weights based on balance\n        alpha = 0.5 if balance > 0.5 else 0.3\n        beta = 1 - alpha\n\n        # Calculate weighted scores for all items\n        weighted_scores = (alpha * value1_lst + beta * value2_lst) / (weight_lst + 1e-6)\n\n        # Identify high-value clusters\n        if len(excluded_items) > 0:\n            # Find top items to consider\n            k = min(5, len(excluded_items))\n            top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n            top_indices = excluded_items[top_indices]\n\n            # Find worst items to replace\n            worst_scores = weighted_scores[included_items]\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform cluster-based swap\n            for candidate_idx in top_indices:\n                if current_weight - weight_lst[worst_idx] + weight_lst[candidate_idx] <= capacity:\n                    new_solution[worst_idx] = 0\n                    new_solution[candidate_idx] = 1\n                    current_weight = current_weight - weight_lst[worst_idx] + weight_lst[candidate_idx]\n                    break\n\n    # Step 2: Adaptive cluster-based exploration\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            # Select a random item from a high-value cluster\n            if len(excluded_items) > 0:\n                cluster_scores = weighted_scores[excluded_items]\n                cluster_idx = np.argmax(cluster_scores)\n                cluster_idx = excluded_items[cluster_idx]\n\n                if current_weight + weight_lst[cluster_idx] <= capacity:\n                    new_solution[cluster_idx] = 1\n                    current_weight += weight_lst[cluster_idx]\n                    included_items = np.where(new_solution == 1)[0]\n                    excluded_items = np.where(new_solution == 0)[0]\n\n    # Step 3: Objective-specific fine-tuning with cluster-based replacement\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Adjust weights based on current balance\n        alpha = 0.6 if ratio > 0.5 else 0.4\n        beta = 1 - alpha\n\n        # Select items from high-value clusters\n        cluster_scores = (alpha * value1_lst[excluded_items] + beta * value2_lst[excluded_items]) / (weight_lst[excluded_items] + 1e-6)\n        best_idx = np.argmax(cluster_scores)\n        best_idx = excluded_items[best_idx]\n\n        # Find worst item in the solution\n        worst_scores = (alpha * value1_lst[included_items] + beta * value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n        worst_idx = np.argmin(worst_scores)\n        worst_idx = included_items[worst_idx]\n\n        # Perform swap if feasible\n        if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n            new_solution[worst_idx] = 0\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{This algorithm selects a solution from the archive based on its potential for multi-objective improvement, then applies a novel local search strategy that combines objective-balanced item selection, adaptive objective prioritization, and diversity-aware perturbation to generate a high-quality neighbor solution while ensuring feasibility, using a creative approach that dynamically balances exploitation of high-value items with exploration of underrepresented objective regions.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Objective-balanced item selection (select items based on balanced objective contributions)\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective balance scores for excluded items\n        balance_scores = (value1_lst[excluded_items] / (np.sum(value1_lst[included_items]) + 1e-6) +\n                         value2_lst[excluded_items] / (np.sum(value2_lst[included_items]) + 1e-6)) / weight_lst[excluded_items]\n\n        # Select top k items to consider for selection\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(balance_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            select_idx = np.random.choice(top_indices)\n\n            # Find the least balanced item to replace based on current objective ratios\n            current_val1 = np.sum(value1_lst[included_items])\n            current_val2 = np.sum(value2_lst[included_items])\n            balance_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n            balance_scores_included = (value1_lst[included_items] * balance_ratio +\n                                      value2_lst[included_items] * (1 - balance_ratio)) / weight_lst[included_items]\n            replace_idx = np.argmin(balance_scores_included)\n            replace_idx = included_items[replace_idx]\n\n            # Perform selection if feasible\n            if current_weight - weight_lst[replace_idx] + weight_lst[select_idx] <= capacity:\n                new_solution[replace_idx] = 0\n                new_solution[select_idx] = 1\n\n    # Step 2: Adaptive objective prioritization (prioritize objectives based on solution state)\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective priorities based on current solution state\n        current_val1 = np.sum(value1_lst[included_items])\n        current_val2 = np.sum(value2_lst[included_items])\n        priority_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Calculate prioritization scores for excluded items\n        priority_scores = (value1_lst[excluded_items] * priority_ratio +\n                          value2_lst[excluded_items] * (1 - priority_ratio)) / weight_lst[excluded_items]\n\n        # Select top k items to consider for prioritization\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(priority_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            prioritize_idx = np.random.choice(top_indices)\n\n            # Find the worst item to replace based on current objective priorities\n            worst_scores = (value1_lst[included_items] * priority_ratio +\n                           value2_lst[included_items] * (1 - priority_ratio)) / weight_lst[included_items]\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform prioritization if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[prioritize_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[prioritize_idx] = 1\n\n    # Step 3: Diversity-aware perturbation (perturb solution based on objective diversity)\n    if len(included_items) > 0:\n        # Calculate objective diversity scores\n        obj1_diversity = len(np.unique(value1_lst[included_items])) / len(value1_lst)\n        obj2_diversity = len(np.unique(value2_lst[included_items])) / len(value2_lst)\n        diversity_score = min(obj1_diversity, obj2_diversity)\n\n        # Determine number of perturbations based on diversity (less diverse solutions get more changes)\n        num_perturb = max(1, int(4 * (1 - diversity_score)))\n\n        for _ in range(num_perturb):\n            # Select a random item to perturb\n            perturb_idx = random.randint(0, len(new_solution) - 1)\n\n            if new_solution[perturb_idx] == 1:\n                # Try to remove item if feasible\n                if current_weight - weight_lst[perturb_idx] <= capacity:\n                    new_solution[perturb_idx] = 0\n            else:\n                # Try to add item if feasible\n                if current_weight + weight_lst[perturb_idx] <= capacity:\n                    new_solution[perturb_idx] = 1\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{This algorithm employs a novel hybrid of adaptive objective prioritization and diversity-aware perturbation with weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement using novel selection criteria\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 1: Novel objective-aware prioritization with adaptive weights\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        weight_factor = 0.5 + 0.5 * (current_val1 / (current_val1 + current_val2 + 1e-6))\n\n        weighted_scores = (value1_lst * weight_factor + value2_lst * (1 - weight_factor)) / (weight_lst * 0.9 + 1e-6)\n\n        # Select top items to consider\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * (1 - weight_factor) + value2_lst[included_items] * weight_factor) / (weight_lst[included_items] * 0.8 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(5 * (1 - diversity) * random.uniform(0.6, 1.4)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with adaptive weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.8 + current_val2 * 0.2 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with adaptive scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.8 + 1e-6)\n        else:\n            # Focus on value1 improvement with adaptive scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.6 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with adaptive scoring\n            worst_scores = (value1_lst[included_items] * 0.6 + value2_lst[included_items] * 0.4) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n\nPlease help me create a new algorithm that has a totally different form from the given ones but can be motivated from them.\n1. Firstly, identify the common backbone idea in the provided algorithms. \n2. Secondly, based on the backbone idea describe your new algorithm in one sentence. The description must be inside within boxed {}.\n3. Thirdly, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nDo not give additional explanations.",
        "sample_order": 308,
        "algorithm": "{This algorithm generates neighbors by combining adaptive objective-driven item swaps with novel diversity-aware perturbation patterns, using weighted objective scores and dynamic neighborhood exploration to balance exploitation of high-value regions with exploration of underrepresented objective dimensions while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        current_val1 = np.sum(value1_lst[included_items])\n        current_val2 = np.sum(value2_lst[included_items])\n        obj_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        combined_scores = (value1_lst[excluded_items] * (1 - obj_ratio) + value2_lst[excluded_items] * obj_ratio) / (weight_lst[excluded_items] * 0.7 + 1e-6)\n\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(combined_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            worst_scores = (value1_lst[included_items] * obj_ratio + value2_lst[included_items] * (1 - obj_ratio)) / (weight_lst[included_items] * 0.8 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    if len(included_items) > 0:\n        obj1_std = np.std(value1_lst[included_items]) if len(included_items) > 1 else 0\n        obj2_std = np.std(value2_lst[included_items]) if len(included_items) > 1 else 0\n        diversity = (obj1_std + obj2_std) / 2\n\n        perturbation_intensity = max(1, int(3 * (1 - diversity) * random.uniform(0.5, 1.5)))\n\n        for _ in range(perturbation_intensity):\n            flip_idx = random.choice(included_items)\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n                current_weight -= weight_lst[flip_idx]\n\n        for _ in range(perturbation_intensity):\n            if len(excluded_items) > 0:\n                add_idx = random.choice(excluded_items)\n                if current_weight + weight_lst[add_idx] <= capacity:\n                    new_solution[add_idx] = 1\n                    current_weight += weight_lst[add_idx]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        current_val1 = np.sum(value1_lst[included_items])\n        current_val2 = np.sum(value2_lst[included_items])\n        balance_factor = 0.6 if current_val1 > current_val2 else 0.4\n\n        improvement_scores = (value1_lst[excluded_items] * balance_factor + value2_lst[excluded_items] * (1 - balance_factor)) / (weight_lst[excluded_items] * 0.6 + 1e-6)\n\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            worst_scores = (value1_lst[included_items] * (1 - balance_factor) + value2_lst[included_items] * balance_factor) / (weight_lst[included_items] * 0.5 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.99598352284258,
            -18.654208858309605
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        current_val1 = np.sum(value1_lst[included_items])\n        current_val2 = np.sum(value2_lst[included_items])\n        obj_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        combined_scores = (value1_lst[excluded_items] * (1 - obj_ratio) + value2_lst[excluded_items] * obj_ratio) / (weight_lst[excluded_items] * 0.7 + 1e-6)\n\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(combined_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            worst_scores = (value1_lst[included_items] * obj_ratio + value2_lst[included_items] * (1 - obj_ratio)) / (weight_lst[included_items] * 0.8 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    if len(included_items) > 0:\n        obj1_std = np.std(value1_lst[included_items]) if len(included_items) > 1 else 0\n        obj2_std = np.std(value2_lst[included_items]) if len(included_items) > 1 else 0\n        diversity = (obj1_std + obj2_std) / 2\n\n        perturbation_intensity = max(1, int(3 * (1 - diversity) * random.uniform(0.5, 1.5)))\n\n        for _ in range(perturbation_intensity):\n            flip_idx = random.choice(included_items)\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n                current_weight -= weight_lst[flip_idx]\n\n        for _ in range(perturbation_intensity):\n            if len(excluded_items) > 0:\n                add_idx = random.choice(excluded_items)\n                if current_weight + weight_lst[add_idx] <= capacity:\n                    new_solution[add_idx] = 1\n                    current_weight += weight_lst[add_idx]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        current_val1 = np.sum(value1_lst[included_items])\n        current_val2 = np.sum(value2_lst[included_items])\n        balance_factor = 0.6 if current_val1 > current_val2 else 0.4\n\n        improvement_scores = (value1_lst[excluded_items] * balance_factor + value2_lst[excluded_items] * (1 - balance_factor)) / (weight_lst[excluded_items] * 0.6 + 1e-6)\n\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            worst_scores = (value1_lst[included_items] * (1 - balance_factor) + value2_lst[included_items] * balance_factor) / (weight_lst[included_items] * 0.5 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n"
    }
]