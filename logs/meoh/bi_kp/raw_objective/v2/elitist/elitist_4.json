[
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a novel local search strategy that combines probabilistic item removal, value-weighted insertion, and adaptive crowding-aware exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = marginal_value1 + marginal_value2\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-weighted insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive crowding-aware exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.819357366354353,
            -18.43242486142109
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a novel local search strategy that combines probabilistic item removal, value-weighted insertion, and adaptive crowding-aware exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = marginal_value1 + marginal_value2\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-weighted insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive crowding-aware exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.98086817454899,
            -18.417995894225676
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a novel local search strategy that combines probabilistic item removal, value-weighted insertion, and adaptive crowding-aware exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = marginal_value1 + marginal_value2\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-weighted insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive crowding-aware exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.651000064831955,
            -18.571452259751904
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a novel local search strategy that combines probabilistic item removal, value-weighted insertion, and adaptive crowding-aware exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = marginal_value1 + marginal_value2\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-weighted insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive crowding-aware exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.75964121859772,
            -18.549749613411734
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a novel local search strategy that combines probabilistic item removal, value-weighted insertion, and adaptive crowding-aware exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = marginal_value1 + marginal_value2\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-weighted insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive crowding-aware exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.954045774496187,
            -18.217066390710585
        ]
    },
    {
        "algorithm": "{This algorithm intelligently selects a solution from the archive based on its potential for local improvement, then applies a hybrid local search strategy combining item swaps and adaptive neighborhood exploration, considering both objective values and their trade-offs, to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too crowded in the archive)\n    # Here, we choose a solution randomly but prioritize those with lower crowding distance (if available)\n    # For simplicity, we select a random solution from the archive\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1, current_value2 = archive[selected_idx][1]\n\n    # Hybrid local search: Combine item swaps and adaptive neighborhood exploration\n    new_solution = base_solution.copy()\n\n    # Step 1: Randomly select items to swap (included with excluded)\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) == 0 or len(excluded_items) == 0:\n        # If no items to swap, perform a random flip\n        flip_idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n        return new_solution\n\n    # Step 2: Perform a swap between an included and excluded item\n    swap_in = random.choice(included_items)\n    swap_out = random.choice(excluded_items)\n\n    # Check feasibility of the swap\n    delta_weight = weight_lst[swap_out] - weight_lst[swap_in]\n    if current_weight + delta_weight <= capacity:\n        new_solution[swap_in] = 0\n        new_solution[swap_out] = 1\n\n    # Step 3: Adaptive neighborhood exploration (flip a random bit if the swap didn't improve)\n    # This is a simple heuristic; more sophisticated strategies can be added\n    if np.array_equal(new_solution, base_solution):\n        flip_idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.91352555470143,
            -18.121894380158153
        ]
    },
    {
        "algorithm": "{This algorithm intelligently selects a solution from the archive based on its dominance and diversity, then applies a hybrid local search strategy combining item swaps, adaptive neighborhood exploration, and probabilistic bit flips to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution based on dominance and diversity\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic bit flip based on item importance\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate item importance scores\n        importance_scores = (value1_lst + value2_lst) / weight_lst\n        prob_flip_in = importance_scores[included_items] / np.sum(importance_scores[included_items])\n        prob_flip_out = importance_scores[excluded_items] / np.sum(importance_scores[excluded_items])\n\n        # Flip an item with probability proportional to its importance\n        if random.random() < 0.7:  # Higher probability for flipping\n            if random.random() < 0.5 and len(included_items) > 0:\n                flip_idx = np.random.choice(included_items, p=prob_flip_in)\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                flip_idx = np.random.choice(excluded_items, p=prob_flip_out)\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    # Step 2: If no flip occurred, perform a random swap between included and excluded items\n    if np.array_equal(new_solution, base_solution):\n        if len(included_items) > 0 and len(excluded_items) > 0:\n            swap_in = random.choice(included_items)\n            swap_out = random.choice(excluded_items)\n            delta_weight = weight_lst[swap_out] - weight_lst[swap_in]\n            if current_weight + delta_weight <= capacity:\n                new_solution[swap_in] = 0\n                new_solution[swap_out] = 1\n\n    # Step 3: If still no change, perform a random flip among least important items\n    if np.array_equal(new_solution, base_solution):\n        if len(included_items) > 0:\n            least_important_in = included_items[np.argmin(importance_scores[included_items])]\n            if current_weight - weight_lst[least_important_in] <= capacity:\n                new_solution[least_important_in] = 0\n        elif len(excluded_items) > 0:\n            most_important_out = excluded_items[np.argmax(importance_scores[excluded_items])]\n            if current_weight + weight_lst[most_important_out] <= capacity:\n                new_solution[most_important_out] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.780444523046285,
            -18.389324612783895
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on a novel scoring function that combines normalized objective values and item diversity, then applies a hybrid local search strategy that prioritizes high-value items with adaptive flipping probabilities and guided neighborhood exploration to generate high-quality neighbor solutions while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Novel selection strategy: combine normalized objective values and item diversity\n    normalized_scores = []\n    max_v1 = max(v1 for _, (v1, _) in archive)\n    max_v2 = max(v2 for _, (_, v2) in archive)\n    for sol, (v1, v2) in archive:\n        diversity = np.sum(sol) / len(sol)  # Fraction of items included\n        normalized_v1 = v1 / max_v1 if max_v1 > 0 else 0\n        normalized_v2 = v2 / max_v2 if max_v2 > 0 else 0\n        score = 0.4 * normalized_v1 + 0.4 * normalized_v2 + 0.2 * diversity\n        normalized_scores.append(score)\n\n    normalized_scores = np.array(normalized_scores)\n    normalized_scores = normalized_scores / np.sum(normalized_scores)\n    selected_idx = np.random.choice(len(archive), p=normalized_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: prioritize high-value items with adaptive probabilities\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Adaptive flipping probabilities based on value ratio\n        flip_candidates = np.concatenate([included_items, excluded_items])\n        flip_probs = np.zeros(len(flip_candidates))\n        for i, idx in enumerate(flip_candidates):\n            value_ratio = (value1_lst[idx] / (value2_lst[idx] + 1e-6))\n            if new_solution[idx] == 1:\n                flip_probs[i] = value_ratio * 0.3  # Prefer removing items with high value ratio\n            else:\n                flip_probs[i] = value_ratio * 0.7  # Prefer adding items with high value ratio\n        flip_probs = flip_probs / np.sum(flip_probs)\n\n        # Perform adaptive flips\n        for _ in range(min(4, len(flip_candidates))):\n            flip_idx = np.random.choice(flip_candidates, p=flip_probs)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Guided neighborhood exploration: flip items with high marginal improvement\n    if np.array_equal(new_solution, base_solution):\n        marginal_values = np.zeros(len(weight_lst))\n        for i in range(len(weight_lst)):\n            if new_solution[i] == 1:\n                marginal_values[i] = (value1_lst[i] + value2_lst[i]) * 0.4\n            else:\n                marginal_values[i] = (value1_lst[i] + value2_lst[i]) * 0.6\n        marginal_values = marginal_values / np.sum(marginal_values)\n\n        for _ in range(min(6, len(weight_lst))):\n            flip_idx = np.random.choice(len(weight_lst), p=marginal_values)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    return new_solution\n\n",
        "score": [
            -18.438259119807853,
            -18.53751299093918
        ]
    },
    {
        "algorithm": "{This algorithm intelligently selects a solution from the archive based on its potential for local improvement, then applies a hybrid local search strategy combining item swaps and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too crowded in the archive)\n    # Here, we choose a solution randomly but prioritize those with lower crowding distance (if available)\n    # For simplicity, we select a random solution from the archive\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: Combine item swaps and adaptive neighborhood exploration\n    new_solution = base_solution.copy()\n\n    # Step 1: Randomly select items to swap (included with excluded)\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) == 0 or len(excluded_items) == 0:\n        # If no items to swap, perform a random flip\n        flip_idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n        return new_solution\n\n    # Step 2: Perform a swap between an included and excluded item\n    swap_in = random.choice(included_items)\n    swap_out = random.choice(excluded_items)\n\n    # Check feasibility of the swap\n    delta_weight = weight_lst[swap_out] - weight_lst[swap_in]\n    if current_weight + delta_weight <= capacity:\n        new_solution[swap_in] = 0\n        new_solution[swap_out] = 1\n\n    # Step 3: Adaptive neighborhood exploration (flip a random bit if the swap didn't improve)\n    # This is a simple heuristic; more sophisticated strategies can be added\n    if np.array_equal(new_solution, base_solution):\n        flip_idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.890917726717365,
            -17.954234354809287
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a novel local search strategy that combines probabilistic item selection, adaptive flipping with value-weighted probabilities, and guided neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with higher combined values)\n    selected_idx = np.random.choice(len(archive), p=np.array([v1 + v2 for _, (v1, v2) in archive]) / sum(v1 + v2 for _, (v1, v2) in archive))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Probabilistic item selection for flipping\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Value-weighted probabilities for flipping\n        flip_candidates = np.concatenate([included_items, excluded_items])\n        flip_probs = np.zeros(len(flip_candidates))\n        for i, idx in enumerate(flip_candidates):\n            if new_solution[idx] == 1:\n                flip_probs[i] = (value1_lst[idx] + value2_lst[idx]) * 0.5  # Prefer removing high-value items\n            else:\n                flip_probs[i] = (value1_lst[idx] + value2_lst[idx]) * 1.5  # Prefer adding high-value items\n        flip_probs = flip_probs / np.sum(flip_probs)\n\n        # Perform probabilistic flips\n        for _ in range(min(3, len(flip_candidates))):\n            flip_idx = np.random.choice(flip_candidates, p=flip_probs)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Guided neighborhood exploration: flip items based on marginal improvement\n    if np.array_equal(new_solution, base_solution):\n        marginal_values = np.zeros(len(weight_lst))\n        for i in range(len(weight_lst)):\n            if new_solution[i] == 1:\n                marginal_values[i] = (value1_lst[i] + value2_lst[i]) * 0.5\n            else:\n                marginal_values[i] = (value1_lst[i] + value2_lst[i]) * 1.5\n        marginal_values = marginal_values / np.sum(marginal_values)\n\n        for _ in range(min(5, len(weight_lst))):\n            flip_idx = np.random.choice(len(weight_lst), p=marginal_values)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    return new_solution\n\n",
        "score": [
            -18.799767353852562,
            -18.05952401332903
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a novel local search strategy that combines probabilistic item removal, value-weighted insertion, and adaptive crowding-aware exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = marginal_value1 + marginal_value2\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-weighted insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive crowding-aware exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.819357366354353,
            -18.43242486142109
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a novel local search strategy that combines probabilistic item removal, value-weighted insertion, and adaptive crowding-aware exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = marginal_value1 + marginal_value2\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-weighted insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive crowding-aware exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.651000064831955,
            -18.571452259751904
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a novel local search strategy that combines probabilistic item removal, value-weighted insertion, and adaptive crowding-aware exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = marginal_value1 + marginal_value2\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-weighted insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive crowding-aware exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.75964121859772,
            -18.549749613411734
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a novel local search strategy that combines probabilistic item removal, value-weighted insertion, and adaptive crowding-aware exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = marginal_value1 + marginal_value2\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-weighted insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive crowding-aware exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.98086817454899,
            -18.417995894225676
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a novel local search strategy that combines probabilistic item removal, value-weighted insertion, and adaptive crowding-aware exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = marginal_value1 + marginal_value2\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-weighted insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive crowding-aware exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.819357366354353,
            -18.43242486142109
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for improvement, then applies a novel local search strategy that combines probabilistic item removal, value-weighted insertion, and adaptive crowding-aware exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item removal (remove items with low marginal contribution)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate marginal contribution for each included item\n        marginal_value1 = value1_lst[included_items]\n        marginal_value2 = value2_lst[included_items]\n        marginal_contribution = marginal_value1 + marginal_value2\n\n        # Remove items with low marginal contribution with higher probability\n        removal_probs = 1 / (1 + marginal_contribution)\n        removal_probs = removal_probs / np.sum(removal_probs)\n\n        remove_idx = np.random.choice(included_items, p=removal_probs)\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Value-weighted insertion (insert items with high value-to-weight ratio)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate value-to-weight ratio for each excluded item\n        value_ratio = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Insert items with high value-to-weight ratio with higher probability\n        insertion_probs = value_ratio / np.sum(value_ratio)\n\n        insert_idx = np.random.choice(excluded_items, p=insertion_probs)\n        if current_weight + weight_lst[insert_idx] <= capacity:\n            new_solution[insert_idx] = 1\n            current_weight += weight_lst[insert_idx]\n\n    # Step 3: Adaptive crowding-aware exploration (flip a random bit if solution is not on the Pareto front)\n    if len(archive) > 1:\n        # Check if the current solution is dominated by any other solution in the archive\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        is_dominated = False\n\n        for sol, (val1, val2) in archive:\n            if (val1 >= current_val1 and val2 > current_val2) or (val1 > current_val1 and val2 >= current_val2):\n                is_dominated = True\n                break\n\n        if is_dominated:\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.651000064831955,
            -18.571452259751904
        ]
    }
]