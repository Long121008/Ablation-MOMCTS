[
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective prioritization and diversity-aware perturbation with weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement using novel selection criteria\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 1: Novel objective-aware prioritization with adaptive weights\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        weight_factor = 0.5 + 0.5 * (current_val1 / (current_val1 + current_val2 + 1e-6))\n\n        weighted_scores = (value1_lst * weight_factor + value2_lst * (1 - weight_factor)) / (weight_lst * 0.9 + 1e-6)\n\n        # Select top items to consider\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * (1 - weight_factor) + value2_lst[included_items] * weight_factor) / (weight_lst[included_items] * 0.8 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(5 * (1 - diversity) * random.uniform(0.6, 1.4)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with adaptive weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.8 + current_val2 * 0.2 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with adaptive scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.8 + 1e-6)\n        else:\n            # Focus on value1 improvement with adaptive scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.6 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with adaptive scoring\n            worst_scores = (value1_lst[included_items] * 0.6 + value2_lst[included_items] * 0.4) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.654494884729814,
            -18.99401824580087
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for multi-objective improvement, then applies a novel local search strategy that combines objective-balanced item selection, adaptive objective prioritization, and diversity-aware perturbation to generate a high-quality neighbor solution while ensuring feasibility, using a creative approach that dynamically balances exploitation of high-value items with exploration of underrepresented objective regions.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Objective-balanced item selection (select items based on balanced objective contributions)\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective balance scores for excluded items\n        balance_scores = (value1_lst[excluded_items] / (np.sum(value1_lst[included_items]) + 1e-6) +\n                         value2_lst[excluded_items] / (np.sum(value2_lst[included_items]) + 1e-6)) / weight_lst[excluded_items]\n\n        # Select top k items to consider for selection\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(balance_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            select_idx = np.random.choice(top_indices)\n\n            # Find the least balanced item to replace based on current objective ratios\n            current_val1 = np.sum(value1_lst[included_items])\n            current_val2 = np.sum(value2_lst[included_items])\n            balance_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n            balance_scores_included = (value1_lst[included_items] * balance_ratio +\n                                      value2_lst[included_items] * (1 - balance_ratio)) / weight_lst[included_items]\n            replace_idx = np.argmin(balance_scores_included)\n            replace_idx = included_items[replace_idx]\n\n            # Perform selection if feasible\n            if current_weight - weight_lst[replace_idx] + weight_lst[select_idx] <= capacity:\n                new_solution[replace_idx] = 0\n                new_solution[select_idx] = 1\n\n    # Step 2: Adaptive objective prioritization (prioritize objectives based on solution state)\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective priorities based on current solution state\n        current_val1 = np.sum(value1_lst[included_items])\n        current_val2 = np.sum(value2_lst[included_items])\n        priority_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Calculate prioritization scores for excluded items\n        priority_scores = (value1_lst[excluded_items] * priority_ratio +\n                          value2_lst[excluded_items] * (1 - priority_ratio)) / weight_lst[excluded_items]\n\n        # Select top k items to consider for prioritization\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(priority_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            prioritize_idx = np.random.choice(top_indices)\n\n            # Find the worst item to replace based on current objective priorities\n            worst_scores = (value1_lst[included_items] * priority_ratio +\n                           value2_lst[included_items] * (1 - priority_ratio)) / weight_lst[included_items]\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform prioritization if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[prioritize_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[prioritize_idx] = 1\n\n    # Step 3: Diversity-aware perturbation (perturb solution based on objective diversity)\n    if len(included_items) > 0:\n        # Calculate objective diversity scores\n        obj1_diversity = len(np.unique(value1_lst[included_items])) / len(value1_lst)\n        obj2_diversity = len(np.unique(value2_lst[included_items])) / len(value2_lst)\n        diversity_score = min(obj1_diversity, obj2_diversity)\n\n        # Determine number of perturbations based on diversity (less diverse solutions get more changes)\n        num_perturb = max(1, int(4 * (1 - diversity_score)))\n\n        for _ in range(num_perturb):\n            # Select a random item to perturb\n            perturb_idx = random.randint(0, len(new_solution) - 1)\n\n            if new_solution[perturb_idx] == 1:\n                # Try to remove item if feasible\n                if current_weight - weight_lst[perturb_idx] <= capacity:\n                    new_solution[perturb_idx] = 0\n            else:\n                # Try to add item if feasible\n                if current_weight + weight_lst[perturb_idx] <= capacity:\n                    new_solution[perturb_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.230717983159106,
            -18.584336971242337
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of objective-driven item prioritization and adaptive neighborhood exploration with dynamic solution balancing, using a combination of multi-objective scoring and diversity-aware perturbations to generate high-quality neighbors while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Objective-driven item prioritization with dynamic weights\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate dynamic objective weights based on current solution balance\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        obj1_weight = 0.5 + 0.3 * (current_val2 / (current_val1 + 1e-6))\n        obj2_weight = 0.5 + 0.3 * (current_val1 / (current_val2 + 1e-6))\n\n        # Calculate multi-objective scores for excluded items\n        mo_scores = (value1_lst[excluded_items] * obj1_weight + value2_lst[excluded_items] * obj2_weight) / (weight_lst[excluded_items] * 0.4 + 1e-6)\n\n        # Select top items to consider\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(mo_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * (1 - obj1_weight) + value2_lst[included_items] * (1 - obj2_weight)) / (weight_lst[included_items] * 0.5 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with diversity awareness\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(3 * (1 - diversity) * random.uniform(0.8, 1.2)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel solution balancing with dynamic objective focus\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective balance with dynamic weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        balance_ratio = current_val1 / (current_val1 * obj1_weight + current_val2 * obj2_weight + 1e-6)\n\n        # Select items based on current balance\n        if balance_ratio > 0.5:\n            # Focus on value2 improvement\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.4 + 1e-6)\n        else:\n            # Focus on value1 improvement\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.4 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with novel scoring\n            worst_scores = (value1_lst[included_items] * obj1_weight + value2_lst[included_items] * obj2_weight) / (weight_lst[included_items] * 0.5 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.685135679393746,
            -18.87805075330563
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective weighting and dynamic neighborhood exploration with item prioritization, using a combination of objective-aware scoring and diversity-sensitive perturbations to generate high-quality neighbors while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Adaptive objective weighting with novel scoring\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate dynamic weights based on current solution balance\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        obj1_weight = 0.5 + 0.3 * (current_val2 / (current_val1 + 1e-6))\n        obj2_weight = 0.5 + 0.3 * (current_val1 / (current_val2 + 1e-6))\n\n        # Novel scoring with dynamic weights\n        weighted_scores = (value1_lst * obj1_weight + value2_lst * obj2_weight) / (weight_lst * 0.6 + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * (1 - obj1_weight) + value2_lst[included_items] * (1 - obj2_weight)) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Dynamic neighborhood exploration with novel intensity\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(4 * (1 - diversity) * random.uniform(0.7, 1.3)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with dynamic weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with dynamic weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * obj1_weight + current_val2 * obj2_weight + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with novel scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n        else:\n            # Focus on value1 improvement with novel scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with novel scoring\n            worst_scores = (value1_lst[included_items] * obj1_weight + value2_lst[included_items] * obj2_weight) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.57056296382639,
            -19.073851764791637
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective prioritization and diversity-aware perturbation with weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement using novel selection criteria\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 1: Novel objective-aware prioritization with adaptive weights\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        weight_factor = 0.5 + 0.5 * (current_val1 / (current_val1 + current_val2 + 1e-6))\n\n        weighted_scores = (value1_lst * weight_factor + value2_lst * (1 - weight_factor)) / (weight_lst * 0.8 + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * (1 - weight_factor) + value2_lst[included_items] * weight_factor) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(4 * (1 - diversity) * random.uniform(0.7, 1.3)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with adaptive weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.7 + current_val2 * 0.3 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with adaptive scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.7 + 1e-6)\n        else:\n            # Focus on value1 improvement with adaptive scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with adaptive scoring\n            worst_scores = (value1_lst[included_items] * 0.5 + value2_lst[included_items] * 0.5) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.616111999506014,
            -19.002072254111845
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution with high potential for improvement by combining probabilistic item selection with objective-aware swaps, adaptive neighborhood exploration, and a novel score function that balances both objectives using a weighted sum approach to generate high-quality neighbor solutions while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic objective-aware selection with weighted score function\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate weighted combined objective scores\n        alpha = 0.7  # Weight for value1\n        beta = 0.3   # Weight for value2\n        combined_scores = (alpha * value1_lst + beta * value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(combined_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace based on weighted score\n            worst_scores = (alpha * value1_lst[included_items] + beta * value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with dynamic intensity\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(4 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Objective-specific fine-tuning with weighted replacement\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Adjust weights based on current balance\n        alpha = 0.6 if ratio > 0.5 else 0.4\n        beta = 1 - alpha\n\n        # Select items based on weighted improvement potential\n        improvement_scores = (alpha * value1_lst[excluded_items] + beta * value2_lst[excluded_items]) / (weight_lst[excluded_items] + 1e-6)\n\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace based on weighted score\n            worst_scores = (alpha * value1_lst[included_items] + beta * value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.486116593229788,
            -18.18120770566933
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for balanced objective improvement, then applies a hybrid local search strategy that combines probabilistic item prioritization, objective-aware replacement, and adaptive neighborhood diversification, while incorporating a novel item clustering technique to identify and exploit groups of items that contribute synergistically to both objectives.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for balanced improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Item clustering and prioritization\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate clustering scores for items (combining value and weight)\n        cluster_scores = (value1_lst * value2_lst) / (weight_lst + 1e-6)\n\n        # Find the most promising cluster to prioritize\n        cluster_indices = np.argsort(-cluster_scores[excluded_items])\n        cluster_size = min(5, len(cluster_indices))\n        cluster_indices = excluded_items[cluster_indices[:cluster_size]]\n\n        if len(cluster_indices) > 0:\n            prioritize_idx = np.random.choice(cluster_indices)\n\n            # Find the worst item in the current solution\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = included_items[np.argmin(worst_scores)]\n\n            # Perform prioritization if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[prioritize_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[prioritize_idx] = 1\n\n    # Step 2: Balanced objective replacement\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate replacement potential considering both objectives\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        balance_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        replacement_scores = (value1_lst[excluded_items] * (1 - balance_ratio) + value2_lst[excluded_items] * balance_ratio) / weight_lst[excluded_items]\n        replace_idx = np.random.choice(excluded_items, p=replacement_scores / np.sum(replacement_scores))\n\n        # Find the least balanced item to replace\n        balance_scores = (value1_lst[included_items] * (1 - balance_ratio) + value2_lst[included_items] * balance_ratio) / weight_lst[included_items]\n        least_balanced_idx = included_items[np.argmin(balance_scores)]\n\n        # Perform replacement if feasible\n        if current_weight - weight_lst[least_balanced_idx] + weight_lst[replace_idx] <= capacity:\n            new_solution[least_balanced_idx] = 0\n            new_solution[replace_idx] = 1\n\n    # Step 3: Adaptive neighborhood diversification with clustering awareness\n    if len(included_items) > 0:\n        # Calculate solution diversity using clustering information\n        cluster_diversity = len(np.unique(np.floor(value1_lst[included_items] / np.mean(value1_lst)))) * \\\n                           len(np.unique(np.floor(value2_lst[included_items] / np.mean(value2_lst))))\n\n        # Determine number of bits to flip based on cluster diversity\n        num_flips = max(1, int(3 * (1 - min(1, cluster_diversity / (len(included_items) + 1e-6)))))\n\n        for _ in range(num_flips):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.960380061248387,
            -18.694170138243813
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution with high potential for improvement in both objectives by combining probabilistic item selection with objective-aware swaps and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic objective-aware selection\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate combined objective scores\n        combined_scores = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(combined_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Objective-specific fine-tuning\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Select items based on objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        else:\n            # Focus on value1 improvement\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] * ratio + value2_lst[included_items] * (1 - ratio)) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.125194556064613,
            -18.64008991764989
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective prioritization and diversity-aware perturbation with weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Novel objective-aware prioritization with weighted scoring\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with different weights\n        weighted_scores = (value1_lst * 0.4 + value2_lst * 0.6) / (weight_lst * 0.7 + 1e-6)\n\n        # Select top items to consider\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * 0.3 + value2_lst[included_items] * 0.7) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(3 * (1 - diversity) * random.uniform(0.8, 1.2)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with different weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with novel weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.6 + current_val2 * 0.4 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with novel scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.6 + 1e-6)\n        else:\n            # Focus on value1 improvement with novel scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.4 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with novel scoring\n            worst_scores = (value1_lst[included_items] * 0.4 + value2_lst[included_items] * 0.6) / (weight_lst[included_items] * 0.5 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.10582703107761,
            -19.389330320689613
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective prioritization, diversity-aware perturbation, and weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Novel objective-aware prioritization with weighted scoring\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with different weights\n        weighted_scores = (value1_lst * 0.5 + value2_lst * 0.5) / (weight_lst * 0.8 + 1e-6)\n\n        # Select top items to consider\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * 0.4 + value2_lst[included_items] * 0.6) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(4 * (1 - diversity) * random.uniform(0.7, 1.3)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with different weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with novel weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.7 + current_val2 * 0.3 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with novel scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n        else:\n            # Focus on value1 improvement with novel scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with novel scoring\n            worst_scores = (value1_lst[included_items] * 0.5 + value2_lst[included_items] * 0.5) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.578859684343357,
            -19.058418823423825
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective prioritization, diversity-aware perturbation, and weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Novel objective-aware prioritization with weighted scoring\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with different weights\n        weighted_scores = (value1_lst * 0.5 + value2_lst * 0.5) / (weight_lst * 0.8 + 1e-6)\n\n        # Select top items to consider\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * 0.4 + value2_lst[included_items] * 0.6) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(4 * (1 - diversity) * random.uniform(0.7, 1.3)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with different weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with novel weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.7 + current_val2 * 0.3 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with novel scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n        else:\n            # Focus on value1 improvement with novel scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with novel scoring\n            worst_scores = (value1_lst[included_items] * 0.5 + value2_lst[included_items] * 0.5) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.578859684343357,
            -19.058418823423825
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective weighting and dynamic neighborhood exploration with item prioritization, using a combination of objective-aware scoring and diversity-sensitive perturbations to generate high-quality neighbors while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Adaptive objective weighting with novel scoring\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate dynamic weights based on current solution balance\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        obj1_weight = 0.5 + 0.3 * (current_val2 / (current_val1 + 1e-6))\n        obj2_weight = 0.5 + 0.3 * (current_val1 / (current_val2 + 1e-6))\n\n        # Novel scoring with dynamic weights\n        weighted_scores = (value1_lst * obj1_weight + value2_lst * obj2_weight) / (weight_lst * 0.6 + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * (1 - obj1_weight) + value2_lst[included_items] * (1 - obj2_weight)) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Dynamic neighborhood exploration with novel intensity\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(4 * (1 - diversity) * random.uniform(0.7, 1.3)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with dynamic weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with dynamic weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * obj1_weight + current_val2 * obj2_weight + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with novel scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n        else:\n            # Focus on value1 improvement with novel scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with novel scoring\n            worst_scores = (value1_lst[included_items] * obj1_weight + value2_lst[included_items] * obj2_weight) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.57056296382639,
            -19.073851764791637
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective prioritization and diversity-aware perturbation with weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement using novel selection criteria\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 1: Novel objective-aware prioritization with adaptive weights\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        weight_factor = 0.5 + 0.5 * (current_val1 / (current_val1 + current_val2 + 1e-6))\n\n        weighted_scores = (value1_lst * weight_factor + value2_lst * (1 - weight_factor)) / (weight_lst * 0.8 + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * (1 - weight_factor) + value2_lst[included_items] * weight_factor) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(4 * (1 - diversity) * random.uniform(0.7, 1.3)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with adaptive weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.7 + current_val2 * 0.3 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with adaptive scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.7 + 1e-6)\n        else:\n            # Focus on value1 improvement with adaptive scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with adaptive scoring\n            worst_scores = (value1_lst[included_items] * 0.5 + value2_lst[included_items] * 0.5) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.616111999506014,
            -19.002072254111845
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution with high potential for improvement by combining probabilistic item selection with objective-aware swaps, adaptive neighborhood exploration, and a novel score function that balances both objectives using a weighted sum approach to generate high-quality neighbor solutions while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic objective-aware selection with weighted score function\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate weighted combined objective scores\n        alpha = 0.7  # Weight for value1\n        beta = 0.3   # Weight for value2\n        combined_scores = (alpha * value1_lst + beta * value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(combined_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace based on weighted score\n            worst_scores = (alpha * value1_lst[included_items] + beta * value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with dynamic intensity\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(4 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Objective-specific fine-tuning with weighted replacement\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Adjust weights based on current balance\n        alpha = 0.6 if ratio > 0.5 else 0.4\n        beta = 1 - alpha\n\n        # Select items based on weighted improvement potential\n        improvement_scores = (alpha * value1_lst[excluded_items] + beta * value2_lst[excluded_items]) / (weight_lst[excluded_items] + 1e-6)\n\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace based on weighted score\n            worst_scores = (alpha * value1_lst[included_items] + beta * value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.486116593229788,
            -18.18120770566933
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for balanced objective improvement, then applies a hybrid local search strategy that combines probabilistic item prioritization, objective-aware replacement, and adaptive neighborhood diversification, while incorporating a novel item clustering technique to identify and exploit groups of items that contribute synergistically to both objectives.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for balanced improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Item clustering and prioritization\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate clustering scores for items (combining value and weight)\n        cluster_scores = (value1_lst * value2_lst) / (weight_lst + 1e-6)\n\n        # Find the most promising cluster to prioritize\n        cluster_indices = np.argsort(-cluster_scores[excluded_items])\n        cluster_size = min(5, len(cluster_indices))\n        cluster_indices = excluded_items[cluster_indices[:cluster_size]]\n\n        if len(cluster_indices) > 0:\n            prioritize_idx = np.random.choice(cluster_indices)\n\n            # Find the worst item in the current solution\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = included_items[np.argmin(worst_scores)]\n\n            # Perform prioritization if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[prioritize_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[prioritize_idx] = 1\n\n    # Step 2: Balanced objective replacement\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate replacement potential considering both objectives\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        balance_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        replacement_scores = (value1_lst[excluded_items] * (1 - balance_ratio) + value2_lst[excluded_items] * balance_ratio) / weight_lst[excluded_items]\n        replace_idx = np.random.choice(excluded_items, p=replacement_scores / np.sum(replacement_scores))\n\n        # Find the least balanced item to replace\n        balance_scores = (value1_lst[included_items] * (1 - balance_ratio) + value2_lst[included_items] * balance_ratio) / weight_lst[included_items]\n        least_balanced_idx = included_items[np.argmin(balance_scores)]\n\n        # Perform replacement if feasible\n        if current_weight - weight_lst[least_balanced_idx] + weight_lst[replace_idx] <= capacity:\n            new_solution[least_balanced_idx] = 0\n            new_solution[replace_idx] = 1\n\n    # Step 3: Adaptive neighborhood diversification with clustering awareness\n    if len(included_items) > 0:\n        # Calculate solution diversity using clustering information\n        cluster_diversity = len(np.unique(np.floor(value1_lst[included_items] / np.mean(value1_lst)))) * \\\n                           len(np.unique(np.floor(value2_lst[included_items] / np.mean(value2_lst))))\n\n        # Determine number of bits to flip based on cluster diversity\n        num_flips = max(1, int(3 * (1 - min(1, cluster_diversity / (len(included_items) + 1e-6)))))\n\n        for _ in range(num_flips):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.960380061248387,
            -18.694170138243813
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution with high potential for improvement in both objectives by combining probabilistic item selection with objective-aware swaps and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic objective-aware selection\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate combined objective scores\n        combined_scores = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(combined_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Objective-specific fine-tuning\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Select items based on objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        else:\n            # Focus on value1 improvement\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] * ratio + value2_lst[included_items] * (1 - ratio)) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.125194556064613,
            -18.64008991764989
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective prioritization and diversity-aware perturbation with weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Novel objective-aware prioritization with weighted scoring\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with different weights\n        weighted_scores = (value1_lst * 0.4 + value2_lst * 0.6) / (weight_lst * 0.7 + 1e-6)\n\n        # Select top items to consider\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * 0.3 + value2_lst[included_items] * 0.7) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(3 * (1 - diversity) * random.uniform(0.8, 1.2)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with different weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with novel weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.6 + current_val2 * 0.4 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with novel scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.6 + 1e-6)\n        else:\n            # Focus on value1 improvement with novel scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.4 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with novel scoring\n            worst_scores = (value1_lst[included_items] * 0.4 + value2_lst[included_items] * 0.6) / (weight_lst[included_items] * 0.5 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.10582703107761,
            -19.389330320689613
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective prioritization and diversity-aware perturbation with weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement using novel selection criteria\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 1: Novel objective-aware prioritization with adaptive weights\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        weight_factor = 0.5 + 0.5 * (current_val1 / (current_val1 + current_val2 + 1e-6))\n\n        weighted_scores = (value1_lst * weight_factor + value2_lst * (1 - weight_factor)) / (weight_lst * 0.9 + 1e-6)\n\n        # Select top items to consider\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * (1 - weight_factor) + value2_lst[included_items] * weight_factor) / (weight_lst[included_items] * 0.8 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(5 * (1 - diversity) * random.uniform(0.6, 1.4)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with adaptive weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.8 + current_val2 * 0.2 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with adaptive scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.8 + 1e-6)\n        else:\n            # Focus on value1 improvement with adaptive scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.6 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with adaptive scoring\n            worst_scores = (value1_lst[included_items] * 0.6 + value2_lst[included_items] * 0.4) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.654494884729814,
            -18.99401824580087
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective-driven item prioritization, diversity-aware perturbation with weighted scoring, and multi-phase exploration with dynamic objective balancing to generate high-quality neighbors by intelligently combining item selection, solution diversification, and objective-specific fine-tuning while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Phase 2: Adaptive objective-driven item prioritization with weighted scoring\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate dynamic objective weights based on current solution balance\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        obj1_weight = 0.6 + 0.2 * (current_val2 / (current_val1 + 1e-6))\n        obj2_weight = 0.6 + 0.2 * (current_val1 / (current_val2 + 1e-6))\n\n        # Calculate weighted scores for excluded items\n        weighted_scores = (value1_lst[excluded_items] * obj1_weight + value2_lst[excluded_items] * obj2_weight) / (weight_lst[excluded_items] * 0.3 + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * (1 - obj1_weight) + value2_lst[included_items] * (1 - obj2_weight)) / (weight_lst[included_items] * 0.4 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Phase 3: Diversity-aware perturbation with weighted scoring\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(5 * (1 - diversity) * random.uniform(0.6, 1.0)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Phase 4: Multi-phase exploration with dynamic objective balancing\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective balance with dynamic weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        balance_ratio = current_val1 / (current_val1 * obj1_weight + current_val2 * obj2_weight + 1e-6)\n\n        # Phase 4a: Objective-specific fine-tuning\n        if balance_ratio > 0.6:\n            # Focus on value2 improvement\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.3 + 1e-6)\n        else:\n            # Focus on value1 improvement\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.3 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with novel scoring\n            worst_scores = (value1_lst[included_items] * obj1_weight + value2_lst[included_items] * obj2_weight) / (weight_lst[included_items] * 0.4 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n        # Phase 4b: Additional diversification step\n        if random.random() < 0.3:\n            # Perform random swap to maintain diversity\n            swap_indices = np.random.choice(included_items, size=min(2, len(included_items)), replace=False)\n            if len(swap_indices) == 2:\n                i, j = swap_indices\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -19.081298010812105,
            -18.68609336319052
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of objective-balanced selection and adaptive neighborhood perturbation with weighted item evaluation to generate high-quality neighbors by intelligently combining solution diversity and objective-specific improvement strategies while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement using novel selection criteria\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 1: Objective-balanced item selection with adaptive weights\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective balance with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        balance_factor = 0.5 + 0.5 * (current_val1 / (current_val1 + current_val2 + 1e-6))\n\n        # Calculate weighted scores for excluded items\n        weighted_scores = (value1_lst[excluded_items] * balance_factor + value2_lst[excluded_items] * (1 - balance_factor)) / (weight_lst[excluded_items] * 0.8 + 1e-6)\n\n        # Select top items to consider\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * (1 - balance_factor) + value2_lst[included_items] * balance_factor) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood perturbation with objective-specific intensity\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(4 * (1 - diversity) * random.uniform(0.7, 1.3)))\n\n        for _ in range(exploration_intensity):\n            # Select random item for perturbation\n            flip_idx = random.randint(0, len(new_solution) - 1)\n\n            if new_solution[flip_idx] == 1:\n                # Try to remove item if feasible\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                # Try to add item if feasible\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Objective-specific fine-tuning with adaptive weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.7 + current_val2 * 0.3 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.6:\n            # Focus on value2 improvement with adaptive scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.9 + 1e-6)\n        else:\n            # Focus on value1 improvement with adaptive scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.7 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with adaptive scoring\n            worst_scores = (value1_lst[included_items] * 0.5 + value2_lst[included_items] * 0.5) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.67810615971546,
            -18.970841288445786
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective prioritization, diversity-aware perturbation, and weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Novel objective-aware prioritization with weighted scoring\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with different weights\n        weighted_scores = (value1_lst * 0.6 + value2_lst * 0.4) / (weight_lst * 0.9 + 1e-6)\n\n        # Select top items to consider\n        k = min(2, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * 0.2 + value2_lst[included_items] * 0.8) / (weight_lst[included_items] * 0.8 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.4\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.6\n        diversity = (obj1_diversity * 0.7 + obj2_diversity * 0.3)\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(5 * (1 - diversity) * random.uniform(0.5, 1.5)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with different weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with novel weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.5 + current_val2 * 0.5 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.6:\n            # Focus on value2 improvement with novel scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.7 + 1e-6)\n        else:\n            # Focus on value1 improvement with novel scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.3 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with novel scoring\n            worst_scores = (value1_lst[included_items] * 0.6 + value2_lst[included_items] * 0.4) / (weight_lst[included_items] * 0.4 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.482930838450095,
            -19.10885762177437
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for multi-objective improvement, then applies a novel local search strategy that combines objective-balanced item selection, adaptive objective prioritization, and diversity-aware perturbation to generate a high-quality neighbor solution while ensuring feasibility, using a creative approach that dynamically balances exploitation of high-value items with exploration of underrepresented objective regions.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (prioritize those with lower crowding distance if available)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Objective-balanced item selection (select items based on balanced objective contributions)\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective balance scores for excluded items\n        balance_scores = (value1_lst[excluded_items] / (np.sum(value1_lst[included_items]) + 1e-6) +\n                         value2_lst[excluded_items] / (np.sum(value2_lst[included_items]) + 1e-6)) / weight_lst[excluded_items]\n\n        # Select top k items to consider for selection\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(balance_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            select_idx = np.random.choice(top_indices)\n\n            # Find the least balanced item to replace based on current objective ratios\n            current_val1 = np.sum(value1_lst[included_items])\n            current_val2 = np.sum(value2_lst[included_items])\n            balance_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n            balance_scores_included = (value1_lst[included_items] * balance_ratio +\n                                      value2_lst[included_items] * (1 - balance_ratio)) / weight_lst[included_items]\n            replace_idx = np.argmin(balance_scores_included)\n            replace_idx = included_items[replace_idx]\n\n            # Perform selection if feasible\n            if current_weight - weight_lst[replace_idx] + weight_lst[select_idx] <= capacity:\n                new_solution[replace_idx] = 0\n                new_solution[select_idx] = 1\n\n    # Step 2: Adaptive objective prioritization (prioritize objectives based on solution state)\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective priorities based on current solution state\n        current_val1 = np.sum(value1_lst[included_items])\n        current_val2 = np.sum(value2_lst[included_items])\n        priority_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Calculate prioritization scores for excluded items\n        priority_scores = (value1_lst[excluded_items] * priority_ratio +\n                          value2_lst[excluded_items] * (1 - priority_ratio)) / weight_lst[excluded_items]\n\n        # Select top k items to consider for prioritization\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(priority_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            prioritize_idx = np.random.choice(top_indices)\n\n            # Find the worst item to replace based on current objective priorities\n            worst_scores = (value1_lst[included_items] * priority_ratio +\n                           value2_lst[included_items] * (1 - priority_ratio)) / weight_lst[included_items]\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform prioritization if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[prioritize_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[prioritize_idx] = 1\n\n    # Step 3: Diversity-aware perturbation (perturb solution based on objective diversity)\n    if len(included_items) > 0:\n        # Calculate objective diversity scores\n        obj1_diversity = len(np.unique(value1_lst[included_items])) / len(value1_lst)\n        obj2_diversity = len(np.unique(value2_lst[included_items])) / len(value2_lst)\n        diversity_score = min(obj1_diversity, obj2_diversity)\n\n        # Determine number of perturbations based on diversity (less diverse solutions get more changes)\n        num_perturb = max(1, int(4 * (1 - diversity_score)))\n\n        for _ in range(num_perturb):\n            # Select a random item to perturb\n            perturb_idx = random.randint(0, len(new_solution) - 1)\n\n            if new_solution[perturb_idx] == 1:\n                # Try to remove item if feasible\n                if current_weight - weight_lst[perturb_idx] <= capacity:\n                    new_solution[perturb_idx] = 0\n            else:\n                # Try to add item if feasible\n                if current_weight + weight_lst[perturb_idx] <= capacity:\n                    new_solution[perturb_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.230717983159106,
            -18.584336971242337
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for objective-specific improvement, then applies a hybrid local search strategy that combines probabilistic item prioritization, objective-aware replacement, and adaptive neighborhood diversification to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for objective-specific improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item prioritization (select items based on objective-specific priorities)\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific priorities for included items\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        priority_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Calculate prioritization scores for excluded items\n        priority_scores = (value1_lst[excluded_items] * priority_ratio + value2_lst[excluded_items] * (1 - priority_ratio)) / (weight_lst[excluded_items] + 1e-6)\n\n        # Select top k items to consider for prioritization\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(priority_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            prioritize_idx = np.random.choice(top_indices)\n\n            # Find the worst item to replace based on current objective priorities\n            worst_scores = (value1_lst[included_items] * priority_ratio + value2_lst[included_items] * (1 - priority_ratio)) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform prioritization if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[prioritize_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[prioritize_idx] = 1\n\n    # Step 2: Objective-aware replacement (replace items based on their potential to improve both objectives)\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate potential improvement scores for excluded items\n        improvement_scores = (value1_lst[excluded_items] + value2_lst[excluded_items]) / (weight_lst[excluded_items] + 1e-6)\n\n        # Select top k items to consider for improvement\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(improvement_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            improve_idx = np.random.choice(top_indices)\n\n            # Find the least valuable item to replace based on combined objective values\n            least_val_idx = np.argmin((value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6))\n            least_val_idx = included_items[least_val_idx]\n\n            # Perform improvement if feasible\n            if current_weight - weight_lst[least_val_idx] + weight_lst[improve_idx] <= capacity:\n                new_solution[least_val_idx] = 0\n                new_solution[improve_idx] = 1\n\n    # Step 3: Adaptive neighborhood diversification (flip bits based on solution diversity)\n    if len(included_items) > 0:\n        # Calculate solution diversity as the ratio of unique objective contributions\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine number of bits to flip based on diversity (less diverse solutions get more changes)\n        num_flips = max(1, int(4 * (1 - diversity)))\n\n        for _ in range(num_flips):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.291897096912464,
            -18.514303412175323
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective weighting and dynamic neighborhood exploration with item prioritization, using a combination of objective-aware scoring and diversity-sensitive perturbations to generate high-quality neighbors while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Adaptive objective weighting with novel scoring\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate dynamic weights based on current solution balance\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        obj1_weight = 0.5 + 0.3 * (current_val2 / (current_val1 + 1e-6))\n        obj2_weight = 0.5 + 0.3 * (current_val1 / (current_val2 + 1e-6))\n\n        # Novel scoring with dynamic weights\n        weighted_scores = (value1_lst * obj1_weight + value2_lst * obj2_weight) / (weight_lst * 0.6 + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * (1 - obj1_weight) + value2_lst[included_items] * (1 - obj2_weight)) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Dynamic neighborhood exploration with novel intensity\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(4 * (1 - diversity) * random.uniform(0.7, 1.3)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with dynamic weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with dynamic weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * obj1_weight + current_val2 * obj2_weight + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with novel scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n        else:\n            # Focus on value1 improvement with novel scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with novel scoring\n            worst_scores = (value1_lst[included_items] * obj1_weight + value2_lst[included_items] * obj2_weight) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.57056296382639,
            -19.073851764791637
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective prioritization and diversity-aware perturbation with weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement using novel selection criteria\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 1: Novel objective-aware prioritization with adaptive weights\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        weight_factor = 0.5 + 0.5 * (current_val1 / (current_val1 + current_val2 + 1e-6))\n\n        weighted_scores = (value1_lst * weight_factor + value2_lst * (1 - weight_factor)) / (weight_lst * 0.8 + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * (1 - weight_factor) + value2_lst[included_items] * weight_factor) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(4 * (1 - diversity) * random.uniform(0.7, 1.3)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with adaptive weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.7 + current_val2 * 0.3 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with adaptive scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.7 + 1e-6)\n        else:\n            # Focus on value1 improvement with adaptive scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with adaptive scoring\n            worst_scores = (value1_lst[included_items] * 0.5 + value2_lst[included_items] * 0.5) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.616111999506014,
            -19.002072254111845
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution with high potential for improvement by combining probabilistic item selection with objective-aware swaps, adaptive neighborhood exploration, and a novel score function that balances both objectives using a weighted sum approach to generate high-quality neighbor solutions while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic objective-aware selection with weighted score function\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate weighted combined objective scores\n        alpha = 0.7  # Weight for value1\n        beta = 0.3   # Weight for value2\n        combined_scores = (alpha * value1_lst + beta * value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(combined_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace based on weighted score\n            worst_scores = (alpha * value1_lst[included_items] + beta * value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with dynamic intensity\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(4 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Objective-specific fine-tuning with weighted replacement\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Adjust weights based on current balance\n        alpha = 0.6 if ratio > 0.5 else 0.4\n        beta = 1 - alpha\n\n        # Select items based on weighted improvement potential\n        improvement_scores = (alpha * value1_lst[excluded_items] + beta * value2_lst[excluded_items]) / (weight_lst[excluded_items] + 1e-6)\n\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace based on weighted score\n            worst_scores = (alpha * value1_lst[included_items] + beta * value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.486116593229788,
            -18.18120770566933
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for balanced objective improvement, then applies a hybrid local search strategy that combines probabilistic item prioritization, objective-aware replacement, and adaptive neighborhood diversification, while incorporating a novel item clustering technique to identify and exploit groups of items that contribute synergistically to both objectives.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for balanced improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Item clustering and prioritization\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate clustering scores for items (combining value and weight)\n        cluster_scores = (value1_lst * value2_lst) / (weight_lst + 1e-6)\n\n        # Find the most promising cluster to prioritize\n        cluster_indices = np.argsort(-cluster_scores[excluded_items])\n        cluster_size = min(5, len(cluster_indices))\n        cluster_indices = excluded_items[cluster_indices[:cluster_size]]\n\n        if len(cluster_indices) > 0:\n            prioritize_idx = np.random.choice(cluster_indices)\n\n            # Find the worst item in the current solution\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = included_items[np.argmin(worst_scores)]\n\n            # Perform prioritization if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[prioritize_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[prioritize_idx] = 1\n\n    # Step 2: Balanced objective replacement\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate replacement potential considering both objectives\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        balance_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        replacement_scores = (value1_lst[excluded_items] * (1 - balance_ratio) + value2_lst[excluded_items] * balance_ratio) / weight_lst[excluded_items]\n        replace_idx = np.random.choice(excluded_items, p=replacement_scores / np.sum(replacement_scores))\n\n        # Find the least balanced item to replace\n        balance_scores = (value1_lst[included_items] * (1 - balance_ratio) + value2_lst[included_items] * balance_ratio) / weight_lst[included_items]\n        least_balanced_idx = included_items[np.argmin(balance_scores)]\n\n        # Perform replacement if feasible\n        if current_weight - weight_lst[least_balanced_idx] + weight_lst[replace_idx] <= capacity:\n            new_solution[least_balanced_idx] = 0\n            new_solution[replace_idx] = 1\n\n    # Step 3: Adaptive neighborhood diversification with clustering awareness\n    if len(included_items) > 0:\n        # Calculate solution diversity using clustering information\n        cluster_diversity = len(np.unique(np.floor(value1_lst[included_items] / np.mean(value1_lst)))) * \\\n                           len(np.unique(np.floor(value2_lst[included_items] / np.mean(value2_lst))))\n\n        # Determine number of bits to flip based on cluster diversity\n        num_flips = max(1, int(3 * (1 - min(1, cluster_diversity / (len(included_items) + 1e-6)))))\n\n        for _ in range(num_flips):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.960380061248387,
            -18.694170138243813
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution with high potential for improvement in both objectives by combining probabilistic item selection with objective-aware swaps and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic objective-aware selection\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate combined objective scores\n        combined_scores = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(combined_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Objective-specific fine-tuning\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Select items based on objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        else:\n            # Focus on value1 improvement\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] * ratio + value2_lst[included_items] * (1 - ratio)) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.125194556064613,
            -18.64008991764989
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective prioritization and diversity-aware perturbation with weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Novel objective-aware prioritization with weighted scoring\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with different weights\n        weighted_scores = (value1_lst * 0.4 + value2_lst * 0.6) / (weight_lst * 0.7 + 1e-6)\n\n        # Select top items to consider\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * 0.3 + value2_lst[included_items] * 0.7) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(3 * (1 - diversity) * random.uniform(0.8, 1.2)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with different weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with novel weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.6 + current_val2 * 0.4 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with novel scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.6 + 1e-6)\n        else:\n            # Focus on value1 improvement with novel scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.4 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with novel scoring\n            worst_scores = (value1_lst[included_items] * 0.4 + value2_lst[included_items] * 0.6) / (weight_lst[included_items] * 0.5 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.10582703107761,
            -19.389330320689613
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective prioritization and diversity-aware perturbation with weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement using novel selection criteria\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 1: Novel objective-aware prioritization with adaptive weights\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        weight_factor = 0.5 + 0.5 * (current_val1 / (current_val1 + current_val2 + 1e-6))\n\n        weighted_scores = (value1_lst * weight_factor + value2_lst * (1 - weight_factor)) / (weight_lst * 0.9 + 1e-6)\n\n        # Select top items to consider\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * (1 - weight_factor) + value2_lst[included_items] * weight_factor) / (weight_lst[included_items] * 0.8 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(5 * (1 - diversity) * random.uniform(0.6, 1.4)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with adaptive weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.8 + current_val2 * 0.2 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with adaptive scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.8 + 1e-6)\n        else:\n            # Focus on value1 improvement with adaptive scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.6 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with adaptive scoring\n            worst_scores = (value1_lst[included_items] * 0.6 + value2_lst[included_items] * 0.4) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.654494884729814,
            -18.99401824580087
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of objective-aware item prioritization and adaptive diversity-driven perturbations, using a combination of value-to-weight ratio analysis and solution structure-aware mutations to generate high-quality neighbors while maintaining feasibility and exploring the solution space more effectively than standard approaches.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Objective-aware value-to-weight ratio analysis\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate normalized value-to-weight ratios for both objectives\n        ratio1 = value1_lst / (weight_lst + 1e-6)\n        ratio2 = value2_lst / (weight_lst + 1e-6)\n\n        # Calculate solution's current balance\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        balance = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Select items based on complementary ratios\n        if balance > 0.5:\n            # Focus on improving value2 when value1 is dominant\n            candidate_scores = ratio2[excluded_items] * (1 - balance)\n        else:\n            # Focus on improving value1 when value2 is dominant\n            candidate_scores = ratio1[excluded_items] * balance\n\n        if len(candidate_scores) > 0:\n            best_candidate = np.argmax(candidate_scores)\n            best_candidate = excluded_items[best_candidate]\n\n            # Find worst item to replace based on both objectives\n            worst_scores = (value1_lst[included_items] * (1 - balance) + value2_lst[included_items] * balance) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_candidate] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_candidate] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[best_candidate]\n\n    # Step 2: Solution structure-aware mutations\n    if len(included_items) > 0:\n        # Calculate solution structure metrics\n        item_density = len(included_items) / len(new_solution)\n        weight_balance = current_weight / capacity\n\n        # Determine mutation intensity based on structure\n        mutation_intensity = max(1, int(3 * (1 - weight_balance) * (1 - item_density)))\n\n        for _ in range(mutation_intensity):\n            # Select mutation type based on structure\n            if random.random() < 0.6:\n                # Focus on removing items when solution is dense\n                if len(included_items) > 0:\n                    remove_idx = random.choice(included_items)\n                    if current_weight - weight_lst[remove_idx] <= capacity:\n                        new_solution[remove_idx] = 0\n                        current_weight -= weight_lst[remove_idx]\n            else:\n                # Focus on adding items when solution is sparse\n                if len(excluded_items) > 0:\n                    add_idx = random.choice(excluded_items)\n                    if current_weight + weight_lst[add_idx] <= capacity:\n                        new_solution[add_idx] = 1\n                        current_weight += weight_lst[add_idx]\n\n    # Step 3: Adaptive objective-specific fine-tuning\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific improvement potential\n        potential1 = np.sum(value1_lst[excluded_items] * (weight_lst[excluded_items] <= (capacity - current_weight)))\n        potential2 = np.sum(value2_lst[excluded_items] * (weight_lst[excluded_items] <= (capacity - current_weight)))\n\n        if potential1 > potential2:\n            # Focus on value1 improvement when potential is higher\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        else:\n            # Focus on value2 improvement when potential is higher\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace based on both objectives\n            worst_scores = (value1_lst[included_items] * (1 - balance) + value2_lst[included_items] * balance) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.938336064678523,
            -18.76920129490102
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective weighting and diversity-aware perturbation with novel item prioritization, using a combination of objective-aware scoring and dynamic neighborhood exploration to generate high-quality neighbors while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement using novel selection criteria\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 1: Novel adaptive objective weighting with dynamic item prioritization\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate dynamic weights based on current solution balance with novel formula\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        obj1_weight = 0.4 + 0.4 * (current_val2 / (current_val1 + current_val2 + 1e-6))\n        obj2_weight = 0.4 + 0.4 * (current_val1 / (current_val2 + current_val1 + 1e-6))\n\n        # Novel scoring with dynamic weights and adaptive normalization\n        weighted_scores = (value1_lst * obj1_weight + value2_lst * obj2_weight) / (weight_lst * 0.7 + 1e-6)\n\n        # Select top items to consider with novel selection strategy\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring with adaptive weights\n            worst_scores = (value1_lst[included_items] * (1 - obj1_weight) + value2_lst[included_items] * (1 - obj2_weight)) / (weight_lst[included_items] * 0.8 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Dynamic neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric with adaptive components\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity * 0.6 + obj2_diversity * 0.4) / 1.0\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(3 * (1 - diversity) * random.uniform(0.6, 1.4)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with adaptive weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with novel adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * obj1_weight + current_val2 * obj2_weight + 1e-6)\n\n        # Select items based on novel objective balance with adaptive scoring\n        if ratio > 0.6:\n            # Focus on value2 improvement with novel scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.6 + 1e-6)\n        else:\n            # Focus on value1 improvement with novel scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.6 + 1e-6)\n\n        # Select top item for potential addition with novel selection\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with novel scoring\n            worst_scores = (value1_lst[included_items] * obj1_weight + value2_lst[included_items] * obj2_weight) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.919313879451554,
            -18.827341896815334
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective prioritization, diversity-aware perturbation, and weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Novel objective-aware prioritization with weighted scoring\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with different weights\n        weighted_scores = (value1_lst * 0.5 + value2_lst * 0.5) / (weight_lst * 0.8 + 1e-6)\n\n        # Select top items to consider\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * 0.4 + value2_lst[included_items] * 0.6) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(4 * (1 - diversity) * random.uniform(0.7, 1.3)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with different weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with novel weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.7 + current_val2 * 0.3 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with novel scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n        else:\n            # Focus on value1 improvement with novel scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with novel scoring\n            worst_scores = (value1_lst[included_items] * 0.5 + value2_lst[included_items] * 0.5) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.578859684343357,
            -19.058418823423825
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective prioritization and diversity-aware perturbation with weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Novel objective-aware prioritization with weighted scoring\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with different weights\n        weighted_scores = (value1_lst * 0.4 + value2_lst * 0.6) / (weight_lst * 0.7 + 1e-6)\n\n        # Select top items to consider\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * 0.3 + value2_lst[included_items] * 0.7) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(3 * (1 - diversity) * random.uniform(0.8, 1.2)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with different weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with novel weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.6 + current_val2 * 0.4 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with novel scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.6 + 1e-6)\n        else:\n            # Focus on value1 improvement with novel scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.4 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with novel scoring\n            worst_scores = (value1_lst[included_items] * 0.4 + value2_lst[included_items] * 0.6) / (weight_lst[included_items] * 0.5 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.10582703107761,
            -19.389330320689613
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective prioritization and diversity-aware perturbation with weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement using novel selection criteria\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 1: Novel objective-aware prioritization with adaptive weights\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        weight_factor = 0.5 + 0.5 * (current_val1 / (current_val1 + current_val2 + 1e-6))\n\n        weighted_scores = (value1_lst * weight_factor + value2_lst * (1 - weight_factor)) / (weight_lst * 0.8 + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * (1 - weight_factor) + value2_lst[included_items] * weight_factor) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(4 * (1 - diversity) * random.uniform(0.7, 1.3)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with adaptive weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.7 + current_val2 * 0.3 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with adaptive scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.7 + 1e-6)\n        else:\n            # Focus on value1 improvement with adaptive scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with adaptive scoring\n            worst_scores = (value1_lst[included_items] * 0.5 + value2_lst[included_items] * 0.5) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.616111999506014,
            -19.002072254111845
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution with high potential for improvement by combining probabilistic item selection with objective-aware swaps, adaptive neighborhood exploration, and a novel score function that balances both objectives using a weighted sum approach to generate high-quality neighbor solutions while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic objective-aware selection with weighted score function\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate weighted combined objective scores\n        alpha = 0.7  # Weight for value1\n        beta = 0.3   # Weight for value2\n        combined_scores = (alpha * value1_lst + beta * value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(combined_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace based on weighted score\n            worst_scores = (alpha * value1_lst[included_items] + beta * value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with dynamic intensity\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(4 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Objective-specific fine-tuning with weighted replacement\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Adjust weights based on current balance\n        alpha = 0.6 if ratio > 0.5 else 0.4\n        beta = 1 - alpha\n\n        # Select items based on weighted improvement potential\n        improvement_scores = (alpha * value1_lst[excluded_items] + beta * value2_lst[excluded_items]) / (weight_lst[excluded_items] + 1e-6)\n\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace based on weighted score\n            worst_scores = (alpha * value1_lst[included_items] + beta * value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.486116593229788,
            -18.18120770566933
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for balanced objective improvement, then applies a hybrid local search strategy that combines probabilistic item prioritization, objective-aware replacement, and adaptive neighborhood diversification, while incorporating a novel item clustering technique to identify and exploit groups of items that contribute synergistically to both objectives.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for balanced improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Item clustering and prioritization\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate clustering scores for items (combining value and weight)\n        cluster_scores = (value1_lst * value2_lst) / (weight_lst + 1e-6)\n\n        # Find the most promising cluster to prioritize\n        cluster_indices = np.argsort(-cluster_scores[excluded_items])\n        cluster_size = min(5, len(cluster_indices))\n        cluster_indices = excluded_items[cluster_indices[:cluster_size]]\n\n        if len(cluster_indices) > 0:\n            prioritize_idx = np.random.choice(cluster_indices)\n\n            # Find the worst item in the current solution\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = included_items[np.argmin(worst_scores)]\n\n            # Perform prioritization if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[prioritize_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[prioritize_idx] = 1\n\n    # Step 2: Balanced objective replacement\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate replacement potential considering both objectives\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        balance_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        replacement_scores = (value1_lst[excluded_items] * (1 - balance_ratio) + value2_lst[excluded_items] * balance_ratio) / weight_lst[excluded_items]\n        replace_idx = np.random.choice(excluded_items, p=replacement_scores / np.sum(replacement_scores))\n\n        # Find the least balanced item to replace\n        balance_scores = (value1_lst[included_items] * (1 - balance_ratio) + value2_lst[included_items] * balance_ratio) / weight_lst[included_items]\n        least_balanced_idx = included_items[np.argmin(balance_scores)]\n\n        # Perform replacement if feasible\n        if current_weight - weight_lst[least_balanced_idx] + weight_lst[replace_idx] <= capacity:\n            new_solution[least_balanced_idx] = 0\n            new_solution[replace_idx] = 1\n\n    # Step 3: Adaptive neighborhood diversification with clustering awareness\n    if len(included_items) > 0:\n        # Calculate solution diversity using clustering information\n        cluster_diversity = len(np.unique(np.floor(value1_lst[included_items] / np.mean(value1_lst)))) * \\\n                           len(np.unique(np.floor(value2_lst[included_items] / np.mean(value2_lst))))\n\n        # Determine number of bits to flip based on cluster diversity\n        num_flips = max(1, int(3 * (1 - min(1, cluster_diversity / (len(included_items) + 1e-6)))))\n\n        for _ in range(num_flips):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.960380061248387,
            -18.694170138243813
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution with high potential for improvement in both objectives by combining probabilistic item selection with objective-aware swaps and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic objective-aware selection\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate combined objective scores\n        combined_scores = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(combined_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Objective-specific fine-tuning\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Select items based on objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        else:\n            # Focus on value1 improvement\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] * ratio + value2_lst[included_items] * (1 - ratio)) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.125194556064613,
            -18.64008991764989
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for objective-specific improvement, then applies a hybrid local search strategy that combines probabilistic item prioritization, objective-aware replacement, and adaptive neighborhood diversification to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for objective-specific improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item prioritization (select items based on objective-specific priorities)\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific priorities for included items\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        priority_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Calculate prioritization scores for excluded items\n        priority_scores = (value1_lst[excluded_items] * priority_ratio + value2_lst[excluded_items] * (1 - priority_ratio)) / (weight_lst[excluded_items] + 1e-6)\n\n        # Select top k items to consider for prioritization\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(priority_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            prioritize_idx = np.random.choice(top_indices)\n\n            # Find the worst item to replace based on current objective priorities\n            worst_scores = (value1_lst[included_items] * priority_ratio + value2_lst[included_items] * (1 - priority_ratio)) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform prioritization if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[prioritize_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[prioritize_idx] = 1\n\n    # Step 2: Objective-aware replacement (replace items based on their potential to improve both objectives)\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate potential improvement scores for excluded items\n        improvement_scores = (value1_lst[excluded_items] + value2_lst[excluded_items]) / (weight_lst[excluded_items] + 1e-6)\n\n        # Select top k items to consider for improvement\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(improvement_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            improve_idx = np.random.choice(top_indices)\n\n            # Find the least valuable item to replace based on combined objective values\n            least_val_idx = np.argmin((value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6))\n            least_val_idx = included_items[least_val_idx]\n\n            # Perform improvement if feasible\n            if current_weight - weight_lst[least_val_idx] + weight_lst[improve_idx] <= capacity:\n                new_solution[least_val_idx] = 0\n                new_solution[improve_idx] = 1\n\n    # Step 3: Adaptive neighborhood diversification (flip bits based on solution diversity)\n    if len(included_items) > 0:\n        # Calculate solution diversity as the ratio of unique objective contributions\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine number of bits to flip based on diversity (less diverse solutions get more changes)\n        num_flips = max(1, int(4 * (1 - diversity)))\n\n        for _ in range(num_flips):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.291897096912464,
            -18.514303412175323
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for balanced objective improvement, then applies a hybrid local search strategy that combines probabilistic item prioritization, objective-aware replacement, and adaptive neighborhood diversification, while incorporating a novel item clustering technique to identify and exploit groups of items that contribute synergistically to both objectives.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for balanced improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Item clustering and prioritization\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate clustering scores for items (combining value and weight)\n        cluster_scores = (value1_lst * value2_lst) / (weight_lst + 1e-6)\n\n        # Find the most promising cluster to prioritize\n        cluster_indices = np.argsort(-cluster_scores[excluded_items])\n        cluster_size = min(5, len(cluster_indices))\n        cluster_indices = excluded_items[cluster_indices[:cluster_size]]\n\n        if len(cluster_indices) > 0:\n            prioritize_idx = np.random.choice(cluster_indices)\n\n            # Find the worst item in the current solution\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = included_items[np.argmin(worst_scores)]\n\n            # Perform prioritization if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[prioritize_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[prioritize_idx] = 1\n\n    # Step 2: Balanced objective replacement\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate replacement potential considering both objectives\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        balance_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        replacement_scores = (value1_lst[excluded_items] * (1 - balance_ratio) + value2_lst[excluded_items] * balance_ratio) / weight_lst[excluded_items]\n        replace_idx = np.random.choice(excluded_items, p=replacement_scores / np.sum(replacement_scores))\n\n        # Find the least balanced item to replace\n        balance_scores = (value1_lst[included_items] * (1 - balance_ratio) + value2_lst[included_items] * balance_ratio) / weight_lst[included_items]\n        least_balanced_idx = included_items[np.argmin(balance_scores)]\n\n        # Perform replacement if feasible\n        if current_weight - weight_lst[least_balanced_idx] + weight_lst[replace_idx] <= capacity:\n            new_solution[least_balanced_idx] = 0\n            new_solution[replace_idx] = 1\n\n    # Step 3: Adaptive neighborhood diversification with clustering awareness\n    if len(included_items) > 0:\n        # Calculate solution diversity using clustering information\n        cluster_diversity = len(np.unique(np.floor(value1_lst[included_items] / np.mean(value1_lst)))) * \\\n                           len(np.unique(np.floor(value2_lst[included_items] / np.mean(value2_lst))))\n\n        # Determine number of bits to flip based on cluster diversity\n        num_flips = max(1, int(3 * (1 - min(1, cluster_diversity / (len(included_items) + 1e-6)))))\n\n        for _ in range(num_flips):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.727138938127982,
            -18.88662831950669
        ]
    },
    {
        "algorithm": "{This algorithm enhances solution quality by combining objective-aware item selection with adaptive neighborhood exploration through a novel hybrid of probabilistic item swaps and diversity-aware perturbation, while maintaining feasibility through constrained item swaps and probabilistic flips.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 1: Novel probabilistic item swap with objective-aware scoring\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel combined scores with probabilistic weights\n        prob_weight = random.uniform(0.3, 0.7)\n        combined_scores = (value1_lst * prob_weight + value2_lst * (1 - prob_weight)) / (weight_lst + 1e-6)\n\n        # Select top items to consider with probabilistic selection\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(combined_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel probabilistic scoring\n            worst_scores = (value1_lst[included_items] * (1 - prob_weight) + value2_lst[included_items] * prob_weight) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible with probabilistic acceptance\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity and random.random() < 0.7:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with probabilistic flips\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel probabilistic metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with probabilistic calculation\n        exploration_intensity = max(1, int(3 * (1 - diversity) * random.uniform(0.5, 1.5)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1 and random.random() < 0.6:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            elif new_solution[flip_idx] == 0 and random.random() < 0.4:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with probabilistic selection\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with probabilistic weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * random.uniform(0.4, 0.6) + current_val2 * random.uniform(0.4, 0.6) + 1e-6)\n\n        # Select items based on novel probabilistic objective balance\n        if ratio > 0.5 and random.random() < 0.7:\n            # Focus on value2 improvement with probabilistic scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * random.uniform(0.3, 0.5) + 1e-6)\n        else:\n            # Focus on value1 improvement with probabilistic scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * random.uniform(0.5, 0.7) + 1e-6)\n\n        # Select top item for potential addition with probabilistic selection\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with probabilistic scoring\n            worst_scores = (value1_lst[included_items] * random.uniform(0.3, 0.5) + value2_lst[included_items] * random.uniform(0.3, 0.5)) / (weight_lst[included_items] * random.uniform(0.6, 0.8) + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible with probabilistic acceptance\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity and random.random() < 0.6:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.148227688562613,
            -18.6083809069652
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution with high potential for improvement by combining probabilistic item selection with objective-aware swaps, adaptive neighborhood exploration, and a novel score function that balances both objectives using a weighted sum approach to generate high-quality neighbor solutions while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic objective-aware selection with weighted score function\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate weighted combined objective scores\n        alpha = 0.6  # Weight for value1\n        beta = 0.4   # Weight for value2\n        combined_scores = (alpha * value1_lst + beta * value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(combined_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace based on weighted score\n            worst_scores = (alpha * value1_lst[included_items] + beta * value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with dynamic intensity\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Objective-specific fine-tuning with weighted replacement\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Adjust weights based on current balance\n        alpha = 0.5 if ratio > 0.5 else 0.5\n        beta = 1 - alpha\n\n        # Select items based on weighted improvement potential\n        improvement_scores = (alpha * value1_lst[excluded_items] + beta * value2_lst[excluded_items]) / (weight_lst[excluded_items] + 1e-6)\n\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace based on weighted score\n            worst_scores = (alpha * value1_lst[included_items] + beta * value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.369828028221022,
            -18.35630483800511
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective weighting and dynamic neighborhood exploration with item prioritization, using a combination of objective-aware scoring and diversity-sensitive perturbations to generate high-quality neighbors while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Adaptive objective weighting with novel scoring\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate dynamic weights based on current solution balance\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        obj1_weight = 0.5 + 0.3 * (current_val2 / (current_val1 + 1e-6))\n        obj2_weight = 0.5 + 0.3 * (current_val1 / (current_val2 + 1e-6))\n\n        # Novel scoring with dynamic weights\n        weighted_scores = (value1_lst * obj1_weight + value2_lst * obj2_weight) / (weight_lst * 0.6 + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * (1 - obj1_weight) + value2_lst[included_items] * (1 - obj2_weight)) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Dynamic neighborhood exploration with novel intensity\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(4 * (1 - diversity) * random.uniform(0.7, 1.3)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with dynamic weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with dynamic weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * obj1_weight + current_val2 * obj2_weight + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with novel scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n        else:\n            # Focus on value1 improvement with novel scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with novel scoring\n            worst_scores = (value1_lst[included_items] * obj1_weight + value2_lst[included_items] * obj2_weight) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.57056296382639,
            -19.073851764791637
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution with high potential for improvement by combining probabilistic item selection with objective-aware swaps, adaptive neighborhood exploration, and a novel score function that balances both objectives using a weighted sum approach to generate high-quality neighbor solutions while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic objective-aware selection with weighted score function\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate weighted combined objective scores\n        alpha = 0.7  # Weight for value1\n        beta = 0.3   # Weight for value2\n        combined_scores = (alpha * value1_lst + beta * value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(combined_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace based on weighted score\n            worst_scores = (alpha * value1_lst[included_items] + beta * value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with dynamic intensity\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(4 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Objective-specific fine-tuning with weighted replacement\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Adjust weights based on current balance\n        alpha = 0.6 if ratio > 0.5 else 0.4\n        beta = 1 - alpha\n\n        # Select items based on weighted improvement potential\n        improvement_scores = (alpha * value1_lst[excluded_items] + beta * value2_lst[excluded_items]) / (weight_lst[excluded_items] + 1e-6)\n\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace based on weighted score\n            worst_scores = (alpha * value1_lst[included_items] + beta * value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.486116593229788,
            -18.18120770566933
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for balanced objective improvement, then applies a hybrid local search strategy that combines probabilistic item prioritization, objective-aware replacement, and adaptive neighborhood diversification, while incorporating a novel item clustering technique to identify and exploit groups of items that contribute synergistically to both objectives.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for balanced improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Item clustering and prioritization\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate clustering scores for items (combining value and weight)\n        cluster_scores = (value1_lst * value2_lst) / (weight_lst + 1e-6)\n\n        # Find the most promising cluster to prioritize\n        cluster_indices = np.argsort(-cluster_scores[excluded_items])\n        cluster_size = min(5, len(cluster_indices))\n        cluster_indices = excluded_items[cluster_indices[:cluster_size]]\n\n        if len(cluster_indices) > 0:\n            prioritize_idx = np.random.choice(cluster_indices)\n\n            # Find the worst item in the current solution\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = included_items[np.argmin(worst_scores)]\n\n            # Perform prioritization if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[prioritize_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[prioritize_idx] = 1\n\n    # Step 2: Balanced objective replacement\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate replacement potential considering both objectives\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        balance_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        replacement_scores = (value1_lst[excluded_items] * (1 - balance_ratio) + value2_lst[excluded_items] * balance_ratio) / weight_lst[excluded_items]\n        replace_idx = np.random.choice(excluded_items, p=replacement_scores / np.sum(replacement_scores))\n\n        # Find the least balanced item to replace\n        balance_scores = (value1_lst[included_items] * (1 - balance_ratio) + value2_lst[included_items] * balance_ratio) / weight_lst[included_items]\n        least_balanced_idx = included_items[np.argmin(balance_scores)]\n\n        # Perform replacement if feasible\n        if current_weight - weight_lst[least_balanced_idx] + weight_lst[replace_idx] <= capacity:\n            new_solution[least_balanced_idx] = 0\n            new_solution[replace_idx] = 1\n\n    # Step 3: Adaptive neighborhood diversification with clustering awareness\n    if len(included_items) > 0:\n        # Calculate solution diversity using clustering information\n        cluster_diversity = len(np.unique(np.floor(value1_lst[included_items] / np.mean(value1_lst)))) * \\\n                           len(np.unique(np.floor(value2_lst[included_items] / np.mean(value2_lst))))\n\n        # Determine number of bits to flip based on cluster diversity\n        num_flips = max(1, int(3 * (1 - min(1, cluster_diversity / (len(included_items) + 1e-6)))))\n\n        for _ in range(num_flips):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.960380061248387,
            -18.694170138243813
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution with high potential for improvement in both objectives by combining probabilistic item selection with objective-aware swaps and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic objective-aware selection\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate combined objective scores\n        combined_scores = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(combined_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Objective-specific fine-tuning\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Select items based on objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        else:\n            # Focus on value1 improvement\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] * ratio + value2_lst[included_items] * (1 - ratio)) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.125194556064613,
            -18.64008991764989
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective prioritization and diversity-aware perturbation with weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Novel objective-aware prioritization with weighted scoring\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with different weights\n        weighted_scores = (value1_lst * 0.4 + value2_lst * 0.6) / (weight_lst * 0.7 + 1e-6)\n\n        # Select top items to consider\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * 0.3 + value2_lst[included_items] * 0.7) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(3 * (1 - diversity) * random.uniform(0.8, 1.2)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with different weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with novel weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.6 + current_val2 * 0.4 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with novel scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.6 + 1e-6)\n        else:\n            # Focus on value1 improvement with novel scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.4 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with novel scoring\n            worst_scores = (value1_lst[included_items] * 0.4 + value2_lst[included_items] * 0.6) / (weight_lst[included_items] * 0.5 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.10582703107761,
            -19.389330320689613
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for objective-specific improvement, then applies a hybrid local search strategy that combines probabilistic item prioritization, objective-aware replacement, and adaptive neighborhood diversification to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for objective-specific improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item prioritization (select items based on objective-specific priorities)\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific priorities for included items\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        priority_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Calculate prioritization scores for excluded items\n        priority_scores = (value1_lst[excluded_items] * priority_ratio + value2_lst[excluded_items] * (1 - priority_ratio)) / (weight_lst[excluded_items] + 1e-6)\n\n        # Select top k items to consider for prioritization\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(priority_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            prioritize_idx = np.random.choice(top_indices)\n\n            # Find the worst item to replace based on current objective priorities\n            worst_scores = (value1_lst[included_items] * priority_ratio + value2_lst[included_items] * (1 - priority_ratio)) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform prioritization if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[prioritize_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[prioritize_idx] = 1\n\n    # Step 2: Objective-aware replacement (replace items based on their potential to improve both objectives)\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate potential improvement scores for excluded items\n        improvement_scores = (value1_lst[excluded_items] + value2_lst[excluded_items]) / (weight_lst[excluded_items] + 1e-6)\n\n        # Select top k items to consider for improvement\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(improvement_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            improve_idx = np.random.choice(top_indices)\n\n            # Find the least valuable item to replace based on combined objective values\n            least_val_idx = np.argmin((value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6))\n            least_val_idx = included_items[least_val_idx]\n\n            # Perform improvement if feasible\n            if current_weight - weight_lst[least_val_idx] + weight_lst[improve_idx] <= capacity:\n                new_solution[least_val_idx] = 0\n                new_solution[improve_idx] = 1\n\n    # Step 3: Adaptive neighborhood diversification (flip bits based on solution diversity)\n    if len(included_items) > 0:\n        # Calculate solution diversity as the ratio of unique objective contributions\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine number of bits to flip based on diversity (less diverse solutions get more changes)\n        num_flips = max(1, int(4 * (1 - diversity)))\n\n        for _ in range(num_flips):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.291897096912464,
            -18.514303412175323
        ]
    },
    {
        "algorithm": "{This algorithm combines objective-aware item prioritization with adaptive cluster-based exploration, using a novel hybrid of value-to-weight ratios and diversity-aware neighborhood search to generate high-quality neighbor solutions while maintaining feasibility through probabilistic cluster-based flips and balanced objective replacement.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        balance_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        cluster_scores = (value1_lst[excluded_items] * (1 - balance_ratio) + value2_lst[excluded_items] * balance_ratio) / (weight_lst[excluded_items] + 1e-6)\n        cluster_indices = np.argsort(-cluster_scores)\n        cluster_size = min(3, len(cluster_indices))\n        cluster_indices = excluded_items[cluster_indices[:cluster_size]]\n\n        if len(cluster_indices) > 0:\n            selected_idx = np.random.choice(cluster_indices)\n            worst_scores = (value1_lst[included_items] * (1 - balance_ratio) + value2_lst[included_items] * balance_ratio) / (weight_lst[included_items] + 1e-6)\n            worst_idx = included_items[np.argmin(worst_scores)]\n\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    if len(included_items) > 0:\n        obj1_diversity = len(np.unique(value1_lst[included_items])) / len(included_items) if len(included_items) > 0 else 0.5\n        obj2_diversity = len(np.unique(value2_lst[included_items])) / len(included_items) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n        exploration_intensity = max(1, int(3 * (1 - diversity) * random.uniform(0.5, 1.5)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.6 + current_val2 * 0.4 + 1e-6)\n\n        if ratio > 0.5:\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n        else:\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n            worst_scores = (value1_lst[included_items] * 0.4 + value2_lst[included_items] * 0.6) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.701154576716043,
            -18.956480565918064
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective prioritization and diversity-aware perturbation with weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement using novel selection criteria\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 1: Novel objective-aware prioritization with adaptive weights\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        weight_factor = 0.5 + 0.5 * (current_val1 / (current_val1 + current_val2 + 1e-6))\n\n        weighted_scores = (value1_lst * weight_factor + value2_lst * (1 - weight_factor)) / (weight_lst * 0.8 + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * (1 - weight_factor) + value2_lst[included_items] * weight_factor) / (weight_lst[included_items] * 0.7 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(4 * (1 - diversity) * random.uniform(0.7, 1.3)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with adaptive weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with adaptive weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.7 + current_val2 * 0.3 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with adaptive scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.7 + 1e-6)\n        else:\n            # Focus on value1 improvement with adaptive scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.5 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with adaptive scoring\n            worst_scores = (value1_lst[included_items] * 0.5 + value2_lst[included_items] * 0.5) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.616111999506014,
            -19.002072254111845
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution with high potential for improvement in both objectives by combining probabilistic item selection with objective-aware swaps and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic objective-aware selection\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate combined objective scores\n        combined_scores = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(combined_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Objective-specific fine-tuning\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Select items based on objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        else:\n            # Focus on value1 improvement\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] * ratio + value2_lst[included_items] * (1 - ratio)) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.125194556064613,
            -18.64008991764989
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for objective-specific improvement, then applies a hybrid local search strategy that combines probabilistic item prioritization, objective-aware replacement, and adaptive neighborhood diversification to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for objective-specific improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item prioritization (select items based on objective-specific priorities)\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific priorities for included items\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        priority_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Calculate prioritization scores for excluded items\n        priority_scores = (value1_lst[excluded_items] * priority_ratio + value2_lst[excluded_items] * (1 - priority_ratio)) / weight_lst[excluded_items]\n\n        # Select top k items to consider for prioritization\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(priority_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            prioritize_idx = np.random.choice(top_indices)\n\n            # Find the worst item to replace based on current objective priorities\n            worst_scores = (value1_lst[included_items] * priority_ratio + value2_lst[included_items] * (1 - priority_ratio)) / weight_lst[included_items]\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform prioritization if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[prioritize_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[prioritize_idx] = 1\n\n    # Step 2: Objective-aware replacement (replace items based on their potential to improve both objectives)\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate potential improvement scores for excluded items\n        improvement_scores = (value1_lst[excluded_items] * value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Select top k items to consider for improvement\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(improvement_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            improve_idx = np.random.choice(top_indices)\n\n            # Find the least valuable item to replace based on combined objective values\n            least_val_idx = np.argmin((value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items])\n            least_val_idx = included_items[least_val_idx]\n\n            # Perform improvement if feasible\n            if current_weight - weight_lst[least_val_idx] + weight_lst[improve_idx] <= capacity:\n                new_solution[least_val_idx] = 0\n                new_solution[improve_idx] = 1\n\n    # Step 3: Adaptive neighborhood diversification (flip bits based on solution diversity)\n    if len(included_items) > 0:\n        # Calculate solution diversity as the ratio of unique objective contributions\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine number of bits to flip based on diversity (less diverse solutions get more changes)\n        num_flips = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(num_flips):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.096530030707598,
            -18.662091361335012
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for balanced objective improvement, then applies a hybrid local search strategy that combines probabilistic item prioritization, objective-aware replacement, and adaptive neighborhood diversification, while incorporating a novel item clustering technique to identify and exploit groups of items that contribute synergistically to both objectives.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for balanced improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Item clustering and prioritization\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate clustering scores for items (combining value and weight)\n        cluster_scores = (value1_lst * value2_lst) / (weight_lst + 1e-6)\n\n        # Find the most promising cluster to prioritize\n        cluster_indices = np.argsort(-cluster_scores[excluded_items])\n        cluster_size = min(5, len(cluster_indices))\n        cluster_indices = excluded_items[cluster_indices[:cluster_size]]\n\n        if len(cluster_indices) > 0:\n            prioritize_idx = np.random.choice(cluster_indices)\n\n            # Find the worst item in the current solution\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = included_items[np.argmin(worst_scores)]\n\n            # Perform prioritization if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[prioritize_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[prioritize_idx] = 1\n\n    # Step 2: Balanced objective replacement\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate replacement potential considering both objectives\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        balance_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        replacement_scores = (value1_lst[excluded_items] * (1 - balance_ratio) + value2_lst[excluded_items] * balance_ratio) / weight_lst[excluded_items]\n        replace_idx = np.random.choice(excluded_items, p=replacement_scores / np.sum(replacement_scores))\n\n        # Find the least balanced item to replace\n        balance_scores = (value1_lst[included_items] * (1 - balance_ratio) + value2_lst[included_items] * balance_ratio) / weight_lst[included_items]\n        least_balanced_idx = included_items[np.argmin(balance_scores)]\n\n        # Perform replacement if feasible\n        if current_weight - weight_lst[least_balanced_idx] + weight_lst[replace_idx] <= capacity:\n            new_solution[least_balanced_idx] = 0\n            new_solution[replace_idx] = 1\n\n    # Step 3: Adaptive neighborhood diversification with clustering awareness\n    if len(included_items) > 0:\n        # Calculate solution diversity using clustering information\n        cluster_diversity = len(np.unique(np.floor(value1_lst[included_items] / np.mean(value1_lst)))) * \\\n                           len(np.unique(np.floor(value2_lst[included_items] / np.mean(value2_lst))))\n\n        # Determine number of bits to flip based on cluster diversity\n        num_flips = max(1, int(3 * (1 - min(1, cluster_diversity / (len(included_items) + 1e-6)))))\n\n        for _ in range(num_flips):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.960380061248387,
            -18.694170138243813
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution with high potential for improvement by combining probabilistic item selection with objective-aware swaps, adaptive neighborhood exploration, and a novel score function that balances both objectives using a weighted sum approach to generate high-quality neighbor solutions while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic objective-aware selection with weighted score function\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate weighted combined objective scores\n        alpha = 0.7  # Weight for value1\n        beta = 0.3   # Weight for value2\n        combined_scores = (alpha * value1_lst + beta * value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(combined_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace based on weighted score\n            worst_scores = (alpha * value1_lst[included_items] + beta * value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with dynamic intensity\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(4 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Objective-specific fine-tuning with weighted replacement\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Adjust weights based on current balance\n        alpha = 0.6 if ratio > 0.5 else 0.4\n        beta = 1 - alpha\n\n        # Select items based on weighted improvement potential\n        improvement_scores = (alpha * value1_lst[excluded_items] + beta * value2_lst[excluded_items]) / (weight_lst[excluded_items] + 1e-6)\n\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace based on weighted score\n            worst_scores = (alpha * value1_lst[included_items] + beta * value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.486116593229788,
            -18.18120770566933
        ]
    },
    {
        "algorithm": "{This algorithm employs a novel hybrid of adaptive objective prioritization and diversity-aware perturbation with weighted item evaluation to generate high-quality neighbors by intelligently balancing exploration and exploitation of the solution space while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Novel objective-aware prioritization with weighted scoring\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate novel weighted scores with different weights\n        weighted_scores = (value1_lst * 0.4 + value2_lst * 0.6) / (weight_lst * 0.7 + 1e-6)\n\n        # Select top items to consider\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(weighted_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace using novel scoring\n            worst_scores = (value1_lst[included_items] * 0.3 + value2_lst[included_items] * 0.7) / (weight_lst[included_items] * 0.6 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration with novel intensity calculation\n    if len(included_items) > 0:\n        # Calculate solution diversity using novel metric\n        obj1_diversity = np.std(value1_lst[included_items]) / (np.mean(value1_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        obj2_diversity = np.std(value2_lst[included_items]) / (np.mean(value2_lst[included_items]) + 1e-6) if len(included_items) > 0 else 0.5\n        diversity = (obj1_diversity + obj2_diversity) / 2\n\n        # Determine exploration intensity with novel calculation\n        exploration_intensity = max(1, int(3 * (1 - diversity) * random.uniform(0.8, 1.2)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Novel objective-specific fine-tuning with different weights\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios with novel weights\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 * 0.6 + current_val2 * 0.4 + 1e-6)\n\n        # Select items based on novel objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement with novel scoring\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] * 0.6 + 1e-6)\n        else:\n            # Focus on value1 improvement with novel scoring\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] * 0.4 + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace with novel scoring\n            worst_scores = (value1_lst[included_items] * 0.4 + value2_lst[included_items] * 0.6) / (weight_lst[included_items] * 0.5 + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.10582703107761,
            -19.389330320689613
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for objective-specific improvement, then applies a hybrid local search strategy that combines probabilistic item prioritization, objective-aware replacement, and adaptive neighborhood diversification to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for objective-specific improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item prioritization (select items based on objective-specific priorities)\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific priorities for included items\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        priority_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Calculate prioritization scores for excluded items\n        priority_scores = (value1_lst[excluded_items] * priority_ratio + value2_lst[excluded_items] * (1 - priority_ratio)) / weight_lst[excluded_items]\n\n        # Select top k items to consider for prioritization\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(priority_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            prioritize_idx = np.random.choice(top_indices)\n\n            # Find the worst item to replace based on current objective priorities\n            worst_scores = (value1_lst[included_items] * priority_ratio + value2_lst[included_items] * (1 - priority_ratio)) / weight_lst[included_items]\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform prioritization if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[prioritize_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[prioritize_idx] = 1\n\n    # Step 2: Objective-aware replacement (replace items based on their potential to improve both objectives)\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate potential improvement scores for excluded items\n        improvement_scores = (value1_lst[excluded_items] * value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Select top k items to consider for improvement\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(improvement_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            improve_idx = np.random.choice(top_indices)\n\n            # Find the least valuable item to replace based on combined objective values\n            least_val_idx = np.argmin((value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items])\n            least_val_idx = included_items[least_val_idx]\n\n            # Perform improvement if feasible\n            if current_weight - weight_lst[least_val_idx] + weight_lst[improve_idx] <= capacity:\n                new_solution[least_val_idx] = 0\n                new_solution[improve_idx] = 1\n\n    # Step 3: Adaptive neighborhood diversification (flip bits based on solution diversity)\n    if len(included_items) > 0:\n        # Calculate solution diversity as the ratio of unique objective contributions\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine number of bits to flip based on diversity (less diverse solutions get more changes)\n        num_flips = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(num_flips):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.096530030707598,
            -18.662091361335012
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution with high potential for improvement in both objectives by combining probabilistic item selection with objective-aware swaps and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic objective-aware selection\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate combined objective scores\n        combined_scores = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(combined_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Objective-specific fine-tuning\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Select items based on objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        else:\n            # Focus on value1 improvement\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] * ratio + value2_lst[included_items] * (1 - ratio)) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.125194556064613,
            -18.64008991764989
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for objective-specific improvement, then applies a hybrid local search strategy that combines probabilistic item prioritization, objective-aware replacement, and adaptive neighborhood diversification to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for objective-specific improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item prioritization (select items based on objective-specific priorities)\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific priorities for included items\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        priority_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Calculate prioritization scores for excluded items\n        priority_scores = (value1_lst[excluded_items] * priority_ratio + value2_lst[excluded_items] * (1 - priority_ratio)) / weight_lst[excluded_items]\n\n        # Select top k items to consider for prioritization\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(priority_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            prioritize_idx = np.random.choice(top_indices)\n\n            # Find the worst item to replace based on current objective priorities\n            worst_scores = (value1_lst[included_items] * priority_ratio + value2_lst[included_items] * (1 - priority_ratio)) / weight_lst[included_items]\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform prioritization if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[prioritize_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[prioritize_idx] = 1\n\n    # Step 2: Objective-aware replacement (replace items based on their potential to improve both objectives)\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate potential improvement scores for excluded items\n        improvement_scores = (value1_lst[excluded_items] * value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Select top k items to consider for improvement\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(improvement_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            improve_idx = np.random.choice(top_indices)\n\n            # Find the least valuable item to replace based on combined objective values\n            least_val_idx = np.argmin((value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items])\n            least_val_idx = included_items[least_val_idx]\n\n            # Perform improvement if feasible\n            if current_weight - weight_lst[least_val_idx] + weight_lst[improve_idx] <= capacity:\n                new_solution[least_val_idx] = 0\n                new_solution[improve_idx] = 1\n\n    # Step 3: Adaptive neighborhood diversification (flip bits based on solution diversity)\n    if len(included_items) > 0:\n        # Calculate solution diversity as the ratio of unique objective contributions\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine number of bits to flip based on diversity (less diverse solutions get more changes)\n        num_flips = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(num_flips):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.096530030707598,
            -18.662091361335012
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution with high potential for improvement in both objectives by combining probabilistic item selection with objective-aware swaps and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic objective-aware selection\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate combined objective scores\n        combined_scores = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(combined_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Objective-specific fine-tuning\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Select items based on objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        else:\n            # Focus on value1 improvement\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] * ratio + value2_lst[included_items] * (1 - ratio)) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.125194556064613,
            -18.64008991764989
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution with high potential for improvement in both objectives by combining probabilistic item selection with objective-aware swaps and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic objective-aware selection\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate combined objective scores\n        combined_scores = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(combined_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Objective-specific fine-tuning\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Select items based on objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        else:\n            # Focus on value1 improvement\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] * ratio + value2_lst[included_items] * (1 - ratio)) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.125194556064613,
            -18.64008991764989
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for objective-specific improvement, then applies a hybrid local search strategy that combines probabilistic item prioritization, objective-aware replacement, and adaptive neighborhood diversification to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for objective-specific improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item prioritization (select items based on objective-specific priorities)\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific priorities for included items\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        priority_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Calculate prioritization scores for excluded items\n        priority_scores = (value1_lst[excluded_items] * priority_ratio + value2_lst[excluded_items] * (1 - priority_ratio)) / weight_lst[excluded_items]\n\n        # Select top k items to consider for prioritization\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(priority_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            prioritize_idx = np.random.choice(top_indices)\n\n            # Find the worst item to replace based on current objective priorities\n            worst_scores = (value1_lst[included_items] * priority_ratio + value2_lst[included_items] * (1 - priority_ratio)) / weight_lst[included_items]\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform prioritization if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[prioritize_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[prioritize_idx] = 1\n\n    # Step 2: Objective-aware replacement (replace items based on their potential to improve both objectives)\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate potential improvement scores for excluded items\n        improvement_scores = (value1_lst[excluded_items] * value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Select top k items to consider for improvement\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(improvement_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            improve_idx = np.random.choice(top_indices)\n\n            # Find the least valuable item to replace based on combined objective values\n            least_val_idx = np.argmin((value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items])\n            least_val_idx = included_items[least_val_idx]\n\n            # Perform improvement if feasible\n            if current_weight - weight_lst[least_val_idx] + weight_lst[improve_idx] <= capacity:\n                new_solution[least_val_idx] = 0\n                new_solution[improve_idx] = 1\n\n    # Step 3: Adaptive neighborhood diversification (flip bits based on solution diversity)\n    if len(included_items) > 0:\n        # Calculate solution diversity as the ratio of unique objective contributions\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine number of bits to flip based on diversity (less diverse solutions get more changes)\n        num_flips = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(num_flips):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.096530030707598,
            -18.662091361335012
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution with high potential for improvement in both objectives by combining probabilistic item selection with objective-aware swaps and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic objective-aware selection\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate combined objective scores\n        combined_scores = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(combined_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Objective-specific fine-tuning\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Select items based on objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        else:\n            # Focus on value1 improvement\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] * ratio + value2_lst[included_items] * (1 - ratio)) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.125194556064613,
            -18.64008991764989
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for objective-specific improvement, then applies a hybrid local search strategy that combines probabilistic item prioritization, objective-aware replacement, and adaptive neighborhood diversification to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for objective-specific improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item prioritization (select items based on objective-specific priorities)\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific priorities for included items\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        priority_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Calculate prioritization scores for excluded items\n        priority_scores = (value1_lst[excluded_items] * priority_ratio + value2_lst[excluded_items] * (1 - priority_ratio)) / weight_lst[excluded_items]\n\n        # Select top k items to consider for prioritization\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(priority_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            prioritize_idx = np.random.choice(top_indices)\n\n            # Find the worst item to replace based on current objective priorities\n            worst_scores = (value1_lst[included_items] * priority_ratio + value2_lst[included_items] * (1 - priority_ratio)) / weight_lst[included_items]\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform prioritization if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[prioritize_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[prioritize_idx] = 1\n\n    # Step 2: Objective-aware replacement (replace items based on their potential to improve both objectives)\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate potential improvement scores for excluded items\n        improvement_scores = (value1_lst[excluded_items] * value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Select top k items to consider for improvement\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(improvement_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            improve_idx = np.random.choice(top_indices)\n\n            # Find the least valuable item to replace based on combined objective values\n            least_val_idx = np.argmin((value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items])\n            least_val_idx = included_items[least_val_idx]\n\n            # Perform improvement if feasible\n            if current_weight - weight_lst[least_val_idx] + weight_lst[improve_idx] <= capacity:\n                new_solution[least_val_idx] = 0\n                new_solution[improve_idx] = 1\n\n    # Step 3: Adaptive neighborhood diversification (flip bits based on solution diversity)\n    if len(included_items) > 0:\n        # Calculate solution diversity as the ratio of unique objective contributions\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine number of bits to flip based on diversity (less diverse solutions get more changes)\n        num_flips = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(num_flips):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.096530030707598,
            -18.662091361335012
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution with high potential for improvement in both objectives by combining probabilistic item selection with objective-aware swaps and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic objective-aware selection\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate combined objective scores\n        combined_scores = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(combined_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Objective-specific fine-tuning\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Select items based on objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        else:\n            # Focus on value1 improvement\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] * ratio + value2_lst[included_items] * (1 - ratio)) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.125194556064613,
            -18.64008991764989
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for objective-specific improvement, then applies a hybrid local search strategy that combines probabilistic item prioritization, objective-aware replacement, and adaptive neighborhood diversification to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for objective-specific improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item prioritization (select items based on objective-specific priorities)\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific priorities for included items\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        priority_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Calculate prioritization scores for excluded items\n        priority_scores = (value1_lst[excluded_items] * priority_ratio + value2_lst[excluded_items] * (1 - priority_ratio)) / weight_lst[excluded_items]\n\n        # Select top k items to consider for prioritization\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(priority_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            prioritize_idx = np.random.choice(top_indices)\n\n            # Find the worst item to replace based on current objective priorities\n            worst_scores = (value1_lst[included_items] * priority_ratio + value2_lst[included_items] * (1 - priority_ratio)) / weight_lst[included_items]\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform prioritization if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[prioritize_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[prioritize_idx] = 1\n\n    # Step 2: Objective-aware replacement (replace items based on their potential to improve both objectives)\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate potential improvement scores for excluded items\n        improvement_scores = (value1_lst[excluded_items] * value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Select top k items to consider for improvement\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(improvement_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            improve_idx = np.random.choice(top_indices)\n\n            # Find the least valuable item to replace based on combined objective values\n            least_val_idx = np.argmin((value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items])\n            least_val_idx = included_items[least_val_idx]\n\n            # Perform improvement if feasible\n            if current_weight - weight_lst[least_val_idx] + weight_lst[improve_idx] <= capacity:\n                new_solution[least_val_idx] = 0\n                new_solution[improve_idx] = 1\n\n    # Step 3: Adaptive neighborhood diversification (flip bits based on solution diversity)\n    if len(included_items) > 0:\n        # Calculate solution diversity as the ratio of unique objective contributions\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine number of bits to flip based on diversity (less diverse solutions get more changes)\n        num_flips = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(num_flips):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.096530030707598,
            -18.662091361335012
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for objective-specific improvement, then applies a hybrid local search strategy that combines probabilistic item prioritization, objective-aware replacement, and adaptive neighborhood diversification to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for objective-specific improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item prioritization (select items based on objective-specific priorities)\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific priorities for included items\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        priority_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Calculate prioritization scores for excluded items\n        priority_scores = (value1_lst[excluded_items] * priority_ratio + value2_lst[excluded_items] * (1 - priority_ratio)) / weight_lst[excluded_items]\n\n        # Select top k items to consider for prioritization\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(priority_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            prioritize_idx = np.random.choice(top_indices)\n\n            # Find the worst item to replace based on current objective priorities\n            worst_scores = (value1_lst[included_items] * priority_ratio + value2_lst[included_items] * (1 - priority_ratio)) / weight_lst[included_items]\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform prioritization if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[prioritize_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[prioritize_idx] = 1\n\n    # Step 2: Objective-aware replacement (replace items based on their potential to improve both objectives)\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate potential improvement scores for excluded items\n        improvement_scores = (value1_lst[excluded_items] * value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Select top k items to consider for improvement\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(improvement_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            improve_idx = np.random.choice(top_indices)\n\n            # Find the least valuable item to replace based on combined objective values\n            least_val_idx = np.argmin((value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items])\n            least_val_idx = included_items[least_val_idx]\n\n            # Perform improvement if feasible\n            if current_weight - weight_lst[least_val_idx] + weight_lst[improve_idx] <= capacity:\n                new_solution[least_val_idx] = 0\n                new_solution[improve_idx] = 1\n\n    # Step 3: Adaptive neighborhood diversification (flip bits based on solution diversity)\n    if len(included_items) > 0:\n        # Calculate solution diversity as the ratio of unique objective contributions\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine number of bits to flip based on diversity (less diverse solutions get more changes)\n        num_flips = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(num_flips):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.096530030707598,
            -18.662091361335012
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution with high potential for improvement in both objectives by combining probabilistic item selection with objective-aware swaps and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic objective-aware selection\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate combined objective scores\n        combined_scores = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(combined_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Objective-specific fine-tuning\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Select items based on objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        else:\n            # Focus on value1 improvement\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] * ratio + value2_lst[included_items] * (1 - ratio)) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.125194556064613,
            -18.64008991764989
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for objective-specific improvement, then applies a hybrid local search strategy that combines probabilistic item prioritization, objective-aware replacement, and adaptive neighborhood diversification to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for objective-specific improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item prioritization (select items based on objective-specific priorities)\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific priorities for included items\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        priority_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Calculate prioritization scores for excluded items\n        priority_scores = (value1_lst[excluded_items] * priority_ratio + value2_lst[excluded_items] * (1 - priority_ratio)) / weight_lst[excluded_items]\n\n        # Select top k items to consider for prioritization\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(priority_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            prioritize_idx = np.random.choice(top_indices)\n\n            # Find the worst item to replace based on current objective priorities\n            worst_scores = (value1_lst[included_items] * priority_ratio + value2_lst[included_items] * (1 - priority_ratio)) / weight_lst[included_items]\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform prioritization if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[prioritize_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[prioritize_idx] = 1\n\n    # Step 2: Objective-aware replacement (replace items based on their potential to improve both objectives)\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate potential improvement scores for excluded items\n        improvement_scores = (value1_lst[excluded_items] * value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Select top k items to consider for improvement\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(improvement_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            improve_idx = np.random.choice(top_indices)\n\n            # Find the least valuable item to replace based on combined objective values\n            least_val_idx = np.argmin((value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items])\n            least_val_idx = included_items[least_val_idx]\n\n            # Perform improvement if feasible\n            if current_weight - weight_lst[least_val_idx] + weight_lst[improve_idx] <= capacity:\n                new_solution[least_val_idx] = 0\n                new_solution[improve_idx] = 1\n\n    # Step 3: Adaptive neighborhood diversification (flip bits based on solution diversity)\n    if len(included_items) > 0:\n        # Calculate solution diversity as the ratio of unique objective contributions\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine number of bits to flip based on diversity (less diverse solutions get more changes)\n        num_flips = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(num_flips):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.096530030707598,
            -18.662091361335012
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution with high potential for improvement in both objectives by combining probabilistic item selection with objective-aware swaps and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic objective-aware selection\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate combined objective scores\n        combined_scores = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n\n        # Select top items to consider\n        k = min(4, len(excluded_items))\n        top_indices = np.argpartition(combined_scores[excluded_items], -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            selected_idx = np.random.choice(top_indices)\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[selected_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[selected_idx] = 1\n                current_weight = current_weight - weight_lst[worst_idx] + weight_lst[selected_idx]\n\n    # Step 2: Adaptive neighborhood exploration\n    if len(included_items) > 0:\n        # Calculate solution diversity\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine exploration intensity\n        exploration_intensity = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(exploration_intensity):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n    # Step 3: Objective-specific fine-tuning\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific ratios\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Select items based on objective balance\n        if ratio > 0.5:\n            # Focus on value2 improvement\n            improvement_scores = value2_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        else:\n            # Focus on value1 improvement\n            improvement_scores = value1_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n\n        # Select top item for potential addition\n        if len(improvement_scores) > 0:\n            best_idx = np.argmax(improvement_scores)\n            best_idx = excluded_items[best_idx]\n\n            # Find worst item to replace\n            worst_scores = (value1_lst[included_items] * ratio + value2_lst[included_items] * (1 - ratio)) / (weight_lst[included_items] + 1e-6)\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.125194556064613,
            -18.64008991764989
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for objective-specific improvement, then applies a hybrid local search strategy that combines probabilistic item prioritization, objective-aware replacement, and adaptive neighborhood diversification to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for objective-specific improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item prioritization (select items based on objective-specific priorities)\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific priorities for included items\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        priority_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Calculate prioritization scores for excluded items\n        priority_scores = (value1_lst[excluded_items] * priority_ratio + value2_lst[excluded_items] * (1 - priority_ratio)) / weight_lst[excluded_items]\n\n        # Select top k items to consider for prioritization\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(priority_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            prioritize_idx = np.random.choice(top_indices)\n\n            # Find the worst item to replace based on current objective priorities\n            worst_scores = (value1_lst[included_items] * priority_ratio + value2_lst[included_items] * (1 - priority_ratio)) / weight_lst[included_items]\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform prioritization if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[prioritize_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[prioritize_idx] = 1\n\n    # Step 2: Objective-aware replacement (replace items based on their potential to improve both objectives)\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate potential improvement scores for excluded items\n        improvement_scores = (value1_lst[excluded_items] * value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Select top k items to consider for improvement\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(improvement_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            improve_idx = np.random.choice(top_indices)\n\n            # Find the least valuable item to replace based on combined objective values\n            least_val_idx = np.argmin((value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items])\n            least_val_idx = included_items[least_val_idx]\n\n            # Perform improvement if feasible\n            if current_weight - weight_lst[least_val_idx] + weight_lst[improve_idx] <= capacity:\n                new_solution[least_val_idx] = 0\n                new_solution[improve_idx] = 1\n\n    # Step 3: Adaptive neighborhood diversification (flip bits based on solution diversity)\n    if len(included_items) > 0:\n        # Calculate solution diversity as the ratio of unique objective contributions\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine number of bits to flip based on diversity (less diverse solutions get more changes)\n        num_flips = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(num_flips):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.096530030707598,
            -18.662091361335012
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for objective-specific improvement, then applies a hybrid local search strategy that combines probabilistic item prioritization, objective-aware replacement, and adaptive neighborhood diversification to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for objective-specific improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item prioritization (select items based on objective-specific priorities)\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate objective-specific priorities for included items\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        priority_ratio = current_val1 / (current_val1 + current_val2 + 1e-6)\n\n        # Calculate prioritization scores for excluded items\n        priority_scores = (value1_lst[excluded_items] * priority_ratio + value2_lst[excluded_items] * (1 - priority_ratio)) / weight_lst[excluded_items]\n\n        # Select top k items to consider for prioritization\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(priority_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            prioritize_idx = np.random.choice(top_indices)\n\n            # Find the worst item to replace based on current objective priorities\n            worst_scores = (value1_lst[included_items] * priority_ratio + value2_lst[included_items] * (1 - priority_ratio)) / weight_lst[included_items]\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform prioritization if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[prioritize_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[prioritize_idx] = 1\n\n    # Step 2: Objective-aware replacement (replace items based on their potential to improve both objectives)\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate potential improvement scores for excluded items\n        improvement_scores = (value1_lst[excluded_items] * value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Select top k items to consider for improvement\n        k = min(5, len(excluded_items))\n        top_indices = np.argpartition(improvement_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            improve_idx = np.random.choice(top_indices)\n\n            # Find the least valuable item to replace based on combined objective values\n            least_val_idx = np.argmin((value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items])\n            least_val_idx = included_items[least_val_idx]\n\n            # Perform improvement if feasible\n            if current_weight - weight_lst[least_val_idx] + weight_lst[improve_idx] <= capacity:\n                new_solution[least_val_idx] = 0\n                new_solution[improve_idx] = 1\n\n    # Step 3: Adaptive neighborhood diversification (flip bits based on solution diversity)\n    if len(included_items) > 0:\n        # Calculate solution diversity as the ratio of unique objective contributions\n        unique_obj1 = len(np.unique(value1_lst[included_items]))\n        unique_obj2 = len(np.unique(value2_lst[included_items]))\n        diversity = min(unique_obj1, unique_obj2) / max(unique_obj1, unique_obj2) if max(unique_obj1, unique_obj2) > 0 else 0.5\n\n        # Determine number of bits to flip based on diversity (less diverse solutions get more changes)\n        num_flips = max(1, int(3 * (1 - diversity)))\n\n        for _ in range(num_flips):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.096530030707598,
            -18.662091361335012
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive based on its potential for multi-objective improvement, then applies a hybrid local search strategy that combines probabilistic item clustering, objective-weighted swapping, and adaptive neighborhood expansion to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for multi-objective improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Probabilistic item clustering (group items with similar characteristics)\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Cluster items based on value correlation\n        value_correlation = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        cluster_threshold = 0.5 + 0.5 * random.random()  # Random threshold between 0.5 and 1.0\n\n        # Identify items that are strongly correlated in values\n        correlated_items = np.where(np.abs(np.corrcoef(value1_lst[included_items], value2_lst[included_items])[0, 1]) > cluster_threshold)[0]\n        correlated_items = included_items[correlated_items]\n\n        if len(correlated_items) > 0:\n            # Select a random item from the correlated cluster\n            swap_out_idx = np.random.choice(correlated_items)\n\n            # Find the best item to swap in from excluded items\n            swap_in_idx = np.argmax((value1_lst[excluded_items] * value2_lst[excluded_items]) / weight_lst[excluded_items])\n            swap_in_idx = excluded_items[swap_in_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[swap_out_idx] + weight_lst[swap_in_idx] <= capacity:\n                new_solution[swap_out_idx] = 0\n                new_solution[swap_in_idx] = 1\n                current_weight = current_weight - weight_lst[swap_out_idx] + weight_lst[swap_in_idx]\n\n    # Step 2: Objective-weighted swapping (swap items based on their relative importance in each objective)\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        total_value = current_val1 + current_val2\n\n        # Calculate objective weights\n        obj1_weight = current_val1 / total_value if total_value > 0 else 0.5\n        obj2_weight = current_val2 / total_value if total_value > 0 else 0.5\n\n        # Calculate swap scores for excluded items\n        swap_scores = (obj1_weight * value1_lst[excluded_items] + obj2_weight * value2_lst[excluded_items]) / weight_lst[excluded_items]\n\n        # Select top k items to consider for swapping\n        k = min(3, len(excluded_items))\n        top_indices = np.argpartition(swap_scores, -k)[-k:]\n        top_indices = excluded_items[top_indices]\n\n        if len(top_indices) > 0:\n            swap_in_idx = np.random.choice(top_indices)\n\n            # Find the worst item to replace based on current objective weights\n            worst_scores = (obj1_weight * value1_lst[included_items] + obj2_weight * value2_lst[included_items]) / weight_lst[included_items]\n            worst_idx = np.argmin(worst_scores)\n            worst_idx = included_items[worst_idx]\n\n            # Perform swap if feasible\n            if current_weight - weight_lst[worst_idx] + weight_lst[swap_in_idx] <= capacity:\n                new_solution[worst_idx] = 0\n                new_solution[swap_in_idx] = 1\n\n    # Step 3: Adaptive neighborhood expansion (flip multiple bits based on solution quality)\n    if len(included_items) > 0:\n        # Calculate solution quality as the product of normalized objective values\n        current_val1 = np.sum(value1_lst * new_solution)\n        current_val2 = np.sum(value2_lst * new_solution)\n        max_val1 = np.sum(value1_lst)\n        max_val2 = np.sum(value2_lst)\n        quality = (current_val1 / max_val1) * (current_val2 / max_val2)\n\n        # Determine number of bits to flip based on quality (poorer solutions get more aggressive changes)\n        num_flips = max(1, int(5 * (1 - quality)))\n\n        for _ in range(num_flips):\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.96323194131221,
            -18.69300438716042
        ]
    }
]