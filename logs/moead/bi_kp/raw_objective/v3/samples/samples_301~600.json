[
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{The new algorithm selects a solution from the archive based on a combination of objective correlation and marginal improvement potential, then applies a hybrid local search strategy that uses value-correlation-aware swaps with adaptive neighborhood exploration and probabilistic acceptance, incorporating dynamic objective weighting and diversity-aware item selection to balance exploration and exploitation while ensuring feasibility.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest correlation and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    correlations = np.corrcoef(objectives.T)[0, 1] if len(archive) > 1 else 0.5\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.4 * correlations * potential\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-correlation-aware swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate dynamic weights based on correlation\n        weight1 = 0.5 + 0.3 * correlations\n        weight2 = 0.5 - 0.3 * correlations\n\n        # Calculate weighted efficiency with correlation adjustment\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n        efficiency *= (1 + 0.2 * correlations)\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.5, 0.3, 0.2] if len(top_candidates) == 3 else [0.7, 0.3])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Diversity-aware neighborhood exploration\n    exploration_depth = min(5, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on diversity\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.8, 1 - value_contribution / (np.max(efficiency) + 1e-10) * (1 - correlations)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and diversity\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.2, min(0.9, efficiency[idx] / (np.max(efficiency) + 1e-10) * (1 + 0.3 * correlations)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{The new algorithm selects a solution from the archive based on a combination of objective correlation and marginal improvement potential, then applies a hybrid local search strategy that uses value-correlation-aware swaps with adaptive neighborhood exploration and probabilistic acceptance, incorporating dynamic objective weighting and diversity-aware item selection to balance exploration and exploitation while ensuring feasibility.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest correlation and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    correlations = np.corrcoef(objectives.T)[0, 1] if len(archive) > 1 else 0.5\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.4 * correlations * potential\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-correlation-aware swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate dynamic weights based on correlation\n        weight1 = 0.5 + 0.3 * correlations\n        weight2 = 0.5 - 0.3 * correlations\n\n        # Calculate weighted efficiency with correlation adjustment\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n        efficiency *= (1 + 0.2 * correlations)\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.5, 0.3, 0.2] if len(top_candidates) == 3 else [0.7, 0.3])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Diversity-aware neighborhood exploration\n    exploration_depth = min(5, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on diversity\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.8, 1 - value_contribution / (np.max(efficiency) + 1e-10) * (1 - correlations)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and diversity\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.2, min(0.9, efficiency[idx] / (np.max(efficiency) + 1e-10) * (1 + 0.3 * correlations)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nPlease help me create a new algorithm that has a totally different form from the given ones but can be motivated from them.\n1. Firstly, identify the common backbone idea in the provided algorithms. \n2. Secondly, based on the backbone idea describe your new algorithm in one sentence. The description must be inside within boxed {}.\n3. Thirdly, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n\n\nDo not give additional explanations.",
        "sample_order": 301,
        "algorithm": "{The new algorithm selects a solution from the archive based on a combination of objective correlation and marginal improvement potential, then applies a hybrid local search strategy that uses value-correlation-aware swaps with adaptive neighborhood exploration and probabilistic acceptance, incorporating dynamic objective weighting and diversity-aware item selection to balance exploration and exploitation while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest correlation and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    correlations = np.corrcoef(objectives.T)[0, 1] if len(archive) > 1 else 0.5\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.4 * correlations * potential\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-correlation-aware swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate dynamic weights based on correlation\n        weight1 = 0.5 + 0.3 * correlations\n        weight2 = 0.5 - 0.3 * correlations\n\n        # Calculate weighted efficiency with correlation adjustment\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n        efficiency *= (1 + 0.2 * correlations)\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.5, 0.3, 0.2] if len(top_candidates) == 3 else [0.7, 0.3])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Diversity-aware neighborhood exploration\n    exploration_depth = min(5, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on diversity\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.8, 1 - value_contribution / (np.max(efficiency) + 1e-10) * (1 - correlations)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and diversity\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.2, min(0.9, efficiency[idx] / (np.max(efficiency) + 1e-10) * (1 + 0.3 * correlations)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -16.772565220025903,
            -19.61036696003339
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest correlation and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    correlations = np.corrcoef(objectives.T)[0, 1] if len(archive) > 1 else 0.5\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.4 * correlations * potential\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-correlation-aware swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate dynamic weights based on correlation\n        weight1 = 0.5 + 0.3 * correlations\n        weight2 = 0.5 - 0.3 * correlations\n\n        # Calculate weighted efficiency with correlation adjustment\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n        efficiency *= (1 + 0.2 * correlations)\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.5, 0.3, 0.2] if len(top_candidates) == 3 else [0.7, 0.3])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Diversity-aware neighborhood exploration\n    exploration_depth = min(5, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on diversity\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.8, 1 - value_contribution / (np.max(efficiency) + 1e-10) * (1 - correlations)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and diversity\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.2, min(0.9, efficiency[idx] / (np.max(efficiency) + 1e-10) * (1 + 0.3 * correlations)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{The new algorithm selects a solution from the archive based on a combination of objective correlation and marginal improvement potential, then applies a hybrid local search strategy that uses value-correlation-aware swaps with adaptive neighborhood exploration and probabilistic acceptance, incorporating dynamic objective weighting and diversity-aware item selection to balance exploration and exploitation while ensuring feasibility.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest correlation and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    correlations = np.corrcoef(objectives.T)[0, 1] if len(archive) > 1 else 0.5\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.4 * correlations * potential\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-correlation-aware swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate dynamic weights based on correlation\n        weight1 = 0.5 + 0.3 * correlations\n        weight2 = 0.5 - 0.3 * correlations\n\n        # Calculate weighted efficiency with correlation adjustment\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n        efficiency *= (1 + 0.2 * correlations)\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.5, 0.3, 0.2] if len(top_candidates) == 3 else [0.7, 0.3])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Diversity-aware neighborhood exploration\n    exploration_depth = min(5, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on diversity\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.8, 1 - value_contribution / (np.max(efficiency) + 1e-10) * (1 - correlations)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and diversity\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.2, min(0.9, efficiency[idx] / (np.max(efficiency) + 1e-10) * (1 + 0.3 * correlations)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{The new algorithm selects a solution from the archive based on a combination of objective correlation and marginal improvement potential, then applies a hybrid local search strategy that uses value-correlation-aware swaps with adaptive neighborhood exploration and probabilistic acceptance, incorporating dynamic objective weighting and diversity-aware item selection to balance exploration and exploitation while ensuring feasibility.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest correlation and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    correlations = np.corrcoef(objectives.T)[0, 1] if len(archive) > 1 else 0.5\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.4 * correlations * potential\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-correlation-aware swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate dynamic weights based on correlation\n        weight1 = 0.5 + 0.3 * correlations\n        weight2 = 0.5 - 0.3 * correlations\n\n        # Calculate weighted efficiency with correlation adjustment\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n        efficiency *= (1 + 0.2 * correlations)\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.5, 0.3, 0.2] if len(top_candidates) == 3 else [0.7, 0.3])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Diversity-aware neighborhood exploration\n    exploration_depth = min(5, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on diversity\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.8, 1 - value_contribution / (np.max(efficiency) + 1e-10) * (1 - correlations)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and diversity\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.2, min(0.9, efficiency[idx] / (np.max(efficiency) + 1e-10) * (1 + 0.3 * correlations)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nPlease help me create a new algorithm that has a totally different form from the given ones but can be motivated from them.\n1. Firstly, identify the common backbone idea in the provided algorithms. \n2. Secondly, based on the backbone idea describe your new algorithm in one sentence. The description must be inside within boxed {}.\n3. Thirdly, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n\n\nDo not give additional explanations.",
        "sample_order": 301,
        "algorithm": "{The new algorithm selects a solution from the archive based on a combination of objective correlation and marginal improvement potential, then applies a hybrid local search strategy that uses value-correlation-aware swaps with adaptive neighborhood exploration and probabilistic acceptance, incorporating dynamic objective weighting and diversity-aware item selection to balance exploration and exploitation while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest correlation and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    correlations = np.corrcoef(objectives.T)[0, 1] if len(archive) > 1 else 0.5\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.4 * correlations * potential\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-correlation-aware swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate dynamic weights based on correlation\n        weight1 = 0.5 + 0.3 * correlations\n        weight2 = 0.5 - 0.3 * correlations\n\n        # Calculate weighted efficiency with correlation adjustment\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n        efficiency *= (1 + 0.2 * correlations)\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.5, 0.3, 0.2] if len(top_candidates) == 3 else [0.7, 0.3])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Diversity-aware neighborhood exploration\n    exploration_depth = min(5, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on diversity\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.8, 1 - value_contribution / (np.max(efficiency) + 1e-10) * (1 - correlations)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and diversity\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.2, min(0.9, efficiency[idx] / (np.max(efficiency) + 1e-10) * (1 + 0.3 * correlations)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -16.772565220025903,
            -19.61036696003339
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest correlation and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    correlations = np.corrcoef(objectives.T)[0, 1] if len(archive) > 1 else 0.5\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.4 * correlations * potential\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-correlation-aware swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate dynamic weights based on correlation\n        weight1 = 0.5 + 0.3 * correlations\n        weight2 = 0.5 - 0.3 * correlations\n\n        # Calculate weighted efficiency with correlation adjustment\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n        efficiency *= (1 + 0.2 * correlations)\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.5, 0.3, 0.2] if len(top_candidates) == 3 else [0.7, 0.3])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Diversity-aware neighborhood exploration\n    exploration_depth = min(5, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on diversity\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.8, 1 - value_contribution / (np.max(efficiency) + 1e-10) * (1 - correlations)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and diversity\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.2, min(0.9, efficiency[idx] / (np.max(efficiency) + 1e-10) * (1 + 0.3 * correlations)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have one algorithm with its code as follows. Algorithm description:\n{The new algorithm selects a solution from the archive based on a combination of objective diversity and marginal improvement potential, then applies a hybrid local search strategy that uses value-weighted swaps with adaptive neighborhood exploration and probabilistic acceptance, incorporating dynamic objective weighting and correlation-aware item selection to balance exploration and exploitation while ensuring feasibility.}\nCode:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest diversity and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    diversity = np.std(objectives, axis=0)\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.5 * np.sum(diversity * objectives, axis=1)\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-weighted swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value ratios and dynamic weights\n        ratio = np.mean(value2_lst[included] / (value1_lst[included] + 1e-10)) if len(included) > 1 else 0.5\n        weight1 = 0.5 + 0.4 * ratio\n        weight2 = 0.5 - 0.4 * ratio\n\n        # Calculate weighted efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            # Select top 2 candidates and choose one based on gain and randomness\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(2, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.7, 0.3] if len(top_candidates) == 2 else [1.0])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Adaptive neighborhood exploration with probabilistic acceptance\n    exploration_depth = min(4, n_items // 3)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on weighted value\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.8, 1 - value_contribution / (np.max(efficiency) + 1e-10)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and remaining capacity\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.2, min(0.9, efficiency[idx] / (np.max(efficiency) + 1e-10)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nPlease assist me in creating a new algorithm that has a different form but can be a modified version of the algorithm provided.\n1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nDo not give additional explanations.",
        "sample_order": 302,
        "algorithm": "{This new algorithm selects a solution from the archive based on a combination of objective correlation and marginal improvement potential, then applies a hybrid local search strategy that uses value-weighted swaps with adaptive neighborhood exploration and probabilistic acceptance, incorporating dynamic objective weighting and correlation-aware item selection to balance exploration and exploitation while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest objective correlation and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    correlations = np.corrcoef(objectives[:, 0], objectives[:, 1])[0, 1]\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.4 * correlations * np.sum(objectives, axis=1)\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-weighted swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate correlation-based weights\n        corr = np.corrcoef(value1_lst[included], value2_lst[included])[0, 1]\n        weight1 = 0.5 + 0.3 * corr\n        weight2 = 0.5 - 0.3 * corr\n\n        # Calculate weighted efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            # Select top 3 candidates and choose one based on gain and randomness\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.6, 0.3, 0.1] if len(top_candidates) == 3 else [0.7, 0.3])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Adaptive neighborhood exploration with probabilistic acceptance\n    exploration_depth = min(5, n_items // 4)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on weighted value\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.7, 1 - value_contribution / (np.max(efficiency) + 1e-10)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and remaining capacity\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.2, min(0.8, efficiency[idx] / (np.max(efficiency) + 1e-10)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -17.89025638827865,
            -18.870499995420587
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest objective correlation and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    correlations = np.corrcoef(objectives[:, 0], objectives[:, 1])[0, 1]\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.4 * correlations * np.sum(objectives, axis=1)\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-weighted swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate correlation-based weights\n        corr = np.corrcoef(value1_lst[included], value2_lst[included])[0, 1]\n        weight1 = 0.5 + 0.3 * corr\n        weight2 = 0.5 - 0.3 * corr\n\n        # Calculate weighted efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            # Select top 3 candidates and choose one based on gain and randomness\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.6, 0.3, 0.1] if len(top_candidates) == 3 else [0.7, 0.3])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Adaptive neighborhood exploration with probabilistic acceptance\n    exploration_depth = min(5, n_items // 4)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on weighted value\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.7, 1 - value_contribution / (np.max(efficiency) + 1e-10)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and remaining capacity\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.2, min(0.8, efficiency[idx] / (np.max(efficiency) + 1e-10)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have one algorithm with its code as follows. Algorithm description:\n{The new algorithm selects a solution from the archive based on a combination of objective correlation and marginal improvement potential, then applies a hybrid local search strategy that uses value-correlation-aware swaps with adaptive neighborhood exploration and probabilistic acceptance, incorporating dynamic objective weighting and diversity-aware item selection to balance exploration and exploitation while ensuring feasibility.}\nCode:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest correlation and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    correlations = np.corrcoef(objectives.T)[0, 1] if len(archive) > 1 else 0.5\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.4 * correlations * potential\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-correlation-aware swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate dynamic weights based on correlation\n        weight1 = 0.5 + 0.3 * correlations\n        weight2 = 0.5 - 0.3 * correlations\n\n        # Calculate weighted efficiency with correlation adjustment\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n        efficiency *= (1 + 0.2 * correlations)\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.5, 0.3, 0.2] if len(top_candidates) == 3 else [0.7, 0.3])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Diversity-aware neighborhood exploration\n    exploration_depth = min(5, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on diversity\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.8, 1 - value_contribution / (np.max(efficiency) + 1e-10) * (1 - correlations)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and diversity\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.2, min(0.9, efficiency[idx] / (np.max(efficiency) + 1e-10) * (1 + 0.3 * correlations)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nPlease identify the main algorithm parameters and assist me in creating a new algorithm that has a different parameter settings of the score function provided.\n1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nDo not give additional explanations.",
        "sample_order": 303,
        "algorithm": "{The new algorithm selects a solution from the archive based on a combination of objective diversity and marginal improvement potential, then applies a hybrid local search strategy that uses value-diversity-aware swaps with adaptive neighborhood exploration and probabilistic acceptance, incorporating dynamic objective weighting and correlation-aware item selection to balance exploration and exploitation while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest diversity and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    diversity = np.std(objectives, axis=0)\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.5 * diversity[0] * potential + 0.3 * diversity[1] * potential\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-diversity-aware swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate dynamic weights based on diversity\n        weight1 = 0.6 + 0.2 * diversity[0]\n        weight2 = 0.6 - 0.2 * diversity[1]\n\n        # Calculate weighted efficiency with diversity adjustment\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n        efficiency *= (1 + 0.1 * diversity[0] + 0.1 * diversity[1])\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(4, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.4, 0.3, 0.2, 0.1] if len(top_candidates) == 4 else [0.6, 0.4])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Correlation-aware neighborhood exploration\n    exploration_depth = min(6, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on correlation\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.8, 1 - value_contribution / (np.max(efficiency) + 1e-10) * (1 - 0.2 * diversity[0] - 0.2 * diversity[1])))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and correlation\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.2, min(0.9, efficiency[idx] / (np.max(efficiency) + 1e-10) * (1 + 0.2 * diversity[0] + 0.2 * diversity[1])))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -19.387764552908145,
            -17.841483124096037
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest diversity and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    diversity = np.std(objectives, axis=0)\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.5 * diversity[0] * potential + 0.3 * diversity[1] * potential\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-diversity-aware swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate dynamic weights based on diversity\n        weight1 = 0.6 + 0.2 * diversity[0]\n        weight2 = 0.6 - 0.2 * diversity[1]\n\n        # Calculate weighted efficiency with diversity adjustment\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n        efficiency *= (1 + 0.1 * diversity[0] + 0.1 * diversity[1])\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(4, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.4, 0.3, 0.2, 0.1] if len(top_candidates) == 4 else [0.6, 0.4])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Correlation-aware neighborhood exploration\n    exploration_depth = min(6, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on correlation\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.8, 1 - value_contribution / (np.max(efficiency) + 1e-10) * (1 - 0.2 * diversity[0] - 0.2 * diversity[1])))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and correlation\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.2, min(0.9, efficiency[idx] / (np.max(efficiency) + 1e-10) * (1 + 0.2 * diversity[0] + 0.2 * diversity[1])))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have one algorithm with its code as follows. Algorithm description:\n{The new algorithm selects a solution from the archive based on a combination of objective diversity and marginal improvement potential, then applies a hybrid local search strategy that uses value-weighted swaps with adaptive neighborhood exploration and probabilistic acceptance, incorporating dynamic objective weighting and correlation-aware item selection to balance exploration and exploitation while ensuring feasibility.}\nCode:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest diversity and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    diversity = np.std(objectives, axis=0)\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.5 * np.sum(diversity * objectives, axis=1)\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-weighted swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value ratios and dynamic weights\n        ratio = np.mean(value2_lst[included] / (value1_lst[included] + 1e-10)) if len(included) > 1 else 0.5\n        weight1 = 0.5 + 0.4 * ratio\n        weight2 = 0.5 - 0.4 * ratio\n\n        # Calculate weighted efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            # Select top 2 candidates and choose one based on gain and randomness\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(2, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.7, 0.3] if len(top_candidates) == 2 else [1.0])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Adaptive neighborhood exploration with probabilistic acceptance\n    exploration_depth = min(4, n_items // 3)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on weighted value\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.8, 1 - value_contribution / (np.max(efficiency) + 1e-10)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and remaining capacity\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.2, min(0.9, efficiency[idx] / (np.max(efficiency) + 1e-10)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nPlease assist me in creating a new algorithm that has a different form but can be a modified version of the algorithm provided.\n1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nDo not give additional explanations.",
        "sample_order": 304,
        "algorithm": "{The new algorithm selects a solution from the archive based on a combination of objective correlation and marginal improvement potential, then applies a hybrid local search strategy that uses value-weighted flips with adaptive neighborhood exploration and probabilistic acceptance, incorporating dynamic objective weighting and correlation-aware item selection to balance exploration and exploitation while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest correlation and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    correlation = np.corrcoef(objectives.T)[0, 1] if len(archive) > 1 else 0.5\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.3 * correlation * np.sum(objectives, axis=1)\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-weighted flips with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0:\n        # Calculate value ratios and dynamic weights\n        ratio = np.mean(value2_lst[included] / (value1_lst[included] + 1e-10)) if len(included) > 1 else 0.5\n        weight1 = 0.6 + 0.3 * ratio\n        weight2 = 0.4 - 0.3 * ratio\n\n        # Calculate weighted efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best flip candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            if current_weight - weight_lst[i] >= 0:\n                loss = -weight1 * value1_lst[i] - weight2 * value2_lst[i]\n                candidates.append((i, loss))\n\n        for j in excluded:\n            if current_weight + weight_lst[j] <= capacity:\n                gain = weight1 * value1_lst[j] + weight2 * value2_lst[j]\n                candidates.append((j, -gain))\n\n        if candidates:\n            # Select top 3 candidates and choose one based on gain/loss and randomness\n            candidates.sort(key=lambda x: x[1])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.5, 0.3, 0.2] if len(top_candidates) == 3 else [0.7, 0.3])\n            best_flip = top_candidates[selected]\n\n            if new_solution[best_flip[0]] == 1:\n                new_solution[best_flip[0]] = 0\n                current_weight -= weight_lst[best_flip[0]]\n            else:\n                new_solution[best_flip[0]] = 1\n                current_weight += weight_lst[best_flip[0]]\n\n    # Step 2: Adaptive neighborhood exploration with probabilistic acceptance\n    exploration_depth = min(5, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on weighted value\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.15, min(0.85, 1 - value_contribution / (np.max(efficiency) + 1e-10)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Probabilistic addition based on efficiency and remaining capacity\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.25, min(0.95, efficiency[idx] / (np.max(efficiency) + 1e-10)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -17.31731472834317,
            -17.499275313851143
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest correlation and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    correlation = np.corrcoef(objectives.T)[0, 1] if len(archive) > 1 else 0.5\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.3 * correlation * np.sum(objectives, axis=1)\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-weighted flips with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0:\n        # Calculate value ratios and dynamic weights\n        ratio = np.mean(value2_lst[included] / (value1_lst[included] + 1e-10)) if len(included) > 1 else 0.5\n        weight1 = 0.6 + 0.3 * ratio\n        weight2 = 0.4 - 0.3 * ratio\n\n        # Calculate weighted efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best flip candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            if current_weight - weight_lst[i] >= 0:\n                loss = -weight1 * value1_lst[i] - weight2 * value2_lst[i]\n                candidates.append((i, loss))\n\n        for j in excluded:\n            if current_weight + weight_lst[j] <= capacity:\n                gain = weight1 * value1_lst[j] + weight2 * value2_lst[j]\n                candidates.append((j, -gain))\n\n        if candidates:\n            # Select top 3 candidates and choose one based on gain/loss and randomness\n            candidates.sort(key=lambda x: x[1])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.5, 0.3, 0.2] if len(top_candidates) == 3 else [0.7, 0.3])\n            best_flip = top_candidates[selected]\n\n            if new_solution[best_flip[0]] == 1:\n                new_solution[best_flip[0]] = 0\n                current_weight -= weight_lst[best_flip[0]]\n            else:\n                new_solution[best_flip[0]] = 1\n                current_weight += weight_lst[best_flip[0]]\n\n    # Step 2: Adaptive neighborhood exploration with probabilistic acceptance\n    exploration_depth = min(5, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on weighted value\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.15, min(0.85, 1 - value_contribution / (np.max(efficiency) + 1e-10)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Probabilistic addition based on efficiency and remaining capacity\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.25, min(0.95, efficiency[idx] / (np.max(efficiency) + 1e-10)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have one algorithm with its code as follows. Algorithm description:\n{The new algorithm selects a solution from the archive based on a combination of objective correlation and marginal improvement potential, then applies a hybrid local search strategy that uses value-correlation-aware swaps with adaptive neighborhood exploration and probabilistic acceptance, incorporating dynamic objective weighting and diversity-aware item selection to balance exploration and exploitation while ensuring feasibility.}\nCode:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest correlation and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    correlations = np.corrcoef(objectives.T)[0, 1] if len(archive) > 1 else 0.5\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.4 * correlations * potential\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-correlation-aware swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate dynamic weights based on correlation\n        weight1 = 0.5 + 0.3 * correlations\n        weight2 = 0.5 - 0.3 * correlations\n\n        # Calculate weighted efficiency with correlation adjustment\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n        efficiency *= (1 + 0.2 * correlations)\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.5, 0.3, 0.2] if len(top_candidates) == 3 else [0.7, 0.3])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Diversity-aware neighborhood exploration\n    exploration_depth = min(5, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on diversity\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.8, 1 - value_contribution / (np.max(efficiency) + 1e-10) * (1 - correlations)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and diversity\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.2, min(0.9, efficiency[idx] / (np.max(efficiency) + 1e-10) * (1 + 0.3 * correlations)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nPlease identify the main algorithm parameters and assist me in creating a new algorithm that has a different parameter settings of the score function provided.\n1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nDo not give additional explanations.",
        "sample_order": 305,
        "algorithm": "{The new algorithm selects a solution from the archive based on a combination of objective diversity and marginal improvement potential, then applies a hybrid local search strategy that uses objective-space-aware swaps with adaptive neighborhood exploration and probabilistic acceptance, incorporating dynamic objective weighting and correlation-aware item selection to balance exploration and exploitation while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest diversity and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    diversity = np.std(objectives, axis=0)\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.3 * diversity[0] * potential + 0.2 * diversity[1] * potential\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Objective-space-aware swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate dynamic weights based on diversity\n        weight1 = 0.4 + 0.4 * diversity[0]\n        weight2 = 0.4 + 0.4 * diversity[1]\n\n        # Calculate weighted efficiency with diversity adjustment\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n        efficiency *= (1 + 0.3 * diversity[0] + 0.2 * diversity[1])\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.6, 0.3, 0.1] if len(top_candidates) == 3 else [0.8, 0.2])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Correlation-aware neighborhood exploration\n    exploration_depth = min(6, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on correlation\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.15, min(0.7, 1 - value_contribution / (np.max(efficiency) + 1e-10) * (0.9 - 0.3 * diversity[0] - 0.2 * diversity[1])))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and correlation\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.25, min(0.85, efficiency[idx] / (np.max(efficiency) + 1e-10) * (1 + 0.2 * diversity[0] + 0.15 * diversity[1])))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -18.833148036235016,
            -18.370252920621304
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest diversity and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    diversity = np.std(objectives, axis=0)\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.3 * diversity[0] * potential + 0.2 * diversity[1] * potential\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Objective-space-aware swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate dynamic weights based on diversity\n        weight1 = 0.4 + 0.4 * diversity[0]\n        weight2 = 0.4 + 0.4 * diversity[1]\n\n        # Calculate weighted efficiency with diversity adjustment\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n        efficiency *= (1 + 0.3 * diversity[0] + 0.2 * diversity[1])\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.6, 0.3, 0.1] if len(top_candidates) == 3 else [0.8, 0.2])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Correlation-aware neighborhood exploration\n    exploration_depth = min(6, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on correlation\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.15, min(0.7, 1 - value_contribution / (np.max(efficiency) + 1e-10) * (0.9 - 0.3 * diversity[0] - 0.2 * diversity[1])))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and correlation\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.25, min(0.85, efficiency[idx] / (np.max(efficiency) + 1e-10) * (1 + 0.2 * diversity[0] + 0.15 * diversity[1])))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have one algorithm with its code as follows. Algorithm description:\n{The new algorithm selects a solution from the archive based on a combination of objective correlation and marginal improvement potential, then applies a hybrid local search strategy that uses value-correlation-aware swaps with adaptive neighborhood exploration and probabilistic acceptance, incorporating dynamic objective weighting and diversity-aware item selection to balance exploration and exploitation while ensuring feasibility.}\nCode:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest correlation and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    correlations = np.corrcoef(objectives.T)[0, 1] if len(archive) > 1 else 0.5\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.4 * correlations * potential\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-correlation-aware swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate dynamic weights based on correlation\n        weight1 = 0.5 + 0.3 * correlations\n        weight2 = 0.5 - 0.3 * correlations\n\n        # Calculate weighted efficiency with correlation adjustment\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n        efficiency *= (1 + 0.2 * correlations)\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.5, 0.3, 0.2] if len(top_candidates) == 3 else [0.7, 0.3])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Diversity-aware neighborhood exploration\n    exploration_depth = min(5, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on diversity\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.8, 1 - value_contribution / (np.max(efficiency) + 1e-10) * (1 - correlations)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and diversity\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.2, min(0.9, efficiency[idx] / (np.max(efficiency) + 1e-10) * (1 + 0.3 * correlations)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nPlease identify the main algorithm parameters and assist me in creating a new algorithm that has a different parameter settings of the score function provided.\n1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nDo not give additional explanations.",
        "sample_order": 306,
        "algorithm": "{The new algorithm selects a solution from the archive based on a combination of objective diversity and marginal improvement potential, then applies a hybrid local search strategy that uses value-diversity-aware swaps with adaptive neighborhood exploration and probabilistic acceptance, incorporating dynamic objective weighting and correlation-aware item selection to balance exploration and exploitation while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest diversity and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    diversity = np.std(objectives, axis=0) if len(archive) > 1 else np.array([1.0, 1.0])\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.5 * diversity[0] * potential + 0.3 * diversity[1] * potential\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-diversity-aware swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate dynamic weights based on diversity\n        weight1 = 0.5 + 0.4 * diversity[0]\n        weight2 = 0.5 - 0.4 * diversity[0]\n\n        # Calculate weighted efficiency with diversity adjustment\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n        efficiency *= (1 + 0.3 * diversity[1])\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.6, 0.3, 0.1] if len(top_candidates) == 3 else [0.8, 0.2])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Correlation-aware neighborhood exploration\n    exploration_depth = min(6, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on correlation\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.2, min(0.9, 1 - value_contribution / (np.max(efficiency) + 1e-10) * (1 - diversity[0])))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and correlation\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.3, min(0.8, efficiency[idx] / (np.max(efficiency) + 1e-10) * (1 + 0.2 * diversity[1])))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -19.405623526069775,
            -16.798106684406974
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest diversity and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    diversity = np.std(objectives, axis=0) if len(archive) > 1 else np.array([1.0, 1.0])\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.5 * diversity[0] * potential + 0.3 * diversity[1] * potential\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-diversity-aware swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate dynamic weights based on diversity\n        weight1 = 0.5 + 0.4 * diversity[0]\n        weight2 = 0.5 - 0.4 * diversity[0]\n\n        # Calculate weighted efficiency with diversity adjustment\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n        efficiency *= (1 + 0.3 * diversity[1])\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.6, 0.3, 0.1] if len(top_candidates) == 3 else [0.8, 0.2])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Correlation-aware neighborhood exploration\n    exploration_depth = min(6, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on correlation\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.2, min(0.9, 1 - value_contribution / (np.max(efficiency) + 1e-10) * (1 - diversity[0])))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and correlation\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.3, min(0.8, efficiency[idx] / (np.max(efficiency) + 1e-10) * (1 + 0.2 * diversity[1])))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have one algorithm with its code as follows. Algorithm description:\n{The new algorithm selects a solution from the archive based on a combination of objective diversity and marginal improvement potential, then applies a hybrid local search strategy that uses value-weighted swaps with adaptive neighborhood exploration and probabilistic acceptance, incorporating dynamic objective weighting and correlation-aware item selection to balance exploration and exploitation while ensuring feasibility.}\nCode:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest diversity and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    diversity = np.std(objectives, axis=0)\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.5 * np.sum(diversity * objectives, axis=1)\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-weighted swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value ratios and dynamic weights\n        ratio = np.mean(value2_lst[included] / (value1_lst[included] + 1e-10)) if len(included) > 1 else 0.5\n        weight1 = 0.5 + 0.4 * ratio\n        weight2 = 0.5 - 0.4 * ratio\n\n        # Calculate weighted efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            # Select top 2 candidates and choose one based on gain and randomness\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(2, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.7, 0.3] if len(top_candidates) == 2 else [1.0])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Adaptive neighborhood exploration with probabilistic acceptance\n    exploration_depth = min(4, n_items // 3)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on weighted value\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.8, 1 - value_contribution / (np.max(efficiency) + 1e-10)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and remaining capacity\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.2, min(0.9, efficiency[idx] / (np.max(efficiency) + 1e-10)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nPlease identify the main algorithm parameters and assist me in creating a new algorithm that has a different parameter settings of the score function provided.\n1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nDo not give additional explanations.",
        "sample_order": 307,
        "algorithm": "{The new algorithm selects a solution from the archive based on a combination of objective dominance and value-to-weight ratio, then applies a hybrid local search strategy that uses correlated swaps with adaptive neighborhood exploration and probabilistic acceptance, incorporating dynamic objective weighting and efficiency-aware item selection to balance exploration and exploitation while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest dominance and value-to-weight ratio\n    objectives = np.array([obj for _, obj in archive])\n    dominance_scores = np.zeros(len(archive))\n    for i in range(len(archive)):\n        dominated = 0\n        for j in range(len(archive)):\n            if i != j and objectives[j][0] >= objectives[i][0] and objectives[j][1] >= objectives[i][1]:\n                if objectives[j][0] > objectives[i][0] or objectives[j][1] > objectives[i][1]:\n                    dominated += 1\n        dominance_scores[i] = 1 / (1 + dominated)\n\n    value_ratios = np.mean(value2_lst / (value1_lst + 1e-10))\n    selection_score = dominance_scores + 0.3 * value_ratios * np.sum(objectives, axis=1)\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Correlated swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate correlation and dynamic weights\n        correlation = np.corrcoef(value1_lst[included], value2_lst[included])[0,1] if len(included) > 1 else 0.5\n        weight1 = 0.6 + 0.3 * correlation\n        weight2 = 0.6 - 0.3 * correlation\n\n        # Calculate weighted efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best correlated swap candidates\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain1 = value1_lst[j] - value1_lst[i]\n                    gain2 = value2_lst[j] - value2_lst[i]\n                    correlation_gain = (gain1 * gain2) / (np.sqrt(gain1**2 + gain2**2) + 1e-10)\n                    candidates.append((i, j, correlation_gain))\n\n        if candidates:\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.5, 0.3, 0.2] if len(top_candidates) == 3 else [0.6, 0.4])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Adaptive neighborhood exploration with probabilistic acceptance\n    exploration_depth = min(5, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on marginal value\n            marginal_value = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.2, min(0.7, 1 - marginal_value / (np.max(efficiency) + 1e-10)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and remaining capacity\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.3, min(0.8, efficiency[idx] / (np.max(efficiency) + 1e-10)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -16.607011638506215,
            -16.65367387108602
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest dominance and value-to-weight ratio\n    objectives = np.array([obj for _, obj in archive])\n    dominance_scores = np.zeros(len(archive))\n    for i in range(len(archive)):\n        dominated = 0\n        for j in range(len(archive)):\n            if i != j and objectives[j][0] >= objectives[i][0] and objectives[j][1] >= objectives[i][1]:\n                if objectives[j][0] > objectives[i][0] or objectives[j][1] > objectives[i][1]:\n                    dominated += 1\n        dominance_scores[i] = 1 / (1 + dominated)\n\n    value_ratios = np.mean(value2_lst / (value1_lst + 1e-10))\n    selection_score = dominance_scores + 0.3 * value_ratios * np.sum(objectives, axis=1)\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Correlated swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate correlation and dynamic weights\n        correlation = np.corrcoef(value1_lst[included], value2_lst[included])[0,1] if len(included) > 1 else 0.5\n        weight1 = 0.6 + 0.3 * correlation\n        weight2 = 0.6 - 0.3 * correlation\n\n        # Calculate weighted efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best correlated swap candidates\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain1 = value1_lst[j] - value1_lst[i]\n                    gain2 = value2_lst[j] - value2_lst[i]\n                    correlation_gain = (gain1 * gain2) / (np.sqrt(gain1**2 + gain2**2) + 1e-10)\n                    candidates.append((i, j, correlation_gain))\n\n        if candidates:\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.5, 0.3, 0.2] if len(top_candidates) == 3 else [0.6, 0.4])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Adaptive neighborhood exploration with probabilistic acceptance\n    exploration_depth = min(5, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on marginal value\n            marginal_value = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.2, min(0.7, 1 - marginal_value / (np.max(efficiency) + 1e-10)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and remaining capacity\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.3, min(0.8, efficiency[idx] / (np.max(efficiency) + 1e-10)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{The new algorithm selects a solution from the archive based on a combination of objective diversity and marginal improvement potential, then applies a hybrid local search strategy that uses value-weighted swaps with adaptive neighborhood exploration and probabilistic acceptance, incorporating dynamic objective weighting and correlation-aware item selection to balance exploration and exploitation while ensuring feasibility.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest diversity and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    diversity = np.std(objectives, axis=0)\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.5 * np.sum(diversity * objectives, axis=1)\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-weighted swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value ratios and dynamic weights\n        ratio = np.mean(value2_lst[included] / (value1_lst[included] + 1e-10)) if len(included) > 1 else 0.5\n        weight1 = 0.5 + 0.4 * ratio\n        weight2 = 0.5 - 0.4 * ratio\n\n        # Calculate weighted efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            # Select top 2 candidates and choose one based on gain and randomness\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(2, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.7, 0.3] if len(top_candidates) == 2 else [1.0])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Adaptive neighborhood exploration with probabilistic acceptance\n    exploration_depth = min(4, n_items // 3)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on weighted value\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.8, 1 - value_contribution / (np.max(efficiency) + 1e-10)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and remaining capacity\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.2, min(0.9, efficiency[idx] / (np.max(efficiency) + 1e-10)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{The new algorithm selects a solution from the archive based on a combination of objective correlation and marginal improvement potential, then applies a hybrid local search strategy that uses value-correlation-aware swaps with adaptive neighborhood exploration and probabilistic acceptance, incorporating dynamic objective weighting and diversity-aware item selection to balance exploration and exploitation while ensuring feasibility.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest correlation and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    correlations = np.corrcoef(objectives.T)[0, 1] if len(archive) > 1 else 0.5\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.4 * correlations * potential\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-correlation-aware swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate dynamic weights based on correlation\n        weight1 = 0.5 + 0.3 * correlations\n        weight2 = 0.5 - 0.3 * correlations\n\n        # Calculate weighted efficiency with correlation adjustment\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n        efficiency *= (1 + 0.2 * correlations)\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.5, 0.3, 0.2] if len(top_candidates) == 3 else [0.7, 0.3])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Diversity-aware neighborhood exploration\n    exploration_depth = min(5, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on diversity\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.8, 1 - value_contribution / (np.max(efficiency) + 1e-10) * (1 - correlations)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and diversity\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.2, min(0.9, efficiency[idx] / (np.max(efficiency) + 1e-10) * (1 + 0.3 * correlations)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nPlease help me create a new algorithm that has a totally different form from the given ones. \n1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nDo not give additional explanations.",
        "sample_order": 308,
        "algorithm": "{The new algorithm selects a solution from the archive based on a combination of objective dominance and solution diversity, then applies a hybrid local search strategy that uses adaptive multi-objective swaps with probabilistic acceptance, incorporating dynamic objective weighting and correlation-aware item selection to balance exploration and exploitation while ensuring feasibility, followed by a novel greedy insertion phase to further improve the solution.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest dominance and diversity\n    objectives = np.array([obj for _, obj in archive])\n    dominance_scores = np.zeros(len(archive))\n    for i in range(len(archive)):\n        dominated = 0\n        for j in range(len(archive)):\n            if i != j and objectives[j][0] >= objectives[i][0] and objectives[j][1] >= objectives[i][1]:\n                dominated += 1\n        dominance_scores[i] = dominated\n\n    diversity_scores = np.zeros(len(archive))\n    for i in range(len(archive)):\n        distances = np.sum(np.abs(objectives[i] - objectives), axis=1)\n        diversity_scores[i] = np.mean(distances)\n\n    selection_score = 0.7 * dominance_scores + 0.3 * diversity_scores\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Adaptive multi-objective swaps\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate dynamic weights based on solution quality\n        obj1_mean = np.mean(objectives[:, 0])\n        obj2_mean = np.mean(objectives[:, 1])\n        weight1 = 0.5 + 0.4 * (objectives[selected_idx][0] / (obj1_mean + 1e-10))\n        weight2 = 0.5 - 0.4 * (objectives[selected_idx][1] / (obj2_mean + 1e-10))\n\n        # Calculate efficiency with correlation adjustment\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n        correlations = np.corrcoef(value1_lst[included], value2_lst[included])[0, 1] if len(included) > 1 else 0.5\n        efficiency *= (1 + 0.3 * correlations)\n\n        # Find best swap candidates\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.5, 0.3, 0.2] if len(top_candidates) == 3 else [0.7, 0.3])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Greedy insertion phase\n    remaining_capacity = capacity - current_weight\n    excluded = np.where(new_solution == 0)[0]\n\n    # Sort excluded items by efficiency\n    efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n    sorted_excluded = sorted(excluded, key=lambda x: -efficiency[x])\n\n    for j in sorted_excluded:\n        if weight_lst[j] <= remaining_capacity:\n            new_solution[j] = 1\n            remaining_capacity -= weight_lst[j]\n\n    return new_solution\n\n",
        "score": [
            -13.807267258730837,
            -13.788593516706634
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest dominance and diversity\n    objectives = np.array([obj for _, obj in archive])\n    dominance_scores = np.zeros(len(archive))\n    for i in range(len(archive)):\n        dominated = 0\n        for j in range(len(archive)):\n            if i != j and objectives[j][0] >= objectives[i][0] and objectives[j][1] >= objectives[i][1]:\n                dominated += 1\n        dominance_scores[i] = dominated\n\n    diversity_scores = np.zeros(len(archive))\n    for i in range(len(archive)):\n        distances = np.sum(np.abs(objectives[i] - objectives), axis=1)\n        diversity_scores[i] = np.mean(distances)\n\n    selection_score = 0.7 * dominance_scores + 0.3 * diversity_scores\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Adaptive multi-objective swaps\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate dynamic weights based on solution quality\n        obj1_mean = np.mean(objectives[:, 0])\n        obj2_mean = np.mean(objectives[:, 1])\n        weight1 = 0.5 + 0.4 * (objectives[selected_idx][0] / (obj1_mean + 1e-10))\n        weight2 = 0.5 - 0.4 * (objectives[selected_idx][1] / (obj2_mean + 1e-10))\n\n        # Calculate efficiency with correlation adjustment\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n        correlations = np.corrcoef(value1_lst[included], value2_lst[included])[0, 1] if len(included) > 1 else 0.5\n        efficiency *= (1 + 0.3 * correlations)\n\n        # Find best swap candidates\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.5, 0.3, 0.2] if len(top_candidates) == 3 else [0.7, 0.3])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Greedy insertion phase\n    remaining_capacity = capacity - current_weight\n    excluded = np.where(new_solution == 0)[0]\n\n    # Sort excluded items by efficiency\n    efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n    sorted_excluded = sorted(excluded, key=lambda x: -efficiency[x])\n\n    for j in sorted_excluded:\n        if weight_lst[j] <= remaining_capacity:\n            new_solution[j] = 1\n            remaining_capacity -= weight_lst[j]\n\n    return new_solution\n\n"
    }
]