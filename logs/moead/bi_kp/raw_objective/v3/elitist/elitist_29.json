[
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on a combination of objective correlation and marginal improvement potential, then applies a hybrid local search strategy that uses value-correlation-aware swaps with adaptive neighborhood exploration and probabilistic acceptance, incorporating dynamic objective weighting and diversity-aware item selection to balance exploration and exploitation while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest correlation and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    correlations = np.corrcoef(objectives.T)[0, 1] if len(archive) > 1 else 0.5\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.4 * correlations * potential\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-correlation-aware swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate dynamic weights based on correlation\n        weight1 = 0.5 + 0.3 * correlations\n        weight2 = 0.5 - 0.3 * correlations\n\n        # Calculate weighted efficiency with correlation adjustment\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n        efficiency *= (1 + 0.2 * correlations)\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.5, 0.3, 0.2] if len(top_candidates) == 3 else [0.7, 0.3])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Diversity-aware neighborhood exploration\n    exploration_depth = min(5, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on diversity\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.8, 1 - value_contribution / (np.max(efficiency) + 1e-10) * (1 - correlations)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and diversity\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.2, min(0.9, efficiency[idx] / (np.max(efficiency) + 1e-10) * (1 + 0.3 * correlations)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -16.794114853862368,
            -19.594996208612528
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on a combination of objective diversity and marginal improvement potential, then applies a hybrid local search strategy that uses value-weighted swaps with adaptive neighborhood exploration and probabilistic acceptance, incorporating dynamic objective weighting and correlation-aware item selection to balance exploration and exploitation while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest diversity and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    diversity = np.std(objectives, axis=0)\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.5 * np.sum(diversity * objectives, axis=1)\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-weighted swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value ratios and dynamic weights\n        ratio = np.mean(value2_lst[included] / (value1_lst[included] + 1e-10)) if len(included) > 1 else 0.5\n        weight1 = 0.5 + 0.4 * ratio\n        weight2 = 0.5 - 0.4 * ratio\n\n        # Calculate weighted efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            # Select top 2 candidates and choose one based on gain and randomness\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(2, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.7, 0.3] if len(top_candidates) == 2 else [1.0])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Adaptive neighborhood exploration with probabilistic acceptance\n    exploration_depth = min(4, n_items // 3)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on weighted value\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.8, 1 - value_contribution / (np.max(efficiency) + 1e-10)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and remaining capacity\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.2, min(0.9, efficiency[idx] / (np.max(efficiency) + 1e-10)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -20.20679173461559,
            -16.173156077616113
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on a combination of objective correlation and marginal improvement potential, then applies a hybrid local search strategy that uses value-correlation-aware swaps with adaptive neighborhood exploration and probabilistic acceptance, incorporating dynamic objective weighting and diversity-aware item selection to balance exploration and exploitation while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest correlation and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    correlations = np.corrcoef(objectives.T)[0, 1] if len(archive) > 1 else 0.5\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.4 * correlations * potential\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-correlation-aware swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate dynamic weights based on correlation\n        weight1 = 0.5 + 0.3 * correlations\n        weight2 = 0.5 - 0.3 * correlations\n\n        # Calculate weighted efficiency with correlation adjustment\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n        efficiency *= (1 + 0.2 * correlations)\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.5, 0.3, 0.2] if len(top_candidates) == 3 else [0.7, 0.3])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Diversity-aware neighborhood exploration\n    exploration_depth = min(5, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on diversity\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.8, 1 - value_contribution / (np.max(efficiency) + 1e-10) * (1 - correlations)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and diversity\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.2, min(0.9, efficiency[idx] / (np.max(efficiency) + 1e-10) * (1 + 0.3 * correlations)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -16.794114853862368,
            -19.594996208612528
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on a combination of objective diversity and marginal improvement potential, then applies a hybrid local search strategy that uses value-weighted swaps with adaptive neighborhood exploration and probabilistic acceptance, incorporating dynamic objective weighting and correlation-aware item selection to balance exploration and exploitation while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest diversity and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    diversity = np.std(objectives, axis=0)\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.5 * np.sum(diversity * objectives, axis=1)\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-weighted swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value ratios and dynamic weights\n        ratio = np.mean(value2_lst[included] / (value1_lst[included] + 1e-10)) if len(included) > 1 else 0.5\n        weight1 = 0.5 + 0.4 * ratio\n        weight2 = 0.5 - 0.4 * ratio\n\n        # Calculate weighted efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            # Select top 2 candidates and choose one based on gain and randomness\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(2, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.7, 0.3] if len(top_candidates) == 2 else [1.0])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Adaptive neighborhood exploration with probabilistic acceptance\n    exploration_depth = min(4, n_items // 3)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on weighted value\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.8, 1 - value_contribution / (np.max(efficiency) + 1e-10)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and remaining capacity\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.2, min(0.9, efficiency[idx] / (np.max(efficiency) + 1e-10)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -20.20679173461559,
            -16.173156077616113
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on a combination of objective correlation and marginal improvement potential, then applies a hybrid local search strategy that uses value-correlation-aware swaps with adaptive neighborhood exploration and probabilistic acceptance, incorporating dynamic objective weighting and diversity-aware item selection to balance exploration and exploitation while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest correlation and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    correlations = np.corrcoef(objectives.T)[0, 1] if len(archive) > 1 else 0.5\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.4 * correlations * potential\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-correlation-aware swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate dynamic weights based on correlation\n        weight1 = 0.5 + 0.3 * correlations\n        weight2 = 0.5 - 0.3 * correlations\n\n        # Calculate weighted efficiency with correlation adjustment\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n        efficiency *= (1 + 0.2 * correlations)\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.5, 0.3, 0.2] if len(top_candidates) == 3 else [0.7, 0.3])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Diversity-aware neighborhood exploration\n    exploration_depth = min(5, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on diversity\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.8, 1 - value_contribution / (np.max(efficiency) + 1e-10) * (1 - correlations)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and diversity\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.2, min(0.9, efficiency[idx] / (np.max(efficiency) + 1e-10) * (1 + 0.3 * correlations)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -16.933650875099076,
            -19.49164683866662
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel local search strategy that combines multi-objective value-aware swaps with adaptive neighborhood exploration, using a hybrid of value correlation analysis and dynamic weight adjustment, but incorporates a probabilistic acceptance criterion to explore diverse neighborhoods while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.sum(objectives, axis=1)\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Multi-objective value-aware swaps with probabilistic acceptance\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value correlations and dynamic weights\n        corr = np.corrcoef(value1_lst[included], value2_lst[included])[0, 1] if len(included) > 1 else 0\n        if np.isnan(corr):\n            corr = 0\n\n        # Dynamic weight adjustment based on correlation\n        weight1 = 0.5 + 0.4 * corr\n        weight2 = 0.5 - 0.4 * corr\n\n        # Calculate combined value efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            # Select top 3 candidates and choose one probabilistically\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.6, 0.3, 0.1] if len(top_candidates) == 3 else [0.7, 0.3])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Adaptive neighborhood exploration with dynamic depth and probabilistic acceptance\n    exploration_depth = min(5, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on value contribution\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.9, 1 - value_contribution / (np.max(efficiency) + 1e-10)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.1, min(0.9, efficiency[idx] / (np.max(efficiency) + 1e-10)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -17.414638126326913,
            -19.000523823906143
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on a combination of objective correlation and marginal improvement potential, then applies a hybrid local search strategy that uses value-correlation-aware swaps with adaptive neighborhood exploration and probabilistic acceptance, incorporating dynamic objective weighting and diversity-aware item selection to balance exploration and exploitation while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest correlation and potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    correlations = np.corrcoef(objectives.T)[0, 1] if len(archive) > 1 else 0.5\n    potential = np.sum(objectives, axis=1)\n    selection_score = potential + 0.4 * correlations * potential\n    selected_idx = np.argmax(selection_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-correlation-aware swaps with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate dynamic weights based on correlation\n        weight1 = 0.5 + 0.3 * correlations\n        weight2 = 0.5 - 0.3 * correlations\n\n        # Calculate weighted efficiency with correlation adjustment\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n        efficiency *= (1 + 0.2 * correlations)\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.5, 0.3, 0.2] if len(top_candidates) == 3 else [0.7, 0.3])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Diversity-aware neighborhood exploration\n    exploration_depth = min(5, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on diversity\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.8, 1 - value_contribution / (np.max(efficiency) + 1e-10) * (1 - correlations)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency and diversity\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.2, min(0.9, efficiency[idx] / (np.max(efficiency) + 1e-10) * (1 + 0.3 * correlations)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -16.794114853862368,
            -19.594996208612528
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel local search strategy that combines multi-objective value-aware swaps with adaptive neighborhood exploration, using a hybrid of value correlation analysis and dynamic weight adjustment, but incorporates a probabilistic acceptance criterion to explore diverse neighborhoods while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.sum(objectives, axis=1)\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Multi-objective value-aware swaps with probabilistic acceptance\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value correlations and dynamic weights\n        corr = np.corrcoef(value1_lst[included], value2_lst[included])[0, 1] if len(included) > 1 else 0\n        if np.isnan(corr):\n            corr = 0\n\n        # Dynamic weight adjustment based on correlation\n        weight1 = 0.5 + 0.4 * corr\n        weight2 = 0.5 - 0.4 * corr\n\n        # Calculate combined value efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            # Select top 3 candidates and choose one probabilistically\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.6, 0.3, 0.1] if len(top_candidates) == 3 else [0.7, 0.3])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Adaptive neighborhood exploration with dynamic depth and probabilistic acceptance\n    exploration_depth = min(5, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on value contribution\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.9, 1 - value_contribution / (np.max(efficiency) + 1e-10)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.1, min(0.9, efficiency[idx] / (np.max(efficiency) + 1e-10)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -17.698753242264786,
            -18.993117891632604
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel local search strategy that combines multi-objective value-aware swaps with adaptive neighborhood exploration, using a hybrid of value correlation analysis and dynamic weight adjustment, but incorporates a probabilistic acceptance criterion to explore diverse neighborhoods while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.sum(objectives, axis=1)\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Multi-objective value-aware swaps with probabilistic acceptance\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value correlations and dynamic weights\n        corr = np.corrcoef(value1_lst[included], value2_lst[included])[0, 1] if len(included) > 1 else 0\n        if np.isnan(corr):\n            corr = 0\n\n        # Dynamic weight adjustment based on correlation\n        weight1 = 0.5 + 0.4 * corr\n        weight2 = 0.5 - 0.4 * corr\n\n        # Calculate combined value efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            # Select top 3 candidates and choose one probabilistically\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.6, 0.3, 0.1] if len(top_candidates) == 3 else [0.7, 0.3])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Adaptive neighborhood exploration with dynamic depth and probabilistic acceptance\n    exploration_depth = min(5, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on value contribution\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.9, 1 - value_contribution / (np.max(efficiency) + 1e-10)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.1, min(0.9, efficiency[idx] / (np.max(efficiency) + 1e-10)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -17.414638126326913,
            -19.000523823906143
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel local search strategy that combines multi-objective value-aware swaps with adaptive neighborhood exploration, using a hybrid of value correlation analysis and dynamic weight adjustment, but incorporates a probabilistic acceptance criterion to explore diverse neighborhoods while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.sum(objectives, axis=1)\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Multi-objective value-aware swaps with probabilistic acceptance\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value correlations and dynamic weights\n        corr = np.corrcoef(value1_lst[included], value2_lst[included])[0, 1] if len(included) > 1 else 0\n        if np.isnan(corr):\n            corr = 0\n\n        # Dynamic weight adjustment based on correlation\n        weight1 = 0.5 + 0.4 * corr\n        weight2 = 0.5 - 0.4 * corr\n\n        # Calculate combined value efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            # Select top 3 candidates and choose one probabilistically\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.6, 0.3, 0.1] if len(top_candidates) == 3 else [0.7, 0.3])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Adaptive neighborhood exploration with dynamic depth and probabilistic acceptance\n    exploration_depth = min(5, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on value contribution\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.9, 1 - value_contribution / (np.max(efficiency) + 1e-10)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.1, min(0.9, efficiency[idx] / (np.max(efficiency) + 1e-10)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -17.698753242264786,
            -18.993117891632604
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel local search strategy that combines multi-objective value-aware swaps with adaptive neighborhood exploration, using a hybrid of value diversity and correlation analysis with dynamic weight adjustment to generate high-quality neighbor solutions while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.sum(objectives, axis=1)  # Sum of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Multi-objective value-aware swaps with diversity and correlation\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value diversity and correlation\n        std1 = np.std(value1_lst[included])\n        std2 = np.std(value2_lst[included])\n        diversity = std1 + std2\n\n        corr = np.corrcoef(value1_lst[included], value2_lst[included])[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # Dynamic weight adjustment based on diversity and correlation\n        weight1 = 0.5 + 0.3 * (diversity / (std1 + std2 + 1e-10)) + 0.2 * corr\n        weight2 = 0.5 - 0.3 * (diversity / (std1 + std2 + 1e-10)) - 0.2 * corr\n\n        # Calculate combined value efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best swap candidates\n        best_gain = -float('inf')\n        best_swap = (-1, -1)\n\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_swap = (i, j)\n\n        if best_swap[0] != -1 and best_swap[1] != -1:\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Adaptive neighborhood exploration with dynamic depth\n    exploration_depth = min(4, n_items // 4)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Try to remove item if it's not critical\n            if current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Try to add item if it fits\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -20.09610213745504,
            -16.871751765441996
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel local search strategy that combines multi-objective value-aware swaps with adaptive neighborhood exploration, using a hybrid of value diversity and correlation analysis with dynamic weight adjustment to generate high-quality neighbor solutions while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.sum(objectives, axis=1)  # Sum of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Multi-objective value-aware swaps with diversity and correlation\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value diversity and correlation\n        std1 = np.std(value1_lst[included])\n        std2 = np.std(value2_lst[included])\n        diversity = std1 + std2\n\n        corr = np.corrcoef(value1_lst[included], value2_lst[included])[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # Dynamic weight adjustment based on diversity and correlation\n        weight1 = 0.5 + 0.3 * (diversity / (std1 + std2 + 1e-10)) + 0.2 * corr\n        weight2 = 0.5 - 0.3 * (diversity / (std1 + std2 + 1e-10)) - 0.2 * corr\n\n        # Calculate combined value efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best swap candidates\n        best_gain = -float('inf')\n        best_swap = (-1, -1)\n\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_swap = (i, j)\n\n        if best_swap[0] != -1 and best_swap[1] != -1:\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Adaptive neighborhood exploration with dynamic depth\n    exploration_depth = min(4, n_items // 4)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Try to remove item if it's not critical\n            if current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Try to add item if it fits\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -20.07769655706536,
            -16.90110103149395
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel local search strategy that combines multi-objective value-aware swaps with adaptive neighborhood exploration, using a hybrid of value diversity and correlation analysis with dynamic weight adjustment to generate high-quality neighbor solutions while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.sum(objectives, axis=1)  # Sum of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Multi-objective value-aware swaps with diversity and correlation\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value diversity and correlation\n        std1 = np.std(value1_lst[included])\n        std2 = np.std(value2_lst[included])\n        diversity = std1 + std2\n\n        corr = np.corrcoef(value1_lst[included], value2_lst[included])[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # Dynamic weight adjustment based on diversity and correlation\n        weight1 = 0.5 + 0.3 * (diversity / (std1 + std2 + 1e-10)) + 0.2 * corr\n        weight2 = 0.5 - 0.3 * (diversity / (std1 + std2 + 1e-10)) - 0.2 * corr\n\n        # Calculate combined value efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best swap candidates\n        best_gain = -float('inf')\n        best_swap = (-1, -1)\n\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_swap = (i, j)\n\n        if best_swap[0] != -1 and best_swap[1] != -1:\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Adaptive neighborhood exploration with dynamic depth\n    exploration_depth = min(4, n_items // 4)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Try to remove item if it's not critical\n            if current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Try to add item if it fits\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -20.09610213745504,
            -16.871751765441996
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel local search strategy that combines multi-objective value-aware swaps with adaptive neighborhood exploration, using a hybrid of value correlation analysis and dynamic weight adjustment, but incorporates a probabilistic acceptance criterion to explore diverse neighborhoods while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.sum(objectives, axis=1)\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Multi-objective value-aware swaps with probabilistic acceptance\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value correlations and dynamic weights\n        corr = np.corrcoef(value1_lst[included], value2_lst[included])[0, 1] if len(included) > 1 else 0\n        if np.isnan(corr):\n            corr = 0\n\n        # Dynamic weight adjustment based on correlation\n        weight1 = 0.5 + 0.4 * corr\n        weight2 = 0.5 - 0.4 * corr\n\n        # Calculate combined value efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best swap candidates with probabilistic selection\n        candidates = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    candidates.append((i, j, gain))\n\n        if candidates:\n            # Select top 3 candidates and choose one probabilistically\n            candidates.sort(key=lambda x: -x[2])\n            top_candidates = candidates[:min(3, len(candidates))]\n            selected = np.random.choice(len(top_candidates), p=[0.6, 0.3, 0.1] if len(top_candidates) == 3 else [0.7, 0.3])\n            best_swap = top_candidates[selected]\n\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Adaptive neighborhood exploration with dynamic depth and probabilistic acceptance\n    exploration_depth = min(5, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on value contribution\n            value_contribution = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            remove_prob = max(0.1, min(0.9, 1 - value_contribution / (np.max(efficiency) + 1e-10)))\n\n            if np.random.rand() < remove_prob and current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on efficiency\n            if current_weight + weight_lst[idx] <= capacity:\n                add_prob = max(0.1, min(0.9, efficiency[idx] / (np.max(efficiency) + 1e-10)))\n                if np.random.rand() < add_prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -17.698753242264786,
            -18.993117891632604
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel local search strategy that combines multi-objective value-aware swaps with adaptive neighborhood exploration, using a hybrid of value diversity and correlation analysis with dynamic weight adjustment, but with modified parameters for the score function to prioritize high-value items more aggressively.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest potential improvement (modified to prioritize higher values)\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.sum(objectives ** 2, axis=1)  # Squared sum to emphasize high-value solutions\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Multi-objective value-aware swaps with modified parameters\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value diversity and correlation\n        std1 = np.std(value1_lst[included])\n        std2 = np.std(value2_lst[included])\n        diversity = std1 + std2\n\n        corr = np.corrcoef(value1_lst[included], value2_lst[included])[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # Modified dynamic weight adjustment (prioritize high-value items more)\n        weight1 = 0.6 + 0.2 * (diversity / (std1 + std2 + 1e-10)) + 0.2 * corr\n        weight2 = 0.4 - 0.2 * (diversity / (std1 + std2 + 1e-10)) - 0.2 * corr\n\n        # Calculate combined value efficiency with modified weights\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best swap candidates\n        best_gain = -float('inf')\n        best_swap = (-1, -1)\n\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_swap = (i, j)\n\n        if best_swap[0] != -1 and best_swap[1] != -1:\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Adaptive neighborhood exploration with modified depth\n    exploration_depth = min(6, n_items // 3)  # Increased depth\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Try to remove item if it's not critical (modified condition)\n            if current_weight - weight_lst[idx] >= capacity * 0.1:  # Keep at least 10% capacity\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Try to add item if it fits\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -19.76338210386764,
            -17.316608620475783
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel local search strategy that combines multi-objective value-aware swaps with adaptive neighborhood exploration, using a hybrid of value diversity and correlation analysis with dynamic weight adjustment to generate high-quality neighbor solutions while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.sum(objectives, axis=1)  # Sum of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Multi-objective value-aware swaps with diversity and correlation\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value diversity and correlation\n        std1 = np.std(value1_lst[included])\n        std2 = np.std(value2_lst[included])\n        diversity = std1 + std2\n\n        corr = np.corrcoef(value1_lst[included], value2_lst[included])[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # Dynamic weight adjustment based on diversity and correlation\n        weight1 = 0.5 + 0.3 * (diversity / (std1 + std2 + 1e-10)) + 0.2 * corr\n        weight2 = 0.5 - 0.3 * (diversity / (std1 + std2 + 1e-10)) - 0.2 * corr\n\n        # Calculate combined value efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best swap candidates\n        best_gain = -float('inf')\n        best_swap = (-1, -1)\n\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_swap = (i, j)\n\n        if best_swap[0] != -1 and best_swap[1] != -1:\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Adaptive neighborhood exploration with dynamic depth\n    exploration_depth = min(4, n_items // 4)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Try to remove item if it's not critical\n            if current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Try to add item if it fits\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -20.07769655706536,
            -16.90110103149395
        ]
    },
    {
        "algorithm": "{This new algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a hybrid local search strategy that combines adaptive value partitioning with dynamic neighborhood exploration, using a weighted correlation-aware swap mechanism to generate high-quality neighbor solutions while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.sum(objectives, axis=1)  # Sum of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Adaptive value partitioning with dynamic weights\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value correlation and partition weights\n        corr = np.corrcoef(value1_lst[included], value2_lst[included])[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # Dynamic weight adjustment based on correlation\n        weight1 = 0.5 + 0.4 * corr\n        weight2 = 0.5 - 0.4 * corr\n\n        # Calculate weighted value efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best swap candidates\n        best_gain = -float('inf')\n        best_swap = (-1, -1)\n\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_swap = (i, j)\n\n        if best_swap[0] != -1 and best_swap[1] != -1:\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Dynamic neighborhood exploration with value diversity\n    exploration_depth = min(5, n_items // 3)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Try to remove item if it's not critical\n            if current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Try to add item if it fits\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -18.55463938860497,
            -18.866683617789274
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel local search strategy that combines multi-objective value-aware swaps with adaptive neighborhood exploration, using a hybrid of value diversity and correlation analysis with dynamic weight adjustment to generate high-quality neighbor solutions while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.sum(objectives, axis=1)  # Sum of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Multi-objective value-aware swaps with diversity and correlation\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value diversity and correlation\n        std1 = np.std(value1_lst[included])\n        std2 = np.std(value2_lst[included])\n        diversity = std1 + std2\n\n        corr = np.corrcoef(value1_lst[included], value2_lst[included])[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # Dynamic weight adjustment based on diversity and correlation\n        weight1 = 0.5 + 0.3 * (diversity / (std1 + std2 + 1e-10)) + 0.2 * corr\n        weight2 = 0.5 - 0.3 * (diversity / (std1 + std2 + 1e-10)) - 0.2 * corr\n\n        # Calculate combined value efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best swap candidates\n        best_gain = -float('inf')\n        best_swap = (-1, -1)\n\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_swap = (i, j)\n\n        if best_swap[0] != -1 and best_swap[1] != -1:\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Adaptive neighborhood exploration with dynamic depth\n    exploration_depth = min(4, n_items // 4)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Try to remove item if it's not critical\n            if current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Try to add item if it fits\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -20.041638178167275,
            -17.07250710703434
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel local search strategy that combines multi-objective value-aware swaps with adaptive neighborhood exploration, using a hybrid of value diversity and correlation analysis with dynamic weight adjustment to generate high-quality neighbor solutions while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.sum(objectives, axis=1)  # Sum of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Multi-objective value-aware swaps with diversity and correlation\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value diversity and correlation\n        std1 = np.std(value1_lst[included])\n        std2 = np.std(value2_lst[included])\n        diversity = std1 + std2\n\n        corr = np.corrcoef(value1_lst[included], value2_lst[included])[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # Dynamic weight adjustment based on diversity and correlation\n        weight1 = 0.5 + 0.3 * (diversity / (std1 + std2 + 1e-10)) + 0.2 * corr\n        weight2 = 0.5 - 0.3 * (diversity / (std1 + std2 + 1e-10)) - 0.2 * corr\n\n        # Calculate combined value efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best swap candidates\n        best_gain = -float('inf')\n        best_swap = (-1, -1)\n\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_swap = (i, j)\n\n        if best_swap[0] != -1 and best_swap[1] != -1:\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Adaptive neighborhood exploration with dynamic depth\n    exploration_depth = min(4, n_items // 4)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Try to remove item if it's not critical\n            if current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Try to add item if it fits\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -20.07769655706536,
            -16.90110103149395
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel local search strategy that combines multi-objective value-aware swaps with adaptive neighborhood exploration, using a hybrid of value diversity and correlation analysis with dynamic weight adjustment to generate high-quality neighbor solutions while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.sum(objectives, axis=1)  # Sum of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Multi-objective value-aware swaps with diversity and correlation\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value diversity and correlation\n        std1 = np.std(value1_lst[included])\n        std2 = np.std(value2_lst[included])\n        diversity = std1 + std2\n\n        corr = np.corrcoef(value1_lst[included], value2_lst[included])[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # Dynamic weight adjustment based on diversity and correlation\n        weight1 = 0.5 + 0.3 * (diversity / (std1 + std2 + 1e-10)) + 0.2 * corr\n        weight2 = 0.5 - 0.3 * (diversity / (std1 + std2 + 1e-10)) - 0.2 * corr\n\n        # Calculate combined value efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best swap candidates\n        best_gain = -float('inf')\n        best_swap = (-1, -1)\n\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_swap = (i, j)\n\n        if best_swap[0] != -1 and best_swap[1] != -1:\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Adaptive neighborhood exploration with dynamic depth\n    exploration_depth = min(4, n_items // 4)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Try to remove item if it's not critical\n            if current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Try to add item if it fits\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -20.025861336626207,
            -17.116196390211286
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel local search strategy that combines multi-objective value-aware swaps with adaptive neighborhood exploration, using a hybrid of value diversity and correlation analysis with dynamic weight adjustment to generate high-quality neighbor solutions while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.sum(objectives, axis=1)  # Sum of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Multi-objective value-aware swaps with diversity and correlation\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value diversity and correlation\n        std1 = np.std(value1_lst[included])\n        std2 = np.std(value2_lst[included])\n        diversity = std1 + std2\n\n        corr = np.corrcoef(value1_lst[included], value2_lst[included])[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # Dynamic weight adjustment based on diversity and correlation\n        weight1 = 0.5 + 0.3 * (diversity / (std1 + std2 + 1e-10)) + 0.2 * corr\n        weight2 = 0.5 - 0.3 * (diversity / (std1 + std2 + 1e-10)) - 0.2 * corr\n\n        # Calculate combined value efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best swap candidates\n        best_gain = -float('inf')\n        best_swap = (-1, -1)\n\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_swap = (i, j)\n\n        if best_swap[0] != -1 and best_swap[1] != -1:\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Adaptive neighborhood exploration with dynamic depth\n    exploration_depth = min(4, n_items // 4)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Try to remove item if it's not critical\n            if current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Try to add item if it fits\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -20.07769655706536,
            -16.90110103149395
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel local search strategy that combines multi-objective value-aware swaps with adaptive neighborhood exploration, using a hybrid of value correlation analysis and dynamic weight adjustment to generate high-quality neighbor solutions while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.sum(objectives, axis=1)  # Sum of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Multi-objective value-aware swaps\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value correlations and dynamic weights\n        corr = np.corrcoef(value1_lst[included], value2_lst[included])[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # Dynamic weight adjustment based on correlation\n        weight1 = 0.5 + 0.4 * corr\n        weight2 = 0.5 - 0.4 * corr\n\n        # Calculate combined value efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best swap candidates\n        best_gain = -float('inf')\n        best_swap = (-1, -1)\n\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_swap = (i, j)\n\n        if best_swap[0] != -1 and best_swap[1] != -1:\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Adaptive neighborhood exploration with dynamic depth\n    exploration_depth = min(5, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Try to remove item if it's not critical\n            if current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Try to add item if it fits\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -18.4816682835023,
            -18.899775500201898
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel local search strategy that combines multi-objective value-aware swaps with adaptive neighborhood exploration, using a hybrid of value diversity and correlation analysis with dynamic weight adjustment to generate high-quality neighbor solutions while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.sum(objectives, axis=1)  # Sum of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Multi-objective value-aware swaps with diversity and correlation\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value diversity and correlation\n        std1 = np.std(value1_lst[included])\n        std2 = np.std(value2_lst[included])\n        diversity = std1 + std2\n\n        corr = np.corrcoef(value1_lst[included], value2_lst[included])[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # Dynamic weight adjustment based on diversity and correlation\n        weight1 = 0.5 + 0.3 * (diversity / (std1 + std2 + 1e-10)) + 0.2 * corr\n        weight2 = 0.5 - 0.3 * (diversity / (std1 + std2 + 1e-10)) - 0.2 * corr\n\n        # Calculate combined value efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best swap candidates\n        best_gain = -float('inf')\n        best_swap = (-1, -1)\n\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_swap = (i, j)\n\n        if best_swap[0] != -1 and best_swap[1] != -1:\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Adaptive neighborhood exploration with dynamic depth\n    exploration_depth = min(4, n_items // 4)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Try to remove item if it's not critical\n            if current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Try to add item if it fits\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -20.07769655706536,
            -16.90110103149395
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel local search strategy that combines multi-objective value-aware swaps with adaptive neighborhood exploration, using a hybrid of value correlation analysis and dynamic weight adjustment to generate high-quality neighbor solutions while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.sum(objectives, axis=1)  # Sum of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Multi-objective value-aware swaps with adaptive depth\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value correlations and dynamic weights\n        corr = np.corrcoef(value1_lst[included], value2_lst[included])[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # Dynamic weight adjustment based on correlation\n        weight1 = 0.5 + 0.4 * corr\n        weight2 = 0.5 - 0.4 * corr\n\n        # Calculate combined value efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best swap candidates with adaptive depth\n        swap_depth = min(10, len(included) // 2)\n        best_swaps = []\n\n        for i in np.random.choice(included, swap_depth, replace=False):\n            for j in np.random.choice(excluded, swap_depth, replace=False):\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    best_swaps.append((gain, i, j))\n\n        if best_swaps:\n            best_swaps.sort(reverse=True, key=lambda x: x[0])\n            best_gain, i, j = best_swaps[0]\n            new_solution[i] = 0\n            new_solution[j] = 1\n            current_weight = current_weight - weight_lst[i] + weight_lst[j]\n\n    # Step 2: Adaptive neighborhood exploration with dynamic depth and probabilistic acceptance\n    exploration_depth = min(8, n_items // 3)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Probabilistic removal based on value efficiency\n            if current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add and np.random.rand() < 0.7:  # 70% chance to accept removal\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Probabilistic addition based on value efficiency\n            if current_weight + weight_lst[idx] <= capacity:\n                if np.random.rand() < 0.6:  # 60% chance to accept addition\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -18.61782966113916,
            -18.86220764927375
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel local search strategy that combines multi-objective value-aware swaps with adaptive neighborhood exploration, using a hybrid of value correlation analysis and dynamic weight adjustment to generate high-quality neighbor solutions while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.sum(objectives, axis=1)  # Sum of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Multi-objective value-aware swaps\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value correlations and dynamic weights\n        corr = np.corrcoef(value1_lst[included], value2_lst[included])[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # Dynamic weight adjustment based on correlation\n        weight1 = 0.5 + 0.4 * corr\n        weight2 = 0.5 - 0.4 * corr\n\n        # Calculate combined value efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best swap candidates\n        best_gain = -float('inf')\n        best_swap = (-1, -1)\n\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_swap = (i, j)\n\n        if best_swap[0] != -1 and best_swap[1] != -1:\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Adaptive neighborhood exploration with dynamic depth\n    exploration_depth = min(5, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Try to remove item if it's not critical\n            if current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Try to add item if it fits\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -18.4816682835023,
            -18.899775500201898
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on a hybrid score combining normalized objective values and diversity metrics, then applies a multi-phase local search strategy with value-correlation-aware perturbations, adaptive neighborhood exploration, and probabilistic item swaps to generate a high-quality neighbor solution while maintaining feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution based on hybrid score combining normalized objectives and diversity\n    objectives = np.array([obj for _, obj in archive])\n    max_obj = np.max(objectives, axis=0)\n    normalized_obj = objectives / (max_obj + 1e-10)\n    diversity = np.std(normalized_obj, axis=0)\n    hybrid_score = np.sum(normalized_obj * (1 + 0.5 * diversity), axis=1)\n    selected_idx = np.argmax(hybrid_score)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Phase 1: Value-correlation-aware perturbations\n    corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n    if np.isnan(corr):\n        corr = 0\n\n    if np.random.rand() < 0.7:\n        num_perturb = min(3, n_items)\n        perturb_indices = np.random.choice(n_items, num_perturb, replace=False)\n\n        for idx in perturb_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Phase 2: Adaptive neighborhood exploration\n    if np.random.rand() < 0.6:\n        efficiency = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        sorted_indices = np.argsort(efficiency)[::-1]\n\n        for idx in sorted_indices:\n            if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                break\n\n    # Phase 3: Probabilistic item swaps\n    if np.random.rand() < 0.4:\n        included = np.where(new_solution == 1)[0]\n        excluded = np.where(new_solution == 0)[0]\n\n        if len(included) > 0 and len(excluded) > 0:\n            out_idx = np.random.choice(included)\n            potential_in = [idx for idx in excluded if current_weight - weight_lst[out_idx] + weight_lst[idx] <= capacity]\n\n            if potential_in:\n                in_idx = np.random.choice(potential_in)\n                new_solution[out_idx] = 0\n                new_solution[in_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.169883536256172,
            -18.600634623005796
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel local search strategy that combines multi-objective value-aware swaps with adaptive neighborhood exploration, using a hybrid of value correlation analysis and dynamic weight adjustment to generate high-quality neighbor solutions while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.sum(objectives, axis=1)  # Sum of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Multi-objective value-aware swaps\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value correlations and dynamic weights\n        corr = np.corrcoef(value1_lst[included], value2_lst[included])[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # Dynamic weight adjustment based on correlation\n        weight1 = 0.5 + 0.4 * corr\n        weight2 = 0.5 - 0.4 * corr\n\n        # Calculate combined value efficiency\n        efficiency = (weight1 * value1_lst + weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Find best swap candidates\n        best_gain = -float('inf')\n        best_swap = (-1, -1)\n\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * weight1 + (value2_lst[j] - value2_lst[i]) * weight2\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_swap = (i, j)\n\n        if best_swap[0] != -1 and best_swap[1] != -1:\n            new_solution[best_swap[0]] = 0\n            new_solution[best_swap[1]] = 1\n            current_weight = current_weight - weight_lst[best_swap[0]] + weight_lst[best_swap[1]]\n\n    # Step 2: Adaptive neighborhood exploration with dynamic depth\n    exploration_depth = min(5, n_items // 2)\n    explore_indices = np.random.choice(n_items, exploration_depth, replace=False)\n\n    for idx in explore_indices:\n        if new_solution[idx] == 1:\n            # Try to remove item if it's not critical\n            if current_weight - weight_lst[idx] >= 0:\n                temp_weight = current_weight - weight_lst[idx]\n                # Check if removing this item allows adding better items\n                can_add = False\n                for j in excluded:\n                    if temp_weight + weight_lst[j] <= capacity:\n                        can_add = True\n                        break\n                if can_add:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n        else:\n            # Try to add item if it fits\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -18.4816682835023,
            -18.899775500201898
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a hybrid local search strategy combining adaptive value-aware item selection with correlation-aware perturbations and diversity-weighted neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement using weighted sum\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.random.dirichlet([1, 1])\n    potential = np.dot(objectives, weights)\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Adaptive value-aware item selection with correlation consideration\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value correlations between objectives\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # Adjust selection based on correlation\n        if corr > 0.5:\n            # Strong positive correlation - focus on both objectives equally\n            value_ratio = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        else:\n            # Weak or negative correlation - use random weighted combination\n            weights = np.random.dirichlet([1, 1])\n            value_ratio = weights[0] * value1_lst + weights[1] * value2_lst\n            value_ratio = value_ratio / (weight_lst + 1e-10)\n\n        # Select top k items to consider for removal\n        k = min(3, len(included))\n        worst_items = np.argsort(value_ratio[included])[:k]\n\n        for i in included[worst_items]:\n            # Try to replace with best possible item from excluded\n            best_gain = -float('inf')\n            best_idx = -1\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) + (value2_lst[j] - value2_lst[i])\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_idx = j\n\n            if best_idx != -1:\n                new_solution[i] = 0\n                new_solution[best_idx] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_idx]\n                break\n\n    # Step 2: Correlation-aware neighborhood exploration\n    corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n    if np.isnan(corr):\n        corr = 0\n\n    if corr > 0.3:\n        # More exploration when objectives are correlated\n        num_explorations = min(5, n_items)\n        explore_indices = np.random.choice(n_items, num_explorations, replace=False)\n\n        for idx in explore_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n    else:\n        # More focused exploration when objectives are not correlated\n        num_explorations = min(2, n_items)\n        explore_indices = np.random.choice(n_items, num_explorations, replace=False)\n\n        for idx in explore_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Diversity-weighted local improvement\n    if np.random.rand() < 0.7:\n        # Calculate diversity-weighted efficiency\n        diversity_weight = np.random.uniform(0.2, 0.8)\n        efficiency1 = value1_lst / (weight_lst + 1e-10)\n        efficiency2 = value2_lst / (weight_lst + 1e-10)\n        combined_efficiency = diversity_weight * efficiency1 + (1 - diversity_weight) * efficiency2\n\n        # Select top item to add\n        best_idx = -1\n        best_efficiency = -float('inf')\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                if combined_efficiency[idx] > best_efficiency:\n                    best_efficiency = combined_efficiency[idx]\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.23967517337746,
            -18.365748727411074
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel hybrid local search strategy combining value-aware item selection with diversity-aware perturbations and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement in both objectives\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.prod(objectives, axis=1)  # Product of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-aware item selection with diversity consideration\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate normalized value ratios for both objectives\n        value_ratio1 = value1_lst / (weight_lst + 1e-10)\n        value_ratio2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine ratios with diversity weighting\n        diversity_weight = np.random.uniform(0.3, 0.7)\n        combined_ratio = diversity_weight * value_ratio1 + (1 - diversity_weight) * value_ratio2\n\n        # Select top k items to consider for removal\n        k = min(5, len(included))\n        worst_items = np.argsort(combined_ratio[included])[:k]\n\n        for i in included[worst_items]:\n            # Try to replace with best possible item from excluded\n            best_gain = -float('inf')\n            best_idx = -1\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * (value2_lst[j] - value2_lst[i])\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_idx = j\n\n            if best_idx != -1:\n                new_solution[i] = 0\n                new_solution[best_idx] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_idx]\n                break\n\n    # Step 2: Adaptive neighborhood exploration with value correlation\n    if np.random.rand() < 0.5:\n        # Calculate value correlations between objectives\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # More exploration when objectives are correlated\n        num_explorations = min(3, n_items)\n        explore_indices = np.random.choice(n_items, num_explorations, replace=False)\n\n        for idx in explore_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Local improvement with value-aware greedy selection\n    if np.random.rand() < 0.6:\n        # Calculate value efficiency for both objectives\n        efficiency1 = value1_lst / (weight_lst + 1e-10)\n        efficiency2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine efficiencies with random weights\n        random_weights = np.random.dirichlet([1, 1])\n        combined_efficiency = random_weights[0] * efficiency1 + random_weights[1] * efficiency2\n\n        # Select top item to add\n        best_idx = -1\n        best_efficiency = -float('inf')\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                if combined_efficiency[idx] > best_efficiency:\n                    best_efficiency = combined_efficiency[idx]\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.701311892881797,
            -18.788977089621042
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel hybrid local search strategy combining value-aware item selection with diversity-aware perturbations and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement in both objectives\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.prod(objectives, axis=1)  # Product of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-aware item selection with diversity consideration\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate normalized value ratios for both objectives\n        value_ratio1 = value1_lst / (weight_lst + 1e-10)\n        value_ratio2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine ratios with diversity weighting\n        diversity_weight = np.random.uniform(0.3, 0.7)\n        combined_ratio = diversity_weight * value_ratio1 + (1 - diversity_weight) * value_ratio2\n\n        # Select top k items to consider for removal\n        k = min(5, len(included))\n        worst_items = np.argsort(combined_ratio[included])[:k]\n\n        for i in included[worst_items]:\n            # Try to replace with best possible item from excluded\n            best_gain = -float('inf')\n            best_idx = -1\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * (value2_lst[j] - value2_lst[i])\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_idx = j\n\n            if best_idx != -1:\n                new_solution[i] = 0\n                new_solution[best_idx] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_idx]\n                break\n\n    # Step 2: Adaptive neighborhood exploration with value correlation\n    if np.random.rand() < 0.5:\n        # Calculate value correlations between objectives\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # More exploration when objectives are correlated\n        num_explorations = min(3, n_items)\n        explore_indices = np.random.choice(n_items, num_explorations, replace=False)\n\n        for idx in explore_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Local improvement with value-aware greedy selection\n    if np.random.rand() < 0.6:\n        # Calculate value efficiency for both objectives\n        efficiency1 = value1_lst / (weight_lst + 1e-10)\n        efficiency2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine efficiencies with random weights\n        random_weights = np.random.dirichlet([1, 1])\n        combined_efficiency = random_weights[0] * efficiency1 + random_weights[1] * efficiency2\n\n        # Select top item to add\n        best_idx = -1\n        best_efficiency = -float('inf')\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                if combined_efficiency[idx] > best_efficiency:\n                    best_efficiency = combined_efficiency[idx]\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.701311892881797,
            -18.788977089621042
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel hybrid local search strategy combining value-aware item selection with diversity-aware perturbations and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement in both objectives\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.prod(objectives, axis=1)  # Product of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-aware item selection with diversity consideration\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate normalized value ratios for both objectives\n        value_ratio1 = value1_lst / (weight_lst + 1e-10)\n        value_ratio2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine ratios with diversity weighting\n        diversity_weight = np.random.uniform(0.3, 0.7)\n        combined_ratio = diversity_weight * value_ratio1 + (1 - diversity_weight) * value_ratio2\n\n        # Select top k items to consider for removal\n        k = min(5, len(included))\n        worst_items = np.argsort(combined_ratio[included])[:k]\n\n        for i in included[worst_items]:\n            # Try to replace with best possible item from excluded\n            best_gain = -float('inf')\n            best_idx = -1\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * (value2_lst[j] - value2_lst[i])\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_idx = j\n\n            if best_idx != -1:\n                new_solution[i] = 0\n                new_solution[best_idx] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_idx]\n                break\n\n    # Step 2: Adaptive neighborhood exploration with value correlation\n    if np.random.rand() < 0.5:\n        # Calculate value correlations between objectives\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # More exploration when objectives are correlated\n        num_explorations = min(3, n_items)\n        explore_indices = np.random.choice(n_items, num_explorations, replace=False)\n\n        for idx in explore_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Local improvement with value-aware greedy selection\n    if np.random.rand() < 0.6:\n        # Calculate value efficiency for both objectives\n        efficiency1 = value1_lst / (weight_lst + 1e-10)\n        efficiency2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine efficiencies with random weights\n        random_weights = np.random.dirichlet([1, 1])\n        combined_efficiency = random_weights[0] * efficiency1 + random_weights[1] * efficiency2\n\n        # Select top item to add\n        best_idx = -1\n        best_efficiency = -float('inf')\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                if combined_efficiency[idx] > best_efficiency:\n                    best_efficiency = combined_efficiency[idx]\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.701311892881797,
            -18.788977089621042
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel hybrid local search strategy combining value-aware item selection with diversity-aware perturbations and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement in both objectives\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.prod(objectives, axis=1)  # Product of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-aware item selection with diversity consideration\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate normalized value ratios for both objectives\n        value_ratio1 = value1_lst / (weight_lst + 1e-10)\n        value_ratio2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine ratios with diversity weighting\n        diversity_weight = np.random.uniform(0.3, 0.7)\n        combined_ratio = diversity_weight * value_ratio1 + (1 - diversity_weight) * value_ratio2\n\n        # Select top k items to consider for removal\n        k = min(5, len(included))\n        worst_items = np.argsort(combined_ratio[included])[:k]\n\n        for i in included[worst_items]:\n            # Try to replace with best possible item from excluded\n            best_gain = -float('inf')\n            best_idx = -1\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * (value2_lst[j] - value2_lst[i])\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_idx = j\n\n            if best_idx != -1:\n                new_solution[i] = 0\n                new_solution[best_idx] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_idx]\n                break\n\n    # Step 2: Adaptive neighborhood exploration with value correlation\n    if np.random.rand() < 0.5:\n        # Calculate value correlations between objectives\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # More exploration when objectives are correlated\n        num_explorations = min(3, n_items)\n        explore_indices = np.random.choice(n_items, num_explorations, replace=False)\n\n        for idx in explore_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Local improvement with value-aware greedy selection\n    if np.random.rand() < 0.6:\n        # Calculate value efficiency for both objectives\n        efficiency1 = value1_lst / (weight_lst + 1e-10)\n        efficiency2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine efficiencies with random weights\n        random_weights = np.random.dirichlet([1, 1])\n        combined_efficiency = random_weights[0] * efficiency1 + random_weights[1] * efficiency2\n\n        # Select top item to add\n        best_idx = -1\n        best_efficiency = -float('inf')\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                if combined_efficiency[idx] > best_efficiency:\n                    best_efficiency = combined_efficiency[idx]\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.701311892881797,
            -18.788977089621042
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel hybrid local search strategy combining value-aware item selection with diversity-aware perturbations and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement in both objectives\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.prod(objectives, axis=1)  # Product of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-aware item selection with diversity consideration\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate normalized value ratios for both objectives\n        value_ratio1 = value1_lst / (weight_lst + 1e-10)\n        value_ratio2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine ratios with diversity weighting\n        diversity_weight = np.random.uniform(0.3, 0.7)\n        combined_ratio = diversity_weight * value_ratio1 + (1 - diversity_weight) * value_ratio2\n\n        # Select top k items to consider for removal\n        k = min(5, len(included))\n        worst_items = np.argsort(combined_ratio[included])[:k]\n\n        for i in included[worst_items]:\n            # Try to replace with best possible item from excluded\n            best_gain = -float('inf')\n            best_idx = -1\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * (value2_lst[j] - value2_lst[i])\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_idx = j\n\n            if best_idx != -1:\n                new_solution[i] = 0\n                new_solution[best_idx] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_idx]\n                break\n\n    # Step 2: Adaptive neighborhood exploration with value correlation\n    if np.random.rand() < 0.5:\n        # Calculate value correlations between objectives\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # More exploration when objectives are correlated\n        num_explorations = min(3, n_items)\n        explore_indices = np.random.choice(n_items, num_explorations, replace=False)\n\n        for idx in explore_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Local improvement with value-aware greedy selection\n    if np.random.rand() < 0.6:\n        # Calculate value efficiency for both objectives\n        efficiency1 = value1_lst / (weight_lst + 1e-10)\n        efficiency2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine efficiencies with random weights\n        random_weights = np.random.dirichlet([1, 1])\n        combined_efficiency = random_weights[0] * efficiency1 + random_weights[1] * efficiency2\n\n        # Select top item to add\n        best_idx = -1\n        best_efficiency = -float('inf')\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                if combined_efficiency[idx] > best_efficiency:\n                    best_efficiency = combined_efficiency[idx]\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.701311892881797,
            -18.788977089621042
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel hybrid local search strategy combining value-aware item selection with diversity-aware perturbations and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement in both objectives\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.prod(objectives, axis=1)  # Product of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-aware item selection with diversity consideration\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate normalized value ratios for both objectives\n        value_ratio1 = value1_lst / (weight_lst + 1e-10)\n        value_ratio2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine ratios with diversity weighting\n        diversity_weight = np.random.uniform(0.3, 0.7)\n        combined_ratio = diversity_weight * value_ratio1 + (1 - diversity_weight) * value_ratio2\n\n        # Select top k items to consider for removal\n        k = min(5, len(included))\n        worst_items = np.argsort(combined_ratio[included])[:k]\n\n        for i in included[worst_items]:\n            # Try to replace with best possible item from excluded\n            best_gain = -float('inf')\n            best_idx = -1\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * (value2_lst[j] - value2_lst[i])\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_idx = j\n\n            if best_idx != -1:\n                new_solution[i] = 0\n                new_solution[best_idx] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_idx]\n                break\n\n    # Step 2: Adaptive neighborhood exploration with value correlation\n    if np.random.rand() < 0.5:\n        # Calculate value correlations between objectives\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # More exploration when objectives are correlated\n        num_explorations = min(3, n_items)\n        explore_indices = np.random.choice(n_items, num_explorations, replace=False)\n\n        for idx in explore_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Local improvement with value-aware greedy selection\n    if np.random.rand() < 0.6:\n        # Calculate value efficiency for both objectives\n        efficiency1 = value1_lst / (weight_lst + 1e-10)\n        efficiency2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine efficiencies with random weights\n        random_weights = np.random.dirichlet([1, 1])\n        combined_efficiency = random_weights[0] * efficiency1 + random_weights[1] * efficiency2\n\n        # Select top item to add\n        best_idx = -1\n        best_efficiency = -float('inf')\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                if combined_efficiency[idx] > best_efficiency:\n                    best_efficiency = combined_efficiency[idx]\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.701311892881797,
            -18.788977089621042
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive with high potential for improvement in both objectives, then applies a hybrid local search strategy combining value-aware item replacement with adaptive neighborhood exploration and correlation-aware perturbations to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with high potential for improvement (highest sum of objectives)\n    objectives = np.array([obj for _, obj in archive])\n    selected_idx = np.argmax(np.sum(objectives, axis=1))\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-aware item replacement with correlation consideration\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value correlations\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # Weighted value efficiency based on correlation\n        efficiency = (1 - abs(corr)) * value1_lst + abs(corr) * value2_lst\n        efficiency /= (weight_lst + 1e-10)\n\n        # Find worst items to consider for removal\n        k = min(3, len(included))\n        worst_items = np.argsort(efficiency[included])[:k]\n\n        for i in included[worst_items]:\n            # Find best replacement item\n            best_gain = -float('inf')\n            best_idx = -1\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * (value2_lst[j] - value2_lst[i])\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_idx = j\n\n            if best_idx != -1:\n                new_solution[i] = 0\n                new_solution[best_idx] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_idx]\n                break\n\n    # Step 2: Adaptive neighborhood exploration with random perturbations\n    if np.random.rand() < 0.4:\n        num_perturbations = min(2, n_items)\n        perturb_indices = np.random.choice(n_items, num_perturbations, replace=False)\n\n        for idx in perturb_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Correlation-aware greedy addition\n    if np.random.rand() < 0.7:\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # Weighted efficiency for addition\n        efficiency = (1 - abs(corr)) * value1_lst + abs(corr) * value2_lst\n        efficiency /= (weight_lst + 1e-10)\n\n        best_idx = -1\n        best_efficiency = -float('inf')\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                if efficiency[idx] > best_efficiency:\n                    best_efficiency = efficiency[idx]\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.638382425562124,
            -17.485518933163398
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel hybrid local search strategy combining value-aware item selection with diversity-aware perturbations and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement in both objectives\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.prod(objectives, axis=1)  # Product of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-aware item selection with diversity consideration\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate normalized value ratios for both objectives\n        value_ratio1 = value1_lst / (weight_lst + 1e-10)\n        value_ratio2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine ratios with diversity weighting\n        diversity_weight = np.random.uniform(0.3, 0.7)\n        combined_ratio = diversity_weight * value_ratio1 + (1 - diversity_weight) * value_ratio2\n\n        # Select top k items to consider for removal\n        k = min(5, len(included))\n        worst_items = np.argsort(combined_ratio[included])[:k]\n\n        for i in included[worst_items]:\n            # Try to replace with best possible item from excluded\n            best_gain = -float('inf')\n            best_idx = -1\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * (value2_lst[j] - value2_lst[i])\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_idx = j\n\n            if best_idx != -1:\n                new_solution[i] = 0\n                new_solution[best_idx] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_idx]\n                break\n\n    # Step 2: Adaptive neighborhood exploration with value correlation\n    if np.random.rand() < 0.5:\n        # Calculate value correlations between objectives\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # More exploration when objectives are correlated\n        num_explorations = min(3, n_items)\n        explore_indices = np.random.choice(n_items, num_explorations, replace=False)\n\n        for idx in explore_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Local improvement with value-aware greedy selection\n    if np.random.rand() < 0.6:\n        # Calculate value efficiency for both objectives\n        efficiency1 = value1_lst / (weight_lst + 1e-10)\n        efficiency2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine efficiencies with random weights\n        random_weights = np.random.dirichlet([1, 1])\n        combined_efficiency = random_weights[0] * efficiency1 + random_weights[1] * efficiency2\n\n        # Select top item to add\n        best_idx = -1\n        best_efficiency = -float('inf')\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                if combined_efficiency[idx] > best_efficiency:\n                    best_efficiency = combined_efficiency[idx]\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.701311892881797,
            -18.788977089621042
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel hybrid local search strategy combining value-aware item selection with diversity-aware perturbations and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement in both objectives\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.prod(objectives, axis=1)  # Product of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-aware item selection with diversity consideration\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate normalized value ratios for both objectives\n        value_ratio1 = value1_lst / (weight_lst + 1e-10)\n        value_ratio2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine ratios with diversity weighting\n        diversity_weight = np.random.uniform(0.3, 0.7)\n        combined_ratio = diversity_weight * value_ratio1 + (1 - diversity_weight) * value_ratio2\n\n        # Select top k items to consider for removal\n        k = min(5, len(included))\n        worst_items = np.argsort(combined_ratio[included])[:k]\n\n        for i in included[worst_items]:\n            # Try to replace with best possible item from excluded\n            best_gain = -float('inf')\n            best_idx = -1\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * (value2_lst[j] - value2_lst[i])\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_idx = j\n\n            if best_idx != -1:\n                new_solution[i] = 0\n                new_solution[best_idx] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_idx]\n                break\n\n    # Step 2: Adaptive neighborhood exploration with value correlation\n    if np.random.rand() < 0.5:\n        # Calculate value correlations between objectives\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # More exploration when objectives are correlated\n        num_explorations = min(3, n_items)\n        explore_indices = np.random.choice(n_items, num_explorations, replace=False)\n\n        for idx in explore_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Local improvement with value-aware greedy selection\n    if np.random.rand() < 0.6:\n        # Calculate value efficiency for both objectives\n        efficiency1 = value1_lst / (weight_lst + 1e-10)\n        efficiency2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine efficiencies with random weights\n        random_weights = np.random.dirichlet([1, 1])\n        combined_efficiency = random_weights[0] * efficiency1 + random_weights[1] * efficiency2\n\n        # Select top item to add\n        best_idx = -1\n        best_efficiency = -float('inf')\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                if combined_efficiency[idx] > best_efficiency:\n                    best_efficiency = combined_efficiency[idx]\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.701311892881797,
            -18.788977089621042
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel hybrid local search strategy that combines value-aware item selection with adaptive perturbation and correlation-aware exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement in both objectives\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.prod(objectives, axis=1)  # Product of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-aware item selection with correlation consideration\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value correlations between objectives\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # Adjust selection based on correlation\n        if corr > 0.5:\n            # Strong positive correlation - focus on both objectives equally\n            weight1, weight2 = 0.5, 0.5\n        else:\n            # Weak or negative correlation - prioritize one objective\n            weight1, weight2 = np.random.dirichlet([1, 1])\n\n        # Calculate combined value ratio\n        value_ratio1 = value1_lst / (weight_lst + 1e-10)\n        value_ratio2 = value2_lst / (weight_lst + 1e-10)\n        combined_ratio = weight1 * value_ratio1 + weight2 * value_ratio2\n\n        # Select top k items to consider for removal\n        k = min(3, len(included))\n        worst_items = np.argsort(combined_ratio[included])[:k]\n\n        for i in included[worst_items]:\n            # Try to replace with best possible item from excluded\n            best_gain = -float('inf')\n            best_idx = -1\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * (value2_lst[j] - value2_lst[i])\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_idx = j\n\n            if best_idx != -1:\n                new_solution[i] = 0\n                new_solution[best_idx] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_idx]\n                break\n\n    # Step 2: Adaptive perturbation with value diversity\n    if np.random.rand() < 0.4:\n        # Calculate value diversity\n        diversity1 = np.std(value1_lst) / (np.mean(value1_lst) + 1e-10)\n        diversity2 = np.std(value2_lst) / (np.mean(value2_lst) + 1e-10)\n\n        # More perturbation when diversity is high\n        num_perturbations = min(2, n_items)\n        if diversity1 + diversity2 > 1.5:\n            num_perturbations = min(4, n_items)\n\n        perturb_indices = np.random.choice(n_items, num_perturbations, replace=False)\n\n        for idx in perturb_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Correlation-aware greedy selection\n    if np.random.rand() < 0.7:\n        # Calculate value correlations again\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # Adjust selection strategy based on correlation\n        if corr > 0.3:\n            # For correlated objectives, use balanced approach\n            weight1, weight2 = 0.5, 0.5\n        else:\n            # For uncorrelated objectives, use random weights\n            weight1, weight2 = np.random.dirichlet([1, 1])\n\n        # Calculate combined efficiency\n        efficiency1 = value1_lst / (weight_lst + 1e-10)\n        efficiency2 = value2_lst / (weight_lst + 1e-10)\n        combined_efficiency = weight1 * efficiency1 + weight2 * efficiency2\n\n        # Select top item to add\n        best_idx = -1\n        best_efficiency = -float('inf')\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                if combined_efficiency[idx] > best_efficiency:\n                    best_efficiency = combined_efficiency[idx]\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.835658058168917,
            -18.712343284077566
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel hybrid local search strategy combining value-aware item selection with diversity-aware perturbations and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement in both objectives\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.prod(objectives, axis=1)  # Product of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-aware item selection with diversity consideration\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate normalized value ratios for both objectives\n        value_ratio1 = value1_lst / (weight_lst + 1e-10)\n        value_ratio2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine ratios with diversity weighting\n        diversity_weight = np.random.uniform(0.3, 0.7)\n        combined_ratio = diversity_weight * value_ratio1 + (1 - diversity_weight) * value_ratio2\n\n        # Select top k items to consider for removal\n        k = min(5, len(included))\n        worst_items = np.argsort(combined_ratio[included])[:k]\n\n        for i in included[worst_items]:\n            # Try to replace with best possible item from excluded\n            best_gain = -float('inf')\n            best_idx = -1\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * (value2_lst[j] - value2_lst[i])\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_idx = j\n\n            if best_idx != -1:\n                new_solution[i] = 0\n                new_solution[best_idx] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_idx]\n                break\n\n    # Step 2: Adaptive neighborhood exploration with value correlation\n    if np.random.rand() < 0.5:\n        # Calculate value correlations between objectives\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # More exploration when objectives are correlated\n        num_explorations = min(3, n_items)\n        explore_indices = np.random.choice(n_items, num_explorations, replace=False)\n\n        for idx in explore_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Local improvement with value-aware greedy selection\n    if np.random.rand() < 0.6:\n        # Calculate value efficiency for both objectives\n        efficiency1 = value1_lst / (weight_lst + 1e-10)\n        efficiency2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine efficiencies with random weights\n        random_weights = np.random.dirichlet([1, 1])\n        combined_efficiency = random_weights[0] * efficiency1 + random_weights[1] * efficiency2\n\n        # Select top item to add\n        best_idx = -1\n        best_efficiency = -float('inf')\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                if combined_efficiency[idx] > best_efficiency:\n                    best_efficiency = combined_efficiency[idx]\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.701311892881797,
            -18.788977089621042
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel hybrid local search strategy combining value-aware item selection with diversity-aware perturbations and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement in both objectives\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.prod(objectives, axis=1)  # Product of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-aware item selection with diversity consideration\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate normalized value ratios for both objectives\n        value_ratio1 = value1_lst / (weight_lst + 1e-10)\n        value_ratio2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine ratios with diversity weighting\n        diversity_weight = np.random.uniform(0.3, 0.7)\n        combined_ratio = diversity_weight * value_ratio1 + (1 - diversity_weight) * value_ratio2\n\n        # Select top k items to consider for removal\n        k = min(5, len(included))\n        worst_items = np.argsort(combined_ratio[included])[:k]\n\n        for i in included[worst_items]:\n            # Try to replace with best possible item from excluded\n            best_gain = -float('inf')\n            best_idx = -1\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * (value2_lst[j] - value2_lst[i])\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_idx = j\n\n            if best_idx != -1:\n                new_solution[i] = 0\n                new_solution[best_idx] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_idx]\n                break\n\n    # Step 2: Adaptive neighborhood exploration with value correlation\n    if np.random.rand() < 0.5:\n        # Calculate value correlations between objectives\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # More exploration when objectives are correlated\n        num_explorations = min(3, n_items)\n        explore_indices = np.random.choice(n_items, num_explorations, replace=False)\n\n        for idx in explore_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Local improvement with value-aware greedy selection\n    if np.random.rand() < 0.6:\n        # Calculate value efficiency for both objectives\n        efficiency1 = value1_lst / (weight_lst + 1e-10)\n        efficiency2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine efficiencies with random weights\n        random_weights = np.random.dirichlet([1, 1])\n        combined_efficiency = random_weights[0] * efficiency1 + random_weights[1] * efficiency2\n\n        # Select top item to add\n        best_idx = -1\n        best_efficiency = -float('inf')\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                if combined_efficiency[idx] > best_efficiency:\n                    best_efficiency = combined_efficiency[idx]\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.701311892881797,
            -18.788977089621042
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel hybrid local search strategy combining value-aware item selection with diversity-aware perturbations and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement in both objectives\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.prod(objectives, axis=1)  # Product of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-aware item selection with diversity consideration\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate normalized value ratios for both objectives\n        value_ratio1 = value1_lst / (weight_lst + 1e-10)\n        value_ratio2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine ratios with diversity weighting\n        diversity_weight = np.random.uniform(0.3, 0.7)\n        combined_ratio = diversity_weight * value_ratio1 + (1 - diversity_weight) * value_ratio2\n\n        # Select top k items to consider for removal\n        k = min(5, len(included))\n        worst_items = np.argsort(combined_ratio[included])[:k]\n\n        for i in included[worst_items]:\n            # Try to replace with best possible item from excluded\n            best_gain = -float('inf')\n            best_idx = -1\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * (value2_lst[j] - value2_lst[i])\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_idx = j\n\n            if best_idx != -1:\n                new_solution[i] = 0\n                new_solution[best_idx] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_idx]\n                break\n\n    # Step 2: Adaptive neighborhood exploration with value correlation\n    if np.random.rand() < 0.5:\n        # Calculate value correlations between objectives\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # More exploration when objectives are correlated\n        num_explorations = min(3, n_items)\n        explore_indices = np.random.choice(n_items, num_explorations, replace=False)\n\n        for idx in explore_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Local improvement with value-aware greedy selection\n    if np.random.rand() < 0.6:\n        # Calculate value efficiency for both objectives\n        efficiency1 = value1_lst / (weight_lst + 1e-10)\n        efficiency2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine efficiencies with random weights\n        random_weights = np.random.dirichlet([1, 1])\n        combined_efficiency = random_weights[0] * efficiency1 + random_weights[1] * efficiency2\n\n        # Select top item to add\n        best_idx = -1\n        best_efficiency = -float('inf')\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                if combined_efficiency[idx] > best_efficiency:\n                    best_efficiency = combined_efficiency[idx]\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.701311892881797,
            -18.788977089621042
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on a weighted sum of normalized objectives, then applies a hybrid local search combining item flips, swaps, and adaptive neighborhood exploration with a different scoring function that prioritizes balanced improvement across both objectives.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest weighted sum of normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    weights = np.array([0.6, 0.4])  # Prioritize value1 more than value2\n    scores = np.dot(normalized_obj, weights)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Generate candidate solutions using hybrid local search\n    candidates = []\n    n_items = len(base_solution)\n\n    # 1. Random item flip with feasibility check\n    flip_idx = np.random.choice(n_items)\n    new_solution = base_solution.copy()\n    if new_solution[flip_idx] == 1:\n        if current_weight - weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 0\n            candidates.append(new_solution.copy())\n    else:\n        if current_weight + weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 1\n            candidates.append(new_solution.copy())\n\n    # 2. Swap two items if feasible\n    if n_items >= 2:\n        idx1, idx2 = np.random.choice(n_items, 2, replace=False)\n        new_solution = base_solution.copy()\n        if new_solution[idx1] != new_solution[idx2]:\n            delta_weight = (new_solution[idx2] - new_solution[idx1]) * (weight_lst[idx1] - weight_lst[idx2])\n            if current_weight + delta_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                candidates.append(new_solution.copy())\n\n    # 3. Adaptive neighborhood: add/remove items with highest marginal gain\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 * 0.6 + marginal_gain2 * 0.4 + np.random.rand(n_items) * 0.1  # Weighted randomness\n\n    k = min(5, n_items)\n    top_indices = np.argsort(combined_gain)[-k:]\n\n    for idx in top_indices:\n        new_solution = base_solution.copy()\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                candidates.append(new_solution.copy())\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                candidates.append(new_solution.copy())\n\n    if not candidates:\n        new_solution = base_solution.copy()\n        for _ in range(10):\n            flip_idx = np.random.choice(n_items)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    break\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    break\n        return new_solution\n\n    # Select the best candidate based on weighted improvement\n    best_candidate = None\n    best_score = -float('inf')\n\n    for candidate in candidates:\n        candidate_weight = np.sum(weight_lst * candidate)\n        if candidate_weight > capacity:\n            continue\n\n        candidate_value1 = np.sum(value1_lst * candidate)\n        candidate_value2 = np.sum(value2_lst * candidate)\n\n        improvement1 = candidate_value1 - current_value1\n        improvement2 = candidate_value2 - current_value2\n        score = improvement1 * 0.6 + improvement2 * 0.4  # Weighted improvement score\n\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate.copy()\n\n    return best_candidate if best_candidate is not None else base_solution.copy()\n\n",
        "score": [
            -19.72116170602232,
            -17.45441245707314
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel hybrid local search strategy combining value-aware item selection with diversity-aware perturbations and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement in both objectives\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.prod(objectives, axis=1)  # Product of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-aware item selection with diversity consideration\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate normalized value ratios for both objectives\n        value_ratio1 = value1_lst / (weight_lst + 1e-10)\n        value_ratio2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine ratios with diversity weighting\n        diversity_weight = np.random.uniform(0.3, 0.7)\n        combined_ratio = diversity_weight * value_ratio1 + (1 - diversity_weight) * value_ratio2\n\n        # Select top k items to consider for removal\n        k = min(5, len(included))\n        worst_items = np.argsort(combined_ratio[included])[:k]\n\n        for i in included[worst_items]:\n            # Try to replace with best possible item from excluded\n            best_gain = -float('inf')\n            best_idx = -1\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * (value2_lst[j] - value2_lst[i])\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_idx = j\n\n            if best_idx != -1:\n                new_solution[i] = 0\n                new_solution[best_idx] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_idx]\n                break\n\n    # Step 2: Adaptive neighborhood exploration with value correlation\n    if np.random.rand() < 0.5:\n        # Calculate value correlations between objectives\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # More exploration when objectives are correlated\n        num_explorations = min(3, n_items)\n        explore_indices = np.random.choice(n_items, num_explorations, replace=False)\n\n        for idx in explore_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Local improvement with value-aware greedy selection\n    if np.random.rand() < 0.6:\n        # Calculate value efficiency for both objectives\n        efficiency1 = value1_lst / (weight_lst + 1e-10)\n        efficiency2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine efficiencies with random weights\n        random_weights = np.random.dirichlet([1, 1])\n        combined_efficiency = random_weights[0] * efficiency1 + random_weights[1] * efficiency2\n\n        # Select top item to add\n        best_idx = -1\n        best_efficiency = -float('inf')\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                if combined_efficiency[idx] > best_efficiency:\n                    best_efficiency = combined_efficiency[idx]\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.701311892881797,
            -18.788977089621042
        ]
    },
    {
        "algorithm": "{The algorithm selects a promising solution from the archive based on its potential for improvement in both objectives, then applies a novel hybrid local search strategy combining item swaps with adaptive neighborhood exploration and value-aware perturbations to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution by considering both objectives with adaptive weighting\n    objectives = np.array([obj for _, obj in archive])\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    adaptive_weights = np.random.dirichlet([1, 1])\n    scores = np.dot(normalized, adaptive_weights)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-aware item swap with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate potential gains for each pair\n        gains = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain1 = value1_lst[j] - value1_lst[i]\n                    gain2 = value2_lst[j] - value2_lst[i]\n                    gains.append((gain1 + gain2, i, j))\n\n        if gains:\n            # Select top k candidates based on combined gain\n            k = min(5, len(gains))\n            top_candidates = sorted(gains, key=lambda x: -x[0])[:k]\n            selected_gain, i, j = random.choice(top_candidates)\n            new_solution[i] = 0\n            new_solution[j] = 1\n            current_weight = current_weight - weight_lst[i] + weight_lst[j]\n\n    # Step 2: Adaptive perturbation based on objective diversity\n    objective_diversity = np.std(objectives, axis=0)\n    if np.random.rand() < 0.3 + 0.5 * (objective_diversity[0] + objective_diversity[1]):\n        # More perturbations when objectives are diverse\n        num_perturbations = min(3, n_items)\n        perturb_indices = np.random.choice(n_items, num_perturbations, replace=False)\n\n        for idx in perturb_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Local greedy improvement for the most promising objective\n    if np.random.rand() < 0.4:\n        # Choose objective to improve based on current diversity\n        obj_to_improve = 0 if objective_diversity[0] > objective_diversity[1] else 1\n        value_lst = value1_lst if obj_to_improve == 0 else value2_lst\n\n        # Find best possible addition\n        best_gain = 0\n        best_idx = -1\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                gain = value_lst[idx]\n                if gain > best_gain:\n                    best_gain = gain\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.026361479018576,
            -18.66517332072339
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on a weighted sum of normalized objectives, then applies a hybrid local search combining item flips, swaps, and adaptive neighborhood exploration with a different scoring function that prioritizes balanced improvement across both objectives.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest weighted sum of normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    weights = np.array([0.6, 0.4])  # Prioritize value1 more than value2\n    scores = np.dot(normalized_obj, weights)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Generate candidate solutions using hybrid local search\n    candidates = []\n    n_items = len(base_solution)\n\n    # 1. Random item flip with feasibility check\n    flip_idx = np.random.choice(n_items)\n    new_solution = base_solution.copy()\n    if new_solution[flip_idx] == 1:\n        if current_weight - weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 0\n            candidates.append(new_solution.copy())\n    else:\n        if current_weight + weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 1\n            candidates.append(new_solution.copy())\n\n    # 2. Swap two items if feasible\n    if n_items >= 2:\n        idx1, idx2 = np.random.choice(n_items, 2, replace=False)\n        new_solution = base_solution.copy()\n        if new_solution[idx1] != new_solution[idx2]:\n            delta_weight = (new_solution[idx2] - new_solution[idx1]) * (weight_lst[idx1] - weight_lst[idx2])\n            if current_weight + delta_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                candidates.append(new_solution.copy())\n\n    # 3. Adaptive neighborhood: add/remove items with highest marginal gain\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 * 0.6 + marginal_gain2 * 0.4 + np.random.rand(n_items) * 0.1  # Weighted randomness\n\n    k = min(5, n_items)\n    top_indices = np.argsort(combined_gain)[-k:]\n\n    for idx in top_indices:\n        new_solution = base_solution.copy()\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                candidates.append(new_solution.copy())\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                candidates.append(new_solution.copy())\n\n    if not candidates:\n        new_solution = base_solution.copy()\n        for _ in range(10):\n            flip_idx = np.random.choice(n_items)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    break\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    break\n        return new_solution\n\n    # Select the best candidate based on weighted improvement\n    best_candidate = None\n    best_score = -float('inf')\n\n    for candidate in candidates:\n        candidate_weight = np.sum(weight_lst * candidate)\n        if candidate_weight > capacity:\n            continue\n\n        candidate_value1 = np.sum(value1_lst * candidate)\n        candidate_value2 = np.sum(value2_lst * candidate)\n\n        improvement1 = candidate_value1 - current_value1\n        improvement2 = candidate_value2 - current_value2\n        score = improvement1 * 0.6 + improvement2 * 0.4  # Weighted improvement score\n\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate.copy()\n\n    return best_candidate if best_candidate is not None else base_solution.copy()\n\n",
        "score": [
            -19.72116170602232,
            -17.45441245707314
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive using a score function that combines normalized objective values with adaptive weighting based on the archive's diversity, then applies a hybrid local search strategy that includes value-aware item swaps, adaptive perturbations, and targeted greedy improvements to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution using a different score function\n    objectives = np.array([obj for _, obj in archive])\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    diversity_weights = np.random.dirichlet([2, 2])  # Different weighting strategy\n    scores = np.dot(normalized, diversity_weights)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Enhanced value-aware item swap with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate potential gains for each pair with different weighting\n        gains = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain1 = value1_lst[j] - value1_lst[i]\n                    gain2 = value2_lst[j] - value2_lst[i]\n                    combined_gain = 0.6 * gain1 + 0.4 * gain2  # Different gain combination\n                    gains.append((combined_gain, i, j))\n\n        if gains:\n            # Select top k candidates with different selection strategy\n            k = min(3, len(gains))\n            top_candidates = sorted(gains, key=lambda x: -x[0])[:k]\n            selected_gain, i, j = random.choice(top_candidates)\n            new_solution[i] = 0\n            new_solution[j] = 1\n            current_weight = current_weight - weight_lst[i] + weight_lst[j]\n\n    # Step 2: Enhanced adaptive perturbation\n    objective_diversity = np.std(objectives, axis=0)\n    perturbation_prob = 0.4 + 0.4 * (objective_diversity[0] + objective_diversity[1])\n    if np.random.rand() < perturbation_prob:\n        num_perturbations = min(5, n_items)\n        perturb_indices = np.random.choice(n_items, num_perturbations, replace=False)\n\n        for idx in perturb_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Enhanced local greedy improvement\n    if np.random.rand() < 0.5:\n        # Different objective selection strategy\n        obj_to_improve = 0 if np.random.rand() < 0.6 else 1\n        value_lst = value1_lst if obj_to_improve == 0 else value2_lst\n\n        # Find best possible addition with different criteria\n        best_gain = 0\n        best_idx = -1\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                gain = value_lst[idx] * (1 + 0.2 * np.random.rand())  # Add randomness\n                if gain > best_gain:\n                    best_gain = gain\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.467440043233896,
            -18.080729088897666
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on a weighted sum of normalized objectives, then applies a hybrid local search combining item flips, swaps, and adaptive neighborhood exploration with a different scoring function that prioritizes balanced improvement across both objectives.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest weighted sum of normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    weights = np.array([0.6, 0.4])  # Prioritize value1 more than value2\n    scores = np.dot(normalized_obj, weights)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Generate candidate solutions using hybrid local search\n    candidates = []\n    n_items = len(base_solution)\n\n    # 1. Random item flip with feasibility check\n    flip_idx = np.random.choice(n_items)\n    new_solution = base_solution.copy()\n    if new_solution[flip_idx] == 1:\n        if current_weight - weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 0\n            candidates.append(new_solution.copy())\n    else:\n        if current_weight + weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 1\n            candidates.append(new_solution.copy())\n\n    # 2. Swap two items if feasible\n    if n_items >= 2:\n        idx1, idx2 = np.random.choice(n_items, 2, replace=False)\n        new_solution = base_solution.copy()\n        if new_solution[idx1] != new_solution[idx2]:\n            delta_weight = (new_solution[idx2] - new_solution[idx1]) * (weight_lst[idx1] - weight_lst[idx2])\n            if current_weight + delta_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                candidates.append(new_solution.copy())\n\n    # 3. Adaptive neighborhood: add/remove items with highest marginal gain\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 * 0.6 + marginal_gain2 * 0.4 + np.random.rand(n_items) * 0.1  # Weighted randomness\n\n    k = min(5, n_items)\n    top_indices = np.argsort(combined_gain)[-k:]\n\n    for idx in top_indices:\n        new_solution = base_solution.copy()\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                candidates.append(new_solution.copy())\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                candidates.append(new_solution.copy())\n\n    if not candidates:\n        new_solution = base_solution.copy()\n        for _ in range(10):\n            flip_idx = np.random.choice(n_items)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    break\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    break\n        return new_solution\n\n    # Select the best candidate based on weighted improvement\n    best_candidate = None\n    best_score = -float('inf')\n\n    for candidate in candidates:\n        candidate_weight = np.sum(weight_lst * candidate)\n        if candidate_weight > capacity:\n            continue\n\n        candidate_value1 = np.sum(value1_lst * candidate)\n        candidate_value2 = np.sum(value2_lst * candidate)\n\n        improvement1 = candidate_value1 - current_value1\n        improvement2 = candidate_value2 - current_value2\n        score = improvement1 * 0.6 + improvement2 * 0.4  # Weighted improvement score\n\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate.copy()\n\n    return best_candidate if best_candidate is not None else base_solution.copy()\n\n",
        "score": [
            -19.72116170602232,
            -17.45441245707314
        ]
    },
    {
        "algorithm": "{The algorithm selects a promising solution from the archive based on its potential for improvement in both objectives, then applies a novel hybrid local search strategy combining item swaps with adaptive neighborhood exploration and value-aware perturbations to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution by considering both objectives with adaptive weighting\n    objectives = np.array([obj for _, obj in archive])\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    adaptive_weights = np.random.dirichlet([1, 1])\n    scores = np.dot(normalized, adaptive_weights)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-aware item swap with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate potential gains for each pair\n        gains = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain1 = value1_lst[j] - value1_lst[i]\n                    gain2 = value2_lst[j] - value2_lst[i]\n                    gains.append((gain1 + gain2, i, j))\n\n        if gains:\n            # Select top k candidates based on combined gain\n            k = min(5, len(gains))\n            top_candidates = sorted(gains, key=lambda x: -x[0])[:k]\n            selected_gain, i, j = random.choice(top_candidates)\n            new_solution[i] = 0\n            new_solution[j] = 1\n            current_weight = current_weight - weight_lst[i] + weight_lst[j]\n\n    # Step 2: Adaptive perturbation based on objective diversity\n    objective_diversity = np.std(objectives, axis=0)\n    if np.random.rand() < 0.3 + 0.5 * (objective_diversity[0] + objective_diversity[1]):\n        # More perturbations when objectives are diverse\n        num_perturbations = min(3, n_items)\n        perturb_indices = np.random.choice(n_items, num_perturbations, replace=False)\n\n        for idx in perturb_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Local greedy improvement for the most promising objective\n    if np.random.rand() < 0.4:\n        # Choose objective to improve based on current diversity\n        obj_to_improve = 0 if objective_diversity[0] > objective_diversity[1] else 1\n        value_lst = value1_lst if obj_to_improve == 0 else value2_lst\n\n        # Find best possible addition\n        best_gain = 0\n        best_idx = -1\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                gain = value_lst[idx]\n                if gain > best_gain:\n                    best_gain = gain\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.038464887439495,
            -18.62077325272734
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on a weighted sum of normalized objectives, then applies a hybrid local search combining item flips, swaps, and adaptive neighborhood exploration with a different scoring function that prioritizes balanced improvement across both objectives.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest weighted sum of normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    weights = np.array([0.6, 0.4])  # Prioritize value1 more than value2\n    scores = np.dot(normalized_obj, weights)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Generate candidate solutions using hybrid local search\n    candidates = []\n    n_items = len(base_solution)\n\n    # 1. Random item flip with feasibility check\n    flip_idx = np.random.choice(n_items)\n    new_solution = base_solution.copy()\n    if new_solution[flip_idx] == 1:\n        if current_weight - weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 0\n            candidates.append(new_solution.copy())\n    else:\n        if current_weight + weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 1\n            candidates.append(new_solution.copy())\n\n    # 2. Swap two items if feasible\n    if n_items >= 2:\n        idx1, idx2 = np.random.choice(n_items, 2, replace=False)\n        new_solution = base_solution.copy()\n        if new_solution[idx1] != new_solution[idx2]:\n            delta_weight = (new_solution[idx2] - new_solution[idx1]) * (weight_lst[idx1] - weight_lst[idx2])\n            if current_weight + delta_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                candidates.append(new_solution.copy())\n\n    # 3. Adaptive neighborhood: add/remove items with highest marginal gain\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 * 0.6 + marginal_gain2 * 0.4 + np.random.rand(n_items) * 0.1  # Weighted randomness\n\n    k = min(5, n_items)\n    top_indices = np.argsort(combined_gain)[-k:]\n\n    for idx in top_indices:\n        new_solution = base_solution.copy()\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                candidates.append(new_solution.copy())\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                candidates.append(new_solution.copy())\n\n    if not candidates:\n        new_solution = base_solution.copy()\n        for _ in range(10):\n            flip_idx = np.random.choice(n_items)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    break\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    break\n        return new_solution\n\n    # Select the best candidate based on weighted improvement\n    best_candidate = None\n    best_score = -float('inf')\n\n    for candidate in candidates:\n        candidate_weight = np.sum(weight_lst * candidate)\n        if candidate_weight > capacity:\n            continue\n\n        candidate_value1 = np.sum(value1_lst * candidate)\n        candidate_value2 = np.sum(value2_lst * candidate)\n\n        improvement1 = candidate_value1 - current_value1\n        improvement2 = candidate_value2 - current_value2\n        score = improvement1 * 0.6 + improvement2 * 0.4  # Weighted improvement score\n\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate.copy()\n\n    return best_candidate if best_candidate is not None else base_solution.copy()\n\n",
        "score": [
            -19.72116170602232,
            -17.45441245707314
        ]
    }
]