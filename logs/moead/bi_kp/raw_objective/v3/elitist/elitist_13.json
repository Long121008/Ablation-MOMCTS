[
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel hybrid local search strategy combining value-aware item selection with diversity-aware perturbations and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement in both objectives\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.prod(objectives, axis=1)  # Product of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-aware item selection with diversity consideration\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate normalized value ratios for both objectives\n        value_ratio1 = value1_lst / (weight_lst + 1e-10)\n        value_ratio2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine ratios with diversity weighting\n        diversity_weight = np.random.uniform(0.3, 0.7)\n        combined_ratio = diversity_weight * value_ratio1 + (1 - diversity_weight) * value_ratio2\n\n        # Select top k items to consider for removal\n        k = min(5, len(included))\n        worst_items = np.argsort(combined_ratio[included])[:k]\n\n        for i in included[worst_items]:\n            # Try to replace with best possible item from excluded\n            best_gain = -float('inf')\n            best_idx = -1\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * (value2_lst[j] - value2_lst[i])\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_idx = j\n\n            if best_idx != -1:\n                new_solution[i] = 0\n                new_solution[best_idx] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_idx]\n                break\n\n    # Step 2: Adaptive neighborhood exploration with value correlation\n    if np.random.rand() < 0.5:\n        # Calculate value correlations between objectives\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # More exploration when objectives are correlated\n        num_explorations = min(3, n_items)\n        explore_indices = np.random.choice(n_items, num_explorations, replace=False)\n\n        for idx in explore_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Local improvement with value-aware greedy selection\n    if np.random.rand() < 0.6:\n        # Calculate value efficiency for both objectives\n        efficiency1 = value1_lst / (weight_lst + 1e-10)\n        efficiency2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine efficiencies with random weights\n        random_weights = np.random.dirichlet([1, 1])\n        combined_efficiency = random_weights[0] * efficiency1 + random_weights[1] * efficiency2\n\n        # Select top item to add\n        best_idx = -1\n        best_efficiency = -float('inf')\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                if combined_efficiency[idx] > best_efficiency:\n                    best_efficiency = combined_efficiency[idx]\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.701311892881797,
            -18.788977089621042
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on a diversity-aware selection criterion, then applies a hybrid local search combining dynamic item grouping, probabilistic swaps, and marginal gain-based exploration with an adaptive scoring function that balances both objectives while prioritizing underrepresented items.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with diversity-aware selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    diversity_scores = np.linalg.norm(normalized_obj[:, np.newaxis] - normalized_obj, axis=2).mean(axis=1)\n    weights = np.array([0.6, 0.4])\n    scores = np.dot(normalized_obj, weights) + 0.3 * diversity_scores\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    candidates = []\n    n_items = len(base_solution)\n\n    # Dynamic item grouping based on value-weight ratio\n    ratio1 = value1_lst / (weight_lst + 1e-10)\n    ratio2 = value2_lst / (weight_lst + 1e-10)\n    combined_ratio = ratio1 * 0.6 + ratio2 * 0.4\n    sorted_indices = np.argsort(combined_ratio)[::-1]\n\n    # Probabilistic swaps between high and low ratio groups\n    if n_items >= 2:\n        high_group = sorted_indices[:n_items//2]\n        low_group = sorted_indices[n_items//2:]\n\n        for _ in range(3):\n            if np.random.rand() < 0.7:\n                idx1 = np.random.choice(high_group)\n                idx2 = np.random.choice(low_group)\n            else:\n                idx1, idx2 = np.random.choice(n_items, 2, replace=False)\n\n            new_solution = base_solution.copy()\n            if new_solution[idx1] != new_solution[idx2]:\n                delta_weight = (new_solution[idx2] - new_solution[idx1]) * (weight_lst[idx1] - weight_lst[idx2])\n                if current_weight + delta_weight <= capacity:\n                    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                    candidates.append(new_solution.copy())\n\n    # Marginal gain-based exploration with adaptive weights\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    adaptive_weights = np.array([0.6, 0.4]) * (1 + 0.2 * np.random.rand(2))\n    combined_gain = marginal_gain1 * adaptive_weights[0] + marginal_gain2 * adaptive_weights[1]\n\n    k = min(5, n_items)\n    top_indices = np.argsort(combined_gain)[-k:]\n\n    for idx in top_indices:\n        new_solution = base_solution.copy()\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                candidates.append(new_solution.copy())\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                candidates.append(new_solution.copy())\n\n    if not candidates:\n        new_solution = base_solution.copy()\n        for _ in range(10):\n            flip_idx = np.random.choice(n_items)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    break\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    break\n        return new_solution\n\n    # Select best candidate with adaptive scoring\n    best_candidate = None\n    best_score = -float('inf')\n\n    for candidate in candidates:\n        candidate_weight = np.sum(weight_lst * candidate)\n        if candidate_weight > capacity:\n            continue\n\n        candidate_value1 = np.sum(value1_lst * candidate)\n        candidate_value2 = np.sum(value2_lst * candidate)\n\n        improvement1 = candidate_value1 - current_value1\n        improvement2 = candidate_value2 - current_value2\n        adaptive_weights = np.array([0.6, 0.4]) * (1 + 0.2 * np.random.rand(2))\n        score = improvement1 * adaptive_weights[0] + improvement2 * adaptive_weights[1]\n\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate.copy()\n\n    return best_candidate if best_candidate is not None else base_solution.copy()\n\n",
        "score": [
            -19.805107693135554,
            -16.56778127570379
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel hybrid local search strategy combining value-aware item selection with diversity-aware perturbations and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement in both objectives\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.prod(objectives, axis=1)  # Product of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-aware item selection with diversity consideration\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate normalized value ratios for both objectives\n        value_ratio1 = value1_lst / (weight_lst + 1e-10)\n        value_ratio2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine ratios with diversity weighting\n        diversity_weight = np.random.uniform(0.3, 0.7)\n        combined_ratio = diversity_weight * value_ratio1 + (1 - diversity_weight) * value_ratio2\n\n        # Select top k items to consider for removal\n        k = min(5, len(included))\n        worst_items = np.argsort(combined_ratio[included])[:k]\n\n        for i in included[worst_items]:\n            # Try to replace with best possible item from excluded\n            best_gain = -float('inf')\n            best_idx = -1\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * (value2_lst[j] - value2_lst[i])\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_idx = j\n\n            if best_idx != -1:\n                new_solution[i] = 0\n                new_solution[best_idx] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_idx]\n                break\n\n    # Step 2: Adaptive neighborhood exploration with value correlation\n    if np.random.rand() < 0.5:\n        # Calculate value correlations between objectives\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # More exploration when objectives are correlated\n        num_explorations = min(3, n_items)\n        explore_indices = np.random.choice(n_items, num_explorations, replace=False)\n\n        for idx in explore_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Local improvement with value-aware greedy selection\n    if np.random.rand() < 0.6:\n        # Calculate value efficiency for both objectives\n        efficiency1 = value1_lst / (weight_lst + 1e-10)\n        efficiency2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine efficiencies with random weights\n        random_weights = np.random.dirichlet([1, 1])\n        combined_efficiency = random_weights[0] * efficiency1 + random_weights[1] * efficiency2\n\n        # Select top item to add\n        best_idx = -1\n        best_efficiency = -float('inf')\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                if combined_efficiency[idx] > best_efficiency:\n                    best_efficiency = combined_efficiency[idx]\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.701311892881797,
            -18.788977089621042
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on a diversity-aware selection criterion, then applies a hybrid local search combining dynamic item grouping, probabilistic swaps, and marginal gain-based exploration with an adaptive scoring function that balances both objectives while prioritizing underrepresented items.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with diversity-aware selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    diversity_scores = np.linalg.norm(normalized_obj[:, np.newaxis] - normalized_obj, axis=2).mean(axis=1)\n    weights = np.array([0.6, 0.4])\n    scores = np.dot(normalized_obj, weights) + 0.3 * diversity_scores\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    candidates = []\n    n_items = len(base_solution)\n\n    # Dynamic item grouping based on value-weight ratio\n    ratio1 = value1_lst / (weight_lst + 1e-10)\n    ratio2 = value2_lst / (weight_lst + 1e-10)\n    combined_ratio = ratio1 * 0.6 + ratio2 * 0.4\n    sorted_indices = np.argsort(combined_ratio)[::-1]\n\n    # Probabilistic swaps between high and low ratio groups\n    if n_items >= 2:\n        high_group = sorted_indices[:n_items//2]\n        low_group = sorted_indices[n_items//2:]\n\n        for _ in range(3):\n            if np.random.rand() < 0.7:\n                idx1 = np.random.choice(high_group)\n                idx2 = np.random.choice(low_group)\n            else:\n                idx1, idx2 = np.random.choice(n_items, 2, replace=False)\n\n            new_solution = base_solution.copy()\n            if new_solution[idx1] != new_solution[idx2]:\n                delta_weight = (new_solution[idx2] - new_solution[idx1]) * (weight_lst[idx1] - weight_lst[idx2])\n                if current_weight + delta_weight <= capacity:\n                    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                    candidates.append(new_solution.copy())\n\n    # Marginal gain-based exploration with adaptive weights\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    adaptive_weights = np.array([0.6, 0.4]) * (1 + 0.2 * np.random.rand(2))\n    combined_gain = marginal_gain1 * adaptive_weights[0] + marginal_gain2 * adaptive_weights[1]\n\n    k = min(5, n_items)\n    top_indices = np.argsort(combined_gain)[-k:]\n\n    for idx in top_indices:\n        new_solution = base_solution.copy()\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                candidates.append(new_solution.copy())\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                candidates.append(new_solution.copy())\n\n    if not candidates:\n        new_solution = base_solution.copy()\n        for _ in range(10):\n            flip_idx = np.random.choice(n_items)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    break\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    break\n        return new_solution\n\n    # Select best candidate with adaptive scoring\n    best_candidate = None\n    best_score = -float('inf')\n\n    for candidate in candidates:\n        candidate_weight = np.sum(weight_lst * candidate)\n        if candidate_weight > capacity:\n            continue\n\n        candidate_value1 = np.sum(value1_lst * candidate)\n        candidate_value2 = np.sum(value2_lst * candidate)\n\n        improvement1 = candidate_value1 - current_value1\n        improvement2 = candidate_value2 - current_value2\n        adaptive_weights = np.array([0.6, 0.4]) * (1 + 0.2 * np.random.rand(2))\n        score = improvement1 * adaptive_weights[0] + improvement2 * adaptive_weights[1]\n\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate.copy()\n\n    return best_candidate if best_candidate is not None else base_solution.copy()\n\n",
        "score": [
            -19.805107693135554,
            -16.56778127570379
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel hybrid local search strategy combining value-aware item selection with diversity-aware perturbations and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement in both objectives\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.prod(objectives, axis=1)  # Product of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-aware item selection with diversity consideration\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate normalized value ratios for both objectives\n        value_ratio1 = value1_lst / (weight_lst + 1e-10)\n        value_ratio2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine ratios with diversity weighting\n        diversity_weight = np.random.uniform(0.3, 0.7)\n        combined_ratio = diversity_weight * value_ratio1 + (1 - diversity_weight) * value_ratio2\n\n        # Select top k items to consider for removal\n        k = min(5, len(included))\n        worst_items = np.argsort(combined_ratio[included])[:k]\n\n        for i in included[worst_items]:\n            # Try to replace with best possible item from excluded\n            best_gain = -float('inf')\n            best_idx = -1\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * (value2_lst[j] - value2_lst[i])\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_idx = j\n\n            if best_idx != -1:\n                new_solution[i] = 0\n                new_solution[best_idx] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_idx]\n                break\n\n    # Step 2: Adaptive neighborhood exploration with value correlation\n    if np.random.rand() < 0.5:\n        # Calculate value correlations between objectives\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # More exploration when objectives are correlated\n        num_explorations = min(3, n_items)\n        explore_indices = np.random.choice(n_items, num_explorations, replace=False)\n\n        for idx in explore_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Local improvement with value-aware greedy selection\n    if np.random.rand() < 0.6:\n        # Calculate value efficiency for both objectives\n        efficiency1 = value1_lst / (weight_lst + 1e-10)\n        efficiency2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine efficiencies with random weights\n        random_weights = np.random.dirichlet([1, 1])\n        combined_efficiency = random_weights[0] * efficiency1 + random_weights[1] * efficiency2\n\n        # Select top item to add\n        best_idx = -1\n        best_efficiency = -float('inf')\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                if combined_efficiency[idx] > best_efficiency:\n                    best_efficiency = combined_efficiency[idx]\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.701311892881797,
            -18.788977089621042
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on a diversity-aware selection criterion, then applies a hybrid local search combining dynamic item grouping, probabilistic swaps, and marginal gain-based exploration with an adaptive scoring function that balances both objectives while prioritizing underrepresented items.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with diversity-aware selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    diversity_scores = np.linalg.norm(normalized_obj[:, np.newaxis] - normalized_obj, axis=2).mean(axis=1)\n    weights = np.array([0.6, 0.4])\n    scores = np.dot(normalized_obj, weights) + 0.3 * diversity_scores\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    candidates = []\n    n_items = len(base_solution)\n\n    # Dynamic item grouping based on value-weight ratio\n    ratio1 = value1_lst / (weight_lst + 1e-10)\n    ratio2 = value2_lst / (weight_lst + 1e-10)\n    combined_ratio = ratio1 * 0.6 + ratio2 * 0.4\n    sorted_indices = np.argsort(combined_ratio)[::-1]\n\n    # Probabilistic swaps between high and low ratio groups\n    if n_items >= 2:\n        high_group = sorted_indices[:n_items//2]\n        low_group = sorted_indices[n_items//2:]\n\n        for _ in range(3):\n            if np.random.rand() < 0.7:\n                idx1 = np.random.choice(high_group)\n                idx2 = np.random.choice(low_group)\n            else:\n                idx1, idx2 = np.random.choice(n_items, 2, replace=False)\n\n            new_solution = base_solution.copy()\n            if new_solution[idx1] != new_solution[idx2]:\n                delta_weight = (new_solution[idx2] - new_solution[idx1]) * (weight_lst[idx1] - weight_lst[idx2])\n                if current_weight + delta_weight <= capacity:\n                    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                    candidates.append(new_solution.copy())\n\n    # Marginal gain-based exploration with adaptive weights\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    adaptive_weights = np.array([0.6, 0.4]) * (1 + 0.2 * np.random.rand(2))\n    combined_gain = marginal_gain1 * adaptive_weights[0] + marginal_gain2 * adaptive_weights[1]\n\n    k = min(5, n_items)\n    top_indices = np.argsort(combined_gain)[-k:]\n\n    for idx in top_indices:\n        new_solution = base_solution.copy()\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                candidates.append(new_solution.copy())\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                candidates.append(new_solution.copy())\n\n    if not candidates:\n        new_solution = base_solution.copy()\n        for _ in range(10):\n            flip_idx = np.random.choice(n_items)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    break\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    break\n        return new_solution\n\n    # Select best candidate with adaptive scoring\n    best_candidate = None\n    best_score = -float('inf')\n\n    for candidate in candidates:\n        candidate_weight = np.sum(weight_lst * candidate)\n        if candidate_weight > capacity:\n            continue\n\n        candidate_value1 = np.sum(value1_lst * candidate)\n        candidate_value2 = np.sum(value2_lst * candidate)\n\n        improvement1 = candidate_value1 - current_value1\n        improvement2 = candidate_value2 - current_value2\n        adaptive_weights = np.array([0.6, 0.4]) * (1 + 0.2 * np.random.rand(2))\n        score = improvement1 * adaptive_weights[0] + improvement2 * adaptive_weights[1]\n\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate.copy()\n\n    return best_candidate if best_candidate is not None else base_solution.copy()\n\n",
        "score": [
            -19.805107693135554,
            -16.56778127570379
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive with high potential for improvement in both objectives, then applies a hybrid local search strategy combining value-aware item replacement with adaptive neighborhood exploration and correlation-aware perturbations to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with high potential for improvement (highest sum of objectives)\n    objectives = np.array([obj for _, obj in archive])\n    selected_idx = np.argmax(np.sum(objectives, axis=1))\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-aware item replacement with correlation consideration\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value correlations\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # Weighted value efficiency based on correlation\n        efficiency = (1 - abs(corr)) * value1_lst + abs(corr) * value2_lst\n        efficiency /= (weight_lst + 1e-10)\n\n        # Find worst items to consider for removal\n        k = min(3, len(included))\n        worst_items = np.argsort(efficiency[included])[:k]\n\n        for i in included[worst_items]:\n            # Find best replacement item\n            best_gain = -float('inf')\n            best_idx = -1\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * (value2_lst[j] - value2_lst[i])\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_idx = j\n\n            if best_idx != -1:\n                new_solution[i] = 0\n                new_solution[best_idx] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_idx]\n                break\n\n    # Step 2: Adaptive neighborhood exploration with random perturbations\n    if np.random.rand() < 0.4:\n        num_perturbations = min(2, n_items)\n        perturb_indices = np.random.choice(n_items, num_perturbations, replace=False)\n\n        for idx in perturb_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Correlation-aware greedy addition\n    if np.random.rand() < 0.7:\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # Weighted efficiency for addition\n        efficiency = (1 - abs(corr)) * value1_lst + abs(corr) * value2_lst\n        efficiency /= (weight_lst + 1e-10)\n\n        best_idx = -1\n        best_efficiency = -float('inf')\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                if efficiency[idx] > best_efficiency:\n                    best_efficiency = efficiency[idx]\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.638382425562124,
            -17.485518933163398
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel hybrid local search strategy combining value-aware item selection with diversity-aware perturbations and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement in both objectives\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.prod(objectives, axis=1)  # Product of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-aware item selection with diversity consideration\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate normalized value ratios for both objectives\n        value_ratio1 = value1_lst / (weight_lst + 1e-10)\n        value_ratio2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine ratios with diversity weighting\n        diversity_weight = np.random.uniform(0.3, 0.7)\n        combined_ratio = diversity_weight * value_ratio1 + (1 - diversity_weight) * value_ratio2\n\n        # Select top k items to consider for removal\n        k = min(5, len(included))\n        worst_items = np.argsort(combined_ratio[included])[:k]\n\n        for i in included[worst_items]:\n            # Try to replace with best possible item from excluded\n            best_gain = -float('inf')\n            best_idx = -1\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * (value2_lst[j] - value2_lst[i])\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_idx = j\n\n            if best_idx != -1:\n                new_solution[i] = 0\n                new_solution[best_idx] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_idx]\n                break\n\n    # Step 2: Adaptive neighborhood exploration with value correlation\n    if np.random.rand() < 0.5:\n        # Calculate value correlations between objectives\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # More exploration when objectives are correlated\n        num_explorations = min(3, n_items)\n        explore_indices = np.random.choice(n_items, num_explorations, replace=False)\n\n        for idx in explore_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Local improvement with value-aware greedy selection\n    if np.random.rand() < 0.6:\n        # Calculate value efficiency for both objectives\n        efficiency1 = value1_lst / (weight_lst + 1e-10)\n        efficiency2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine efficiencies with random weights\n        random_weights = np.random.dirichlet([1, 1])\n        combined_efficiency = random_weights[0] * efficiency1 + random_weights[1] * efficiency2\n\n        # Select top item to add\n        best_idx = -1\n        best_efficiency = -float('inf')\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                if combined_efficiency[idx] > best_efficiency:\n                    best_efficiency = combined_efficiency[idx]\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.701311892881797,
            -18.788977089621042
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on a diversity-aware selection criterion, then applies a hybrid local search combining dynamic item grouping, probabilistic swaps, and marginal gain-based exploration with an adaptive scoring function that balances both objectives while prioritizing underrepresented items.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with diversity-aware selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    diversity_scores = np.linalg.norm(normalized_obj[:, np.newaxis] - normalized_obj, axis=2).mean(axis=1)\n    weights = np.array([0.6, 0.4])\n    scores = np.dot(normalized_obj, weights) + 0.3 * diversity_scores\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    candidates = []\n    n_items = len(base_solution)\n\n    # Dynamic item grouping based on value-weight ratio\n    ratio1 = value1_lst / (weight_lst + 1e-10)\n    ratio2 = value2_lst / (weight_lst + 1e-10)\n    combined_ratio = ratio1 * 0.6 + ratio2 * 0.4\n    sorted_indices = np.argsort(combined_ratio)[::-1]\n\n    # Probabilistic swaps between high and low ratio groups\n    if n_items >= 2:\n        high_group = sorted_indices[:n_items//2]\n        low_group = sorted_indices[n_items//2:]\n\n        for _ in range(3):\n            if np.random.rand() < 0.7:\n                idx1 = np.random.choice(high_group)\n                idx2 = np.random.choice(low_group)\n            else:\n                idx1, idx2 = np.random.choice(n_items, 2, replace=False)\n\n            new_solution = base_solution.copy()\n            if new_solution[idx1] != new_solution[idx2]:\n                delta_weight = (new_solution[idx2] - new_solution[idx1]) * (weight_lst[idx1] - weight_lst[idx2])\n                if current_weight + delta_weight <= capacity:\n                    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                    candidates.append(new_solution.copy())\n\n    # Marginal gain-based exploration with adaptive weights\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    adaptive_weights = np.array([0.6, 0.4]) * (1 + 0.2 * np.random.rand(2))\n    combined_gain = marginal_gain1 * adaptive_weights[0] + marginal_gain2 * adaptive_weights[1]\n\n    k = min(5, n_items)\n    top_indices = np.argsort(combined_gain)[-k:]\n\n    for idx in top_indices:\n        new_solution = base_solution.copy()\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                candidates.append(new_solution.copy())\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                candidates.append(new_solution.copy())\n\n    if not candidates:\n        new_solution = base_solution.copy()\n        for _ in range(10):\n            flip_idx = np.random.choice(n_items)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    break\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    break\n        return new_solution\n\n    # Select best candidate with adaptive scoring\n    best_candidate = None\n    best_score = -float('inf')\n\n    for candidate in candidates:\n        candidate_weight = np.sum(weight_lst * candidate)\n        if candidate_weight > capacity:\n            continue\n\n        candidate_value1 = np.sum(value1_lst * candidate)\n        candidate_value2 = np.sum(value2_lst * candidate)\n\n        improvement1 = candidate_value1 - current_value1\n        improvement2 = candidate_value2 - current_value2\n        adaptive_weights = np.array([0.6, 0.4]) * (1 + 0.2 * np.random.rand(2))\n        score = improvement1 * adaptive_weights[0] + improvement2 * adaptive_weights[1]\n\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate.copy()\n\n    return best_candidate if best_candidate is not None else base_solution.copy()\n\n",
        "score": [
            -19.805107693135554,
            -16.56778127570379
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel hybrid local search strategy combining value-aware item selection with diversity-aware perturbations and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement in both objectives\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.prod(objectives, axis=1)  # Product of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-aware item selection with diversity consideration\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate normalized value ratios for both objectives\n        value_ratio1 = value1_lst / (weight_lst + 1e-10)\n        value_ratio2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine ratios with diversity weighting\n        diversity_weight = np.random.uniform(0.3, 0.7)\n        combined_ratio = diversity_weight * value_ratio1 + (1 - diversity_weight) * value_ratio2\n\n        # Select top k items to consider for removal\n        k = min(5, len(included))\n        worst_items = np.argsort(combined_ratio[included])[:k]\n\n        for i in included[worst_items]:\n            # Try to replace with best possible item from excluded\n            best_gain = -float('inf')\n            best_idx = -1\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * (value2_lst[j] - value2_lst[i])\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_idx = j\n\n            if best_idx != -1:\n                new_solution[i] = 0\n                new_solution[best_idx] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_idx]\n                break\n\n    # Step 2: Adaptive neighborhood exploration with value correlation\n    if np.random.rand() < 0.5:\n        # Calculate value correlations between objectives\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # More exploration when objectives are correlated\n        num_explorations = min(3, n_items)\n        explore_indices = np.random.choice(n_items, num_explorations, replace=False)\n\n        for idx in explore_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Local improvement with value-aware greedy selection\n    if np.random.rand() < 0.6:\n        # Calculate value efficiency for both objectives\n        efficiency1 = value1_lst / (weight_lst + 1e-10)\n        efficiency2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine efficiencies with random weights\n        random_weights = np.random.dirichlet([1, 1])\n        combined_efficiency = random_weights[0] * efficiency1 + random_weights[1] * efficiency2\n\n        # Select top item to add\n        best_idx = -1\n        best_efficiency = -float('inf')\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                if combined_efficiency[idx] > best_efficiency:\n                    best_efficiency = combined_efficiency[idx]\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.701311892881797,
            -18.788977089621042
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on a diversity-aware selection criterion, then applies a hybrid local search combining dynamic item grouping, probabilistic swaps, and marginal gain-based exploration with an adaptive scoring function that balances both objectives while prioritizing underrepresented items.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with diversity-aware selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    diversity_scores = np.linalg.norm(normalized_obj[:, np.newaxis] - normalized_obj, axis=2).mean(axis=1)\n    weights = np.array([0.6, 0.4])\n    scores = np.dot(normalized_obj, weights) + 0.3 * diversity_scores\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    candidates = []\n    n_items = len(base_solution)\n\n    # Dynamic item grouping based on value-weight ratio\n    ratio1 = value1_lst / (weight_lst + 1e-10)\n    ratio2 = value2_lst / (weight_lst + 1e-10)\n    combined_ratio = ratio1 * 0.6 + ratio2 * 0.4\n    sorted_indices = np.argsort(combined_ratio)[::-1]\n\n    # Probabilistic swaps between high and low ratio groups\n    if n_items >= 2:\n        high_group = sorted_indices[:n_items//2]\n        low_group = sorted_indices[n_items//2:]\n\n        for _ in range(3):\n            if np.random.rand() < 0.7:\n                idx1 = np.random.choice(high_group)\n                idx2 = np.random.choice(low_group)\n            else:\n                idx1, idx2 = np.random.choice(n_items, 2, replace=False)\n\n            new_solution = base_solution.copy()\n            if new_solution[idx1] != new_solution[idx2]:\n                delta_weight = (new_solution[idx2] - new_solution[idx1]) * (weight_lst[idx1] - weight_lst[idx2])\n                if current_weight + delta_weight <= capacity:\n                    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                    candidates.append(new_solution.copy())\n\n    # Marginal gain-based exploration with adaptive weights\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    adaptive_weights = np.array([0.6, 0.4]) * (1 + 0.2 * np.random.rand(2))\n    combined_gain = marginal_gain1 * adaptive_weights[0] + marginal_gain2 * adaptive_weights[1]\n\n    k = min(5, n_items)\n    top_indices = np.argsort(combined_gain)[-k:]\n\n    for idx in top_indices:\n        new_solution = base_solution.copy()\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                candidates.append(new_solution.copy())\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                candidates.append(new_solution.copy())\n\n    if not candidates:\n        new_solution = base_solution.copy()\n        for _ in range(10):\n            flip_idx = np.random.choice(n_items)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    break\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    break\n        return new_solution\n\n    # Select best candidate with adaptive scoring\n    best_candidate = None\n    best_score = -float('inf')\n\n    for candidate in candidates:\n        candidate_weight = np.sum(weight_lst * candidate)\n        if candidate_weight > capacity:\n            continue\n\n        candidate_value1 = np.sum(value1_lst * candidate)\n        candidate_value2 = np.sum(value2_lst * candidate)\n\n        improvement1 = candidate_value1 - current_value1\n        improvement2 = candidate_value2 - current_value2\n        adaptive_weights = np.array([0.6, 0.4]) * (1 + 0.2 * np.random.rand(2))\n        score = improvement1 * adaptive_weights[0] + improvement2 * adaptive_weights[1]\n\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate.copy()\n\n    return best_candidate if best_candidate is not None else base_solution.copy()\n\n",
        "score": [
            -19.805107693135554,
            -16.56778127570379
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel hybrid local search strategy that combines value-aware item selection with adaptive perturbation and correlation-aware exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement in both objectives\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.prod(objectives, axis=1)  # Product of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-aware item selection with correlation consideration\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value correlations between objectives\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # Adjust selection based on correlation\n        if corr > 0.5:\n            # Strong positive correlation - focus on both objectives equally\n            weight1, weight2 = 0.5, 0.5\n        else:\n            # Weak or negative correlation - prioritize one objective\n            weight1, weight2 = np.random.dirichlet([1, 1])\n\n        # Calculate combined value ratio\n        value_ratio1 = value1_lst / (weight_lst + 1e-10)\n        value_ratio2 = value2_lst / (weight_lst + 1e-10)\n        combined_ratio = weight1 * value_ratio1 + weight2 * value_ratio2\n\n        # Select top k items to consider for removal\n        k = min(3, len(included))\n        worst_items = np.argsort(combined_ratio[included])[:k]\n\n        for i in included[worst_items]:\n            # Try to replace with best possible item from excluded\n            best_gain = -float('inf')\n            best_idx = -1\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * (value2_lst[j] - value2_lst[i])\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_idx = j\n\n            if best_idx != -1:\n                new_solution[i] = 0\n                new_solution[best_idx] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_idx]\n                break\n\n    # Step 2: Adaptive perturbation with value diversity\n    if np.random.rand() < 0.4:\n        # Calculate value diversity\n        diversity1 = np.std(value1_lst) / (np.mean(value1_lst) + 1e-10)\n        diversity2 = np.std(value2_lst) / (np.mean(value2_lst) + 1e-10)\n\n        # More perturbation when diversity is high\n        num_perturbations = min(2, n_items)\n        if diversity1 + diversity2 > 1.5:\n            num_perturbations = min(4, n_items)\n\n        perturb_indices = np.random.choice(n_items, num_perturbations, replace=False)\n\n        for idx in perturb_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Correlation-aware greedy selection\n    if np.random.rand() < 0.7:\n        # Calculate value correlations again\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # Adjust selection strategy based on correlation\n        if corr > 0.3:\n            # For correlated objectives, use balanced approach\n            weight1, weight2 = 0.5, 0.5\n        else:\n            # For uncorrelated objectives, use random weights\n            weight1, weight2 = np.random.dirichlet([1, 1])\n\n        # Calculate combined efficiency\n        efficiency1 = value1_lst / (weight_lst + 1e-10)\n        efficiency2 = value2_lst / (weight_lst + 1e-10)\n        combined_efficiency = weight1 * efficiency1 + weight2 * efficiency2\n\n        # Select top item to add\n        best_idx = -1\n        best_efficiency = -float('inf')\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                if combined_efficiency[idx] > best_efficiency:\n                    best_efficiency = combined_efficiency[idx]\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.835658058168917,
            -18.712343284077566
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel hybrid local search strategy combining value-aware item selection with diversity-aware perturbations and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement in both objectives\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.prod(objectives, axis=1)  # Product of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-aware item selection with diversity consideration\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate normalized value ratios for both objectives\n        value_ratio1 = value1_lst / (weight_lst + 1e-10)\n        value_ratio2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine ratios with diversity weighting\n        diversity_weight = np.random.uniform(0.3, 0.7)\n        combined_ratio = diversity_weight * value_ratio1 + (1 - diversity_weight) * value_ratio2\n\n        # Select top k items to consider for removal\n        k = min(5, len(included))\n        worst_items = np.argsort(combined_ratio[included])[:k]\n\n        for i in included[worst_items]:\n            # Try to replace with best possible item from excluded\n            best_gain = -float('inf')\n            best_idx = -1\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * (value2_lst[j] - value2_lst[i])\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_idx = j\n\n            if best_idx != -1:\n                new_solution[i] = 0\n                new_solution[best_idx] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_idx]\n                break\n\n    # Step 2: Adaptive neighborhood exploration with value correlation\n    if np.random.rand() < 0.5:\n        # Calculate value correlations between objectives\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # More exploration when objectives are correlated\n        num_explorations = min(3, n_items)\n        explore_indices = np.random.choice(n_items, num_explorations, replace=False)\n\n        for idx in explore_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Local improvement with value-aware greedy selection\n    if np.random.rand() < 0.6:\n        # Calculate value efficiency for both objectives\n        efficiency1 = value1_lst / (weight_lst + 1e-10)\n        efficiency2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine efficiencies with random weights\n        random_weights = np.random.dirichlet([1, 1])\n        combined_efficiency = random_weights[0] * efficiency1 + random_weights[1] * efficiency2\n\n        # Select top item to add\n        best_idx = -1\n        best_efficiency = -float('inf')\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                if combined_efficiency[idx] > best_efficiency:\n                    best_efficiency = combined_efficiency[idx]\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.701311892881797,
            -18.788977089621042
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on a diversity-aware selection criterion, then applies a hybrid local search combining dynamic item grouping, probabilistic swaps, and marginal gain-based exploration with an adaptive scoring function that balances both objectives while prioritizing underrepresented items.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with diversity-aware selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    diversity_scores = np.linalg.norm(normalized_obj[:, np.newaxis] - normalized_obj, axis=2).mean(axis=1)\n    weights = np.array([0.6, 0.4])\n    scores = np.dot(normalized_obj, weights) + 0.3 * diversity_scores\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    candidates = []\n    n_items = len(base_solution)\n\n    # Dynamic item grouping based on value-weight ratio\n    ratio1 = value1_lst / (weight_lst + 1e-10)\n    ratio2 = value2_lst / (weight_lst + 1e-10)\n    combined_ratio = ratio1 * 0.6 + ratio2 * 0.4\n    sorted_indices = np.argsort(combined_ratio)[::-1]\n\n    # Probabilistic swaps between high and low ratio groups\n    if n_items >= 2:\n        high_group = sorted_indices[:n_items//2]\n        low_group = sorted_indices[n_items//2:]\n\n        for _ in range(3):\n            if np.random.rand() < 0.7:\n                idx1 = np.random.choice(high_group)\n                idx2 = np.random.choice(low_group)\n            else:\n                idx1, idx2 = np.random.choice(n_items, 2, replace=False)\n\n            new_solution = base_solution.copy()\n            if new_solution[idx1] != new_solution[idx2]:\n                delta_weight = (new_solution[idx2] - new_solution[idx1]) * (weight_lst[idx1] - weight_lst[idx2])\n                if current_weight + delta_weight <= capacity:\n                    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                    candidates.append(new_solution.copy())\n\n    # Marginal gain-based exploration with adaptive weights\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    adaptive_weights = np.array([0.6, 0.4]) * (1 + 0.2 * np.random.rand(2))\n    combined_gain = marginal_gain1 * adaptive_weights[0] + marginal_gain2 * adaptive_weights[1]\n\n    k = min(5, n_items)\n    top_indices = np.argsort(combined_gain)[-k:]\n\n    for idx in top_indices:\n        new_solution = base_solution.copy()\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                candidates.append(new_solution.copy())\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                candidates.append(new_solution.copy())\n\n    if not candidates:\n        new_solution = base_solution.copy()\n        for _ in range(10):\n            flip_idx = np.random.choice(n_items)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    break\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    break\n        return new_solution\n\n    # Select best candidate with adaptive scoring\n    best_candidate = None\n    best_score = -float('inf')\n\n    for candidate in candidates:\n        candidate_weight = np.sum(weight_lst * candidate)\n        if candidate_weight > capacity:\n            continue\n\n        candidate_value1 = np.sum(value1_lst * candidate)\n        candidate_value2 = np.sum(value2_lst * candidate)\n\n        improvement1 = candidate_value1 - current_value1\n        improvement2 = candidate_value2 - current_value2\n        adaptive_weights = np.array([0.6, 0.4]) * (1 + 0.2 * np.random.rand(2))\n        score = improvement1 * adaptive_weights[0] + improvement2 * adaptive_weights[1]\n\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate.copy()\n\n    return best_candidate if best_candidate is not None else base_solution.copy()\n\n",
        "score": [
            -19.805107693135554,
            -16.56778127570379
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel hybrid local search strategy combining value-aware item selection with diversity-aware perturbations and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement in both objectives\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.prod(objectives, axis=1)  # Product of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-aware item selection with diversity consideration\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate normalized value ratios for both objectives\n        value_ratio1 = value1_lst / (weight_lst + 1e-10)\n        value_ratio2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine ratios with diversity weighting\n        diversity_weight = np.random.uniform(0.3, 0.7)\n        combined_ratio = diversity_weight * value_ratio1 + (1 - diversity_weight) * value_ratio2\n\n        # Select top k items to consider for removal\n        k = min(5, len(included))\n        worst_items = np.argsort(combined_ratio[included])[:k]\n\n        for i in included[worst_items]:\n            # Try to replace with best possible item from excluded\n            best_gain = -float('inf')\n            best_idx = -1\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * (value2_lst[j] - value2_lst[i])\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_idx = j\n\n            if best_idx != -1:\n                new_solution[i] = 0\n                new_solution[best_idx] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_idx]\n                break\n\n    # Step 2: Adaptive neighborhood exploration with value correlation\n    if np.random.rand() < 0.5:\n        # Calculate value correlations between objectives\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # More exploration when objectives are correlated\n        num_explorations = min(3, n_items)\n        explore_indices = np.random.choice(n_items, num_explorations, replace=False)\n\n        for idx in explore_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Local improvement with value-aware greedy selection\n    if np.random.rand() < 0.6:\n        # Calculate value efficiency for both objectives\n        efficiency1 = value1_lst / (weight_lst + 1e-10)\n        efficiency2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine efficiencies with random weights\n        random_weights = np.random.dirichlet([1, 1])\n        combined_efficiency = random_weights[0] * efficiency1 + random_weights[1] * efficiency2\n\n        # Select top item to add\n        best_idx = -1\n        best_efficiency = -float('inf')\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                if combined_efficiency[idx] > best_efficiency:\n                    best_efficiency = combined_efficiency[idx]\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.701311892881797,
            -18.788977089621042
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on a diversity-aware selection criterion, then applies a hybrid local search combining dynamic item grouping, probabilistic swaps, and marginal gain-based exploration with an adaptive scoring function that balances both objectives while prioritizing underrepresented items.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with diversity-aware selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    diversity_scores = np.linalg.norm(normalized_obj[:, np.newaxis] - normalized_obj, axis=2).mean(axis=1)\n    weights = np.array([0.6, 0.4])\n    scores = np.dot(normalized_obj, weights) + 0.3 * diversity_scores\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    candidates = []\n    n_items = len(base_solution)\n\n    # Dynamic item grouping based on value-weight ratio\n    ratio1 = value1_lst / (weight_lst + 1e-10)\n    ratio2 = value2_lst / (weight_lst + 1e-10)\n    combined_ratio = ratio1 * 0.6 + ratio2 * 0.4\n    sorted_indices = np.argsort(combined_ratio)[::-1]\n\n    # Probabilistic swaps between high and low ratio groups\n    if n_items >= 2:\n        high_group = sorted_indices[:n_items//2]\n        low_group = sorted_indices[n_items//2:]\n\n        for _ in range(3):\n            if np.random.rand() < 0.7:\n                idx1 = np.random.choice(high_group)\n                idx2 = np.random.choice(low_group)\n            else:\n                idx1, idx2 = np.random.choice(n_items, 2, replace=False)\n\n            new_solution = base_solution.copy()\n            if new_solution[idx1] != new_solution[idx2]:\n                delta_weight = (new_solution[idx2] - new_solution[idx1]) * (weight_lst[idx1] - weight_lst[idx2])\n                if current_weight + delta_weight <= capacity:\n                    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                    candidates.append(new_solution.copy())\n\n    # Marginal gain-based exploration with adaptive weights\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    adaptive_weights = np.array([0.6, 0.4]) * (1 + 0.2 * np.random.rand(2))\n    combined_gain = marginal_gain1 * adaptive_weights[0] + marginal_gain2 * adaptive_weights[1]\n\n    k = min(5, n_items)\n    top_indices = np.argsort(combined_gain)[-k:]\n\n    for idx in top_indices:\n        new_solution = base_solution.copy()\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                candidates.append(new_solution.copy())\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                candidates.append(new_solution.copy())\n\n    if not candidates:\n        new_solution = base_solution.copy()\n        for _ in range(10):\n            flip_idx = np.random.choice(n_items)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    break\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    break\n        return new_solution\n\n    # Select best candidate with adaptive scoring\n    best_candidate = None\n    best_score = -float('inf')\n\n    for candidate in candidates:\n        candidate_weight = np.sum(weight_lst * candidate)\n        if candidate_weight > capacity:\n            continue\n\n        candidate_value1 = np.sum(value1_lst * candidate)\n        candidate_value2 = np.sum(value2_lst * candidate)\n\n        improvement1 = candidate_value1 - current_value1\n        improvement2 = candidate_value2 - current_value2\n        adaptive_weights = np.array([0.6, 0.4]) * (1 + 0.2 * np.random.rand(2))\n        score = improvement1 * adaptive_weights[0] + improvement2 * adaptive_weights[1]\n\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate.copy()\n\n    return best_candidate if best_candidate is not None else base_solution.copy()\n\n",
        "score": [
            -19.805107693135554,
            -16.56778127570379
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel hybrid local search strategy combining value-aware item selection with diversity-aware perturbations and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement in both objectives\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.prod(objectives, axis=1)  # Product of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-aware item selection with diversity consideration\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate normalized value ratios for both objectives\n        value_ratio1 = value1_lst / (weight_lst + 1e-10)\n        value_ratio2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine ratios with diversity weighting\n        diversity_weight = np.random.uniform(0.3, 0.7)\n        combined_ratio = diversity_weight * value_ratio1 + (1 - diversity_weight) * value_ratio2\n\n        # Select top k items to consider for removal\n        k = min(5, len(included))\n        worst_items = np.argsort(combined_ratio[included])[:k]\n\n        for i in included[worst_items]:\n            # Try to replace with best possible item from excluded\n            best_gain = -float('inf')\n            best_idx = -1\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * (value2_lst[j] - value2_lst[i])\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_idx = j\n\n            if best_idx != -1:\n                new_solution[i] = 0\n                new_solution[best_idx] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_idx]\n                break\n\n    # Step 2: Adaptive neighborhood exploration with value correlation\n    if np.random.rand() < 0.5:\n        # Calculate value correlations between objectives\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # More exploration when objectives are correlated\n        num_explorations = min(3, n_items)\n        explore_indices = np.random.choice(n_items, num_explorations, replace=False)\n\n        for idx in explore_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Local improvement with value-aware greedy selection\n    if np.random.rand() < 0.6:\n        # Calculate value efficiency for both objectives\n        efficiency1 = value1_lst / (weight_lst + 1e-10)\n        efficiency2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine efficiencies with random weights\n        random_weights = np.random.dirichlet([1, 1])\n        combined_efficiency = random_weights[0] * efficiency1 + random_weights[1] * efficiency2\n\n        # Select top item to add\n        best_idx = -1\n        best_efficiency = -float('inf')\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                if combined_efficiency[idx] > best_efficiency:\n                    best_efficiency = combined_efficiency[idx]\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.701311892881797,
            -18.788977089621042
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on a diversity-aware selection criterion, then applies a hybrid local search combining dynamic item grouping, probabilistic swaps, and marginal gain-based exploration with an adaptive scoring function that balances both objectives while prioritizing underrepresented items.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with diversity-aware selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    diversity_scores = np.linalg.norm(normalized_obj[:, np.newaxis] - normalized_obj, axis=2).mean(axis=1)\n    weights = np.array([0.6, 0.4])\n    scores = np.dot(normalized_obj, weights) + 0.3 * diversity_scores\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    candidates = []\n    n_items = len(base_solution)\n\n    # Dynamic item grouping based on value-weight ratio\n    ratio1 = value1_lst / (weight_lst + 1e-10)\n    ratio2 = value2_lst / (weight_lst + 1e-10)\n    combined_ratio = ratio1 * 0.6 + ratio2 * 0.4\n    sorted_indices = np.argsort(combined_ratio)[::-1]\n\n    # Probabilistic swaps between high and low ratio groups\n    if n_items >= 2:\n        high_group = sorted_indices[:n_items//2]\n        low_group = sorted_indices[n_items//2:]\n\n        for _ in range(3):\n            if np.random.rand() < 0.7:\n                idx1 = np.random.choice(high_group)\n                idx2 = np.random.choice(low_group)\n            else:\n                idx1, idx2 = np.random.choice(n_items, 2, replace=False)\n\n            new_solution = base_solution.copy()\n            if new_solution[idx1] != new_solution[idx2]:\n                delta_weight = (new_solution[idx2] - new_solution[idx1]) * (weight_lst[idx1] - weight_lst[idx2])\n                if current_weight + delta_weight <= capacity:\n                    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                    candidates.append(new_solution.copy())\n\n    # Marginal gain-based exploration with adaptive weights\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    adaptive_weights = np.array([0.6, 0.4]) * (1 + 0.2 * np.random.rand(2))\n    combined_gain = marginal_gain1 * adaptive_weights[0] + marginal_gain2 * adaptive_weights[1]\n\n    k = min(5, n_items)\n    top_indices = np.argsort(combined_gain)[-k:]\n\n    for idx in top_indices:\n        new_solution = base_solution.copy()\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                candidates.append(new_solution.copy())\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                candidates.append(new_solution.copy())\n\n    if not candidates:\n        new_solution = base_solution.copy()\n        for _ in range(10):\n            flip_idx = np.random.choice(n_items)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    break\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    break\n        return new_solution\n\n    # Select best candidate with adaptive scoring\n    best_candidate = None\n    best_score = -float('inf')\n\n    for candidate in candidates:\n        candidate_weight = np.sum(weight_lst * candidate)\n        if candidate_weight > capacity:\n            continue\n\n        candidate_value1 = np.sum(value1_lst * candidate)\n        candidate_value2 = np.sum(value2_lst * candidate)\n\n        improvement1 = candidate_value1 - current_value1\n        improvement2 = candidate_value2 - current_value2\n        adaptive_weights = np.array([0.6, 0.4]) * (1 + 0.2 * np.random.rand(2))\n        score = improvement1 * adaptive_weights[0] + improvement2 * adaptive_weights[1]\n\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate.copy()\n\n    return best_candidate if best_candidate is not None else base_solution.copy()\n\n",
        "score": [
            -19.805107693135554,
            -16.56778127570379
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel hybrid local search strategy combining value-aware item selection with diversity-aware perturbations and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement in both objectives\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.prod(objectives, axis=1)  # Product of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Adaptive value-aware replacement with correlation-aware weighting\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value correlations between objectives\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # Calculate normalized value ratios with correlation weighting\n        combined_ratio = (1 - corr) * (value1_lst / (weight_lst + 1e-10)) + corr * (value2_lst / (weight_lst + 1e-10))\n\n        # Select top k items to consider for removal\n        k = min(5, len(included))\n        worst_items = np.argsort(combined_ratio[included])[:k]\n\n        for i in included[worst_items]:\n            # Try to replace with best possible item from excluded\n            best_gain = -float('inf')\n            best_idx = -1\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * (value2_lst[j] - value2_lst[i])\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_idx = j\n\n            if best_idx != -1:\n                new_solution[i] = 0\n                new_solution[best_idx] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_idx]\n                break\n\n    # Step 2: Dynamic neighborhood exploration with value diversity\n    if np.random.rand() < 0.5:\n        # Calculate value diversity for both objectives\n        value_diversity1 = np.std(value1_lst[new_solution == 1]) if len(included) > 0 else 0\n        value_diversity2 = np.std(value2_lst[new_solution == 1]) if len(included) > 0 else 0\n\n        # More exploration when diversity is low\n        diversity_threshold = 0.3\n        if value_diversity1 < diversity_threshold or value_diversity2 < diversity_threshold:\n            num_explorations = min(3, n_items)\n            explore_indices = np.random.choice(n_items, num_explorations, replace=False)\n\n            for idx in explore_indices:\n                if new_solution[idx] == 1:\n                    if current_weight - weight_lst[idx] >= 0:\n                        new_solution[idx] = 0\n                        current_weight -= weight_lst[idx]\n                else:\n                    if current_weight + weight_lst[idx] <= capacity:\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n\n    # Step 3: Hybrid greedy selection with adaptive value weighting\n    if np.random.rand() < 0.6:\n        # Calculate value efficiency with adaptive weighting\n        efficiency1 = value1_lst / (weight_lst + 1e-10)\n        efficiency2 = value2_lst / (weight_lst + 1e-10)\n\n        # Adaptive weighting based on current solution's value balance\n        value_balance = current_value1 / (current_value1 + current_value2 + 1e-10)\n        combined_efficiency = (1 - value_balance) * efficiency1 + value_balance * efficiency2\n\n        # Select top item to add\n        best_idx = -1\n        best_efficiency = -float('inf')\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                if combined_efficiency[idx] > best_efficiency:\n                    best_efficiency = combined_efficiency[idx]\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.220382838471956,
            -18.094999867663955
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on a weighted sum of normalized objectives, then applies a hybrid local search combining item flips, swaps, and adaptive neighborhood exploration with a different scoring function that prioritizes balanced improvement across both objectives.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest weighted sum of normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    weights = np.array([0.6, 0.4])  # Prioritize value1 more than value2\n    scores = np.dot(normalized_obj, weights)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Generate candidate solutions using hybrid local search\n    candidates = []\n    n_items = len(base_solution)\n\n    # 1. Random item flip with feasibility check\n    flip_idx = np.random.choice(n_items)\n    new_solution = base_solution.copy()\n    if new_solution[flip_idx] == 1:\n        if current_weight - weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 0\n            candidates.append(new_solution.copy())\n    else:\n        if current_weight + weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 1\n            candidates.append(new_solution.copy())\n\n    # 2. Swap two items if feasible\n    if n_items >= 2:\n        idx1, idx2 = np.random.choice(n_items, 2, replace=False)\n        new_solution = base_solution.copy()\n        if new_solution[idx1] != new_solution[idx2]:\n            delta_weight = (new_solution[idx2] - new_solution[idx1]) * (weight_lst[idx1] - weight_lst[idx2])\n            if current_weight + delta_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                candidates.append(new_solution.copy())\n\n    # 3. Adaptive neighborhood: add/remove items with highest marginal gain\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 * 0.6 + marginal_gain2 * 0.4 + np.random.rand(n_items) * 0.1  # Weighted randomness\n\n    k = min(5, n_items)\n    top_indices = np.argsort(combined_gain)[-k:]\n\n    for idx in top_indices:\n        new_solution = base_solution.copy()\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                candidates.append(new_solution.copy())\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                candidates.append(new_solution.copy())\n\n    if not candidates:\n        new_solution = base_solution.copy()\n        for _ in range(10):\n            flip_idx = np.random.choice(n_items)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    break\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    break\n        return new_solution\n\n    # Select the best candidate based on weighted improvement\n    best_candidate = None\n    best_score = -float('inf')\n\n    for candidate in candidates:\n        candidate_weight = np.sum(weight_lst * candidate)\n        if candidate_weight > capacity:\n            continue\n\n        candidate_value1 = np.sum(value1_lst * candidate)\n        candidate_value2 = np.sum(value2_lst * candidate)\n\n        improvement1 = candidate_value1 - current_value1\n        improvement2 = candidate_value2 - current_value2\n        score = improvement1 * 0.6 + improvement2 * 0.4  # Weighted improvement score\n\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate.copy()\n\n    return best_candidate if best_candidate is not None else base_solution.copy()\n\n",
        "score": [
            -19.72116170602232,
            -17.45441245707314
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on a diversity-aware selection criterion, then applies a hybrid local search combining dynamic item grouping, probabilistic swaps, and marginal gain-based exploration with an adaptive scoring function that balances both objectives while prioritizing underrepresented items.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with diversity-aware selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    diversity_scores = np.linalg.norm(normalized_obj[:, np.newaxis] - normalized_obj, axis=2).mean(axis=1)\n    weights = np.array([0.6, 0.4])\n    scores = np.dot(normalized_obj, weights) + 0.3 * diversity_scores\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    candidates = []\n    n_items = len(base_solution)\n\n    # Dynamic item grouping based on value-weight ratio\n    ratio1 = value1_lst / (weight_lst + 1e-10)\n    ratio2 = value2_lst / (weight_lst + 1e-10)\n    combined_ratio = ratio1 * 0.6 + ratio2 * 0.4\n    sorted_indices = np.argsort(combined_ratio)[::-1]\n\n    # Probabilistic swaps between high and low ratio groups\n    if n_items >= 2:\n        high_group = sorted_indices[:n_items//2]\n        low_group = sorted_indices[n_items//2:]\n\n        for _ in range(3):\n            if np.random.rand() < 0.7:\n                idx1 = np.random.choice(high_group)\n                idx2 = np.random.choice(low_group)\n            else:\n                idx1, idx2 = np.random.choice(n_items, 2, replace=False)\n\n            new_solution = base_solution.copy()\n            if new_solution[idx1] != new_solution[idx2]:\n                delta_weight = (new_solution[idx2] - new_solution[idx1]) * (weight_lst[idx1] - weight_lst[idx2])\n                if current_weight + delta_weight <= capacity:\n                    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                    candidates.append(new_solution.copy())\n\n    # Marginal gain-based exploration with adaptive weights\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    adaptive_weights = np.array([0.6, 0.4]) * (1 + 0.2 * np.random.rand(2))\n    combined_gain = marginal_gain1 * adaptive_weights[0] + marginal_gain2 * adaptive_weights[1]\n\n    k = min(5, n_items)\n    top_indices = np.argsort(combined_gain)[-k:]\n\n    for idx in top_indices:\n        new_solution = base_solution.copy()\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                candidates.append(new_solution.copy())\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                candidates.append(new_solution.copy())\n\n    if not candidates:\n        new_solution = base_solution.copy()\n        for _ in range(10):\n            flip_idx = np.random.choice(n_items)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    break\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    break\n        return new_solution\n\n    # Select best candidate with adaptive scoring\n    best_candidate = None\n    best_score = -float('inf')\n\n    for candidate in candidates:\n        candidate_weight = np.sum(weight_lst * candidate)\n        if candidate_weight > capacity:\n            continue\n\n        candidate_value1 = np.sum(value1_lst * candidate)\n        candidate_value2 = np.sum(value2_lst * candidate)\n\n        improvement1 = candidate_value1 - current_value1\n        improvement2 = candidate_value2 - current_value2\n        adaptive_weights = np.array([0.6, 0.4]) * (1 + 0.2 * np.random.rand(2))\n        score = improvement1 * adaptive_weights[0] + improvement2 * adaptive_weights[1]\n\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate.copy()\n\n    return best_candidate if best_candidate is not None else base_solution.copy()\n\n",
        "score": [
            -19.805107693135554,
            -16.56778127570379
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel hybrid local search strategy combining value-aware item selection with diversity-aware perturbations and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement in both objectives\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.prod(objectives, axis=1)  # Product of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-aware item selection with diversity consideration\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate normalized value ratios for both objectives\n        value_ratio1 = value1_lst / (weight_lst + 1e-10)\n        value_ratio2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine ratios with diversity weighting\n        diversity_weight = np.random.uniform(0.3, 0.7)\n        combined_ratio = diversity_weight * value_ratio1 + (1 - diversity_weight) * value_ratio2\n\n        # Select top k items to consider for removal\n        k = min(5, len(included))\n        worst_items = np.argsort(combined_ratio[included])[:k]\n\n        for i in included[worst_items]:\n            # Try to replace with best possible item from excluded\n            best_gain = -float('inf')\n            best_idx = -1\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * (value2_lst[j] - value2_lst[i])\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_idx = j\n\n            if best_idx != -1:\n                new_solution[i] = 0\n                new_solution[best_idx] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_idx]\n                break\n\n    # Step 2: Adaptive neighborhood exploration with value correlation\n    if np.random.rand() < 0.5:\n        # Calculate value correlations between objectives\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # More exploration when objectives are correlated\n        num_explorations = min(3, n_items)\n        explore_indices = np.random.choice(n_items, num_explorations, replace=False)\n\n        for idx in explore_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Local improvement with value-aware greedy selection\n    if np.random.rand() < 0.6:\n        # Calculate value efficiency for both objectives\n        efficiency1 = value1_lst / (weight_lst + 1e-10)\n        efficiency2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine efficiencies with random weights\n        random_weights = np.random.dirichlet([1, 1])\n        combined_efficiency = random_weights[0] * efficiency1 + random_weights[1] * efficiency2\n\n        # Select top item to add\n        best_idx = -1\n        best_efficiency = -float('inf')\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                if combined_efficiency[idx] > best_efficiency:\n                    best_efficiency = combined_efficiency[idx]\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.701311892881797,
            -18.788977089621042
        ]
    },
    {
        "algorithm": "{The algorithm selects a promising solution from the archive based on its potential for improvement in both objectives, then applies a novel hybrid local search strategy combining item swaps with adaptive neighborhood exploration and value-aware perturbations to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution by considering both objectives with adaptive weighting\n    objectives = np.array([obj for _, obj in archive])\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    adaptive_weights = np.random.dirichlet([1, 1])\n    scores = np.dot(normalized, adaptive_weights)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-aware item swap with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate potential gains for each pair\n        gains = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain1 = value1_lst[j] - value1_lst[i]\n                    gain2 = value2_lst[j] - value2_lst[i]\n                    gains.append((gain1 + gain2, i, j))\n\n        if gains:\n            # Select top k candidates based on combined gain\n            k = min(5, len(gains))\n            top_candidates = sorted(gains, key=lambda x: -x[0])[:k]\n            selected_gain, i, j = random.choice(top_candidates)\n            new_solution[i] = 0\n            new_solution[j] = 1\n            current_weight = current_weight - weight_lst[i] + weight_lst[j]\n\n    # Step 2: Adaptive perturbation based on objective diversity\n    objective_diversity = np.std(objectives, axis=0)\n    if np.random.rand() < 0.3 + 0.5 * (objective_diversity[0] + objective_diversity[1]):\n        # More perturbations when objectives are diverse\n        num_perturbations = min(3, n_items)\n        perturb_indices = np.random.choice(n_items, num_perturbations, replace=False)\n\n        for idx in perturb_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Local greedy improvement for the most promising objective\n    if np.random.rand() < 0.4:\n        # Choose objective to improve based on current diversity\n        obj_to_improve = 0 if objective_diversity[0] > objective_diversity[1] else 1\n        value_lst = value1_lst if obj_to_improve == 0 else value2_lst\n\n        # Find best possible addition\n        best_gain = 0\n        best_idx = -1\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                gain = value_lst[idx]\n                if gain > best_gain:\n                    best_gain = gain\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.026361479018576,
            -18.66517332072339
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on a weighted sum of normalized objectives, then applies a hybrid local search combining item flips, swaps, and adaptive neighborhood exploration with a different scoring function that prioritizes balanced improvement across both objectives.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest weighted sum of normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    weights = np.array([0.6, 0.4])  # Prioritize value1 more than value2\n    scores = np.dot(normalized_obj, weights)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Generate candidate solutions using hybrid local search\n    candidates = []\n    n_items = len(base_solution)\n\n    # 1. Random item flip with feasibility check\n    flip_idx = np.random.choice(n_items)\n    new_solution = base_solution.copy()\n    if new_solution[flip_idx] == 1:\n        if current_weight - weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 0\n            candidates.append(new_solution.copy())\n    else:\n        if current_weight + weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 1\n            candidates.append(new_solution.copy())\n\n    # 2. Swap two items if feasible\n    if n_items >= 2:\n        idx1, idx2 = np.random.choice(n_items, 2, replace=False)\n        new_solution = base_solution.copy()\n        if new_solution[idx1] != new_solution[idx2]:\n            delta_weight = (new_solution[idx2] - new_solution[idx1]) * (weight_lst[idx1] - weight_lst[idx2])\n            if current_weight + delta_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                candidates.append(new_solution.copy())\n\n    # 3. Adaptive neighborhood: add/remove items with highest marginal gain\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 * 0.6 + marginal_gain2 * 0.4 + np.random.rand(n_items) * 0.1  # Weighted randomness\n\n    k = min(5, n_items)\n    top_indices = np.argsort(combined_gain)[-k:]\n\n    for idx in top_indices:\n        new_solution = base_solution.copy()\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                candidates.append(new_solution.copy())\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                candidates.append(new_solution.copy())\n\n    if not candidates:\n        new_solution = base_solution.copy()\n        for _ in range(10):\n            flip_idx = np.random.choice(n_items)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    break\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    break\n        return new_solution\n\n    # Select the best candidate based on weighted improvement\n    best_candidate = None\n    best_score = -float('inf')\n\n    for candidate in candidates:\n        candidate_weight = np.sum(weight_lst * candidate)\n        if candidate_weight > capacity:\n            continue\n\n        candidate_value1 = np.sum(value1_lst * candidate)\n        candidate_value2 = np.sum(value2_lst * candidate)\n\n        improvement1 = candidate_value1 - current_value1\n        improvement2 = candidate_value2 - current_value2\n        score = improvement1 * 0.6 + improvement2 * 0.4  # Weighted improvement score\n\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate.copy()\n\n    return best_candidate if best_candidate is not None else base_solution.copy()\n\n",
        "score": [
            -19.72116170602232,
            -17.45441245707314
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive using a score function that combines normalized objective values with adaptive weighting based on the archive's diversity, then applies a hybrid local search strategy that includes value-aware item swaps, adaptive perturbations, and targeted greedy improvements to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution using a different score function\n    objectives = np.array([obj for _, obj in archive])\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    diversity_weights = np.random.dirichlet([2, 2])  # Different weighting strategy\n    scores = np.dot(normalized, diversity_weights)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Enhanced value-aware item swap with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate potential gains for each pair with different weighting\n        gains = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain1 = value1_lst[j] - value1_lst[i]\n                    gain2 = value2_lst[j] - value2_lst[i]\n                    combined_gain = 0.6 * gain1 + 0.4 * gain2  # Different gain combination\n                    gains.append((combined_gain, i, j))\n\n        if gains:\n            # Select top k candidates with different selection strategy\n            k = min(3, len(gains))\n            top_candidates = sorted(gains, key=lambda x: -x[0])[:k]\n            selected_gain, i, j = random.choice(top_candidates)\n            new_solution[i] = 0\n            new_solution[j] = 1\n            current_weight = current_weight - weight_lst[i] + weight_lst[j]\n\n    # Step 2: Enhanced adaptive perturbation\n    objective_diversity = np.std(objectives, axis=0)\n    perturbation_prob = 0.4 + 0.4 * (objective_diversity[0] + objective_diversity[1])\n    if np.random.rand() < perturbation_prob:\n        num_perturbations = min(5, n_items)\n        perturb_indices = np.random.choice(n_items, num_perturbations, replace=False)\n\n        for idx in perturb_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Enhanced local greedy improvement\n    if np.random.rand() < 0.5:\n        # Different objective selection strategy\n        obj_to_improve = 0 if np.random.rand() < 0.6 else 1\n        value_lst = value1_lst if obj_to_improve == 0 else value2_lst\n\n        # Find best possible addition with different criteria\n        best_gain = 0\n        best_idx = -1\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                gain = value_lst[idx] * (1 + 0.2 * np.random.rand())  # Add randomness\n                if gain > best_gain:\n                    best_gain = gain\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.467440043233896,
            -18.080729088897666
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on a weighted sum of normalized objectives, then applies a hybrid local search combining item flips, swaps, and adaptive neighborhood exploration with a different scoring function that prioritizes balanced improvement across both objectives.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest weighted sum of normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    weights = np.array([0.6, 0.4])  # Prioritize value1 more than value2\n    scores = np.dot(normalized_obj, weights)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Generate candidate solutions using hybrid local search\n    candidates = []\n    n_items = len(base_solution)\n\n    # 1. Random item flip with feasibility check\n    flip_idx = np.random.choice(n_items)\n    new_solution = base_solution.copy()\n    if new_solution[flip_idx] == 1:\n        if current_weight - weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 0\n            candidates.append(new_solution.copy())\n    else:\n        if current_weight + weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 1\n            candidates.append(new_solution.copy())\n\n    # 2. Swap two items if feasible\n    if n_items >= 2:\n        idx1, idx2 = np.random.choice(n_items, 2, replace=False)\n        new_solution = base_solution.copy()\n        if new_solution[idx1] != new_solution[idx2]:\n            delta_weight = (new_solution[idx2] - new_solution[idx1]) * (weight_lst[idx1] - weight_lst[idx2])\n            if current_weight + delta_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                candidates.append(new_solution.copy())\n\n    # 3. Adaptive neighborhood: add/remove items with highest marginal gain\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 * 0.6 + marginal_gain2 * 0.4 + np.random.rand(n_items) * 0.1  # Weighted randomness\n\n    k = min(5, n_items)\n    top_indices = np.argsort(combined_gain)[-k:]\n\n    for idx in top_indices:\n        new_solution = base_solution.copy()\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                candidates.append(new_solution.copy())\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                candidates.append(new_solution.copy())\n\n    if not candidates:\n        new_solution = base_solution.copy()\n        for _ in range(10):\n            flip_idx = np.random.choice(n_items)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    break\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    break\n        return new_solution\n\n    # Select the best candidate based on weighted improvement\n    best_candidate = None\n    best_score = -float('inf')\n\n    for candidate in candidates:\n        candidate_weight = np.sum(weight_lst * candidate)\n        if candidate_weight > capacity:\n            continue\n\n        candidate_value1 = np.sum(value1_lst * candidate)\n        candidate_value2 = np.sum(value2_lst * candidate)\n\n        improvement1 = candidate_value1 - current_value1\n        improvement2 = candidate_value2 - current_value2\n        score = improvement1 * 0.6 + improvement2 * 0.4  # Weighted improvement score\n\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate.copy()\n\n    return best_candidate if best_candidate is not None else base_solution.copy()\n\n",
        "score": [
            -19.72116170602232,
            -17.45441245707314
        ]
    },
    {
        "algorithm": "{The algorithm selects a promising solution from the archive based on its potential for improvement in both objectives, then applies a novel hybrid local search strategy combining item swaps with adaptive neighborhood exploration and value-aware perturbations to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution by considering both objectives with adaptive weighting\n    objectives = np.array([obj for _, obj in archive])\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    adaptive_weights = np.random.dirichlet([1, 1])\n    scores = np.dot(normalized, adaptive_weights)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-aware item swap with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate potential gains for each pair\n        gains = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain1 = value1_lst[j] - value1_lst[i]\n                    gain2 = value2_lst[j] - value2_lst[i]\n                    gains.append((gain1 + gain2, i, j))\n\n        if gains:\n            # Select top k candidates based on combined gain\n            k = min(5, len(gains))\n            top_candidates = sorted(gains, key=lambda x: -x[0])[:k]\n            selected_gain, i, j = random.choice(top_candidates)\n            new_solution[i] = 0\n            new_solution[j] = 1\n            current_weight = current_weight - weight_lst[i] + weight_lst[j]\n\n    # Step 2: Adaptive perturbation based on objective diversity\n    objective_diversity = np.std(objectives, axis=0)\n    if np.random.rand() < 0.3 + 0.5 * (objective_diversity[0] + objective_diversity[1]):\n        # More perturbations when objectives are diverse\n        num_perturbations = min(3, n_items)\n        perturb_indices = np.random.choice(n_items, num_perturbations, replace=False)\n\n        for idx in perturb_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Local greedy improvement for the most promising objective\n    if np.random.rand() < 0.4:\n        # Choose objective to improve based on current diversity\n        obj_to_improve = 0 if objective_diversity[0] > objective_diversity[1] else 1\n        value_lst = value1_lst if obj_to_improve == 0 else value2_lst\n\n        # Find best possible addition\n        best_gain = 0\n        best_idx = -1\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                gain = value_lst[idx]\n                if gain > best_gain:\n                    best_gain = gain\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.038464887439495,
            -18.62077325272734
        ]
    },
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel hybrid local search strategy combining item swaps with adaptive neighborhood exploration, value-aware perturbations, and multi-objective greedy improvements to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution by considering both objectives with adaptive weighting\n    objectives = np.array([obj for _, obj in archive])\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    adaptive_weights = np.random.dirichlet([1, 1])\n    scores = np.dot(normalized, adaptive_weights)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Multi-objective item swap with adaptive neighborhood\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate potential gains for each pair\n        gains = []\n        for i in included:\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain1 = value1_lst[j] - value1_lst[i]\n                    gain2 = value2_lst[j] - value2_lst[i]\n                    gains.append((gain1 + gain2, i, j))\n\n        if gains:\n            # Select top k candidates based on combined gain\n            k = min(3, len(gains))\n            top_candidates = sorted(gains, key=lambda x: -x[0])[:k]\n            selected_gain, i, j = random.choice(top_candidates)\n            new_solution[i] = 0\n            new_solution[j] = 1\n            current_weight = current_weight - weight_lst[i] + weight_lst[j]\n\n    # Step 2: Adaptive perturbation based on objective diversity\n    objective_diversity = np.std(objectives, axis=0)\n    if np.random.rand() < 0.4 + 0.4 * (objective_diversity[0] + objective_diversity[1]):\n        num_perturbations = min(2, n_items)\n        perturb_indices = np.random.choice(n_items, num_perturbations, replace=False)\n\n        for idx in perturb_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Multi-objective greedy improvement\n    if np.random.rand() < 0.5:\n        # Choose objective to improve based on current diversity\n        obj_to_improve = 0 if objective_diversity[0] > objective_diversity[1] else 1\n        value_lst = value1_lst if obj_to_improve == 0 else value2_lst\n\n        # Find best possible addition\n        best_gain = 0\n        best_idx = -1\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                gain = value_lst[idx]\n                if gain > best_gain:\n                    best_gain = gain\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.079196598283335,
            -18.581771485288467
        ]
    },
    {
        "algorithm": "{The algorithm intelligently selects a solution from the archive based on its potential for improvement, then applies a hybrid local search operator that combines item swaps, flips, and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest sum of normalized objectives as a starting point\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    scores = normalized_obj.sum(axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Generate candidate solutions using hybrid local search\n    candidates = []\n    n_items = len(base_solution)\n\n    # 1. Random item flip with feasibility check\n    flip_idx = np.random.choice(n_items)\n    new_solution = base_solution.copy()\n    if new_solution[flip_idx] == 1:\n        if current_weight - weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 0\n            candidates.append(new_solution.copy())\n    else:\n        if current_weight + weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 1\n            candidates.append(new_solution.copy())\n\n    # 2. Swap two items if feasible\n    if n_items >= 2:\n        idx1, idx2 = np.random.choice(n_items, 2, replace=False)\n        new_solution = base_solution.copy()\n        if new_solution[idx1] != new_solution[idx2]:\n            delta_weight = (new_solution[idx2] - new_solution[idx1]) * (weight_lst[idx1] - weight_lst[idx2])\n            if current_weight + delta_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                candidates.append(new_solution.copy())\n\n    # 3. Adaptive neighborhood: add/remove items with highest marginal gain\n    # Calculate marginal gains for each item\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Combine marginal gains with randomness\n    combined_gain = marginal_gain1 + marginal_gain2 + np.random.rand(n_items) * 0.1\n\n    # Select top k items to consider\n    k = min(5, n_items)\n    top_indices = np.argsort(combined_gain)[-k:]\n\n    for idx in top_indices:\n        new_solution = base_solution.copy()\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                candidates.append(new_solution.copy())\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                candidates.append(new_solution.copy())\n\n    if not candidates:\n        # If no candidates found, return a slightly modified version of the base solution\n        new_solution = base_solution.copy()\n        # Try to flip a random item that doesn't violate capacity\n        for _ in range(10):\n            flip_idx = np.random.choice(n_items)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    break\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    break\n        return new_solution\n\n    # Select the best candidate based on combined objective improvement\n    best_candidate = None\n    best_score = -float('inf')\n\n    for candidate in candidates:\n        candidate_weight = np.sum(weight_lst * candidate)\n        if candidate_weight > capacity:\n            continue\n\n        candidate_value1 = np.sum(value1_lst * candidate)\n        candidate_value2 = np.sum(value2_lst * candidate)\n\n        # Calculate improvement score\n        improvement1 = candidate_value1 - current_value1\n        improvement2 = candidate_value2 - current_value2\n        score = improvement1 + improvement2\n\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate.copy()\n\n    return best_candidate if best_candidate is not None else base_solution.copy()\n\n",
        "score": [
            -19.175428418766153,
            -18.319888943682244
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on a weighted sum of normalized objectives, then applies a hybrid local search combining item flips, swaps, and adaptive neighborhood exploration with a different scoring function that prioritizes balanced improvement across both objectives.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest weighted sum of normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    weights = np.array([0.6, 0.4])  # Prioritize value1 more than value2\n    scores = np.dot(normalized_obj, weights)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Generate candidate solutions using hybrid local search\n    candidates = []\n    n_items = len(base_solution)\n\n    # 1. Random item flip with feasibility check\n    flip_idx = np.random.choice(n_items)\n    new_solution = base_solution.copy()\n    if new_solution[flip_idx] == 1:\n        if current_weight - weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 0\n            candidates.append(new_solution.copy())\n    else:\n        if current_weight + weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 1\n            candidates.append(new_solution.copy())\n\n    # 2. Swap two items if feasible\n    if n_items >= 2:\n        idx1, idx2 = np.random.choice(n_items, 2, replace=False)\n        new_solution = base_solution.copy()\n        if new_solution[idx1] != new_solution[idx2]:\n            delta_weight = (new_solution[idx2] - new_solution[idx1]) * (weight_lst[idx1] - weight_lst[idx2])\n            if current_weight + delta_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                candidates.append(new_solution.copy())\n\n    # 3. Adaptive neighborhood: add/remove items with highest marginal gain\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 * 0.6 + marginal_gain2 * 0.4 + np.random.rand(n_items) * 0.1  # Weighted randomness\n\n    k = min(5, n_items)\n    top_indices = np.argsort(combined_gain)[-k:]\n\n    for idx in top_indices:\n        new_solution = base_solution.copy()\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                candidates.append(new_solution.copy())\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                candidates.append(new_solution.copy())\n\n    if not candidates:\n        new_solution = base_solution.copy()\n        for _ in range(10):\n            flip_idx = np.random.choice(n_items)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    break\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    break\n        return new_solution\n\n    # Select the best candidate based on weighted improvement\n    best_candidate = None\n    best_score = -float('inf')\n\n    for candidate in candidates:\n        candidate_weight = np.sum(weight_lst * candidate)\n        if candidate_weight > capacity:\n            continue\n\n        candidate_value1 = np.sum(value1_lst * candidate)\n        candidate_value2 = np.sum(value2_lst * candidate)\n\n        improvement1 = candidate_value1 - current_value1\n        improvement2 = candidate_value2 - current_value2\n        score = improvement1 * 0.6 + improvement2 * 0.4  # Weighted improvement score\n\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate.copy()\n\n    return best_candidate if best_candidate is not None else base_solution.copy()\n\n",
        "score": [
            -19.72116170602232,
            -17.45441245707314
        ]
    },
    {
        "algorithm": "{The algorithm intelligently selects a solution from the archive based on its potential for improvement, then applies a hybrid local search operator that combines item swaps, flips, and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest sum of normalized objectives as a starting point\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    scores = normalized_obj.sum(axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Generate candidate solutions using hybrid local search\n    candidates = []\n    n_items = len(base_solution)\n\n    # 1. Random item flip with feasibility check\n    flip_idx = np.random.choice(n_items)\n    new_solution = base_solution.copy()\n    if new_solution[flip_idx] == 1:\n        if current_weight - weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 0\n            candidates.append(new_solution.copy())\n    else:\n        if current_weight + weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 1\n            candidates.append(new_solution.copy())\n\n    # 2. Swap two items if feasible\n    if n_items >= 2:\n        idx1, idx2 = np.random.choice(n_items, 2, replace=False)\n        new_solution = base_solution.copy()\n        if new_solution[idx1] != new_solution[idx2]:\n            delta_weight = (new_solution[idx2] - new_solution[idx1]) * (weight_lst[idx1] - weight_lst[idx2])\n            if current_weight + delta_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                candidates.append(new_solution.copy())\n\n    # 3. Adaptive neighborhood: add/remove items with highest marginal gain\n    # Calculate marginal gains for each item\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Combine marginal gains with randomness\n    combined_gain = marginal_gain1 + marginal_gain2 + np.random.rand(n_items) * 0.1\n\n    # Select top k items to consider\n    k = min(5, n_items)\n    top_indices = np.argsort(combined_gain)[-k:]\n\n    for idx in top_indices:\n        new_solution = base_solution.copy()\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                candidates.append(new_solution.copy())\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                candidates.append(new_solution.copy())\n\n    if not candidates:\n        # If no candidates found, return a slightly modified version of the base solution\n        new_solution = base_solution.copy()\n        # Try to flip a random item that doesn't violate capacity\n        for _ in range(10):\n            flip_idx = np.random.choice(n_items)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    break\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    break\n        return new_solution\n\n    # Select the best candidate based on combined objective improvement\n    best_candidate = None\n    best_score = -float('inf')\n\n    for candidate in candidates:\n        candidate_weight = np.sum(weight_lst * candidate)\n        if candidate_weight > capacity:\n            continue\n\n        candidate_value1 = np.sum(value1_lst * candidate)\n        candidate_value2 = np.sum(value2_lst * candidate)\n\n        # Calculate improvement score\n        improvement1 = candidate_value1 - current_value1\n        improvement2 = candidate_value2 - current_value2\n        score = improvement1 + improvement2\n\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate.copy()\n\n    return best_candidate if best_candidate is not None else base_solution.copy()\n\n",
        "score": [
            -19.175428418766153,
            -18.319888943682244
        ]
    },
    {
        "algorithm": "{The algorithm intelligently selects a solution from the archive based on its potential for improvement, then applies a hybrid local search operator that combines item swaps, flips, and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest sum of normalized objectives as a starting point\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    scores = normalized_obj.sum(axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Generate candidate solutions using hybrid local search\n    candidates = []\n    n_items = len(base_solution)\n\n    # 1. Random item flip with feasibility check\n    flip_idx = np.random.choice(n_items)\n    new_solution = base_solution.copy()\n    if new_solution[flip_idx] == 1:\n        if current_weight - weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 0\n            candidates.append(new_solution.copy())\n    else:\n        if current_weight + weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 1\n            candidates.append(new_solution.copy())\n\n    # 2. Swap two items if feasible\n    if n_items >= 2:\n        idx1, idx2 = np.random.choice(n_items, 2, replace=False)\n        new_solution = base_solution.copy()\n        if new_solution[idx1] != new_solution[idx2]:\n            delta_weight = (new_solution[idx2] - new_solution[idx1]) * (weight_lst[idx1] - weight_lst[idx2])\n            if current_weight + delta_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                candidates.append(new_solution.copy())\n\n    # 3. Adaptive neighborhood: add/remove items with highest marginal gain\n    # Calculate marginal gains for each item\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Combine marginal gains with randomness\n    combined_gain = marginal_gain1 + marginal_gain2 + np.random.rand(n_items) * 0.1\n\n    # Select top k items to consider\n    k = min(5, n_items)\n    top_indices = np.argsort(combined_gain)[-k:]\n\n    for idx in top_indices:\n        new_solution = base_solution.copy()\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                candidates.append(new_solution.copy())\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                candidates.append(new_solution.copy())\n\n    if not candidates:\n        # If no candidates found, return a slightly modified version of the base solution\n        new_solution = base_solution.copy()\n        # Try to flip a random item that doesn't violate capacity\n        for _ in range(10):\n            flip_idx = np.random.choice(n_items)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    break\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    break\n        return new_solution\n\n    # Select the best candidate based on combined objective improvement\n    best_candidate = None\n    best_score = -float('inf')\n\n    for candidate in candidates:\n        candidate_weight = np.sum(weight_lst * candidate)\n        if candidate_weight > capacity:\n            continue\n\n        candidate_value1 = np.sum(value1_lst * candidate)\n        candidate_value2 = np.sum(value2_lst * candidate)\n\n        # Calculate improvement score\n        improvement1 = candidate_value1 - current_value1\n        improvement2 = candidate_value2 - current_value2\n        score = improvement1 + improvement2\n\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate.copy()\n\n    return best_candidate if best_candidate is not None else base_solution.copy()\n\n",
        "score": [
            -19.175428418766153,
            -18.319888943682244
        ]
    }
]