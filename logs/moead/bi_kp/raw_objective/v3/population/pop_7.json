[
    {
        "algorithm": "{The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a novel hybrid local search strategy combining value-aware item selection with diversity-aware perturbations and adaptive neighborhood exploration to generate a high-quality neighbor solution while ensuring feasibility.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement in both objectives\n    objectives = np.array([obj for _, obj in archive])\n    potential = np.prod(objectives, axis=1)  # Product of objectives as improvement potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Value-aware item selection with diversity consideration\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate normalized value ratios for both objectives\n        value_ratio1 = value1_lst / (weight_lst + 1e-10)\n        value_ratio2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine ratios with diversity weighting\n        diversity_weight = np.random.uniform(0.3, 0.7)\n        combined_ratio = diversity_weight * value_ratio1 + (1 - diversity_weight) * value_ratio2\n\n        # Select top k items to consider for removal\n        k = min(5, len(included))\n        worst_items = np.argsort(combined_ratio[included])[:k]\n\n        for i in included[worst_items]:\n            # Try to replace with best possible item from excluded\n            best_gain = -float('inf')\n            best_idx = -1\n            for j in excluded:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    gain = (value1_lst[j] - value1_lst[i]) * (value2_lst[j] - value2_lst[i])\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_idx = j\n\n            if best_idx != -1:\n                new_solution[i] = 0\n                new_solution[best_idx] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_idx]\n                break\n\n    # Step 2: Adaptive neighborhood exploration with value correlation\n    if np.random.rand() < 0.5:\n        # Calculate value correlations between objectives\n        corr = np.corrcoef(value1_lst, value2_lst)[0, 1]\n        if np.isnan(corr):\n            corr = 0\n\n        # More exploration when objectives are correlated\n        num_explorations = min(3, n_items)\n        explore_indices = np.random.choice(n_items, num_explorations, replace=False)\n\n        for idx in explore_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 3: Local improvement with value-aware greedy selection\n    if np.random.rand() < 0.6:\n        # Calculate value efficiency for both objectives\n        efficiency1 = value1_lst / (weight_lst + 1e-10)\n        efficiency2 = value2_lst / (weight_lst + 1e-10)\n\n        # Combine efficiencies with random weights\n        random_weights = np.random.dirichlet([1, 1])\n        combined_efficiency = random_weights[0] * efficiency1 + random_weights[1] * efficiency2\n\n        # Select top item to add\n        best_idx = -1\n        best_efficiency = -float('inf')\n        for idx in np.where(new_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                if combined_efficiency[idx] > best_efficiency:\n                    best_efficiency = combined_efficiency[idx]\n                    best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -18.701311892881797,
            -18.788977089621042
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive based on a diversity-aware selection criterion, then applies a hybrid local search combining dynamic item grouping, probabilistic swaps, and marginal gain-based exploration with an adaptive scoring function that balances both objectives while prioritizing underrepresented items.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with diversity-aware selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    diversity_scores = np.linalg.norm(normalized_obj[:, np.newaxis] - normalized_obj, axis=2).mean(axis=1)\n    weights = np.array([0.6, 0.4])\n    scores = np.dot(normalized_obj, weights) + 0.3 * diversity_scores\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    candidates = []\n    n_items = len(base_solution)\n\n    # Dynamic item grouping based on value-weight ratio\n    ratio1 = value1_lst / (weight_lst + 1e-10)\n    ratio2 = value2_lst / (weight_lst + 1e-10)\n    combined_ratio = ratio1 * 0.6 + ratio2 * 0.4\n    sorted_indices = np.argsort(combined_ratio)[::-1]\n\n    # Probabilistic swaps between high and low ratio groups\n    if n_items >= 2:\n        high_group = sorted_indices[:n_items//2]\n        low_group = sorted_indices[n_items//2:]\n\n        for _ in range(3):\n            if np.random.rand() < 0.7:\n                idx1 = np.random.choice(high_group)\n                idx2 = np.random.choice(low_group)\n            else:\n                idx1, idx2 = np.random.choice(n_items, 2, replace=False)\n\n            new_solution = base_solution.copy()\n            if new_solution[idx1] != new_solution[idx2]:\n                delta_weight = (new_solution[idx2] - new_solution[idx1]) * (weight_lst[idx1] - weight_lst[idx2])\n                if current_weight + delta_weight <= capacity:\n                    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                    candidates.append(new_solution.copy())\n\n    # Marginal gain-based exploration with adaptive weights\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    adaptive_weights = np.array([0.6, 0.4]) * (1 + 0.2 * np.random.rand(2))\n    combined_gain = marginal_gain1 * adaptive_weights[0] + marginal_gain2 * adaptive_weights[1]\n\n    k = min(5, n_items)\n    top_indices = np.argsort(combined_gain)[-k:]\n\n    for idx in top_indices:\n        new_solution = base_solution.copy()\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                candidates.append(new_solution.copy())\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                candidates.append(new_solution.copy())\n\n    if not candidates:\n        new_solution = base_solution.copy()\n        for _ in range(10):\n            flip_idx = np.random.choice(n_items)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    break\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    break\n        return new_solution\n\n    # Select best candidate with adaptive scoring\n    best_candidate = None\n    best_score = -float('inf')\n\n    for candidate in candidates:\n        candidate_weight = np.sum(weight_lst * candidate)\n        if candidate_weight > capacity:\n            continue\n\n        candidate_value1 = np.sum(value1_lst * candidate)\n        candidate_value2 = np.sum(value2_lst * candidate)\n\n        improvement1 = candidate_value1 - current_value1\n        improvement2 = candidate_value2 - current_value2\n        adaptive_weights = np.array([0.6, 0.4]) * (1 + 0.2 * np.random.rand(2))\n        score = improvement1 * adaptive_weights[0] + improvement2 * adaptive_weights[1]\n\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate.copy()\n\n    return best_candidate if best_candidate is not None else base_solution.copy()\n\n",
        "score": [
            -19.805107693135554,
            -16.56778127570379
        ]
    }
]