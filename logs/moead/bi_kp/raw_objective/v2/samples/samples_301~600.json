[
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have one algorithm with its code as follows. Algorithm description:\n{The new algorithm selects a solution from the archive using a hypervolume-aware selection, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's hypervolume contribution, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius based on the solution's position in the Pareto front.}\nCode:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    selected_idx = np.argmax(np.prod(normalized, axis=1))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    hv_contribution = np.prod(normalized[selected_idx])\n    alpha = 0.9 if hv_contribution > 0.5 else 0.1\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    exploration_radius = min(4, len(candidates))\n    for _ in range(5):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n\nPlease assist me in creating a new algorithm that has a different form but can be a modified version of the algorithm provided.\n1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nDo not give additional explanations.",
        "sample_order": 301,
        "algorithm": "{The new algorithm selects a solution from the archive using a crowding-distance-aware selection, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-value ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's crowding distance contribution, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius based on the solution's position in the Pareto front.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n\n    crowding_distances = np.zeros(len(archive))\n    sorted_indices = np.argsort(objectives[:, 0])\n    crowding_distances[sorted_indices[0]] = crowding_distances[sorted_indices[-1]] = float('inf')\n    for i in range(1, len(archive) - 1):\n        crowding_distances[sorted_indices[i]] = abs(objectives[sorted_indices[i+1], 0] - objectives[sorted_indices[i-1], 0]) / (max_v1 - 0)\n\n    sorted_indices = np.argsort(objectives[:, 1])\n    crowding_distances[sorted_indices[0]] = crowding_distances[sorted_indices[-1]] = float('inf')\n    for i in range(1, len(archive) - 1):\n        crowding_distances[sorted_indices[i]] += abs(objectives[sorted_indices[i+1], 1] - objectives[sorted_indices[i-1], 1]) / (max_v2 - 0)\n\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    cd_contribution = crowding_distances[selected_idx]\n    beta = 0.7 if cd_contribution > np.median(crowding_distances) else 0.3\n    vv_ratio = (value1_lst * beta + value2_lst * (1 - beta)) / (value1_lst + value2_lst + 1e-6)\n\n    exploration_radius = min(3, len(candidates))\n    for _ in range(4):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            remove_candidates = sorted(candidates, key=lambda i: -vv_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vv_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(-vv_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -15.821484033012466,
            -15.100768316891843
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n\n    crowding_distances = np.zeros(len(archive))\n    sorted_indices = np.argsort(objectives[:, 0])\n    crowding_distances[sorted_indices[0]] = crowding_distances[sorted_indices[-1]] = float('inf')\n    for i in range(1, len(archive) - 1):\n        crowding_distances[sorted_indices[i]] = abs(objectives[sorted_indices[i+1], 0] - objectives[sorted_indices[i-1], 0]) / (max_v1 - 0)\n\n    sorted_indices = np.argsort(objectives[:, 1])\n    crowding_distances[sorted_indices[0]] = crowding_distances[sorted_indices[-1]] = float('inf')\n    for i in range(1, len(archive) - 1):\n        crowding_distances[sorted_indices[i]] += abs(objectives[sorted_indices[i+1], 1] - objectives[sorted_indices[i-1], 1]) / (max_v2 - 0)\n\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    cd_contribution = crowding_distances[selected_idx]\n    beta = 0.7 if cd_contribution > np.median(crowding_distances) else 0.3\n    vv_ratio = (value1_lst * beta + value2_lst * (1 - beta)) / (value1_lst + value2_lst + 1e-6)\n\n    exploration_radius = min(3, len(candidates))\n    for _ in range(4):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            remove_candidates = sorted(candidates, key=lambda i: -vv_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vv_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(-vv_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have one algorithm with its code as follows. Algorithm description:\n{The new algorithm selects a solution from the archive using a hypervolume-aware selection, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's hypervolume contribution, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius based on the solution's position in the Pareto front.}\nCode:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    selected_idx = np.argmax(np.prod(normalized, axis=1))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    hv_contribution = np.prod(normalized[selected_idx])\n    alpha = 0.9 if hv_contribution > 0.5 else 0.1\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    exploration_radius = min(4, len(candidates))\n    for _ in range(5):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n\nPlease identify the main algorithm parameters and assist me in creating a new algorithm that has a different parameter settings of the score function provided.\n1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nDo not give additional explanations.",
        "sample_order": 302,
        "algorithm": "{The new algorithm selects a solution from the archive using a crowding-distance-aware selection, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's crowding distance, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius based on the solution's position in the Pareto front.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    objectives = np.array([obj for _, obj in archive])\n    crowding_dist = np.zeros(len(archive))\n    for i in range(2):\n        sorted_indices = np.argsort(objectives[:, i])\n        crowding_dist[sorted_indices[0]] = np.inf\n        crowding_dist[sorted_indices[-1]] = np.inf\n        for j in range(1, len(archive) - 1):\n            if objectives[sorted_indices[-1], i] == objectives[sorted_indices[0], i]:\n                crowding_dist[sorted_indices[j]] += 0\n            else:\n                crowding_dist[sorted_indices[j]] += (objectives[sorted_indices[j+1], i] - objectives[sorted_indices[j-1], i]) / (objectives[sorted_indices[-1], i] - objectives[sorted_indices[0], i])\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    cd_contribution = crowding_dist[selected_idx]\n    beta = 0.8 if cd_contribution > np.median(crowding_dist) else 0.2\n    vw_ratio = (value1_lst * beta + value2_lst * (1 - beta)) / weight_lst\n\n    exploration_radius = min(3, len(candidates))\n    for _ in range(4):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            remove_candidates = sorted(candidates, key=lambda i: -vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(-vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -13.825520668886355,
            -13.723149202250028
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    objectives = np.array([obj for _, obj in archive])\n    crowding_dist = np.zeros(len(archive))\n    for i in range(2):\n        sorted_indices = np.argsort(objectives[:, i])\n        crowding_dist[sorted_indices[0]] = np.inf\n        crowding_dist[sorted_indices[-1]] = np.inf\n        for j in range(1, len(archive) - 1):\n            if objectives[sorted_indices[-1], i] == objectives[sorted_indices[0], i]:\n                crowding_dist[sorted_indices[j]] += 0\n            else:\n                crowding_dist[sorted_indices[j]] += (objectives[sorted_indices[j+1], i] - objectives[sorted_indices[j-1], i]) / (objectives[sorted_indices[-1], i] - objectives[sorted_indices[0], i])\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    cd_contribution = crowding_dist[selected_idx]\n    beta = 0.8 if cd_contribution > np.median(crowding_dist) else 0.2\n    vw_ratio = (value1_lst * beta + value2_lst * (1 - beta)) / weight_lst\n\n    exploration_radius = min(3, len(candidates))\n    for _ in range(4):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            remove_candidates = sorted(candidates, key=lambda i: -vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(-vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{The new algorithm selects a solution from the archive using a novel diversity-aware selection based on the angle between normalized objectives and a reference direction, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's dominance count, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Diversity-aware selection based on angle with reference direction\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    reference_dir = np.array([0.7, 0.3])  # Predefined reference direction\n    angles = np.arccos(np.clip(np.dot(normalized, reference_dir), -1.0, 1.0))\n    selected_idx = np.argmin(angles)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on dominance count\n    dominance_count = sum(1 for obj in objectives if (obj[0] > objectives[selected_idx][0] and obj[1] >= objectives[selected_idx][1]) or (obj[0] >= objectives[selected_idx][0] and obj[1] > objectives[selected_idx][1]))\n    alpha = 0.8 if dominance_count > 0 else 0.2\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(5, len(candidates))\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio and correlation\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio and correlation\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with correlation-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{The new algorithm selects a solution from the archive using a novel diversity-aware selection based on the angle between normalized objectives and a reference direction, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's dominance count, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Diversity-aware selection based on angle with reference direction\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    reference_dir = np.array([0.7, 0.3])  # Predefined reference direction\n    angles = np.arccos(np.clip(np.dot(normalized, reference_dir), -1.0, 1.0))\n    selected_idx = np.argmin(angles)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on dominance count\n    dominance_count = sum(1 for obj in objectives if (obj[0] > objectives[selected_idx][0] and obj[1] >= objectives[selected_idx][1]) or (obj[0] >= objectives[selected_idx][0] and obj[1] > objectives[selected_idx][1]))\n    alpha = 0.8 if dominance_count > 0 else 0.2\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(5, len(candidates))\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio and correlation\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio and correlation\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with correlation-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n\nPlease help me create a new algorithm that has a totally different form from the given ones. \n1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nDo not give additional explanations.",
        "sample_order": 303,
        "algorithm": "{The new algorithm selects a solution from the archive using a novelty-aware selection based on the Euclidean distance to a dynamically adjusted reference point, then applies a hybrid local search combining adaptive item grouping with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's dominance count, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius, and employs a targeted flip mechanism that considers both individual and pairwise item effects.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Novelty-aware selection based on Euclidean distance to dynamic reference point\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    reference_point = np.array([0.6, 0.4])  # Dynamic reference point\n    distances = np.linalg.norm(normalized - reference_point, axis=1)\n    selected_idx = np.argmax(distances)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on dominance count\n    dominance_count = sum(1 for obj in objectives if (obj[0] > objectives[selected_idx][0] and obj[1] >= objectives[selected_idx][1]) or (obj[0] >= objectives[selected_idx][0] and obj[1] > objectives[selected_idx][1]))\n    alpha = 0.7 if dominance_count > 0 else 0.3\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with adaptive item grouping\n    group_size = min(3, len(candidates))\n    for _ in range(2):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Group items based on similarity in value-to-weight ratio\n            groups = []\n            sorted_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            for i in range(0, len(sorted_candidates), group_size):\n                groups.append(sorted_candidates[i:i+group_size])\n\n            # Select group to remove based on lowest average value-to-weight ratio\n            group_scores = [np.mean([vw_ratio[i] for i in group]) for group in groups]\n            remove_group = groups[np.argmin(group_scores)]\n            temp_weight = current_weight - np.sum(weight_lst[remove_group])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_group:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # Targeted flip mechanism considering pairwise effects\n    if np.array_equal(new_solution, base_solution) and len(candidates) > 0 and len(non_candidates) > 0:\n        # Calculate pairwise correlations\n        corr_matrix = np.corrcoef(np.vstack([value1_lst, value2_lst]))\n        corr_scores = np.zeros(len(candidates))\n        for i, idx in enumerate(candidates):\n            corr_scores[i] = np.sum(corr_matrix[0, value1_lst != 0] + corr_matrix[1, value2_lst != 0])\n\n        # Select item to flip based on lowest correlation score\n        flip_idx = candidates[np.argmin(corr_scores)]\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] >= 0:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -17.027695784104598,
            -17.993743676145073
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Novelty-aware selection based on Euclidean distance to dynamic reference point\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    reference_point = np.array([0.6, 0.4])  # Dynamic reference point\n    distances = np.linalg.norm(normalized - reference_point, axis=1)\n    selected_idx = np.argmax(distances)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on dominance count\n    dominance_count = sum(1 for obj in objectives if (obj[0] > objectives[selected_idx][0] and obj[1] >= objectives[selected_idx][1]) or (obj[0] >= objectives[selected_idx][0] and obj[1] > objectives[selected_idx][1]))\n    alpha = 0.7 if dominance_count > 0 else 0.3\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with adaptive item grouping\n    group_size = min(3, len(candidates))\n    for _ in range(2):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Group items based on similarity in value-to-weight ratio\n            groups = []\n            sorted_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            for i in range(0, len(sorted_candidates), group_size):\n                groups.append(sorted_candidates[i:i+group_size])\n\n            # Select group to remove based on lowest average value-to-weight ratio\n            group_scores = [np.mean([vw_ratio[i] for i in group]) for group in groups]\n            remove_group = groups[np.argmin(group_scores)]\n            temp_weight = current_weight - np.sum(weight_lst[remove_group])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_group:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # Targeted flip mechanism considering pairwise effects\n    if np.array_equal(new_solution, base_solution) and len(candidates) > 0 and len(non_candidates) > 0:\n        # Calculate pairwise correlations\n        corr_matrix = np.corrcoef(np.vstack([value1_lst, value2_lst]))\n        corr_scores = np.zeros(len(candidates))\n        for i, idx in enumerate(candidates):\n            corr_scores[i] = np.sum(corr_matrix[0, value1_lst != 0] + corr_matrix[1, value2_lst != 0])\n\n        # Select item to flip based on lowest correlation score\n        flip_idx = candidates[np.argmin(corr_scores)]\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] >= 0:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have one algorithm with its code as follows. Algorithm description:\n{The new algorithm selects a solution from the archive using a hypervolume-aware selection, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's hypervolume contribution, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius based on the solution's position in the Pareto front.}\nCode:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    selected_idx = np.argmax(np.prod(normalized, axis=1))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    hv_contribution = np.prod(normalized[selected_idx])\n    alpha = 0.9 if hv_contribution > 0.5 else 0.1\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    exploration_radius = min(4, len(candidates))\n    for _ in range(5):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n\nPlease identify the main algorithm parameters and assist me in creating a new algorithm that has a different parameter settings of the score function provided.\n1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nDo not give additional explanations.",
        "sample_order": 304,
        "algorithm": "{The new algorithm selects a solution from the archive using a crowding-distance-aware selection, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's crowding distance, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius based on the solution's position in the Pareto front.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    objectives = np.array([obj for _, obj in archive])\n    crowding_dist = np.zeros(len(archive))\n    for i in range(2):\n        sorted_indices = np.argsort(objectives[:, i])\n        crowding_dist[sorted_indices[0]] = np.inf\n        crowding_dist[sorted_indices[-1]] = np.inf\n        for j in range(1, len(archive)-1):\n            crowding_dist[sorted_indices[j]] += (objectives[sorted_indices[j+1], i] - objectives[sorted_indices[j-1], i]) / (objectives[sorted_indices[-1], i] - objectives[sorted_indices[0], i])\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    cd_contribution = crowding_dist[selected_idx]\n    beta = 0.7 if cd_contribution > 1.0 else 0.3\n    vw_ratio = (value1_lst * beta + value2_lst * (1 - beta)) / weight_lst\n\n    exploration_radius = min(3, len(candidates))\n    for _ in range(4):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.724178918342265,
            -17.434028263877416
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    objectives = np.array([obj for _, obj in archive])\n    crowding_dist = np.zeros(len(archive))\n    for i in range(2):\n        sorted_indices = np.argsort(objectives[:, i])\n        crowding_dist[sorted_indices[0]] = np.inf\n        crowding_dist[sorted_indices[-1]] = np.inf\n        for j in range(1, len(archive)-1):\n            crowding_dist[sorted_indices[j]] += (objectives[sorted_indices[j+1], i] - objectives[sorted_indices[j-1], i]) / (objectives[sorted_indices[-1], i] - objectives[sorted_indices[0], i])\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    cd_contribution = crowding_dist[selected_idx]\n    beta = 0.7 if cd_contribution > 1.0 else 0.3\n    vw_ratio = (value1_lst * beta + value2_lst * (1 - beta)) / weight_lst\n\n    exploration_radius = min(3, len(candidates))\n    for _ in range(4):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{The new algorithm selects a solution from the archive using a novel diversity-aware selection based on the angle between normalized objectives and a reference direction, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's dominance count, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Diversity-aware selection based on angle with reference direction\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    reference_dir = np.array([0.7, 0.3])  # Predefined reference direction\n    angles = np.arccos(np.clip(np.dot(normalized, reference_dir), -1.0, 1.0))\n    selected_idx = np.argmin(angles)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on dominance count\n    dominance_count = sum(1 for obj in objectives if (obj[0] > objectives[selected_idx][0] and obj[1] >= objectives[selected_idx][1]) or (obj[0] >= objectives[selected_idx][0] and obj[1] > objectives[selected_idx][1]))\n    alpha = 0.8 if dominance_count > 0 else 0.2\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(5, len(candidates))\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio and correlation\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio and correlation\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with correlation-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{The new algorithm selects a solution from the archive using a hypervolume-aware selection, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's hypervolume contribution, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius based on the solution's position in the Pareto front.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    selected_idx = np.argmax(np.prod(normalized, axis=1))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    hv_contribution = np.prod(normalized[selected_idx])\n    alpha = 0.9 if hv_contribution > 0.5 else 0.1\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    exploration_radius = min(4, len(candidates))\n    for _ in range(5):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n\nPlease help me create a new algorithm that has a totally different form from the given ones. \n1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nDo not give additional explanations.",
        "sample_order": 305,
        "algorithm": "{The new algorithm selects a solution from the archive using a crowding-distance-aware selection, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's crowding distance, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius based on the solution's position in the Pareto front.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n\n    # Crowding-distance-aware selection\n    crowding_distances = np.zeros(len(archive))\n    sorted_indices = np.argsort(objectives[:, 0])\n    crowding_distances[sorted_indices[0]] = crowding_distances[sorted_indices[-1]] = float('inf')\n    for i in range(1, len(sorted_indices)-1):\n        crowding_distances[sorted_indices[i]] += (objectives[sorted_indices[i+1], 0] - objectives[sorted_indices[i-1], 0]) / (max_v1 - 0)\n\n    sorted_indices = np.argsort(objectives[:, 1])\n    crowding_distances[sorted_indices[0]] = crowding_distances[sorted_indices[-1]] = float('inf')\n    for i in range(1, len(sorted_indices)-1):\n        crowding_distances[sorted_indices[i]] += (objectives[sorted_indices[i+1], 1] - objectives[sorted_indices[i-1], 1]) / (max_v2 - 0)\n\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on crowding distance\n    cd = crowding_distances[selected_idx]\n    alpha = 0.5 if cd > 0.3 else 0.7\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(3, len(candidates))\n    for _ in range(4):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -18.566577488236327,
            -18.064045810652768
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n\n    # Crowding-distance-aware selection\n    crowding_distances = np.zeros(len(archive))\n    sorted_indices = np.argsort(objectives[:, 0])\n    crowding_distances[sorted_indices[0]] = crowding_distances[sorted_indices[-1]] = float('inf')\n    for i in range(1, len(sorted_indices)-1):\n        crowding_distances[sorted_indices[i]] += (objectives[sorted_indices[i+1], 0] - objectives[sorted_indices[i-1], 0]) / (max_v1 - 0)\n\n    sorted_indices = np.argsort(objectives[:, 1])\n    crowding_distances[sorted_indices[0]] = crowding_distances[sorted_indices[-1]] = float('inf')\n    for i in range(1, len(sorted_indices)-1):\n        crowding_distances[sorted_indices[i]] += (objectives[sorted_indices[i+1], 1] - objectives[sorted_indices[i-1], 1]) / (max_v2 - 0)\n\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on crowding distance\n    cd = crowding_distances[selected_idx]\n    alpha = 0.5 if cd > 0.3 else 0.7\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(3, len(candidates))\n    for _ in range(4):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n"
    }
]