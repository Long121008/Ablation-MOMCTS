[
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a novel diversity-aware selection based on the angle between normalized objectives and a reference direction, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's dominance count, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Diversity-aware selection based on angle with reference direction\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    reference_dir = np.array([0.7, 0.3])  # Predefined reference direction\n    angles = np.arccos(np.clip(np.dot(normalized, reference_dir), -1.0, 1.0))\n    selected_idx = np.argmin(angles)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on dominance count\n    dominance_count = sum(1 for obj in objectives if (obj[0] > objectives[selected_idx][0] and obj[1] >= objectives[selected_idx][1]) or (obj[0] >= objectives[selected_idx][0] and obj[1] > objectives[selected_idx][1]))\n    alpha = 0.8 if dominance_count > 0 else 0.2\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(5, len(candidates))\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio and correlation\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio and correlation\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with correlation-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -16.977471828375702,
            -19.767227640847345
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a hypervolume-aware selection, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's hypervolume contribution, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius based on the solution's position in the Pareto front.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    selected_idx = np.argmax(np.prod(normalized, axis=1))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    hv_contribution = np.prod(normalized[selected_idx])\n    alpha = 0.9 if hv_contribution > 0.5 else 0.1\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    exploration_radius = min(4, len(candidates))\n    for _ in range(5):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -20.239027198403534,
            -16.232029285063383
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a novel diversity-aware selection based on the angle between normalized objectives and a reference direction, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's dominance count, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Diversity-aware selection based on angle with reference direction\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    reference_dir = np.array([0.7, 0.3])  # Predefined reference direction\n    angles = np.arccos(np.clip(np.dot(normalized, reference_dir), -1.0, 1.0))\n    selected_idx = np.argmin(angles)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on dominance count\n    dominance_count = sum(1 for obj in objectives if (obj[0] > objectives[selected_idx][0] and obj[1] >= objectives[selected_idx][1]) or (obj[0] >= objectives[selected_idx][0] and obj[1] > objectives[selected_idx][1]))\n    alpha = 0.8 if dominance_count > 0 else 0.2\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(5, len(candidates))\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio and correlation\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio and correlation\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with correlation-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -16.977471828375702,
            -19.767227640847345
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a hypervolume-aware selection, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's hypervolume contribution, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius based on the solution's position in the Pareto front.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    selected_idx = np.argmax(np.prod(normalized, axis=1))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    hv_contribution = np.prod(normalized[selected_idx])\n    alpha = 0.9 if hv_contribution > 0.5 else 0.1\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    exploration_radius = min(4, len(candidates))\n    for _ in range(5):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -20.239027198403534,
            -16.232029285063383
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a novelty-aware selection based on the solution's distance to the reference point in the objective space, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's novelty score, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius based on the solution's distance to the reference point.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    reference_point = np.array([1.0, 1.0])  # Ideal reference point\n    distances = np.linalg.norm(reference_point - normalized, axis=1)\n    selected_idx = np.argmax(distances)  # Select the most novel solution\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    novelty_score = distances[selected_idx]\n    alpha = 0.7 if novelty_score > 0.5 else 0.3\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    exploration_radius = min(3, len(candidates))\n    for _ in range(4):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -18.038498616159906,
            -19.351368851945075
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a novel diversity-aware selection based on the angle between normalized objectives and a reference direction, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's dominance count, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Diversity-aware selection based on angle with reference direction\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    reference_dir = np.array([0.7, 0.3])  # Predefined reference direction\n    angles = np.arccos(np.clip(np.dot(normalized, reference_dir), -1.0, 1.0))\n    selected_idx = np.argmin(angles)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on dominance count\n    dominance_count = sum(1 for obj in objectives if (obj[0] > objectives[selected_idx][0] and obj[1] >= objectives[selected_idx][1]) or (obj[0] >= objectives[selected_idx][0] and obj[1] > objectives[selected_idx][1]))\n    alpha = 0.8 if dominance_count > 0 else 0.2\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(5, len(candidates))\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio and correlation\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio and correlation\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with correlation-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -16.977471828375702,
            -19.767227640847345
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a dominance-aware selection based on the Pareto front's hypervolume contribution, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's hypervolume contribution, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius based on the solution's position in the Pareto front.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Hypervolume-based selection with adaptive weighting\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    hv_contributions = np.prod(normalized, axis=1)\n    selected_idx = np.argmax(hv_contributions)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Adaptive value-weight ratio with correlation-aware scoring\n    alpha = 0.7 if hv_contributions[selected_idx] > 0.5 else 0.3\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n    item_scores = vw_ratio * (1 + np.random.rand(len(weight_lst)) * 0.2)  # Add small randomness for exploration\n\n    # Dynamic exploration with correlation-aware swaps\n    exploration_radius = min(3, len(candidates))\n    for _ in range(4):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low score and correlation\n            remove_candidates = sorted(candidates, key=lambda i: item_scores[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high score and correlation\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -item_scores[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a hypervolume-aware flip\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(item_scores)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.977201158402252,
            -17.362563383196296
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a hypervolume-aware selection, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's hypervolume contribution, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius based on the solution's position in the Pareto front.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    selected_idx = np.argmax(np.prod(normalized, axis=1))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    hv_contribution = np.prod(normalized[selected_idx])\n    alpha = 0.9 if hv_contribution > 0.5 else 0.1\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    exploration_radius = min(4, len(candidates))\n    for _ in range(5):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -20.239027198403534,
            -16.232029285063383
        ]
    },
    {
        "algorithm": "{This new algorithm selects a solution from the archive using a crowding-distance-aware selection, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's crowding distance, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius based on the solution's position in the crowding-distance front.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Crowding-distance-based selection\n    objectives = np.array([obj for _, obj in archive])\n    sorted_indices = np.argsort(objectives[:, 0])\n    distances = np.zeros(len(archive))\n    for i in range(1, len(archive)-1):\n        distances[sorted_indices[i]] = objectives[sorted_indices[i+1], 0] - objectives[sorted_indices[i-1], 0]\n    selected_idx = np.argmax(distances)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on crowding distance\n    crowding_distance = distances[selected_idx]\n    beta = 0.7 if crowding_distance > np.median(distances) else 0.3\n    vw_ratio = (value1_lst * beta + value2_lst * (1 - beta)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(3, len(candidates))\n    for _ in range(5):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio and correlation\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio and correlation\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with crowding-distance-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.643785479423205,
            -17.81819691989925
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a novel diversity-aware selection based on the angle between normalized objectives and a reference direction, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's dominance count, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Diversity-aware selection based on angle with reference direction\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    reference_dir = np.array([0.7, 0.3])  # Predefined reference direction\n    angles = np.arccos(np.clip(np.dot(normalized, reference_dir), -1.0, 1.0))\n    selected_idx = np.argmin(angles)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on dominance count\n    dominance_count = sum(1 for obj in objectives if (obj[0] > objectives[selected_idx][0] and obj[1] >= objectives[selected_idx][1]) or (obj[0] >= objectives[selected_idx][0] and obj[1] > objectives[selected_idx][1]))\n    alpha = 0.8 if dominance_count > 0 else 0.2\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(5, len(candidates))\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio and correlation\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio and correlation\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with correlation-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -16.977471828375702,
            -19.767227640847345
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a novel diversity-aware selection based on the angle between normalized objectives and a reference direction, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's dominance count, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Diversity-aware selection based on angle with reference direction\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    reference_dir = np.array([0.7, 0.3])  # Predefined reference direction\n    angles = np.arccos(np.clip(np.dot(normalized, reference_dir), -1.0, 1.0))\n    selected_idx = np.argmin(angles)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on dominance count\n    dominance_count = sum(1 for obj in objectives if (obj[0] > objectives[selected_idx][0] and obj[1] >= objectives[selected_idx][1]) or (obj[0] >= objectives[selected_idx][0] and obj[1] > objectives[selected_idx][1]))\n    alpha = 0.8 if dominance_count > 0 else 0.2\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(5, len(candidates))\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio and correlation\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio and correlation\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with correlation-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -16.977471828375702,
            -19.767227640847345
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a dominance-aware selection based on the Pareto front's hypervolume contribution, then applies a novel local search strategy that combines item swaps with a probabilistic neighborhood exploration prioritizing items with high value-to-weight ratios while ensuring feasibility, using a dynamic parameter setting for the score function that considers the ratio of normalized objectives with adaptive weights based on the current solution's hypervolume contribution, and incorporates a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius based on the solution's position in the Pareto front, while also employing a targeted flip operation with a hypervolume-aware strategy when no improvement is found.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Hypervolume-based selection\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    selected_idx = np.argmax(np.prod(normalized, axis=1))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on hypervolume contribution\n    hv_contribution = np.prod(normalized[selected_idx])\n    alpha = 0.9 if hv_contribution > 0.5 else 0.1\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Novel local search strategy with dynamic exploration\n    exploration_radius = min(4, len(candidates))\n    for _ in range(5):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio and correlation\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio and correlation\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with hypervolume-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -20.13636905106217,
            -16.35636416630281
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a novel diversity-aware selection based on the angle between normalized objectives and a reference direction, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's dominance count, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Diversity-aware selection based on angle with reference direction\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    reference_dir = np.array([0.7, 0.3])  # Predefined reference direction\n    angles = np.arccos(np.clip(np.dot(normalized, reference_dir), -1.0, 1.0))\n    selected_idx = np.argmin(angles)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on dominance count\n    dominance_count = sum(1 for obj in objectives if (obj[0] > objectives[selected_idx][0] and obj[1] >= objectives[selected_idx][1]) or (obj[0] >= objectives[selected_idx][0] and obj[1] > objectives[selected_idx][1]))\n    alpha = 0.8 if dominance_count > 0 else 0.2\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(5, len(candidates))\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio and correlation\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio and correlation\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with correlation-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -16.977471828375702,
            -19.767227640847345
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a dominance-aware selection based on the Pareto front's crowding distance, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's crowding distance, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius based on the solution's position in the Pareto front.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Crowding distance-based selection\n    objectives = np.array([obj for _, obj in archive])\n    front = objectives.copy()\n    front = front[np.lexsort((front[:,1], front[:,0]))]\n    distances = np.zeros(len(front))\n    distances[0] = distances[-1] = float('inf')\n\n    for i in range(1, len(front)-1):\n        distances[i] = (front[i+1,0] - front[i-1,0]) / (front[-1,0] - front[0,0]) + (front[i+1,1] - front[i-1,1]) / (front[-1,1] - front[0,1])\n\n    selected_idx = np.argmax(distances)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on crowding distance\n    crowding_dist = distances[selected_idx]\n    beta = 0.8 if crowding_dist > 1.0 else 0.2\n    vw_ratio = (value1_lst * beta + value2_lst * (1 - beta)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(5, len(candidates))\n    for _ in range(6):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio and correlation\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio and correlation\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with crowding distance-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.990393488205616,
            -16.866551526153287
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a crowding-distance-aware selection that prioritizes solutions in less crowded regions, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's crowding distance, while also incorporating a novel neighborhood exploration strategy that considers item synergies and a dynamic exploration radius.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Crowding-distance-aware selection\n    objectives = np.array([obj for _, obj in archive])\n    sorted_obj = objectives[np.lexsort((objectives[:, 1], objectives[:, 0]))]\n    crowding_distance = np.zeros(len(sorted_obj))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding_distance[sorted_idx[0]] = crowding_distance[sorted_idx[-1]] = np.inf\n        for i in range(1, len(sorted_obj) - 1):\n            crowding_distance[sorted_idx[i]] += (sorted_obj[sorted_idx[i + 1], m] - sorted_obj[sorted_idx[i - 1], m]) / (sorted_obj[-1, m] - sorted_obj[0, m])\n\n    selected_idx = np.argmin(crowding_distance)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on crowding distance\n    beta = 0.6 if crowding_distance[selected_idx] > 0.5 else 0.4\n    vw_ratio = (value1_lst * beta + value2_lst * (1 - beta)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(4, len(candidates))\n    for _ in range(4):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio and synergy\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio and synergy\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with synergy-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -18.6774644303583,
            -18.82248879206619
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a novel diversity-aware selection based on the angle between normalized objectives and a reference direction, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's dominance count, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Diversity-aware selection based on angle with reference direction\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    reference_dir = np.array([0.7, 0.3])  # Predefined reference direction\n    angles = np.arccos(np.clip(np.dot(normalized, reference_dir), -1.0, 1.0))\n    selected_idx = np.argmin(angles)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on dominance count\n    dominance_count = sum(1 for obj in objectives if (obj[0] > objectives[selected_idx][0] and obj[1] >= objectives[selected_idx][1]) or (obj[0] >= objectives[selected_idx][0] and obj[1] > objectives[selected_idx][1]))\n    alpha = 0.8 if dominance_count > 0 else 0.2\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(5, len(candidates))\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio and correlation\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio and correlation\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with correlation-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -16.977471828375702,
            -19.767227640847345
        ]
    },
    {
        "algorithm": "{This new algorithm selects a solution from the archive using a fitness-proportionate selection based on normalized objective values, then applies a hybrid local search combining item swaps with a weighted value-to-weight ratio exploration that adapts to the current solution's performance, while incorporating a dynamic exploration radius and correlation-aware neighborhood selection to generate high-quality neighbors.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Fitness-proportionate selection based on normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    fitness = normalized[:, 0] * 0.6 + normalized[:, 1] * 0.4  # Weighted fitness\n    selected_idx = random.choices(range(len(archive)), weights=fitness, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on solution performance\n    performance_ratio = objectives[selected_idx][0] / (objectives[selected_idx][1] + 1e-6)\n    beta = 0.7 if performance_ratio > 1.2 else 0.3\n    wv_ratio = (value1_lst * beta + value2_lst * (1 - beta)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(3, max(1, int(len(candidates) * 0.3)))\n    for _ in range(2):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low weighted value-to-weight ratio\n            remove_candidates = sorted(candidates, key=lambda i: wv_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high weighted value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -wv_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with correlation-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(wv_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -18.056237974884667,
            -19.341731467506666
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a crowding-distance-aware selection that prioritizes solutions in less crowded regions of the objective space, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's crowding distance, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Crowding-distance-aware selection\n    objectives = np.array([obj for _, obj in archive])\n    sorted_v1 = np.sort(objectives[:, 0])\n    sorted_v2 = np.sort(objectives[:, 1])\n    crowding = np.zeros(len(archive))\n\n    for i in range(len(archive)):\n        if i == 0 or i == len(archive) - 1:\n            crowding[i] = float('inf')\n        else:\n            crowding[i] = (sorted_v1[i+1] - sorted_v1[i-1]) / (sorted_v1[-1] - sorted_v1[0]) + (sorted_v2[i+1] - sorted_v2[i-1]) / (sorted_v2[-1] - sorted_v2[0])\n\n    selected_idx = np.argmin(crowding)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on crowding distance\n    alpha = 0.5 if crowding[selected_idx] > np.median(crowding) else 0.7\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(3, len(candidates))\n    for _ in range(5):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with correlation-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.67508038106402,
            -17.683708390757037
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a novel diversity-aware selection based on the angle between normalized objectives and a reference direction, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's dominance count, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Diversity-aware selection based on angle with reference direction\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    reference_dir = np.array([0.7, 0.3])  # Predefined reference direction\n    angles = np.arccos(np.clip(np.dot(normalized, reference_dir), -1.0, 1.0))\n    selected_idx = np.argmin(angles)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on dominance count\n    dominance_count = sum(1 for obj in objectives if (obj[0] > objectives[selected_idx][0] and obj[1] >= objectives[selected_idx][1]) or (obj[0] >= objectives[selected_idx][0] and obj[1] > objectives[selected_idx][1]))\n    alpha = 0.8 if dominance_count > 0 else 0.2\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(5, len(candidates))\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio and correlation\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio and correlation\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with correlation-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -16.977471828375702,
            -19.767227640847345
        ]
    },
    {
        "algorithm": "{This new algorithm selects a solution from the archive using a crowding-distance-aware selection to identify under-explored regions, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses an adaptive exploration strategy that dynamically adjusts the search radius based on the solution's position in the objective space, incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Crowding-distance-aware selection\n    objectives = np.array([obj for _, obj in archive])\n    sorted_idx = np.lexsort((objectives[:, 1], objectives[:, 0]))\n    sorted_objectives = objectives[sorted_idx]\n\n    crowding_dist = np.zeros(len(archive))\n    for i in range(2):\n        sorted_order = np.argsort(sorted_objectives[:, i])\n        crowding_dist[sorted_order[0]] = np.inf\n        crowding_dist[sorted_order[-1]] = np.inf\n        for j in range(1, len(sorted_order) - 1):\n            crowding_dist[sorted_order[j]] += (sorted_objectives[sorted_order[j+1], i] - sorted_objectives[sorted_order[j-1], i]) / (sorted_objectives[-1, i] - sorted_objectives[0, i] + 1e-10)\n\n    selected_idx = np.argmin(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Adaptive exploration radius based on objective space position\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized_obj = objectives[selected_idx] / np.array([max_v1, max_v2])\n    exploration_radius = int(3 + 2 * (1 - normalized_obj[0]) * (1 - normalized_obj[1]))\n    exploration_radius = max(1, min(exploration_radius, len(candidates)))\n\n    # Hybrid local search with dynamic exploration\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            vw_ratio = (value1_lst + value2_lst) / weight_lst\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio and correlation\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with correlation-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.227289541255267,
            -18.462112708656978
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a crowding-distance-aware selection, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's crowding distance, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Crowding-distance-aware selection\n    objectives = np.array([obj for _, obj in archive])\n    sorted_indices = np.argsort(objectives[:, 0])\n    distances = np.zeros(len(archive))\n    distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n    for i in range(1, len(archive) - 1):\n        distances[i] = objectives[sorted_indices[i+1], 0] - objectives[sorted_indices[i-1], 0]\n    sorted_indices = np.argsort(objectives[:, 1])\n    for i in range(1, len(archive) - 1):\n        distances[i] += objectives[sorted_indices[i+1], 1] - objectives[sorted_indices[i-1], 1]\n    selected_idx = np.argmax(distances)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on crowding distance\n    crowding_distance = distances[selected_idx]\n    alpha = 0.6 if crowding_distance > 0.5 * np.mean(distances) else 0.4\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(4, len(candidates))\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with correlation-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -18.63178591811652,
            -18.87883787223202
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a novel diversity-aware selection based on the angle between normalized objectives and a reference direction, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's dominance count, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Diversity-aware selection based on angle with reference direction\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    reference_dir = np.array([0.7, 0.3])  # Predefined reference direction\n    angles = np.arccos(np.clip(np.dot(normalized, reference_dir), -1.0, 1.0))\n    selected_idx = np.argmin(angles)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on dominance count\n    dominance_count = sum(1 for obj in objectives if (obj[0] > objectives[selected_idx][0] and obj[1] >= objectives[selected_idx][1]) or (obj[0] >= objectives[selected_idx][0] and obj[1] > objectives[selected_idx][1]))\n    alpha = 0.8 if dominance_count > 0 else 0.2\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(5, len(candidates))\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio and correlation\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio and correlation\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with correlation-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -16.977471828375702,
            -19.767227640847345
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a novel diversity-aware selection based on the angle between normalized objectives and a reference direction, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's dominance count, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Diversity-aware selection based on angle with reference direction\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    reference_dir = np.array([0.7, 0.3])  # Predefined reference direction\n    angles = np.arccos(np.clip(np.dot(normalized, reference_dir), -1.0, 1.0))\n    selected_idx = np.argmin(angles)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on dominance count\n    dominance_count = sum(1 for obj in objectives if (obj[0] > objectives[selected_idx][0] and obj[1] >= objectives[selected_idx][1]) or (obj[0] >= objectives[selected_idx][0] and obj[1] > objectives[selected_idx][1]))\n    alpha = 0.8 if dominance_count > 0 else 0.2\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(5, len(candidates))\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio and correlation\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio and correlation\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with correlation-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -16.977471828375702,
            -19.767227640847345
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a diversity-aware selection based on the angle between normalized objectives and a reference direction, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's dominance count, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    reference_dir = np.array([0.7, 0.3])\n    angles = np.arccos(np.clip(np.dot(normalized, reference_dir), -1.0, 1.0))\n    selected_idx = np.argmin(angles)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    dominance_count = sum(1 for obj in objectives if (obj[0] > objectives[selected_idx][0] and obj[1] >= objectives[selected_idx][1]) or (obj[0] >= objectives[selected_idx][0] and obj[1] > objectives[selected_idx][1]))\n    alpha = 0.8 if dominance_count > 0 else 0.2\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    exploration_radius = min(5, len(candidates))\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -17.17096694892213,
            -19.717540011041528
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a novel diversity-aware selection based on the angle between normalized objectives and a reference direction, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's dominance count, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Diversity-aware selection based on angle with reference direction\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    reference_dir = np.array([0.7, 0.3])  # Predefined reference direction\n    angles = np.arccos(np.clip(np.dot(normalized, reference_dir), -1.0, 1.0))\n    selected_idx = np.argmin(angles)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on dominance count\n    dominance_count = sum(1 for obj in objectives if (obj[0] > objectives[selected_idx][0] and obj[1] >= objectives[selected_idx][1]) or (obj[0] >= objectives[selected_idx][0] and obj[1] > objectives[selected_idx][1]))\n    alpha = 0.8 if dominance_count > 0 else 0.2\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(5, len(candidates))\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio and correlation\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio and correlation\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with correlation-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -16.977471828375702,
            -19.767227640847345
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a crowding-distance-aware selection to identify under-explored regions, then applies a novel hybrid local search that combines item swaps with a probabilistic neighborhood exploration prioritizing high-value-to-weight-ratio items while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's crowding distance, while also incorporating a novel neighborhood exploration strategy that considers item dependencies and a dynamic exploration radius based on the solution's position in the objective space.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Crowding-distance-aware selection\n    objectives = np.array([obj for _, obj in archive])\n    sorted_indices = np.lexsort((objectives[:, 1], objectives[:, 0]))\n    sorted_objectives = objectives[sorted_indices]\n\n    crowding_distances = np.zeros(len(sorted_objectives))\n    for i in range(1, len(sorted_objectives) - 1):\n        crowding_distances[i] = (\n            (sorted_objectives[i+1, 0] - sorted_objectives[i-1, 0]) / (sorted_objectives[-1, 0] - sorted_objectives[0, 0]) +\n            (sorted_objectives[i+1, 1] - sorted_objectives[i-1, 1]) / (sorted_objectives[-1, 1] - sorted_objectives[0, 1])\n        )\n\n    # Select the solution with the smallest crowding distance (most crowded region)\n    selected_idx = sorted_indices[np.argmin(crowding_distances)]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on crowding distance\n    alpha = 0.7 if crowding_distances[np.where(sorted_indices == selected_idx)[0][0]] > 0.3 else 0.3\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(3, len(candidates))\n    for _ in range(4):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio and dependency\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio and dependency\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with dependency-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -18.13864488912278,
            -19.221767634376427
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a novel diversity-aware selection based on the angle between normalized objectives and a reference direction, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's dominance count, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Diversity-aware selection based on angle with reference direction\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    reference_dir = np.array([0.7, 0.3])  # Predefined reference direction\n    angles = np.arccos(np.clip(np.dot(normalized, reference_dir), -1.0, 1.0))\n    selected_idx = np.argmin(angles)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on dominance count\n    dominance_count = sum(1 for obj in objectives if (obj[0] > objectives[selected_idx][0] and obj[1] >= objectives[selected_idx][1]) or (obj[0] >= objectives[selected_idx][0] and obj[1] > objectives[selected_idx][1]))\n    alpha = 0.8 if dominance_count > 0 else 0.2\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(5, len(candidates))\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio and correlation\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio and correlation\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with correlation-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -16.977471828375702,
            -19.767227640847345
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a dominance-aware selection based on the Pareto front's hypervolume contribution, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's hypervolume contribution, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius based on the solution's position in the Pareto front.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Hypervolume-based selection\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    selected_idx = np.argmax(np.prod(normalized, axis=1))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on hypervolume contribution\n    hv_contribution = np.prod(normalized[selected_idx])\n    alpha = 0.9 if hv_contribution > 0.5 else 0.1\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(4, len(candidates))\n    for _ in range(5):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio and correlation\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio and correlation\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with hypervolume-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -20.133844213512887,
            -16.39203382307051
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a novel diversity-aware selection based on the angle between normalized objectives and a reference direction, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's dominance count, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Diversity-aware selection based on angle with reference direction\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    reference_dir = np.array([0.7, 0.3])  # Predefined reference direction\n    angles = np.arccos(np.clip(np.dot(normalized, reference_dir), -1.0, 1.0))\n    selected_idx = np.argmin(angles)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on dominance count\n    dominance_count = sum(1 for obj in objectives if (obj[0] > objectives[selected_idx][0] and obj[1] >= objectives[selected_idx][1]) or (obj[0] >= objectives[selected_idx][0] and obj[1] > objectives[selected_idx][1]))\n    alpha = 0.8 if dominance_count > 0 else 0.2\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(5, len(candidates))\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio and correlation\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio and correlation\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with correlation-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -16.977471828375702,
            -19.767227640847345
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a novel diversity-aware selection based on the angle between normalized objectives and a reference direction, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's dominance count, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Diversity-aware selection based on angle with reference direction\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    reference_dir = np.array([0.7, 0.3])  # Predefined reference direction\n    angles = np.arccos(np.clip(np.dot(normalized, reference_dir), -1.0, 1.0))\n    selected_idx = np.argmin(angles)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on dominance count\n    dominance_count = sum(1 for obj in objectives if (obj[0] > objectives[selected_idx][0] and obj[1] >= objectives[selected_idx][1]) or (obj[0] >= objectives[selected_idx][0] and obj[1] > objectives[selected_idx][1]))\n    alpha = 0.8 if dominance_count > 0 else 0.2\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(5, len(candidates))\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio and correlation\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio and correlation\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with correlation-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -16.977471828375702,
            -19.767227640847345
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a crowding-distance-aware selection to balance exploration and exploitation, then applies an adaptive local search that combines item swaps with a probabilistic neighborhood exploration prioritizing items with high value-to-weight ratios, while dynamically adjusting the exploration radius based on the solution's position in the Pareto front and using a novel score function that combines normalized objective values with adaptive weights determined by the solution's crowding distance in the objective space.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Crowding-distance-based selection\n    objectives = np.array([obj for _, obj in archive])\n    sorted_indices = np.lexsort((objectives[:, 1], objectives[:, 0]))\n    sorted_objectives = objectives[sorted_indices]\n\n    crowding_distances = np.zeros(len(sorted_objectives))\n    for i in range(2):\n        sorted_order = np.argsort(sorted_objectives[:, i])\n        crowding_distances[sorted_order[0]] = np.inf\n        crowding_distances[sorted_order[-1]] = np.inf\n        for j in range(1, len(sorted_order) - 1):\n            crowding_distances[sorted_order[j]] += (sorted_objectives[sorted_order[j+1], i] - sorted_objectives[sorted_order[j-1], i])\n\n    selected_idx = sorted_indices[np.argmax(crowding_distances)]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on crowding distance\n    crowding = crowding_distances[np.where(sorted_indices == selected_idx)[0][0]]\n    beta = 0.7 if crowding > 0 else 0.3\n    vw_ratio = (value1_lst * beta + value2_lst * (1 - beta)) / weight_lst\n\n    # Adaptive local search with dynamic exploration radius\n    exploration_radius = min(5, max(2, int(len(candidates) * 0.3)))\n    for _ in range(6):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a crowding-distance-aware flip\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.986485268717495,
            -17.18172389629182
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a novel diversity-aware selection based on the angle between normalized objectives and a reference direction, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's dominance count, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Diversity-aware selection based on angle with reference direction\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    reference_dir = np.array([0.7, 0.3])  # Predefined reference direction\n    angles = np.arccos(np.clip(np.dot(normalized, reference_dir), -1.0, 1.0))\n    selected_idx = np.argmin(angles)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on dominance count\n    dominance_count = sum(1 for obj in objectives if (obj[0] > objectives[selected_idx][0] and obj[1] >= objectives[selected_idx][1]) or (obj[0] >= objectives[selected_idx][0] and obj[1] > objectives[selected_idx][1]))\n    alpha = 0.8 if dominance_count > 0 else 0.2\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(5, len(candidates))\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio and correlation\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio and correlation\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with correlation-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -16.977471828375702,
            -19.767227640847345
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a weighted random selection based on the product of normalized objective values with different weights, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a different parameter setting for the score function by considering the sum of normalized objectives with different weights.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    weights = [(0.6 * obj[0]/max_v1 + 0.4 * obj[1]/max_v2) for _, obj in archive]  # Sum of normalized objectives with different weights\n\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Probabilistic neighborhood exploration with value-to-weight ratio\n    for _ in range(3):  # Increased trials\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            vw_ratio = (value1_lst * 0.7 + value2_lst * 0.3) / weight_lst  # Different weight combination\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(3, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip\n    if np.array_equal(new_solution, base_solution):\n        # Flip items with lowest value-to-weight ratio\n        vw_ratio = (value1_lst * 0.3 + value2_lst * 0.7) / weight_lst  # Different weight combination\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.881238273007625,
            -17.612570262095716
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a weighted random selection based on the sum of normalized objective values with different weights, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a different parameter setting for the score function by considering the product of normalized objectives with different weights.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    weights = [(0.4 * obj[0]/max_v1 + 0.6 * obj[1]/max_v2) for _, obj in archive]  # Sum of normalized objectives with different weights\n\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Probabilistic neighborhood exploration with value-to-weight ratio\n    for _ in range(3):  # Increased trials\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            vw_ratio = (value1_lst * 0.3 + value2_lst * 0.7) / weight_lst  # Different weight combination\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(3, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip\n    if np.array_equal(new_solution, base_solution):\n        # Flip items with lowest value-to-weight ratio\n        vw_ratio = (value1_lst * 0.7 + value2_lst * 0.3) / weight_lst  # Different weight combination\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -17.89709842921563,
            -19.47732976854395
        ]
    },
    {
        "algorithm": "{This algorithm selects a solution from the archive using a weighted random selection based on the ratio of normalized objective values, then applies a hybrid local search combining item flips with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a different parameter setting for the score function by considering the product of normalized objectives with different weights.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    weights = [(obj[0]/max_v1) * (obj[1]/max_v2) for _, obj in archive]  # Product of normalized objectives with different weights\n\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Probabilistic neighborhood exploration with value-to-weight ratio\n    for _ in range(2):  # Reduced trials\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            vw_ratio = (value1_lst * 0.5 + value2_lst * 0.5) / weight_lst  # Equal weight combination\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(2, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip\n    if np.array_equal(new_solution, base_solution):\n        # Flip items with lowest value-to-weight ratio\n        vw_ratio = (value1_lst * 0.4 + value2_lst * 0.6) / weight_lst  # Different weight combination\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.00902078441625,
            -18.68709607071208
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a novel diversity-aware selection based on the angle between normalized objectives and a reference direction, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's dominance count, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Diversity-aware selection based on angle with reference direction\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    reference_dir = np.array([0.7, 0.3])  # Predefined reference direction\n    angles = np.arccos(np.clip(np.dot(normalized, reference_dir), -1.0, 1.0))\n    selected_idx = np.argmin(angles)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on dominance count\n    dominance_count = sum(1 for obj in objectives if (obj[0] > objectives[selected_idx][0] and obj[1] >= objectives[selected_idx][1]) or (obj[0] >= objectives[selected_idx][0] and obj[1] > objectives[selected_idx][1]))\n    alpha = 0.8 if dominance_count > 0 else 0.2\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(5, len(candidates))\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio and correlation\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio and correlation\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with correlation-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -16.977471828375702,
            -19.767227640847345
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a weighted random selection based on the product of normalized objective values with different weights, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a different parameter setting for the score function by considering the sum of normalized objectives with different weights.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    weights = [(0.6 * obj[0]/max_v1 + 0.4 * obj[1]/max_v2) for _, obj in archive]  # Sum of normalized objectives with different weights\n\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Probabilistic neighborhood exploration with value-to-weight ratio\n    for _ in range(3):  # Increased trials\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            vw_ratio = (value1_lst * 0.7 + value2_lst * 0.3) / weight_lst  # Different weight combination\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(3, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip\n    if np.array_equal(new_solution, base_solution):\n        # Flip items with lowest value-to-weight ratio\n        vw_ratio = (value1_lst * 0.3 + value2_lst * 0.7) / weight_lst  # Different weight combination\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.881238273007625,
            -17.612570262095716
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a novelty-aware selection based on the Euclidean distance to the ideal point, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's novelty score, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Novelty-aware selection based on distance to ideal point\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = objectives.max(axis=0)\n    distances = np.linalg.norm(objectives - ideal_point, axis=1)\n    selected_idx = np.argmax(distances)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on novelty score\n    novelty_score = distances[selected_idx] / (ideal_point[0] + ideal_point[1])\n    alpha = 0.6 if novelty_score > 0.5 else 0.4\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(4, len(candidates))\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio and correlation\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio and correlation\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with novelty-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -18.5801928976947,
            -19.01235711839125
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a weighted random selection based on the harmonic mean of normalized objective values, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a different parameter setting for the score function by considering the weighted sum of normalized objectives with different weights.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    weights = [(2 * (0.5 * obj[0]/max_v1) * (0.5 * obj[1]/max_v2)) / (0.5 * obj[0]/max_v1 + 0.5 * obj[1]/max_v2) for _, obj in archive]  # Harmonic mean of normalized objectives\n\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Probabilistic neighborhood exploration with value-to-weight ratio\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            vw_ratio = (value1_lst * 0.4 + value2_lst * 0.6) / weight_lst  # Different weight combination\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(2, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip\n    if np.array_equal(new_solution, base_solution):\n        # Flip items with lowest value-to-weight ratio\n        vw_ratio = (value1_lst * 0.6 + value2_lst * 0.4) / weight_lst  # Different weight combination\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -18.53452629153658,
            -19.107744137154803
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a weighted random selection based on the product of normalized objective values with different weights, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a different parameter setting for the score function by considering the sum of normalized objectives with different weights.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    weights = [(0.6 * obj[0]/max_v1 + 0.4 * obj[1]/max_v2) for _, obj in archive]  # Sum of normalized objectives with different weights\n\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Probabilistic neighborhood exploration with value-to-weight ratio\n    for _ in range(3):  # Increased trials\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            vw_ratio = (value1_lst * 0.7 + value2_lst * 0.3) / weight_lst  # Different weight combination\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(3, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip\n    if np.array_equal(new_solution, base_solution):\n        # Flip items with lowest value-to-weight ratio\n        vw_ratio = (value1_lst * 0.3 + value2_lst * 0.7) / weight_lst  # Different weight combination\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.881238273007625,
            -17.612570262095716
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a weighted random selection based on the product of normalized objective values with equal weights, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a different parameter setting for the score function by considering the product of normalized objectives with equal weights.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    weights = [(obj[0]/max_v1) * (obj[1]/max_v2) for _, obj in archive]  # Product of normalized objectives with equal weights\n\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Probabilistic neighborhood exploration with value-to-weight ratio\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            vw_ratio = (value1_lst * 0.5 + value2_lst * 0.5) / weight_lst  # Equal weight combination\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(3, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip\n    if np.array_equal(new_solution, base_solution):\n        # Flip items with lowest value-to-weight ratio\n        vw_ratio = (value1_lst * 0.5 + value2_lst * 0.5) / weight_lst  # Equal weight combination\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.163528136113595,
            -18.56729063895306
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a novel diversity-aware selection based on the angle between normalized objectives and a reference direction, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's dominance count, while also incorporating a novel neighborhood exploration strategy that considers item correlations and a dynamic exploration radius.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Diversity-aware selection based on angle with reference direction\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    reference_dir = np.array([0.7, 0.3])  # Predefined reference direction\n    angles = np.arccos(np.clip(np.dot(normalized, reference_dir), -1.0, 1.0))\n    selected_idx = np.argmin(angles)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on dominance count\n    dominance_count = sum(1 for obj in objectives if (obj[0] > objectives[selected_idx][0] and obj[1] >= objectives[selected_idx][1]) or (obj[0] >= objectives[selected_idx][0] and obj[1] > objectives[selected_idx][1]))\n    alpha = 0.8 if dominance_count > 0 else 0.2\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with dynamic exploration radius\n    exploration_radius = min(5, len(candidates))\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio and correlation\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_radius, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio and correlation\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with correlation-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -16.977471828375702,
            -19.767227640847345
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a quality-diversity hybrid selection based on the product of normalized objective values with adaptive weights, then applies a novel local search combining item swaps with a probabilistic exploration that prioritizes items with high value-to-weight ratios while dynamically adjusting the exploration scope based on the solution's position in the Pareto front, and uses a hybrid score function that considers both the sum and product of normalized objectives with time-varying weights.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Quality-diversity hybrid selection\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    quality_scores = normalized[:, 0] * normalized[:, 1]  # Product of normalized objectives\n    diversity_scores = np.linalg.norm(normalized - normalized.mean(axis=0), axis=1)\n    combined_scores = quality_scores * 0.6 + diversity_scores * 0.4\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on Pareto front position\n    is_extreme = (objectives[selected_idx][0] >= max_v1 * 0.95) or (objectives[selected_idx][1] >= max_v2 * 0.95)\n    alpha = 0.3 if is_extreme else 0.5\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with dynamic exploration scope\n    exploration_scope = min(4, len(candidates)) if is_extreme else min(6, len(candidates))\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(exploration_scope, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with adaptive strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -17.554508383375655,
            -19.616370694573092
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a roulette wheel selection based on the harmonic mean of normalized objective values, then applies a hybrid local search that combines item swaps with a probabilistic neighborhood exploration prioritizing items with high value-to-weight ratios in a weighted sum fashion, while ensuring feasibility and using a different parameter setting for the score function by considering the geometric mean of normalized objectives with different weights.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n\n    # Calculate harmonic mean of normalized objectives\n    harmonic_weights = [(2 * obj[0]/max_v1 * obj[1]/max_v2) / (obj[0]/max_v1 + obj[1]/max_v2) for _, obj in archive]\n\n    selected_idx = random.choices(range(len(archive)), weights=harmonic_weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Probabilistic neighborhood exploration with weighted value-to-weight ratio\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Weighted value-to-weight ratio\n            vw_ratio = (value1_lst * 0.5 + value2_lst * 0.5) / weight_lst  # Equal weights\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(2, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip based on geometric mean\n    if np.array_equal(new_solution, base_solution):\n        # Calculate geometric mean of normalized objectives\n        geo_vw_ratio = np.sqrt((value1_lst/max_v1) * (value2_lst/max_v2))\n        flip_candidates = np.argsort(geo_vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.00703722718613,
            -18.723588845110974
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a weighted random selection based on the sum of normalized objective values with different weights, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a different parameter setting for the score function by considering the product of normalized objectives with different weights.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    weights = [(0.4 * obj[0]/max_v1 + 0.6 * obj[1]/max_v2) for _, obj in archive]  # Sum of normalized objectives with different weights\n\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Probabilistic neighborhood exploration with value-to-weight ratio\n    for _ in range(3):  # Increased trials\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            vw_ratio = (value1_lst * 0.5 + value2_lst * 0.5) / weight_lst  # Different weight combination\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(3, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip\n    if np.array_equal(new_solution, base_solution):\n        # Flip items with lowest value-to-weight ratio\n        vw_ratio = (value1_lst * 0.5 + value2_lst * 0.5) / weight_lst  # Different weight combination\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.14482287121252,
            -18.58300716029515
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a weighted random selection based on the product of normalized objective values with different weights, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a different parameter setting for the score function by considering the sum of normalized objectives with different weights.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    weights = [(0.6 * obj[0]/max_v1 + 0.4 * obj[1]/max_v2) for _, obj in archive]  # Sum of normalized objectives with different weights\n\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Probabilistic neighborhood exploration with value-to-weight ratio\n    for _ in range(3):  # Increased trials\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            vw_ratio = (value1_lst * 0.7 + value2_lst * 0.3) / weight_lst  # Different weight combination\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(3, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip\n    if np.array_equal(new_solution, base_solution):\n        # Flip items with lowest value-to-weight ratio\n        vw_ratio = (value1_lst * 0.3 + value2_lst * 0.7) / weight_lst  # Different weight combination\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.881238273007625,
            -17.612570262095716
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a weighted random selection based on the sum of normalized objective values with different weights, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a different parameter setting for the score function by considering the product of normalized objectives with different weights.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    weights = [(0.4 * obj[0]/max_v1 + 0.6 * obj[1]/max_v2) for _, obj in archive]  # Sum of normalized objectives with different weights\n\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Probabilistic neighborhood exploration with value-to-weight ratio\n    for _ in range(3):  # Increased trials\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            vw_ratio = (value1_lst * 0.3 + value2_lst * 0.7) / weight_lst  # Different weight combination\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(3, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip\n    if np.array_equal(new_solution, base_solution):\n        # Flip items with lowest value-to-weight ratio\n        vw_ratio = (value1_lst * 0.7 + value2_lst * 0.3) / weight_lst  # Different weight combination\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -17.976405777141974,
            -19.418867595284553
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a weighted random selection based on the product of normalized objective values with different weights, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a different parameter setting for the score function by considering the sum of normalized objectives with different weights.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    weights = [(0.6 * obj[0]/max_v1 + 0.4 * obj[1]/max_v2) for _, obj in archive]  # Sum of normalized objectives with different weights\n\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Probabilistic neighborhood exploration with value-to-weight ratio\n    for _ in range(3):  # Increased trials\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            vw_ratio = (value1_lst * 0.7 + value2_lst * 0.3) / weight_lst  # Different weight combination\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(3, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip\n    if np.array_equal(new_solution, base_solution):\n        # Flip items with lowest value-to-weight ratio\n        vw_ratio = (value1_lst * 0.3 + value2_lst * 0.7) / weight_lst  # Different weight combination\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.881238273007625,
            -17.612570262095716
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a weighted random selection based on the sum of normalized objective values with different weights, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a different parameter setting for the score function by considering the product of normalized objectives with different weights.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    weights = [(0.4 * obj[0]/max_v1 + 0.6 * obj[1]/max_v2) for _, obj in archive]  # Product of normalized objectives with different weights\n\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Probabilistic neighborhood exploration with value-to-weight ratio\n    for _ in range(3):  # Increased trials\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            vw_ratio = (value1_lst * 0.3 + value2_lst * 0.7) / weight_lst  # Different weight combination\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(3, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip\n    if np.array_equal(new_solution, base_solution):\n        # Flip items with lowest value-to-weight ratio\n        vw_ratio = (value1_lst * 0.7 + value2_lst * 0.3) / weight_lst  # Different weight combination\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -17.915283152984355,
            -19.459649488874025
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a weighted random selection based on the product of normalized objective values with equal weights, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a different parameter setting for the score function by considering the sum of normalized objectives with equal weights.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    weights = [(0.5 * obj[0]/max_v1 + 0.5 * obj[1]/max_v2) for _, obj in archive]  # Equal weight sum of normalized objectives\n\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Probabilistic neighborhood exploration with value-to-weight ratio\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            vw_ratio = (value1_lst * 0.5 + value2_lst * 0.5) / weight_lst  # Equal weight combination\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(3, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip\n    if np.array_equal(new_solution, base_solution):\n        vw_ratio = (value1_lst * 0.5 + value2_lst * 0.5) / weight_lst  # Equal weight combination\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.137337290296152,
            -18.61303931198216
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a tournament selection based on the Euclidean distance between normalized objectives and the ideal point, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's dominance count.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Tournament selection based on distance to ideal point\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    ideal_point = np.array([1.0, 1.0])\n    distances = np.linalg.norm(normalized - ideal_point, axis=1)\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin(distances[selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on dominance count\n    dominance_count = sum(1 for obj in objectives if (obj[0] > objectives[selected_idx][0] and obj[1] >= objectives[selected_idx][1]) or (obj[0] >= objectives[selected_idx][0] and obj[1] > objectives[selected_idx][1]))\n    alpha = 0.7 if dominance_count > 0 else 0.3\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with probabilistic exploration\n    for _ in range(5):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(3, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with dominance-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -17.831208554660687,
            -19.490061476215182
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a weighted random selection based on the product of normalized objective values with different weights, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a different parameter setting for the score function by considering the sum of normalized objectives with different weights.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    weights = [(0.6 * obj[0]/max_v1 + 0.4 * obj[1]/max_v2) for _, obj in archive]  # Sum of normalized objectives with different weights\n\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Probabilistic neighborhood exploration with value-to-weight ratio\n    for _ in range(3):  # Increased trials\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            vw_ratio = (value1_lst * 0.7 + value2_lst * 0.3) / weight_lst  # Different weight combination\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(3, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip\n    if np.array_equal(new_solution, base_solution):\n        # Flip items with lowest value-to-weight ratio\n        vw_ratio = (value1_lst * 0.3 + value2_lst * 0.7) / weight_lst  # Different weight combination\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.881238273007625,
            -17.612570262095716
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a tournament selection based on the Euclidean distance between normalized objectives and the ideal point, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's dominance count.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Tournament selection based on distance to ideal point\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    ideal_point = np.array([1.0, 1.0])\n    distances = np.linalg.norm(normalized - ideal_point, axis=1)\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin(distances[selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on dominance count\n    dominance_count = sum(1 for obj in objectives if (obj[0] > objectives[selected_idx][0] and obj[1] >= objectives[selected_idx][1]) or (obj[0] >= objectives[selected_idx][0] and obj[1] > objectives[selected_idx][1]))\n    alpha = 0.7 if dominance_count > 0 else 0.3\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with probabilistic exploration\n    for _ in range(5):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(3, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with dominance-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -17.831208554660687,
            -19.490061476215182
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a weighted random selection based on the product of normalized objective values with different weights, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a different parameter setting for the score function by considering the sum of normalized objectives with different weights.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    weights = [(0.6 * obj[0]/max_v1 + 0.4 * obj[1]/max_v2) for _, obj in archive]  # Sum of normalized objectives with different weights\n\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Probabilistic neighborhood exploration with value-to-weight ratio\n    for _ in range(3):  # Increased trials\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            vw_ratio = (value1_lst * 0.7 + value2_lst * 0.3) / weight_lst  # Different weight combination\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(3, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip\n    if np.array_equal(new_solution, base_solution):\n        # Flip items with lowest value-to-weight ratio\n        vw_ratio = (value1_lst * 0.3 + value2_lst * 0.7) / weight_lst  # Different weight combination\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.881238273007625,
            -17.612570262095716
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a diversity-aware selection based on the angle between normalized objectives and the ideal point, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's dominance count, while also incorporating a novel neighborhood exploration strategy that considers the correlation between objectives to guide the search more effectively.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Diversity-aware selection based on angle to ideal point\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    ideal_point = np.array([1.0, 1.0])\n    angles = np.arctan2(normalized[:, 1] - ideal_point[1], normalized[:, 0] - ideal_point[0])\n    diversity_weights = 1.0 / (1.0 + np.abs(angles - np.median(angles)))\n    selected_idx = random.choices(range(len(archive)), weights=diversity_weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on objective correlation\n    correlation = np.corrcoef(value1_lst, value2_lst)[0, 1]\n    alpha = 0.5 if correlation > 0.5 else 0.3\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with correlation-aware exploration\n    for _ in range(5):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(3, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio and correlation\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                # Adjust score based on correlation\n                if correlation > 0.5:\n                    sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n                else:\n                    sorted_items = sorted(available_items, key=lambda i: -(value1_lst[i] / weight_lst[i] + value2_lst[i] / weight_lst[i]))\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with correlation-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        if correlation > 0.5:\n            flip_candidates = np.argsort(vw_ratio)\n        else:\n            flip_candidates = np.argsort((value1_lst + value2_lst) / weight_lst)\n\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -18.279359371683007,
            -19.153268812175114
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a weighted random selection based on the product of normalized objective values with different weights, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a different parameter setting for the score function by considering the sum of normalized objectives with different weights.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    weights = [(0.6 * obj[0]/max_v1 + 0.4 * obj[1]/max_v2) for _, obj in archive]  # Sum of normalized objectives with different weights\n\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Probabilistic neighborhood exploration with value-to-weight ratio\n    for _ in range(3):  # Increased trials\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            vw_ratio = (value1_lst * 0.7 + value2_lst * 0.3) / weight_lst  # Different weight combination\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(3, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip\n    if np.array_equal(new_solution, base_solution):\n        # Flip items with lowest value-to-weight ratio\n        vw_ratio = (value1_lst * 0.3 + value2_lst * 0.7) / weight_lst  # Different weight combination\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.881238273007625,
            -17.612570262095716
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a weighted random selection based on the product of normalized objective values with different weights, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a different parameter setting for the score function by considering the sum of normalized objectives with different weights, and incorporates a novel adaptive mutation strategy that dynamically adjusts the mutation rate based on the diversity of the archive and the current solution's performance, creating a more diverse and high-quality neighborhood.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    weights = [(0.4 * obj[0]/max_v1 + 0.6 * obj[1]/max_v2) for _, obj in archive]  # Different weight combination\n\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Adaptive mutation strategy\n    diversity = len(archive) / len(base_solution) if len(archive) > 0 else 0.5\n    mutation_rate = min(0.3, 0.1 + 0.2 * diversity)\n\n    # Hybrid local search with adaptive mutation\n    for _ in range(5):  # More trials for better exploration\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio with adaptive weights\n            vw_ratio = (value1_lst * (0.5 + 0.2 * random.random()) + value2_lst * (0.5 - 0.2 * random.random())) / weight_lst\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(2, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio with adaptive weights\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # Apply adaptive mutation\n    if random.random() < mutation_rate:\n        mutation_type = random.choice(['swap', 'flip', 'invert'])\n        if mutation_type == 'swap' and len(candidates) > 1:\n            i, j = random.sample(list(candidates), 2)\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        elif mutation_type == 'flip' and len(candidates) + len(non_candidates) > 0:\n            i = random.choice(np.concatenate([candidates, non_candidates]))\n            if new_solution[i] == 1 and current_weight - weight_lst[i] >= 0:\n                new_solution[i] = 0\n            elif new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n        elif mutation_type == 'invert' and len(candidates) > 0:\n            i = random.choice(candidates)\n            new_solution[i] = 0\n            # Find best item to replace\n            vw_ratio = (value1_lst * 0.6 + value2_lst * 0.4) / weight_lst\n            available_items = [i for i in non_candidates if weight_lst[i] <= capacity - (current_weight - weight_lst[i])]\n            if available_items:\n                best_item = max(available_items, key=lambda i: vw_ratio[i])\n                new_solution[best_item] = 1\n\n    return new_solution\n\n",
        "score": [
            -19.59466405879268,
            -18.135011365965312
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a tournament selection based on the Euclidean distance between normalized objectives and the ideal point, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering the ratio of normalized objectives with adaptive weights based on the current solution's dominance count.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Tournament selection based on distance to ideal point\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = objectives.max(axis=0)\n    normalized = objectives / np.array([max_v1, max_v2])\n    ideal_point = np.array([1.0, 1.0])\n    distances = np.linalg.norm(normalized - ideal_point, axis=1)\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin(distances[selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic parameter setting based on dominance count\n    dominance_count = sum(1 for obj in objectives if (obj[0] > objectives[selected_idx][0] and obj[1] >= objectives[selected_idx][1]) or (obj[0] >= objectives[selected_idx][0] and obj[1] > objectives[selected_idx][1]))\n    alpha = 0.7 if dominance_count > 0 else 0.3\n    vw_ratio = (value1_lst * alpha + value2_lst * (1 - alpha)) / weight_lst\n\n    # Hybrid local search with probabilistic exploration\n    for _ in range(5):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(3, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a targeted flip with dominance-aware strategy\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -17.831208554660687,
            -19.490061476215182
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a weighted random selection based on the product of normalized objective values with different weights, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a different parameter setting for the score function by considering the sum of normalized objectives with different weights.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    weights = [(0.6 * obj[0]/max_v1 + 0.4 * obj[1]/max_v2) for _, obj in archive]  # Sum of normalized objectives with different weights\n\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Probabilistic neighborhood exploration with value-to-weight ratio\n    for _ in range(3):  # Increased trials\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            vw_ratio = (value1_lst * 0.7 + value2_lst * 0.3) / weight_lst  # Different weight combination\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(3, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip\n    if np.array_equal(new_solution, base_solution):\n        # Flip items with lowest value-to-weight ratio\n        vw_ratio = (value1_lst * 0.3 + value2_lst * 0.7) / weight_lst  # Different weight combination\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.881238273007625,
            -17.612570262095716
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a tournament selection based on a combined objective score, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value dominance while ensuring feasibility, and uses a different parameter setting for the score function by considering the sum of normalized objectives with different weights.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    tournament_size = min(5, len(archive))\n    selected_idx = random.choice(random.sample(range(len(archive)), tournament_size))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Hybrid local search with value dominance\n    for _ in range(5):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Value dominance metric\n            dominance = (value1_lst * 0.5 + value2_lst * 0.5) / (weight_lst + 1e-6)\n            remove_candidates = sorted(candidates, key=lambda i: dominance[i])\n            num_remove = random.randint(1, min(2, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -dominance[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip\n    if np.array_equal(new_solution, base_solution):\n        dominance = (value1_lst * 0.6 + value2_lst * 0.4) / (weight_lst + 1e-6)\n        flip_candidates = np.argsort(dominance)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.124860949116865,
            -18.614562015003294
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a weighted random selection based on the sum of normalized objective values with different weights, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a different parameter setting for the score function by considering the product of normalized objectives with different weights.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    weights = [(0.4 * obj[0]/max_v1 + 0.6 * obj[1]/max_v2) for _, obj in archive]  # Product of normalized objectives with different weights\n\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Probabilistic neighborhood exploration with value-to-weight ratio\n    for _ in range(3):  # Increased trials\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            vw_ratio = (value1_lst * 0.5 + value2_lst * 0.5) / weight_lst  # Different weight combination\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(3, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip\n    if np.array_equal(new_solution, base_solution):\n        # Flip items with lowest value-to-weight ratio\n        vw_ratio = (value1_lst * 0.5 + value2_lst * 0.5) / weight_lst  # Different weight combination\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.17634162161996,
            -18.551077344743472
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a weighted random selection based on the sum of normalized objective values with different weights, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a different parameter setting for the score function by considering the product of normalized objectives with different weights.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    weights = [(0.4 * obj[0]/max_v1 * 0.6 * obj[1]/max_v2) for _, obj in archive]  # Product of normalized objectives with different weights\n\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Probabilistic neighborhood exploration with value-to-weight ratio\n    for _ in range(3):  # Increased trials\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            vw_ratio = (value1_lst * 0.3 + value2_lst * 0.7) / weight_lst  # Different weight combination\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(3, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip\n    if np.array_equal(new_solution, base_solution):\n        # Flip items with lowest value-to-weight ratio\n        vw_ratio = (value1_lst * 0.7 + value2_lst * 0.3) / weight_lst  # Different weight combination\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -17.9462944502577,
            -19.43831544166403
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a weighted random selection based on the sum of normalized objective values with different weights, then applies a hybrid local search that combines item swaps with a probabilistic neighborhood exploration prioritizing items with high value-to-weight ratios (using a different weight combination) while ensuring feasibility, and includes a targeted flip operation if no improvement is found.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    weights = [(0.4 * obj[0]/max_v1 + 0.6 * obj[1]/max_v2) for _, obj in archive]  # Different weight combination\n\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Probabilistic neighborhood exploration with value-to-weight ratio\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            vw_ratio = (value1_lst * 0.5 + value2_lst * 0.5) / weight_lst  # Different weight combination\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(2, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip\n    if np.array_equal(new_solution, base_solution):\n        # Flip items with lowest value-to-weight ratio\n        vw_ratio = (value1_lst * 0.6 + value2_lst * 0.4) / weight_lst  # Different weight combination\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.079787472545526,
            -18.64155154990391
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a weighted random selection based on the product of normalized objective values with different weights, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a different parameter setting for the score function by considering the sum of normalized objectives with different weights.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    weights = [(0.6 * obj[0]/max_v1 + 0.4 * obj[1]/max_v2) for _, obj in archive]  # Sum of normalized objectives with different weights\n\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Probabilistic neighborhood exploration with value-to-weight ratio\n    for _ in range(3):  # Increased trials\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            vw_ratio = (value1_lst * 0.7 + value2_lst * 0.3) / weight_lst  # Different weight combination\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(3, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip\n    if np.array_equal(new_solution, base_solution):\n        # Flip items with lowest value-to-weight ratio\n        vw_ratio = (value1_lst * 0.3 + value2_lst * 0.7) / weight_lst  # Different weight combination\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.881238273007625,
            -17.612570262095716
        ]
    },
    {
        "algorithm": "{This new algorithm selects a solution from the archive using a weighted random selection based on the sum of normalized objectives with different weights, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a different parameter setting for the score function by considering the product of normalized objectives with different weights.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    weights = [(obj[0]/max_v1 * 0.4 + obj[1]/max_v2 * 0.6) for _, obj in archive]  # Sum of normalized objectives with weights\n\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Probabilistic neighborhood exploration with value-to-weight ratio\n    for _ in range(3):  # More trials\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            vw_ratio = (value1_lst * 0.5 + value2_lst * 0.5) / weight_lst  # Different weight combination\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(3, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip\n    if np.array_equal(new_solution, base_solution):\n        # Flip items with lowest value-to-weight ratio\n        vw_ratio = (value1_lst * 0.6 + value2_lst * 0.4) / weight_lst  # Different weight combination\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.144538861714363,
            -18.587309667215894
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a weighted random selection based on the ratio of normalized objective values, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a different parameter setting for the score function by considering the product of normalized objectives with different weights.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    weights = [(obj[0]/max_v1) * (obj[1]/max_v2) for _, obj in archive]  # Product of normalized objectives\n\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Probabilistic neighborhood exploration with value-to-weight ratio\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            vw_ratio = (value1_lst * 0.5 + value2_lst * 0.5) / weight_lst  # Equal weight combination\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(2, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip\n    if np.array_equal(new_solution, base_solution):\n        # Flip items with lowest value-to-weight ratio\n        vw_ratio = (value1_lst * 0.5 + value2_lst * 0.5) / weight_lst  # Equal weight combination\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.073688694175253,
            -18.645725210171413
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a weighted random selection based on the harmonic mean of normalized objective values, then applies a hybrid local search that combines item swaps with a probabilistic neighborhood exploration prioritizing items with high value-to-weight ratios while ensuring feasibility, and uses a different parameter setting for the score function by considering the product of normalized objectives with different weights.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    weights = [2 * (obj[0]/max_v1) * (obj[1]/max_v2) / ((obj[0]/max_v1) + (obj[1]/max_v2)) for _, obj in archive]  # Harmonic mean of normalized objectives\n\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Probabilistic neighborhood exploration with value-to-weight ratio\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            vw_ratio = (value1_lst * 0.5 + value2_lst * 0.5) / weight_lst  # Equal weight combination\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(2, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip\n    if np.array_equal(new_solution, base_solution):\n        # Flip items with lowest value-to-weight ratio\n        vw_ratio = (value1_lst * 0.4 + value2_lst * 0.6) / weight_lst  # Different weight combination\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.06963488411425,
            -18.659029005266614
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a tournament-based selection considering both objective values and diversity, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic parameter setting for the score function by considering a weighted combination of normalized objectives with adaptive weights based on their relative importance.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Tournament-based selection considering both objectives and diversity\n    tournament_size = min(5, len(archive))\n    selected_idx = random.choice(random.sample(range(len(archive)), tournament_size))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_v1, current_v2 = archive[selected_idx][1]\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Calculate adaptive weights based on relative importance\n    max_v1 = max(obj[0] for _, obj in archive)\n    max_v2 = max(obj[1] for _, obj in archive)\n    v1_weight = 0.5 if max_v1 > 0 else 0.5\n    v2_weight = 1 - v1_weight\n\n    # Hybrid local search with probabilistic exploration\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio with adaptive weights\n            vw_ratio = (value1_lst * v1_weight + value2_lst * v2_weight) / weight_lst\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(3, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip with adaptive weights\n    if np.array_equal(new_solution, base_solution):\n        vw_ratio = (value1_lst * v1_weight + value2_lst * v2_weight) / weight_lst\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.138797262017462,
            -18.592009752814143
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a weighted random selection based on the product of normalized objective values with different weights, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a different parameter setting for the score function by considering the sum of normalized objectives with different weights.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    weights = [(0.6 * obj[0]/max_v1 + 0.4 * obj[1]/max_v2) for _, obj in archive]  # Sum of normalized objectives with different weights\n\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Probabilistic neighborhood exploration with value-to-weight ratio\n    for _ in range(3):  # Increased trials\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            vw_ratio = (value1_lst * 0.7 + value2_lst * 0.3) / weight_lst  # Different weight combination\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(3, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip\n    if np.array_equal(new_solution, base_solution):\n        # Flip items with lowest value-to-weight ratio\n        vw_ratio = (value1_lst * 0.3 + value2_lst * 0.7) / weight_lst  # Different weight combination\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.8985557162141,
            -17.58171637398599
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a weighted random selection based on the harmonic mean of normalized objective values, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a dynamic weight adjustment mechanism to balance the exploration of both objectives.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    max_v1 = max(obj[0] for _, obj in archive)\n    max_v2 = max(obj[1] for _, obj in archive)\n\n    # Calculate harmonic mean of normalized objectives with dynamic weights\n    alpha = 0.5 * (1 + np.sin(len(archive) / 10))  # Dynamic weight factor\n    weights = [(2 * (alpha * obj[0]/max_v1) * ((1-alpha) * obj[1]/max_v2)) /\n               ((alpha * obj[0]/max_v1) + ((1-alpha) * obj[1]/max_v2)) for _, obj in archive]\n\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Dynamic value-to-weight ratio calculation\n    beta = 0.3 + 0.4 * (1 - np.exp(-len(archive)/100))  # Dynamic weight factor\n    vw_ratio = (value1_lst * beta + value2_lst * (1-beta)) / weight_lst\n\n    # Hybrid neighborhood exploration\n    for _ in range(4):  # Increased trials with dynamic adjustment\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(4, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a probabilistic flip based on dynamic ratio\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if random.random() < 0.3:  # Probabilistic flip\n                if new_solution[i] == 1:\n                    if current_weight - weight_lst[i] >= 0:\n                        new_solution[i] = 0\n                        break\n                else:\n                    if current_weight + weight_lst[i] <= capacity:\n                        new_solution[i] = 1\n                        break\n\n    return new_solution\n\n",
        "score": [
            -19.26991717530702,
            -18.335309102795897
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a tournament selection based on the product of normalized objective values with different weights, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a different parameter setting for the score function by considering the sum of normalized objectives with different weights.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    scores = [(obj[0]/max_v1 * 0.5 + obj[1]/max_v2 * 0.5) for _, obj in archive]  # Product of normalized objectives with different weights\n\n    selected_idx = random.choices(range(len(archive)), weights=scores, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Probabilistic neighborhood exploration with value-to-weight ratio\n    for _ in range(3):\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            vw_ratio = (value1_lst * 0.5 + value2_lst * 0.5) / weight_lst  # Different weight combination\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(2, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip\n    if np.array_equal(new_solution, base_solution):\n        vw_ratio = (value1_lst * 0.7 + value2_lst * 0.3) / weight_lst  # Different weight combination\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.050288933279543,
            -18.673881201673023
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a weighted random selection based on the sum of normalized objective values, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a different parameter setting for the score function.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    weights = [(obj[0]/max_v1 + obj[1]/max_v2) for _, obj in archive]  # Changed to sum instead of product\n\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Probabilistic neighborhood exploration with value-to-weight ratio\n    for _ in range(3):  # Reduced trials\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            vw_ratio = (value1_lst + value2_lst) / weight_lst\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(3, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip\n    if np.array_equal(new_solution, base_solution):\n        # Flip items with lowest value-to-weight ratio\n        vw_ratio = (value1_lst + value2_lst) / weight_lst\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.204560256859423,
            -18.536946752989312
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a weighted random selection based on the product of normalized objective values, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a different parameter setting for the score function.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    weights = [(obj[0]/max_v1) * (obj[1]/max_v2) for _, obj in archive]  # Changed to product instead of sum\n\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Probabilistic neighborhood exploration with value-to-weight ratio\n    for _ in range(3):  # Reduced trials\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            vw_ratio = (value1_lst + value2_lst) / weight_lst\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(3, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip\n    if np.array_equal(new_solution, base_solution):\n        # Flip items with lowest value-to-weight ratio\n        vw_ratio = (value1_lst + value2_lst) / weight_lst\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.170230436380553,
            -18.55775908818245
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a tournament selection based on the dominance count of each solution, then applies a hybrid local search that combines item swaps with a probabilistic neighborhood exploration prioritizing items with high value-to-weight ratios, while ensuring feasibility through a capacity-aware item selection strategy.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    tournament_size = min(5, len(archive))\n    selected_indices = random.sample(range(len(archive)), tournament_size)\n    selected_idx = max(selected_indices, key=lambda i: sum(1 for j in selected_indices if archive[i][1][0] >= archive[j][1][0] and archive[i][1][1] >= archive[j][1][1]))\n\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n\n    # Calculate value-to-weight ratios for both objectives\n    vw_ratio1 = value1_lst / weight_lst\n    vw_ratio2 = value2_lst / weight_lst\n    combined_ratio = (vw_ratio1 + vw_ratio2) / 2\n\n    # Probabilistic neighborhood exploration with combined ratio\n    for _ in range(5):\n        candidates = np.where(new_solution == 1)[0]\n        non_candidates = np.where(new_solution == 0)[0]\n\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low combined ratio\n            remove_candidates = sorted(candidates, key=lambda i: combined_ratio[i])\n            num_remove = random.randint(1, min(3, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high combined ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -combined_ratio[i])\n\n                best_add_indices = []\n                temp_weight_check = temp_weight\n                for i in sorted_items:\n                    if temp_weight_check + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight_check += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n                    current_weight = temp_weight_check\n\n    # If no improvement, perform a capacity-aware flip\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.argsort(combined_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.087182662881773,
            -18.632184663896055
        ]
    },
    {
        "algorithm": "{The new algorithm selects a solution from the archive using a weighted random selection based on the sum of normalized objective values, then applies a hybrid local search combining item swaps with a probabilistic neighborhood exploration that prioritizes items with high value-to-weight ratios while ensuring feasibility, and uses a different parameter setting for the score function.}",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    weights = [(obj[0]/max_v1 + obj[1]/max_v2) for _, obj in archive]  # Changed to sum instead of product\n\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    candidates = np.where(new_solution == 1)[0]\n    non_candidates = np.where(new_solution == 0)[0]\n\n    # Probabilistic neighborhood exploration with value-to-weight ratio\n    for _ in range(3):  # Reduced trials\n        if len(candidates) > 0 and len(non_candidates) > 0:\n            # Select items to remove based on low value-to-weight ratio\n            vw_ratio = (value1_lst + value2_lst) / weight_lst\n            remove_candidates = sorted(candidates, key=lambda i: vw_ratio[i])\n            num_remove = random.randint(1, min(3, len(candidates)))\n            remove_indices = random.sample(remove_candidates[:num_remove], num_remove)\n            temp_weight = current_weight - np.sum(weight_lst[remove_indices])\n\n            # Find best items to add based on high value-to-weight ratio\n            remaining_capacity = capacity - temp_weight\n            available_items = [i for i in non_candidates if weight_lst[i] <= remaining_capacity]\n            if available_items:\n                sorted_items = sorted(available_items, key=lambda i: -vw_ratio[i])\n\n                best_add_indices = []\n                for i in sorted_items:\n                    if temp_weight + weight_lst[i] <= capacity:\n                        best_add_indices.append(i)\n                        temp_weight += weight_lst[i]\n\n                if best_add_indices:\n                    for idx in remove_indices:\n                        new_solution[idx] = 0\n                    for idx in best_add_indices:\n                        new_solution[idx] = 1\n\n    # If no improvement, perform a targeted flip\n    if np.array_equal(new_solution, base_solution):\n        # Flip items with lowest value-to-weight ratio\n        vw_ratio = (value1_lst + value2_lst) / weight_lst\n        flip_candidates = np.argsort(vw_ratio)\n        for i in flip_candidates:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    break\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -19.204560256859423,
            -18.536946752989312
        ]
    }
]