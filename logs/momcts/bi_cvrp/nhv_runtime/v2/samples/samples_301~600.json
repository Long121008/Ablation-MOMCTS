[
    {
        "prompt": "You are solving a Bi-objective Capacitated Vehicle Routing Problem (Bi-CVRP), where a single depot and multiple customers are located in 2D space. Each customer has a positive demand, and all vehicles in the fleet have identical capacity limits. The objective is to construct a set of routes, each starting and ending at the depot, such that all customers are served, vehicle capacities are not exceeded on any route, and two conflicting objectives are minimized: (1) the total travel distance across all routes, and (2) the makespan, defined as the length of the longest individual route. Each solution in the archive is represented as a list of NumPy arrays, where each array denotes a single route (starting and ending with depot index 0), and is paired with a tuple of two objective values (total_distance, makespan). Your task is to implement a function named 'select_neighbor' that selects one promising solution from the archive and apply a novel or hybrid local search operator to generate a feasible neighbor solution from it. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself. Avoid standard methods like pure 2-opt; instead, invent or combine transformations, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. Ensure that the returned neighbor solution remains feasible under the vehicle capacity constraint. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        None\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    def adaptive_pareto_score(solution, objectives):\n        total_dist, makespan = objectives\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        # Dynamic weight based on solution characteristics\n        weight = 0.5 + 0.3 * (1 - makespan / (max_makespan + 1e-6))  # More weight to makespan for longer routes\n        return weight * norm_dist + (1 - weight) * norm_makespan\n\n    # Select solution using adaptive Pareto scoring\n    scored_solutions = [(adaptive_pareto_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.3 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Demand-aware route inversion with adaptive Pareto consideration\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4:\n            # Calculate demand balance score\n            total_demand = sum(demand[route[1:-1]])\n            demand_diff = 0\n            for i in range(1, len(route)-1):\n                segment_demand = sum(demand[route[1:i]])\n                demand_diff = max(demand_diff, abs(segment_demand - 0.5 * total_demand))\n\n            # More aggressive inversion for poorly balanced routes\n            inversion_prob = 0.3 + 0.4 * (demand_diff / (total_demand + 1e-6))\n            if random.random() < inversion_prob:\n                # Find the most demand-imbalanced segment\n                best_split = 1\n                best_score = -1\n                for i in range(1, len(route)-1):\n                    segment_demand = sum(demand[route[1:i]])\n                    score = abs(segment_demand - 0.5 * total_demand) / (segment_demand + 1e-6)\n                    if score > best_score:\n                        best_score = score\n                        best_split = i\n\n                inverted_route = np.concatenate([route[:best_split], route[best_split:][::-1]])\n                if is_feasible(inverted_route):\n                    new_solution[route_idx] = inverted_route\n\n    # Hybrid split-reinsert with demand-aware positioning\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5 and random.random() < 0.4:\n            # Find the most demand-imbalanced split point\n            total_demand = sum(demand[route[1:-1]])\n            best_split = -1\n            best_diff = -1\n            for i in range(2, len(route)-2):\n                segment_demand = sum(demand[route[1:i]])\n                diff = abs(segment_demand - 0.5 * total_demand) / (total_demand + 1e-6)\n                if diff > best_diff:\n                    best_diff = diff\n                    best_split = i\n\n            if best_split > 1:\n                segment1 = route[:best_split+1]\n                segment2 = np.concatenate([[0], route[best_split+1:]])\n\n                if is_feasible(segment1) and is_feasible(segment2):\n                    new_solution[route_idx] = segment1\n                    new_solution.insert(route_idx+1, segment2)\n                    break\n\n    # Capacity-check clustering with adaptive Pareto consideration\n    if len(new_solution) > 1 and random.random() < 0.5:\n        route_stats = []\n        for route in new_solution:\n            if len(route) > 2:\n                centroid = np.mean(coords[route[1:-1]], axis=0)\n                total_demand = sum(demand[route[1:-1]])\n                route_stats.append((centroid, total_demand, route))\n\n        if len(route_stats) > 1:\n            # Find closest pairs with similar demand\n            closest_pairs = []\n            for i in range(len(route_stats)):\n                for j in range(i+1, len(route_stats)):\n                    dist = np.linalg.norm(route_stats[i][0] - route_stats[j][0])\n                    demand_diff = abs(route_stats[i][1] - route_stats[j][1])\n                    # Weight distance and demand difference based on Pareto weights\n                    weighted_score = 0.6 * dist + 0.4 * demand_diff\n                    closest_pairs.append((weighted_score, i, j))\n\n            closest_pairs.sort()\n            for _, i, j in closest_pairs[:min(2, len(closest_pairs))]:\n                route_i = route_stats[i][2]\n                route_j = route_stats[j][2]\n                if sum(demand[route_i[1:-1]]) + sum(demand[route_j[1:-1]]) <= capacity:\n                    # Find best merge points\n                    min_dist = float('inf')\n                    best_i, best_j = 0, 0\n                    for a in range(1, len(route_i)-1):\n                        for b in range(1, len(route_j)-1):\n                            dist = distance_matrix[route_i[a]][route_j[b]]\n                            if dist < min_dist:\n                                min_dist = dist\n                                best_i, best_j = a, b\n\n                    merged_route = np.concatenate([route_i[:best_i+1], route_j[best_j:-1], route_i[-1:]])\n                    new_solution = [r for r in new_solution if not np.array_equal(r, route_i) and not np.array_equal(r, route_j)]\n                    new_solution.append(merged_route)\n                    break\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 301,
        "algorithm": "The algorithm selects promising solutions from the archive using a dynamic Pareto-based scoring system that prioritizes solutions with balanced objective values, then applies a hybrid local search combining demand-aware route inversion, adaptive split-reinsert operations, and capacity-constrained route merging with spatial and demand considerations to generate high-quality neighbor solutions. The method intelligently balances spatial proximity and demand constraints, favoring operations that improve both total distance and makespan objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    def dynamic_pareto_score(solution, objectives):\n        total_dist, makespan = objectives\n        min_dist = min(obj[0] for _, obj in archive)\n        min_makespan = min(obj[1] for _, obj in archive)\n        norm_dist = 1 - (total_dist - min_dist) / (max(obj[0] for _, obj in archive) - min_dist + 1e-6)\n        norm_makespan = 1 - (makespan - min_makespan) / (max(obj[1] for _, obj in archive) - min_makespan + 1e-6)\n        # Adaptive weight based on solution characteristics\n        weight = 0.4 + 0.4 * (norm_makespan - norm_dist)  # More weight to underperforming objective\n        return weight * norm_dist + (1 - weight) * norm_makespan\n\n    # Select solution using dynamic Pareto scoring\n    scored_solutions = [(dynamic_pareto_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0], reverse=True)\n    top_k = max(1, int(0.25 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Demand-balanced route inversion with spatial consideration\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4 and random.random() < 0.4:\n            # Calculate spatial and demand balance\n            centroid = np.mean(coords[route[1:-1]], axis=0)\n            total_demand = sum(demand[route[1:-1]])\n            imbalance_score = 0\n            for i in range(1, len(route)-1):\n                segment_demand = sum(demand[route[1:i]])\n                spatial_dist = np.linalg.norm(coords[route[i]] - centroid)\n                imbalance_score = max(imbalance_score, abs(segment_demand - 0.5 * total_demand) * spatial_dist)\n\n            inversion_prob = 0.2 + 0.6 * (imbalance_score / (total_demand * np.max(distance_matrix) + 1e-6))\n            if random.random() < inversion_prob:\n                # Find optimal inversion point considering both demand and spatial balance\n                best_split = 1\n                best_score = -1\n                for i in range(1, len(route)-1):\n                    segment_demand = sum(demand[route[1:i]])\n                    spatial_dist = np.linalg.norm(coords[route[i]] - centroid)\n                    score = (abs(segment_demand - 0.5 * total_demand) / (segment_demand + 1e-6)) * spatial_dist\n                    if score > best_score:\n                        best_score = score\n                        best_split = i\n\n                inverted_route = np.concatenate([route[:best_split], route[best_split:][::-1]])\n                if is_feasible(inverted_route):\n                    new_solution[route_idx] = inverted_route\n\n    # Adaptive split with demand and spatial clustering\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5 and random.random() < 0.35:\n            # Find optimal split point considering demand and spatial clustering\n            total_demand = sum(demand[route[1:-1]])\n            centroid = np.mean(coords[route[1:-1]], axis=0)\n            best_split = -1\n            best_score = -1\n            for i in range(2, len(route)-2):\n                segment_demand = sum(demand[route[1:i]])\n                segment_centroid = np.mean(coords[route[1:i]], axis=0)\n                demand_diff = abs(segment_demand - 0.5 * total_demand) / (total_demand + 1e-6)\n                spatial_diff = np.linalg.norm(segment_centroid - centroid)\n                score = demand_diff * spatial_diff\n                if score > best_score:\n                    best_score = score\n                    best_split = i\n\n            if best_split > 1:\n                segment1 = route[:best_split+1]\n                segment2 = np.concatenate([[0], route[best_split+1:]])\n\n                if is_feasible(segment1) and is_feasible(segment2):\n                    new_solution[route_idx] = segment1\n                    new_solution.insert(route_idx+1, segment2)\n                    break\n\n    # Demand-aware route merging with spatial proximity\n    if len(new_solution) > 1 and random.random() < 0.45:\n        route_stats = []\n        for route in new_solution:\n            if len(route) > 2:\n                centroid = np.mean(coords[route[1:-1]], axis=0)\n                total_demand = sum(demand[route[1:-1]])\n                route_stats.append((centroid, total_demand, route))\n\n        if len(route_stats) > 1:\n            # Find best merge candidates considering demand and spatial proximity\n            best_pairs = []\n            for i in range(len(route_stats)):\n                for j in range(i+1, len(route_stats)):\n                    dist = np.linalg.norm(route_stats[i][0] - route_stats[j][0])\n                    demand_diff = abs(route_stats[i][1] - route_stats[j][1])\n                    # Weighted score combining spatial and demand factors\n                    weighted_score = 0.5 * dist + 0.5 * demand_diff\n                    best_pairs.append((weighted_score, i, j))\n\n            best_pairs.sort()\n            for _, i, j in best_pairs[:min(3, len(best_pairs))]:\n                route_i = route_stats[i][2]\n                route_j = route_stats[j][2]\n                if sum(demand[route_i[1:-1]]) + sum(demand[route_j[1:-1]]) <= capacity:\n                    # Find best merge points considering spatial proximity\n                    min_dist = float('inf')\n                    best_i, best_j = 0, 0\n                    for a in range(1, len(route_i)-1):\n                        for b in range(1, len(route_j)-1):\n                            dist = distance_matrix[route_i[a]][route_j[b]]\n                            if dist < min_dist:\n                                min_dist = dist\n                                best_i, best_j = a, b\n\n                    merged_route = np.concatenate([route_i[:best_i+1], route_j[best_j:-1], route_i[-1:]])\n                    new_solution = [r for r in new_solution if not np.array_equal(r, route_i) and not np.array_equal(r, route_j)]\n                    new_solution.append(merged_route)\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.6138163831147472,
            0.8771076500415802
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    def dynamic_pareto_score(solution, objectives):\n        total_dist, makespan = objectives\n        min_dist = min(obj[0] for _, obj in archive)\n        min_makespan = min(obj[1] for _, obj in archive)\n        norm_dist = 1 - (total_dist - min_dist) / (max(obj[0] for _, obj in archive) - min_dist + 1e-6)\n        norm_makespan = 1 - (makespan - min_makespan) / (max(obj[1] for _, obj in archive) - min_makespan + 1e-6)\n        # Adaptive weight based on solution characteristics\n        weight = 0.4 + 0.4 * (norm_makespan - norm_dist)  # More weight to underperforming objective\n        return weight * norm_dist + (1 - weight) * norm_makespan\n\n    # Select solution using dynamic Pareto scoring\n    scored_solutions = [(dynamic_pareto_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0], reverse=True)\n    top_k = max(1, int(0.25 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Demand-balanced route inversion with spatial consideration\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4 and random.random() < 0.4:\n            # Calculate spatial and demand balance\n            centroid = np.mean(coords[route[1:-1]], axis=0)\n            total_demand = sum(demand[route[1:-1]])\n            imbalance_score = 0\n            for i in range(1, len(route)-1):\n                segment_demand = sum(demand[route[1:i]])\n                spatial_dist = np.linalg.norm(coords[route[i]] - centroid)\n                imbalance_score = max(imbalance_score, abs(segment_demand - 0.5 * total_demand) * spatial_dist)\n\n            inversion_prob = 0.2 + 0.6 * (imbalance_score / (total_demand * np.max(distance_matrix) + 1e-6))\n            if random.random() < inversion_prob:\n                # Find optimal inversion point considering both demand and spatial balance\n                best_split = 1\n                best_score = -1\n                for i in range(1, len(route)-1):\n                    segment_demand = sum(demand[route[1:i]])\n                    spatial_dist = np.linalg.norm(coords[route[i]] - centroid)\n                    score = (abs(segment_demand - 0.5 * total_demand) / (segment_demand + 1e-6)) * spatial_dist\n                    if score > best_score:\n                        best_score = score\n                        best_split = i\n\n                inverted_route = np.concatenate([route[:best_split], route[best_split:][::-1]])\n                if is_feasible(inverted_route):\n                    new_solution[route_idx] = inverted_route\n\n    # Adaptive split with demand and spatial clustering\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5 and random.random() < 0.35:\n            # Find optimal split point considering demand and spatial clustering\n            total_demand = sum(demand[route[1:-1]])\n            centroid = np.mean(coords[route[1:-1]], axis=0)\n            best_split = -1\n            best_score = -1\n            for i in range(2, len(route)-2):\n                segment_demand = sum(demand[route[1:i]])\n                segment_centroid = np.mean(coords[route[1:i]], axis=0)\n                demand_diff = abs(segment_demand - 0.5 * total_demand) / (total_demand + 1e-6)\n                spatial_diff = np.linalg.norm(segment_centroid - centroid)\n                score = demand_diff * spatial_diff\n                if score > best_score:\n                    best_score = score\n                    best_split = i\n\n            if best_split > 1:\n                segment1 = route[:best_split+1]\n                segment2 = np.concatenate([[0], route[best_split+1:]])\n\n                if is_feasible(segment1) and is_feasible(segment2):\n                    new_solution[route_idx] = segment1\n                    new_solution.insert(route_idx+1, segment2)\n                    break\n\n    # Demand-aware route merging with spatial proximity\n    if len(new_solution) > 1 and random.random() < 0.45:\n        route_stats = []\n        for route in new_solution:\n            if len(route) > 2:\n                centroid = np.mean(coords[route[1:-1]], axis=0)\n                total_demand = sum(demand[route[1:-1]])\n                route_stats.append((centroid, total_demand, route))\n\n        if len(route_stats) > 1:\n            # Find best merge candidates considering demand and spatial proximity\n            best_pairs = []\n            for i in range(len(route_stats)):\n                for j in range(i+1, len(route_stats)):\n                    dist = np.linalg.norm(route_stats[i][0] - route_stats[j][0])\n                    demand_diff = abs(route_stats[i][1] - route_stats[j][1])\n                    # Weighted score combining spatial and demand factors\n                    weighted_score = 0.5 * dist + 0.5 * demand_diff\n                    best_pairs.append((weighted_score, i, j))\n\n            best_pairs.sort()\n            for _, i, j in best_pairs[:min(3, len(best_pairs))]:\n                route_i = route_stats[i][2]\n                route_j = route_stats[j][2]\n                if sum(demand[route_i[1:-1]]) + sum(demand[route_j[1:-1]]) <= capacity:\n                    # Find best merge points considering spatial proximity\n                    min_dist = float('inf')\n                    best_i, best_j = 0, 0\n                    for a in range(1, len(route_i)-1):\n                        for b in range(1, len(route_j)-1):\n                            dist = distance_matrix[route_i[a]][route_j[b]]\n                            if dist < min_dist:\n                                min_dist = dist\n                                best_i, best_j = a, b\n\n                    merged_route = np.concatenate([route_i[:best_i+1], route_j[best_j:-1], route_i[-1:]])\n                    new_solution = [r for r in new_solution if not np.array_equal(r, route_i) and not np.array_equal(r, route_j)]\n                    new_solution.append(merged_route)\n                    break\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Capacitated Vehicle Routing Problem (Bi-CVRP), where a single depot and multiple customers are located in 2D space. Each customer has a positive demand, and all vehicles in the fleet have identical capacity limits. The objective is to construct a set of routes, each starting and ending at the depot, such that all customers are served, vehicle capacities are not exceeded on any route, and two conflicting objectives are minimized: (1) the total travel distance across all routes, and (2) the makespan, defined as the length of the longest individual route. Each solution in the archive is represented as a list of NumPy arrays, where each array denotes a single route (starting and ending with depot index 0), and is paired with a tuple of two objective values (total_distance, makespan). Your task is to implement a function named 'select_neighbor' that selects one promising solution from the archive and apply a novel or hybrid local search operator to generate a feasible neighbor solution from it. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself. Avoid standard methods like pure 2-opt; instead, invent or combine transformations, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. Ensure that the returned neighbor solution remains feasible under the vehicle capacity constraint. The function should return the new neighbor solution.\n            I have 6 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    def adaptive_pareto_score(solution, objectives):\n        total_dist, makespan = objectives\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        # Dynamic weight based on solution characteristics\n        weight = 0.5 + 0.3 * (1 - makespan / (max_makespan + 1e-6))  # More weight to makespan for longer routes\n        return weight * norm_dist + (1 - weight) * norm_makespan\n\n    # Select solution using adaptive Pareto scoring\n    scored_solutions = [(adaptive_pareto_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.3 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Demand-aware route inversion with adaptive Pareto consideration\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4:\n            # Calculate demand balance score\n            total_demand = sum(demand[route[1:-1]])\n            demand_diff = 0\n            for i in range(1, len(route)-1):\n                segment_demand = sum(demand[route[1:i]])\n                demand_diff = max(demand_diff, abs(segment_demand - 0.5 * total_demand))\n\n            # More aggressive inversion for poorly balanced routes\n            inversion_prob = 0.3 + 0.4 * (demand_diff / (total_demand + 1e-6))\n            if random.random() < inversion_prob:\n                # Find the most demand-imbalanced segment\n                best_split = 1\n                best_score = -1\n                for i in range(1, len(route)-1):\n                    segment_demand = sum(demand[route[1:i]])\n                    score = abs(segment_demand - 0.5 * total_demand) / (segment_demand + 1e-6)\n                    if score > best_score:\n                        best_score = score\n                        best_split = i\n\n                inverted_route = np.concatenate([route[:best_split], route[best_split:][::-1]])\n                if is_feasible(inverted_route):\n                    new_solution[route_idx] = inverted_route\n\n    # Hybrid split-reinsert with demand-aware positioning\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5 and random.random() < 0.4:\n            # Find the most demand-imbalanced split point\n            total_demand = sum(demand[route[1:-1]])\n            best_split = -1\n            best_diff = -1\n            for i in range(2, len(route)-2):\n                segment_demand = sum(demand[route[1:i]])\n                diff = abs(segment_demand - 0.5 * total_demand) / (total_demand + 1e-6)\n                if diff > best_diff:\n                    best_diff = diff\n                    best_split = i\n\n            if best_split > 1:\n                segment1 = route[:best_split+1]\n                segment2 = np.concatenate([[0], route[best_split+1:]])\n\n                if is_feasible(segment1) and is_feasible(segment2):\n                    new_solution[route_idx] = segment1\n                    new_solution.insert(route_idx+1, segment2)\n                    break\n\n    # Capacity-check clustering with adaptive Pareto consideration\n    if len(new_solution) > 1 and random.random() < 0.5:\n        route_stats = []\n        for route in new_solution:\n            if len(route) > 2:\n                centroid = np.mean(coords[route[1:-1]], axis=0)\n                total_demand = sum(demand[route[1:-1]])\n                route_stats.append((centroid, total_demand, route))\n\n        if len(route_stats) > 1:\n            # Find closest pairs with similar demand\n            closest_pairs = []\n            for i in range(len(route_stats)):\n                for j in range(i+1, len(route_stats)):\n                    dist = np.linalg.norm(route_stats[i][0] - route_stats[j][0])\n                    demand_diff = abs(route_stats[i][1] - route_stats[j][1])\n                    # Weight distance and demand difference based on Pareto weights\n                    weighted_score = 0.6 * dist + 0.4 * demand_diff\n                    closest_pairs.append((weighted_score, i, j))\n\n            closest_pairs.sort()\n            for _, i, j in closest_pairs[:min(2, len(closest_pairs))]:\n                route_i = route_stats[i][2]\n                route_j = route_stats[j][2]\n                if sum(demand[route_i[1:-1]]) + sum(demand[route_j[1:-1]]) <= capacity:\n                    # Find best merge points\n                    min_dist = float('inf')\n                    best_i, best_j = 0, 0\n                    for a in range(1, len(route_i)-1):\n                        for b in range(1, len(route_j)-1):\n                            dist = distance_matrix[route_i[a]][route_j[b]]\n                            if dist < min_dist:\n                                min_dist = dist\n                                best_i, best_j = a, b\n\n                    merged_route = np.concatenate([route_i[:best_i+1], route_j[best_j:-1], route_i[-1:]])\n                    new_solution = [r for r in new_solution if not np.array_equal(r, route_i) and not np.array_equal(r, route_j)]\n                    new_solution.append(merged_route)\n                    break\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive spatial-demand clustering with probabilistic route inversion and dynamic capacity-aware merging, prioritizing solutions with balanced normalized objectives and spatial diversity while applying demand-aware splitting, centroid-based inversion, and capacity-feasible merging to generate high-quality neighbors. It first selects promising solutions based on a spatial-demand score (balancing normalized distance and makespan with spatial diversity), then applies three key transformations: merging nearby routes when feasible, probabilistically inverting segments of routes around farthest centroid nodes, and splitting oversized routes while maintaining capacity constraints. The method explores Pareto-efficient regions by probabilistically applying these transformations while preserving feasibility.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    def spatial_demand_score(sol, obj):\n        total_dist, makespan = obj\n        max_dist = max(o[0] for _, o in archive)\n        max_makespan = max(o[1] for _, o in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        spatial_diversity = np.std([np.mean(coords[route[1:-1]], axis=0) for route in sol])\n        return (0.5 * norm_dist + 0.5 * norm_makespan) * (1 + 0.3 * spatial_diversity)\n\n    scored_solutions = [(spatial_demand_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.3 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Adaptive spatial-demand clustering\n    if len(new_solution) > 1 and random.random() < 0.6:\n        route_stats = []\n        for route in new_solution:\n            if len(route) > 2:\n                centroid = np.mean(coords[route[1:-1]], axis=0)\n                total_demand = sum(demand[route[1:-1]])\n                route_stats.append((centroid, total_demand, route))\n\n        if len(route_stats) > 1:\n            centroids = np.array([stat[0] for stat in route_stats])\n            demands = np.array([stat[1] for stat in route_stats])\n            routes = [stat[2] for stat in route_stats]\n\n            for i in range(len(routes)):\n                for j in range(i+1, len(routes)):\n                    if np.linalg.norm(centroids[i] - centroids[j]) < 0.3 * np.max(np.linalg.norm(centroids - np.mean(centroids, axis=0), axis=1)):\n                        if demands[i] + demands[j] <= capacity:\n                            merged_route = np.concatenate([routes[i][:-1], routes[j][1:]])\n                            if is_feasible(merged_route):\n                                new_solution = [r for r in new_solution if not np.array_equal(r, routes[i]) and not np.array_equal(r, routes[j])]\n                                new_solution.append(merged_route)\n                                break\n\n    # Centroid-based probabilistic inversion\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4:\n            centroid = np.mean(coords[route[1:-1]], axis=0)\n            farthest_node = max(route[1:-1], key=lambda x: np.linalg.norm(coords[x] - centroid))\n            pos = np.where(route == farthest_node)[0][0]\n            if random.random() < 0.5:\n                inverted_route = np.concatenate([route[:pos], route[pos:][::-1]])\n                if is_feasible(inverted_route):\n                    new_solution[route_idx] = inverted_route\n\n    # Dynamic capacity-aware splitting\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5 and random.random() < 0.4:\n            total_demand = sum(demand[route[1:-1]])\n            split_pos = random.randint(2, len(route)-3)\n            segment1 = route[:split_pos+1]\n            segment2 = np.concatenate([[0], route[split_pos+1:]])\n\n            if is_feasible(segment1) and is_feasible(segment2):\n                new_solution[route_idx] = segment1\n                new_solution.insert(route_idx+1, segment2)\n                break\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from an archive using a dynamic fitness score that balances normalized distance and makespan objectives, with added diversity consideration. It then applies a hybrid local search combining spatial-aware route merging (with demand balancing), adaptive route inversion (based on spatial diversity), and probabilistic route splitting (with demand-aware positioning) while ensuring capacity feasibility. The approach prioritizes solutions with moderate makespan (0.6 weight) over total distance (0.4 weight) and emphasizes route balancing through strategic merging and splitting operations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    def dynamic_fitness_score(solution, objectives):\n        total_dist, makespan = objectives\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        diversity_factor = 1 - len(solution) / (max(len(sol) for sol, _ in archive) + 1)\n        return (0.4 * norm_dist + 0.6 * norm_makespan) * (1 + 0.2 * diversity_factor)\n\n    scored_solutions = [(dynamic_fitness_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.3 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Spatial-aware route merging with demand balancing\n    route_stats = [(sum(demand[route[1:-1]]), len(route)-2) for route in new_solution]\n    avg_load = np.mean([load for load, _ in route_stats]) if route_stats else 0\n    avg_length = np.mean([length for _, length in route_stats]) if route_stats else 0\n\n    for i in range(len(new_solution)):\n        route_i = new_solution[i]\n        load_i, length_i = route_stats[i]\n        for j in range(i+1, len(new_solution)):\n            route_j = new_solution[j]\n            load_j, length_j = route_stats[j]\n            if abs(load_i - load_j) <= 0.4 * avg_load and abs(length_i - length_j) <= 0.4 * avg_length:\n                if load_i + load_j <= capacity:\n                    min_dist = float('inf')\n                    best_pair = (0, 0)\n                    for a in range(1, len(route_i)-1):\n                        for b in range(1, len(route_j)-1):\n                            dist = distance_matrix[route_i[a]][route_j[b]]\n                            if dist < min_dist:\n                                min_dist = dist\n                                best_pair = (a, b)\n                    merged_route = np.concatenate([route_i[:best_pair[0]+1], route_j[best_pair[1]:-1], route_i[-1:]])\n                    new_solution = [route for idx, route in enumerate(new_solution) if idx not in [i, j]] + [merged_route]\n                    route_stats = [(sum(demand[route[1:-1]]), len(route)-2) for route in new_solution]\n                    break\n\n    # Adaptive route inversion with spatial diversity\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4:\n            centroid = np.mean(coords[route[1:-1]], axis=0)\n            farthest_node = max(route[1:-1], key=lambda x: np.linalg.norm(coords[x] - centroid))\n            pos = np.where(route == farthest_node)[0][0]\n            inversion_prob = 0.6 if len(route) > 8 else 0.3\n            if random.random() < inversion_prob:\n                if is_feasible(np.concatenate([route[:pos], route[pos:][::-1]])):\n                    new_solution[route_idx] = np.concatenate([route[:pos], route[pos:][::-1]])\n\n    # Probabilistic route splitting with demand-aware positioning\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5 and random.random() < 0.5:\n            load = sum(demand[route[1:-1]])\n            split_pos = random.randint(2, len(route)-3)\n            if (sum(demand[route[1:split_pos]]) <= capacity and\n                sum(demand[route[split_pos:-1]]) <= capacity and\n                abs(sum(demand[route[1:split_pos]]) - 0.5 * load) <= 0.3 * avg_load):\n                new_route1 = np.concatenate([route[:split_pos], [0]])\n                new_route2 = np.concatenate([[0], route[split_pos:]])\n                new_solution[route_idx] = new_route1\n                new_solution.insert(route_idx+1, new_route2)\n                break\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    def adaptive_weighted_score(solution, objectives):\n        total_dist, makespan = objectives\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        weight = 0.5 + 0.3 * (random.random() - 0.5)\n        return weight * norm_dist + (1 - weight) * norm_makespan\n\n    scored_solutions = [(adaptive_weighted_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.25 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Adaptive demand clustering\n    route_demands = [sum(demand[route[1:-1]]) for route in new_solution]\n    avg_demand = np.mean(route_demands) if route_demands else 0\n    demand_threshold = 0.3 * avg_demand\n\n    for i in range(len(new_solution)):\n        route_i = new_solution[i]\n        if len(route_i) > 3:\n            for j in range(i+1, len(new_solution)):\n                route_j = new_solution[j]\n                if abs(sum(demand[route_i[1:-1]]) - sum(demand[route_j[1:-1]])) <= demand_threshold:\n                    if sum(demand[route_i[1:-1]]) + sum(demand[route_j[1:-1]]) <= capacity:\n                        min_dist = float('inf')\n                        best_pair = (0, 0)\n                        for a in range(1, len(route_i)-1):\n                            for b in range(1, len(route_j)-1):\n                                dist = distance_matrix[route_i[a]][route_j[b]]\n                                if dist < min_dist:\n                                    min_dist = dist\n                                    best_pair = (a, b)\n                        merged_route = np.concatenate([route_i[:best_pair[0]+1], route_j[best_pair[1]:-1], route_i[-1:]])\n                        new_solution = [route for idx, route in enumerate(new_solution) if idx not in [i, j]] + [merged_route]\n                        break\n\n    # Spatial-aware route inversion\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5:\n            centroid = np.mean(coords[route[1:-1]], axis=0)\n            farthest_node = max(route[1:-1], key=lambda x: np.linalg.norm(coords[x] - centroid))\n            pos = np.where(route == farthest_node)[0][0]\n            if random.random() < 0.5:\n                if is_feasible(np.concatenate([route[:pos], route[pos:][::-1]])):\n                    new_route = np.concatenate([route[:pos], route[pos:][::-1]])\n                    new_solution[route_idx] = new_route\n\n    # Probabilistic route reshaping\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4 and random.random() < 0.4:\n            split_pos = random.randint(2, len(route)-3)\n            if sum(demand[route[1:split_pos]]) <= capacity and sum(demand[route[split_pos:-1]]) <= capacity:\n                new_route1 = np.concatenate([route[:split_pos], [0]])\n                new_route2 = np.concatenate([[0], route[split_pos:]])\n                new_solution[route_idx] = new_route1\n                new_solution.insert(route_idx+1, new_route2)\n                break\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm adaptively selects a promising solution from the archive using weighted scoring that balances distance and makespan objectives, then applies a hybrid local search combining demand-balanced route reshaping, probabilistic route inversion with capacity checks, and spatial-demand-aware route merging to generate high-quality neighbor solutions while preserving feasibility. It prioritizes solutions with better normalized objective values (with dynamic weights) and focuses on improving routes by splitting, inverting segments, and merging spatially close routes with similar demands.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    def adaptive_weighted_score(solution, objectives):\n        total_dist, makespan = objectives\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        weight = 0.5 + 0.2 * (random.random() - 0.5)  # Dynamic weight between 0.3 and 0.7\n        return weight * norm_dist + (1 - weight) * norm_makespan\n\n    scored_solutions = [(adaptive_weighted_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.3 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Demand-balanced route reshaping\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4:\n            total_route_demand = sum(demand[route[1:-1]])\n            target_demand = total_route_demand / (len(route)-2)\n            max_diff = 0\n            split_pos = -1\n            for i in range(1, len(route)-1):\n                segment_demand = sum(demand[route[1:i]])\n                diff = abs(segment_demand - target_demand * (i-1))\n                if diff > max_diff:\n                    max_diff = diff\n                    split_pos = i\n            if split_pos > 1 and split_pos < len(route)-2:\n                segment1 = route[:split_pos+1]\n                segment2 = np.concatenate([[0], route[split_pos+1:]])\n                if is_feasible(segment1) and is_feasible(segment2):\n                    new_solution[route_idx] = segment1\n                    new_solution.insert(route_idx+1, segment2)\n                    break\n\n    # Probabilistic route inversion with capacity check\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5 and random.random() < 0.4:\n            start = random.randint(1, len(route)-3)\n            end = random.randint(start+1, len(route)-2)\n            if is_feasible(np.concatenate([route[:start], route[start:end][::-1], route[end:]])):\n                new_route = np.concatenate([route[:start], route[start:end][::-1], route[end:]])\n                new_solution[route_idx] = new_route\n\n    # Spatial-demand-aware route merging\n    if len(new_solution) > 1 and random.random() < 0.5:\n        route_centroids = []\n        for route in new_solution:\n            if len(route) > 2:\n                route_coords = coords[route[1:-1]]\n                centroid = np.mean(route_coords, axis=0)\n                total_demand = sum(demand[route[1:-1]])\n                route_centroids.append((centroid, total_demand))\n        if len(route_centroids) > 1:\n            closest_pairs = []\n            for i in range(len(route_centroids)):\n                for j in range(i+1, len(route_centroids)):\n                    dist = np.linalg.norm(route_centroids[i][0] - route_centroids[j][0])\n                    demand_diff = abs(route_centroids[i][1] - route_centroids[j][1])\n                    closest_pairs.append((dist + 0.5*demand_diff, i, j))\n            if closest_pairs:\n                closest_pairs.sort()\n                for _, i, j in closest_pairs[:min(2, len(closest_pairs))]:\n                    route_i = new_solution[i]\n                    route_j = new_solution[j]\n                    if sum(demand[route_i[1:-1]]) + sum(demand[route_j[1:-1]]) <= capacity:\n                        min_dist = float('inf')\n                        best_i, best_j = 0, 0\n                        for a in range(1, len(route_i)-1):\n                            for b in range(1, len(route_j)-1):\n                                dist = distance_matrix[route_i[a]][route_j[b]]\n                                if dist < min_dist:\n                                    min_dist = dist\n                                    best_i, best_j = a, b\n                        merged_route = np.concatenate([route_i[:best_i+1], route_j[best_j:-1], route_i[-1:]])\n                        new_solution[i] = merged_route\n                        new_solution.pop(j)\n                        break\n\n    return new_solution\n\n\nNo. 6 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive (prioritizing non-dominated or slightly dominated solutions) and applies a hybrid local search combining route swapping, demand-aware 2-opt with customer relocations, and adaptive route merging/splitting, while ensuring feasibility through capacity checks. It balances distance and makespan objectives by probabilistically applying these operations and reverting infeasible changes. The approach emphasizes demand-aware transformations and adaptive route adjustments to improve solution quality.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    if len(archive) > 1:\n        # Sort solutions by Pareto dominance and select one\n        sorted_solutions = sorted(archive, key=lambda x: (x[1][0], x[1][1]))\n        # Select a solution that is not too dominated in either objective\n        candidate_indices = [i for i in range(len(sorted_solutions))\n                           if i < len(sorted_solutions)//2 or random.random() < 0.3]\n        selected_idx = random.choice(candidate_indices)\n        base_solution = archive[selected_idx][0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = [route.copy() for route in base_solution]\n\n    # Hybrid local search strategy\n    if random.random() < 0.5:  # Route swapping with demand-aware check\n        if len(new_solution) > 1:\n            i, j = random.sample(range(len(new_solution)), 2)\n            route_i = new_solution[i]\n            route_j = new_solution[j]\n\n            # Check if swapping customers between routes is feasible\n            if (np.sum(demand[route_i[1:-1]]) + np.sum(demand[route_j[1:-1]]) <= 2 * capacity):\n                # Try to swap a segment between routes\n                if len(route_i) > 3 and len(route_j) > 3:\n                    # Select a random segment from each route\n                    seg_i_start = random.randint(1, len(route_i)-3)\n                    seg_i_end = random.randint(seg_i_start, len(route_i)-2)\n                    seg_j_start = random.randint(1, len(route_j)-3)\n                    seg_j_end = random.randint(seg_j_start, len(route_j)-2)\n\n                    # Check capacity constraints\n                    if (np.sum(demand[route_i[seg_i_start:seg_i_end]]) + np.sum(demand[route_j[1:-1]]) <= capacity and\n                        np.sum(demand[route_j[seg_j_start:seg_j_end]]) + np.sum(demand[route_i[1:-1]]) <= capacity):\n                        # Perform the swap\n                        new_route_i = np.concatenate([\n                            route_i[:seg_i_start],\n                            route_j[seg_j_start:seg_j_end],\n                            route_i[seg_i_end:]\n                        ])\n                        new_route_j = np.concatenate([\n                            route_j[:seg_j_start],\n                            route_i[seg_i_start:seg_i_end],\n                            route_j[seg_j_end:]\n                        ])\n\n                        # Update solution\n                        new_solution[i] = new_route_i\n                        new_solution[j] = new_route_j\n    else:  # Intra-route 2-opt with demand-aware relocations\n        if len(new_solution) > 0:\n            route_idx = random.randint(0, len(new_solution)-1)\n            route = new_solution[route_idx].copy()\n\n            if len(route) > 4:\n                # Select two random edges to reverse\n                a = random.randint(1, len(route)-3)\n                b = random.randint(a+1, len(route)-2)\n\n                # Check if reversing this segment is feasible\n                if np.sum(demand[route[a:b]]) == np.sum(demand[route[a:b][::-1]]):\n                    # Perform 2-opt\n                    new_route = np.concatenate([\n                        route[:a],\n                        route[a:b][::-1],\n                        route[b:]\n                    ])\n                    new_solution[route_idx] = new_route\n\n                    # Additional demand-aware relocation\n                    if random.random() < 0.3:\n                        # Try to relocate a customer to a different position\n                        relocate_pos = random.randint(1, len(new_route)-2)\n                        if relocate_pos != a and relocate_pos != b-1:\n                            customer = new_route[relocate_pos]\n                            # Find a better position for this customer\n                            best_pos = relocate_pos\n                            best_dist = float('inf')\n                            for pos in range(1, len(new_route)-1):\n                                if pos != relocate_pos:\n                                    # Check capacity constraint\n                                    if (np.sum(demand[new_route[1:pos]]) + demand[customer] <= capacity and\n                                        np.sum(demand[new_route[pos:-1]]) + demand[customer] <= capacity):\n                                        # Calculate new distance\n                                        prev_node = new_route[pos-1] if pos > 1 else 0\n                                        next_node = new_route[pos] if pos < len(new_route)-1 else 0\n                                        new_dist = (distance_matrix[prev_node][customer] +\n                                                   distance_matrix[customer][next_node] -\n                                                   distance_matrix[prev_node][next_node])\n                                        if new_dist < best_dist:\n                                            best_dist = new_dist\n                                            best_pos = pos\n                            if best_pos != relocate_pos:\n                                # Perform relocation\n                                new_route = np.concatenate([\n                                    new_route[:relocate_pos],\n                                    new_route[relocate_pos+1:]\n                                ])\n                                new_route = np.insert(new_route, best_pos, customer)\n                                new_solution[route_idx] = new_route\n\n    # Adaptive route merging/splitting\n    if len(new_solution) > 1 and random.random() < 0.3:\n        # Try to merge two routes if possible\n        i, j = random.sample(range(len(new_solution)), 2)\n        route_i = new_solution[i]\n        route_j = new_solution[j]\n\n        if (np.sum(demand[route_i[1:-1]]) + np.sum(demand[route_j[1:-1]]) <= capacity):\n            # Check if merging is beneficial\n            dist_before = distance_matrix[route_i[-2]][0] + distance_matrix[route_j[-2]][0]\n            dist_after = distance_matrix[route_i[-2]][route_j[1]] + distance_matrix[route_j[-2]][0]\n\n            if dist_after < dist_before:\n                # Merge routes\n                merged_route = np.concatenate([\n                    route_i[:-1],\n                    route_j[1:]\n                ])\n                # Update solution\n                new_solution[i] = merged_route\n                new_solution.pop(j)\n\n    if random.random() < 0.2 and len(new_solution) < len(demand)-1:\n        # Try to split a route if beneficial\n        route_idx = random.randint(0, len(new_solution)-1)\n        route = new_solution[route_idx]\n\n        if len(route) > 5:\n            # Find a good split point\n            best_split = -1\n            best_diff = float('inf')\n\n            for split in range(2, len(route)-2):\n                # Check capacity constraints for both parts\n                if (np.sum(demand[route[1:split]]) <= capacity and\n                    np.sum(demand[route[split:-1]]) <= capacity):\n                    # Calculate difference in distances\n                    dist_before = (distance_matrix[route[split-1]][route[split]] +\n                                 distance_matrix[route[split]][route[split+1]])\n                    dist_after = (distance_matrix[route[split-1]][0] +\n                                 distance_matrix[0][route[split]] +\n                                 distance_matrix[route[split]][0] +\n                                 distance_matrix[0][route[split+1]])\n                    diff = dist_after - dist_before\n                    if diff < best_diff:\n                        best_diff = diff\n                        best_split = split\n\n            if best_split != -1:\n                # Perform split\n                route1 = np.concatenate([route[:best_split], [0]])\n                route2 = np.concatenate([[0], route[best_split:]])\n                new_solution[route_idx] = route1\n                new_solution.insert(route_idx+1, route2)\n\n    # Ensure all routes are feasible\n    for route in new_solution:\n        if np.sum(demand[route[1:-1]]) > capacity:\n            # If infeasible, revert to original route\n            for i in range(len(new_solution)):\n                if np.array_equal(new_solution[i], route):\n                    new_solution[i] = base_solution[i]\n                    break\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: *Demand-aware clustering, hybrid split-invert, adaptive Pareto weights, capacity-constrained reinsertion*\n- **Advice**: Combine *demand-aware clustering* with *hybrid split-invert* using *adaptive Pareto weights* to balance distance/makespan while ensuring capacity constraints.\n- **Avoid**: Static single-objective swaps; rigid Pareto selection without demand checks; over-reliance on randomness without guided selection.\n- **Explanation**: Hybrid operators dynamically balance objectives by integrating demand-aware reshaping with probabilistic route adjustments, preventing constraint violations and premature convergence.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 302,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    def adaptive_pareto_demand_score(solution, objectives):\n        total_dist, makespan = objectives\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n\n        # Calculate demand balance score for the solution\n        demand_balance = 0\n        for route in solution:\n            if len(route) > 2:\n                route_demand = sum(demand[route[1:-1]])\n                demand_balance += abs(route_demand - capacity/2) / (capacity/2)\n\n        # Dynamic weight based on solution characteristics\n        weight = 0.5 + 0.3 * (1 - makespan / (max_makespan + 1e-6))  # More weight to makespan for longer routes\n        return (weight * norm_dist + (1 - weight) * norm_makespan) * (1 + 0.2 * demand_balance)\n\n    # Select solution using adaptive Pareto-demand scoring\n    scored_solutions = [(adaptive_pareto_demand_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.3 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Hybrid demand-aware route reshaping\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4:\n            # Calculate demand balance score for the route\n            total_route_demand = sum(demand[route[1:-1]])\n            demand_balance = 0\n            for i in range(1, len(route)-1):\n                segment_demand = sum(demand[route[1:i]])\n                demand_balance = max(demand_balance, abs(segment_demand - 0.5 * total_route_demand))\n\n            # More aggressive reshaping for poorly balanced routes\n            reshaping_prob = 0.3 + 0.4 * (demand_balance / (total_route_demand + 1e-6))\n            if random.random() < reshaping_prob:\n                # Find the most demand-imbalanced split point\n                best_split = 1\n                best_score = -1\n                for i in range(1, len(route)-1):\n                    segment_demand = sum(demand[route[1:i]])\n                    score = abs(segment_demand - 0.5 * total_route_demand) / (total_route_demand + 1e-6)\n                    if score > best_score:\n                        best_score = score\n                        best_split = i\n\n                # Apply hybrid transformation: split + invert\n                segment1 = route[:best_split+1]\n                segment2 = np.concatenate([[0], route[best_split+1:]])\n\n                if is_feasible(segment1) and is_feasible(segment2):\n                    # Invert the second segment if it improves demand balance\n                    if random.random() < 0.5:\n                        segment2 = np.concatenate([segment2[:1], segment2[1:-1][::-1], segment2[-1:]])\n                        if not is_feasible(segment2):\n                            segment2 = np.concatenate([[0], route[best_split+1:]])\n\n                    new_solution[route_idx] = segment1\n                    new_solution.insert(route_idx+1, segment2)\n                    break\n\n    # Adaptive spatial-demand clustering with capacity check\n    if len(new_solution) > 1 and random.random() < 0.5:\n        route_stats = []\n        for route in new_solution:\n            if len(route) > 2:\n                centroid = np.mean(coords[route[1:-1]], axis=0)\n                total_demand = sum(demand[route[1:-1]])\n                route_stats.append((centroid, total_demand, route))\n\n        if len(route_stats) > 1:\n            # Find closest pairs with similar demand\n            closest_pairs = []\n            for i in range(len(route_stats)):\n                for j in range(i+1, len(route_stats)):\n                    dist = np.linalg.norm(route_stats[i][0] - route_stats[j][0])\n                    demand_diff = abs(route_stats[i][1] - route_stats[j][1])\n                    # Weight distance and demand difference based on Pareto weights\n                    weighted_score = 0.6 * dist + 0.4 * demand_diff\n                    closest_pairs.append((weighted_score, i, j))\n\n            closest_pairs.sort()\n            for _, i, j in closest_pairs[:min(2, len(closest_pairs))]:\n                route_i = route_stats[i][2]\n                route_j = route_stats[j][2]\n                if sum(demand[route_i[1:-1]]) + sum(demand[route_j[1:-1]]) <= capacity:\n                    # Find best merge points\n                    min_dist = float('inf')\n                    best_i, best_j = 0, 0\n                    for a in range(1, len(route_i)-1):\n                        for b in range(1, len(route_j)-1):\n                            dist = distance_matrix[route_i[a]][route_j[b]]\n                            if dist < min_dist:\n                                min_dist = dist\n                                best_i, best_j = a, b\n\n                    merged_route = np.concatenate([route_i[:best_i+1], route_j[best_j:-1], route_i[-1:]])\n                    new_solution = [r for r in new_solution if not np.array_equal(r, route_i) and not np.array_equal(r, route_j)]\n                    new_solution.append(merged_route)\n                    break\n\n    # Demand-aware route inversion with spatial diversity\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4:\n            centroid = np.mean(coords[route[1:-1]], axis=0)\n            farthest_node = max(route[1:-1], key=lambda x: np.linalg.norm(coords[x] - centroid))\n            pos = np.where(route == farthest_node)[0][0]\n\n            # More likely to invert for routes with high demand imbalance\n            total_demand = sum(demand[route[1:-1]])\n            demand_diff = abs(sum(demand[route[1:pos]]) - 0.5 * total_demand)\n            inversion_prob = 0.4 + 0.3 * (demand_diff / (total_demand + 1e-6))\n\n            if random.random() < inversion_prob:\n                inverted_route = np.concatenate([route[:pos], route[pos:][::-1]])\n                if is_feasible(inverted_route):\n                    new_solution[route_idx] = inverted_route\n\n    return new_solution\n\n",
        "score": [
            -0.7731290349340081,
            1.3690739274024963
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    def adaptive_pareto_demand_score(solution, objectives):\n        total_dist, makespan = objectives\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n\n        # Calculate demand balance score for the solution\n        demand_balance = 0\n        for route in solution:\n            if len(route) > 2:\n                route_demand = sum(demand[route[1:-1]])\n                demand_balance += abs(route_demand - capacity/2) / (capacity/2)\n\n        # Dynamic weight based on solution characteristics\n        weight = 0.5 + 0.3 * (1 - makespan / (max_makespan + 1e-6))  # More weight to makespan for longer routes\n        return (weight * norm_dist + (1 - weight) * norm_makespan) * (1 + 0.2 * demand_balance)\n\n    # Select solution using adaptive Pareto-demand scoring\n    scored_solutions = [(adaptive_pareto_demand_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.3 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Hybrid demand-aware route reshaping\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4:\n            # Calculate demand balance score for the route\n            total_route_demand = sum(demand[route[1:-1]])\n            demand_balance = 0\n            for i in range(1, len(route)-1):\n                segment_demand = sum(demand[route[1:i]])\n                demand_balance = max(demand_balance, abs(segment_demand - 0.5 * total_route_demand))\n\n            # More aggressive reshaping for poorly balanced routes\n            reshaping_prob = 0.3 + 0.4 * (demand_balance / (total_route_demand + 1e-6))\n            if random.random() < reshaping_prob:\n                # Find the most demand-imbalanced split point\n                best_split = 1\n                best_score = -1\n                for i in range(1, len(route)-1):\n                    segment_demand = sum(demand[route[1:i]])\n                    score = abs(segment_demand - 0.5 * total_route_demand) / (total_route_demand + 1e-6)\n                    if score > best_score:\n                        best_score = score\n                        best_split = i\n\n                # Apply hybrid transformation: split + invert\n                segment1 = route[:best_split+1]\n                segment2 = np.concatenate([[0], route[best_split+1:]])\n\n                if is_feasible(segment1) and is_feasible(segment2):\n                    # Invert the second segment if it improves demand balance\n                    if random.random() < 0.5:\n                        segment2 = np.concatenate([segment2[:1], segment2[1:-1][::-1], segment2[-1:]])\n                        if not is_feasible(segment2):\n                            segment2 = np.concatenate([[0], route[best_split+1:]])\n\n                    new_solution[route_idx] = segment1\n                    new_solution.insert(route_idx+1, segment2)\n                    break\n\n    # Adaptive spatial-demand clustering with capacity check\n    if len(new_solution) > 1 and random.random() < 0.5:\n        route_stats = []\n        for route in new_solution:\n            if len(route) > 2:\n                centroid = np.mean(coords[route[1:-1]], axis=0)\n                total_demand = sum(demand[route[1:-1]])\n                route_stats.append((centroid, total_demand, route))\n\n        if len(route_stats) > 1:\n            # Find closest pairs with similar demand\n            closest_pairs = []\n            for i in range(len(route_stats)):\n                for j in range(i+1, len(route_stats)):\n                    dist = np.linalg.norm(route_stats[i][0] - route_stats[j][0])\n                    demand_diff = abs(route_stats[i][1] - route_stats[j][1])\n                    # Weight distance and demand difference based on Pareto weights\n                    weighted_score = 0.6 * dist + 0.4 * demand_diff\n                    closest_pairs.append((weighted_score, i, j))\n\n            closest_pairs.sort()\n            for _, i, j in closest_pairs[:min(2, len(closest_pairs))]:\n                route_i = route_stats[i][2]\n                route_j = route_stats[j][2]\n                if sum(demand[route_i[1:-1]]) + sum(demand[route_j[1:-1]]) <= capacity:\n                    # Find best merge points\n                    min_dist = float('inf')\n                    best_i, best_j = 0, 0\n                    for a in range(1, len(route_i)-1):\n                        for b in range(1, len(route_j)-1):\n                            dist = distance_matrix[route_i[a]][route_j[b]]\n                            if dist < min_dist:\n                                min_dist = dist\n                                best_i, best_j = a, b\n\n                    merged_route = np.concatenate([route_i[:best_i+1], route_j[best_j:-1], route_i[-1:]])\n                    new_solution = [r for r in new_solution if not np.array_equal(r, route_i) and not np.array_equal(r, route_j)]\n                    new_solution.append(merged_route)\n                    break\n\n    # Demand-aware route inversion with spatial diversity\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4:\n            centroid = np.mean(coords[route[1:-1]], axis=0)\n            farthest_node = max(route[1:-1], key=lambda x: np.linalg.norm(coords[x] - centroid))\n            pos = np.where(route == farthest_node)[0][0]\n\n            # More likely to invert for routes with high demand imbalance\n            total_demand = sum(demand[route[1:-1]])\n            demand_diff = abs(sum(demand[route[1:pos]]) - 0.5 * total_demand)\n            inversion_prob = 0.4 + 0.3 * (demand_diff / (total_demand + 1e-6))\n\n            if random.random() < inversion_prob:\n                inverted_route = np.concatenate([route[:pos], route[pos:][::-1]])\n                if is_feasible(inverted_route):\n                    new_solution[route_idx] = inverted_route\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Capacitated Vehicle Routing Problem (Bi-CVRP), where a single depot and multiple customers are located in 2D space. Each customer has a positive demand, and all vehicles in the fleet have identical capacity limits. The objective is to construct a set of routes, each starting and ending at the depot, such that all customers are served, vehicle capacities are not exceeded on any route, and two conflicting objectives are minimized: (1) the total travel distance across all routes, and (2) the makespan, defined as the length of the longest individual route. Each solution in the archive is represented as a list of NumPy arrays, where each array denotes a single route (starting and ending with depot index 0), and is paired with a tuple of two objective values (total_distance, makespan). Your task is to implement a function named 'select_neighbor' that selects one promising solution from the archive and apply a novel or hybrid local search operator to generate a feasible neighbor solution from it. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself. Avoid standard methods like pure 2-opt; instead, invent or combine transformations, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. Ensure that the returned neighbor solution remains feasible under the vehicle capacity constraint. The function should return the new neighbor solution.\n        I have 6 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive Pareto scoring with a hybrid local search strategy that prioritizes demand-balanced route merging while probabilistically applying route inversion to improve both distance and makespan objectives, all while maintaining feasibility through capacity-aware operations. It first selects promising solutions based on normalized objective trade-offs, then applies dynamic route reshaping (inversion and merging) to balance objectives, with special attention to spatially close and demand-complementary routes. The algorithm emphasizes capacity constraints through rigorous checks during route modifications and splitting.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    def adaptive_pareto_score(solution, objectives):\n        total_dist, makespan = objectives\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        weight = 0.5 + 0.3 * (random.random() - 0.5)\n        return weight * norm_dist + (1 - weight) * norm_makespan\n\n    scored_solutions = [(adaptive_pareto_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.4 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Dynamic Pareto-aware route inversion\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5 and random.random() < 0.5:\n            start = random.randint(1, len(route)-3)\n            end = random.randint(start+1, len(route)-2)\n            inverted_segment = route[start:end][::-1]\n            if is_feasible(np.concatenate([route[:start], inverted_segment, route[end:]])):\n                new_route = np.concatenate([route[:start], inverted_segment, route[end:]])\n                new_solution[route_idx] = new_route\n\n    # Adaptive demand-centric clustering\n    if len(new_solution) > 1 and random.random() < 0.6:\n        route_demands = [sum(demand[route[1:-1]]) for route in new_solution]\n        route_centroids = []\n        for route in new_solution:\n            if len(route) > 2:\n                route_coords = coords[route[1:-1]]\n                centroid = np.mean(route_coords, axis=0)\n                route_centroids.append(centroid)\n\n        if len(route_centroids) > 1:\n            closest_pairs = []\n            for i in range(len(route_centroids)):\n                for j in range(i+1, len(route_centroids)):\n                    dist = np.linalg.norm(route_centroids[i] - route_centroids[j])\n                    demand_diff = abs(route_demands[i] - route_demands[j])\n                    closest_pairs.append((dist + 0.3*demand_diff, i, j))\n\n            if closest_pairs:\n                closest_pairs.sort()\n                for _, i, j in closest_pairs[:min(2, len(closest_pairs))]:\n                    route_i = new_solution[i]\n                    route_j = new_solution[j]\n                    if sum(demand[route_i[1:-1]]) + sum(demand[route_j[1:-1]]) <= capacity:\n                        min_dist = float('inf')\n                        best_i, best_j = 0, 0\n                        for a in range(1, len(route_i)-1):\n                            for b in range(1, len(route_j)-1):\n                                dist = distance_matrix[route_i[a]][route_j[b]]\n                                if dist < min_dist:\n                                    min_dist = dist\n                                    best_i, best_j = a, b\n                        merged_route = np.concatenate([route_i[:best_i+1], route_j[best_j:-1], route_i[-1:]])\n                        new_solution[i] = merged_route\n                        new_solution.pop(j)\n                        break\n\n    # Capacity-aware route splitting\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4 and sum(demand[route[1:-1]]) > 0.8 * capacity:\n            split_pos = random.randint(2, len(route)-3)\n            segment1 = route[:split_pos+1]\n            segment2 = np.concatenate([[0], route[split_pos+1:]])\n            if is_feasible(segment1) and is_feasible(segment2):\n                new_solution[route_idx] = segment1\n                new_solution.insert(route_idx+1, segment2)\n                break\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm implements a novel hybrid local search strategy that combines adaptive spatial-demand clustering with probabilistic route inversion and segment swapping, while dynamically balancing distance and makespan objectives through an oscillating weighting scheme and ensuring feasibility through capacity-aware route modifications and splitting. It prioritizes solutions with better normalized objective scores, applies spatial clustering to merge similar routes, probabilistically inverts route segments, swaps segments between routes while maintaining capacity, and splits overloaded routes for better demand balance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    def dynamic_weighting(solution, objectives):\n        total_dist, makespan = objectives\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        weight = 0.3 + 0.3 * (np.sin(len(archive) / 10) + 1)  # Oscillating weight between 0.3 and 0.6\n        return weight * norm_dist + (1 - weight) * norm_makespan\n\n    scored_solutions = [(dynamic_weighting(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.4 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Adaptive spatial-demand clustering\n    if len(new_solution) > 1 and random.random() < 0.5:\n        route_data = []\n        for route in new_solution:\n            if len(route) > 2:\n                route_coords = coords[route[1:-1]]\n                centroid = np.mean(route_coords, axis=0)\n                total_demand = sum(demand[route[1:-1]])\n                route_data.append((centroid, total_demand, route))\n\n        if len(route_data) > 1:\n            clusters = []\n            while len(route_data) > 0:\n                base = route_data.pop(0)\n                cluster = [base]\n                i = 0\n                while i < len(route_data):\n                    centroid, demand_val, _ = route_data[i]\n                    dist = np.linalg.norm(base[0] - centroid)\n                    demand_diff = abs(base[1] - demand_val)\n                    if dist < 1.2 * np.mean(distance_matrix) and demand_diff < 0.4 * capacity:\n                        cluster.append(route_data.pop(i))\n                    else:\n                        i += 1\n                clusters.append(cluster)\n\n            for cluster in clusters:\n                if len(cluster) > 1:\n                    for i in range(len(cluster)-1):\n                        for j in range(i+1, len(cluster)):\n                            route_i = cluster[i][2]\n                            route_j = cluster[j][2]\n                            if sum(demand[route_i[1:-1]]) + sum(demand[route_j[1:-1]]) <= capacity:\n                                min_dist = float('inf')\n                                best_i, best_j = 0, 0\n                                for a in range(1, len(route_i)-1):\n                                    for b in range(1, len(route_j)-1):\n                                        dist = distance_matrix[route_i[a]][route_j[b]]\n                                        if dist < min_dist:\n                                            min_dist = dist\n                                            best_i, best_j = a, b\n                                merged_route = np.concatenate([route_i[:best_i+1], route_j[best_j:-1], route_i[-1:]])\n                                new_solution = [r for r in new_solution if not np.array_equal(r, route_i) and not np.array_equal(r, route_j)]\n                                new_solution.append(merged_route)\n                                break\n\n    # Probabilistic route inversion with capacity check\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5 and random.random() < 0.4:\n            start = random.randint(1, len(route)-3)\n            end = random.randint(start+1, len(route)-2)\n            inverted_segment = route[start:end][::-1]\n            if is_feasible(np.concatenate([route[:start], inverted_segment, route[end:]])):\n                new_route = np.concatenate([route[:start], inverted_segment, route[end:]])\n                new_solution[route_idx] = new_route\n\n    # Segment swapping with demand balance consideration\n    if len(new_solution) > 1 and random.random() < 0.6:\n        i, j = random.sample(range(len(new_solution)), 2)\n        route_i = new_solution[i]\n        route_j = new_solution[j]\n\n        if len(route_i) > 3 and len(route_j) > 3:\n            seg_i_start = random.randint(1, len(route_i)-3)\n            seg_i_end = random.randint(seg_i_start, len(route_i)-2)\n            seg_j_start = random.randint(1, len(route_j)-3)\n            seg_j_end = random.randint(seg_j_start, len(route_j)-2)\n\n            demand_i = sum(demand[route_i[seg_i_start:seg_i_end]])\n            demand_j = sum(demand[route_j[seg_j_start:seg_j_end]])\n\n            if (sum(demand[route_i[1:-1]]) - demand_i + demand_j <= capacity and\n                sum(demand[route_j[1:-1]]) - demand_j + demand_i <= capacity):\n\n                new_route_i = np.concatenate([\n                    route_i[:seg_i_start],\n                    route_j[seg_j_start:seg_j_end],\n                    route_i[seg_i_end:]\n                ])\n                new_route_j = np.concatenate([\n                    route_j[:seg_j_start],\n                    route_i[seg_i_start:seg_i_end],\n                    route_j[seg_j_end:]\n                ])\n\n                if is_feasible(new_route_i) and is_feasible(new_route_j):\n                    new_solution[i] = new_route_i\n                    new_solution[j] = new_route_j\n\n    # Capacity-aware route splitting with demand balancing\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4 and sum(demand[route[1:-1]]) > 0.7 * capacity:\n            total_demand = sum(demand[route[1:-1]])\n            best_split = None\n            min_diff = float('inf')\n            for i in range(2, len(route)-2):\n                segment_demand = sum(demand[route[1:i]])\n                remaining_demand = total_demand - segment_demand\n                current_diff = abs(segment_demand - remaining_demand)\n                if current_diff < min_diff:\n                    min_diff = current_diff\n                    best_split = i\n            if best_split and min_diff < capacity * 0.3:\n                segment1 = route[:best_split+1]\n                segment2 = np.concatenate([[0], route[best_split+1:]])\n                if is_feasible(segment1) and is_feasible(segment2):\n                    new_solution[route_idx] = segment1\n                    new_solution.insert(route_idx+1, segment2)\n                    break\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm implements a hybrid local search strategy that combines adaptive demand-aware route splitting, spatial-proximity guided demand-balanced reinsertion, and dynamic capacity-balanced route reshaping, prioritizing solutions with balanced distance and makespan objectives while ensuring capacity feasibility. It intelligently selects promising solutions from the archive using an adaptive weighted scoring mechanism, then applies probabilistic route transformations to improve both objectives. The method dynamically balances exploration and exploitation through weighted selection and conditional probabilistic operations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    def adaptive_weighted_score(sol, obj):\n        total_dist, makespan = obj\n        max_dist = max(o[0] for _, o in archive)\n        max_makespan = max(o[1] for _, o in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        weight = 0.5 + 0.3 * (random.random() - 0.5)\n        return (1 - weight) * norm_dist + weight * norm_makespan\n\n    scored_solutions = [(adaptive_weighted_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.3 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Demand-aware route splitting with probabilistic inversion\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4 and random.random() < 0.6:\n            customers = route[1:-1]\n            demands = demand[customers]\n            supply = np.cumsum(demands)\n            target_supply = supply[-1] / 2\n\n            split_pos = np.argmin(np.abs(supply - target_supply)) + 1\n            segment1 = route[:split_pos+1]\n            segment2 = np.concatenate([[0], route[split_pos+1:]])\n\n            if is_feasible(segment1) and is_feasible(segment2):\n                if random.random() < 0.4:\n                    segment2 = np.concatenate([[0], segment2[-2:0:-1], segment2[-1:]])\n                new_solution[route_idx] = segment1\n                new_solution.insert(route_idx+1, segment2)\n                break\n\n    # Spatial-proximity guided demand-balanced reinsertion\n    if len(new_solution) > 1 and random.random() < 0.7:\n        source_idx = random.randint(0, len(new_solution)-1)\n        target_idx = random.randint(0, len(new_solution)-1)\n        if source_idx != target_idx:\n            source_route = new_solution[source_idx]\n            target_route = new_solution[target_idx]\n\n            if len(source_route) > 3:\n                customer_pos = random.randint(1, len(source_route)-2)\n                customer = source_route[customer_pos]\n\n                if sum(demand[target_route[1:-1]]) + demand[customer] <= capacity:\n                    new_source = np.concatenate([source_route[:customer_pos], source_route[customer_pos+1:]])\n                    best_pos = 1\n                    min_increase = float('inf')\n\n                    for pos in range(1, len(target_route)):\n                        new_target = np.concatenate([target_route[:pos], [customer], target_route[pos:]])\n                        dist_increase = (distance_matrix[target_route[pos-1]][customer] +\n                                        distance_matrix[customer][target_route[pos]] -\n                                        distance_matrix[target_route[pos-1]][target_route[pos]])\n\n                        if dist_increase < min_increase:\n                            min_increase = dist_increase\n                            best_pos = pos\n\n                    new_target = np.concatenate([target_route[:best_pos], [customer], target_route[best_pos:]])\n\n                    if is_feasible(new_source) and is_feasible(new_target):\n                        new_solution[source_idx] = new_source\n                        new_solution[target_idx] = new_target\n\n    # Dynamic capacity-balanced route reshaping\n    if len(new_solution) > 1 and random.random() < 0.5:\n        route_stats = []\n        for route in new_solution:\n            if len(route) > 2:\n                total_demand = sum(demand[route[1:-1]])\n                route_stats.append((total_demand, route))\n\n        if len(route_stats) > 1:\n            route_stats.sort(key=lambda x: x[0])\n            for i in range(len(route_stats)-1):\n                j = len(route_stats)-1-i\n                if i >= j:\n                    break\n\n                route_i = route_stats[i][1]\n                route_j = route_stats[j][1]\n\n                if sum(demand[route_i[1:-1]]) + sum(demand[route_j[1:-1]]) <= capacity:\n                    merged_route = np.concatenate([route_i[:-1], route_j[1:]])\n\n                    if is_feasible(merged_route):\n                        new_solution = [r for r in new_solution if not np.array_equal(r, route_i) and not np.array_equal(r, route_j)]\n                        new_solution.append(merged_route)\n                        break\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive route segmentation with demand-aware reinsertion, prioritizing spatial proximity and demand balance to generate high-quality neighbor solutions while maintaining capacity constraints. It first selects promising solutions from the archive using an adaptive weighted scoring that balances distance and makespan objectives, then dynamically splits routes based on spatial centroids and demand distribution, followed by capacity-constrained reinsertion of segments into spatially nearby routes to improve both objectives. The method emphasizes spatial-demand-aware splitting and probabilistic reinsertion to explore the solution space effectively.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    def adaptive_weighted_score(sol, obj):\n        total_dist, makespan = obj\n        max_dist = max(o[0] for _, o in archive)\n        max_makespan = max(o[1] for _, o in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        weight = 0.5 + 0.3 * (random.random() - 0.5)\n        return weight * norm_dist + (1 - weight) * norm_makespan\n\n    scored_solutions = [(adaptive_weighted_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.3 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Spatial-demand-aware route segmentation\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 3 and random.random() < 0.6:\n            customers = route[1:-1]\n            route_coords = coords[customers]\n            centroid = np.mean(route_coords, axis=0)\n            dists = np.linalg.norm(route_coords - centroid, axis=1)\n            demands = demand[customers]\n\n            # Split based on spatial proximity and demand balance\n            split_pos = np.argmax(dists) + 1 if random.random() < 0.7 else np.argmin(demands) + 1\n            segment1 = route[:split_pos+1]\n            segment2 = np.concatenate([[0], route[split_pos+1:]])\n\n            if is_feasible(segment1) and is_feasible(segment2):\n                new_solution[route_idx] = segment1\n                new_solution.insert(route_idx+1, segment2)\n                break\n\n    # Capacity-constrained reinsertion with spatial proximity\n    if len(new_solution) > 1 and random.random() < 0.5:\n        # Select a random segment to reinsert\n        source_route_idx = random.randint(0, len(new_solution)-1)\n        source_route = new_solution[source_route_idx]\n        if len(source_route) > 3:\n            start = random.randint(1, len(source_route)-3)\n            end = random.randint(start+1, len(source_route)-2)\n            segment = source_route[start:end+1]\n            segment_demand = sum(demand[segment[1:-1]])\n\n            # Find target route with spatial proximity\n            source_centroid = np.mean(coords[source_route[1:-1]], axis=0)\n            closest_route_idx = -1\n            min_dist = float('inf')\n            for i, route in enumerate(new_solution):\n                if i != source_route_idx and len(route) > 1:\n                    route_centroid = np.mean(coords[route[1:-1]], axis=0)\n                    dist = np.linalg.norm(source_centroid - route_centroid)\n                    if dist < min_dist:\n                        min_dist = dist\n                        closest_route_idx = i\n\n            if closest_route_idx != -1 and sum(demand[new_solution[closest_route_idx][1:-1]]) + segment_demand <= capacity:\n                # Find best insertion point\n                best_pos = 1\n                best_cost = float('inf')\n                target_route = new_solution[closest_route_idx]\n                for i in range(1, len(target_route)):\n                    cost = distance_matrix[target_route[i-1]][segment[1]] + distance_matrix[segment[-2]][target_route[i]]\n                    if cost < best_cost:\n                        best_cost = cost\n                        best_pos = i\n\n                # Perform reinsertion\n                new_route = np.concatenate([target_route[:best_pos], segment, target_route[best_pos:]])\n                new_solution[closest_route_idx] = new_route\n                new_solution[source_route_idx] = np.concatenate([source_route[:start], source_route[end+1:]])\n\n                # Remove empty routes\n                new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm combines centroid-based route clustering with adaptive demand-sensitive operations, prioritizing spatial proximity (40%) and demand balance (60%) for merging, while using demand imbalance (60%) and capacity utilization (40%) to guide splitting and inversion. It dynamically adjusts routes by merging spatially close routes with complementary demands, splitting imbalanced routes, and inverting routes with high demand imbalance, all while maintaining feasibility. The selection process balances normalized distance (50%), makespan (40%), and spatial variance (30%) to identify promising solutions for further optimization.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    def multi_objective_selection(solutions, objectives):\n        norm_dist = (objectives[0] - min(obj[0] for _, obj in archive)) / (max(obj[0] for _, obj in archive) - min(obj[0] for _, obj in archive) + 1e-6)\n        norm_makespan = (objectives[1] - min(obj[1] for _, obj in archive)) / (max(obj[1] for _, obj in archive) - min(obj[1] for _, obj in archive) + 1e-6)\n        spatial_variance = np.std([np.mean(coords[route[1:-1]], axis=0) for route in solutions])\n        return 0.5 * norm_dist + 0.4 * norm_makespan + 0.3 * (1 - spatial_variance / np.max(np.std(coords, axis=0)))\n\n    scored_solutions = [(multi_objective_selection(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    selection_pool = scored_solutions[:max(1, int(0.3 * len(scored_solutions)))]\n    selected_solution = random.choice([sol for _, sol in selection_pool])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    # Spatial-aware route clustering with demand constraints\n    route_centroids = []\n    for route in new_solution:\n        if len(route) > 2:\n            centroid = np.mean(coords[route[1:-1]], axis=0)\n            route_centroids.append((centroid, route))\n\n    for i in range(len(route_centroids)):\n        for j in range(i+1, len(route_centroids)):\n            centroid_i, route_i = route_centroids[i]\n            centroid_j, route_j = route_centroids[j]\n            spatial_dist = np.linalg.norm(centroid_i - centroid_j)\n            demand_i = sum(demand[route_i[1:-1]])\n            demand_j = sum(demand[route_j[1:-1]])\n\n            if demand_i + demand_j <= capacity:\n                merge_prob = 0.4 * (1 - spatial_dist/np.max(distance_matrix)) + 0.6 * (1 - abs(demand_i - demand_j)/max(demand_i, demand_j))\n                if random.random() < merge_prob:\n                    # Find best insertion points\n                    min_dist = float('inf')\n                    best_pair = (0, 0)\n                    for a in range(1, len(route_i)-1):\n                        for b in range(1, len(route_j)-1):\n                            dist = distance_matrix[route_i[a]][route_j[b]] * (1 + 0.2 * abs(demand[route_i[a]] - demand[route_j[b]])/capacity)\n                            if dist < min_dist:\n                                min_dist = dist\n                                best_pair = (a, b)\n                    merged_route = np.concatenate([route_i[:best_pair[0]+1], route_j[best_pair[1]:-1], route_i[-1:]])\n                    new_solution = [route for idx, route in enumerate(new_solution) if idx not in [i, j]] + [merged_route]\n                    break\n\n    # Adaptive demand-sensitive splitting\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5:\n            total_demand = sum(demand[route[1:-1]])\n            split_candidates = []\n            for pos in range(2, len(route)-2):\n                left_demand = sum(demand[route[1:pos]])\n                right_demand = total_demand - left_demand\n                demand_balance = 1 - abs(left_demand - right_demand)/total_demand\n                left_centroid = np.mean(coords[route[1:pos]], axis=0)\n                right_centroid = np.mean(coords[route[pos:-1]], axis=0)\n                spatial_separation = np.linalg.norm(left_centroid - right_centroid)\n                split_score = 0.7 * demand_balance + 0.3 * (spatial_separation / np.max(distance_matrix))\n                split_candidates.append((split_score, pos))\n\n            if split_candidates:\n                split_candidates.sort(reverse=True, key=lambda x: x[0])\n                best_pos = split_candidates[0][1]\n                if sum(demand[route[1:best_pos]]) <= capacity and sum(demand[route[best_pos:-1]]) <= capacity:\n                    new_route1 = np.concatenate([route[:best_pos], [0]])\n                    new_route2 = np.concatenate([[0], route[best_pos:]])\n                    new_solution[route_idx] = new_route1\n                    new_solution.insert(route_idx+1, new_route2)\n                    break\n\n    # Demand-balanced route inversion\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4:\n            demand_profile = np.cumsum(demand[route[1:-1]])\n            total_demand = demand_profile[-1]\n            imbalance = max(demand_profile) - min(demand_profile)\n            inversion_prob = 0.6 * (imbalance/total_demand) + 0.4 * (1 - sum(demand[route[1:-1]])/capacity)\n            if inversion_prob > 0.8 and random.random() < 0.6:\n                farthest_node = max(route[1:-1], key=lambda x: np.linalg.norm(coords[x] - np.mean(coords[route[1:-1]], axis=0)))\n                pos = np.where(route == farthest_node)[0][0]\n                inverted_route = np.concatenate([route[:pos], route[pos:][::-1]])\n                if sum(demand[inverted_route[1:-1]]) <= capacity:\n                    new_solution[route_idx] = inverted_route\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n\nNo. 6 algorithm's description and the corresponding code are:\nThe algorithm combines demand-aware route partitioning, spatial-demand correlation analysis, adaptive route fusion, and probabilistic route rebalancing to generate high-quality neighbors by prioritizing under-explored regions of the Pareto front, focusing on demand distribution and spatial proximity while maintaining feasibility through dynamic capacity checks. It intelligently selects solutions with lower Pareto front coverage scores and applies probabilistic transformations to balance route lengths and demands, with higher emphasis on demand-aware partitioning and spatial correlation analysis.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    def pareto_distance_score(solution, objectives):\n        total_dist, makespan = objectives\n        min_dist = min(obj[0] for _, obj in archive)\n        min_makespan = min(obj[1] for _, obj in archive)\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n\n        norm_dist = (total_dist - min_dist) / (max_dist - min_dist + 1e-6)\n        norm_makespan = (makespan - min_makespan) / (max_makespan - min_makespan + 1e-6)\n\n        crowding_dist = np.sqrt(norm_dist**2 + norm_makespan**2)\n        return crowding_dist\n\n    scored_solutions = [(pareto_distance_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    bottom_k = max(1, int(0.3 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[-bottom_k:]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Demand-aware route partitioning\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5:\n            demands = demand[route[1:-1]]\n            sorted_indices = np.argsort(demands)\n            partition_size = max(1, len(sorted_indices) // 2)\n            for i in range(0, len(sorted_indices), partition_size):\n                partition = sorted_indices[i:i+partition_size]\n                if len(partition) > 1 and random.random() < 0.5:\n                    segment = route[1:-1][partition]\n                    if sum(demands[partition]) <= capacity:\n                        new_route = np.concatenate([[0], segment, [0]])\n                        if is_feasible(new_route):\n                            new_solution[route_idx] = new_route\n                            break\n\n    # Spatial-demand correlation analysis\n    if len(new_solution) > 1 and random.random() < 0.6:\n        route_stats = []\n        for route in new_solution:\n            if len(route) > 2:\n                route_coords = coords[route[1:-1]]\n                centroid = np.mean(route_coords, axis=0)\n                demand_density = sum(demand[route[1:-1]]) / len(route_coords)\n                route_stats.append((centroid, demand_density))\n\n        if len(route_stats) > 1:\n            correlation_pairs = []\n            for i in range(len(route_stats)):\n                for j in range(i+1, len(route_stats)):\n                    spatial_dist = np.linalg.norm(route_stats[i][0] - route_stats[j][0])\n                    demand_diff = abs(route_stats[i][1] - route_stats[j][1])\n                    correlation_pairs.append((spatial_dist * (1 + demand_diff), i, j))\n\n            if correlation_pairs:\n                correlation_pairs.sort()\n                for _, i, j in correlation_pairs[:min(3, len(correlation_pairs))]:\n                    route_i = new_solution[i]\n                    route_j = new_solution[j]\n                    if sum(demand[route_i[1:-1]]) + sum(demand[route_j[1:-1]]) <= capacity:\n                        merged_route = np.concatenate([route_i[:-1], route_j[1:]])\n                        if is_feasible(merged_route):\n                            new_solution[i] = merged_route\n                            new_solution.pop(j)\n                            break\n\n    # Adaptive route fusion\n    if len(new_solution) > 1 and random.random() < 0.4:\n        route_lengths = [len(route) for route in new_solution]\n        long_routes = [i for i, l in enumerate(route_lengths) if l > 4]\n        if long_routes:\n            route_idx = random.choice(long_routes)\n            route = new_solution[route_idx]\n            best_split = -1\n            best_improvement = 0\n\n            for split in range(3, len(route)-3):\n                part1 = route[:split+1]\n                part2 = np.concatenate([[0], route[split+1:]])\n                if is_feasible(part1) and is_feasible(part2):\n                    current_length = distance_matrix[route[:-1], route[1:]].sum()\n                    new_length = (distance_matrix[part1[:-1], part1[1:]].sum() +\n                                 distance_matrix[part2[:-1], part2[1:]].sum())\n                    improvement = current_length - new_length\n                    if improvement > best_improvement:\n                        best_improvement = improvement\n                        best_split = split\n\n            if best_split != -1:\n                part1 = route[:best_split+1]\n                part2 = np.concatenate([[0], route[best_split+1:]])\n                new_solution[route_idx] = part1\n                new_solution.insert(route_idx+1, part2)\n\n    # Probabilistic route rebalancing\n    if random.random() < 0.5 and len(new_solution) < len(demand)-1:\n        route_idx = random.randint(0, len(new_solution)-1)\n        route = new_solution[route_idx]\n\n        if len(route) > 4:\n            current_demand = sum(demand[route[1:-1]])\n            target_demand = capacity * 0.7\n            if current_demand > target_demand:\n                excess = current_demand - target_demand\n                candidates = [i for i in range(1, len(route)-1) if demand[route[i]] <= excess]\n\n                if candidates:\n                    node_idx = random.choice(candidates)\n                    new_route = np.concatenate([route[:node_idx+1], [0], route[node_idx+1:]])\n                    if is_feasible(new_route[:-1]) and is_feasible(np.concatenate([[0], new_route[node_idx+1:]])):\n                        new_solution[route_idx] = new_route[:-1]\n                        new_solution.insert(route_idx+1, np.concatenate([[0], new_route[node_idx+1:]]))\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: - **Keywords**: *Demand-aware clustering, hybrid split-invert, adaptive Pareto weights, capacity-constrained reinsertion*\n- **Advice**: Combine *demand-aware clustering* with *hybrid split-invert* using *adaptive Pareto weights* to balance distance/makespan while ensuring capacity constraints.\n- **Avoid**: Static single-objective swaps; rigid Pareto selection without demand checks; over-reliance on randomness without guided selection.\n- **Explanation**: Hybrid operators dynamically balance objectives by integrating demand-aware reshaping with probabilistic route adjustments, preventing constraint violations and premature convergence.\n\n*(This ensures actionable advice, clear keywords, and explanations tied to the analysis, while avoiding ineffectiveness.)*\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 303,
        "algorithm": "The algorithm combines adaptive Pareto-weighted solution selection with hybrid local search operators, including demand-aware clustering, spatial-demand inversion, capacity-constrained reinsertion, and demand-sensitive splitting, prioritizing balanced demand distribution and spatial proximity while dynamically adjusting exploration based on solution quality and problem characteristics. Key variables like demand balance and spatial variance guide operator selection, with probabilistic application to maintain solution diversity, while feasibility checks ensure capacity constraints are respected throughout all operations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    def adaptive_pareto_weight(sol, obj):\n        total_dist, makespan = obj\n        max_dist = max(o[0] for _, o in archive)\n        max_makespan = max(o[1] for _, o in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        weight = 0.5 + 0.3 * (np.sin(len(archive)/10) + 1) * 0.5\n        return weight * norm_dist + (1 - weight) * norm_makespan\n\n    scored_solutions = [(adaptive_pareto_weight(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.3 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Demand-aware clustering with spatial inversion\n    route_data = []\n    for route in new_solution:\n        if len(route) > 2:\n            route_demand = sum(demand[route[1:-1]])\n            route_centroid = np.mean(coords[route[1:-1]], axis=0)\n            route_data.append((route_centroid, route_demand, route))\n\n    if len(route_data) > 1:\n        for i in range(len(route_data)):\n            for j in range(i+1, len(route_data)):\n                centroid_i, demand_i, route_i = route_data[i]\n                centroid_j, demand_j, route_j = route_data[j]\n                spatial_dist = np.linalg.norm(centroid_i - centroid_j)\n                demand_diff = abs(demand_i - demand_j)\n\n                merge_prob = 0.4 * (1 - spatial_dist/np.max(distance_matrix)) + 0.6 * (1 - demand_diff/capacity)\n                if merge_prob > 0.7 and random.random() < 0.5:\n                    if demand_i + demand_j <= capacity:\n                        # Find best insertion points\n                        min_dist = float('inf')\n                        best_pair = (0, 0)\n                        for a in range(1, len(route_i)-1):\n                            for b in range(1, len(route_j)-1):\n                                dist = distance_matrix[route_i[a]][route_j[b]] * (1 + 0.2 * abs(demand[route_i[a]] - demand[route_j[b]])/capacity)\n                                if dist < min_dist:\n                                    min_dist = dist\n                                    best_pair = (a, b)\n\n                        merged_route = np.concatenate([route_i[:best_pair[0]+1], route_j[best_pair[1]:-1], route_i[-1:]])\n                        new_solution = [route for idx, route in enumerate(new_solution) if idx not in [i, j]] + [merged_route]\n                        break\n\n    # Hybrid spatial-demand inversion\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5:\n            demands = demand[route[1:-1]]\n            demand_balance = np.std(demands) / (np.mean(demands) + 1e-6)\n            spatial_variance = np.std(np.linalg.norm(coords[route[1:-1]] - np.mean(coords[route[1:-1]], axis=0), axis=1))\n\n            inversion_prob = 0.5 * (1 - demand_balance) + 0.5 * (spatial_variance / np.max(distance_matrix))\n            if inversion_prob > 0.7 and random.random() < 0.4:\n                # Select segment to invert\n                start = random.randint(1, len(route)-4)\n                end = random.randint(start+1, len(route)-2)\n                inverted_segment = route[start:end][::-1]\n\n                # Check feasibility\n                if is_feasible(np.concatenate([route[:start], inverted_segment, route[end:]])):\n                    new_route = np.concatenate([route[:start], inverted_segment, route[end:]])\n                    new_solution[route_idx] = new_route\n\n    # Capacity-constrained reinsertion with demand balance\n    if len(new_solution) > 1 and random.random() < 0.6:\n        # Select source and target routes\n        source_idx = random.randint(0, len(new_solution)-1)\n        target_idx = random.randint(0, len(new_solution)-1)\n        if source_idx != target_idx:\n            source_route = new_solution[source_idx]\n            target_route = new_solution[target_idx]\n\n            if len(source_route) > 3:\n                # Select segment to reinsert\n                start = random.randint(1, len(source_route)-3)\n                end = random.randint(start+1, len(source_route)-2)\n                segment = source_route[start:end+1]\n                segment_demand = sum(demand[segment[1:-1]])\n\n                if sum(demand[target_route[1:-1]]) + segment_demand <= capacity:\n                    # Find best insertion point\n                    best_pos = 1\n                    best_cost = float('inf')\n                    for i in range(1, len(target_route)):\n                        cost = distance_matrix[target_route[i-1]][segment[1]] + distance_matrix[segment[-2]][target_route[i]]\n                        if cost < best_cost:\n                            best_cost = cost\n                            best_pos = i\n\n                    # Perform reinsertion\n                    new_target = np.concatenate([target_route[:best_pos], segment, target_route[best_pos:]])\n                    new_source = np.concatenate([source_route[:start], source_route[end+1:]])\n\n                    if is_feasible(new_target) and is_feasible(new_source):\n                        new_solution[source_idx] = new_source\n                        new_solution[target_idx] = new_target\n\n    # Demand-sensitive splitting\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5:\n            demands = demand[route[1:-1]]\n            demand_profile = np.cumsum(demands)\n            total_demand = demand_profile[-1]\n            best_split = -1\n            best_balance = float('inf')\n\n            for pos in range(2, len(route)-2):\n                left_demand = demand_profile[pos-1]\n                right_demand = total_demand - left_demand\n                balance = abs(left_demand - right_demand)\n                if balance < best_balance and left_demand <= capacity and right_demand <= capacity:\n                    best_balance = balance\n                    best_split = pos\n\n            if best_split != -1:\n                new_route1 = np.concatenate([route[:best_split+1], [0]])\n                new_route2 = np.concatenate([[0], route[best_split+1:]])\n                new_solution[route_idx] = new_route1\n                new_solution.insert(route_idx+1, new_route2)\n                break\n\n    # Clean up empty routes\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n",
        "score": [
            -0.6205517551369849,
            1.528939425945282
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    def adaptive_pareto_weight(sol, obj):\n        total_dist, makespan = obj\n        max_dist = max(o[0] for _, o in archive)\n        max_makespan = max(o[1] for _, o in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        weight = 0.5 + 0.3 * (np.sin(len(archive)/10) + 1) * 0.5\n        return weight * norm_dist + (1 - weight) * norm_makespan\n\n    scored_solutions = [(adaptive_pareto_weight(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.3 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Demand-aware clustering with spatial inversion\n    route_data = []\n    for route in new_solution:\n        if len(route) > 2:\n            route_demand = sum(demand[route[1:-1]])\n            route_centroid = np.mean(coords[route[1:-1]], axis=0)\n            route_data.append((route_centroid, route_demand, route))\n\n    if len(route_data) > 1:\n        for i in range(len(route_data)):\n            for j in range(i+1, len(route_data)):\n                centroid_i, demand_i, route_i = route_data[i]\n                centroid_j, demand_j, route_j = route_data[j]\n                spatial_dist = np.linalg.norm(centroid_i - centroid_j)\n                demand_diff = abs(demand_i - demand_j)\n\n                merge_prob = 0.4 * (1 - spatial_dist/np.max(distance_matrix)) + 0.6 * (1 - demand_diff/capacity)\n                if merge_prob > 0.7 and random.random() < 0.5:\n                    if demand_i + demand_j <= capacity:\n                        # Find best insertion points\n                        min_dist = float('inf')\n                        best_pair = (0, 0)\n                        for a in range(1, len(route_i)-1):\n                            for b in range(1, len(route_j)-1):\n                                dist = distance_matrix[route_i[a]][route_j[b]] * (1 + 0.2 * abs(demand[route_i[a]] - demand[route_j[b]])/capacity)\n                                if dist < min_dist:\n                                    min_dist = dist\n                                    best_pair = (a, b)\n\n                        merged_route = np.concatenate([route_i[:best_pair[0]+1], route_j[best_pair[1]:-1], route_i[-1:]])\n                        new_solution = [route for idx, route in enumerate(new_solution) if idx not in [i, j]] + [merged_route]\n                        break\n\n    # Hybrid spatial-demand inversion\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5:\n            demands = demand[route[1:-1]]\n            demand_balance = np.std(demands) / (np.mean(demands) + 1e-6)\n            spatial_variance = np.std(np.linalg.norm(coords[route[1:-1]] - np.mean(coords[route[1:-1]], axis=0), axis=1))\n\n            inversion_prob = 0.5 * (1 - demand_balance) + 0.5 * (spatial_variance / np.max(distance_matrix))\n            if inversion_prob > 0.7 and random.random() < 0.4:\n                # Select segment to invert\n                start = random.randint(1, len(route)-4)\n                end = random.randint(start+1, len(route)-2)\n                inverted_segment = route[start:end][::-1]\n\n                # Check feasibility\n                if is_feasible(np.concatenate([route[:start], inverted_segment, route[end:]])):\n                    new_route = np.concatenate([route[:start], inverted_segment, route[end:]])\n                    new_solution[route_idx] = new_route\n\n    # Capacity-constrained reinsertion with demand balance\n    if len(new_solution) > 1 and random.random() < 0.6:\n        # Select source and target routes\n        source_idx = random.randint(0, len(new_solution)-1)\n        target_idx = random.randint(0, len(new_solution)-1)\n        if source_idx != target_idx:\n            source_route = new_solution[source_idx]\n            target_route = new_solution[target_idx]\n\n            if len(source_route) > 3:\n                # Select segment to reinsert\n                start = random.randint(1, len(source_route)-3)\n                end = random.randint(start+1, len(source_route)-2)\n                segment = source_route[start:end+1]\n                segment_demand = sum(demand[segment[1:-1]])\n\n                if sum(demand[target_route[1:-1]]) + segment_demand <= capacity:\n                    # Find best insertion point\n                    best_pos = 1\n                    best_cost = float('inf')\n                    for i in range(1, len(target_route)):\n                        cost = distance_matrix[target_route[i-1]][segment[1]] + distance_matrix[segment[-2]][target_route[i]]\n                        if cost < best_cost:\n                            best_cost = cost\n                            best_pos = i\n\n                    # Perform reinsertion\n                    new_target = np.concatenate([target_route[:best_pos], segment, target_route[best_pos:]])\n                    new_source = np.concatenate([source_route[:start], source_route[end+1:]])\n\n                    if is_feasible(new_target) and is_feasible(new_source):\n                        new_solution[source_idx] = new_source\n                        new_solution[target_idx] = new_target\n\n    # Demand-sensitive splitting\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5:\n            demands = demand[route[1:-1]]\n            demand_profile = np.cumsum(demands)\n            total_demand = demand_profile[-1]\n            best_split = -1\n            best_balance = float('inf')\n\n            for pos in range(2, len(route)-2):\n                left_demand = demand_profile[pos-1]\n                right_demand = total_demand - left_demand\n                balance = abs(left_demand - right_demand)\n                if balance < best_balance and left_demand <= capacity and right_demand <= capacity:\n                    best_balance = balance\n                    best_split = pos\n\n            if best_split != -1:\n                new_route1 = np.concatenate([route[:best_split+1], [0]])\n                new_route2 = np.concatenate([[0], route[best_split+1:]])\n                new_solution[route_idx] = new_route1\n                new_solution.insert(route_idx+1, new_route2)\n                break\n\n    # Clean up empty routes\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Capacitated Vehicle Routing Problem (Bi-CVRP), where a single depot and multiple customers are located in 2D space. Each customer has a positive demand, and all vehicles in the fleet have identical capacity limits. The objective is to construct a set of routes, each starting and ending at the depot, such that all customers are served, vehicle capacities are not exceeded on any route, and two conflicting objectives are minimized: (1) the total travel distance across all routes, and (2) the makespan, defined as the length of the longest individual route. Each solution in the archive is represented as a list of NumPy arrays, where each array denotes a single route (starting and ending with depot index 0), and is paired with a tuple of two objective values (total_distance, makespan). Your task is to implement a function named 'select_neighbor' that selects one promising solution from the archive and apply a novel or hybrid local search operator to generate a feasible neighbor solution from it. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself. Avoid standard methods like pure 2-opt; instead, invent or combine transformations, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. Ensure that the returned neighbor solution remains feasible under the vehicle capacity constraint. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm combines adaptive route segmentation with demand-aware reinsertion, prioritizing spatial proximity and demand balance to generate high-quality neighbor solutions while maintaining capacity constraints. It first selects promising solutions from the archive using an adaptive weighted scoring that balances distance and makespan objectives, then dynamically splits routes based on spatial centroids and demand distribution, followed by capacity-constrained reinsertion of segments into spatially nearby routes to improve both objectives. The method emphasizes spatial-demand-aware splitting and probabilistic reinsertion to explore the solution space effectively.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    def adaptive_weighted_score(sol, obj):\n        total_dist, makespan = obj\n        max_dist = max(o[0] for _, o in archive)\n        max_makespan = max(o[1] for _, o in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        weight = 0.5 + 0.3 * (random.random() - 0.5)\n        return weight * norm_dist + (1 - weight) * norm_makespan\n\n    scored_solutions = [(adaptive_weighted_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.3 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Spatial-demand-aware route segmentation\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 3 and random.random() < 0.6:\n            customers = route[1:-1]\n            route_coords = coords[customers]\n            centroid = np.mean(route_coords, axis=0)\n            dists = np.linalg.norm(route_coords - centroid, axis=1)\n            demands = demand[customers]\n\n            # Split based on spatial proximity and demand balance\n            split_pos = np.argmax(dists) + 1 if random.random() < 0.7 else np.argmin(demands) + 1\n            segment1 = route[:split_pos+1]\n            segment2 = np.concatenate([[0], route[split_pos+1:]])\n\n            if is_feasible(segment1) and is_feasible(segment2):\n                new_solution[route_idx] = segment1\n                new_solution.insert(route_idx+1, segment2)\n                break\n\n    # Capacity-constrained reinsertion with spatial proximity\n    if len(new_solution) > 1 and random.random() < 0.5:\n        # Select a random segment to reinsert\n        source_route_idx = random.randint(0, len(new_solution)-1)\n        source_route = new_solution[source_route_idx]\n        if len(source_route) > 3:\n            start = random.randint(1, len(source_route)-3)\n            end = random.randint(start+1, len(source_route)-2)\n            segment = source_route[start:end+1]\n            segment_demand = sum(demand[segment[1:-1]])\n\n            # Find target route with spatial proximity\n            source_centroid = np.mean(coords[source_route[1:-1]], axis=0)\n            closest_route_idx = -1\n            min_dist = float('inf')\n            for i, route in enumerate(new_solution):\n                if i != source_route_idx and len(route) > 1:\n                    route_centroid = np.mean(coords[route[1:-1]], axis=0)\n                    dist = np.linalg.norm(source_centroid - route_centroid)\n                    if dist < min_dist:\n                        min_dist = dist\n                        closest_route_idx = i\n\n            if closest_route_idx != -1 and sum(demand[new_solution[closest_route_idx][1:-1]]) + segment_demand <= capacity:\n                # Find best insertion point\n                best_pos = 1\n                best_cost = float('inf')\n                target_route = new_solution[closest_route_idx]\n                for i in range(1, len(target_route)):\n                    cost = distance_matrix[target_route[i-1]][segment[1]] + distance_matrix[segment[-2]][target_route[i]]\n                    if cost < best_cost:\n                        best_cost = cost\n                        best_pos = i\n\n                # Perform reinsertion\n                new_route = np.concatenate([target_route[:best_pos], segment, target_route[best_pos:]])\n                new_solution[closest_route_idx] = new_route\n                new_solution[source_route_idx] = np.concatenate([source_route[:start], source_route[end+1:]])\n\n                # Remove empty routes\n                new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid fitness score that prioritizes makespan (70%) over total distance (30%) while incorporating spatial diversity, then applies three adaptive local search operators: capacity-aware route merging, demand-density-based route inversion, and probabilistic spatial-balanced route splitting, all while ensuring feasibility through capacity checks. The approach emphasizes balancing route quality and diversity, with probabilistic elements to explore different neighborhoods while maintaining solution feasibility.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    def hybrid_fitness_score(solution, objectives):\n        total_dist, makespan = objectives\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        spatial_diversity = np.std([np.mean(coords[route[1:-1]], axis=0) for route in solution]) if len(solution) > 1 else 0\n        return (0.3 * norm_dist + 0.7 * norm_makespan) * (1 + 0.3 * spatial_diversity)\n\n    scored_solutions = [(hybrid_fitness_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.2 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Adaptive route clustering with capacity-aware merging\n    route_stats = [(sum(demand[route[1:-1]]), len(route)-2) for route in new_solution]\n    avg_load = np.mean([load for load, _ in route_stats]) if route_stats else 0\n    avg_length = np.mean([length for _, length in route_stats]) if route_stats else 0\n\n    for i in range(len(new_solution)):\n        route_i = new_solution[i]\n        load_i, length_i = route_stats[i]\n        for j in range(i+1, len(new_solution)):\n            route_j = new_solution[j]\n            load_j, length_j = route_stats[j]\n            if abs(load_i - load_j) <= 0.3 * avg_load and abs(length_i - length_j) <= 0.3 * avg_length:\n                if load_i + load_j <= capacity:\n                    min_dist = float('inf')\n                    best_pair = (0, 0)\n                    for a in range(1, len(route_i)-1):\n                        for b in range(1, len(route_j)-1):\n                            dist = distance_matrix[route_i[a]][route_j[b]]\n                            if dist < min_dist:\n                                min_dist = dist\n                                best_pair = (a, b)\n                    merged_route = np.concatenate([route_i[:best_pair[0]+1], route_j[best_pair[1]:-1], route_i[-1:]])\n                    new_solution = [route for idx, route in enumerate(new_solution) if idx not in [i, j]] + [merged_route]\n                    route_stats = [(sum(demand[route[1:-1]]), len(route)-2) for route in new_solution]\n                    break\n\n    # Dynamic route inversion based on demand density\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4:\n            demand_density = np.mean([demand[node] for node in route[1:-1]])\n            high_demand_nodes = [node for node in route[1:-1] if demand[node] > 1.2 * demand_density]\n            if high_demand_nodes and random.random() < 0.4:\n                pos = np.where(route == high_demand_nodes[0])[0][0]\n                if is_feasible(np.concatenate([route[:pos], route[pos:][::-1]])):\n                    new_solution[route_idx] = np.concatenate([route[:pos], route[pos:][::-1]])\n\n    # Probabilistic route splitting with spatial balancing\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 6 and random.random() < 0.4:\n            centroid = np.mean(coords[route[1:-1]], axis=0)\n            farthest_node = max(route[1:-1], key=lambda x: np.linalg.norm(coords[x] - centroid))\n            split_pos = np.where(route == farthest_node)[0][0]\n            if (sum(demand[route[1:split_pos]]) <= capacity and\n                sum(demand[route[split_pos:-1]]) <= capacity and\n                abs(split_pos - len(route)/2) <= 0.4 * len(route)):\n                new_route1 = np.concatenate([route[:split_pos], [0]])\n                new_route2 = np.concatenate([[0], route[split_pos:]])\n                new_solution[route_idx] = new_route1\n                new_solution.insert(route_idx+1, new_route2)\n                break\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: *Demand-aware clustering, hybrid split-invert, adaptive Pareto weights, capacity-constrained reinsertion*\n- **Advice**: Combine *demand-aware clustering* with *hybrid split-invert* using *adaptive Pareto weights* to balance distance/makespan while ensuring capacity constraints.\n- **Avoid**: Static single-objective swaps; rigid Pareto selection without demand checks; over-reliance on randomness without guided selection.\n- **Explanation**: Hybrid operators dynamically balance objectives by integrating demand-aware reshaping with probabilistic route adjustments, preventing constraint violations and premature convergence.\n\n*(This ensures actionable advice, clear keywords, and explanations tied to the analysis, while avoiding ineffectiveness.)*\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 304,
        "algorithm": "The algorithm combines demand-aware spatial clustering with hybrid route inversion and probabilistic splitting to balance distance and makespan objectives, prioritizing solutions with balanced trade-offs through adaptive Pareto-weighted selection while ensuring feasibility through capacity-constrained operations. It first clusters routes by spatial proximity and demand similarity, then selectively inverts high-demand segments to improve makespan, followed by probabilistic splitting of overloaded routes into capacity-balanced segments. The approach balances exploration (via random selection from top 25% solutions) with exploitation (focusing on high-demand nodes and capacity-balanced splits), dynamically adjusting based on Pareto dominance and normalized objective values.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    def pareto_weighted_score(solution, objectives):\n        total_dist, makespan = objectives\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        pareto_front = [obj for _, obj in archive]\n        pareto_front.sort()\n        pareto_rank = sum(1 for obj in pareto_front if (obj[0] < total_dist and obj[1] < makespan))\n        return (0.4 * norm_dist + 0.6 * norm_makespan) * (1 + 0.2 * (1 - pareto_rank/len(archive)))\n\n    scored_solutions = [(pareto_weighted_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.25 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Demand-aware spatial clustering\n    route_centroids = [np.mean(coords[route[1:-1]], axis=0) for route in new_solution]\n    route_demands = [sum(demand[route[1:-1]]) for route in new_solution]\n\n    for i in range(len(new_solution)):\n        for j in range(i+1, len(new_solution)):\n            dist = np.linalg.norm(route_centroids[i] - route_centroids[j])\n            demand_diff = abs(route_demands[i] - route_demands[j])\n            if dist < 0.3 * np.max(distance_matrix) and demand_diff < 0.2 * capacity:\n                if route_demands[i] + route_demands[j] <= capacity:\n                    # Find closest nodes between routes\n                    min_dist = float('inf')\n                    best_pair = (0, 0)\n                    for a in range(1, len(new_solution[i])-1):\n                        for b in range(1, len(new_solution[j])-1):\n                            d = distance_matrix[new_solution[i][a]][new_solution[j][b]]\n                            if d < min_dist:\n                                min_dist = d\n                                best_pair = (a, b)\n                    # Merge routes\n                    merged_route = np.concatenate([\n                        new_solution[i][:best_pair[0]+1],\n                        new_solution[j][best_pair[1]:-1],\n                        new_solution[i][-1:]\n                    ])\n                    new_solution = [route for idx, route in enumerate(new_solution) if idx not in [i, j]] + [merged_route]\n                    route_centroids = [np.mean(coords[route[1:-1]], axis=0) for route in new_solution]\n                    route_demands = [sum(demand[route[1:-1]]) for route in new_solution]\n                    break\n\n    # Hybrid route inversion with demand density\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4:\n            demand_density = np.mean([demand[node] for node in route[1:-1]])\n            high_demand_nodes = [node for node in route[1:-1] if demand[node] > 1.3 * demand_density]\n            if high_demand_nodes and random.random() < 0.5:\n                start_pos = np.where(route == high_demand_nodes[0])[0][0]\n                end_pos = np.where(route == high_demand_nodes[-1])[0][0] + 1\n                inverted_segment = route[start_pos:end_pos][::-1]\n                new_route = np.concatenate([route[:start_pos], inverted_segment, route[end_pos:]])\n                if is_feasible(new_route):\n                    new_solution[route_idx] = new_route\n\n    # Probabilistic capacity-balanced splitting\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5 and random.random() < 0.4:\n            total_demand = sum(demand[route[1:-1]])\n            if total_demand > 0.7 * capacity:\n                split_pos = 1\n                current_demand = 0\n                for i in range(1, len(route)-1):\n                    current_demand += demand[route[i]]\n                    if current_demand > total_demand / 2 and abs(current_demand - total_demand/2) < 0.2 * total_demand:\n                        split_pos = i\n                        break\n                if (sum(demand[route[1:split_pos+1]]) <= capacity and\n                    sum(demand[route[split_pos+1:-1]]) <= capacity):\n                    new_route1 = np.concatenate([route[:split_pos+1], [0]])\n                    new_route2 = np.concatenate([[0], route[split_pos+1:]])\n                    new_solution[route_idx] = new_route1\n                    new_solution.insert(route_idx+1, new_route2)\n                    break\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n",
        "score": [
            -0.5193738243860186,
            1.020798921585083
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    def pareto_weighted_score(solution, objectives):\n        total_dist, makespan = objectives\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        pareto_front = [obj for _, obj in archive]\n        pareto_front.sort()\n        pareto_rank = sum(1 for obj in pareto_front if (obj[0] < total_dist and obj[1] < makespan))\n        return (0.4 * norm_dist + 0.6 * norm_makespan) * (1 + 0.2 * (1 - pareto_rank/len(archive)))\n\n    scored_solutions = [(pareto_weighted_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.25 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Demand-aware spatial clustering\n    route_centroids = [np.mean(coords[route[1:-1]], axis=0) for route in new_solution]\n    route_demands = [sum(demand[route[1:-1]]) for route in new_solution]\n\n    for i in range(len(new_solution)):\n        for j in range(i+1, len(new_solution)):\n            dist = np.linalg.norm(route_centroids[i] - route_centroids[j])\n            demand_diff = abs(route_demands[i] - route_demands[j])\n            if dist < 0.3 * np.max(distance_matrix) and demand_diff < 0.2 * capacity:\n                if route_demands[i] + route_demands[j] <= capacity:\n                    # Find closest nodes between routes\n                    min_dist = float('inf')\n                    best_pair = (0, 0)\n                    for a in range(1, len(new_solution[i])-1):\n                        for b in range(1, len(new_solution[j])-1):\n                            d = distance_matrix[new_solution[i][a]][new_solution[j][b]]\n                            if d < min_dist:\n                                min_dist = d\n                                best_pair = (a, b)\n                    # Merge routes\n                    merged_route = np.concatenate([\n                        new_solution[i][:best_pair[0]+1],\n                        new_solution[j][best_pair[1]:-1],\n                        new_solution[i][-1:]\n                    ])\n                    new_solution = [route for idx, route in enumerate(new_solution) if idx not in [i, j]] + [merged_route]\n                    route_centroids = [np.mean(coords[route[1:-1]], axis=0) for route in new_solution]\n                    route_demands = [sum(demand[route[1:-1]]) for route in new_solution]\n                    break\n\n    # Hybrid route inversion with demand density\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4:\n            demand_density = np.mean([demand[node] for node in route[1:-1]])\n            high_demand_nodes = [node for node in route[1:-1] if demand[node] > 1.3 * demand_density]\n            if high_demand_nodes and random.random() < 0.5:\n                start_pos = np.where(route == high_demand_nodes[0])[0][0]\n                end_pos = np.where(route == high_demand_nodes[-1])[0][0] + 1\n                inverted_segment = route[start_pos:end_pos][::-1]\n                new_route = np.concatenate([route[:start_pos], inverted_segment, route[end_pos:]])\n                if is_feasible(new_route):\n                    new_solution[route_idx] = new_route\n\n    # Probabilistic capacity-balanced splitting\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5 and random.random() < 0.4:\n            total_demand = sum(demand[route[1:-1]])\n            if total_demand > 0.7 * capacity:\n                split_pos = 1\n                current_demand = 0\n                for i in range(1, len(route)-1):\n                    current_demand += demand[route[i]]\n                    if current_demand > total_demand / 2 and abs(current_demand - total_demand/2) < 0.2 * total_demand:\n                        split_pos = i\n                        break\n                if (sum(demand[route[1:split_pos+1]]) <= capacity and\n                    sum(demand[route[split_pos+1:-1]]) <= capacity):\n                    new_route1 = np.concatenate([route[:split_pos+1], [0]])\n                    new_route2 = np.concatenate([[0], route[split_pos+1:]])\n                    new_solution[route_idx] = new_route1\n                    new_solution.insert(route_idx+1, new_route2)\n                    break\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Capacitated Vehicle Routing Problem (Bi-CVRP), where a single depot and multiple customers are located in 2D space. Each customer has a positive demand, and all vehicles in the fleet have identical capacity limits. The objective is to construct a set of routes, each starting and ending at the depot, such that all customers are served, vehicle capacities are not exceeded on any route, and two conflicting objectives are minimized: (1) the total travel distance across all routes, and (2) the makespan, defined as the length of the longest individual route. Each solution in the archive is represented as a list of NumPy arrays, where each array denotes a single route (starting and ending with depot index 0), and is paired with a tuple of two objective values (total_distance, makespan). Your task is to implement a function named 'select_neighbor' that selects one promising solution from the archive and apply a novel or hybrid local search operator to generate a feasible neighbor solution from it. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself. Avoid standard methods like pure 2-opt; instead, invent or combine transformations, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. Ensure that the returned neighbor solution remains feasible under the vehicle capacity constraint. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm combines adaptive demand-aware Pareto selection with hybrid local search operators, prioritizing solutions based on a dynamic score that balances distance and makespan while considering demand distribution. It applies spatially-constrained inversions, probabilistic demand-balanced segment splits, and capacity-aware reallocations, with iterative feasibility checks and demand-validated repairs. The method dynamically adjusts operator probabilities to maintain exploration-exploitation balance, giving higher priority to demand-weighted routes and spatial-demand-constrained reinsertions.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    def demand_pareto_score(sol, obj):\n        total_dist, makespan = obj\n        demand_weights = np.mean(demand[np.concatenate([r[1:-1] for r in sol])]) if any(len(r) > 2 for r in sol) else 1\n        max_dist = max(o[0] for _, o in archive)\n        max_makespan = max(o[1] for _, o in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        return (0.4 * norm_dist + 0.6 * norm_makespan) * (1 + 0.2 * (demand_weights - 1))\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    scored_solutions = [(demand_pareto_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.3 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    # Demand-aware spatial inversion\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4 and random.random() < 0.7:\n            customers = route[1:-1]\n            demands = demand[customers]\n            demand_ratios = demands / sum(demands) if sum(demands) > 0 else np.ones(len(demands)) / len(demands)\n\n            # Find inversion points based on demand balance\n            cumulative_ratio = np.cumsum(demand_ratios)\n            split_pos = np.argmin(np.abs(cumulative_ratio - 0.5)) + 1\n\n            if split_pos > 1 and split_pos < len(route)-2:\n                segment1 = route[:split_pos+1]\n                segment2 = np.concatenate([[0], route[split_pos+1:]])\n\n                if is_feasible(segment1) and is_feasible(segment2):\n                    if random.random() < 0.5:\n                        segment2 = np.concatenate([[0], segment2[-2:0:-1], segment2[-1:]])\n                    new_solution[route_idx] = segment1\n                    new_solution.insert(route_idx+1, segment2)\n                    break\n\n    # Probabilistic demand-balanced reallocation\n    if len(new_solution) > 1 and random.random() < 0.6:\n        route_stats = []\n        for route in new_solution:\n            if len(route) > 2:\n                total_demand = sum(demand[route[1:-1]])\n                route_stats.append((total_demand, route))\n\n        if len(route_stats) > 1:\n            route_stats.sort(key=lambda x: x[0])\n            for i in range(len(route_stats)-1):\n                j = len(route_stats)-1-i\n                if i >= j:\n                    break\n\n                route_i = route_stats[i][1]\n                route_j = route_stats[j][1]\n\n                if sum(demand[route_i[1:-1]]) + sum(demand[route_j[1:-1]]) <= capacity:\n                    merged_route = np.concatenate([route_i[:-1], route_j[1:]])\n\n                    if is_feasible(merged_route):\n                        new_solution = [r for r in new_solution if not np.array_equal(r, route_i) and not np.array_equal(r, route_j)]\n                        new_solution.append(merged_route)\n                        break\n\n    # Spatial-demand constrained reinsertion\n    if len(new_solution) > 1 and random.random() < 0.5:\n        source_idx = random.randint(0, len(new_solution)-1)\n        target_idx = random.randint(0, len(new_solution)-1)\n        if source_idx != target_idx:\n            source_route = new_solution[source_idx]\n            target_route = new_solution[target_idx]\n\n            if len(source_route) > 3:\n                # Find customer with balanced demand and spatial proximity\n                best_customer = None\n                best_score = float('inf')\n\n                for pos in range(1, len(source_route)-1):\n                    customer = source_route[pos]\n                    spatial_score = np.mean([distance_matrix[customer][n] for n in target_route[1:-1]])\n                    demand_score = abs(demand[customer] - np.mean(demand[target_route[1:-1]]))\n\n                    if spatial_score + demand_score < best_score:\n                        best_score = spatial_score + demand_score\n                        best_customer = customer\n                        best_pos = pos\n\n                if best_customer is not None and sum(demand[target_route[1:-1]]) + demand[best_customer] <= capacity:\n                    new_source = np.concatenate([source_route[:best_pos], source_route[best_pos+1:]])\n                    best_insert_pos = 1\n                    min_increase = float('inf')\n\n                    for pos in range(1, len(target_route)):\n                        dist_increase = (distance_matrix[target_route[pos-1]][best_customer] +\n                                       distance_matrix[best_customer][target_route[pos]] -\n                                       distance_matrix[target_route[pos-1]][target_route[pos]])\n\n                        if dist_increase < min_increase:\n                            min_increase = dist_increase\n                            best_insert_pos = pos\n\n                    new_target = np.concatenate([target_route[:best_insert_pos], [best_customer], target_route[best_insert_pos:]])\n\n                    if is_feasible(new_source) and is_feasible(new_target):\n                        new_solution[source_idx] = new_source\n                        new_solution[target_idx] = new_target\n\n    # Capacity validation and repair\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if sum(demand[route[1:-1]]) > capacity:\n            cumulative_demand = 0\n            split_pos = -1\n            for i in range(1, len(route)-1):\n                cumulative_demand += demand[route[i]]\n                if cumulative_demand > capacity:\n                    split_pos = i\n                    break\n\n            if split_pos > 1:\n                route1 = np.concatenate([route[:split_pos], [0]])\n                route2 = np.concatenate([[0], route[split_pos:]])\n                new_solution[route_idx] = route1\n                new_solution.insert(route_idx+1, route2)\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid fitness score that prioritizes makespan (70%) over total distance (30%) while incorporating spatial diversity, then applies three adaptive local search operators: capacity-aware route merging, demand-density-based route inversion, and probabilistic spatial-balanced route splitting, all while ensuring feasibility through capacity checks. The approach emphasizes balancing route quality and diversity, with probabilistic elements to explore different neighborhoods while maintaining solution feasibility.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    def hybrid_fitness_score(solution, objectives):\n        total_dist, makespan = objectives\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        spatial_diversity = np.std([np.mean(coords[route[1:-1]], axis=0) for route in solution]) if len(solution) > 1 else 0\n        return (0.3 * norm_dist + 0.7 * norm_makespan) * (1 + 0.3 * spatial_diversity)\n\n    scored_solutions = [(hybrid_fitness_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.2 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Adaptive route clustering with capacity-aware merging\n    route_stats = [(sum(demand[route[1:-1]]), len(route)-2) for route in new_solution]\n    avg_load = np.mean([load for load, _ in route_stats]) if route_stats else 0\n    avg_length = np.mean([length for _, length in route_stats]) if route_stats else 0\n\n    for i in range(len(new_solution)):\n        route_i = new_solution[i]\n        load_i, length_i = route_stats[i]\n        for j in range(i+1, len(new_solution)):\n            route_j = new_solution[j]\n            load_j, length_j = route_stats[j]\n            if abs(load_i - load_j) <= 0.3 * avg_load and abs(length_i - length_j) <= 0.3 * avg_length:\n                if load_i + load_j <= capacity:\n                    min_dist = float('inf')\n                    best_pair = (0, 0)\n                    for a in range(1, len(route_i)-1):\n                        for b in range(1, len(route_j)-1):\n                            dist = distance_matrix[route_i[a]][route_j[b]]\n                            if dist < min_dist:\n                                min_dist = dist\n                                best_pair = (a, b)\n                    merged_route = np.concatenate([route_i[:best_pair[0]+1], route_j[best_pair[1]:-1], route_i[-1:]])\n                    new_solution = [route for idx, route in enumerate(new_solution) if idx not in [i, j]] + [merged_route]\n                    route_stats = [(sum(demand[route[1:-1]]), len(route)-2) for route in new_solution]\n                    break\n\n    # Dynamic route inversion based on demand density\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4:\n            demand_density = np.mean([demand[node] for node in route[1:-1]])\n            high_demand_nodes = [node for node in route[1:-1] if demand[node] > 1.2 * demand_density]\n            if high_demand_nodes and random.random() < 0.4:\n                pos = np.where(route == high_demand_nodes[0])[0][0]\n                if is_feasible(np.concatenate([route[:pos], route[pos:][::-1]])):\n                    new_solution[route_idx] = np.concatenate([route[:pos], route[pos:][::-1]])\n\n    # Probabilistic route splitting with spatial balancing\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 6 and random.random() < 0.4:\n            centroid = np.mean(coords[route[1:-1]], axis=0)\n            farthest_node = max(route[1:-1], key=lambda x: np.linalg.norm(coords[x] - centroid))\n            split_pos = np.where(route == farthest_node)[0][0]\n            if (sum(demand[route[1:split_pos]]) <= capacity and\n                sum(demand[route[split_pos:-1]]) <= capacity and\n                abs(split_pos - len(route)/2) <= 0.4 * len(route)):\n                new_route1 = np.concatenate([route[:split_pos], [0]])\n                new_route2 = np.concatenate([[0], route[split_pos:]])\n                new_solution[route_idx] = new_route1\n                new_solution.insert(route_idx+1, new_route2)\n                break\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: *Demand-aware clustering, hybrid split-invert, adaptive Pareto weights, capacity-constrained reinsertion*\n- **Advice**: Combine *demand-aware clustering* with *hybrid split-invert* using *adaptive Pareto weights* to balance distance/makespan while ensuring capacity constraints.\n- **Avoid**: Static single-objective swaps; rigid Pareto selection without demand checks; over-reliance on randomness without guided selection.\n- **Explanation**: Hybrid operators dynamically balance objectives by integrating demand-aware reshaping with probabilistic route adjustments, preventing constraint violations and premature convergence.\n\n*(This ensures actionable advice, clear keywords, and explanations tied to the analysis, while avoiding ineffectiveness.)*\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 305,
        "algorithm": "The algorithm combines demand-aware spatial clustering with adaptive route reshaping to generate high-quality neighbors, prioritizing solutions with balanced distance and makespan while incorporating demand density and spatial diversity. It applies capacity-constrained merging, demand-balanced inversions, and spatial-balanced splitting, with dynamic operator probabilities to maintain exploration-exploitation balance, and ensures feasibility through iterative demand validation. Key variables are weighted (distance and makespan normalized with demand and spatial diversity), with higher emphasis on demand-balanced operations and probabilistic splitting for spatial balance.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    def dynamic_pareto_score(sol, obj):\n        total_dist, makespan = obj\n        demand_density = np.mean(demand[np.concatenate([r[1:-1] for r in sol])]) if any(len(r) > 2 for r in sol) else 1\n        spatial_diversity = np.std([np.mean(coords[route[1:-1]], axis=0) for route in sol]) if len(sol) > 1 else 0\n        max_dist = max(o[0] for _, o in archive)\n        max_makespan = max(o[1] for _, o in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        return (0.5 * norm_dist + 0.5 * norm_makespan) * (1 + 0.3 * demand_density + 0.2 * spatial_diversity)\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    scored_solutions = [(dynamic_pareto_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.25 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    # Demand-aware spatial clustering\n    if len(new_solution) > 1 and random.random() < 0.7:\n        route_centroids = [np.mean(coords[route[1:-1]], axis=0) for route in new_solution]\n        for i in range(len(new_solution)):\n            for j in range(i+1, len(new_solution)):\n                if np.linalg.norm(route_centroids[i] - route_centroids[j]) < 0.5 * np.mean([np.linalg.norm(c) for c in coords[1:]]):\n                    route_i = new_solution[i]\n                    route_j = new_solution[j]\n                    if sum(demand[route_i[1:-1]]) + sum(demand[route_j[1:-1]]) <= capacity:\n                        merged_route = np.concatenate([route_i[:-1], route_j[1:]])\n                        if is_feasible(merged_route):\n                            new_solution = [r for idx, r in enumerate(new_solution) if idx not in [i, j]] + [merged_route]\n                            break\n\n    # Adaptive demand-balanced inversion\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4 and random.random() < 0.6:\n            demand_ratios = demand[route[1:-1]] / sum(demand[route[1:-1]])\n            split_pos = np.argmin(np.abs(np.cumsum(demand_ratios) - 0.5)) + 1\n            if split_pos > 1 and split_pos < len(route)-2:\n                segment1 = route[:split_pos+1]\n                segment2 = np.concatenate([[0], route[split_pos+1:]])\n                if is_feasible(segment1) and is_feasible(segment2):\n                    if random.random() < 0.5:\n                        segment2 = np.concatenate([[0], segment2[-2:0:-1], segment2[-1:]])\n                    new_solution[route_idx] = segment1\n                    new_solution.insert(route_idx+1, segment2)\n                    break\n\n    # Probabilistic spatial-balanced splitting\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5 and random.random() < 0.5:\n            centroid = np.mean(coords[route[1:-1]], axis=0)\n            farthest_node = max(route[1:-1], key=lambda x: np.linalg.norm(coords[x] - centroid))\n            split_pos = np.where(route == farthest_node)[0][0]\n            if (sum(demand[route[1:split_pos]]) <= capacity and\n                sum(demand[route[split_pos:-1]]) <= capacity and\n                abs(split_pos - len(route)/2) <= 0.3 * len(route)):\n                new_route1 = np.concatenate([route[:split_pos], [0]])\n                new_route2 = np.concatenate([[0], route[split_pos:]])\n                new_solution[route_idx] = new_route1\n                new_solution.insert(route_idx+1, new_route2)\n                break\n\n    # Capacity validation and repair\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if sum(demand[route[1:-1]]) > capacity:\n            cumulative_demand = 0\n            split_pos = -1\n            for i in range(1, len(route)-1):\n                cumulative_demand += demand[route[i]]\n                if cumulative_demand > capacity:\n                    split_pos = i\n                    break\n            if split_pos > 1:\n                route1 = np.concatenate([route[:split_pos], [0]])\n                route2 = np.concatenate([[0], route[split_pos:]])\n                new_solution[route_idx] = route1\n                new_solution.insert(route_idx+1, route2)\n\n    return new_solution\n\n",
        "score": [
            -0.723044376318458,
            10.421262502670288
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    def dynamic_pareto_score(sol, obj):\n        total_dist, makespan = obj\n        demand_density = np.mean(demand[np.concatenate([r[1:-1] for r in sol])]) if any(len(r) > 2 for r in sol) else 1\n        spatial_diversity = np.std([np.mean(coords[route[1:-1]], axis=0) for route in sol]) if len(sol) > 1 else 0\n        max_dist = max(o[0] for _, o in archive)\n        max_makespan = max(o[1] for _, o in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        return (0.5 * norm_dist + 0.5 * norm_makespan) * (1 + 0.3 * demand_density + 0.2 * spatial_diversity)\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    scored_solutions = [(dynamic_pareto_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.25 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    # Demand-aware spatial clustering\n    if len(new_solution) > 1 and random.random() < 0.7:\n        route_centroids = [np.mean(coords[route[1:-1]], axis=0) for route in new_solution]\n        for i in range(len(new_solution)):\n            for j in range(i+1, len(new_solution)):\n                if np.linalg.norm(route_centroids[i] - route_centroids[j]) < 0.5 * np.mean([np.linalg.norm(c) for c in coords[1:]]):\n                    route_i = new_solution[i]\n                    route_j = new_solution[j]\n                    if sum(demand[route_i[1:-1]]) + sum(demand[route_j[1:-1]]) <= capacity:\n                        merged_route = np.concatenate([route_i[:-1], route_j[1:]])\n                        if is_feasible(merged_route):\n                            new_solution = [r for idx, r in enumerate(new_solution) if idx not in [i, j]] + [merged_route]\n                            break\n\n    # Adaptive demand-balanced inversion\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4 and random.random() < 0.6:\n            demand_ratios = demand[route[1:-1]] / sum(demand[route[1:-1]])\n            split_pos = np.argmin(np.abs(np.cumsum(demand_ratios) - 0.5)) + 1\n            if split_pos > 1 and split_pos < len(route)-2:\n                segment1 = route[:split_pos+1]\n                segment2 = np.concatenate([[0], route[split_pos+1:]])\n                if is_feasible(segment1) and is_feasible(segment2):\n                    if random.random() < 0.5:\n                        segment2 = np.concatenate([[0], segment2[-2:0:-1], segment2[-1:]])\n                    new_solution[route_idx] = segment1\n                    new_solution.insert(route_idx+1, segment2)\n                    break\n\n    # Probabilistic spatial-balanced splitting\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5 and random.random() < 0.5:\n            centroid = np.mean(coords[route[1:-1]], axis=0)\n            farthest_node = max(route[1:-1], key=lambda x: np.linalg.norm(coords[x] - centroid))\n            split_pos = np.where(route == farthest_node)[0][0]\n            if (sum(demand[route[1:split_pos]]) <= capacity and\n                sum(demand[route[split_pos:-1]]) <= capacity and\n                abs(split_pos - len(route)/2) <= 0.3 * len(route)):\n                new_route1 = np.concatenate([route[:split_pos], [0]])\n                new_route2 = np.concatenate([[0], route[split_pos:]])\n                new_solution[route_idx] = new_route1\n                new_solution.insert(route_idx+1, new_route2)\n                break\n\n    # Capacity validation and repair\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if sum(demand[route[1:-1]]) > capacity:\n            cumulative_demand = 0\n            split_pos = -1\n            for i in range(1, len(route)-1):\n                cumulative_demand += demand[route[i]]\n                if cumulative_demand > capacity:\n                    split_pos = i\n                    break\n            if split_pos > 1:\n                route1 = np.concatenate([route[:split_pos], [0]])\n                route2 = np.concatenate([[0], route[split_pos:]])\n                new_solution[route_idx] = route1\n                new_solution.insert(route_idx+1, route2)\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Capacitated Vehicle Routing Problem (Bi-CVRP), where a single depot and multiple customers are located in 2D space. Each customer has a positive demand, and all vehicles in the fleet have identical capacity limits. The objective is to construct a set of routes, each starting and ending at the depot, such that all customers are served, vehicle capacities are not exceeded on any route, and two conflicting objectives are minimized: (1) the total travel distance across all routes, and (2) the makespan, defined as the length of the longest individual route. Each solution in the archive is represented as a list of NumPy arrays, where each array denotes a single route (starting and ending with depot index 0), and is paired with a tuple of two objective values (total_distance, makespan). Your task is to implement a function named 'select_neighbor' that selects one promising solution from the archive and apply a novel or hybrid local search operator to generate a feasible neighbor solution from it. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself. Avoid standard methods like pure 2-opt; instead, invent or combine transformations, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. Ensure that the returned neighbor solution remains feasible under the vehicle capacity constraint. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the archive using a hybrid fitness score that prioritizes makespan (70%) over total distance (30%) while incorporating spatial diversity, then applies three adaptive local search operators: capacity-aware route merging, demand-density-based route inversion, and probabilistic spatial-balanced route splitting, all while ensuring feasibility through capacity checks. The approach emphasizes balancing route quality and diversity, with probabilistic elements to explore different neighborhoods while maintaining solution feasibility.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    def hybrid_fitness_score(solution, objectives):\n        total_dist, makespan = objectives\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        spatial_diversity = np.std([np.mean(coords[route[1:-1]], axis=0) for route in solution]) if len(solution) > 1 else 0\n        return (0.3 * norm_dist + 0.7 * norm_makespan) * (1 + 0.3 * spatial_diversity)\n\n    scored_solutions = [(hybrid_fitness_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.2 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Adaptive route clustering with capacity-aware merging\n    route_stats = [(sum(demand[route[1:-1]]), len(route)-2) for route in new_solution]\n    avg_load = np.mean([load for load, _ in route_stats]) if route_stats else 0\n    avg_length = np.mean([length for _, length in route_stats]) if route_stats else 0\n\n    for i in range(len(new_solution)):\n        route_i = new_solution[i]\n        load_i, length_i = route_stats[i]\n        for j in range(i+1, len(new_solution)):\n            route_j = new_solution[j]\n            load_j, length_j = route_stats[j]\n            if abs(load_i - load_j) <= 0.3 * avg_load and abs(length_i - length_j) <= 0.3 * avg_length:\n                if load_i + load_j <= capacity:\n                    min_dist = float('inf')\n                    best_pair = (0, 0)\n                    for a in range(1, len(route_i)-1):\n                        for b in range(1, len(route_j)-1):\n                            dist = distance_matrix[route_i[a]][route_j[b]]\n                            if dist < min_dist:\n                                min_dist = dist\n                                best_pair = (a, b)\n                    merged_route = np.concatenate([route_i[:best_pair[0]+1], route_j[best_pair[1]:-1], route_i[-1:]])\n                    new_solution = [route for idx, route in enumerate(new_solution) if idx not in [i, j]] + [merged_route]\n                    route_stats = [(sum(demand[route[1:-1]]), len(route)-2) for route in new_solution]\n                    break\n\n    # Dynamic route inversion based on demand density\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4:\n            demand_density = np.mean([demand[node] for node in route[1:-1]])\n            high_demand_nodes = [node for node in route[1:-1] if demand[node] > 1.2 * demand_density]\n            if high_demand_nodes and random.random() < 0.4:\n                pos = np.where(route == high_demand_nodes[0])[0][0]\n                if is_feasible(np.concatenate([route[:pos], route[pos:][::-1]])):\n                    new_solution[route_idx] = np.concatenate([route[:pos], route[pos:][::-1]])\n\n    # Probabilistic route splitting with spatial balancing\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 6 and random.random() < 0.4:\n            centroid = np.mean(coords[route[1:-1]], axis=0)\n            farthest_node = max(route[1:-1], key=lambda x: np.linalg.norm(coords[x] - centroid))\n            split_pos = np.where(route == farthest_node)[0][0]\n            if (sum(demand[route[1:split_pos]]) <= capacity and\n                sum(demand[route[split_pos:-1]]) <= capacity and\n                abs(split_pos - len(route)/2) <= 0.4 * len(route)):\n                new_route1 = np.concatenate([route[:split_pos], [0]])\n                new_route2 = np.concatenate([[0], route[split_pos:]])\n                new_solution[route_idx] = new_route1\n                new_solution.insert(route_idx+1, new_route2)\n                break\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 306,
        "algorithm": "The algorithm dynamically selects a promising solution from the archive based on a fitness score combining normalized objectives, route load balance, and spatial entropy, then applies a hybrid local search combining intra-route demand-sensitive reordering, inter-route demand-balanced swapping, and probabilistic route splitting to improve both distance and makespan while maintaining feasibility. The fitness prioritizes makespan (60%) over distance (40%) with secondary considerations for load balance and spatial distribution, while the local search emphasizes demand-aware transformations and route balancing.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    def dynamic_fitness(solution, objectives):\n        total_dist, makespan = objectives\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n\n        route_loads = [sum(demand[route[1:-1]]) for route in solution]\n        load_balance = 1 - np.std(route_loads) / capacity if len(route_loads) > 1 else 0\n\n        spatial_entropy = 0\n        for route in solution:\n            if len(route) > 2:\n                centroid = np.mean(coords[route[1:-1]], axis=0)\n                distances = [np.linalg.norm(coords[node] - centroid) for node in route[1:-1]]\n                spatial_entropy += np.sum(distances) / len(distances)\n\n        return (0.4 * norm_dist + 0.6 * norm_makespan) * (1 + 0.2 * load_balance + 0.1 * spatial_entropy)\n\n    scored_solutions = [(dynamic_fitness(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.3 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Dynamic reordering with demand-sensitivity\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 3:\n            demand_profile = demand[route[1:-1]]\n            demand_ratio = demand_profile / np.mean(demand_profile)\n            sorted_indices = np.argsort(demand_ratio)[::-1]\n            new_order = route[1:-1][sorted_indices]\n            new_route = np.concatenate([[0], new_order, [0]])\n            if is_feasible(new_route):\n                new_solution[route_idx] = new_route\n\n    # Demand-balanced inter-route swapping\n    route_loads = [sum(demand[route[1:-1]]) for route in new_solution]\n    avg_load = np.mean(route_loads)\n    for i in range(len(new_solution)):\n        for j in range(i+1, len(new_solution)):\n            route_i, route_j = new_solution[i], new_solution[j]\n            load_i, load_j = route_loads[i], route_loads[j]\n            if abs(load_i - load_j) > 0.2 * avg_load:\n                continue\n\n            for a in range(1, len(route_i)-1):\n                for b in range(1, len(route_j)-1):\n                    node_i, node_j = route_i[a], route_j[b]\n                    new_load_i = load_i - demand[node_i] + demand[node_j]\n                    new_load_j = load_j - demand[node_j] + demand[node_i]\n                    if new_load_i <= capacity and new_load_j <= capacity:\n                        new_route_i = np.concatenate([route_i[:a], [node_j], route_i[a+1:]])\n                        new_route_j = np.concatenate([route_j[:b], [node_i], route_j[b+1:]])\n                        if is_feasible(new_route_i) and is_feasible(new_route_j):\n                            new_solution[i] = new_route_i\n                            new_solution[j] = new_route_j\n                            route_loads[i] = new_load_i\n                            route_loads[j] = new_load_j\n                            break\n\n    # Probabilistic route balancing\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4 and random.random() < 0.3:\n            total_demand = sum(demand[route[1:-1]])\n            target_load = total_demand / 2\n            current_load = 0\n            split_pos = 1\n            for i in range(1, len(route)-1):\n                current_load += demand[route[i]]\n                if current_load >= target_load:\n                    split_pos = i\n                    break\n\n            if (sum(demand[route[1:split_pos]]) <= capacity and\n                sum(demand[route[split_pos:-1]]) <= capacity):\n                new_route1 = np.concatenate([route[:split_pos], [0]])\n                new_route2 = np.concatenate([[0], route[split_pos:]])\n                new_solution[route_idx] = new_route1\n                new_solution.insert(route_idx+1, new_route2)\n                break\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n",
        "score": [
            -0.7001265779361955,
            7.887087136507034
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    def dynamic_fitness(solution, objectives):\n        total_dist, makespan = objectives\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n\n        route_loads = [sum(demand[route[1:-1]]) for route in solution]\n        load_balance = 1 - np.std(route_loads) / capacity if len(route_loads) > 1 else 0\n\n        spatial_entropy = 0\n        for route in solution:\n            if len(route) > 2:\n                centroid = np.mean(coords[route[1:-1]], axis=0)\n                distances = [np.linalg.norm(coords[node] - centroid) for node in route[1:-1]]\n                spatial_entropy += np.sum(distances) / len(distances)\n\n        return (0.4 * norm_dist + 0.6 * norm_makespan) * (1 + 0.2 * load_balance + 0.1 * spatial_entropy)\n\n    scored_solutions = [(dynamic_fitness(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.3 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Dynamic reordering with demand-sensitivity\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 3:\n            demand_profile = demand[route[1:-1]]\n            demand_ratio = demand_profile / np.mean(demand_profile)\n            sorted_indices = np.argsort(demand_ratio)[::-1]\n            new_order = route[1:-1][sorted_indices]\n            new_route = np.concatenate([[0], new_order, [0]])\n            if is_feasible(new_route):\n                new_solution[route_idx] = new_route\n\n    # Demand-balanced inter-route swapping\n    route_loads = [sum(demand[route[1:-1]]) for route in new_solution]\n    avg_load = np.mean(route_loads)\n    for i in range(len(new_solution)):\n        for j in range(i+1, len(new_solution)):\n            route_i, route_j = new_solution[i], new_solution[j]\n            load_i, load_j = route_loads[i], route_loads[j]\n            if abs(load_i - load_j) > 0.2 * avg_load:\n                continue\n\n            for a in range(1, len(route_i)-1):\n                for b in range(1, len(route_j)-1):\n                    node_i, node_j = route_i[a], route_j[b]\n                    new_load_i = load_i - demand[node_i] + demand[node_j]\n                    new_load_j = load_j - demand[node_j] + demand[node_i]\n                    if new_load_i <= capacity and new_load_j <= capacity:\n                        new_route_i = np.concatenate([route_i[:a], [node_j], route_i[a+1:]])\n                        new_route_j = np.concatenate([route_j[:b], [node_i], route_j[b+1:]])\n                        if is_feasible(new_route_i) and is_feasible(new_route_j):\n                            new_solution[i] = new_route_i\n                            new_solution[j] = new_route_j\n                            route_loads[i] = new_load_i\n                            route_loads[j] = new_load_j\n                            break\n\n    # Probabilistic route balancing\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4 and random.random() < 0.3:\n            total_demand = sum(demand[route[1:-1]])\n            target_load = total_demand / 2\n            current_load = 0\n            split_pos = 1\n            for i in range(1, len(route)-1):\n                current_load += demand[route[i]]\n                if current_load >= target_load:\n                    split_pos = i\n                    break\n\n            if (sum(demand[route[1:split_pos]]) <= capacity and\n                sum(demand[route[split_pos:-1]]) <= capacity):\n                new_route1 = np.concatenate([route[:split_pos], [0]])\n                new_route2 = np.concatenate([[0], route[split_pos:]])\n                new_solution[route_idx] = new_route1\n                new_solution.insert(route_idx+1, new_route2)\n                break\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Capacitated Vehicle Routing Problem (Bi-CVRP), where a single depot and multiple customers are located in 2D space. Each customer has a positive demand, and all vehicles in the fleet have identical capacity limits. The objective is to construct a set of routes, each starting and ending at the depot, such that all customers are served, vehicle capacities are not exceeded on any route, and two conflicting objectives are minimized: (1) the total travel distance across all routes, and (2) the makespan, defined as the length of the longest individual route. Each solution in the archive is represented as a list of NumPy arrays, where each array denotes a single route (starting and ending with depot index 0), and is paired with a tuple of two objective values (total_distance, makespan). Your task is to implement a function named 'select_neighbor' that selects one promising solution from the archive and apply a novel or hybrid local search operator to generate a feasible neighbor solution from it. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself. Avoid standard methods like pure 2-opt; instead, invent or combine transformations, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. Ensure that the returned neighbor solution remains feasible under the vehicle capacity constraint. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the archive using a hybrid fitness score that prioritizes makespan (70%) over total distance (30%) while incorporating spatial diversity, then applies three adaptive local search operators: capacity-aware route merging, demand-density-based route inversion, and probabilistic spatial-balanced route splitting, all while ensuring feasibility through capacity checks. The approach emphasizes balancing route quality and diversity, with probabilistic elements to explore different neighborhoods while maintaining solution feasibility.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    def hybrid_fitness_score(solution, objectives):\n        total_dist, makespan = objectives\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        spatial_diversity = np.std([np.mean(coords[route[1:-1]], axis=0) for route in solution]) if len(solution) > 1 else 0\n        return (0.3 * norm_dist + 0.7 * norm_makespan) * (1 + 0.3 * spatial_diversity)\n\n    scored_solutions = [(hybrid_fitness_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.2 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Adaptive route clustering with capacity-aware merging\n    route_stats = [(sum(demand[route[1:-1]]), len(route)-2) for route in new_solution]\n    avg_load = np.mean([load for load, _ in route_stats]) if route_stats else 0\n    avg_length = np.mean([length for _, length in route_stats]) if route_stats else 0\n\n    for i in range(len(new_solution)):\n        route_i = new_solution[i]\n        load_i, length_i = route_stats[i]\n        for j in range(i+1, len(new_solution)):\n            route_j = new_solution[j]\n            load_j, length_j = route_stats[j]\n            if abs(load_i - load_j) <= 0.3 * avg_load and abs(length_i - length_j) <= 0.3 * avg_length:\n                if load_i + load_j <= capacity:\n                    min_dist = float('inf')\n                    best_pair = (0, 0)\n                    for a in range(1, len(route_i)-1):\n                        for b in range(1, len(route_j)-1):\n                            dist = distance_matrix[route_i[a]][route_j[b]]\n                            if dist < min_dist:\n                                min_dist = dist\n                                best_pair = (a, b)\n                    merged_route = np.concatenate([route_i[:best_pair[0]+1], route_j[best_pair[1]:-1], route_i[-1:]])\n                    new_solution = [route for idx, route in enumerate(new_solution) if idx not in [i, j]] + [merged_route]\n                    route_stats = [(sum(demand[route[1:-1]]), len(route)-2) for route in new_solution]\n                    break\n\n    # Dynamic route inversion based on demand density\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4:\n            demand_density = np.mean([demand[node] for node in route[1:-1]])\n            high_demand_nodes = [node for node in route[1:-1] if demand[node] > 1.2 * demand_density]\n            if high_demand_nodes and random.random() < 0.4:\n                pos = np.where(route == high_demand_nodes[0])[0][0]\n                if is_feasible(np.concatenate([route[:pos], route[pos:][::-1]])):\n                    new_solution[route_idx] = np.concatenate([route[:pos], route[pos:][::-1]])\n\n    # Probabilistic route splitting with spatial balancing\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 6 and random.random() < 0.4:\n            centroid = np.mean(coords[route[1:-1]], axis=0)\n            farthest_node = max(route[1:-1], key=lambda x: np.linalg.norm(coords[x] - centroid))\n            split_pos = np.where(route == farthest_node)[0][0]\n            if (sum(demand[route[1:split_pos]]) <= capacity and\n                sum(demand[route[split_pos:-1]]) <= capacity and\n                abs(split_pos - len(route)/2) <= 0.4 * len(route)):\n                new_route1 = np.concatenate([route[:split_pos], [0]])\n                new_route2 = np.concatenate([[0], route[split_pos:]])\n                new_solution[route_idx] = new_route1\n                new_solution.insert(route_idx+1, new_route2)\n                break\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 307,
        "algorithm": "The algorithm prioritizes total distance (60%) over makespan (40%) while balancing load across routes, then applies adaptive demand-aware merging of similar routes, probabilistic spatial inversion of far-outlying nodes, and capacity-constrained demand-balanced splitting of overloaded routes, ensuring feasibility through dynamic checks. It intelligently selects solutions from a top 30% fitness-scored subset of the archive for local improvement.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    def distance_fitness_score(solution, objectives):\n        total_dist, makespan = objectives\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        load_balance = np.std([sum(demand[route[1:-1]]) for route in solution]) if len(solution) > 1 else 0\n        return (0.6 * norm_dist + 0.4 * norm_makespan) * (1 - 0.2 * load_balance)\n\n    scored_solutions = [(distance_fitness_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.3 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Adaptive route clustering with demand-aware merging\n    route_stats = [(sum(demand[route[1:-1]]), len(route)-2) for route in new_solution]\n    avg_demand = np.mean([d for d, _ in route_stats]) if route_stats else 0\n    avg_length = np.mean([l for _, l in route_stats]) if route_stats else 0\n\n    for i in range(len(new_solution)):\n        route_i = new_solution[i]\n        demand_i, length_i = route_stats[i]\n        for j in range(i+1, len(new_solution)):\n            route_j = new_solution[j]\n            demand_j, length_j = route_stats[j]\n            if abs(demand_i - demand_j) <= 0.4 * avg_demand and abs(length_i - length_j) <= 0.4 * avg_length:\n                if demand_i + demand_j <= capacity:\n                    min_dist = float('inf')\n                    best_pair = (0, 0)\n                    for a in range(1, len(route_i)-1):\n                        for b in range(1, len(route_j)-1):\n                            dist = distance_matrix[route_i[a]][route_j[b]]\n                            if dist < min_dist:\n                                min_dist = dist\n                                best_pair = (a, b)\n                    merged_route = np.concatenate([route_i[:best_pair[0]+1], route_j[best_pair[1]:-1], route_i[-1:]])\n                    new_solution = [route for idx, route in enumerate(new_solution) if idx not in [i, j]] + [merged_route]\n                    route_stats = [(sum(demand[route[1:-1]]), len(route)-2) for route in new_solution]\n                    break\n\n    # Probabilistic route inversion based on spatial density\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4:\n            spatial_density = np.mean([np.linalg.norm(coords[node] - np.mean(coords[route[1:-1]], axis=0)) for node in route[1:-1]])\n            far_nodes = [node for node in route[1:-1] if np.linalg.norm(coords[node] - np.mean(coords[route[1:-1]], axis=0)) > 1.3 * spatial_density]\n            if far_nodes and random.random() < 0.5:\n                pos = np.where(route == far_nodes[0])[0][0]\n                if is_feasible(np.concatenate([route[:pos], route[pos:][::-1]])):\n                    new_solution[route_idx] = np.concatenate([route[:pos], route[pos:][::-1]])\n\n    # Capacity-constrained route splitting with demand balancing\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 6 and random.random() < 0.5:\n            total_demand = sum(demand[route[1:-1]])\n            split_pos = 1\n            min_diff = float('inf')\n            for pos in range(2, len(route)-1):\n                if sum(demand[route[1:pos]]) <= capacity and sum(demand[route[pos:-1]]) <= capacity:\n                    diff = abs(sum(demand[route[1:pos]]) - total_demand/2)\n                    if diff < min_diff:\n                        min_diff = diff\n                        split_pos = pos\n            if min_diff < 0.3 * total_demand:\n                new_route1 = np.concatenate([route[:split_pos], [0]])\n                new_route2 = np.concatenate([[0], route[split_pos:]])\n                new_solution[route_idx] = new_route1\n                new_solution.insert(route_idx+1, new_route2)\n                break\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n",
        "score": [
            -0.7000468587147147,
            3.0124163031578064
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    def distance_fitness_score(solution, objectives):\n        total_dist, makespan = objectives\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        load_balance = np.std([sum(demand[route[1:-1]]) for route in solution]) if len(solution) > 1 else 0\n        return (0.6 * norm_dist + 0.4 * norm_makespan) * (1 - 0.2 * load_balance)\n\n    scored_solutions = [(distance_fitness_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.3 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Adaptive route clustering with demand-aware merging\n    route_stats = [(sum(demand[route[1:-1]]), len(route)-2) for route in new_solution]\n    avg_demand = np.mean([d for d, _ in route_stats]) if route_stats else 0\n    avg_length = np.mean([l for _, l in route_stats]) if route_stats else 0\n\n    for i in range(len(new_solution)):\n        route_i = new_solution[i]\n        demand_i, length_i = route_stats[i]\n        for j in range(i+1, len(new_solution)):\n            route_j = new_solution[j]\n            demand_j, length_j = route_stats[j]\n            if abs(demand_i - demand_j) <= 0.4 * avg_demand and abs(length_i - length_j) <= 0.4 * avg_length:\n                if demand_i + demand_j <= capacity:\n                    min_dist = float('inf')\n                    best_pair = (0, 0)\n                    for a in range(1, len(route_i)-1):\n                        for b in range(1, len(route_j)-1):\n                            dist = distance_matrix[route_i[a]][route_j[b]]\n                            if dist < min_dist:\n                                min_dist = dist\n                                best_pair = (a, b)\n                    merged_route = np.concatenate([route_i[:best_pair[0]+1], route_j[best_pair[1]:-1], route_i[-1:]])\n                    new_solution = [route for idx, route in enumerate(new_solution) if idx not in [i, j]] + [merged_route]\n                    route_stats = [(sum(demand[route[1:-1]]), len(route)-2) for route in new_solution]\n                    break\n\n    # Probabilistic route inversion based on spatial density\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4:\n            spatial_density = np.mean([np.linalg.norm(coords[node] - np.mean(coords[route[1:-1]], axis=0)) for node in route[1:-1]])\n            far_nodes = [node for node in route[1:-1] if np.linalg.norm(coords[node] - np.mean(coords[route[1:-1]], axis=0)) > 1.3 * spatial_density]\n            if far_nodes and random.random() < 0.5:\n                pos = np.where(route == far_nodes[0])[0][0]\n                if is_feasible(np.concatenate([route[:pos], route[pos:][::-1]])):\n                    new_solution[route_idx] = np.concatenate([route[:pos], route[pos:][::-1]])\n\n    # Capacity-constrained route splitting with demand balancing\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 6 and random.random() < 0.5:\n            total_demand = sum(demand[route[1:-1]])\n            split_pos = 1\n            min_diff = float('inf')\n            for pos in range(2, len(route)-1):\n                if sum(demand[route[1:pos]]) <= capacity and sum(demand[route[pos:-1]]) <= capacity:\n                    diff = abs(sum(demand[route[1:pos]]) - total_demand/2)\n                    if diff < min_diff:\n                        min_diff = diff\n                        split_pos = pos\n            if min_diff < 0.3 * total_demand:\n                new_route1 = np.concatenate([route[:split_pos], [0]])\n                new_route2 = np.concatenate([[0], route[split_pos:]])\n                new_solution[route_idx] = new_route1\n                new_solution.insert(route_idx+1, new_route2)\n                break\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Capacitated Vehicle Routing Problem (Bi-CVRP), where a single depot and multiple customers are located in 2D space. Each customer has a positive demand, and all vehicles in the fleet have identical capacity limits. The objective is to construct a set of routes, each starting and ending at the depot, such that all customers are served, vehicle capacities are not exceeded on any route, and two conflicting objectives are minimized: (1) the total travel distance across all routes, and (2) the makespan, defined as the length of the longest individual route. Each solution in the archive is represented as a list of NumPy arrays, where each array denotes a single route (starting and ending with depot index 0), and is paired with a tuple of two objective values (total_distance, makespan). Your task is to implement a function named 'select_neighbor' that selects one promising solution from the archive and apply a novel or hybrid local search operator to generate a feasible neighbor solution from it. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself. Avoid standard methods like pure 2-opt; instead, invent or combine transformations, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. Ensure that the returned neighbor solution remains feasible under the vehicle capacity constraint. The function should return the new neighbor solution.\n            I have 5 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid fitness score that prioritizes makespan (70%) over total distance (30%) while incorporating spatial diversity, then applies three adaptive local search operators: capacity-aware route merging, demand-density-based route inversion, and probabilistic spatial-balanced route splitting, all while ensuring feasibility through capacity checks. The approach emphasizes balancing route quality and diversity, with probabilistic elements to explore different neighborhoods while maintaining solution feasibility.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    def hybrid_fitness_score(solution, objectives):\n        total_dist, makespan = objectives\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        spatial_diversity = np.std([np.mean(coords[route[1:-1]], axis=0) for route in solution]) if len(solution) > 1 else 0\n        return (0.3 * norm_dist + 0.7 * norm_makespan) * (1 + 0.3 * spatial_diversity)\n\n    scored_solutions = [(hybrid_fitness_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.2 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Adaptive route clustering with capacity-aware merging\n    route_stats = [(sum(demand[route[1:-1]]), len(route)-2) for route in new_solution]\n    avg_load = np.mean([load for load, _ in route_stats]) if route_stats else 0\n    avg_length = np.mean([length for _, length in route_stats]) if route_stats else 0\n\n    for i in range(len(new_solution)):\n        route_i = new_solution[i]\n        load_i, length_i = route_stats[i]\n        for j in range(i+1, len(new_solution)):\n            route_j = new_solution[j]\n            load_j, length_j = route_stats[j]\n            if abs(load_i - load_j) <= 0.3 * avg_load and abs(length_i - length_j) <= 0.3 * avg_length:\n                if load_i + load_j <= capacity:\n                    min_dist = float('inf')\n                    best_pair = (0, 0)\n                    for a in range(1, len(route_i)-1):\n                        for b in range(1, len(route_j)-1):\n                            dist = distance_matrix[route_i[a]][route_j[b]]\n                            if dist < min_dist:\n                                min_dist = dist\n                                best_pair = (a, b)\n                    merged_route = np.concatenate([route_i[:best_pair[0]+1], route_j[best_pair[1]:-1], route_i[-1:]])\n                    new_solution = [route for idx, route in enumerate(new_solution) if idx not in [i, j]] + [merged_route]\n                    route_stats = [(sum(demand[route[1:-1]]), len(route)-2) for route in new_solution]\n                    break\n\n    # Dynamic route inversion based on demand density\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4:\n            demand_density = np.mean([demand[node] for node in route[1:-1]])\n            high_demand_nodes = [node for node in route[1:-1] if demand[node] > 1.2 * demand_density]\n            if high_demand_nodes and random.random() < 0.4:\n                pos = np.where(route == high_demand_nodes[0])[0][0]\n                if is_feasible(np.concatenate([route[:pos], route[pos:][::-1]])):\n                    new_solution[route_idx] = np.concatenate([route[:pos], route[pos:][::-1]])\n\n    # Probabilistic route splitting with spatial balancing\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 6 and random.random() < 0.4:\n            centroid = np.mean(coords[route[1:-1]], axis=0)\n            farthest_node = max(route[1:-1], key=lambda x: np.linalg.norm(coords[x] - centroid))\n            split_pos = np.where(route == farthest_node)[0][0]\n            if (sum(demand[route[1:split_pos]]) <= capacity and\n                sum(demand[route[split_pos:-1]]) <= capacity and\n                abs(split_pos - len(route)/2) <= 0.4 * len(route)):\n                new_route1 = np.concatenate([route[:split_pos], [0]])\n                new_route2 = np.concatenate([[0], route[split_pos:]])\n                new_solution[route_idx] = new_route1\n                new_solution.insert(route_idx+1, new_route2)\n                break\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from an archive using a dynamic fitness score that balances normalized distance and makespan objectives, with added diversity consideration. It then applies a hybrid local search combining spatial-aware route merging (with demand balancing), adaptive route inversion (based on spatial diversity), and probabilistic route splitting (with demand-aware positioning) while ensuring capacity feasibility. The approach prioritizes solutions with moderate makespan (0.6 weight) over total distance (0.4 weight) and emphasizes route balancing through strategic merging and splitting operations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    def dynamic_fitness_score(solution, objectives):\n        total_dist, makespan = objectives\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        diversity_factor = 1 - len(solution) / (max(len(sol) for sol, _ in archive) + 1)\n        return (0.4 * norm_dist + 0.6 * norm_makespan) * (1 + 0.2 * diversity_factor)\n\n    scored_solutions = [(dynamic_fitness_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.3 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Spatial-aware route merging with demand balancing\n    route_stats = [(sum(demand[route[1:-1]]), len(route)-2) for route in new_solution]\n    avg_load = np.mean([load for load, _ in route_stats]) if route_stats else 0\n    avg_length = np.mean([length for _, length in route_stats]) if route_stats else 0\n\n    for i in range(len(new_solution)):\n        route_i = new_solution[i]\n        load_i, length_i = route_stats[i]\n        for j in range(i+1, len(new_solution)):\n            route_j = new_solution[j]\n            load_j, length_j = route_stats[j]\n            if abs(load_i - load_j) <= 0.4 * avg_load and abs(length_i - length_j) <= 0.4 * avg_length:\n                if load_i + load_j <= capacity:\n                    min_dist = float('inf')\n                    best_pair = (0, 0)\n                    for a in range(1, len(route_i)-1):\n                        for b in range(1, len(route_j)-1):\n                            dist = distance_matrix[route_i[a]][route_j[b]]\n                            if dist < min_dist:\n                                min_dist = dist\n                                best_pair = (a, b)\n                    merged_route = np.concatenate([route_i[:best_pair[0]+1], route_j[best_pair[1]:-1], route_i[-1:]])\n                    new_solution = [route for idx, route in enumerate(new_solution) if idx not in [i, j]] + [merged_route]\n                    route_stats = [(sum(demand[route[1:-1]]), len(route)-2) for route in new_solution]\n                    break\n\n    # Adaptive route inversion with spatial diversity\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4:\n            centroid = np.mean(coords[route[1:-1]], axis=0)\n            farthest_node = max(route[1:-1], key=lambda x: np.linalg.norm(coords[x] - centroid))\n            pos = np.where(route == farthest_node)[0][0]\n            inversion_prob = 0.6 if len(route) > 8 else 0.3\n            if random.random() < inversion_prob:\n                if is_feasible(np.concatenate([route[:pos], route[pos:][::-1]])):\n                    new_solution[route_idx] = np.concatenate([route[:pos], route[pos:][::-1]])\n\n    # Probabilistic route splitting with demand-aware positioning\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5 and random.random() < 0.5:\n            load = sum(demand[route[1:-1]])\n            split_pos = random.randint(2, len(route)-3)\n            if (sum(demand[route[1:split_pos]]) <= capacity and\n                sum(demand[route[split_pos:-1]]) <= capacity and\n                abs(sum(demand[route[1:split_pos]]) - 0.5 * load) <= 0.3 * avg_load):\n                new_route1 = np.concatenate([route[:split_pos], [0]])\n                new_route2 = np.concatenate([[0], route[split_pos:]])\n                new_solution[route_idx] = new_route1\n                new_solution.insert(route_idx+1, new_route2)\n                break\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    def adaptive_weighted_score(solution, objectives):\n        total_dist, makespan = objectives\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        weight = 0.5 + 0.3 * (random.random() - 0.5)\n        return weight * norm_dist + (1 - weight) * norm_makespan\n\n    scored_solutions = [(adaptive_weighted_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.25 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Adaptive demand clustering\n    route_demands = [sum(demand[route[1:-1]]) for route in new_solution]\n    avg_demand = np.mean(route_demands) if route_demands else 0\n    demand_threshold = 0.3 * avg_demand\n\n    for i in range(len(new_solution)):\n        route_i = new_solution[i]\n        if len(route_i) > 3:\n            for j in range(i+1, len(new_solution)):\n                route_j = new_solution[j]\n                if abs(sum(demand[route_i[1:-1]]) - sum(demand[route_j[1:-1]])) <= demand_threshold:\n                    if sum(demand[route_i[1:-1]]) + sum(demand[route_j[1:-1]]) <= capacity:\n                        min_dist = float('inf')\n                        best_pair = (0, 0)\n                        for a in range(1, len(route_i)-1):\n                            for b in range(1, len(route_j)-1):\n                                dist = distance_matrix[route_i[a]][route_j[b]]\n                                if dist < min_dist:\n                                    min_dist = dist\n                                    best_pair = (a, b)\n                        merged_route = np.concatenate([route_i[:best_pair[0]+1], route_j[best_pair[1]:-1], route_i[-1:]])\n                        new_solution = [route for idx, route in enumerate(new_solution) if idx not in [i, j]] + [merged_route]\n                        break\n\n    # Spatial-aware route inversion\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5:\n            centroid = np.mean(coords[route[1:-1]], axis=0)\n            farthest_node = max(route[1:-1], key=lambda x: np.linalg.norm(coords[x] - centroid))\n            pos = np.where(route == farthest_node)[0][0]\n            if random.random() < 0.5:\n                if is_feasible(np.concatenate([route[:pos], route[pos:][::-1]])):\n                    new_route = np.concatenate([route[:pos], route[pos:][::-1]])\n                    new_solution[route_idx] = new_route\n\n    # Probabilistic route reshaping\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4 and random.random() < 0.4:\n            split_pos = random.randint(2, len(route)-3)\n            if sum(demand[route[1:split_pos]]) <= capacity and sum(demand[route[split_pos:-1]]) <= capacity:\n                new_route1 = np.concatenate([route[:split_pos], [0]])\n                new_route2 = np.concatenate([[0], route[split_pos:]])\n                new_solution[route_idx] = new_route1\n                new_solution.insert(route_idx+1, new_route2)\n                break\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm adaptively selects a promising solution from the archive using weighted scoring that balances distance and makespan objectives, then applies a hybrid local search combining demand-balanced route reshaping, probabilistic route inversion with capacity checks, and spatial-demand-aware route merging to generate high-quality neighbor solutions while preserving feasibility. It prioritizes solutions with better normalized objective values (with dynamic weights) and focuses on improving routes by splitting, inverting segments, and merging spatially close routes with similar demands.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    def adaptive_weighted_score(solution, objectives):\n        total_dist, makespan = objectives\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        weight = 0.5 + 0.2 * (random.random() - 0.5)  # Dynamic weight between 0.3 and 0.7\n        return weight * norm_dist + (1 - weight) * norm_makespan\n\n    scored_solutions = [(adaptive_weighted_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.3 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Demand-balanced route reshaping\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4:\n            total_route_demand = sum(demand[route[1:-1]])\n            target_demand = total_route_demand / (len(route)-2)\n            max_diff = 0\n            split_pos = -1\n            for i in range(1, len(route)-1):\n                segment_demand = sum(demand[route[1:i]])\n                diff = abs(segment_demand - target_demand * (i-1))\n                if diff > max_diff:\n                    max_diff = diff\n                    split_pos = i\n            if split_pos > 1 and split_pos < len(route)-2:\n                segment1 = route[:split_pos+1]\n                segment2 = np.concatenate([[0], route[split_pos+1:]])\n                if is_feasible(segment1) and is_feasible(segment2):\n                    new_solution[route_idx] = segment1\n                    new_solution.insert(route_idx+1, segment2)\n                    break\n\n    # Probabilistic route inversion with capacity check\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5 and random.random() < 0.4:\n            start = random.randint(1, len(route)-3)\n            end = random.randint(start+1, len(route)-2)\n            if is_feasible(np.concatenate([route[:start], route[start:end][::-1], route[end:]])):\n                new_route = np.concatenate([route[:start], route[start:end][::-1], route[end:]])\n                new_solution[route_idx] = new_route\n\n    # Spatial-demand-aware route merging\n    if len(new_solution) > 1 and random.random() < 0.5:\n        route_centroids = []\n        for route in new_solution:\n            if len(route) > 2:\n                route_coords = coords[route[1:-1]]\n                centroid = np.mean(route_coords, axis=0)\n                total_demand = sum(demand[route[1:-1]])\n                route_centroids.append((centroid, total_demand))\n        if len(route_centroids) > 1:\n            closest_pairs = []\n            for i in range(len(route_centroids)):\n                for j in range(i+1, len(route_centroids)):\n                    dist = np.linalg.norm(route_centroids[i][0] - route_centroids[j][0])\n                    demand_diff = abs(route_centroids[i][1] - route_centroids[j][1])\n                    closest_pairs.append((dist + 0.5*demand_diff, i, j))\n            if closest_pairs:\n                closest_pairs.sort()\n                for _, i, j in closest_pairs[:min(2, len(closest_pairs))]:\n                    route_i = new_solution[i]\n                    route_j = new_solution[j]\n                    if sum(demand[route_i[1:-1]]) + sum(demand[route_j[1:-1]]) <= capacity:\n                        min_dist = float('inf')\n                        best_i, best_j = 0, 0\n                        for a in range(1, len(route_i)-1):\n                            for b in range(1, len(route_j)-1):\n                                dist = distance_matrix[route_i[a]][route_j[b]]\n                                if dist < min_dist:\n                                    min_dist = dist\n                                    best_i, best_j = a, b\n                        merged_route = np.concatenate([route_i[:best_i+1], route_j[best_j:-1], route_i[-1:]])\n                        new_solution[i] = merged_route\n                        new_solution.pop(j)\n                        break\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive (prioritizing non-dominated or slightly dominated solutions) and applies a hybrid local search combining route swapping, demand-aware 2-opt with customer relocations, and adaptive route merging/splitting, while ensuring feasibility through capacity checks. It balances distance and makespan objectives by probabilistically applying these operations and reverting infeasible changes. The approach emphasizes demand-aware transformations and adaptive route adjustments to improve solution quality.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    if len(archive) > 1:\n        # Sort solutions by Pareto dominance and select one\n        sorted_solutions = sorted(archive, key=lambda x: (x[1][0], x[1][1]))\n        # Select a solution that is not too dominated in either objective\n        candidate_indices = [i for i in range(len(sorted_solutions))\n                           if i < len(sorted_solutions)//2 or random.random() < 0.3]\n        selected_idx = random.choice(candidate_indices)\n        base_solution = archive[selected_idx][0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = [route.copy() for route in base_solution]\n\n    # Hybrid local search strategy\n    if random.random() < 0.5:  # Route swapping with demand-aware check\n        if len(new_solution) > 1:\n            i, j = random.sample(range(len(new_solution)), 2)\n            route_i = new_solution[i]\n            route_j = new_solution[j]\n\n            # Check if swapping customers between routes is feasible\n            if (np.sum(demand[route_i[1:-1]]) + np.sum(demand[route_j[1:-1]]) <= 2 * capacity):\n                # Try to swap a segment between routes\n                if len(route_i) > 3 and len(route_j) > 3:\n                    # Select a random segment from each route\n                    seg_i_start = random.randint(1, len(route_i)-3)\n                    seg_i_end = random.randint(seg_i_start, len(route_i)-2)\n                    seg_j_start = random.randint(1, len(route_j)-3)\n                    seg_j_end = random.randint(seg_j_start, len(route_j)-2)\n\n                    # Check capacity constraints\n                    if (np.sum(demand[route_i[seg_i_start:seg_i_end]]) + np.sum(demand[route_j[1:-1]]) <= capacity and\n                        np.sum(demand[route_j[seg_j_start:seg_j_end]]) + np.sum(demand[route_i[1:-1]]) <= capacity):\n                        # Perform the swap\n                        new_route_i = np.concatenate([\n                            route_i[:seg_i_start],\n                            route_j[seg_j_start:seg_j_end],\n                            route_i[seg_i_end:]\n                        ])\n                        new_route_j = np.concatenate([\n                            route_j[:seg_j_start],\n                            route_i[seg_i_start:seg_i_end],\n                            route_j[seg_j_end:]\n                        ])\n\n                        # Update solution\n                        new_solution[i] = new_route_i\n                        new_solution[j] = new_route_j\n    else:  # Intra-route 2-opt with demand-aware relocations\n        if len(new_solution) > 0:\n            route_idx = random.randint(0, len(new_solution)-1)\n            route = new_solution[route_idx].copy()\n\n            if len(route) > 4:\n                # Select two random edges to reverse\n                a = random.randint(1, len(route)-3)\n                b = random.randint(a+1, len(route)-2)\n\n                # Check if reversing this segment is feasible\n                if np.sum(demand[route[a:b]]) == np.sum(demand[route[a:b][::-1]]):\n                    # Perform 2-opt\n                    new_route = np.concatenate([\n                        route[:a],\n                        route[a:b][::-1],\n                        route[b:]\n                    ])\n                    new_solution[route_idx] = new_route\n\n                    # Additional demand-aware relocation\n                    if random.random() < 0.3:\n                        # Try to relocate a customer to a different position\n                        relocate_pos = random.randint(1, len(new_route)-2)\n                        if relocate_pos != a and relocate_pos != b-1:\n                            customer = new_route[relocate_pos]\n                            # Find a better position for this customer\n                            best_pos = relocate_pos\n                            best_dist = float('inf')\n                            for pos in range(1, len(new_route)-1):\n                                if pos != relocate_pos:\n                                    # Check capacity constraint\n                                    if (np.sum(demand[new_route[1:pos]]) + demand[customer] <= capacity and\n                                        np.sum(demand[new_route[pos:-1]]) + demand[customer] <= capacity):\n                                        # Calculate new distance\n                                        prev_node = new_route[pos-1] if pos > 1 else 0\n                                        next_node = new_route[pos] if pos < len(new_route)-1 else 0\n                                        new_dist = (distance_matrix[prev_node][customer] +\n                                                   distance_matrix[customer][next_node] -\n                                                   distance_matrix[prev_node][next_node])\n                                        if new_dist < best_dist:\n                                            best_dist = new_dist\n                                            best_pos = pos\n                            if best_pos != relocate_pos:\n                                # Perform relocation\n                                new_route = np.concatenate([\n                                    new_route[:relocate_pos],\n                                    new_route[relocate_pos+1:]\n                                ])\n                                new_route = np.insert(new_route, best_pos, customer)\n                                new_solution[route_idx] = new_route\n\n    # Adaptive route merging/splitting\n    if len(new_solution) > 1 and random.random() < 0.3:\n        # Try to merge two routes if possible\n        i, j = random.sample(range(len(new_solution)), 2)\n        route_i = new_solution[i]\n        route_j = new_solution[j]\n\n        if (np.sum(demand[route_i[1:-1]]) + np.sum(demand[route_j[1:-1]]) <= capacity):\n            # Check if merging is beneficial\n            dist_before = distance_matrix[route_i[-2]][0] + distance_matrix[route_j[-2]][0]\n            dist_after = distance_matrix[route_i[-2]][route_j[1]] + distance_matrix[route_j[-2]][0]\n\n            if dist_after < dist_before:\n                # Merge routes\n                merged_route = np.concatenate([\n                    route_i[:-1],\n                    route_j[1:]\n                ])\n                # Update solution\n                new_solution[i] = merged_route\n                new_solution.pop(j)\n\n    if random.random() < 0.2 and len(new_solution) < len(demand)-1:\n        # Try to split a route if beneficial\n        route_idx = random.randint(0, len(new_solution)-1)\n        route = new_solution[route_idx]\n\n        if len(route) > 5:\n            # Find a good split point\n            best_split = -1\n            best_diff = float('inf')\n\n            for split in range(2, len(route)-2):\n                # Check capacity constraints for both parts\n                if (np.sum(demand[route[1:split]]) <= capacity and\n                    np.sum(demand[route[split:-1]]) <= capacity):\n                    # Calculate difference in distances\n                    dist_before = (distance_matrix[route[split-1]][route[split]] +\n                                 distance_matrix[route[split]][route[split+1]])\n                    dist_after = (distance_matrix[route[split-1]][0] +\n                                 distance_matrix[0][route[split]] +\n                                 distance_matrix[route[split]][0] +\n                                 distance_matrix[0][route[split+1]])\n                    diff = dist_after - dist_before\n                    if diff < best_diff:\n                        best_diff = diff\n                        best_split = split\n\n            if best_split != -1:\n                # Perform split\n                route1 = np.concatenate([route[:best_split], [0]])\n                route2 = np.concatenate([[0], route[best_split:]])\n                new_solution[route_idx] = route1\n                new_solution.insert(route_idx+1, route2)\n\n    # Ensure all routes are feasible\n    for route in new_solution:\n        if np.sum(demand[route[1:-1]]) > capacity:\n            # If infeasible, revert to original route\n            for i in range(len(new_solution)):\n                if np.array_equal(new_solution[i], route):\n                    new_solution[i] = base_solution[i]\n                    break\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: *Demand-aware clustering, hybrid split-invert, adaptive Pareto weights, capacity-constrained reinsertion*\n- **Advice**: Combine *demand-aware clustering* with *hybrid split-invert* using *adaptive Pareto weights* to balance distance/makespan while ensuring capacity constraints.\n- **Avoid**: Static single-objective swaps; rigid Pareto selection without demand checks; over-reliance on randomness without guided selection.\n- **Explanation**: Hybrid operators dynamically balance objectives by integrating demand-aware reshaping with probabilistic route adjustments, preventing constraint violations and premature convergence.\n\n*(This ensures actionable advice, clear keywords, and explanations tied to the analysis, while avoiding ineffectiveness.)*\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 308,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    def hybrid_pareto_score(solution, objectives):\n        total_dist, makespan = objectives\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        weight = 0.5 + 0.3 * (random.random() - 0.5)\n        diversity = np.std([np.mean(coords[route[1:-1]], axis=0) for route in solution]) if len(solution) > 1 else 0\n        return (weight * norm_dist + (1 - weight) * norm_makespan) * (1 + 0.2 * diversity)\n\n    scored_solutions = [(hybrid_pareto_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.25 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Demand-aware route clustering with adaptive merging\n    route_stats = [(sum(demand[route[1:-1]]), len(route)-2) for route in new_solution]\n    avg_load = np.mean([load for load, _ in route_stats]) if route_stats else 0\n    avg_length = np.mean([length for _, length in route_stats]) if route_stats else 0\n\n    for i in range(len(new_solution)):\n        route_i = new_solution[i]\n        load_i, length_i = route_stats[i]\n        for j in range(i+1, len(new_solution)):\n            route_j = new_solution[j]\n            load_j, length_j = route_stats[j]\n            if abs(load_i - load_j) <= 0.3 * avg_load and abs(length_i - length_j) <= 0.3 * avg_length:\n                if load_i + load_j <= capacity:\n                    min_dist = float('inf')\n                    best_pair = (0, 0)\n                    for a in range(1, len(route_i)-1):\n                        for b in range(1, len(route_j)-1):\n                            dist = distance_matrix[route_i[a]][route_j[b]]\n                            if dist < min_dist:\n                                min_dist = dist\n                                best_pair = (a, b)\n                    merged_route = np.concatenate([route_i[:best_pair[0]+1], route_j[best_pair[1]:-1], route_i[-1:]])\n                    new_solution = [route for idx, route in enumerate(new_solution) if idx not in [i, j]] + [merged_route]\n                    route_stats = [(sum(demand[route[1:-1]]), len(route)-2) for route in new_solution]\n                    break\n\n    # Hybrid split-invert with demand density and spatial awareness\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5:\n            demand_density = np.mean([demand[node] for node in route[1:-1]])\n            high_demand_nodes = [node for node in route[1:-1] if demand[node] > 1.2 * demand_density]\n            if high_demand_nodes and random.random() < 0.5:\n                pos = np.where(route == high_demand_nodes[0])[0][0]\n                if is_feasible(np.concatenate([route[:pos], route[pos:][::-1]])):\n                    new_route = np.concatenate([route[:pos], route[pos:][::-1]])\n                    centroid = np.mean(coords[new_route[1:-1]], axis=0)\n                    farthest_node = max(new_route[1:-1], key=lambda x: np.linalg.norm(coords[x] - centroid))\n                    split_pos = np.where(new_route == farthest_node)[0][0]\n                    if split_pos > 1 and split_pos < len(new_route)-2:\n                        segment1 = np.concatenate([new_route[:split_pos], [0]])\n                        segment2 = np.concatenate([[0], new_route[split_pos:]])\n                        if is_feasible(segment1) and is_feasible(segment2):\n                            new_solution[route_idx] = segment1\n                            new_solution.insert(route_idx+1, segment2)\n\n    # Adaptive Pareto-aware route reshaping\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4 and random.random() < 0.4:\n            total_route_demand = sum(demand[route[1:-1]])\n            target_demand = total_route_demand / (len(route)-2)\n            max_diff = 0\n            split_pos = -1\n            for i in range(1, len(route)-1):\n                segment_demand = sum(demand[route[1:i]])\n                diff = abs(segment_demand - target_demand * (i-1))\n                if diff > max_diff:\n                    max_diff = diff\n                    split_pos = i\n            if split_pos > 1 and split_pos < len(route)-2:\n                segment1 = route[:split_pos+1]\n                segment2 = np.concatenate([[0], route[split_pos+1:]])\n                if is_feasible(segment1) and is_feasible(segment2):\n                    new_solution[route_idx] = segment1\n                    new_solution.insert(route_idx+1, segment2)\n\n    # Capacity-constrained customer reinsertion\n    if len(new_solution) > 1 and random.random() < 0.3:\n        i, j = random.sample(range(len(new_solution)), 2)\n        route_i = new_solution[i]\n        route_j = new_solution[j]\n        if len(route_i) > 3 and len(route_j) > 3:\n            customer = random.choice(route_i[1:-1])\n            if sum(demand[route_j[1:-1]]) + demand[customer] <= capacity:\n                best_pos = -1\n                best_dist = float('inf')\n                for pos in range(1, len(route_j)-1):\n                    prev_node = route_j[pos-1]\n                    next_node = route_j[pos]\n                    new_dist = (distance_matrix[prev_node][customer] +\n                              distance_matrix[customer][next_node] -\n                              distance_matrix[prev_node][next_node])\n                    if new_dist < best_dist:\n                        best_dist = new_dist\n                        best_pos = pos\n                if best_pos != -1:\n                    new_route_i = np.delete(route_i, np.where(route_i == customer)[0][0])\n                    new_route_j = np.insert(route_j, best_pos, customer)\n                    if is_feasible(new_route_i) and is_feasible(new_route_j):\n                        new_solution[i] = new_route_i\n                        new_solution[j] = new_route_j\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n",
        "score": [
            -0.7834690641120865,
            1.684058964252472
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    def hybrid_pareto_score(solution, objectives):\n        total_dist, makespan = objectives\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        weight = 0.5 + 0.3 * (random.random() - 0.5)\n        diversity = np.std([np.mean(coords[route[1:-1]], axis=0) for route in solution]) if len(solution) > 1 else 0\n        return (weight * norm_dist + (1 - weight) * norm_makespan) * (1 + 0.2 * diversity)\n\n    scored_solutions = [(hybrid_pareto_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.25 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Demand-aware route clustering with adaptive merging\n    route_stats = [(sum(demand[route[1:-1]]), len(route)-2) for route in new_solution]\n    avg_load = np.mean([load for load, _ in route_stats]) if route_stats else 0\n    avg_length = np.mean([length for _, length in route_stats]) if route_stats else 0\n\n    for i in range(len(new_solution)):\n        route_i = new_solution[i]\n        load_i, length_i = route_stats[i]\n        for j in range(i+1, len(new_solution)):\n            route_j = new_solution[j]\n            load_j, length_j = route_stats[j]\n            if abs(load_i - load_j) <= 0.3 * avg_load and abs(length_i - length_j) <= 0.3 * avg_length:\n                if load_i + load_j <= capacity:\n                    min_dist = float('inf')\n                    best_pair = (0, 0)\n                    for a in range(1, len(route_i)-1):\n                        for b in range(1, len(route_j)-1):\n                            dist = distance_matrix[route_i[a]][route_j[b]]\n                            if dist < min_dist:\n                                min_dist = dist\n                                best_pair = (a, b)\n                    merged_route = np.concatenate([route_i[:best_pair[0]+1], route_j[best_pair[1]:-1], route_i[-1:]])\n                    new_solution = [route for idx, route in enumerate(new_solution) if idx not in [i, j]] + [merged_route]\n                    route_stats = [(sum(demand[route[1:-1]]), len(route)-2) for route in new_solution]\n                    break\n\n    # Hybrid split-invert with demand density and spatial awareness\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5:\n            demand_density = np.mean([demand[node] for node in route[1:-1]])\n            high_demand_nodes = [node for node in route[1:-1] if demand[node] > 1.2 * demand_density]\n            if high_demand_nodes and random.random() < 0.5:\n                pos = np.where(route == high_demand_nodes[0])[0][0]\n                if is_feasible(np.concatenate([route[:pos], route[pos:][::-1]])):\n                    new_route = np.concatenate([route[:pos], route[pos:][::-1]])\n                    centroid = np.mean(coords[new_route[1:-1]], axis=0)\n                    farthest_node = max(new_route[1:-1], key=lambda x: np.linalg.norm(coords[x] - centroid))\n                    split_pos = np.where(new_route == farthest_node)[0][0]\n                    if split_pos > 1 and split_pos < len(new_route)-2:\n                        segment1 = np.concatenate([new_route[:split_pos], [0]])\n                        segment2 = np.concatenate([[0], new_route[split_pos:]])\n                        if is_feasible(segment1) and is_feasible(segment2):\n                            new_solution[route_idx] = segment1\n                            new_solution.insert(route_idx+1, segment2)\n\n    # Adaptive Pareto-aware route reshaping\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4 and random.random() < 0.4:\n            total_route_demand = sum(demand[route[1:-1]])\n            target_demand = total_route_demand / (len(route)-2)\n            max_diff = 0\n            split_pos = -1\n            for i in range(1, len(route)-1):\n                segment_demand = sum(demand[route[1:i]])\n                diff = abs(segment_demand - target_demand * (i-1))\n                if diff > max_diff:\n                    max_diff = diff\n                    split_pos = i\n            if split_pos > 1 and split_pos < len(route)-2:\n                segment1 = route[:split_pos+1]\n                segment2 = np.concatenate([[0], route[split_pos+1:]])\n                if is_feasible(segment1) and is_feasible(segment2):\n                    new_solution[route_idx] = segment1\n                    new_solution.insert(route_idx+1, segment2)\n\n    # Capacity-constrained customer reinsertion\n    if len(new_solution) > 1 and random.random() < 0.3:\n        i, j = random.sample(range(len(new_solution)), 2)\n        route_i = new_solution[i]\n        route_j = new_solution[j]\n        if len(route_i) > 3 and len(route_j) > 3:\n            customer = random.choice(route_i[1:-1])\n            if sum(demand[route_j[1:-1]]) + demand[customer] <= capacity:\n                best_pos = -1\n                best_dist = float('inf')\n                for pos in range(1, len(route_j)-1):\n                    prev_node = route_j[pos-1]\n                    next_node = route_j[pos]\n                    new_dist = (distance_matrix[prev_node][customer] +\n                              distance_matrix[customer][next_node] -\n                              distance_matrix[prev_node][next_node])\n                    if new_dist < best_dist:\n                        best_dist = new_dist\n                        best_pos = pos\n                if best_pos != -1:\n                    new_route_i = np.delete(route_i, np.where(route_i == customer)[0][0])\n                    new_route_j = np.insert(route_j, best_pos, customer)\n                    if is_feasible(new_route_i) and is_feasible(new_route_j):\n                        new_solution[i] = new_route_i\n                        new_solution[j] = new_route_j\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Capacitated Vehicle Routing Problem (Bi-CVRP), where a single depot and multiple customers are located in 2D space. Each customer has a positive demand, and all vehicles in the fleet have identical capacity limits. The objective is to construct a set of routes, each starting and ending at the depot, such that all customers are served, vehicle capacities are not exceeded on any route, and two conflicting objectives are minimized: (1) the total travel distance across all routes, and (2) the makespan, defined as the length of the longest individual route. Each solution in the archive is represented as a list of NumPy arrays, where each array denotes a single route (starting and ending with depot index 0), and is paired with a tuple of two objective values (total_distance, makespan). Your task is to implement a function named 'select_neighbor' that selects one promising solution from the archive and apply a novel or hybrid local search operator to generate a feasible neighbor solution from it. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself. Avoid standard methods like pure 2-opt; instead, invent or combine transformations, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. Ensure that the returned neighbor solution remains feasible under the vehicle capacity constraint. The function should return the new neighbor solution.\n        I have 6 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive Pareto scoring with a hybrid local search strategy that prioritizes demand-balanced route merging while probabilistically applying route inversion to improve both distance and makespan objectives, all while maintaining feasibility through capacity-aware operations. It first selects promising solutions based on normalized objective trade-offs, then applies dynamic route reshaping (inversion and merging) to balance objectives, with special attention to spatially close and demand-complementary routes. The algorithm emphasizes capacity constraints through rigorous checks during route modifications and splitting.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    def adaptive_pareto_score(solution, objectives):\n        total_dist, makespan = objectives\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        weight = 0.5 + 0.3 * (random.random() - 0.5)\n        return weight * norm_dist + (1 - weight) * norm_makespan\n\n    scored_solutions = [(adaptive_pareto_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.4 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Dynamic Pareto-aware route inversion\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5 and random.random() < 0.5:\n            start = random.randint(1, len(route)-3)\n            end = random.randint(start+1, len(route)-2)\n            inverted_segment = route[start:end][::-1]\n            if is_feasible(np.concatenate([route[:start], inverted_segment, route[end:]])):\n                new_route = np.concatenate([route[:start], inverted_segment, route[end:]])\n                new_solution[route_idx] = new_route\n\n    # Adaptive demand-centric clustering\n    if len(new_solution) > 1 and random.random() < 0.6:\n        route_demands = [sum(demand[route[1:-1]]) for route in new_solution]\n        route_centroids = []\n        for route in new_solution:\n            if len(route) > 2:\n                route_coords = coords[route[1:-1]]\n                centroid = np.mean(route_coords, axis=0)\n                route_centroids.append(centroid)\n\n        if len(route_centroids) > 1:\n            closest_pairs = []\n            for i in range(len(route_centroids)):\n                for j in range(i+1, len(route_centroids)):\n                    dist = np.linalg.norm(route_centroids[i] - route_centroids[j])\n                    demand_diff = abs(route_demands[i] - route_demands[j])\n                    closest_pairs.append((dist + 0.3*demand_diff, i, j))\n\n            if closest_pairs:\n                closest_pairs.sort()\n                for _, i, j in closest_pairs[:min(2, len(closest_pairs))]:\n                    route_i = new_solution[i]\n                    route_j = new_solution[j]\n                    if sum(demand[route_i[1:-1]]) + sum(demand[route_j[1:-1]]) <= capacity:\n                        min_dist = float('inf')\n                        best_i, best_j = 0, 0\n                        for a in range(1, len(route_i)-1):\n                            for b in range(1, len(route_j)-1):\n                                dist = distance_matrix[route_i[a]][route_j[b]]\n                                if dist < min_dist:\n                                    min_dist = dist\n                                    best_i, best_j = a, b\n                        merged_route = np.concatenate([route_i[:best_i+1], route_j[best_j:-1], route_i[-1:]])\n                        new_solution[i] = merged_route\n                        new_solution.pop(j)\n                        break\n\n    # Capacity-aware route splitting\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4 and sum(demand[route[1:-1]]) > 0.8 * capacity:\n            split_pos = random.randint(2, len(route)-3)\n            segment1 = route[:split_pos+1]\n            segment2 = np.concatenate([[0], route[split_pos+1:]])\n            if is_feasible(segment1) and is_feasible(segment2):\n                new_solution[route_idx] = segment1\n                new_solution.insert(route_idx+1, segment2)\n                break\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm implements a novel hybrid local search strategy that combines adaptive spatial-demand clustering with probabilistic route inversion and segment swapping, while dynamically balancing distance and makespan objectives through an oscillating weighting scheme and ensuring feasibility through capacity-aware route modifications and splitting. It prioritizes solutions with better normalized objective scores, applies spatial clustering to merge similar routes, probabilistically inverts route segments, swaps segments between routes while maintaining capacity, and splits overloaded routes for better demand balance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    def dynamic_weighting(solution, objectives):\n        total_dist, makespan = objectives\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        weight = 0.3 + 0.3 * (np.sin(len(archive) / 10) + 1)  # Oscillating weight between 0.3 and 0.6\n        return weight * norm_dist + (1 - weight) * norm_makespan\n\n    scored_solutions = [(dynamic_weighting(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.4 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Adaptive spatial-demand clustering\n    if len(new_solution) > 1 and random.random() < 0.5:\n        route_data = []\n        for route in new_solution:\n            if len(route) > 2:\n                route_coords = coords[route[1:-1]]\n                centroid = np.mean(route_coords, axis=0)\n                total_demand = sum(demand[route[1:-1]])\n                route_data.append((centroid, total_demand, route))\n\n        if len(route_data) > 1:\n            clusters = []\n            while len(route_data) > 0:\n                base = route_data.pop(0)\n                cluster = [base]\n                i = 0\n                while i < len(route_data):\n                    centroid, demand_val, _ = route_data[i]\n                    dist = np.linalg.norm(base[0] - centroid)\n                    demand_diff = abs(base[1] - demand_val)\n                    if dist < 1.2 * np.mean(distance_matrix) and demand_diff < 0.4 * capacity:\n                        cluster.append(route_data.pop(i))\n                    else:\n                        i += 1\n                clusters.append(cluster)\n\n            for cluster in clusters:\n                if len(cluster) > 1:\n                    for i in range(len(cluster)-1):\n                        for j in range(i+1, len(cluster)):\n                            route_i = cluster[i][2]\n                            route_j = cluster[j][2]\n                            if sum(demand[route_i[1:-1]]) + sum(demand[route_j[1:-1]]) <= capacity:\n                                min_dist = float('inf')\n                                best_i, best_j = 0, 0\n                                for a in range(1, len(route_i)-1):\n                                    for b in range(1, len(route_j)-1):\n                                        dist = distance_matrix[route_i[a]][route_j[b]]\n                                        if dist < min_dist:\n                                            min_dist = dist\n                                            best_i, best_j = a, b\n                                merged_route = np.concatenate([route_i[:best_i+1], route_j[best_j:-1], route_i[-1:]])\n                                new_solution = [r for r in new_solution if not np.array_equal(r, route_i) and not np.array_equal(r, route_j)]\n                                new_solution.append(merged_route)\n                                break\n\n    # Probabilistic route inversion with capacity check\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5 and random.random() < 0.4:\n            start = random.randint(1, len(route)-3)\n            end = random.randint(start+1, len(route)-2)\n            inverted_segment = route[start:end][::-1]\n            if is_feasible(np.concatenate([route[:start], inverted_segment, route[end:]])):\n                new_route = np.concatenate([route[:start], inverted_segment, route[end:]])\n                new_solution[route_idx] = new_route\n\n    # Segment swapping with demand balance consideration\n    if len(new_solution) > 1 and random.random() < 0.6:\n        i, j = random.sample(range(len(new_solution)), 2)\n        route_i = new_solution[i]\n        route_j = new_solution[j]\n\n        if len(route_i) > 3 and len(route_j) > 3:\n            seg_i_start = random.randint(1, len(route_i)-3)\n            seg_i_end = random.randint(seg_i_start, len(route_i)-2)\n            seg_j_start = random.randint(1, len(route_j)-3)\n            seg_j_end = random.randint(seg_j_start, len(route_j)-2)\n\n            demand_i = sum(demand[route_i[seg_i_start:seg_i_end]])\n            demand_j = sum(demand[route_j[seg_j_start:seg_j_end]])\n\n            if (sum(demand[route_i[1:-1]]) - demand_i + demand_j <= capacity and\n                sum(demand[route_j[1:-1]]) - demand_j + demand_i <= capacity):\n\n                new_route_i = np.concatenate([\n                    route_i[:seg_i_start],\n                    route_j[seg_j_start:seg_j_end],\n                    route_i[seg_i_end:]\n                ])\n                new_route_j = np.concatenate([\n                    route_j[:seg_j_start],\n                    route_i[seg_i_start:seg_i_end],\n                    route_j[seg_j_end:]\n                ])\n\n                if is_feasible(new_route_i) and is_feasible(new_route_j):\n                    new_solution[i] = new_route_i\n                    new_solution[j] = new_route_j\n\n    # Capacity-aware route splitting with demand balancing\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4 and sum(demand[route[1:-1]]) > 0.7 * capacity:\n            total_demand = sum(demand[route[1:-1]])\n            best_split = None\n            min_diff = float('inf')\n            for i in range(2, len(route)-2):\n                segment_demand = sum(demand[route[1:i]])\n                remaining_demand = total_demand - segment_demand\n                current_diff = abs(segment_demand - remaining_demand)\n                if current_diff < min_diff:\n                    min_diff = current_diff\n                    best_split = i\n            if best_split and min_diff < capacity * 0.3:\n                segment1 = route[:best_split+1]\n                segment2 = np.concatenate([[0], route[best_split+1:]])\n                if is_feasible(segment1) and is_feasible(segment2):\n                    new_solution[route_idx] = segment1\n                    new_solution.insert(route_idx+1, segment2)\n                    break\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm implements a hybrid local search strategy that combines adaptive demand-aware route splitting, spatial-proximity guided demand-balanced reinsertion, and dynamic capacity-balanced route reshaping, prioritizing solutions with balanced distance and makespan objectives while ensuring capacity feasibility. It intelligently selects promising solutions from the archive using an adaptive weighted scoring mechanism, then applies probabilistic route transformations to improve both objectives. The method dynamically balances exploration and exploitation through weighted selection and conditional probabilistic operations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    def adaptive_weighted_score(sol, obj):\n        total_dist, makespan = obj\n        max_dist = max(o[0] for _, o in archive)\n        max_makespan = max(o[1] for _, o in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        weight = 0.5 + 0.3 * (random.random() - 0.5)\n        return (1 - weight) * norm_dist + weight * norm_makespan\n\n    scored_solutions = [(adaptive_weighted_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.3 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Demand-aware route splitting with probabilistic inversion\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4 and random.random() < 0.6:\n            customers = route[1:-1]\n            demands = demand[customers]\n            supply = np.cumsum(demands)\n            target_supply = supply[-1] / 2\n\n            split_pos = np.argmin(np.abs(supply - target_supply)) + 1\n            segment1 = route[:split_pos+1]\n            segment2 = np.concatenate([[0], route[split_pos+1:]])\n\n            if is_feasible(segment1) and is_feasible(segment2):\n                if random.random() < 0.4:\n                    segment2 = np.concatenate([[0], segment2[-2:0:-1], segment2[-1:]])\n                new_solution[route_idx] = segment1\n                new_solution.insert(route_idx+1, segment2)\n                break\n\n    # Spatial-proximity guided demand-balanced reinsertion\n    if len(new_solution) > 1 and random.random() < 0.7:\n        source_idx = random.randint(0, len(new_solution)-1)\n        target_idx = random.randint(0, len(new_solution)-1)\n        if source_idx != target_idx:\n            source_route = new_solution[source_idx]\n            target_route = new_solution[target_idx]\n\n            if len(source_route) > 3:\n                customer_pos = random.randint(1, len(source_route)-2)\n                customer = source_route[customer_pos]\n\n                if sum(demand[target_route[1:-1]]) + demand[customer] <= capacity:\n                    new_source = np.concatenate([source_route[:customer_pos], source_route[customer_pos+1:]])\n                    best_pos = 1\n                    min_increase = float('inf')\n\n                    for pos in range(1, len(target_route)):\n                        new_target = np.concatenate([target_route[:pos], [customer], target_route[pos:]])\n                        dist_increase = (distance_matrix[target_route[pos-1]][customer] +\n                                        distance_matrix[customer][target_route[pos]] -\n                                        distance_matrix[target_route[pos-1]][target_route[pos]])\n\n                        if dist_increase < min_increase:\n                            min_increase = dist_increase\n                            best_pos = pos\n\n                    new_target = np.concatenate([target_route[:best_pos], [customer], target_route[best_pos:]])\n\n                    if is_feasible(new_source) and is_feasible(new_target):\n                        new_solution[source_idx] = new_source\n                        new_solution[target_idx] = new_target\n\n    # Dynamic capacity-balanced route reshaping\n    if len(new_solution) > 1 and random.random() < 0.5:\n        route_stats = []\n        for route in new_solution:\n            if len(route) > 2:\n                total_demand = sum(demand[route[1:-1]])\n                route_stats.append((total_demand, route))\n\n        if len(route_stats) > 1:\n            route_stats.sort(key=lambda x: x[0])\n            for i in range(len(route_stats)-1):\n                j = len(route_stats)-1-i\n                if i >= j:\n                    break\n\n                route_i = route_stats[i][1]\n                route_j = route_stats[j][1]\n\n                if sum(demand[route_i[1:-1]]) + sum(demand[route_j[1:-1]]) <= capacity:\n                    merged_route = np.concatenate([route_i[:-1], route_j[1:]])\n\n                    if is_feasible(merged_route):\n                        new_solution = [r for r in new_solution if not np.array_equal(r, route_i) and not np.array_equal(r, route_j)]\n                        new_solution.append(merged_route)\n                        break\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive route segmentation with demand-aware reinsertion, prioritizing spatial proximity and demand balance to generate high-quality neighbor solutions while maintaining capacity constraints. It first selects promising solutions from the archive using an adaptive weighted scoring that balances distance and makespan objectives, then dynamically splits routes based on spatial centroids and demand distribution, followed by capacity-constrained reinsertion of segments into spatially nearby routes to improve both objectives. The method emphasizes spatial-demand-aware splitting and probabilistic reinsertion to explore the solution space effectively.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    def adaptive_weighted_score(sol, obj):\n        total_dist, makespan = obj\n        max_dist = max(o[0] for _, o in archive)\n        max_makespan = max(o[1] for _, o in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        weight = 0.5 + 0.3 * (random.random() - 0.5)\n        return weight * norm_dist + (1 - weight) * norm_makespan\n\n    scored_solutions = [(adaptive_weighted_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.3 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Spatial-demand-aware route segmentation\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 3 and random.random() < 0.6:\n            customers = route[1:-1]\n            route_coords = coords[customers]\n            centroid = np.mean(route_coords, axis=0)\n            dists = np.linalg.norm(route_coords - centroid, axis=1)\n            demands = demand[customers]\n\n            # Split based on spatial proximity and demand balance\n            split_pos = np.argmax(dists) + 1 if random.random() < 0.7 else np.argmin(demands) + 1\n            segment1 = route[:split_pos+1]\n            segment2 = np.concatenate([[0], route[split_pos+1:]])\n\n            if is_feasible(segment1) and is_feasible(segment2):\n                new_solution[route_idx] = segment1\n                new_solution.insert(route_idx+1, segment2)\n                break\n\n    # Capacity-constrained reinsertion with spatial proximity\n    if len(new_solution) > 1 and random.random() < 0.5:\n        # Select a random segment to reinsert\n        source_route_idx = random.randint(0, len(new_solution)-1)\n        source_route = new_solution[source_route_idx]\n        if len(source_route) > 3:\n            start = random.randint(1, len(source_route)-3)\n            end = random.randint(start+1, len(source_route)-2)\n            segment = source_route[start:end+1]\n            segment_demand = sum(demand[segment[1:-1]])\n\n            # Find target route with spatial proximity\n            source_centroid = np.mean(coords[source_route[1:-1]], axis=0)\n            closest_route_idx = -1\n            min_dist = float('inf')\n            for i, route in enumerate(new_solution):\n                if i != source_route_idx and len(route) > 1:\n                    route_centroid = np.mean(coords[route[1:-1]], axis=0)\n                    dist = np.linalg.norm(source_centroid - route_centroid)\n                    if dist < min_dist:\n                        min_dist = dist\n                        closest_route_idx = i\n\n            if closest_route_idx != -1 and sum(demand[new_solution[closest_route_idx][1:-1]]) + segment_demand <= capacity:\n                # Find best insertion point\n                best_pos = 1\n                best_cost = float('inf')\n                target_route = new_solution[closest_route_idx]\n                for i in range(1, len(target_route)):\n                    cost = distance_matrix[target_route[i-1]][segment[1]] + distance_matrix[segment[-2]][target_route[i]]\n                    if cost < best_cost:\n                        best_cost = cost\n                        best_pos = i\n\n                # Perform reinsertion\n                new_route = np.concatenate([target_route[:best_pos], segment, target_route[best_pos:]])\n                new_solution[closest_route_idx] = new_route\n                new_solution[source_route_idx] = np.concatenate([source_route[:start], source_route[end+1:]])\n\n                # Remove empty routes\n                new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm combines centroid-based route clustering with adaptive demand-sensitive operations, prioritizing spatial proximity (40%) and demand balance (60%) for merging, while using demand imbalance (60%) and capacity utilization (40%) to guide splitting and inversion. It dynamically adjusts routes by merging spatially close routes with complementary demands, splitting imbalanced routes, and inverting routes with high demand imbalance, all while maintaining feasibility. The selection process balances normalized distance (50%), makespan (40%), and spatial variance (30%) to identify promising solutions for further optimization.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    def multi_objective_selection(solutions, objectives):\n        norm_dist = (objectives[0] - min(obj[0] for _, obj in archive)) / (max(obj[0] for _, obj in archive) - min(obj[0] for _, obj in archive) + 1e-6)\n        norm_makespan = (objectives[1] - min(obj[1] for _, obj in archive)) / (max(obj[1] for _, obj in archive) - min(obj[1] for _, obj in archive) + 1e-6)\n        spatial_variance = np.std([np.mean(coords[route[1:-1]], axis=0) for route in solutions])\n        return 0.5 * norm_dist + 0.4 * norm_makespan + 0.3 * (1 - spatial_variance / np.max(np.std(coords, axis=0)))\n\n    scored_solutions = [(multi_objective_selection(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    selection_pool = scored_solutions[:max(1, int(0.3 * len(scored_solutions)))]\n    selected_solution = random.choice([sol for _, sol in selection_pool])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    # Spatial-aware route clustering with demand constraints\n    route_centroids = []\n    for route in new_solution:\n        if len(route) > 2:\n            centroid = np.mean(coords[route[1:-1]], axis=0)\n            route_centroids.append((centroid, route))\n\n    for i in range(len(route_centroids)):\n        for j in range(i+1, len(route_centroids)):\n            centroid_i, route_i = route_centroids[i]\n            centroid_j, route_j = route_centroids[j]\n            spatial_dist = np.linalg.norm(centroid_i - centroid_j)\n            demand_i = sum(demand[route_i[1:-1]])\n            demand_j = sum(demand[route_j[1:-1]])\n\n            if demand_i + demand_j <= capacity:\n                merge_prob = 0.4 * (1 - spatial_dist/np.max(distance_matrix)) + 0.6 * (1 - abs(demand_i - demand_j)/max(demand_i, demand_j))\n                if random.random() < merge_prob:\n                    # Find best insertion points\n                    min_dist = float('inf')\n                    best_pair = (0, 0)\n                    for a in range(1, len(route_i)-1):\n                        for b in range(1, len(route_j)-1):\n                            dist = distance_matrix[route_i[a]][route_j[b]] * (1 + 0.2 * abs(demand[route_i[a]] - demand[route_j[b]])/capacity)\n                            if dist < min_dist:\n                                min_dist = dist\n                                best_pair = (a, b)\n                    merged_route = np.concatenate([route_i[:best_pair[0]+1], route_j[best_pair[1]:-1], route_i[-1:]])\n                    new_solution = [route for idx, route in enumerate(new_solution) if idx not in [i, j]] + [merged_route]\n                    break\n\n    # Adaptive demand-sensitive splitting\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5:\n            total_demand = sum(demand[route[1:-1]])\n            split_candidates = []\n            for pos in range(2, len(route)-2):\n                left_demand = sum(demand[route[1:pos]])\n                right_demand = total_demand - left_demand\n                demand_balance = 1 - abs(left_demand - right_demand)/total_demand\n                left_centroid = np.mean(coords[route[1:pos]], axis=0)\n                right_centroid = np.mean(coords[route[pos:-1]], axis=0)\n                spatial_separation = np.linalg.norm(left_centroid - right_centroid)\n                split_score = 0.7 * demand_balance + 0.3 * (spatial_separation / np.max(distance_matrix))\n                split_candidates.append((split_score, pos))\n\n            if split_candidates:\n                split_candidates.sort(reverse=True, key=lambda x: x[0])\n                best_pos = split_candidates[0][1]\n                if sum(demand[route[1:best_pos]]) <= capacity and sum(demand[route[best_pos:-1]]) <= capacity:\n                    new_route1 = np.concatenate([route[:best_pos], [0]])\n                    new_route2 = np.concatenate([[0], route[best_pos:]])\n                    new_solution[route_idx] = new_route1\n                    new_solution.insert(route_idx+1, new_route2)\n                    break\n\n    # Demand-balanced route inversion\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 4:\n            demand_profile = np.cumsum(demand[route[1:-1]])\n            total_demand = demand_profile[-1]\n            imbalance = max(demand_profile) - min(demand_profile)\n            inversion_prob = 0.6 * (imbalance/total_demand) + 0.4 * (1 - sum(demand[route[1:-1]])/capacity)\n            if inversion_prob > 0.8 and random.random() < 0.6:\n                farthest_node = max(route[1:-1], key=lambda x: np.linalg.norm(coords[x] - np.mean(coords[route[1:-1]], axis=0)))\n                pos = np.where(route == farthest_node)[0][0]\n                inverted_route = np.concatenate([route[:pos], route[pos:][::-1]])\n                if sum(demand[inverted_route[1:-1]]) <= capacity:\n                    new_solution[route_idx] = inverted_route\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n\nNo. 6 algorithm's description and the corresponding code are:\nThe algorithm combines demand-aware route partitioning, spatial-demand correlation analysis, adaptive route fusion, and probabilistic route rebalancing to generate high-quality neighbors by prioritizing under-explored regions of the Pareto front, focusing on demand distribution and spatial proximity while maintaining feasibility through dynamic capacity checks. It intelligently selects solutions with lower Pareto front coverage scores and applies probabilistic transformations to balance route lengths and demands, with higher emphasis on demand-aware partitioning and spatial correlation analysis.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    def pareto_distance_score(solution, objectives):\n        total_dist, makespan = objectives\n        min_dist = min(obj[0] for _, obj in archive)\n        min_makespan = min(obj[1] for _, obj in archive)\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n\n        norm_dist = (total_dist - min_dist) / (max_dist - min_dist + 1e-6)\n        norm_makespan = (makespan - min_makespan) / (max_makespan - min_makespan + 1e-6)\n\n        crowding_dist = np.sqrt(norm_dist**2 + norm_makespan**2)\n        return crowding_dist\n\n    scored_solutions = [(pareto_distance_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    bottom_k = max(1, int(0.3 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[-bottom_k:]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Demand-aware route partitioning\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5:\n            demands = demand[route[1:-1]]\n            sorted_indices = np.argsort(demands)\n            partition_size = max(1, len(sorted_indices) // 2)\n            for i in range(0, len(sorted_indices), partition_size):\n                partition = sorted_indices[i:i+partition_size]\n                if len(partition) > 1 and random.random() < 0.5:\n                    segment = route[1:-1][partition]\n                    if sum(demands[partition]) <= capacity:\n                        new_route = np.concatenate([[0], segment, [0]])\n                        if is_feasible(new_route):\n                            new_solution[route_idx] = new_route\n                            break\n\n    # Spatial-demand correlation analysis\n    if len(new_solution) > 1 and random.random() < 0.6:\n        route_stats = []\n        for route in new_solution:\n            if len(route) > 2:\n                route_coords = coords[route[1:-1]]\n                centroid = np.mean(route_coords, axis=0)\n                demand_density = sum(demand[route[1:-1]]) / len(route_coords)\n                route_stats.append((centroid, demand_density))\n\n        if len(route_stats) > 1:\n            correlation_pairs = []\n            for i in range(len(route_stats)):\n                for j in range(i+1, len(route_stats)):\n                    spatial_dist = np.linalg.norm(route_stats[i][0] - route_stats[j][0])\n                    demand_diff = abs(route_stats[i][1] - route_stats[j][1])\n                    correlation_pairs.append((spatial_dist * (1 + demand_diff), i, j))\n\n            if correlation_pairs:\n                correlation_pairs.sort()\n                for _, i, j in correlation_pairs[:min(3, len(correlation_pairs))]:\n                    route_i = new_solution[i]\n                    route_j = new_solution[j]\n                    if sum(demand[route_i[1:-1]]) + sum(demand[route_j[1:-1]]) <= capacity:\n                        merged_route = np.concatenate([route_i[:-1], route_j[1:]])\n                        if is_feasible(merged_route):\n                            new_solution[i] = merged_route\n                            new_solution.pop(j)\n                            break\n\n    # Adaptive route fusion\n    if len(new_solution) > 1 and random.random() < 0.4:\n        route_lengths = [len(route) for route in new_solution]\n        long_routes = [i for i, l in enumerate(route_lengths) if l > 4]\n        if long_routes:\n            route_idx = random.choice(long_routes)\n            route = new_solution[route_idx]\n            best_split = -1\n            best_improvement = 0\n\n            for split in range(3, len(route)-3):\n                part1 = route[:split+1]\n                part2 = np.concatenate([[0], route[split+1:]])\n                if is_feasible(part1) and is_feasible(part2):\n                    current_length = distance_matrix[route[:-1], route[1:]].sum()\n                    new_length = (distance_matrix[part1[:-1], part1[1:]].sum() +\n                                 distance_matrix[part2[:-1], part2[1:]].sum())\n                    improvement = current_length - new_length\n                    if improvement > best_improvement:\n                        best_improvement = improvement\n                        best_split = split\n\n            if best_split != -1:\n                part1 = route[:best_split+1]\n                part2 = np.concatenate([[0], route[best_split+1:]])\n                new_solution[route_idx] = part1\n                new_solution.insert(route_idx+1, part2)\n\n    # Probabilistic route rebalancing\n    if random.random() < 0.5 and len(new_solution) < len(demand)-1:\n        route_idx = random.randint(0, len(new_solution)-1)\n        route = new_solution[route_idx]\n\n        if len(route) > 4:\n            current_demand = sum(demand[route[1:-1]])\n            target_demand = capacity * 0.7\n            if current_demand > target_demand:\n                excess = current_demand - target_demand\n                candidates = [i for i in range(1, len(route)-1) if demand[route[i]] <= excess]\n\n                if candidates:\n                    node_idx = random.choice(candidates)\n                    new_route = np.concatenate([route[:node_idx+1], [0], route[node_idx+1:]])\n                    if is_feasible(new_route[:-1]) and is_feasible(np.concatenate([[0], new_route[node_idx+1:]])):\n                        new_solution[route_idx] = new_route[:-1]\n                        new_solution.insert(route_idx+1, np.concatenate([[0], new_route[node_idx+1:]]))\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s the refined self-reflection with four clear bullet points:\n\n- **Keywords**: *Demand-aware clustering, hybrid split-invert, adaptive Pareto weights, capacity-constrained reinsertion*\n- **Advice**: Combine *demand-aware clustering* with *hybrid split-invert* using *adaptive Pareto weights* to balance distance/makespan while ensuring capacity constraints.\n- **Avoid**: Static single-objective swaps; rigid Pareto selection without demand checks; over-reliance on randomness without guided selection.\n- **Explanation**: Hybrid operators dynamically balance objectives by integrating demand-aware reshaping with probabilistic route adjustments, preventing constraint violations and premature convergence.\n\n*(This ensures actionable advice, clear keywords, and explanations tied to the analysis, while avoiding ineffectiveness.)*\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 309,
        "algorithm": "This algorithm combines adaptive Pareto-weighted selection with hybrid demand-aware clustering, split-invert operations, and capacity-constrained reinsertion to balance distance and makespan objectives while maintaining feasibility. It prioritizes solutions with better normalized objective scores, dynamically adjusts weights between objectives, and uses demand-sensitive clustering to merge routes when feasible, while probabilistically applying split-invert operations and reinsertion to improve solutions. The critical design ideas are the adaptive Pareto weighting, demand-aware clustering, and capacity-constrained operations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    def adaptive_pareto_weight(solution, objectives):\n        total_dist, makespan = objectives\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        weight = 0.5 + 0.3 * (np.sin(len(archive) / 10) + 1)  # Oscillating weight between 0.3 and 0.6\n        return weight * norm_dist + (1 - weight) * norm_makespan\n\n    scored_solutions = [(adaptive_pareto_weight(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.4 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Demand-aware route clustering\n    if len(new_solution) > 1 and random.random() < 0.5:\n        route_data = []\n        for route in new_solution:\n            if len(route) > 2:\n                route_coords = coords[route[1:-1]]\n                centroid = np.mean(route_coords, axis=0)\n                total_demand = sum(demand[route[1:-1]])\n                route_data.append((centroid, total_demand, route))\n\n        if len(route_data) > 1:\n            clusters = []\n            while len(route_data) > 0:\n                base = route_data.pop(0)\n                cluster = [base]\n                i = 0\n                while i < len(route_data):\n                    centroid, demand_val, _ = route_data[i]\n                    dist = np.linalg.norm(base[0] - centroid)\n                    demand_diff = abs(base[1] - demand_val)\n                    if dist < 1.2 * np.mean(distance_matrix) and demand_diff < 0.4 * capacity:\n                        cluster.append(route_data.pop(i))\n                    else:\n                        i += 1\n                clusters.append(cluster)\n\n            for cluster in clusters:\n                if len(cluster) > 1:\n                    for i in range(len(cluster)-1):\n                        for j in range(i+1, len(cluster)):\n                            route_i = cluster[i][2]\n                            route_j = cluster[j][2]\n                            if sum(demand[route_i[1:-1]]) + sum(demand[route_j[1:-1]]) <= capacity:\n                                min_dist = float('inf')\n                                best_i, best_j = 0, 0\n                                for a in range(1, len(route_i)-1):\n                                    for b in range(1, len(route_j)-1):\n                                        dist = distance_matrix[route_i[a]][route_j[b]]\n                                        if dist < min_dist:\n                                            min_dist = dist\n                                            best_i, best_j = a, b\n                                merged_route = np.concatenate([route_i[:best_i+1], route_j[best_j:-1], route_i[-1:]])\n                                new_solution = [r for r in new_solution if not np.array_equal(r, route_i) and not np.array_equal(r, route_j)]\n                                new_solution.append(merged_route)\n                                break\n\n    # Hybrid split-invert with demand balance\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5 and random.random() < 0.6:\n            # Split based on demand balance\n            demands = demand[route[1:-1]]\n            cumulative = np.cumsum(demands)\n            target = cumulative[-1] / 2\n            split_pos = np.argmin(np.abs(cumulative - target)) + 1\n\n            segment1 = route[:split_pos+1]\n            segment2 = np.concatenate([[0], route[split_pos+1:]])\n\n            if is_feasible(segment1) and is_feasible(segment2):\n                # Invert segment with high demand imbalance\n                if random.random() < 0.5:\n                    segment2 = np.concatenate([[0], segment2[-2:0:-1], segment2[-1:]])\n                new_solution[route_idx] = segment1\n                new_solution.insert(route_idx+1, segment2)\n                break\n\n    # Capacity-constrained reinsertion\n    if len(new_solution) > 1 and random.random() < 0.7:\n        source_idx = random.randint(0, len(new_solution)-1)\n        target_idx = random.randint(0, len(new_solution)-1)\n        if source_idx != target_idx:\n            source_route = new_solution[source_idx]\n            target_route = new_solution[target_idx]\n\n            if len(source_route) > 3:\n                customer_pos = random.randint(1, len(source_route)-2)\n                customer = source_route[customer_pos]\n\n                if sum(demand[target_route[1:-1]]) + demand[customer] <= capacity:\n                    new_source = np.concatenate([source_route[:customer_pos], source_route[customer_pos+1:]])\n                    best_pos = 1\n                    min_increase = float('inf')\n\n                    for pos in range(1, len(target_route)):\n                        dist_increase = (distance_matrix[target_route[pos-1]][customer] +\n                                        distance_matrix[customer][target_route[pos]] -\n                                        distance_matrix[target_route[pos-1]][target_route[pos]])\n\n                        if dist_increase < min_increase:\n                            min_increase = dist_increase\n                            best_pos = pos\n\n                    new_target = np.concatenate([target_route[:best_pos], [customer], target_route[best_pos:]])\n\n                    if is_feasible(new_source) and is_feasible(new_target):\n                        new_solution[source_idx] = new_source\n                        new_solution[target_idx] = new_target\n\n    return new_solution\n\n",
        "score": [
            -0.6866088436095239,
            0.2942003309726715
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    def adaptive_pareto_weight(solution, objectives):\n        total_dist, makespan = objectives\n        max_dist = max(obj[0] for _, obj in archive)\n        max_makespan = max(obj[1] for _, obj in archive)\n        norm_dist = total_dist / max_dist if max_dist > 0 else 0\n        norm_makespan = makespan / max_makespan if max_makespan > 0 else 0\n        weight = 0.5 + 0.3 * (np.sin(len(archive) / 10) + 1)  # Oscillating weight between 0.3 and 0.6\n        return weight * norm_dist + (1 - weight) * norm_makespan\n\n    scored_solutions = [(adaptive_pareto_weight(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: x[0])\n    top_k = max(1, int(0.4 * len(scored_solutions)))\n    selected_solution = random.choice([sol for _, sol in scored_solutions[:top_k]])\n\n    new_solution = [route.copy() for route in selected_solution]\n\n    def is_feasible(route):\n        return sum(demand[route[1:-1]]) <= capacity\n\n    # Demand-aware route clustering\n    if len(new_solution) > 1 and random.random() < 0.5:\n        route_data = []\n        for route in new_solution:\n            if len(route) > 2:\n                route_coords = coords[route[1:-1]]\n                centroid = np.mean(route_coords, axis=0)\n                total_demand = sum(demand[route[1:-1]])\n                route_data.append((centroid, total_demand, route))\n\n        if len(route_data) > 1:\n            clusters = []\n            while len(route_data) > 0:\n                base = route_data.pop(0)\n                cluster = [base]\n                i = 0\n                while i < len(route_data):\n                    centroid, demand_val, _ = route_data[i]\n                    dist = np.linalg.norm(base[0] - centroid)\n                    demand_diff = abs(base[1] - demand_val)\n                    if dist < 1.2 * np.mean(distance_matrix) and demand_diff < 0.4 * capacity:\n                        cluster.append(route_data.pop(i))\n                    else:\n                        i += 1\n                clusters.append(cluster)\n\n            for cluster in clusters:\n                if len(cluster) > 1:\n                    for i in range(len(cluster)-1):\n                        for j in range(i+1, len(cluster)):\n                            route_i = cluster[i][2]\n                            route_j = cluster[j][2]\n                            if sum(demand[route_i[1:-1]]) + sum(demand[route_j[1:-1]]) <= capacity:\n                                min_dist = float('inf')\n                                best_i, best_j = 0, 0\n                                for a in range(1, len(route_i)-1):\n                                    for b in range(1, len(route_j)-1):\n                                        dist = distance_matrix[route_i[a]][route_j[b]]\n                                        if dist < min_dist:\n                                            min_dist = dist\n                                            best_i, best_j = a, b\n                                merged_route = np.concatenate([route_i[:best_i+1], route_j[best_j:-1], route_i[-1:]])\n                                new_solution = [r for r in new_solution if not np.array_equal(r, route_i) and not np.array_equal(r, route_j)]\n                                new_solution.append(merged_route)\n                                break\n\n    # Hybrid split-invert with demand balance\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) > 5 and random.random() < 0.6:\n            # Split based on demand balance\n            demands = demand[route[1:-1]]\n            cumulative = np.cumsum(demands)\n            target = cumulative[-1] / 2\n            split_pos = np.argmin(np.abs(cumulative - target)) + 1\n\n            segment1 = route[:split_pos+1]\n            segment2 = np.concatenate([[0], route[split_pos+1:]])\n\n            if is_feasible(segment1) and is_feasible(segment2):\n                # Invert segment with high demand imbalance\n                if random.random() < 0.5:\n                    segment2 = np.concatenate([[0], segment2[-2:0:-1], segment2[-1:]])\n                new_solution[route_idx] = segment1\n                new_solution.insert(route_idx+1, segment2)\n                break\n\n    # Capacity-constrained reinsertion\n    if len(new_solution) > 1 and random.random() < 0.7:\n        source_idx = random.randint(0, len(new_solution)-1)\n        target_idx = random.randint(0, len(new_solution)-1)\n        if source_idx != target_idx:\n            source_route = new_solution[source_idx]\n            target_route = new_solution[target_idx]\n\n            if len(source_route) > 3:\n                customer_pos = random.randint(1, len(source_route)-2)\n                customer = source_route[customer_pos]\n\n                if sum(demand[target_route[1:-1]]) + demand[customer] <= capacity:\n                    new_source = np.concatenate([source_route[:customer_pos], source_route[customer_pos+1:]])\n                    best_pos = 1\n                    min_increase = float('inf')\n\n                    for pos in range(1, len(target_route)):\n                        dist_increase = (distance_matrix[target_route[pos-1]][customer] +\n                                        distance_matrix[customer][target_route[pos]] -\n                                        distance_matrix[target_route[pos-1]][target_route[pos]])\n\n                        if dist_increase < min_increase:\n                            min_increase = dist_increase\n                            best_pos = pos\n\n                    new_target = np.concatenate([target_route[:best_pos], [customer], target_route[best_pos:]])\n\n                    if is_feasible(new_source) and is_feasible(new_target):\n                        new_solution[source_idx] = new_source\n                        new_solution[target_idx] = new_target\n\n    return new_solution\n\n",
        "operation": "elitist"
    }
]