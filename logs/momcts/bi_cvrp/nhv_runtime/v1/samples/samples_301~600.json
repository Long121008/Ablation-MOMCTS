[
    {
        "prompt": "You are solving a Bi-objective Capacitated Vehicle Routing Problem (Bi-CVRP), where a single depot and multiple customers are located in 2D space. Each customer has a positive demand, and all vehicles in the fleet have identical capacity limits. The objective is to construct a set of routes, each starting and ending at the depot, such that all customers are served, vehicle capacities are not exceeded on any route, and two conflicting objectives are minimized: (1) the total travel distance across all routes, and (2) the makespan, defined as the length of the longest individual route. Each solution in the archive is represented as a list of NumPy arrays, where each array denotes a single route (starting and ending with depot index 0), and is paired with a tuple of two objective values (total_distance, makespan). Your task is to implement a function named 'select_neighbor' that selects one promising solution from the archive and apply a novel or hybrid local search operator to generate a feasible neighbor solution from it. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself. Avoid standard methods like pure 2-opt; instead, invent or combine transformations, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. Ensure that the returned neighbor solution remains feasible under the vehicle capacity constraint. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm combines extreme-value targeting with adaptive demand-spatial clustering by dynamically prioritizing solutions with high demand density and makespan, applying a hybrid local search that alternates between capacity-aware route splitting (70% weight) and spatial-demand hybrid swaps (30% weight), while continuously adjusting operator weights based on archive diversity to balance distance and makespan optimization. It selects solutions with the highest combined demand density and makespan scores, then performs iterative route splitting at demand hotspots and demand-weighted node swaps between imbalanced routes, ensuring feasibility through continuous capacity validation and spatial checks. The operator weights adapt dynamically based on archive diversity to maintain solution quality across both objectives.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    demand_densities = []\n    makespans = np.array([obj[1] for _, obj in archive])\n    for sol, obj in archive:\n        total_demand = sum(np.sum(demand[route[1:-1]]) for route in sol)\n        density = total_demand / (obj[0] + 1e-6)\n        demand_densities.append(density)\n\n    # Select solution with highest combined score\n    combined_scores = np.array(demand_densities) * makespans\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Dynamic operator weights based on archive diversity\n    if len(archive) > 1:\n        distances = np.array([obj[0] for _, obj in archive])\n        crowding = (np.max(distances) - np.min(distances)) / (np.mean(distances) + 1e-6)\n        split_weight = 0.7 + 0.2 * crowding\n        swap_weight = 0.3 - 0.2 * crowding\n    else:\n        split_weight = 0.7\n        swap_weight = 0.3\n\n    # Phase 1: Capacity-aware demand hotspot splitting\n    for _ in range(2):\n        if len(new_solution) < 1:\n            break\n\n        # Find route with highest demand concentration near capacity\n        demand_sums = [np.sum(demand[route[1:-1]]) for route in new_solution]\n        route_idx = np.argmax(demand_sums)\n        route = new_solution[route_idx]\n\n        if len(route) <= 3:\n            continue\n\n        # Identify demand hotspot (top 30% demand nodes)\n        demands = demand[route[1:-1]]\n        sorted_idx = np.argsort(demands)[::-1]\n        hotspot_size = max(2, int(0.3 * len(demands)))\n        hotspot_nodes = route[sorted_idx[:hotspot_size] + 1]  # +1 for route index\n\n        # Split at first hotspot node\n        split_pos = np.where(route == hotspot_nodes[0])[0][0]\n        if split_pos > 1 and split_pos < len(route) - 1:\n            fragment = route[split_pos:]\n            remaining = route[:split_pos]\n\n            if (np.sum(demand[fragment[1:-1]]) <= capacity and\n                np.sum(demand[remaining[1:-1]]) <= capacity):\n                new_solution[route_idx] = remaining\n                new_solution.append(fragment)\n\n    # Phase 2: Spatial-demand hybrid swaps\n    for _ in range(3):\n        if len(new_solution) < 2:\n            break\n\n        # Select routes with high spatial-demand imbalance\n        route_pairs = []\n        for i in range(len(new_solution)):\n            for j in range(i+1, len(new_solution)):\n                route1, route2 = new_solution[i], new_solution[j]\n                last1, first2 = route1[-2], route2[1]\n                spatial_dist = distance_matrix[last1, first2]\n                demand_diff = abs(np.sum(demand[route1[1:-1]]) - np.sum(demand[route2[1:-1]]))\n                imbalance = spatial_dist * demand_diff\n                route_pairs.append((imbalance, (i, j)))\n\n        if not route_pairs:\n            continue\n\n        # Select pair with highest imbalance\n        _, (i, j) = max(route_pairs)\n        route1, route2 = new_solution[i], new_solution[j]\n\n        # Try demand-weighted node swaps\n        if len(route1) > 3 and len(route2) > 3:\n            # Find nodes with similar demand\n            route1_demands = demand[route1[1:-1]]\n            route2_demands = demand[route2[1:-1]]\n            median1, median2 = np.median(route1_demands), np.median(route2_demands)\n\n            if abs(median1 - median2) < 0.3 * (median1 + median2):\n                # Select random nodes\n                node1_pos = random.randint(1, len(route1)-2)\n                node2_pos = random.randint(1, len(route2)-2)\n                node1, node2 = route1[node1_pos], route2[node2_pos]\n\n                # Check capacity and spatial improvement\n                new_route1 = route1.copy()\n                new_route1[node1_pos] = node2\n                new_route2 = route2.copy()\n                new_route2[node2_pos] = node1\n\n                if (np.sum(demand[new_route1[1:-1]]) <= capacity and\n                    np.sum(demand[new_route2[1:-1]]) <= capacity):\n\n                    old_dist = (distance_matrix[route1[node1_pos-1], node1] +\n                                distance_matrix[node1, route1[node1_pos+1]] +\n                                distance_matrix[route2[node2_pos-1], node2] +\n                                distance_matrix[node2, route2[node2_pos+1]])\n\n                    new_dist = (distance_matrix[route1[node1_pos-1], node2] +\n                                distance_matrix[node2, route1[node1_pos+1]] +\n                                distance_matrix[route2[node2_pos-1], node1] +\n                                distance_matrix[node1, route2[node2_pos+1]])\n\n                    if new_dist < old_dist:\n                        new_solution[i] = new_route1\n                        new_solution[j] = new_route2\n\n    # Final cleanup\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 301,
        "algorithm": "The algorithm dynamically balances route consolidation and demand redistribution by prioritizing either operator based on makespan variance and archive diversity, using spatial and demand-aware selection to generate feasible neighbors that trade off distance and makespan objectives. It selects high-density solutions and applies weighted local search operators, merging similar routes when makespan variance is low and redistributing demand-heavy nodes when variance is high, while maintaining capacity constraints through continuous feasibility checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    demand_densities = []\n    makespans = np.array([obj[1] for _, obj in archive])\n    makespan_variance = np.var(makespans)\n\n    for sol, obj in archive:\n        total_demand = sum(np.sum(demand[route[1:-1]]) for route in sol)\n        density = total_demand / (obj[0] + 1e-6)\n        demand_densities.append(density)\n\n    # Select solution with highest combined score (density * normalized makespan)\n    combined_scores = np.array(demand_densities) * (makespans / (np.mean(makespans) + 1e-6))\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Dynamic operator weights based on makespan variance and archive size\n    if len(archive) > 1:\n        merge_weight = 0.6 + 0.3 * (1 - makespan_variance / (np.max(makespans) + 1e-6))\n        redistribute_weight = 0.4 - 0.3 * (1 - makespan_variance / (np.max(makespans) + 1e-6))\n    else:\n        merge_weight = 0.6\n        redistribute_weight = 0.4\n\n    # Phase 1: Demand-aware route merging (higher weight when makespan variance is low)\n    if random.random() < merge_weight and len(new_solution) > 2:\n        # Find two closest routes based on spatial and demand similarity\n        route_pairs = []\n        for i in range(len(new_solution)):\n            for j in range(i+1, len(new_solution)):\n                route1, route2 = new_solution[i], new_solution[j]\n                last1, first2 = route1[-2], route2[1]\n                spatial_dist = distance_matrix[last1, first2]\n                demand_diff = abs(np.sum(demand[route1[1:-1]]) - np.sum(demand[route2[1:-1]]))\n                similarity = 1 / (1 + spatial_dist + 0.1 * demand_diff)\n                route_pairs.append((similarity, (i, j)))\n\n        if route_pairs:\n            _, (i, j) = max(route_pairs)\n            route1, route2 = new_solution[i], new_solution[j]\n\n            # Try merging routes if capacity allows\n            merged_route = np.concatenate([route1[:-1], route2[1:]])\n            if np.sum(demand[merged_route[1:-1]]) <= capacity:\n                new_solution[i] = merged_route\n                del new_solution[j]\n\n    # Phase 2: Demand-weighted node redistribution (higher weight when makespan variance is high)\n    if random.random() < redistribute_weight and len(new_solution) > 1:\n        # Select route with highest demand and shortest route with lowest demand\n        demand_sums = [np.sum(demand[route[1:-1]]) for route in new_solution]\n        route_lengths = [len(route) for route in new_solution]\n\n        heavy_idx = np.argmax(demand_sums)\n        light_idx = np.argmin([d if l > 3 else float('inf') for d, l in zip(demand_sums, route_lengths)])\n\n        if heavy_idx != light_idx:\n            heavy_route = new_solution[heavy_idx]\n            light_route = new_solution[light_idx]\n\n            # Identify nodes in heavy route that can be moved to light route\n            for node in heavy_route[1:-1]:\n                if np.sum(demand[light_route[1:-1]]) + demand[node] <= capacity:\n                    # Find best insertion position in light route\n                    best_pos = 1\n                    best_cost = float('inf')\n\n                    for pos in range(1, len(light_route)):\n                        cost = (distance_matrix[light_route[pos-1], node] +\n                                distance_matrix[node, light_route[pos]] -\n                                distance_matrix[light_route[pos-1], light_route[pos]])\n\n                        if cost < best_cost:\n                            best_cost = cost\n                            best_pos = pos\n\n                    # Perform the move if it improves the solution\n                    if best_cost < 0:\n                        new_heavy = np.delete(heavy_route, np.where(heavy_route == node)[0][0])\n                        new_light = np.insert(light_route, best_pos, node)\n\n                        new_solution[heavy_idx] = new_heavy\n                        new_solution[light_idx] = new_light\n\n                        # Early exit if significant improvement found\n                        if len(new_heavy) <= 2:\n                            break\n\n    # Final cleanup: remove empty routes\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n",
        "score": [
            -0.7842880611179236,
            0.9162099063396454
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    demand_densities = []\n    makespans = np.array([obj[1] for _, obj in archive])\n    makespan_variance = np.var(makespans)\n\n    for sol, obj in archive:\n        total_demand = sum(np.sum(demand[route[1:-1]]) for route in sol)\n        density = total_demand / (obj[0] + 1e-6)\n        demand_densities.append(density)\n\n    # Select solution with highest combined score (density * normalized makespan)\n    combined_scores = np.array(demand_densities) * (makespans / (np.mean(makespans) + 1e-6))\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Dynamic operator weights based on makespan variance and archive size\n    if len(archive) > 1:\n        merge_weight = 0.6 + 0.3 * (1 - makespan_variance / (np.max(makespans) + 1e-6))\n        redistribute_weight = 0.4 - 0.3 * (1 - makespan_variance / (np.max(makespans) + 1e-6))\n    else:\n        merge_weight = 0.6\n        redistribute_weight = 0.4\n\n    # Phase 1: Demand-aware route merging (higher weight when makespan variance is low)\n    if random.random() < merge_weight and len(new_solution) > 2:\n        # Find two closest routes based on spatial and demand similarity\n        route_pairs = []\n        for i in range(len(new_solution)):\n            for j in range(i+1, len(new_solution)):\n                route1, route2 = new_solution[i], new_solution[j]\n                last1, first2 = route1[-2], route2[1]\n                spatial_dist = distance_matrix[last1, first2]\n                demand_diff = abs(np.sum(demand[route1[1:-1]]) - np.sum(demand[route2[1:-1]]))\n                similarity = 1 / (1 + spatial_dist + 0.1 * demand_diff)\n                route_pairs.append((similarity, (i, j)))\n\n        if route_pairs:\n            _, (i, j) = max(route_pairs)\n            route1, route2 = new_solution[i], new_solution[j]\n\n            # Try merging routes if capacity allows\n            merged_route = np.concatenate([route1[:-1], route2[1:]])\n            if np.sum(demand[merged_route[1:-1]]) <= capacity:\n                new_solution[i] = merged_route\n                del new_solution[j]\n\n    # Phase 2: Demand-weighted node redistribution (higher weight when makespan variance is high)\n    if random.random() < redistribute_weight and len(new_solution) > 1:\n        # Select route with highest demand and shortest route with lowest demand\n        demand_sums = [np.sum(demand[route[1:-1]]) for route in new_solution]\n        route_lengths = [len(route) for route in new_solution]\n\n        heavy_idx = np.argmax(demand_sums)\n        light_idx = np.argmin([d if l > 3 else float('inf') for d, l in zip(demand_sums, route_lengths)])\n\n        if heavy_idx != light_idx:\n            heavy_route = new_solution[heavy_idx]\n            light_route = new_solution[light_idx]\n\n            # Identify nodes in heavy route that can be moved to light route\n            for node in heavy_route[1:-1]:\n                if np.sum(demand[light_route[1:-1]]) + demand[node] <= capacity:\n                    # Find best insertion position in light route\n                    best_pos = 1\n                    best_cost = float('inf')\n\n                    for pos in range(1, len(light_route)):\n                        cost = (distance_matrix[light_route[pos-1], node] +\n                                distance_matrix[node, light_route[pos]] -\n                                distance_matrix[light_route[pos-1], light_route[pos]])\n\n                        if cost < best_cost:\n                            best_cost = cost\n                            best_pos = pos\n\n                    # Perform the move if it improves the solution\n                    if best_cost < 0:\n                        new_heavy = np.delete(heavy_route, np.where(heavy_route == node)[0][0])\n                        new_light = np.insert(light_route, best_pos, node)\n\n                        new_solution[heavy_idx] = new_heavy\n                        new_solution[light_idx] = new_light\n\n                        # Early exit if significant improvement found\n                        if len(new_heavy) <= 2:\n                            break\n\n    # Final cleanup: remove empty routes\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Capacitated Vehicle Routing Problem (Bi-CVRP), where a single depot and multiple customers are located in 2D space. Each customer has a positive demand, and all vehicles in the fleet have identical capacity limits. The objective is to construct a set of routes, each starting and ending at the depot, such that all customers are served, vehicle capacities are not exceeded on any route, and two conflicting objectives are minimized: (1) the total travel distance across all routes, and (2) the makespan, defined as the length of the longest individual route. Each solution in the archive is represented as a list of NumPy arrays, where each array denotes a single route (starting and ending with depot index 0), and is paired with a tuple of two objective values (total_distance, makespan). Your task is to implement a function named 'select_neighbor' that selects one promising solution from the archive and apply a novel or hybrid local search operator to generate a feasible neighbor solution from it. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself. Avoid standard methods like pure 2-opt; instead, invent or combine transformations, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. Ensure that the returned neighbor solution remains feasible under the vehicle capacity constraint. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm combines extreme-value targeting with adaptive demand-spatial clustering by dynamically prioritizing solutions with high demand density and makespan, applying a hybrid local search that alternates between capacity-aware route splitting (70% weight) and spatial-demand hybrid swaps (30% weight), while continuously adjusting operator weights based on archive diversity to balance distance and makespan optimization. It selects solutions with the highest combined demand density and makespan scores, then performs iterative route splitting at demand hotspots and demand-weighted node swaps between imbalanced routes, ensuring feasibility through continuous capacity validation and spatial checks. The operator weights adapt dynamically based on archive diversity to maintain solution quality across both objectives.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    demand_densities = []\n    makespans = np.array([obj[1] for _, obj in archive])\n    for sol, obj in archive:\n        total_demand = sum(np.sum(demand[route[1:-1]]) for route in sol)\n        density = total_demand / (obj[0] + 1e-6)\n        demand_densities.append(density)\n\n    # Select solution with highest combined score\n    combined_scores = np.array(demand_densities) * makespans\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Dynamic operator weights based on archive diversity\n    if len(archive) > 1:\n        distances = np.array([obj[0] for _, obj in archive])\n        crowding = (np.max(distances) - np.min(distances)) / (np.mean(distances) + 1e-6)\n        split_weight = 0.7 + 0.2 * crowding\n        swap_weight = 0.3 - 0.2 * crowding\n    else:\n        split_weight = 0.7\n        swap_weight = 0.3\n\n    # Phase 1: Capacity-aware demand hotspot splitting\n    for _ in range(2):\n        if len(new_solution) < 1:\n            break\n\n        # Find route with highest demand concentration near capacity\n        demand_sums = [np.sum(demand[route[1:-1]]) for route in new_solution]\n        route_idx = np.argmax(demand_sums)\n        route = new_solution[route_idx]\n\n        if len(route) <= 3:\n            continue\n\n        # Identify demand hotspot (top 30% demand nodes)\n        demands = demand[route[1:-1]]\n        sorted_idx = np.argsort(demands)[::-1]\n        hotspot_size = max(2, int(0.3 * len(demands)))\n        hotspot_nodes = route[sorted_idx[:hotspot_size] + 1]  # +1 for route index\n\n        # Split at first hotspot node\n        split_pos = np.where(route == hotspot_nodes[0])[0][0]\n        if split_pos > 1 and split_pos < len(route) - 1:\n            fragment = route[split_pos:]\n            remaining = route[:split_pos]\n\n            if (np.sum(demand[fragment[1:-1]]) <= capacity and\n                np.sum(demand[remaining[1:-1]]) <= capacity):\n                new_solution[route_idx] = remaining\n                new_solution.append(fragment)\n\n    # Phase 2: Spatial-demand hybrid swaps\n    for _ in range(3):\n        if len(new_solution) < 2:\n            break\n\n        # Select routes with high spatial-demand imbalance\n        route_pairs = []\n        for i in range(len(new_solution)):\n            for j in range(i+1, len(new_solution)):\n                route1, route2 = new_solution[i], new_solution[j]\n                last1, first2 = route1[-2], route2[1]\n                spatial_dist = distance_matrix[last1, first2]\n                demand_diff = abs(np.sum(demand[route1[1:-1]]) - np.sum(demand[route2[1:-1]]))\n                imbalance = spatial_dist * demand_diff\n                route_pairs.append((imbalance, (i, j)))\n\n        if not route_pairs:\n            continue\n\n        # Select pair with highest imbalance\n        _, (i, j) = max(route_pairs)\n        route1, route2 = new_solution[i], new_solution[j]\n\n        # Try demand-weighted node swaps\n        if len(route1) > 3 and len(route2) > 3:\n            # Find nodes with similar demand\n            route1_demands = demand[route1[1:-1]]\n            route2_demands = demand[route2[1:-1]]\n            median1, median2 = np.median(route1_demands), np.median(route2_demands)\n\n            if abs(median1 - median2) < 0.3 * (median1 + median2):\n                # Select random nodes\n                node1_pos = random.randint(1, len(route1)-2)\n                node2_pos = random.randint(1, len(route2)-2)\n                node1, node2 = route1[node1_pos], route2[node2_pos]\n\n                # Check capacity and spatial improvement\n                new_route1 = route1.copy()\n                new_route1[node1_pos] = node2\n                new_route2 = route2.copy()\n                new_route2[node2_pos] = node1\n\n                if (np.sum(demand[new_route1[1:-1]]) <= capacity and\n                    np.sum(demand[new_route2[1:-1]]) <= capacity):\n\n                    old_dist = (distance_matrix[route1[node1_pos-1], node1] +\n                                distance_matrix[node1, route1[node1_pos+1]] +\n                                distance_matrix[route2[node2_pos-1], node2] +\n                                distance_matrix[node2, route2[node2_pos+1]])\n\n                    new_dist = (distance_matrix[route1[node1_pos-1], node2] +\n                                distance_matrix[node2, route1[node1_pos+1]] +\n                                distance_matrix[route2[node2_pos-1], node1] +\n                                distance_matrix[node1, route2[node2_pos+1]])\n\n                    if new_dist < old_dist:\n                        new_solution[i] = new_route1\n                        new_solution[j] = new_route2\n\n    # Final cleanup\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 302,
        "algorithm": "The algorithm selects solutions with high distance-makespan correlation from the archive and applies a hybrid local search alternating between spatial hotspot merging (60%) and demand-aware route reversal (40%), dynamically adjusting weights based on archive balance to optimize both objectives while preserving feasibility. It prioritizes routes with spatial imbalance (closest node swaps) and high demand density (route reversals), ensuring capacity constraints are met throughout transformations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    distances = np.array([obj[0] for _, obj in archive])\n    makespans = np.array([obj[1] for _, obj in archive])\n    correlation = np.corrcoef(distances, makespans)[0,1]\n    selected_idx = np.argmax(correlation * distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    if len(archive) > 1:\n        balance = (np.max(makespans) - np.min(makespans)) / (np.mean(makespans) + 1e-6)\n        merge_weight = 0.6 + 0.2 * balance\n        reverse_weight = 0.4 - 0.2 * balance\n    else:\n        merge_weight = 0.6\n        reverse_weight = 0.4\n\n    for _ in range(2):\n        if len(new_solution) < 2:\n            break\n\n        spatial_scores = []\n        for i in range(len(new_solution)):\n            route = new_solution[i]\n            if len(route) <= 3:\n                continue\n            last_node = route[-2]\n            centroid = np.mean(coords[route[1:-1]], axis=0)\n            spatial_score = np.linalg.norm(coords[last_node] - centroid)\n            spatial_scores.append((spatial_score, i))\n\n        if not spatial_scores:\n            continue\n\n        _, route_idx = max(spatial_scores)\n        route = new_solution[route_idx]\n\n        if len(route) <= 3:\n            continue\n\n        closest_pair = None\n        min_distance = float('inf')\n        for i in range(1, len(route)-1):\n            for j in range(i+1, len(route)-1):\n                dist = distance_matrix[route[i], route[j]]\n                if dist < min_distance:\n                    min_distance = dist\n                    closest_pair = (i, j)\n\n        if closest_pair:\n            i, j = closest_pair\n            new_route = route.copy()\n            new_route[i], new_route[j] = new_route[j], new_route[i]\n            if np.sum(demand[new_route[1:-1]]) <= capacity:\n                new_solution[route_idx] = new_route\n\n    for _ in range(3):\n        if len(new_solution) < 2:\n            break\n\n        demand_scores = []\n        for i in range(len(new_solution)):\n            route = new_solution[i]\n            if len(route) <= 3:\n                continue\n            demand_score = np.sum(demand[route[1:-1]]) / (len(route)-2)\n            demand_scores.append((demand_score, i))\n\n        if not demand_scores:\n            continue\n\n        _, route_idx = max(demand_scores)\n        route = new_solution[route_idx]\n\n        if len(route) <= 3:\n            continue\n\n        reversed_route = route.copy()\n        reversed_route[1:-1] = reversed_route[-2:0:-1]\n        if np.sum(demand[reversed_route[1:-1]]) <= capacity:\n            new_solution[route_idx] = reversed_route\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n",
        "score": [
            -0.6950103745312837,
            1.6661049127578735
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    distances = np.array([obj[0] for _, obj in archive])\n    makespans = np.array([obj[1] for _, obj in archive])\n    correlation = np.corrcoef(distances, makespans)[0,1]\n    selected_idx = np.argmax(correlation * distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    if len(archive) > 1:\n        balance = (np.max(makespans) - np.min(makespans)) / (np.mean(makespans) + 1e-6)\n        merge_weight = 0.6 + 0.2 * balance\n        reverse_weight = 0.4 - 0.2 * balance\n    else:\n        merge_weight = 0.6\n        reverse_weight = 0.4\n\n    for _ in range(2):\n        if len(new_solution) < 2:\n            break\n\n        spatial_scores = []\n        for i in range(len(new_solution)):\n            route = new_solution[i]\n            if len(route) <= 3:\n                continue\n            last_node = route[-2]\n            centroid = np.mean(coords[route[1:-1]], axis=0)\n            spatial_score = np.linalg.norm(coords[last_node] - centroid)\n            spatial_scores.append((spatial_score, i))\n\n        if not spatial_scores:\n            continue\n\n        _, route_idx = max(spatial_scores)\n        route = new_solution[route_idx]\n\n        if len(route) <= 3:\n            continue\n\n        closest_pair = None\n        min_distance = float('inf')\n        for i in range(1, len(route)-1):\n            for j in range(i+1, len(route)-1):\n                dist = distance_matrix[route[i], route[j]]\n                if dist < min_distance:\n                    min_distance = dist\n                    closest_pair = (i, j)\n\n        if closest_pair:\n            i, j = closest_pair\n            new_route = route.copy()\n            new_route[i], new_route[j] = new_route[j], new_route[i]\n            if np.sum(demand[new_route[1:-1]]) <= capacity:\n                new_solution[route_idx] = new_route\n\n    for _ in range(3):\n        if len(new_solution) < 2:\n            break\n\n        demand_scores = []\n        for i in range(len(new_solution)):\n            route = new_solution[i]\n            if len(route) <= 3:\n                continue\n            demand_score = np.sum(demand[route[1:-1]]) / (len(route)-2)\n            demand_scores.append((demand_score, i))\n\n        if not demand_scores:\n            continue\n\n        _, route_idx = max(demand_scores)\n        route = new_solution[route_idx]\n\n        if len(route) <= 3:\n            continue\n\n        reversed_route = route.copy()\n        reversed_route[1:-1] = reversed_route[-2:0:-1]\n        if np.sum(demand[reversed_route[1:-1]]) <= capacity:\n            new_solution[route_idx] = reversed_route\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Capacitated Vehicle Routing Problem (Bi-CVRP), where a single depot and multiple customers are located in 2D space. Each customer has a positive demand, and all vehicles in the fleet have identical capacity limits. The objective is to construct a set of routes, each starting and ending at the depot, such that all customers are served, vehicle capacities are not exceeded on any route, and two conflicting objectives are minimized: (1) the total travel distance across all routes, and (2) the makespan, defined as the length of the longest individual route. Each solution in the archive is represented as a list of NumPy arrays, where each array denotes a single route (starting and ending with depot index 0), and is paired with a tuple of two objective values (total_distance, makespan). Your task is to implement a function named 'select_neighbor' that selects one promising solution from the archive and apply a novel or hybrid local search operator to generate a feasible neighbor solution from it. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself. Avoid standard methods like pure 2-opt; instead, invent or combine transformations, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. Ensure that the returned neighbor solution remains feasible under the vehicle capacity constraint. The function should return the new neighbor solution.\n            I have 6 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm combines extreme-value targeting with adaptive demand-spatial clustering by dynamically prioritizing solutions with high demand density and makespan, applying a hybrid local search that alternates between capacity-aware route splitting (70% weight) and spatial-demand hybrid swaps (30% weight), while continuously adjusting operator weights based on archive diversity to balance distance and makespan optimization. It selects solutions with the highest combined demand density and makespan scores, then performs iterative route splitting at demand hotspots and demand-weighted node swaps between imbalanced routes, ensuring feasibility through continuous capacity validation and spatial checks. The operator weights adapt dynamically based on archive diversity to maintain solution quality across both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    demand_densities = []\n    makespans = np.array([obj[1] for _, obj in archive])\n    for sol, obj in archive:\n        total_demand = sum(np.sum(demand[route[1:-1]]) for route in sol)\n        density = total_demand / (obj[0] + 1e-6)\n        demand_densities.append(density)\n\n    # Select solution with highest combined score\n    combined_scores = np.array(demand_densities) * makespans\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Dynamic operator weights based on archive diversity\n    if len(archive) > 1:\n        distances = np.array([obj[0] for _, obj in archive])\n        crowding = (np.max(distances) - np.min(distances)) / (np.mean(distances) + 1e-6)\n        split_weight = 0.7 + 0.2 * crowding\n        swap_weight = 0.3 - 0.2 * crowding\n    else:\n        split_weight = 0.7\n        swap_weight = 0.3\n\n    # Phase 1: Capacity-aware demand hotspot splitting\n    for _ in range(2):\n        if len(new_solution) < 1:\n            break\n\n        # Find route with highest demand concentration near capacity\n        demand_sums = [np.sum(demand[route[1:-1]]) for route in new_solution]\n        route_idx = np.argmax(demand_sums)\n        route = new_solution[route_idx]\n\n        if len(route) <= 3:\n            continue\n\n        # Identify demand hotspot (top 30% demand nodes)\n        demands = demand[route[1:-1]]\n        sorted_idx = np.argsort(demands)[::-1]\n        hotspot_size = max(2, int(0.3 * len(demands)))\n        hotspot_nodes = route[sorted_idx[:hotspot_size] + 1]  # +1 for route index\n\n        # Split at first hotspot node\n        split_pos = np.where(route == hotspot_nodes[0])[0][0]\n        if split_pos > 1 and split_pos < len(route) - 1:\n            fragment = route[split_pos:]\n            remaining = route[:split_pos]\n\n            if (np.sum(demand[fragment[1:-1]]) <= capacity and\n                np.sum(demand[remaining[1:-1]]) <= capacity):\n                new_solution[route_idx] = remaining\n                new_solution.append(fragment)\n\n    # Phase 2: Spatial-demand hybrid swaps\n    for _ in range(3):\n        if len(new_solution) < 2:\n            break\n\n        # Select routes with high spatial-demand imbalance\n        route_pairs = []\n        for i in range(len(new_solution)):\n            for j in range(i+1, len(new_solution)):\n                route1, route2 = new_solution[i], new_solution[j]\n                last1, first2 = route1[-2], route2[1]\n                spatial_dist = distance_matrix[last1, first2]\n                demand_diff = abs(np.sum(demand[route1[1:-1]]) - np.sum(demand[route2[1:-1]]))\n                imbalance = spatial_dist * demand_diff\n                route_pairs.append((imbalance, (i, j)))\n\n        if not route_pairs:\n            continue\n\n        # Select pair with highest imbalance\n        _, (i, j) = max(route_pairs)\n        route1, route2 = new_solution[i], new_solution[j]\n\n        # Try demand-weighted node swaps\n        if len(route1) > 3 and len(route2) > 3:\n            # Find nodes with similar demand\n            route1_demands = demand[route1[1:-1]]\n            route2_demands = demand[route2[1:-1]]\n            median1, median2 = np.median(route1_demands), np.median(route2_demands)\n\n            if abs(median1 - median2) < 0.3 * (median1 + median2):\n                # Select random nodes\n                node1_pos = random.randint(1, len(route1)-2)\n                node2_pos = random.randint(1, len(route2)-2)\n                node1, node2 = route1[node1_pos], route2[node2_pos]\n\n                # Check capacity and spatial improvement\n                new_route1 = route1.copy()\n                new_route1[node1_pos] = node2\n                new_route2 = route2.copy()\n                new_route2[node2_pos] = node1\n\n                if (np.sum(demand[new_route1[1:-1]]) <= capacity and\n                    np.sum(demand[new_route2[1:-1]]) <= capacity):\n\n                    old_dist = (distance_matrix[route1[node1_pos-1], node1] +\n                                distance_matrix[node1, route1[node1_pos+1]] +\n                                distance_matrix[route2[node2_pos-1], node2] +\n                                distance_matrix[node2, route2[node2_pos+1]])\n\n                    new_dist = (distance_matrix[route1[node1_pos-1], node2] +\n                                distance_matrix[node2, route1[node1_pos+1]] +\n                                distance_matrix[route2[node2_pos-1], node1] +\n                                distance_matrix[node1, route2[node2_pos+1]])\n\n                    if new_dist < old_dist:\n                        new_solution[i] = new_route1\n                        new_solution[j] = new_route2\n\n    # Final cleanup\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm combines extreme-solution targeting with adaptive demand-spatial clustering by prioritizing solutions with high demand density and makespan, then dynamically applies capacity-aware route splitting (70% weight) and spatial-demand hybrid swaps (30% weight) to balance distance and makespan while maintaining feasibility through continuous demand validation and spatial checks. The operator weights adjust based on archive diversity, with splitting favored in crowded archives and swaps in sparse ones.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    demand_densities = []\n    for sol, obj in archive:\n        total_demand = sum(np.sum(demand[route[1:-1]]) for route in sol)\n        density = total_demand / (obj[0] + 1e-6)\n        demand_densities.append(density)\n\n    # Combine with makespan to select extreme solution\n    makespans = np.array([obj[1] for _, obj in archive])\n    extreme_scores = np.array(demand_densities) * makespans\n    selected_idx = np.argmax(extreme_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Dynamic operator weights based on archive diversity\n    if len(archive) > 1:\n        distances = np.array([obj[0] for _, obj in archive])\n        crowding = (np.max(distances) - np.min(distances)) / (np.mean(distances) + 1e-6)\n        split_weight = 0.7 + 0.2 * crowding\n        swap_weight = 0.3 - 0.2 * crowding\n    else:\n        split_weight = 0.7\n        swap_weight = 0.3\n\n    # Phase 1: Capacity-aware demand hotspot splitting\n    for _ in range(2):\n        if len(new_solution) < 1:\n            break\n\n        # Find route with highest demand concentration near capacity\n        demand_sums = [np.sum(demand[route[1:-1]]) for route in new_solution]\n        route_idx = np.argmax(demand_sums)\n        route = new_solution[route_idx]\n\n        if len(route) <= 3:\n            continue\n\n        # Identify demand hotspot (top 30% demand nodes)\n        demands = demand[route[1:-1]]\n        sorted_idx = np.argsort(demands)[::-1]\n        hotspot_size = max(2, int(0.3 * len(demands)))\n        hotspot_nodes = route[sorted_idx[:hotspot_size] + 1]  # +1 for route index\n\n        # Split at first hotspot node\n        split_pos = np.where(route == hotspot_nodes[0])[0][0]\n        if split_pos > 1 and split_pos < len(route) - 1:\n            fragment = route[split_pos:]\n            remaining = route[:split_pos]\n\n            if (np.sum(demand[fragment[1:-1]]) <= capacity and\n                np.sum(demand[remaining[1:-1]]) <= capacity):\n                new_solution[route_idx] = remaining\n                new_solution.append(fragment)\n\n    # Phase 2: Spatial-demand hybrid swaps\n    for _ in range(3):\n        if len(new_solution) < 2:\n            break\n\n        # Select routes with high spatial-demand imbalance\n        route_pairs = []\n        for i in range(len(new_solution)):\n            for j in range(i+1, len(new_solution)):\n                route1, route2 = new_solution[i], new_solution[j]\n                last1, first2 = route1[-2], route2[1]\n                spatial_dist = distance_matrix[last1, first2]\n                demand_diff = abs(np.sum(demand[route1[1:-1]]) - np.sum(demand[route2[1:-1]]))\n                imbalance = spatial_dist * demand_diff\n                route_pairs.append((imbalance, (i, j)))\n\n        if not route_pairs:\n            continue\n\n        # Select pair with highest imbalance\n        _, (i, j) = max(route_pairs)\n        route1, route2 = new_solution[i], new_solution[j]\n\n        # Try demand-weighted node swaps\n        if len(route1) > 3 and len(route2) > 3:\n            # Find nodes with similar demand\n            route1_demands = demand[route1[1:-1]]\n            route2_demands = demand[route2[1:-1]]\n            median1, median2 = np.median(route1_demands), np.median(route2_demands)\n\n            if abs(median1 - median2) < 0.3 * (median1 + median2):\n                # Select random nodes\n                node1_pos = random.randint(1, len(route1)-2)\n                node2_pos = random.randint(1, len(route2)-2)\n                node1, node2 = route1[node1_pos], route2[node2_pos]\n\n                # Check capacity and spatial improvement\n                new_route1 = route1.copy()\n                new_route1[node1_pos] = node2\n                new_route2 = route2.copy()\n                new_route2[node2_pos] = node1\n\n                if (np.sum(demand[new_route1[1:-1]]) <= capacity and\n                    np.sum(demand[new_route2[1:-1]]) <= capacity):\n\n                    old_dist = (distance_matrix[route1[node1_pos-1], node1] +\n                                distance_matrix[node1, route1[node1_pos+1]] +\n                                distance_matrix[route2[node2_pos-1], node2] +\n                                distance_matrix[node2, route2[node2_pos+1]])\n\n                    new_dist = (distance_matrix[route1[node1_pos-1], node2] +\n                                distance_matrix[node2, route1[node1_pos+1]] +\n                                distance_matrix[route2[node2_pos-1], node1] +\n                                distance_matrix[node1, route2[node2_pos+1]])\n\n                    if new_dist < old_dist:\n                        new_solution[i] = new_route1\n                        new_solution[j] = new_route2\n\n    # Final cleanup\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm combines demand-aware route segmentation with spatial-demand hybrid optimization, prioritizing high-demand-density solutions and alternating between demand-based clustering and spatial-demand swaps to balance efficiency and route compactness while ensuring feasibility. It emphasizes demand patterns in clustering and spatial proximity in merging/swapping operations, with dynamic thresholds for demand differences and capacity checks. The multi-phase approach (segmentation \u2192 merging \u2192 node swaps) progressively refines solutions while maintaining feasibility.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    demand_densities = []\n    for sol, obj in archive:\n        total_demand = sum(np.sum(demand[route[1:-1]]) for route in sol)\n        total_distance = obj[0]\n        density = total_demand / total_distance if total_distance > 0 else float('inf')\n        demand_densities.append(density)\n\n    selected_idx = np.argmax(demand_densities)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Phase 1: Demand-aware route segmentation\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) <= 4:\n            continue\n\n        # Find demand clusters in the route\n        demands = demand[route[1:-1]]\n        sorted_indices = np.argsort(demands)\n        clusters = []\n        current_cluster = [route[sorted_indices[0] + 1]]  # +1 to convert to route index\n\n        for i in range(1, len(sorted_indices)):\n            prev_idx = sorted_indices[i-1] + 1\n            curr_idx = sorted_indices[i] + 1\n\n            # Check if demand difference exceeds threshold\n            if demands[sorted_indices[i]] - demands[sorted_indices[i-1]] > 0.2 * np.mean(demands):\n                clusters.append(current_cluster)\n                current_cluster = [curr_idx]\n            else:\n                current_cluster.append(curr_idx)\n\n        if current_cluster:\n            clusters.append(current_cluster)\n\n        # Reconstruct route with demand-based segments\n        if len(clusters) > 1:\n            new_route = [0]\n            for cluster in clusters:\n                # Find best insertion point for the cluster\n                best_pos = 1\n                best_cost = float('inf')\n\n                for pos in range(1, len(new_route)):\n                    # Calculate insertion cost\n                    cost = (distance_matrix[new_route[pos-1], cluster[0]] +\n                            distance_matrix[cluster[-1], new_route[pos]] -\n                            distance_matrix[new_route[pos-1], new_route[pos]])\n\n                    if cost < best_cost:\n                        best_cost = cost\n                        best_pos = pos\n\n                new_route = new_route[:best_pos] + cluster + new_route[best_pos:]\n\n            new_route.append(0)\n            new_solution[route_idx] = np.array(new_route)\n\n    # Phase 2: Spatial-demand hybrid optimization\n    for _ in range(3):\n        if len(new_solution) < 2:\n            break\n\n        # Select two routes for potential merging\n        route_indices = random.sample(range(len(new_solution)), 2)\n        route1, route2 = new_solution[route_indices[0]], new_solution[route_indices[1]]\n\n        # Check if merging is feasible\n        total_demand = np.sum(demand[route1[1:-1]]) + np.sum(demand[route2[1:-1]])\n        if total_demand > capacity:\n            continue\n\n        # Calculate spatial proximity\n        last_node1 = route1[-2]\n        first_node2 = route2[1]\n        spatial_dist = distance_matrix[last_node1, first_node2]\n\n        # Calculate demand balance\n        demand_diff = abs(np.sum(demand[route1[1:-1]]) - np.sum(demand[route2[1:-1]]))\n\n        # Merge if spatial proximity is good and demand balance is reasonable\n        if spatial_dist < np.mean(distance_matrix) * 0.7 and demand_diff < capacity * 0.3:\n            merged_route = np.concatenate([route1[:-1], route2[1:]])\n            new_solution[route_indices[0]] = merged_route\n            new_solution.pop(route_indices[1] if route_indices[1] > route_indices[0] else route_indices[0])\n\n    # Phase 3: Demand-patterned node swaps\n    for _ in range(5):\n        if len(new_solution) < 2:\n            break\n\n        route_indices = random.sample(range(len(new_solution)), 2)\n        route1, route2 = new_solution[route_indices[0]], new_solution[route_indices[1]]\n\n        if len(route1) <= 3 or len(route2) <= 3:\n            continue\n\n        # Find nodes with similar demand patterns\n        route1_demands = demand[route1[1:-1]]\n        route2_demands = demand[route2[1:-1]]\n\n        if len(route1_demands) == 0 or len(route2_demands) == 0:\n            continue\n\n        # Find nodes with similar demand in both routes\n        median1 = np.median(route1_demands)\n        median2 = np.median(route2_demands)\n\n        if abs(median1 - median2) > 0.2 * (median1 + median2):\n            continue\n\n        # Select random nodes from each route\n        node1_pos = random.randint(1, len(route1)-2)\n        node2_pos = random.randint(1, len(route2)-2)\n        node1 = route1[node1_pos]\n        node2 = route2[node2_pos]\n\n        # Check capacity constraints\n        new_route1 = route1.copy()\n        new_route1[node1_pos] = node2\n        new_route2 = route2.copy()\n        new_route2[node2_pos] = node1\n\n        if (np.sum(demand[new_route1[1:-1]]) <= capacity and\n            np.sum(demand[new_route2[1:-1]]) <= capacity):\n\n            # Calculate spatial improvement\n            old_dist = (distance_matrix[route1[node1_pos-1], node1] +\n                         distance_matrix[node1, route1[node1_pos+1]] +\n                         distance_matrix[route2[node2_pos-1], node2] +\n                         distance_matrix[node2, route2[node2_pos+1]])\n\n            new_dist = (distance_matrix[route1[node1_pos-1], node2] +\n                         distance_matrix[node2, route1[node1_pos+1]] +\n                         distance_matrix[route2[node2_pos-1], node1] +\n                         distance_matrix[node1, route2[node2_pos+1]])\n\n            if new_dist < old_dist:\n                new_solution[route_indices[0]] = new_route1\n                new_solution[route_indices[1]] = new_route2\n\n    # Final cleanup\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]) / (1 + abs(x[1][0] - x[1][1])))\n    selected_idx = min(3, len(archive_sorted) - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Multi-stage local search\n    for _ in range(4):  # Perform 4 iterations of the multi-stage operator\n        # Stage 1: Route splitting with demand-aware fragmentation\n        if len(new_solution) > 1:\n            route_idx = random.randint(0, len(new_solution) - 1)\n            route = new_solution[route_idx]\n\n            if len(route) > 4:  # Only split if route is long enough\n                # Find split point that balances demand\n                total_demand = np.sum(demand[route[1:-1]])\n                half_demand = total_demand / 2\n                current_demand = 0\n                split_pos = 1\n\n                for i in range(1, len(route) - 1):\n                    current_demand += demand[route[i]]\n                    if current_demand >= half_demand:\n                        split_pos = i\n                        break\n\n                fragment1 = route[:split_pos+1]\n                fragment2 = np.concatenate([[0], route[split_pos+1:]])\n\n                if (np.sum(demand[fragment1[1:-1]]) <= capacity and\n                    np.sum(demand[fragment2[1:-1]]) <= capacity):\n                    new_solution[route_idx] = fragment1\n                    new_solution.append(fragment2)\n\n        # Stage 2: Customer reallocation with demand pattern matching\n        if len(new_solution) > 1:\n            route_idx = random.randint(0, len(new_solution) - 1)\n            route = new_solution[route_idx]\n\n            if len(route) > 3:\n                # Select customers with similar demand patterns\n                route_demand = demand[route[1:-1]]\n                median_demand = np.median(route_demand)\n                similar_customers = [i for i, d in enumerate(route_demand)\n                                   if abs(d - median_demand) <= median_demand * 0.3]\n\n                if similar_customers:\n                    customer_pos = random.choice(similar_customers) + 1  # +1 for route index\n                    customer = route[customer_pos]\n\n                    # Find best route to insert based on demand compatibility\n                    best_route_idx = -1\n                    best_pos = -1\n                    min_demand_diff = float('inf')\n\n                    for other_idx, other_route in enumerate(new_solution):\n                        if other_idx == route_idx:\n                            continue\n\n                        other_demand = np.sum(demand[other_route[1:-1]])\n                        if other_demand + demand[customer] > capacity:\n                            continue\n\n                        for pos in range(1, len(other_route)):\n                            # Prefer positions that maintain demand balance\n                            new_demand = other_demand + demand[customer]\n                            demand_diff = abs(new_demand - capacity/2)\n\n                            if demand_diff < min_demand_diff:\n                                min_demand_diff = demand_diff\n                                best_route_idx = other_idx\n                                best_pos = pos\n\n                    if best_route_idx != -1:\n                        # Move customer to best position\n                        other_route = new_solution[best_route_idx]\n                        new_other_route = np.concatenate([\n                            other_route[:best_pos],\n                            [customer],\n                            other_route[best_pos:]\n                        ])\n                        new_solution[best_route_idx] = new_other_route\n\n                        # Remove from original route\n                        new_route = np.concatenate([route[:customer_pos], route[customer_pos+1:]])\n                        new_solution[route_idx] = new_route\n\n        # Stage 3: Route merging with load balancing\n        if len(new_solution) > 1:\n            # Select two routes to potentially merge\n            routes_to_merge = random.sample(range(len(new_solution)), min(2, len(new_solution)))\n\n            route1 = new_solution[routes_to_merge[0]]\n            route2 = new_solution[routes_to_merge[1]]\n\n            # Check if merging is feasible and maintains balanced load\n            total_demand = np.sum(demand[route1[1:-1]]) + np.sum(demand[route2[1:-1]])\n            if total_demand <= capacity and len(route1) + len(route2) - 2 <= 25:  # Slightly larger route limit\n                # Create merged route\n                merged_route = np.concatenate([route1[:-1], route2[1:]])\n\n                # Update solution\n                new_solution = [route for i, route in enumerate(new_solution)\n                               if i not in routes_to_merge]\n                new_solution.append(merged_route)\n\n    # Final cleanup\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a weighted combination of normalized distance and makespan (60% distance, 40% makespan), then applies a hybrid local search combining route fragmentation, customer reallocation, and route merging. It iteratively fragments long routes, reallocates customers between routes with capacity checks, and merges small routes while limiting route length to 20 nodes. The solution is refined through 5 iterations and finally normalized to remove empty routes.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    weights = np.array([(obj[0] / max(1, obj[0]), obj[1] / max(1, obj[1])) for _, obj in archive])\n    scores = weights[:, 0] * 0.6 + weights[:, 1] * 0.4  # Weighted combination\n    selected_idx = np.argmin(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Hybrid local search: route fragmentation + customer reallocation + route merging\n    for _ in range(5):  # Perform 5 iterations\n        # Randomly select a route to fragment\n        route_idx = random.randint(0, len(new_solution) - 1)\n        route = new_solution[route_idx]\n\n        if len(route) <= 3:\n            continue\n\n        # Fragment route at random point\n        split_pos = random.randint(2, len(route) - 2)\n        fragment = route[split_pos:]\n        remaining = route[:split_pos]\n\n        # Check capacity feasibility for fragments\n        if np.sum(demand[fragment[1:-1]]) <= capacity and np.sum(demand[remaining[1:-1]]) <= capacity:\n            new_solution[route_idx] = remaining\n            new_solution.append(fragment)\n\n        # Customer reallocation: move customers between routes\n        if len(new_solution) > 1:\n            other_route_idx = random.choice([i for i in range(len(new_solution)) if i != route_idx])\n            other_route = new_solution[other_route_idx]\n\n            # Select customers to move (up to 2)\n            customers_to_move = random.sample(range(1, len(route) - 1), min(2, len(route) - 2))\n\n            for customer_pos in sorted(customers_to_move, reverse=True):\n                customer = route[customer_pos]\n\n                # Find best insertion position in other route\n                best_pos = 1\n                min_increase = float('inf')\n                for pos in range(1, len(other_route)):\n                    dist_increase = (distance_matrix[other_route[pos-1], customer] +\n                                   distance_matrix[customer, other_route[pos]] -\n                                   distance_matrix[other_route[pos-1], other_route[pos]])\n\n                    if dist_increase < min_increase:\n                        min_increase = dist_increase\n                        best_pos = pos\n\n                # Check capacity feasibility\n                if np.sum(demand[other_route[1:-1]]) + demand[customer] <= capacity:\n                    # Insert customer into other route\n                    new_other_route = np.concatenate([other_route[:best_pos], [customer], other_route[best_pos:]])\n                    new_solution[other_route_idx] = new_other_route\n\n                    # Remove customer from original route\n                    new_route = np.concatenate([route[:customer_pos], route[customer_pos+1:]])\n                    new_solution[route_idx] = new_route\n                    route = new_route\n\n        # Route merging: try to merge small routes\n        if len(new_solution) > 1:\n            # Select two routes to potentially merge\n            routes_to_merge = random.sample(range(len(new_solution)), min(2, len(new_solution)))\n\n            route1 = new_solution[routes_to_merge[0]]\n            route2 = new_solution[routes_to_merge[1]]\n\n            # Check if merging is feasible\n            if (np.sum(demand[route1[1:-1]]) + np.sum(demand[route2[1:-1]]) <= capacity and\n                len(route1) + len(route2) - 2 <= 20):  # Limit route length\n\n                # Create merged route (route1 + route2 without depot)\n                merged_route = np.concatenate([route1[:-1], route2[1:]])\n\n                # Update solution\n                new_solution = [route for i, route in enumerate(new_solution)\n                               if i not in routes_to_merge]\n                new_solution.append(merged_route)\n\n    # Remove empty routes and normalize\n    new_solution = [route for route in new_solution if len(route) > 2]\n    new_solution = [np.array(route) for route in new_solution]\n\n    return new_solution\n\n\nNo. 6 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with low total distance and makespan, then applies a hybrid local search combining route reversal and customer insertion to generate a neighbor solution while ensuring feasibility. It intelligently balances exploration and exploitation by iteratively modifying routes and customers, checking capacity constraints, and removing empty routes. The key design choices include prioritizing solutions with better objectives, combining 2-opt-like operations with customer relocations, and ensuring feasibility at each step.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0], x[1][1]))\n    selected_idx = min(5, len(archive_sorted) - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n\n    # Make a deep copy of the solution to modify\n    new_solution = [route.copy() for route in base_solution]\n\n    # Hybrid local search: combine route reversal and customer insertion\n    for _ in range(3):  # Perform 3 iterations of the hybrid operator\n        # Randomly select a route to modify\n        route_idx = random.randint(0, len(new_solution) - 1)\n        route = new_solution[route_idx]\n\n        if len(route) <= 3:  # Skip if route is too short\n            continue\n\n        # Apply route reversal (2-opt-like operation)\n        i, j = sorted(random.sample(range(1, len(route) - 1), 2))\n        reversed_segment = route[i:j+1][::-1]\n        new_route = np.concatenate([route[:i], reversed_segment, route[j+1:]])\n\n        # Check capacity feasibility\n        if np.sum(demand[new_route[1:-1]]) <= capacity:\n            new_solution[route_idx] = new_route\n            route = new_route\n\n        # Apply customer insertion (move a customer to another route)\n        if len(new_solution) > 1:\n            other_route_idx = random.choice([i for i in range(len(new_solution)) if i != route_idx])\n            other_route = new_solution[other_route_idx]\n\n            # Select a random customer to move\n            customer_pos = random.randint(1, len(route) - 2)\n            customer = route[customer_pos]\n\n            # Find insertion position in other route\n            best_pos = 1\n            min_increase = float('inf')\n            for pos in range(1, len(other_route)):\n                # Calculate distance increase\n                dist_increase = (distance_matrix[other_route[pos-1], customer] +\n                                distance_matrix[customer, other_route[pos]] -\n                                distance_matrix[other_route[pos-1], other_route[pos]])\n\n                if dist_increase < min_increase:\n                    min_increase = dist_increase\n                    best_pos = pos\n\n            # Check capacity feasibility\n            if np.sum(demand[other_route[1:-1]]) + demand[customer] <= capacity:\n                # Insert customer into other route\n                new_other_route = np.concatenate([other_route[:best_pos], [customer], other_route[best_pos:]])\n                new_solution[other_route_idx] = new_other_route\n\n                # Remove customer from original route\n                new_route = np.concatenate([route[:customer_pos], route[customer_pos+1:]])\n                new_solution[route_idx] = new_route\n\n    # Remove empty routes\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### Keywords:\n- **Adaptive demand-spatial clustering**\n- **Multi-objective hybrid reallocation**\n- **Dynamic operator fusion**\n- **Extreme-solution targeting**\n\n### Advice:\n1. **Cluster customers by demand and spatial proximity**, prioritizing extreme routes (high distance/makespan) for focused improvement.\n2. **Dynamically fuse operators**: 70% demand-aware reinsertion + 30% capacity-gap reversal, weighted by archive diversity.\n3. **Break-and-repair routes** at depot-proximal capacity gaps, balancing spatial and demand efficiency.\n4. **Adjust operator weights** based on archive diversity (e.g., increase splitting in crowded regions).\n\n### Avoid:\n- Static demand thresholds\n- Rigid operator sequences\n- Single-stage reinsertion\n- Uniform extreme-solution selection\n\n### Explanation:\nThis hybrid approach balances demand and spatial efficiency, dynamically adapts operators to archive needs, and ensures feasible neighbors while exploring Pareto trade-offs. Extreme-solution targeting drives multi-objective improvement, while adaptive operator fusion maintains diversity.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 303,
        "algorithm": "The algorithm selects the most promising solution from the archive by combining demand density and makespan scores, then applies a dynamic hybrid local search that alternates between demand-aware route splitting (prioritized 70% of the time) and spatial-demand hybrid optimization (30% of the time), with operator weights adjusted based on archive diversity to balance exploration and exploitation. The splitting phase identifies and splits routes at demand hotspots while maintaining capacity constraints, while the optimization phase performs demand-weighted node swaps between routes to improve spatial efficiency, ensuring feasibility through continuous capacity validation and spatial checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    demand_densities = []\n    makespans = np.array([obj[1] for _, obj in archive])\n    for sol, obj in archive:\n        total_demand = sum(np.sum(demand[route[1:-1]]) for route in sol)\n        density = total_demand / (obj[0] + 1e-6)\n        demand_densities.append(density)\n\n    # Select solution with highest combined score\n    combined_scores = np.array(demand_densities) * makespans\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Dynamic operator weights based on archive diversity\n    if len(archive) > 1:\n        distances = np.array([obj[0] for _, obj in archive])\n        crowding = (np.max(distances) - np.min(distances)) / (np.mean(distances) + 1e-6)\n        split_weight = 0.7 + 0.2 * crowding\n        swap_weight = 0.3 - 0.2 * crowding\n    else:\n        split_weight = 0.7\n        swap_weight = 0.3\n\n    # Apply operators based on weights\n    if random.random() < split_weight:\n        # Demand-aware route splitting\n        for _ in range(2):\n            if len(new_solution) < 1:\n                break\n\n            # Find route with highest demand concentration\n            demand_sums = [np.sum(demand[route[1:-1]]) for route in new_solution]\n            route_idx = np.argmax(demand_sums)\n            route = new_solution[route_idx]\n\n            if len(route) <= 3:\n                continue\n\n            # Identify demand hotspot (top 30% demand nodes)\n            demands = demand[route[1:-1]]\n            sorted_idx = np.argsort(demands)[::-1]\n            hotspot_size = max(2, int(0.3 * len(demands)))\n            hotspot_nodes = route[sorted_idx[:hotspot_size] + 1]  # +1 for route index\n\n            # Split at first hotspot node\n            split_pos = np.where(route == hotspot_nodes[0])[0][0]\n            if split_pos > 1 and split_pos < len(route) - 1:\n                fragment = route[split_pos:]\n                remaining = route[:split_pos]\n\n                if (np.sum(demand[fragment[1:-1]]) <= capacity and\n                    np.sum(demand[remaining[1:-1]]) <= capacity):\n                    new_solution[route_idx] = remaining\n                    new_solution.append(fragment)\n    else:\n        # Spatial-demand hybrid optimization\n        for _ in range(3):\n            if len(new_solution) < 2:\n                break\n\n            # Select routes with high spatial-demand imbalance\n            route_pairs = []\n            for i in range(len(new_solution)):\n                for j in range(i+1, len(new_solution)):\n                    route1, route2 = new_solution[i], new_solution[j]\n                    last1, first2 = route1[-2], route2[1]\n                    spatial_dist = distance_matrix[last1, first2]\n                    demand_diff = abs(np.sum(demand[route1[1:-1]]) - np.sum(demand[route2[1:-1]]))\n                    imbalance = spatial_dist * demand_diff\n                    route_pairs.append((imbalance, (i, j)))\n\n            if not route_pairs:\n                continue\n\n            # Select pair with highest imbalance\n            _, (i, j) = max(route_pairs)\n            route1, route2 = new_solution[i], new_solution[j]\n\n            # Try demand-weighted node swaps\n            if len(route1) > 3 and len(route2) > 3:\n                # Find nodes with similar demand\n                route1_demands = demand[route1[1:-1]]\n                route2_demands = demand[route2[1:-1]]\n                median1, median2 = np.median(route1_demands), np.median(route2_demands)\n\n                if abs(median1 - median2) < 0.3 * (median1 + median2):\n                    # Select random nodes\n                    node1_pos = random.randint(1, len(route1)-2)\n                    node2_pos = random.randint(1, len(route2)-2)\n                    node1, node2 = route1[node1_pos], route2[node2_pos]\n\n                    # Check capacity and spatial improvement\n                    new_route1 = route1.copy()\n                    new_route1[node1_pos] = node2\n                    new_route2 = route2.copy()\n                    new_route2[node2_pos] = node1\n\n                    if (np.sum(demand[new_route1[1:-1]]) <= capacity and\n                        np.sum(demand[new_route2[1:-1]]) <= capacity):\n\n                        old_dist = (distance_matrix[route1[node1_pos-1], node1] +\n                                    distance_matrix[node1, route1[node1_pos+1]] +\n                                    distance_matrix[route2[node2_pos-1], node2] +\n                                    distance_matrix[node2, route2[node2_pos+1]])\n\n                        new_dist = (distance_matrix[route1[node1_pos-1], node2] +\n                                    distance_matrix[node2, route1[node1_pos+1]] +\n                                    distance_matrix[route2[node2_pos-1], node1] +\n                                    distance_matrix[node1, route2[node2_pos+1]])\n\n                        if new_dist < old_dist:\n                            new_solution[i] = new_route1\n                            new_solution[j] = new_route2\n\n    # Final cleanup\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n",
        "score": [
            -0.7417621382995943,
            0.7890875935554504
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    demand_densities = []\n    makespans = np.array([obj[1] for _, obj in archive])\n    for sol, obj in archive:\n        total_demand = sum(np.sum(demand[route[1:-1]]) for route in sol)\n        density = total_demand / (obj[0] + 1e-6)\n        demand_densities.append(density)\n\n    # Select solution with highest combined score\n    combined_scores = np.array(demand_densities) * makespans\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Dynamic operator weights based on archive diversity\n    if len(archive) > 1:\n        distances = np.array([obj[0] for _, obj in archive])\n        crowding = (np.max(distances) - np.min(distances)) / (np.mean(distances) + 1e-6)\n        split_weight = 0.7 + 0.2 * crowding\n        swap_weight = 0.3 - 0.2 * crowding\n    else:\n        split_weight = 0.7\n        swap_weight = 0.3\n\n    # Apply operators based on weights\n    if random.random() < split_weight:\n        # Demand-aware route splitting\n        for _ in range(2):\n            if len(new_solution) < 1:\n                break\n\n            # Find route with highest demand concentration\n            demand_sums = [np.sum(demand[route[1:-1]]) for route in new_solution]\n            route_idx = np.argmax(demand_sums)\n            route = new_solution[route_idx]\n\n            if len(route) <= 3:\n                continue\n\n            # Identify demand hotspot (top 30% demand nodes)\n            demands = demand[route[1:-1]]\n            sorted_idx = np.argsort(demands)[::-1]\n            hotspot_size = max(2, int(0.3 * len(demands)))\n            hotspot_nodes = route[sorted_idx[:hotspot_size] + 1]  # +1 for route index\n\n            # Split at first hotspot node\n            split_pos = np.where(route == hotspot_nodes[0])[0][0]\n            if split_pos > 1 and split_pos < len(route) - 1:\n                fragment = route[split_pos:]\n                remaining = route[:split_pos]\n\n                if (np.sum(demand[fragment[1:-1]]) <= capacity and\n                    np.sum(demand[remaining[1:-1]]) <= capacity):\n                    new_solution[route_idx] = remaining\n                    new_solution.append(fragment)\n    else:\n        # Spatial-demand hybrid optimization\n        for _ in range(3):\n            if len(new_solution) < 2:\n                break\n\n            # Select routes with high spatial-demand imbalance\n            route_pairs = []\n            for i in range(len(new_solution)):\n                for j in range(i+1, len(new_solution)):\n                    route1, route2 = new_solution[i], new_solution[j]\n                    last1, first2 = route1[-2], route2[1]\n                    spatial_dist = distance_matrix[last1, first2]\n                    demand_diff = abs(np.sum(demand[route1[1:-1]]) - np.sum(demand[route2[1:-1]]))\n                    imbalance = spatial_dist * demand_diff\n                    route_pairs.append((imbalance, (i, j)))\n\n            if not route_pairs:\n                continue\n\n            # Select pair with highest imbalance\n            _, (i, j) = max(route_pairs)\n            route1, route2 = new_solution[i], new_solution[j]\n\n            # Try demand-weighted node swaps\n            if len(route1) > 3 and len(route2) > 3:\n                # Find nodes with similar demand\n                route1_demands = demand[route1[1:-1]]\n                route2_demands = demand[route2[1:-1]]\n                median1, median2 = np.median(route1_demands), np.median(route2_demands)\n\n                if abs(median1 - median2) < 0.3 * (median1 + median2):\n                    # Select random nodes\n                    node1_pos = random.randint(1, len(route1)-2)\n                    node2_pos = random.randint(1, len(route2)-2)\n                    node1, node2 = route1[node1_pos], route2[node2_pos]\n\n                    # Check capacity and spatial improvement\n                    new_route1 = route1.copy()\n                    new_route1[node1_pos] = node2\n                    new_route2 = route2.copy()\n                    new_route2[node2_pos] = node1\n\n                    if (np.sum(demand[new_route1[1:-1]]) <= capacity and\n                        np.sum(demand[new_route2[1:-1]]) <= capacity):\n\n                        old_dist = (distance_matrix[route1[node1_pos-1], node1] +\n                                    distance_matrix[node1, route1[node1_pos+1]] +\n                                    distance_matrix[route2[node2_pos-1], node2] +\n                                    distance_matrix[node2, route2[node2_pos+1]])\n\n                        new_dist = (distance_matrix[route1[node1_pos-1], node2] +\n                                    distance_matrix[node2, route1[node1_pos+1]] +\n                                    distance_matrix[route2[node2_pos-1], node1] +\n                                    distance_matrix[node1, route2[node2_pos+1]])\n\n                        if new_dist < old_dist:\n                            new_solution[i] = new_route1\n                            new_solution[j] = new_route2\n\n    # Final cleanup\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Capacitated Vehicle Routing Problem (Bi-CVRP), where a single depot and multiple customers are located in 2D space. Each customer has a positive demand, and all vehicles in the fleet have identical capacity limits. The objective is to construct a set of routes, each starting and ending at the depot, such that all customers are served, vehicle capacities are not exceeded on any route, and two conflicting objectives are minimized: (1) the total travel distance across all routes, and (2) the makespan, defined as the length of the longest individual route. Each solution in the archive is represented as a list of NumPy arrays, where each array denotes a single route (starting and ending with depot index 0), and is paired with a tuple of two objective values (total_distance, makespan). Your task is to implement a function named 'select_neighbor' that selects one promising solution from the archive and apply a novel or hybrid local search operator to generate a feasible neighbor solution from it. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself. Avoid standard methods like pure 2-opt; instead, invent or combine transformations, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. Ensure that the returned neighbor solution remains feasible under the vehicle capacity constraint. The function should return the new neighbor solution.\n        I have 6 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with low total distance and makespan, then applies a hybrid local search combining route reversal and customer insertion to generate a neighbor solution while ensuring feasibility. It intelligently balances exploration and exploitation by iteratively modifying routes and customers, checking capacity constraints, and removing empty routes. The key design choices include prioritizing solutions with better objectives, combining 2-opt-like operations with customer relocations, and ensuring feasibility at each step.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0], x[1][1]))\n    selected_idx = min(5, len(archive_sorted) - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n\n    # Make a deep copy of the solution to modify\n    new_solution = [route.copy() for route in base_solution]\n\n    # Hybrid local search: combine route reversal and customer insertion\n    for _ in range(3):  # Perform 3 iterations of the hybrid operator\n        # Randomly select a route to modify\n        route_idx = random.randint(0, len(new_solution) - 1)\n        route = new_solution[route_idx]\n\n        if len(route) <= 3:  # Skip if route is too short\n            continue\n\n        # Apply route reversal (2-opt-like operation)\n        i, j = sorted(random.sample(range(1, len(route) - 1), 2))\n        reversed_segment = route[i:j+1][::-1]\n        new_route = np.concatenate([route[:i], reversed_segment, route[j+1:]])\n\n        # Check capacity feasibility\n        if np.sum(demand[new_route[1:-1]]) <= capacity:\n            new_solution[route_idx] = new_route\n            route = new_route\n\n        # Apply customer insertion (move a customer to another route)\n        if len(new_solution) > 1:\n            other_route_idx = random.choice([i for i in range(len(new_solution)) if i != route_idx])\n            other_route = new_solution[other_route_idx]\n\n            # Select a random customer to move\n            customer_pos = random.randint(1, len(route) - 2)\n            customer = route[customer_pos]\n\n            # Find insertion position in other route\n            best_pos = 1\n            min_increase = float('inf')\n            for pos in range(1, len(other_route)):\n                # Calculate distance increase\n                dist_increase = (distance_matrix[other_route[pos-1], customer] +\n                                distance_matrix[customer, other_route[pos]] -\n                                distance_matrix[other_route[pos-1], other_route[pos]])\n\n                if dist_increase < min_increase:\n                    min_increase = dist_increase\n                    best_pos = pos\n\n            # Check capacity feasibility\n            if np.sum(demand[other_route[1:-1]]) + demand[customer] <= capacity:\n                # Insert customer into other route\n                new_other_route = np.concatenate([other_route[:best_pos], [customer], other_route[best_pos:]])\n                new_solution[other_route_idx] = new_other_route\n\n                # Remove customer from original route\n                new_route = np.concatenate([route[:customer_pos], route[customer_pos+1:]])\n                new_solution[route_idx] = new_route\n\n    # Remove empty routes\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a balanced solution from the archive, then applies a dynamic hybrid local search combining demand-aware spatial clustering, load-balanced route fragmentation, and multi-objective hybrid reinsertion, adaptively adjusting operator probabilities based on operator success rates while maintaining feasibility through continuous capacity checks. It prioritizes operators that show recent success (e.g., increasing weights for merge/split if successful) and focuses on spatial proximity and demand compatibility for route modifications.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    archive_sorted = sorted(archive, key=lambda x: abs(x[1][0] - x[1][1]))\n    selected_idx = min(2, len(archive_sorted) - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate route statistics and centroids\n    route_stats = []\n    route_centroids = []\n    for route in new_solution:\n        if len(route) <= 2:\n            route_stats.append((0, 0, 0, 0))\n            route_centroids.append(np.zeros(2))\n            continue\n        customers = route[1:-1]\n        total_demand = np.sum(demand[customers])\n        total_distance = sum(distance_matrix[route[i], route[i+1]] for i in range(len(route)-1))\n        centroid = np.mean(coords[customers], axis=0)\n        route_stats.append((total_demand, total_distance, centroid, len(customers)))\n        route_centroids.append(centroid)\n\n    # Dynamic hybrid local search\n    operators = ['merge', 'split', 'reverse', 'insert']\n    operator_weights = [0.3, 0.3, 0.2, 0.2]  # Initial weights\n\n    for _ in range(5):  # Perform 5 iterations\n        # Select operator based on current weights\n        operator = random.choices(operators, weights=operator_weights, k=1)[0]\n\n        if operator == 'merge' and len(new_solution) >= 2:\n            # Find closest pair of routes\n            min_dist = float('inf')\n            best_pair = None\n            for i in range(len(new_solution)):\n                for j in range(i+1, len(new_solution)):\n                    dist = np.linalg.norm(route_centroids[i] - route_centroids[j])\n                    if dist < min_dist:\n                        min_dist = dist\n                        best_pair = (i, j)\n\n            if best_pair:\n                i, j = best_pair\n                route1, route2 = new_solution[i], new_solution[j]\n                total_demand = route_stats[i][0] + route_stats[j][0]\n                if total_demand <= capacity:\n                    merged_route = np.concatenate([route1[:-1], route2[1:]])\n                    new_solution[i] = merged_route\n                    new_solution.pop(j)\n                    route_stats.pop(j)\n                    route_centroids.pop(j)\n                    if len(merged_route) > 2:\n                        customers = merged_route[1:-1]\n                        route_stats[i] = (np.sum(demand[customers]),\n                                         sum(distance_matrix[merged_route[k], merged_route[k+1]] for k in range(len(merged_route)-1)),\n                                         np.mean(coords[customers], axis=0),\n                                         len(customers))\n                        route_centroids[i] = route_stats[i][2]\n                    else:\n                        route_stats[i] = (0, 0, np.zeros(2), 0)\n                        route_centroids[i] = np.zeros(2)\n                    # Update weights to favor merge more if successful\n                    operator_weights = [w * 1.1 if op == 'merge' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'split' and len(new_solution) > 1:\n            # Find longest route with high demand\n            longest_idx = max(range(len(new_solution)), key=lambda i: route_stats[i][0])\n            route = new_solution[longest_idx]\n            if len(route) > 4:\n                customers = route[1:-1]\n                total_demand = route_stats[longest_idx][0]\n                best_split = None\n                min_diff = float('inf')\n\n                for j in range(2, len(route)-2):\n                    left_demand = np.sum(demand[route[1:j+1]])\n                    right_demand = total_demand - left_demand\n                    if left_demand <= capacity and right_demand <= capacity:\n                        diff = abs(left_demand - right_demand)\n                        if diff < min_diff:\n                            min_diff = diff\n                            best_split = j\n\n                if best_split:\n                    j = best_split\n                    first_part = route[:j+1] + [0]\n                    second_part = [0] + route[j+1:]\n\n                    new_solution[longest_idx] = first_part\n                    new_solution.append(second_part)\n\n                    # Update stats for both parts\n                    for k, part in enumerate([first_part, second_part]):\n                        if len(part) > 2:\n                            customers = part[1:-1]\n                            stats = (np.sum(demand[customers]),\n                                   sum(distance_matrix[part[i], part[i+1]] for i in range(len(part)-1)),\n                                   np.mean(coords[customers], axis=0),\n                                   len(customers))\n                            if k == 0:\n                                route_stats[longest_idx] = stats\n                                route_centroids[longest_idx] = stats[2]\n                            else:\n                                route_stats.append(stats)\n                                route_centroids.append(stats[2])\n                        else:\n                            if k == 0:\n                                route_stats[longest_idx] = (0, 0, np.zeros(2), 0)\n                                route_centroids[longest_idx] = np.zeros(2)\n                            else:\n                                route_stats.append((0, 0, np.zeros(2), 0))\n                                route_centroids.append(np.zeros(2))\n                    # Update weights to favor split more if successful\n                    operator_weights = [w * 1.1 if op == 'split' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'reverse' and len(new_solution) > 0:\n            # Select a route to reverse\n            route_idx = random.randint(0, len(new_solution) - 1)\n            route = new_solution[route_idx]\n            if len(route) > 3:\n                i, j = sorted(random.sample(range(1, len(route) - 1), 2))\n                reversed_segment = route[i:j+1][::-1]\n                new_route = np.concatenate([route[:i], reversed_segment, route[j+1:]])\n\n                if np.sum(demand[new_route[1:-1]]) <= capacity:\n                    new_solution[route_idx] = new_route\n                    customers = new_route[1:-1]\n                    route_stats[route_idx] = (np.sum(demand[customers]),\n                                             sum(distance_matrix[new_route[k], new_route[k+1]] for k in range(len(new_route)-1)),\n                                             np.mean(coords[customers], axis=0),\n                                             len(customers))\n                    route_centroids[route_idx] = route_stats[route_idx][2]\n                    # Update weights to favor reverse more if successful\n                    operator_weights = [w * 1.1 if op == 'reverse' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'insert' and len(new_solution) > 1:\n            # Select two different routes\n            route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n            route1, route2 = new_solution[route1_idx], new_solution[route2_idx]\n\n            if len(route1) > 3 and len(route2) > 2:\n                # Select a customer to move\n                customer_pos = random.randint(1, len(route1) - 2)\n                customer = route1[customer_pos]\n\n                # Find best insertion position in route2\n                best_pos = 1\n                min_increase = float('inf')\n                for pos in range(1, len(route2)):\n                    dist_increase = (distance_matrix[route2[pos-1], customer] +\n                                   distance_matrix[customer, route2[pos]] -\n                                   distance_matrix[route2[pos-1], route2[pos]])\n\n                    if dist_increase < min_increase:\n                        min_increase = dist_increase\n                        best_pos = pos\n\n                # Check capacity feasibility\n                if route_stats[route2_idx][0] + demand[customer] <= capacity:\n                    # Insert customer into route2\n                    new_route2 = np.concatenate([route2[:best_pos], [customer], route2[best_pos:]])\n                    new_solution[route2_idx] = new_route2\n\n                    # Remove customer from route1\n                    new_route1 = np.concatenate([route1[:customer_pos], route1[customer_pos+1:]])\n                    new_solution[route1_idx] = new_route1\n\n                    # Update stats for both routes\n                    for k, route in enumerate([new_route1, new_route2]):\n                        if len(route) > 2:\n                            customers = route[1:-1]\n                            stats = (np.sum(demand[customers]),\n                                   sum(distance_matrix[route[i], route[i+1]] for i in range(len(route)-1)),\n                                   np.mean(coords[customers], axis=0),\n                                   len(customers))\n                            if k == 0:\n                                route_stats[route1_idx] = stats\n                                route_centroids[route1_idx] = stats[2]\n                            else:\n                                route_stats[route2_idx] = stats\n                                route_centroids[route2_idx] = stats[2]\n                        else:\n                            if k == 0:\n                                route_stats[route1_idx] = (0, 0, np.zeros(2), 0)\n                                route_centroids[route1_idx] = np.zeros(2)\n                            else:\n                                route_stats[route2_idx] = (0, 0, np.zeros(2), 0)\n                                route_centroids[route2_idx] = np.zeros(2)\n                    # Update weights to favor insert more if successful\n                    operator_weights = [w * 1.1 if op == 'insert' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n    # Remove empty routes\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using adaptive extreme-solution targeting, then applies a multi-stage hybrid local search combining demand-aware spatial clustering, dynamic operator fusion, and weighted multi-objective reinsertion to generate a neighbor solution while maintaining feasibility. It prioritizes operators that improve both objectives (distance and makespan) through weighted scoring, with higher weights for successful operators, and balances improvements between routes based on demand clusters. The algorithm dynamically adjusts operator weights and focuses on demand-aware transformations to balance the bi-objective optimization.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    archive_sorted = sorted(archive, key=lambda x: max(x[1][0], x[1][1]), reverse=True)\n    selected_idx = min(3, len(archive_sorted) - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate route statistics and demand clusters\n    route_stats = []\n    demand_clusters = []\n    for route in new_solution:\n        if len(route) <= 2:\n            route_stats.append((0, 0, 0, 0))\n            demand_clusters.append(0)\n            continue\n        customers = route[1:-1]\n        total_demand = np.sum(demand[customers])\n        total_distance = sum(distance_matrix[route[i], route[i+1]] for i in range(len(route)-1))\n        demand_cluster = np.mean(demand[customers])\n        route_stats.append((total_demand, total_distance, demand_cluster, len(customers)))\n        demand_clusters.append(demand_cluster)\n\n    # Dynamic operator fusion\n    operators = ['cluster_merge', 'demand_split', 'reverse', 'weighted_insert']\n    operator_weights = [0.3, 0.3, 0.2, 0.2]\n\n    for _ in range(5):\n        operator = random.choices(operators, weights=operator_weights, k=1)[0]\n\n        if operator == 'cluster_merge' and len(new_solution) >= 2:\n            # Merge routes from the same demand cluster\n            cluster_routes = {}\n            for i, route in enumerate(new_solution):\n                if len(route) > 2:\n                    cluster = route_stats[i][2]\n                    if cluster not in cluster_routes:\n                        cluster_routes[cluster] = []\n                    cluster_routes[cluster].append(i)\n\n            for cluster, routes in cluster_routes.items():\n                if len(routes) >= 2:\n                    i, j = sorted(routes[:2])\n                    route1, route2 = new_solution[i], new_solution[j]\n                    total_demand = route_stats[i][0] + route_stats[j][0]\n                    if total_demand <= capacity:\n                        merged_route = np.concatenate([route1[:-1], route2[1:]])\n                        new_solution[i] = merged_route\n                        new_solution.pop(j)\n                        route_stats.pop(j)\n                        demand_clusters.pop(j)\n                        if len(merged_route) > 2:\n                            customers = merged_route[1:-1]\n                            route_stats[i] = (np.sum(demand[customers]),\n                                            sum(distance_matrix[merged_route[k], merged_route[k+1]] for k in range(len(merged_route)-1)),\n                                            np.mean(demand[customers]),\n                                            len(customers))\n                            demand_clusters[i] = route_stats[i][2]\n                        else:\n                            route_stats[i] = (0, 0, 0, 0)\n                            demand_clusters[i] = 0\n                        operator_weights = [w * 1.1 if op == 'cluster_merge' else w * 0.9 for w, op in zip(operator_weights, operators)]\n                        break\n\n        elif operator == 'demand_split' and len(new_solution) > 1:\n            # Split routes based on demand balance\n            longest_idx = max(range(len(new_solution)), key=lambda i: route_stats[i][0])\n            route = new_solution[longest_idx]\n            if len(route) > 4:\n                customers = route[1:-1]\n                total_demand = route_stats[longest_idx][0]\n                best_split = None\n                min_diff = float('inf')\n\n                for j in range(2, len(route)-2):\n                    left_demand = np.sum(demand[route[1:j+1]])\n                    right_demand = total_demand - left_demand\n                    if left_demand <= capacity and right_demand <= capacity:\n                        diff = abs(left_demand - right_demand)\n                        if diff < min_diff:\n                            min_diff = diff\n                            best_split = j\n\n                if best_split:\n                    j = best_split\n                    first_part = route[:j+1] + [0]\n                    second_part = [0] + route[j+1:]\n\n                    new_solution[longest_idx] = first_part\n                    new_solution.append(second_part)\n\n                    for k, part in enumerate([first_part, second_part]):\n                        if len(part) > 2:\n                            customers = part[1:-1]\n                            stats = (np.sum(demand[customers]),\n                                   sum(distance_matrix[part[i], part[i+1]] for i in range(len(part)-1)),\n                                   np.mean(demand[customers]),\n                                   len(customers))\n                            if k == 0:\n                                route_stats[longest_idx] = stats\n                                demand_clusters[longest_idx] = stats[2]\n                            else:\n                                route_stats.append(stats)\n                                demand_clusters.append(stats[2])\n                        else:\n                            if k == 0:\n                                route_stats[longest_idx] = (0, 0, 0, 0)\n                                demand_clusters[longest_idx] = 0\n                            else:\n                                route_stats.append((0, 0, 0, 0))\n                                demand_clusters.append(0)\n                    operator_weights = [w * 1.1 if op == 'demand_split' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'reverse' and len(new_solution) > 0:\n            # Reverse route segment with demand-aware selection\n            route_idx = random.randint(0, len(new_solution) - 1)\n            route = new_solution[route_idx]\n            if len(route) > 3:\n                i, j = sorted(random.sample(range(1, len(route) - 1), 2))\n                reversed_segment = route[i:j+1][::-1]\n                new_route = np.concatenate([route[:i], reversed_segment, route[j+1:]])\n\n                if np.sum(demand[new_route[1:-1]]) <= capacity:\n                    new_solution[route_idx] = new_route\n                    customers = new_route[1:-1]\n                    route_stats[route_idx] = (np.sum(demand[customers]),\n                                           sum(distance_matrix[new_route[k], new_route[k+1]] for k in range(len(new_route)-1)),\n                                           np.mean(demand[customers]),\n                                           len(customers))\n                    demand_clusters[route_idx] = route_stats[route_idx][2]\n                    operator_weights = [w * 1.1 if op == 'reverse' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'weighted_insert' and len(new_solution) > 1:\n            # Weighted multi-objective reinsertion\n            route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n            route1, route2 = new_solution[route1_idx], new_solution[route2_idx]\n\n            if len(route1) > 3 and len(route2) > 2:\n                customer_pos = random.randint(1, len(route1) - 2)\n                customer = route1[customer_pos]\n\n                best_pos = 1\n                min_score = float('inf')\n                for pos in range(1, len(route2)):\n                    dist_increase = distance_matrix[route2[pos-1], customer] + distance_matrix[customer, route2[pos]] - distance_matrix[route2[pos-1], route2[pos]]\n                    makespan_increase = max(0, dist_increase - (route_stats[route2_idx][1] - distance_matrix[route2[pos-1], route2[pos]]))\n                    weighted_score = 0.7 * dist_increase + 0.3 * makespan_increase\n\n                    if weighted_score < min_score:\n                        min_score = weighted_score\n                        best_pos = pos\n\n                if route_stats[route2_idx][0] + demand[customer] <= capacity:\n                    new_route2 = np.concatenate([route2[:best_pos], [customer], route2[best_pos:]])\n                    new_solution[route2_idx] = new_route2\n\n                    new_route1 = np.concatenate([route1[:customer_pos], route1[customer_pos+1:]])\n                    new_solution[route1_idx] = new_route1\n\n                    for k, route in enumerate([new_route1, new_route2]):\n                        if len(route) > 2:\n                            customers = route[1:-1]\n                            stats = (np.sum(demand[customers]),\n                                   sum(distance_matrix[route[i], route[i+1]] for i in range(len(route)-1)),\n                                   np.mean(demand[customers]),\n                                   len(customers))\n                            if k == 0:\n                                route_stats[route1_idx] = stats\n                                demand_clusters[route1_idx] = stats[2]\n                            else:\n                                route_stats[route2_idx] = stats\n                                demand_clusters[route2_idx] = stats[2]\n                        else:\n                            if k == 0:\n                                route_stats[route1_idx] = (0, 0, 0, 0)\n                                demand_clusters[route1_idx] = 0\n                            else:\n                                route_stats[route2_idx] = (0, 0, 0, 0)\n                                demand_clusters[route2_idx] = 0\n                    operator_weights = [w * 1.1 if op == 'weighted_insert' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive demand-spatial clustering with extreme-solution targeting to prioritize reallocating customers from overloaded routes, using a weighted hybrid local search approach that dynamically adjusts operator probabilities based on success rates and archive diversity, while maintaining feasibility through capacity checks and spatial proximity constraints. It selectively applies demand-aware spatial reinsertion, capacity-balanced fragmentation, and demand-balanced swaps to extreme routes, breaking and repairing routes at capacity gaps to balance spatial efficiency and demand distribution. The algorithm emphasizes high-demand regions, spatial coherence, and capacity balance while adapting operator selection based on performance feedback.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0], x[1][1]), reverse=True)\n    selected_idx = min(2, len(archive_sorted) - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    all_customers = []\n    for route in new_solution:\n        if len(route) > 2:\n            all_customers.extend(route[1:-1])\n\n    if not all_customers:\n        return new_solution\n\n    demand_clusters = []\n    for route in new_solution:\n        if len(route) > 2:\n            customers = route[1:-1]\n            total_demand = np.sum(demand[customers])\n            demand_density = total_demand / len(customers)\n            demand_clusters.append((total_demand, demand_density))\n        else:\n            demand_clusters.append((0, 0))\n\n    operators = ['spatial_reinsert', 'capacity_fragment', 'demand_balance']\n    operator_weights = [0.4, 0.3, 0.3]\n\n    for _ in range(5):\n        operator = random.choices(operators, weights=operator_weights, k=1)[0]\n\n        if operator == 'spatial_reinsert' and len(new_solution) > 1:\n            route_idx = max(range(len(new_solution)), key=lambda i: demand_clusters[i][0] if len(new_solution[i]) > 2 else 0)\n            route = new_solution[route_idx]\n\n            if len(route) > 3:\n                customer_pos = random.randint(1, len(route)-2)\n                customer = route[customer_pos]\n\n                best_route = None\n                best_pos = None\n                min_distance = float('inf')\n\n                for r_idx in range(len(new_solution)):\n                    if r_idx == route_idx or len(new_solution[r_idx]) < 2:\n                        continue\n\n                    target_route = new_solution[r_idx]\n                    for pos in range(1, len(target_route)):\n                        new_demand = demand_clusters[r_idx][0] + demand[customer]\n                        if new_demand > capacity:\n                            continue\n\n                        distance_score = distance_matrix[target_route[pos-1], customer] + distance_matrix[customer, target_route[pos]] - distance_matrix[target_route[pos-1], target_route[pos]]\n                        spatial_score = np.linalg.norm(coords[customer] - np.mean(coords[target_route[1:-1]], axis=0))\n                        total_score = 0.6 * distance_score + 0.4 * spatial_score\n\n                        if total_score < min_distance:\n                            min_distance = total_score\n                            best_route = r_idx\n                            best_pos = pos\n\n                if best_route is not None:\n                    target_route = new_solution[best_route]\n                    new_target_route = np.concatenate([target_route[:best_pos], [customer], target_route[best_pos:]])\n                    new_solution[best_route] = new_target_route\n\n                    new_route = np.concatenate([route[:customer_pos], route[customer_pos+1:]])\n                    new_solution[route_idx] = new_route\n\n                    for r in [route_idx, best_route]:\n                        if len(new_solution[r]) > 2:\n                            customers = new_solution[r][1:-1]\n                            total_demand = np.sum(demand[customers])\n                            demand_density = total_demand / len(customers)\n                            demand_clusters[r] = (total_demand, demand_density)\n                        else:\n                            demand_clusters[r] = (0, 0)\n\n                    operator_weights = [w * 1.2 if op == 'spatial_reinsert' else w * 0.8 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'capacity_fragment' and len(new_solution) > 0:\n            route_idx = max(range(len(new_solution)), key=lambda i: demand_clusters[i][0] if len(new_solution[i]) > 2 else 0)\n            route = new_solution[route_idx]\n\n            if len(route) > 4:\n                best_split = None\n                min_diff = float('inf')\n\n                for j in range(2, len(route)-2):\n                    left_demand = np.sum(demand[route[1:j+1]])\n                    right_demand = np.sum(demand[route[j+1:-1]])\n                    if left_demand <= capacity and right_demand <= capacity:\n                        diff = abs(left_demand - right_demand)\n                        if diff < min_diff:\n                            min_diff = diff\n                            best_split = j\n\n                if best_split:\n                    j = best_split\n                    first_part = np.concatenate([route[:j+1], [0]])\n                    second_part = np.concatenate([[0], route[j+1:]])\n\n                    new_solution[route_idx] = first_part\n                    new_solution.append(second_part)\n\n                    for part in [first_part, second_part]:\n                        if len(part) > 2:\n                            customers = part[1:-1]\n                            total_demand = np.sum(demand[customers])\n                            demand_density = total_demand / len(customers)\n                            demand_clusters.append((total_demand, demand_density))\n                        else:\n                            demand_clusters.append((0, 0))\n\n                    operator_weights = [w * 1.2 if op == 'capacity_fragment' else w * 0.8 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'demand_balance' and len(new_solution) > 1:\n            min_diff = float('inf')\n            best_pair = None\n            for i in range(len(new_solution)):\n                for j in range(i+1, len(new_solution)):\n                    if len(new_solution[i]) > 2 and len(new_solution[j]) > 2:\n                        diff = abs(demand_clusters[i][0] - demand_clusters[j][0])\n                        if diff < min_diff:\n                            min_diff = diff\n                            best_pair = (i, j)\n\n            if best_pair:\n                i, j = best_pair\n                route1, route2 = new_solution[i], new_solution[j]\n\n                if len(route1) > 3 and len(route2) > 3:\n                    customer1_pos = random.randint(1, len(route1)-2)\n                    customer2_pos = random.randint(1, len(route2)-2)\n                    customer1, customer2 = route1[customer1_pos], route2[customer2_pos]\n\n                    new_demand1 = demand_clusters[i][0] - demand[customer1] + demand[customer2]\n                    new_demand2 = demand_clusters[j][0] - demand[customer2] + demand[customer1]\n\n                    if new_demand1 <= capacity and new_demand2 <= capacity:\n                        new_route1 = route1.copy()\n                        new_route1[customer1_pos] = customer2\n                        new_route2 = route2.copy()\n                        new_route2[customer2_pos] = customer1\n\n                        new_solution[i] = new_route1\n                        new_solution[j] = new_route2\n\n                        for r in [i, j]:\n                            customers = new_solution[r][1:-1]\n                            total_demand = np.sum(demand[customers])\n                            demand_density = total_demand / len(customers)\n                            demand_clusters[r] = (total_demand, demand_density)\n\n                        operator_weights = [w * 1.2 if op == 'demand_balance' else w * 0.8 for w, op in zip(operator_weights, operators)]\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm implements a multi-stage, demand-aware local search strategy that first selects a promising solution from the archive using crowding distance metrics, then applies a hybrid of demand-based route fragmentation (70% probability) and route reversal (30% probability) to generate neighbors while respecting capacity constraints. It prioritizes solutions with high crowding distances and dynamically adjusts operator weights to balance exploration and exploitation, ensuring feasible solutions through continuous demand checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    if len(archive) > 1:\n        distances = np.array([obj[0] for _, obj in archive])\n        makespans = np.array([obj[1] for _, obj in archive])\n        norm_dist = (distances - np.min(distances)) / (np.max(distances) - np.min(distances) + 1e-6)\n        norm_makespan = (makespans - np.min(makespans)) / (np.max(makespans) - np.min(makespans) + 1e-6)\n        crowding = np.zeros(len(archive))\n        for i in range(len(archive)):\n            left = i - 1 if i > 0 else 0\n            right = i + 1 if i < len(archive) - 1 else len(archive) - 1\n            crowding[i] = norm_dist[right] - norm_dist[left] + norm_makespan[right] - norm_makespan[left]\n        selected_idx = np.argmax(crowding)\n    else:\n        selected_idx = 0\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    for _ in range(3):\n        if len(new_solution) > 1:\n            route_idx = random.choice(range(len(new_solution)))\n            route = new_solution[route_idx]\n            if len(route) > 3:\n                demands = demand[route[1:-1]]\n                mean_demand = np.mean(demands)\n                split_pos = 1\n                current_demand = 0\n                for i in range(1, len(route)-1):\n                    current_demand += demand[route[i]]\n                    if current_demand >= mean_demand * (len(route)-2) / 2:\n                        split_pos = i\n                        break\n                fragment = route[split_pos:]\n                remaining = route[:split_pos]\n                if np.sum(demand[fragment[1:-1]]) <= capacity and np.sum(demand[remaining[1:-1]]) <= capacity:\n                    new_solution[route_idx] = remaining\n                    new_solution.append(fragment)\n\n        if len(new_solution) > 1 and random.random() < 0.3:\n            route_idx = random.choice(range(len(new_solution)))\n            route = new_solution[route_idx]\n            if len(route) > 4:\n                i, j = sorted(random.sample(range(1, len(route)-1), 2))\n                reversed_segment = route[i:j+1][::-1]\n                new_route = np.concatenate([route[:i], reversed_segment, route[j+1:]])\n                if np.sum(demand[new_route[1:-1]]) <= capacity:\n                    new_solution[route_idx] = new_route\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n\nNo. 6 algorithm's description and the corresponding code are:\nThis algorithm implements an adaptive multi-objective local search for the Bi-CVRP that combines four specialized operators (fragmentation, reallocation, hybrid insertion, and swapping) with dynamic weighting based on operator success. It prioritizes solutions with high potential for Pareto improvement by selectively breaking and repairing routes at capacity gaps, balancing spatial efficiency with demand compatibility through probabilistic transformations, and adjusts operator probabilities based on recent success rates. The method maintains feasibility through continuous capacity checks while targeting both total distance and makespan minimization.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] * 0.5 + x[1][1] * 0.5) / (1 + 0.3 * abs(x[1][0] - x[1][1])))\n    selected_idx = min(1, len(archive_sorted) - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    route_stats = []\n    for route in new_solution:\n        customers = route[1:-1]\n        total_demand = np.sum(demand[customers])\n        total_distance = sum(distance_matrix[route[i], route[i+1]] for i in range(len(route)-1))\n        route_stats.append((total_demand, total_distance))\n\n    operators = ['fragment', 'reallocate', 'hybrid_insert', 'swap']\n    operator_weights = [0.25, 0.25, 0.25, 0.25]\n\n    for _ in range(5):\n        operator = random.choices(operators, weights=operator_weights, k=1)[0]\n\n        if operator == 'fragment' and len(new_solution) > 1:\n            target_idx = np.argmax([stats[1] for stats in route_stats])\n            route = new_solution[target_idx]\n            if len(route) > 4:\n                split_pos = len(route) // 2\n                fragment1 = route[:split_pos+1]\n                fragment2 = np.concatenate([[0], route[split_pos+1:]])\n\n                if (np.sum(demand[fragment1[1:-1]]) <= capacity and\n                    np.sum(demand[fragment2[1:-1]]) <= capacity):\n                    new_solution[target_idx] = fragment1\n                    new_solution.append(fragment2)\n                    route_stats[target_idx] = (np.sum(demand[fragment1[1:-1]]),\n                                             sum(distance_matrix[fragment1[i], fragment1[i+1]] for i in range(len(fragment1)-1)))\n                    route_stats.append((np.sum(demand[fragment2[1:-1]]),\n                                      sum(distance_matrix[fragment2[i], fragment2[i+1]] for i in range(len(fragment2)-1))))\n                    operator_weights = [w * 1.1 if op == 'fragment' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'reallocate' and len(new_solution) > 1:\n            target_idx = np.argmax([stats[0] for stats in route_stats])\n            route = new_solution[target_idx]\n            if len(route) > 3:\n                customers = route[1:-1]\n                if len(customers) > 0:\n                    demand_weights = np.abs(demand[customers] - np.mean(demand[route[1:-1]]))\n                    selected_customer_idx = np.argmax(demand_weights)\n                    customer = customers[selected_customer_idx]\n                    customer_pos = np.where(route == customer)[0][0]\n\n                    best_route_idx = -1\n                    best_score = float('inf')\n\n                    for other_idx, other_route in enumerate(new_solution):\n                        if other_idx == target_idx:\n                            continue\n\n                        other_demand = route_stats[other_idx][0]\n                        if other_demand + demand[customer] > capacity:\n                            continue\n\n                        spatial_dist = distance_matrix[other_route[-2], customer]\n                        demand_score = abs(other_demand + demand[customer] - capacity * 0.6)\n\n                        total_score = spatial_dist * 0.4 + demand_score * 0.6\n\n                        if total_score < best_score:\n                            best_score = total_score\n                            best_route_idx = other_idx\n\n                    if best_route_idx != -1:\n                        other_route = new_solution[best_route_idx]\n                        new_other_route = np.concatenate([other_route[:-1], [customer], [0]])\n                        new_solution[best_route_idx] = new_other_route\n                        route_stats[best_route_idx] = (route_stats[best_route_idx][0] + demand[customer],\n                                                      route_stats[best_route_idx][1] + distance_matrix[other_route[-2], customer])\n\n                        new_route = np.concatenate([route[:customer_pos], route[customer_pos+1:]])\n                        new_solution[target_idx] = new_route\n                        route_stats[target_idx] = (route_stats[target_idx][0] - demand[customer],\n                                                  route_stats[target_idx][1] - distance_matrix[route[customer_pos-1], route[customer_pos]] - distance_matrix[route[customer_pos], route[customer_pos+1]] + distance_matrix[route[customer_pos-1], route[customer_pos+1]])\n                        operator_weights = [w * 1.1 if op == 'reallocate' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'hybrid_insert' and len(new_solution) > 1:\n            target_idx = random.randint(0, len(new_solution) - 1)\n            route = new_solution[target_idx]\n            if len(route) > 3:\n                customers = route[1:-1]\n                if len(customers) > 0:\n                    demand_weights = np.abs(demand[customers] - np.mean(demand[route[1:-1]]))\n                    selected_customer_idx = np.argmin(demand_weights)\n                    customer = customers[selected_customer_idx]\n                    customer_pos = np.where(route == customer)[0][0]\n\n                    best_route_idx = -1\n                    best_pos = -1\n                    best_score = float('inf')\n\n                    for other_idx, other_route in enumerate(new_solution):\n                        if other_idx == target_idx:\n                            continue\n\n                        other_demand = route_stats[other_idx][0]\n                        if other_demand + demand[customer] > capacity:\n                            continue\n\n                        for pos in range(1, len(other_route)):\n                            dist_increase = (distance_matrix[other_route[pos-1], customer] +\n                                           distance_matrix[customer, other_route[pos]] -\n                                           distance_matrix[other_route[pos-1], other_route[pos]])\n\n                            demand_score = abs(other_demand + demand[customer] - capacity * 0.5)\n\n                            total_score = dist_increase * 0.6 + demand_score * 0.4\n\n                            if total_score < best_score:\n                                best_score = total_score\n                                best_route_idx = other_idx\n                                best_pos = pos\n\n                    if best_route_idx != -1:\n                        other_route = new_solution[best_route_idx]\n                        new_other_route = np.concatenate([other_route[:best_pos], [customer], other_route[best_pos:]])\n                        new_solution[best_route_idx] = new_other_route\n                        route_stats[best_route_idx] = (route_stats[best_route_idx][0] + demand[customer],\n                                                      route_stats[best_route_idx][1] + best_score)\n\n                        new_route = np.concatenate([route[:customer_pos], route[customer_pos+1:]])\n                        new_solution[target_idx] = new_route\n                        route_stats[target_idx] = (route_stats[target_idx][0] - demand[customer],\n                                                  route_stats[target_idx][1] - best_score)\n                        operator_weights = [w * 1.1 if op == 'hybrid_insert' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'swap' and len(new_solution) > 1:\n            route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n            route1, route2 = new_solution[route1_idx], new_solution[route2_idx]\n\n            if len(route1) > 3 and len(route2) > 3:\n                customer1_pos = random.randint(1, len(route1) - 2)\n                customer2_pos = random.randint(1, len(route2) - 2)\n                customer1, customer2 = route1[customer1_pos], route2[customer2_pos]\n\n                if (route_stats[route1_idx][0] - demand[customer1] + demand[customer2] <= capacity and\n                    route_stats[route2_idx][0] - demand[customer2] + demand[customer1] <= capacity):\n\n                    route1[customer1_pos], route2[customer2_pos] = customer2, customer1\n\n                    dist1_change = (distance_matrix[route1[customer1_pos-1], customer2] +\n                                  distance_matrix[customer2, route1[customer1_pos+1]] -\n                                  distance_matrix[route1[customer1_pos-1], customer1] -\n                                  distance_matrix[customer1, route1[customer1_pos+1]])\n\n                    dist2_change = (distance_matrix[route2[customer2_pos-1], customer1] +\n                                  distance_matrix[customer1, route2[customer2_pos+1]] -\n                                  distance_matrix[route2[customer2_pos-1], customer2] -\n                                  distance_matrix[customer2, route2[customer2_pos+1]])\n\n                    route_stats[route1_idx] = (route_stats[route1_idx][0] - demand[customer1] + demand[customer2],\n                                             route_stats[route1_idx][1] + dist1_change)\n                    route_stats[route2_idx] = (route_stats[route2_idx][0] - demand[customer2] + demand[customer1],\n                                             route_stats[route2_idx][1] + dist2_change)\n                    operator_weights = [w * 1.1 if op == 'swap' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: ### Keywords:\n- **Adaptive demand-distance clustering**\n- **Multi-objective hybrid reinsertion**\n- **Dynamic operator fusion**\n- **Extreme-solution targeting**\n\n### Advice:\n1. **Cluster customers by demand and spatial proximity**, prioritizing extreme routes (high distance/makespan) for focused improvement.\n2. **Dynamically fuse operators**: 70% demand-aware reinsertion + 30% capacity-gap reversal, weighted by archive diversity.\n3. **Break-and-repair routes** at depot-proximal capacity gaps, balancing spatial and demand efficiency.\n4. **Adjust operator weights** based on archive diversity (e.g., increase splitting in crowded regions).\n\n### Avoid:\n- Static demand thresholds\n- Rigid operator sequences\n- Single-stage reinsertion\n- Uniform extreme-solution selection\n\n### Explanation:\nThis hybrid approach balances demand and spatial efficiency, dynamically adapts operators to archive needs, and ensures feasible neighbors while exploring Pareto trade-offs. Extreme-solution targeting drives multi-objective improvement, while adaptive operator fusion maintains diversity.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 304,
        "algorithm": "The algorithm implements an adaptive hybrid local search for the Bi-CVRP by combining demand-distance clustering, dynamic operator fusion, and extreme-solution targeting. It prioritizes routes with high demand density for fragmentation, selectively reinserts customers to balance capacity, and reverses segments in near-capacity routes, with operator weights adjusted based on success rates. The selection of operators and their application are dynamically adjusted to balance spatial efficiency and demand distribution.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    if len(archive) > 1:\n        distances = np.array([obj[0] for _, obj in archive])\n        makespans = np.array([obj[1] for _, obj in archive])\n        norm_dist = (distances - np.min(distances)) / (np.max(distances) - np.min(distances) + 1e-6)\n        norm_makespan = (makespans - np.min(makespans)) / (np.max(makespans) - np.min(makespans) + 1e-6)\n        crowding = norm_dist + norm_makespan\n        selected_idx = np.argmax(crowding)\n    else:\n        selected_idx = 0\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate route statistics and demand clusters\n    route_stats = []\n    demand_clusters = []\n    for route in new_solution:\n        if len(route) <= 2:\n            route_stats.append((0, 0, 0))\n            demand_clusters.append(0)\n            continue\n        customers = route[1:-1]\n        total_demand = np.sum(demand[customers])\n        total_distance = sum(distance_matrix[route[i], route[i+1]] for i in range(len(route)-1))\n        demand_density = total_demand / len(customers) if len(customers) > 0 else 0\n        route_stats.append((total_demand, total_distance, demand_density))\n        demand_clusters.append(demand_density)\n\n    # Dynamic operator fusion\n    operators = ['cluster_fragment', 'demand_reinsert', 'capacity_reverse']\n    operator_weights = [0.5, 0.3, 0.2]\n\n    for _ in range(5):\n        operator = random.choices(operators, weights=operator_weights, k=1)[0]\n\n        if operator == 'cluster_fragment' and len(new_solution) > 1:\n            # Fragment routes with high demand density\n            target_idx = np.argmax([stats[2] for stats in route_stats])\n            route = new_solution[target_idx]\n            if len(route) > 4:\n                split_pos = len(route) // 2\n                fragment1 = route[:split_pos+1]\n                fragment2 = np.concatenate([[0], route[split_pos+1:]])\n\n                if (np.sum(demand[fragment1[1:-1]]) <= capacity and\n                    np.sum(demand[fragment2[1:-1]]) <= capacity):\n                    new_solution[target_idx] = fragment1\n                    new_solution.append(fragment2)\n                    route_stats[target_idx] = (np.sum(demand[fragment1[1:-1]]),\n                                             sum(distance_matrix[fragment1[i], fragment1[i+1]] for i in range(len(fragment1)-1)),\n                                             np.sum(demand[fragment1[1:-1]]) / len(fragment1[1:-1]) if len(fragment1[1:-1]) > 0 else 0)\n                    route_stats.append((np.sum(demand[fragment2[1:-1]]),\n                                      sum(distance_matrix[fragment2[i], fragment2[i+1]] for i in range(len(fragment2)-1)),\n                                      np.sum(demand[fragment2[1:-1]]) / len(fragment2[1:-1]) if len(fragment2[1:-1]) > 0 else 0))\n                    operator_weights = [w * 1.1 if op == 'cluster_fragment' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'demand_reinsert' and len(new_solution) > 1:\n            # Reinsert customers from high-demand routes to better-matching routes\n            source_idx = np.argmax([stats[0] for stats in route_stats])\n            source_route = new_solution[source_idx]\n            if len(source_route) > 3:\n                customers = source_route[1:-1]\n                demand_weights = np.abs(demand[customers] - np.mean(demand[source_route[1:-1]]))\n                selected_customer_idx = np.argmax(demand_weights)\n                customer = customers[selected_customer_idx]\n                customer_pos = np.where(source_route == customer)[0][0]\n\n                best_route_idx = -1\n                best_pos = -1\n                best_score = float('inf')\n\n                for other_idx, other_route in enumerate(new_solution):\n                    if other_idx == source_idx:\n                        continue\n\n                    other_demand = route_stats[other_idx][0]\n                    if other_demand + demand[customer] > capacity:\n                        continue\n\n                    # Find best insertion position\n                    for pos in range(1, len(other_route)):\n                        dist_increase = (distance_matrix[other_route[pos-1], customer] +\n                                       distance_matrix[customer, other_route[pos]] -\n                                       distance_matrix[other_route[pos-1], other_route[pos]])\n\n                        demand_score = abs(other_demand + demand[customer] - capacity * 0.5)\n\n                        total_score = dist_increase * 0.6 + demand_score * 0.4\n\n                        if total_score < best_score:\n                            best_score = total_score\n                            best_route_idx = other_idx\n                            best_pos = pos\n\n                if best_route_idx != -1:\n                    other_route = new_solution[best_route_idx]\n                    new_other_route = np.concatenate([other_route[:best_pos], [customer], other_route[best_pos:]])\n                    new_solution[best_route_idx] = new_other_route\n                    route_stats[best_route_idx] = (route_stats[best_route_idx][0] + demand[customer],\n                                                  route_stats[best_route_idx][1] + best_score,\n                                                  (route_stats[best_route_idx][0] + demand[customer]) / len(new_other_route[1:-1]) if len(new_other_route[1:-1]) > 0 else 0)\n\n                    new_source_route = np.concatenate([source_route[:customer_pos], source_route[customer_pos+1:]])\n                    new_solution[source_idx] = new_source_route\n                    route_stats[source_idx] = (route_stats[source_idx][0] - demand[customer],\n                                             route_stats[source_idx][1] - best_score,\n                                             (route_stats[source_idx][0] - demand[customer]) / len(new_source_route[1:-1]) if len(new_source_route[1:-1]) > 0 else 0)\n                    operator_weights = [w * 1.1 if op == 'demand_reinsert' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'capacity_reverse' and len(new_solution) > 0:\n            # Reverse segments in routes near capacity limits\n            target_idx = np.argmin([capacity - stats[0] for stats in route_stats])\n            route = new_solution[target_idx]\n            if len(route) > 4:\n                i, j = sorted(random.sample(range(1, len(route)-1), 2))\n                reversed_segment = route[i:j+1][::-1]\n                new_route = np.concatenate([route[:i], reversed_segment, route[j+1:]])\n\n                if np.sum(demand[new_route[1:-1]]) <= capacity:\n                    new_solution[target_idx] = new_route\n                    route_stats[target_idx] = (route_stats[target_idx][0],\n                                             sum(distance_matrix[new_route[k], new_route[k+1]] for k in range(len(new_route)-1)),\n                                             route_stats[target_idx][2])\n                    operator_weights = [w * 1.1 if op == 'capacity_reverse' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n    # Remove empty routes\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n",
        "score": [
            -0.7413984046832535,
            0.48912686109542847
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    if len(archive) > 1:\n        distances = np.array([obj[0] for _, obj in archive])\n        makespans = np.array([obj[1] for _, obj in archive])\n        norm_dist = (distances - np.min(distances)) / (np.max(distances) - np.min(distances) + 1e-6)\n        norm_makespan = (makespans - np.min(makespans)) / (np.max(makespans) - np.min(makespans) + 1e-6)\n        crowding = norm_dist + norm_makespan\n        selected_idx = np.argmax(crowding)\n    else:\n        selected_idx = 0\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate route statistics and demand clusters\n    route_stats = []\n    demand_clusters = []\n    for route in new_solution:\n        if len(route) <= 2:\n            route_stats.append((0, 0, 0))\n            demand_clusters.append(0)\n            continue\n        customers = route[1:-1]\n        total_demand = np.sum(demand[customers])\n        total_distance = sum(distance_matrix[route[i], route[i+1]] for i in range(len(route)-1))\n        demand_density = total_demand / len(customers) if len(customers) > 0 else 0\n        route_stats.append((total_demand, total_distance, demand_density))\n        demand_clusters.append(demand_density)\n\n    # Dynamic operator fusion\n    operators = ['cluster_fragment', 'demand_reinsert', 'capacity_reverse']\n    operator_weights = [0.5, 0.3, 0.2]\n\n    for _ in range(5):\n        operator = random.choices(operators, weights=operator_weights, k=1)[0]\n\n        if operator == 'cluster_fragment' and len(new_solution) > 1:\n            # Fragment routes with high demand density\n            target_idx = np.argmax([stats[2] for stats in route_stats])\n            route = new_solution[target_idx]\n            if len(route) > 4:\n                split_pos = len(route) // 2\n                fragment1 = route[:split_pos+1]\n                fragment2 = np.concatenate([[0], route[split_pos+1:]])\n\n                if (np.sum(demand[fragment1[1:-1]]) <= capacity and\n                    np.sum(demand[fragment2[1:-1]]) <= capacity):\n                    new_solution[target_idx] = fragment1\n                    new_solution.append(fragment2)\n                    route_stats[target_idx] = (np.sum(demand[fragment1[1:-1]]),\n                                             sum(distance_matrix[fragment1[i], fragment1[i+1]] for i in range(len(fragment1)-1)),\n                                             np.sum(demand[fragment1[1:-1]]) / len(fragment1[1:-1]) if len(fragment1[1:-1]) > 0 else 0)\n                    route_stats.append((np.sum(demand[fragment2[1:-1]]),\n                                      sum(distance_matrix[fragment2[i], fragment2[i+1]] for i in range(len(fragment2)-1)),\n                                      np.sum(demand[fragment2[1:-1]]) / len(fragment2[1:-1]) if len(fragment2[1:-1]) > 0 else 0))\n                    operator_weights = [w * 1.1 if op == 'cluster_fragment' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'demand_reinsert' and len(new_solution) > 1:\n            # Reinsert customers from high-demand routes to better-matching routes\n            source_idx = np.argmax([stats[0] for stats in route_stats])\n            source_route = new_solution[source_idx]\n            if len(source_route) > 3:\n                customers = source_route[1:-1]\n                demand_weights = np.abs(demand[customers] - np.mean(demand[source_route[1:-1]]))\n                selected_customer_idx = np.argmax(demand_weights)\n                customer = customers[selected_customer_idx]\n                customer_pos = np.where(source_route == customer)[0][0]\n\n                best_route_idx = -1\n                best_pos = -1\n                best_score = float('inf')\n\n                for other_idx, other_route in enumerate(new_solution):\n                    if other_idx == source_idx:\n                        continue\n\n                    other_demand = route_stats[other_idx][0]\n                    if other_demand + demand[customer] > capacity:\n                        continue\n\n                    # Find best insertion position\n                    for pos in range(1, len(other_route)):\n                        dist_increase = (distance_matrix[other_route[pos-1], customer] +\n                                       distance_matrix[customer, other_route[pos]] -\n                                       distance_matrix[other_route[pos-1], other_route[pos]])\n\n                        demand_score = abs(other_demand + demand[customer] - capacity * 0.5)\n\n                        total_score = dist_increase * 0.6 + demand_score * 0.4\n\n                        if total_score < best_score:\n                            best_score = total_score\n                            best_route_idx = other_idx\n                            best_pos = pos\n\n                if best_route_idx != -1:\n                    other_route = new_solution[best_route_idx]\n                    new_other_route = np.concatenate([other_route[:best_pos], [customer], other_route[best_pos:]])\n                    new_solution[best_route_idx] = new_other_route\n                    route_stats[best_route_idx] = (route_stats[best_route_idx][0] + demand[customer],\n                                                  route_stats[best_route_idx][1] + best_score,\n                                                  (route_stats[best_route_idx][0] + demand[customer]) / len(new_other_route[1:-1]) if len(new_other_route[1:-1]) > 0 else 0)\n\n                    new_source_route = np.concatenate([source_route[:customer_pos], source_route[customer_pos+1:]])\n                    new_solution[source_idx] = new_source_route\n                    route_stats[source_idx] = (route_stats[source_idx][0] - demand[customer],\n                                             route_stats[source_idx][1] - best_score,\n                                             (route_stats[source_idx][0] - demand[customer]) / len(new_source_route[1:-1]) if len(new_source_route[1:-1]) > 0 else 0)\n                    operator_weights = [w * 1.1 if op == 'demand_reinsert' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'capacity_reverse' and len(new_solution) > 0:\n            # Reverse segments in routes near capacity limits\n            target_idx = np.argmin([capacity - stats[0] for stats in route_stats])\n            route = new_solution[target_idx]\n            if len(route) > 4:\n                i, j = sorted(random.sample(range(1, len(route)-1), 2))\n                reversed_segment = route[i:j+1][::-1]\n                new_route = np.concatenate([route[:i], reversed_segment, route[j+1:]])\n\n                if np.sum(demand[new_route[1:-1]]) <= capacity:\n                    new_solution[target_idx] = new_route\n                    route_stats[target_idx] = (route_stats[target_idx][0],\n                                             sum(distance_matrix[new_route[k], new_route[k+1]] for k in range(len(new_route)-1)),\n                                             route_stats[target_idx][2])\n                    operator_weights = [w * 1.1 if op == 'capacity_reverse' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n    # Remove empty routes\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Capacitated Vehicle Routing Problem (Bi-CVRP), where a single depot and multiple customers are located in 2D space. Each customer has a positive demand, and all vehicles in the fleet have identical capacity limits. The objective is to construct a set of routes, each starting and ending at the depot, such that all customers are served, vehicle capacities are not exceeded on any route, and two conflicting objectives are minimized: (1) the total travel distance across all routes, and (2) the makespan, defined as the length of the longest individual route. Each solution in the archive is represented as a list of NumPy arrays, where each array denotes a single route (starting and ending with depot index 0), and is paired with a tuple of two objective values (total_distance, makespan). Your task is to implement a function named 'select_neighbor' that selects one promising solution from the archive and apply a novel or hybrid local search operator to generate a feasible neighbor solution from it. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself. Avoid standard methods like pure 2-opt; instead, invent or combine transformations, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. Ensure that the returned neighbor solution remains feasible under the vehicle capacity constraint. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm combines adaptive demand-spatial clustering with extreme-solution targeting to prioritize reallocating customers from overloaded routes, using a weighted hybrid local search approach that dynamically adjusts operator probabilities based on success rates and archive diversity, while maintaining feasibility through capacity checks and spatial proximity constraints. It selectively applies demand-aware spatial reinsertion, capacity-balanced fragmentation, and demand-balanced swaps to extreme routes, breaking and repairing routes at capacity gaps to balance spatial efficiency and demand distribution. The algorithm emphasizes high-demand regions, spatial coherence, and capacity balance while adapting operator selection based on performance feedback.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0], x[1][1]), reverse=True)\n    selected_idx = min(2, len(archive_sorted) - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    all_customers = []\n    for route in new_solution:\n        if len(route) > 2:\n            all_customers.extend(route[1:-1])\n\n    if not all_customers:\n        return new_solution\n\n    demand_clusters = []\n    for route in new_solution:\n        if len(route) > 2:\n            customers = route[1:-1]\n            total_demand = np.sum(demand[customers])\n            demand_density = total_demand / len(customers)\n            demand_clusters.append((total_demand, demand_density))\n        else:\n            demand_clusters.append((0, 0))\n\n    operators = ['spatial_reinsert', 'capacity_fragment', 'demand_balance']\n    operator_weights = [0.4, 0.3, 0.3]\n\n    for _ in range(5):\n        operator = random.choices(operators, weights=operator_weights, k=1)[0]\n\n        if operator == 'spatial_reinsert' and len(new_solution) > 1:\n            route_idx = max(range(len(new_solution)), key=lambda i: demand_clusters[i][0] if len(new_solution[i]) > 2 else 0)\n            route = new_solution[route_idx]\n\n            if len(route) > 3:\n                customer_pos = random.randint(1, len(route)-2)\n                customer = route[customer_pos]\n\n                best_route = None\n                best_pos = None\n                min_distance = float('inf')\n\n                for r_idx in range(len(new_solution)):\n                    if r_idx == route_idx or len(new_solution[r_idx]) < 2:\n                        continue\n\n                    target_route = new_solution[r_idx]\n                    for pos in range(1, len(target_route)):\n                        new_demand = demand_clusters[r_idx][0] + demand[customer]\n                        if new_demand > capacity:\n                            continue\n\n                        distance_score = distance_matrix[target_route[pos-1], customer] + distance_matrix[customer, target_route[pos]] - distance_matrix[target_route[pos-1], target_route[pos]]\n                        spatial_score = np.linalg.norm(coords[customer] - np.mean(coords[target_route[1:-1]], axis=0))\n                        total_score = 0.6 * distance_score + 0.4 * spatial_score\n\n                        if total_score < min_distance:\n                            min_distance = total_score\n                            best_route = r_idx\n                            best_pos = pos\n\n                if best_route is not None:\n                    target_route = new_solution[best_route]\n                    new_target_route = np.concatenate([target_route[:best_pos], [customer], target_route[best_pos:]])\n                    new_solution[best_route] = new_target_route\n\n                    new_route = np.concatenate([route[:customer_pos], route[customer_pos+1:]])\n                    new_solution[route_idx] = new_route\n\n                    for r in [route_idx, best_route]:\n                        if len(new_solution[r]) > 2:\n                            customers = new_solution[r][1:-1]\n                            total_demand = np.sum(demand[customers])\n                            demand_density = total_demand / len(customers)\n                            demand_clusters[r] = (total_demand, demand_density)\n                        else:\n                            demand_clusters[r] = (0, 0)\n\n                    operator_weights = [w * 1.2 if op == 'spatial_reinsert' else w * 0.8 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'capacity_fragment' and len(new_solution) > 0:\n            route_idx = max(range(len(new_solution)), key=lambda i: demand_clusters[i][0] if len(new_solution[i]) > 2 else 0)\n            route = new_solution[route_idx]\n\n            if len(route) > 4:\n                best_split = None\n                min_diff = float('inf')\n\n                for j in range(2, len(route)-2):\n                    left_demand = np.sum(demand[route[1:j+1]])\n                    right_demand = np.sum(demand[route[j+1:-1]])\n                    if left_demand <= capacity and right_demand <= capacity:\n                        diff = abs(left_demand - right_demand)\n                        if diff < min_diff:\n                            min_diff = diff\n                            best_split = j\n\n                if best_split:\n                    j = best_split\n                    first_part = np.concatenate([route[:j+1], [0]])\n                    second_part = np.concatenate([[0], route[j+1:]])\n\n                    new_solution[route_idx] = first_part\n                    new_solution.append(second_part)\n\n                    for part in [first_part, second_part]:\n                        if len(part) > 2:\n                            customers = part[1:-1]\n                            total_demand = np.sum(demand[customers])\n                            demand_density = total_demand / len(customers)\n                            demand_clusters.append((total_demand, demand_density))\n                        else:\n                            demand_clusters.append((0, 0))\n\n                    operator_weights = [w * 1.2 if op == 'capacity_fragment' else w * 0.8 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'demand_balance' and len(new_solution) > 1:\n            min_diff = float('inf')\n            best_pair = None\n            for i in range(len(new_solution)):\n                for j in range(i+1, len(new_solution)):\n                    if len(new_solution[i]) > 2 and len(new_solution[j]) > 2:\n                        diff = abs(demand_clusters[i][0] - demand_clusters[j][0])\n                        if diff < min_diff:\n                            min_diff = diff\n                            best_pair = (i, j)\n\n            if best_pair:\n                i, j = best_pair\n                route1, route2 = new_solution[i], new_solution[j]\n\n                if len(route1) > 3 and len(route2) > 3:\n                    customer1_pos = random.randint(1, len(route1)-2)\n                    customer2_pos = random.randint(1, len(route2)-2)\n                    customer1, customer2 = route1[customer1_pos], route2[customer2_pos]\n\n                    new_demand1 = demand_clusters[i][0] - demand[customer1] + demand[customer2]\n                    new_demand2 = demand_clusters[j][0] - demand[customer2] + demand[customer1]\n\n                    if new_demand1 <= capacity and new_demand2 <= capacity:\n                        new_route1 = route1.copy()\n                        new_route1[customer1_pos] = customer2\n                        new_route2 = route2.copy()\n                        new_route2[customer2_pos] = customer1\n\n                        new_solution[i] = new_route1\n                        new_solution[j] = new_route2\n\n                        for r in [i, j]:\n                            customers = new_solution[r][1:-1]\n                            total_demand = np.sum(demand[customers])\n                            demand_density = total_demand / len(customers)\n                            demand_clusters[r] = (total_demand, demand_density)\n\n                        operator_weights = [w * 1.2 if op == 'demand_balance' else w * 0.8 for w, op in zip(operator_weights, operators)]\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm implements a demand-aware hybrid local search strategy that first selects extreme solutions (high makespan or demand density) and then dynamically blends capacity-balanced route splitting (60% weight) with spatial-demand cluster merging (40% weight), adjusting operator weights based on archive diversity to balance distance and makespan minimization while maintaining feasibility through continuous demand and spatial validation. The selection prioritizes routes with high demand concentration near capacity for splitting, while merging focuses on spatially and demand-similar route pairs to reduce fragmentation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    demand_densities = []\n    makespans = []\n    for sol, obj in archive:\n        total_demand = sum(np.sum(demand[route[1:-1]]) for route in sol)\n        density = total_demand / (obj[0] + 1e-6)\n        demand_densities.append(density)\n        makespans.append(obj[1])\n\n    extreme_scores = np.array(demand_densities) * np.array(makespans)\n    selected_idx = np.argmax(extreme_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Step 2: Dynamic operator weights based on archive diversity\n    if len(archive) > 1:\n        distances = np.array([obj[0] for _, obj in archive])\n        crowding = (np.max(distances) - np.min(distances)) / (np.mean(distances) + 1e-6)\n        split_weight = 0.6 + 0.3 * crowding\n        merge_weight = 0.4 - 0.3 * crowding\n    else:\n        split_weight = 0.6\n        merge_weight = 0.4\n\n    # Step 3: Capacity-balanced route splitting\n    for _ in range(2):\n        if len(new_solution) < 1:\n            break\n\n        # Find route with highest demand concentration near capacity\n        demand_sums = [np.sum(demand[route[1:-1]]) for route in new_solution]\n        route_idx = np.argmax(demand_sums)\n        route = new_solution[route_idx]\n\n        if len(route) <= 3:\n            continue\n\n        # Calculate demand distribution\n        demands = demand[route[1:-1]]\n        cumulative_demand = np.cumsum(demands)\n        total_demand = cumulative_demand[-1]\n\n        # Find split point that balances capacity\n        target_demand = total_demand / 2\n        split_pos = np.argmin(np.abs(cumulative_demand - target_demand)) + 1  # +1 for route index\n\n        if split_pos > 1 and split_pos < len(route) - 1:\n            fragment = route[split_pos:]\n            remaining = route[:split_pos]\n\n            if (np.sum(demand[fragment[1:-1]]) <= capacity and\n                np.sum(demand[remaining[1:-1]]) <= capacity):\n                new_solution[route_idx] = remaining\n                new_solution.append(fragment)\n\n    # Step 4: Spatial-demand cluster merging\n    for _ in range(3):\n        if len(new_solution) < 2:\n            break\n\n        # Find closest route pairs based on spatial and demand similarity\n        route_pairs = []\n        for i in range(len(new_solution)):\n            for j in range(i+1, len(new_solution)):\n                route1, route2 = new_solution[i], new_solution[j]\n                # Spatial distance between last node of route1 and first node of route2\n                spatial_dist = distance_matrix[route1[-2], route2[1]]\n                # Demand similarity\n                demand_diff = abs(np.sum(demand[route1[1:-1]]) - np.sum(demand[route2[1:-1]]))\n                similarity_score = spatial_dist * demand_diff\n                route_pairs.append((similarity_score, (i, j)))\n\n        if not route_pairs:\n            continue\n\n        # Select pair with lowest similarity score\n        _, (i, j) = min(route_pairs)\n        route1, route2 = new_solution[i], new_solution[j]\n\n        # Check if merging is feasible\n        total_demand = np.sum(demand[route1[1:-1]]) + np.sum(demand[route2[1:-1]])\n        if total_demand <= capacity:\n            # Merge routes\n            merged_route = np.concatenate([route1[:-1], route2[1:]])\n            new_solution[i] = merged_route\n            del new_solution[j]\n\n    # Final cleanup\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### Keywords:\n- **Adaptive demand-distance clustering**\n- **Multi-objective hybrid reinsertion**\n- **Dynamic operator fusion**\n- **Extreme-solution targeting**\n\n### Advice:\n1. **Cluster customers by demand and spatial proximity**, prioritizing extreme routes (high distance/makespan) for focused improvement.\n2. **Dynamically fuse operators**: 70% demand-aware reinsertion + 30% capacity-gap reversal, weighted by archive diversity.\n3. **Break-and-repair routes** at depot-proximal capacity gaps, balancing spatial and demand efficiency.\n4. **Adjust operator weights** based on archive diversity (e.g., increase splitting in crowded regions).\n\n### Avoid:\n- Static demand thresholds\n- Rigid operator sequences\n- Single-stage reinsertion\n- Uniform extreme-solution selection\n\n### Explanation:\nThis hybrid approach balances demand and spatial efficiency, dynamically adapts operators to archive needs, and ensures feasible neighbors while exploring Pareto trade-offs. Extreme-solution targeting drives multi-objective improvement, while adaptive operator fusion maintains diversity.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 305,
        "algorithm": "The algorithm selects promising solutions from an archive based on extreme demand density and makespan scores, then applies a hybrid local search using three specialized operators (demand-balanced route splitting, spatial-aware customer reallocation, and capacity-constrained route merging) weighted by their recent success and archive diversity, prioritizing operators that improve both distance and makespan objectives while maintaining feasibility through continuous demand and spatial validation. The selection process emphasizes solutions with high demand density and makespan, while the local search dynamically adapts operator weights based on archive diversity, with demand-split and spatial-reallocation operators given higher initial weights.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    demand_densities = []\n    makespans = []\n    for sol, obj in archive:\n        total_demand = sum(np.sum(demand[route[1:-1]]) for route in sol)\n        density = total_demand / (obj[0] + 1e-6)\n        demand_densities.append(density)\n        makespans.append(obj[1])\n\n    # Score solutions by combined demand density and makespan\n    extreme_scores = np.array(demand_densities) * np.array(makespans)\n    selected_idx = np.argmax(extreme_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Step 2: Dynamic operator weights based on archive diversity\n    if len(archive) > 1:\n        distances = np.array([obj[0] for _, obj in archive])\n        crowding = (np.max(distances) - np.min(distances)) / (np.mean(distances) + 1e-6)\n        split_weight = 0.5 + 0.2 * crowding\n        realloc_weight = 0.3 + 0.2 * (1 - crowding)\n        merge_weight = 0.2 + 0.1 * crowding\n    else:\n        split_weight = 0.5\n        realloc_weight = 0.3\n        merge_weight = 0.2\n\n    operators = ['demand_split', 'spatial_realloc', 'capacity_merge']\n    operator_weights = [split_weight, realloc_weight, merge_weight]\n\n    # Step 3: Apply hybrid local search\n    for _ in range(3):\n        operator = random.choices(operators, weights=operator_weights, k=1)[0]\n\n        if operator == 'demand_split' and len(new_solution) > 0:\n            # Find route with highest demand concentration\n            demand_sums = [np.sum(demand[route[1:-1]]) for route in new_solution]\n            route_idx = np.argmax(demand_sums)\n            route = new_solution[route_idx]\n\n            if len(route) > 3:\n                # Calculate demand distribution\n                demands = demand[route[1:-1]]\n                cumulative_demand = np.cumsum(demands)\n                total_demand = cumulative_demand[-1]\n\n                # Find split point that balances demand\n                target_demand = total_demand / 2\n                split_pos = np.argmin(np.abs(cumulative_demand - target_demand)) + 1\n\n                if split_pos > 1 and split_pos < len(route) - 1:\n                    fragment = route[split_pos:]\n                    remaining = route[:split_pos]\n\n                    if (np.sum(demand[fragment[1:-1]]) <= capacity and\n                        np.sum(demand[remaining[1:-1]]) <= capacity):\n                        new_solution[route_idx] = remaining\n                        new_solution.append(fragment)\n                        operator_weights = [w * 1.1 if op == 'demand_split' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'spatial_realloc' and len(new_solution) > 1:\n            # Find route with highest spatial deviation\n            spatial_deviations = []\n            for route in new_solution:\n                if len(route) > 2:\n                    customers = route[1:-1]\n                    centroid = np.mean(coords[customers], axis=0)\n                    deviations = np.linalg.norm(coords[customers] - centroid, axis=1)\n                    spatial_deviations.append(np.mean(deviations))\n                else:\n                    spatial_deviations.append(0)\n\n            route_idx = np.argmax(spatial_deviations)\n            route = new_solution[route_idx]\n\n            if len(route) > 3:\n                # Select customer farthest from centroid\n                customers = route[1:-1]\n                centroid = np.mean(coords[customers], axis=0)\n                deviations = np.linalg.norm(coords[customers] - centroid, axis=1)\n                customer_pos = np.argmax(deviations) + 1  # +1 to account for route[0] being depot\n                customer = route[customer_pos]\n\n                # Find best target route and position\n                best_route = None\n                best_pos = None\n                min_score = float('inf')\n\n                for r_idx in range(len(new_solution)):\n                    if r_idx == route_idx or len(new_solution[r_idx]) < 2:\n                        continue\n\n                    target_route = new_solution[r_idx]\n                    for pos in range(1, len(target_route)):\n                        new_demand = np.sum(demand[target_route[1:-1]]) + demand[customer]\n                        if new_demand > capacity:\n                            continue\n\n                        # Score by spatial proximity and distance improvement\n                        spatial_score = np.linalg.norm(coords[customer] - np.mean(coords[target_route[1:-1]], axis=0))\n                        distance_score = (distance_matrix[target_route[pos-1], customer] +\n                                         distance_matrix[customer, target_route[pos]] -\n                                         distance_matrix[target_route[pos-1], target_route[pos]])\n                        total_score = 0.7 * spatial_score + 0.3 * distance_score\n\n                        if total_score < min_score:\n                            min_score = total_score\n                            best_route = r_idx\n                            best_pos = pos\n\n                if best_route is not None:\n                    target_route = new_solution[best_route]\n                    new_target_route = np.concatenate([target_route[:best_pos], [customer], target_route[best_pos:]])\n                    new_solution[best_route] = new_target_route\n\n                    new_route = np.concatenate([route[:customer_pos], route[customer_pos+1:]])\n                    new_solution[route_idx] = new_route\n                    operator_weights = [w * 1.1 if op == 'spatial_realloc' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'capacity_merge' and len(new_solution) > 1:\n            # Find route pair with smallest capacity gap\n            demand_sums = [np.sum(demand[route[1:-1]]) for route in new_solution]\n            min_gap = float('inf')\n            best_pair = None\n\n            for i in range(len(new_solution)):\n                for j in range(i+1, len(new_solution)):\n                    gap = abs(demand_sums[i] - demand_sums[j])\n                    if gap < min_gap and (demand_sums[i] + demand_sums[j]) <= capacity:\n                        min_gap = gap\n                        best_pair = (i, j)\n\n            if best_pair:\n                i, j = best_pair\n                route1, route2 = new_solution[i], new_solution[j]\n\n                # Check spatial proximity\n                spatial_dist = distance_matrix[route1[-2], route2[1]]\n                if spatial_dist < np.mean(distance_matrix[np.triu_indices(len(distance_matrix), 1)]):\n                    merged_route = np.concatenate([route1[:-1], route2[1:]])\n                    new_solution[i] = merged_route\n                    del new_solution[j]\n                    operator_weights = [w * 1.1 if op == 'capacity_merge' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n    # Final cleanup\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n",
        "score": [
            -0.4067170457437262,
            2.9947590231895447
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    demand_densities = []\n    makespans = []\n    for sol, obj in archive:\n        total_demand = sum(np.sum(demand[route[1:-1]]) for route in sol)\n        density = total_demand / (obj[0] + 1e-6)\n        demand_densities.append(density)\n        makespans.append(obj[1])\n\n    # Score solutions by combined demand density and makespan\n    extreme_scores = np.array(demand_densities) * np.array(makespans)\n    selected_idx = np.argmax(extreme_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Step 2: Dynamic operator weights based on archive diversity\n    if len(archive) > 1:\n        distances = np.array([obj[0] for _, obj in archive])\n        crowding = (np.max(distances) - np.min(distances)) / (np.mean(distances) + 1e-6)\n        split_weight = 0.5 + 0.2 * crowding\n        realloc_weight = 0.3 + 0.2 * (1 - crowding)\n        merge_weight = 0.2 + 0.1 * crowding\n    else:\n        split_weight = 0.5\n        realloc_weight = 0.3\n        merge_weight = 0.2\n\n    operators = ['demand_split', 'spatial_realloc', 'capacity_merge']\n    operator_weights = [split_weight, realloc_weight, merge_weight]\n\n    # Step 3: Apply hybrid local search\n    for _ in range(3):\n        operator = random.choices(operators, weights=operator_weights, k=1)[0]\n\n        if operator == 'demand_split' and len(new_solution) > 0:\n            # Find route with highest demand concentration\n            demand_sums = [np.sum(demand[route[1:-1]]) for route in new_solution]\n            route_idx = np.argmax(demand_sums)\n            route = new_solution[route_idx]\n\n            if len(route) > 3:\n                # Calculate demand distribution\n                demands = demand[route[1:-1]]\n                cumulative_demand = np.cumsum(demands)\n                total_demand = cumulative_demand[-1]\n\n                # Find split point that balances demand\n                target_demand = total_demand / 2\n                split_pos = np.argmin(np.abs(cumulative_demand - target_demand)) + 1\n\n                if split_pos > 1 and split_pos < len(route) - 1:\n                    fragment = route[split_pos:]\n                    remaining = route[:split_pos]\n\n                    if (np.sum(demand[fragment[1:-1]]) <= capacity and\n                        np.sum(demand[remaining[1:-1]]) <= capacity):\n                        new_solution[route_idx] = remaining\n                        new_solution.append(fragment)\n                        operator_weights = [w * 1.1 if op == 'demand_split' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'spatial_realloc' and len(new_solution) > 1:\n            # Find route with highest spatial deviation\n            spatial_deviations = []\n            for route in new_solution:\n                if len(route) > 2:\n                    customers = route[1:-1]\n                    centroid = np.mean(coords[customers], axis=0)\n                    deviations = np.linalg.norm(coords[customers] - centroid, axis=1)\n                    spatial_deviations.append(np.mean(deviations))\n                else:\n                    spatial_deviations.append(0)\n\n            route_idx = np.argmax(spatial_deviations)\n            route = new_solution[route_idx]\n\n            if len(route) > 3:\n                # Select customer farthest from centroid\n                customers = route[1:-1]\n                centroid = np.mean(coords[customers], axis=0)\n                deviations = np.linalg.norm(coords[customers] - centroid, axis=1)\n                customer_pos = np.argmax(deviations) + 1  # +1 to account for route[0] being depot\n                customer = route[customer_pos]\n\n                # Find best target route and position\n                best_route = None\n                best_pos = None\n                min_score = float('inf')\n\n                for r_idx in range(len(new_solution)):\n                    if r_idx == route_idx or len(new_solution[r_idx]) < 2:\n                        continue\n\n                    target_route = new_solution[r_idx]\n                    for pos in range(1, len(target_route)):\n                        new_demand = np.sum(demand[target_route[1:-1]]) + demand[customer]\n                        if new_demand > capacity:\n                            continue\n\n                        # Score by spatial proximity and distance improvement\n                        spatial_score = np.linalg.norm(coords[customer] - np.mean(coords[target_route[1:-1]], axis=0))\n                        distance_score = (distance_matrix[target_route[pos-1], customer] +\n                                         distance_matrix[customer, target_route[pos]] -\n                                         distance_matrix[target_route[pos-1], target_route[pos]])\n                        total_score = 0.7 * spatial_score + 0.3 * distance_score\n\n                        if total_score < min_score:\n                            min_score = total_score\n                            best_route = r_idx\n                            best_pos = pos\n\n                if best_route is not None:\n                    target_route = new_solution[best_route]\n                    new_target_route = np.concatenate([target_route[:best_pos], [customer], target_route[best_pos:]])\n                    new_solution[best_route] = new_target_route\n\n                    new_route = np.concatenate([route[:customer_pos], route[customer_pos+1:]])\n                    new_solution[route_idx] = new_route\n                    operator_weights = [w * 1.1 if op == 'spatial_realloc' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'capacity_merge' and len(new_solution) > 1:\n            # Find route pair with smallest capacity gap\n            demand_sums = [np.sum(demand[route[1:-1]]) for route in new_solution]\n            min_gap = float('inf')\n            best_pair = None\n\n            for i in range(len(new_solution)):\n                for j in range(i+1, len(new_solution)):\n                    gap = abs(demand_sums[i] - demand_sums[j])\n                    if gap < min_gap and (demand_sums[i] + demand_sums[j]) <= capacity:\n                        min_gap = gap\n                        best_pair = (i, j)\n\n            if best_pair:\n                i, j = best_pair\n                route1, route2 = new_solution[i], new_solution[j]\n\n                # Check spatial proximity\n                spatial_dist = distance_matrix[route1[-2], route2[1]]\n                if spatial_dist < np.mean(distance_matrix[np.triu_indices(len(distance_matrix), 1)]):\n                    merged_route = np.concatenate([route1[:-1], route2[1:]])\n                    new_solution[i] = merged_route\n                    del new_solution[j]\n                    operator_weights = [w * 1.1 if op == 'capacity_merge' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n    # Final cleanup\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Capacitated Vehicle Routing Problem (Bi-CVRP), where a single depot and multiple customers are located in 2D space. Each customer has a positive demand, and all vehicles in the fleet have identical capacity limits. The objective is to construct a set of routes, each starting and ending at the depot, such that all customers are served, vehicle capacities are not exceeded on any route, and two conflicting objectives are minimized: (1) the total travel distance across all routes, and (2) the makespan, defined as the length of the longest individual route. Each solution in the archive is represented as a list of NumPy arrays, where each array denotes a single route (starting and ending with depot index 0), and is paired with a tuple of two objective values (total_distance, makespan). Your task is to implement a function named 'select_neighbor' that selects one promising solution from the archive and apply a novel or hybrid local search operator to generate a feasible neighbor solution from it. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself. Avoid standard methods like pure 2-opt; instead, invent or combine transformations, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. Ensure that the returned neighbor solution remains feasible under the vehicle capacity constraint. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with low total distance and makespan, then applies a hybrid local search combining route reversal and customer insertion to generate a neighbor solution while ensuring feasibility. It intelligently balances exploration and exploitation by iteratively modifying routes and customers, checking capacity constraints, and removing empty routes. The key design choices include prioritizing solutions with better objectives, combining 2-opt-like operations with customer relocations, and ensuring feasibility at each step.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0], x[1][1]))\n    selected_idx = min(5, len(archive_sorted) - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n\n    # Make a deep copy of the solution to modify\n    new_solution = [route.copy() for route in base_solution]\n\n    # Hybrid local search: combine route reversal and customer insertion\n    for _ in range(3):  # Perform 3 iterations of the hybrid operator\n        # Randomly select a route to modify\n        route_idx = random.randint(0, len(new_solution) - 1)\n        route = new_solution[route_idx]\n\n        if len(route) <= 3:  # Skip if route is too short\n            continue\n\n        # Apply route reversal (2-opt-like operation)\n        i, j = sorted(random.sample(range(1, len(route) - 1), 2))\n        reversed_segment = route[i:j+1][::-1]\n        new_route = np.concatenate([route[:i], reversed_segment, route[j+1:]])\n\n        # Check capacity feasibility\n        if np.sum(demand[new_route[1:-1]]) <= capacity:\n            new_solution[route_idx] = new_route\n            route = new_route\n\n        # Apply customer insertion (move a customer to another route)\n        if len(new_solution) > 1:\n            other_route_idx = random.choice([i for i in range(len(new_solution)) if i != route_idx])\n            other_route = new_solution[other_route_idx]\n\n            # Select a random customer to move\n            customer_pos = random.randint(1, len(route) - 2)\n            customer = route[customer_pos]\n\n            # Find insertion position in other route\n            best_pos = 1\n            min_increase = float('inf')\n            for pos in range(1, len(other_route)):\n                # Calculate distance increase\n                dist_increase = (distance_matrix[other_route[pos-1], customer] +\n                                distance_matrix[customer, other_route[pos]] -\n                                distance_matrix[other_route[pos-1], other_route[pos]])\n\n                if dist_increase < min_increase:\n                    min_increase = dist_increase\n                    best_pos = pos\n\n            # Check capacity feasibility\n            if np.sum(demand[other_route[1:-1]]) + demand[customer] <= capacity:\n                # Insert customer into other route\n                new_other_route = np.concatenate([other_route[:best_pos], [customer], other_route[best_pos:]])\n                new_solution[other_route_idx] = new_other_route\n\n                # Remove customer from original route\n                new_route = np.concatenate([route[:customer_pos], route[customer_pos+1:]])\n                new_solution[route_idx] = new_route\n\n    # Remove empty routes\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm implements a demand-aware hybrid local search strategy that first selects extreme solutions (high makespan or demand density) and then dynamically blends capacity-balanced route splitting (60% weight) with spatial-demand cluster merging (40% weight), adjusting operator weights based on archive diversity to balance distance and makespan minimization while maintaining feasibility through continuous demand and spatial validation. The selection prioritizes routes with high demand concentration near capacity for splitting, while merging focuses on spatially and demand-similar route pairs to reduce fragmentation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    demand_densities = []\n    makespans = []\n    for sol, obj in archive:\n        total_demand = sum(np.sum(demand[route[1:-1]]) for route in sol)\n        density = total_demand / (obj[0] + 1e-6)\n        demand_densities.append(density)\n        makespans.append(obj[1])\n\n    extreme_scores = np.array(demand_densities) * np.array(makespans)\n    selected_idx = np.argmax(extreme_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Step 2: Dynamic operator weights based on archive diversity\n    if len(archive) > 1:\n        distances = np.array([obj[0] for _, obj in archive])\n        crowding = (np.max(distances) - np.min(distances)) / (np.mean(distances) + 1e-6)\n        split_weight = 0.6 + 0.3 * crowding\n        merge_weight = 0.4 - 0.3 * crowding\n    else:\n        split_weight = 0.6\n        merge_weight = 0.4\n\n    # Step 3: Capacity-balanced route splitting\n    for _ in range(2):\n        if len(new_solution) < 1:\n            break\n\n        # Find route with highest demand concentration near capacity\n        demand_sums = [np.sum(demand[route[1:-1]]) for route in new_solution]\n        route_idx = np.argmax(demand_sums)\n        route = new_solution[route_idx]\n\n        if len(route) <= 3:\n            continue\n\n        # Calculate demand distribution\n        demands = demand[route[1:-1]]\n        cumulative_demand = np.cumsum(demands)\n        total_demand = cumulative_demand[-1]\n\n        # Find split point that balances capacity\n        target_demand = total_demand / 2\n        split_pos = np.argmin(np.abs(cumulative_demand - target_demand)) + 1  # +1 for route index\n\n        if split_pos > 1 and split_pos < len(route) - 1:\n            fragment = route[split_pos:]\n            remaining = route[:split_pos]\n\n            if (np.sum(demand[fragment[1:-1]]) <= capacity and\n                np.sum(demand[remaining[1:-1]]) <= capacity):\n                new_solution[route_idx] = remaining\n                new_solution.append(fragment)\n\n    # Step 4: Spatial-demand cluster merging\n    for _ in range(3):\n        if len(new_solution) < 2:\n            break\n\n        # Find closest route pairs based on spatial and demand similarity\n        route_pairs = []\n        for i in range(len(new_solution)):\n            for j in range(i+1, len(new_solution)):\n                route1, route2 = new_solution[i], new_solution[j]\n                # Spatial distance between last node of route1 and first node of route2\n                spatial_dist = distance_matrix[route1[-2], route2[1]]\n                # Demand similarity\n                demand_diff = abs(np.sum(demand[route1[1:-1]]) - np.sum(demand[route2[1:-1]]))\n                similarity_score = spatial_dist * demand_diff\n                route_pairs.append((similarity_score, (i, j)))\n\n        if not route_pairs:\n            continue\n\n        # Select pair with lowest similarity score\n        _, (i, j) = min(route_pairs)\n        route1, route2 = new_solution[i], new_solution[j]\n\n        # Check if merging is feasible\n        total_demand = np.sum(demand[route1[1:-1]]) + np.sum(demand[route2[1:-1]])\n        if total_demand <= capacity:\n            # Merge routes\n            merged_route = np.concatenate([route1[:-1], route2[1:]])\n            new_solution[i] = merged_route\n            del new_solution[j]\n\n    # Final cleanup\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### Keywords:\n- **Adaptive demand-distance clustering**\n- **Multi-objective hybrid reinsertion**\n- **Dynamic operator fusion**\n- **Extreme-solution targeting**\n\n### Advice:\n1. **Cluster customers by demand and spatial proximity**, prioritizing extreme routes (high distance/makespan) for focused improvement.\n2. **Dynamically fuse operators**: 70% demand-aware reinsertion + 30% capacity-gap reversal, weighted by archive diversity.\n3. **Break-and-repair routes** at depot-proximal capacity gaps, balancing spatial and demand efficiency.\n4. **Adjust operator weights** based on archive diversity (e.g., increase splitting in crowded regions).\n\n### Avoid:\n- Static demand thresholds\n- Rigid operator sequences\n- Single-stage reinsertion\n- Uniform extreme-solution selection\n\n### Explanation:\nThis hybrid approach balances demand and spatial efficiency, dynamically adapts operators to archive needs, and ensures feasible neighbors while exploring Pareto trade-offs. Extreme-solution targeting drives multi-objective improvement, while adaptive operator fusion maintains diversity.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 306,
        "algorithm": "The algorithm selects extreme solutions from the archive (based on high makespan and demand concentration) and applies a hybrid local search combining capacity-balanced fragmentation (75% weight) and spatial-demand-aware merging (25% weight), where operator weights dynamically adjust based on archive diversity to balance distance and makespan reduction while maintaining feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    makespans = [obj[1] for _, obj in archive]\n    demand_concentrations = [sum(np.sum(demand[route[1:-1]]) for route in sol) / (len(sol) + 1e-6) for sol, _ in archive]\n    extreme_scores = np.array(makespans) * np.array(demand_concentrations)\n    selected_idx = np.argmax(extreme_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Step 2: Dynamic operator weights based on archive diversity\n    if len(archive) > 1:\n        distances = np.array([obj[0] for _, obj in archive])\n        crowding = (np.max(distances) - np.min(distances)) / (np.mean(distances) + 1e-6)\n        fragment_weight = 0.75 - 0.25 * crowding\n        merge_weight = 0.25 + 0.25 * crowding\n    else:\n        fragment_weight = 0.75\n        merge_weight = 0.25\n\n    # Step 3: Capacity-balanced route fragmentation (75% weight)\n    for _ in range(int(3 * fragment_weight)):\n        if len(new_solution) < 1:\n            break\n\n        # Find route with highest demand concentration\n        demand_sums = [np.sum(demand[route[1:-1]]) for route in new_solution]\n        route_idx = np.argmax(demand_sums)\n        route = new_solution[route_idx]\n\n        if len(route) <= 3:\n            continue\n\n        # Find optimal fragmentation point\n        demands = demand[route[1:-1]]\n        cumulative_demand = np.cumsum(demands)\n        total_demand = cumulative_demand[-1]\n\n        # Find point that balances capacity\n        split_pos = np.argmin(np.abs(cumulative_demand - total_demand * 0.6)) + 1\n\n        if split_pos > 1 and split_pos < len(route) - 1:\n            fragment = route[split_pos:]\n            remaining = route[:split_pos]\n\n            if (np.sum(demand[fragment[1:-1]]) <= capacity and\n                np.sum(demand[remaining[1:-1]]) <= capacity):\n                new_solution[route_idx] = remaining\n                new_solution.append(fragment)\n\n    # Step 4: Spatial-demand-aware route merging (25% weight)\n    for _ in range(int(3 * merge_weight)):\n        if len(new_solution) < 2:\n            break\n\n        # Find best merge candidates\n        route_pairs = []\n        for i in range(len(new_solution)):\n            for j in range(i+1, len(new_solution)):\n                route1, route2 = new_solution[i], new_solution[j]\n\n                # Spatial proximity score\n                spatial_score = distance_matrix[route1[-2], route2[1]]\n\n                # Demand balance score\n                demand_diff = abs(np.sum(demand[route1[1:-1]]) - np.sum(demand[route2[1:-1]]))\n                demand_score = demand_diff / capacity\n\n                # Combined score\n                score = spatial_score * (1 + demand_score)\n                route_pairs.append((score, (i, j)))\n\n        if not route_pairs:\n            continue\n\n        # Select pair with best score\n        _, (i, j) = min(route_pairs)\n        route1, route2 = new_solution[i], new_solution[j]\n\n        # Check feasibility\n        total_demand = np.sum(demand[route1[1:-1]]) + np.sum(demand[route2[1:-1]])\n        if total_demand <= capacity:\n            # Merge routes\n            merged_route = np.concatenate([route1[:-1], route2[1:]])\n            new_solution[i] = merged_route\n            del new_solution[j]\n\n    # Final cleanup\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n",
        "score": [
            -0.7554644778423583,
            0.4840386211872101
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    makespans = [obj[1] for _, obj in archive]\n    demand_concentrations = [sum(np.sum(demand[route[1:-1]]) for route in sol) / (len(sol) + 1e-6) for sol, _ in archive]\n    extreme_scores = np.array(makespans) * np.array(demand_concentrations)\n    selected_idx = np.argmax(extreme_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Step 2: Dynamic operator weights based on archive diversity\n    if len(archive) > 1:\n        distances = np.array([obj[0] for _, obj in archive])\n        crowding = (np.max(distances) - np.min(distances)) / (np.mean(distances) + 1e-6)\n        fragment_weight = 0.75 - 0.25 * crowding\n        merge_weight = 0.25 + 0.25 * crowding\n    else:\n        fragment_weight = 0.75\n        merge_weight = 0.25\n\n    # Step 3: Capacity-balanced route fragmentation (75% weight)\n    for _ in range(int(3 * fragment_weight)):\n        if len(new_solution) < 1:\n            break\n\n        # Find route with highest demand concentration\n        demand_sums = [np.sum(demand[route[1:-1]]) for route in new_solution]\n        route_idx = np.argmax(demand_sums)\n        route = new_solution[route_idx]\n\n        if len(route) <= 3:\n            continue\n\n        # Find optimal fragmentation point\n        demands = demand[route[1:-1]]\n        cumulative_demand = np.cumsum(demands)\n        total_demand = cumulative_demand[-1]\n\n        # Find point that balances capacity\n        split_pos = np.argmin(np.abs(cumulative_demand - total_demand * 0.6)) + 1\n\n        if split_pos > 1 and split_pos < len(route) - 1:\n            fragment = route[split_pos:]\n            remaining = route[:split_pos]\n\n            if (np.sum(demand[fragment[1:-1]]) <= capacity and\n                np.sum(demand[remaining[1:-1]]) <= capacity):\n                new_solution[route_idx] = remaining\n                new_solution.append(fragment)\n\n    # Step 4: Spatial-demand-aware route merging (25% weight)\n    for _ in range(int(3 * merge_weight)):\n        if len(new_solution) < 2:\n            break\n\n        # Find best merge candidates\n        route_pairs = []\n        for i in range(len(new_solution)):\n            for j in range(i+1, len(new_solution)):\n                route1, route2 = new_solution[i], new_solution[j]\n\n                # Spatial proximity score\n                spatial_score = distance_matrix[route1[-2], route2[1]]\n\n                # Demand balance score\n                demand_diff = abs(np.sum(demand[route1[1:-1]]) - np.sum(demand[route2[1:-1]]))\n                demand_score = demand_diff / capacity\n\n                # Combined score\n                score = spatial_score * (1 + demand_score)\n                route_pairs.append((score, (i, j)))\n\n        if not route_pairs:\n            continue\n\n        # Select pair with best score\n        _, (i, j) = min(route_pairs)\n        route1, route2 = new_solution[i], new_solution[j]\n\n        # Check feasibility\n        total_demand = np.sum(demand[route1[1:-1]]) + np.sum(demand[route2[1:-1]])\n        if total_demand <= capacity:\n            # Merge routes\n            merged_route = np.concatenate([route1[:-1], route2[1:]])\n            new_solution[i] = merged_route\n            del new_solution[j]\n\n    # Final cleanup\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Capacitated Vehicle Routing Problem (Bi-CVRP), where a single depot and multiple customers are located in 2D space. Each customer has a positive demand, and all vehicles in the fleet have identical capacity limits. The objective is to construct a set of routes, each starting and ending at the depot, such that all customers are served, vehicle capacities are not exceeded on any route, and two conflicting objectives are minimized: (1) the total travel distance across all routes, and (2) the makespan, defined as the length of the longest individual route. Each solution in the archive is represented as a list of NumPy arrays, where each array denotes a single route (starting and ending with depot index 0), and is paired with a tuple of two objective values (total_distance, makespan). Your task is to implement a function named 'select_neighbor' that selects one promising solution from the archive and apply a novel or hybrid local search operator to generate a feasible neighbor solution from it. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself. Avoid standard methods like pure 2-opt; instead, invent or combine transformations, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. Ensure that the returned neighbor solution remains feasible under the vehicle capacity constraint. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm implements a demand-aware hybrid local search strategy that first selects extreme solutions (high makespan or demand density) and then dynamically blends capacity-balanced route splitting (60% weight) with spatial-demand cluster merging (40% weight), adjusting operator weights based on archive diversity to balance distance and makespan minimization while maintaining feasibility through continuous demand and spatial validation. The selection prioritizes routes with high demand concentration near capacity for splitting, while merging focuses on spatially and demand-similar route pairs to reduce fragmentation.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    demand_densities = []\n    makespans = []\n    for sol, obj in archive:\n        total_demand = sum(np.sum(demand[route[1:-1]]) for route in sol)\n        density = total_demand / (obj[0] + 1e-6)\n        demand_densities.append(density)\n        makespans.append(obj[1])\n\n    extreme_scores = np.array(demand_densities) * np.array(makespans)\n    selected_idx = np.argmax(extreme_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Step 2: Dynamic operator weights based on archive diversity\n    if len(archive) > 1:\n        distances = np.array([obj[0] for _, obj in archive])\n        crowding = (np.max(distances) - np.min(distances)) / (np.mean(distances) + 1e-6)\n        split_weight = 0.6 + 0.3 * crowding\n        merge_weight = 0.4 - 0.3 * crowding\n    else:\n        split_weight = 0.6\n        merge_weight = 0.4\n\n    # Step 3: Capacity-balanced route splitting\n    for _ in range(2):\n        if len(new_solution) < 1:\n            break\n\n        # Find route with highest demand concentration near capacity\n        demand_sums = [np.sum(demand[route[1:-1]]) for route in new_solution]\n        route_idx = np.argmax(demand_sums)\n        route = new_solution[route_idx]\n\n        if len(route) <= 3:\n            continue\n\n        # Calculate demand distribution\n        demands = demand[route[1:-1]]\n        cumulative_demand = np.cumsum(demands)\n        total_demand = cumulative_demand[-1]\n\n        # Find split point that balances capacity\n        target_demand = total_demand / 2\n        split_pos = np.argmin(np.abs(cumulative_demand - target_demand)) + 1  # +1 for route index\n\n        if split_pos > 1 and split_pos < len(route) - 1:\n            fragment = route[split_pos:]\n            remaining = route[:split_pos]\n\n            if (np.sum(demand[fragment[1:-1]]) <= capacity and\n                np.sum(demand[remaining[1:-1]]) <= capacity):\n                new_solution[route_idx] = remaining\n                new_solution.append(fragment)\n\n    # Step 4: Spatial-demand cluster merging\n    for _ in range(3):\n        if len(new_solution) < 2:\n            break\n\n        # Find closest route pairs based on spatial and demand similarity\n        route_pairs = []\n        for i in range(len(new_solution)):\n            for j in range(i+1, len(new_solution)):\n                route1, route2 = new_solution[i], new_solution[j]\n                # Spatial distance between last node of route1 and first node of route2\n                spatial_dist = distance_matrix[route1[-2], route2[1]]\n                # Demand similarity\n                demand_diff = abs(np.sum(demand[route1[1:-1]]) - np.sum(demand[route2[1:-1]]))\n                similarity_score = spatial_dist * demand_diff\n                route_pairs.append((similarity_score, (i, j)))\n\n        if not route_pairs:\n            continue\n\n        # Select pair with lowest similarity score\n        _, (i, j) = min(route_pairs)\n        route1, route2 = new_solution[i], new_solution[j]\n\n        # Check if merging is feasible\n        total_demand = np.sum(demand[route1[1:-1]]) + np.sum(demand[route2[1:-1]])\n        if total_demand <= capacity:\n            # Merge routes\n            merged_route = np.concatenate([route1[:-1], route2[1:]])\n            new_solution[i] = merged_route\n            del new_solution[j]\n\n    # Final cleanup\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 307,
        "algorithm": "This algorithm implements a hybrid local search strategy that first selects solutions based on a weighted combination of demand density (70%) and spatial dispersion (30%), then dynamically applies demand-balanced route splitting and spatial-aware route merging with adaptive weights based on Pareto front proximity, while ensuring feasibility through continuous validation of capacity and spatial constraints. The selection prioritizes solutions with high demand density and spatial dispersion, while the operators adaptively balance between splitting high-demand routes and merging spatially compatible routes, with more aggressive operations applied to Pareto-front solutions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    selection_scores = []\n    for sol, obj in archive:\n        total_demand = sum(np.sum(demand[route[1:-1]]) for route in sol)\n        demand_density = total_demand / (obj[0] + 1e-6)\n\n        # Calculate spatial dispersion (average distance between route centroids)\n        centroids = []\n        for route in sol:\n            if len(route) > 2:\n                route_coords = coords[route[1:-1]]\n                centroid = np.mean(route_coords, axis=0)\n                centroids.append(centroid)\n        if len(centroids) > 1:\n            centroid_distances = []\n            for i in range(len(centroids)):\n                for j in range(i+1, len(centroids)):\n                    centroid_distances.append(np.linalg.norm(centroids[i] - centroids[j]))\n            spatial_dispersion = np.mean(centroid_distances) if centroid_distances else 0\n        else:\n            spatial_dispersion = 0\n\n        # Weighted selection score\n        score = 0.7 * demand_density + 0.3 * spatial_dispersion\n        selection_scores.append(score)\n\n    selected_idx = np.argmax(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Step 2: Dynamic operator weights based on Pareto front proximity\n    if len(archive) > 1:\n        # Calculate solution's distance to Pareto front\n        distances = [obj[0] for _, obj in archive]\n        makespans = [obj[1] for _, obj in archive]\n        pareto_front = []\n\n        # Identify Pareto front using non-dominated sorting\n        for i in range(len(archive)):\n            dominated = False\n            for j in range(len(archive)):\n                if i != j and distances[j] <= distances[i] and makespans[j] <= makespans[i] and (distances[j] < distances[i] or makespans[j] < makespans[i]):\n                    dominated = True\n                    break\n            if not dominated:\n                pareto_front.append(i)\n\n        if selected_idx in pareto_front:\n            # Solutions on Pareto front get more aggressive operators\n            split_weight = 0.7\n            merge_weight = 0.3\n        else:\n            # Solutions off Pareto front get more conservative operators\n            split_weight = 0.4\n            merge_weight = 0.6\n    else:\n        split_weight = 0.5\n        merge_weight = 0.5\n\n    # Step 3: Demand-balanced route splitting\n    for _ in range(2):\n        if len(new_solution) < 1:\n            break\n\n        # Select route with highest demand imbalance\n        demand_sums = [np.sum(demand[route[1:-1]]) for route in new_solution]\n        route_idx = np.argmax(demand_sums)\n        route = new_solution[route_idx]\n\n        if len(route) <= 3:\n            continue\n\n        # Calculate demand distribution and find optimal split point\n        demands = demand[route[1:-1]]\n        cumulative_demand = np.cumsum(demands)\n        total_demand = cumulative_demand[-1]\n\n        # Find split point that balances capacity while minimizing spatial disruption\n        best_split = None\n        min_disruption = float('inf')\n\n        for pos in range(1, len(route)-1):\n            left_demand = cumulative_demand[pos-1]\n            right_demand = total_demand - left_demand\n\n            # Check capacity constraints\n            if left_demand <= capacity and right_demand <= capacity:\n                # Calculate spatial disruption (distance between split point and route centroid)\n                split_point = route[pos]\n                route_coords = coords[route[1:-1]]\n                centroid = np.mean(route_coords, axis=0)\n                disruption = np.linalg.norm(coords[split_point] - centroid)\n\n                if disruption < min_disruption:\n                    min_disruption = disruption\n                    best_split = pos\n\n        if best_split is not None:\n            fragment = route[best_split:]\n            remaining = route[:best_split+1]\n\n            if (np.sum(demand[fragment[1:-1]]) <= capacity and\n                np.sum(demand[remaining[1:-1]]) <= capacity):\n                new_solution[route_idx] = remaining\n                new_solution.append(fragment)\n\n    # Step 4: Spatial-aware route merging\n    for _ in range(3):\n        if len(new_solution) < 2:\n            break\n\n        # Find route pairs with high spatial and demand compatibility\n        route_pairs = []\n        for i in range(len(new_solution)):\n            for j in range(i+1, len(new_solution)):\n                route1, route2 = new_solution[i], new_solution[j]\n\n                # Spatial proximity (distance between last node of route1 and first node of route2)\n                spatial_dist = distance_matrix[route1[-2], route2[1]]\n\n                # Demand compatibility (normalized difference)\n                demand1 = np.sum(demand[route1[1:-1]])\n                demand2 = np.sum(demand[route2[1:-1]])\n                demand_diff = abs(demand1 - demand2) / max(demand1, demand2, 1)\n\n                # Compatibility score (lower is better)\n                compatibility = 0.6 * spatial_dist + 0.4 * demand_diff\n                route_pairs.append((compatibility, (i, j)))\n\n        if not route_pairs:\n            continue\n\n        # Select pair with highest compatibility (lowest score)\n        _, (i, j) = min(route_pairs)\n        route1, route2 = new_solution[i], new_solution[j]\n\n        # Check if merging is feasible\n        total_demand = np.sum(demand[route1[1:-1]]) + np.sum(demand[route2[1:-1]])\n        if total_demand <= capacity:\n            # Merge routes\n            merged_route = np.concatenate([route1[:-1], route2[1:]])\n            new_solution[i] = merged_route\n            del new_solution[j]\n\n    # Final cleanup\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n",
        "score": [
            -0.7437359227986264,
            4.858162611722946
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    selection_scores = []\n    for sol, obj in archive:\n        total_demand = sum(np.sum(demand[route[1:-1]]) for route in sol)\n        demand_density = total_demand / (obj[0] + 1e-6)\n\n        # Calculate spatial dispersion (average distance between route centroids)\n        centroids = []\n        for route in sol:\n            if len(route) > 2:\n                route_coords = coords[route[1:-1]]\n                centroid = np.mean(route_coords, axis=0)\n                centroids.append(centroid)\n        if len(centroids) > 1:\n            centroid_distances = []\n            for i in range(len(centroids)):\n                for j in range(i+1, len(centroids)):\n                    centroid_distances.append(np.linalg.norm(centroids[i] - centroids[j]))\n            spatial_dispersion = np.mean(centroid_distances) if centroid_distances else 0\n        else:\n            spatial_dispersion = 0\n\n        # Weighted selection score\n        score = 0.7 * demand_density + 0.3 * spatial_dispersion\n        selection_scores.append(score)\n\n    selected_idx = np.argmax(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Step 2: Dynamic operator weights based on Pareto front proximity\n    if len(archive) > 1:\n        # Calculate solution's distance to Pareto front\n        distances = [obj[0] for _, obj in archive]\n        makespans = [obj[1] for _, obj in archive]\n        pareto_front = []\n\n        # Identify Pareto front using non-dominated sorting\n        for i in range(len(archive)):\n            dominated = False\n            for j in range(len(archive)):\n                if i != j and distances[j] <= distances[i] and makespans[j] <= makespans[i] and (distances[j] < distances[i] or makespans[j] < makespans[i]):\n                    dominated = True\n                    break\n            if not dominated:\n                pareto_front.append(i)\n\n        if selected_idx in pareto_front:\n            # Solutions on Pareto front get more aggressive operators\n            split_weight = 0.7\n            merge_weight = 0.3\n        else:\n            # Solutions off Pareto front get more conservative operators\n            split_weight = 0.4\n            merge_weight = 0.6\n    else:\n        split_weight = 0.5\n        merge_weight = 0.5\n\n    # Step 3: Demand-balanced route splitting\n    for _ in range(2):\n        if len(new_solution) < 1:\n            break\n\n        # Select route with highest demand imbalance\n        demand_sums = [np.sum(demand[route[1:-1]]) for route in new_solution]\n        route_idx = np.argmax(demand_sums)\n        route = new_solution[route_idx]\n\n        if len(route) <= 3:\n            continue\n\n        # Calculate demand distribution and find optimal split point\n        demands = demand[route[1:-1]]\n        cumulative_demand = np.cumsum(demands)\n        total_demand = cumulative_demand[-1]\n\n        # Find split point that balances capacity while minimizing spatial disruption\n        best_split = None\n        min_disruption = float('inf')\n\n        for pos in range(1, len(route)-1):\n            left_demand = cumulative_demand[pos-1]\n            right_demand = total_demand - left_demand\n\n            # Check capacity constraints\n            if left_demand <= capacity and right_demand <= capacity:\n                # Calculate spatial disruption (distance between split point and route centroid)\n                split_point = route[pos]\n                route_coords = coords[route[1:-1]]\n                centroid = np.mean(route_coords, axis=0)\n                disruption = np.linalg.norm(coords[split_point] - centroid)\n\n                if disruption < min_disruption:\n                    min_disruption = disruption\n                    best_split = pos\n\n        if best_split is not None:\n            fragment = route[best_split:]\n            remaining = route[:best_split+1]\n\n            if (np.sum(demand[fragment[1:-1]]) <= capacity and\n                np.sum(demand[remaining[1:-1]]) <= capacity):\n                new_solution[route_idx] = remaining\n                new_solution.append(fragment)\n\n    # Step 4: Spatial-aware route merging\n    for _ in range(3):\n        if len(new_solution) < 2:\n            break\n\n        # Find route pairs with high spatial and demand compatibility\n        route_pairs = []\n        for i in range(len(new_solution)):\n            for j in range(i+1, len(new_solution)):\n                route1, route2 = new_solution[i], new_solution[j]\n\n                # Spatial proximity (distance between last node of route1 and first node of route2)\n                spatial_dist = distance_matrix[route1[-2], route2[1]]\n\n                # Demand compatibility (normalized difference)\n                demand1 = np.sum(demand[route1[1:-1]])\n                demand2 = np.sum(demand[route2[1:-1]])\n                demand_diff = abs(demand1 - demand2) / max(demand1, demand2, 1)\n\n                # Compatibility score (lower is better)\n                compatibility = 0.6 * spatial_dist + 0.4 * demand_diff\n                route_pairs.append((compatibility, (i, j)))\n\n        if not route_pairs:\n            continue\n\n        # Select pair with highest compatibility (lowest score)\n        _, (i, j) = min(route_pairs)\n        route1, route2 = new_solution[i], new_solution[j]\n\n        # Check if merging is feasible\n        total_demand = np.sum(demand[route1[1:-1]]) + np.sum(demand[route2[1:-1]])\n        if total_demand <= capacity:\n            # Merge routes\n            merged_route = np.concatenate([route1[:-1], route2[1:]])\n            new_solution[i] = merged_route\n            del new_solution[j]\n\n    # Final cleanup\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Capacitated Vehicle Routing Problem (Bi-CVRP), where a single depot and multiple customers are located in 2D space. Each customer has a positive demand, and all vehicles in the fleet have identical capacity limits. The objective is to construct a set of routes, each starting and ending at the depot, such that all customers are served, vehicle capacities are not exceeded on any route, and two conflicting objectives are minimized: (1) the total travel distance across all routes, and (2) the makespan, defined as the length of the longest individual route. Each solution in the archive is represented as a list of NumPy arrays, where each array denotes a single route (starting and ending with depot index 0), and is paired with a tuple of two objective values (total_distance, makespan). Your task is to implement a function named 'select_neighbor' that selects one promising solution from the archive and apply a novel or hybrid local search operator to generate a feasible neighbor solution from it. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself. Avoid standard methods like pure 2-opt; instead, invent or combine transformations, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. Ensure that the returned neighbor solution remains feasible under the vehicle capacity constraint. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm implements a demand-aware hybrid local search strategy that first selects extreme solutions (high makespan or demand density) and then dynamically blends capacity-balanced route splitting (60% weight) with spatial-demand cluster merging (40% weight), adjusting operator weights based on archive diversity to balance distance and makespan minimization while maintaining feasibility through continuous demand and spatial validation. The selection prioritizes routes with high demand concentration near capacity for splitting, while merging focuses on spatially and demand-similar route pairs to reduce fragmentation.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    demand_densities = []\n    makespans = []\n    for sol, obj in archive:\n        total_demand = sum(np.sum(demand[route[1:-1]]) for route in sol)\n        density = total_demand / (obj[0] + 1e-6)\n        demand_densities.append(density)\n        makespans.append(obj[1])\n\n    extreme_scores = np.array(demand_densities) * np.array(makespans)\n    selected_idx = np.argmax(extreme_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Step 2: Dynamic operator weights based on archive diversity\n    if len(archive) > 1:\n        distances = np.array([obj[0] for _, obj in archive])\n        crowding = (np.max(distances) - np.min(distances)) / (np.mean(distances) + 1e-6)\n        split_weight = 0.6 + 0.3 * crowding\n        merge_weight = 0.4 - 0.3 * crowding\n    else:\n        split_weight = 0.6\n        merge_weight = 0.4\n\n    # Step 3: Capacity-balanced route splitting\n    for _ in range(2):\n        if len(new_solution) < 1:\n            break\n\n        # Find route with highest demand concentration near capacity\n        demand_sums = [np.sum(demand[route[1:-1]]) for route in new_solution]\n        route_idx = np.argmax(demand_sums)\n        route = new_solution[route_idx]\n\n        if len(route) <= 3:\n            continue\n\n        # Calculate demand distribution\n        demands = demand[route[1:-1]]\n        cumulative_demand = np.cumsum(demands)\n        total_demand = cumulative_demand[-1]\n\n        # Find split point that balances capacity\n        target_demand = total_demand / 2\n        split_pos = np.argmin(np.abs(cumulative_demand - target_demand)) + 1  # +1 for route index\n\n        if split_pos > 1 and split_pos < len(route) - 1:\n            fragment = route[split_pos:]\n            remaining = route[:split_pos]\n\n            if (np.sum(demand[fragment[1:-1]]) <= capacity and\n                np.sum(demand[remaining[1:-1]]) <= capacity):\n                new_solution[route_idx] = remaining\n                new_solution.append(fragment)\n\n    # Step 4: Spatial-demand cluster merging\n    for _ in range(3):\n        if len(new_solution) < 2:\n            break\n\n        # Find closest route pairs based on spatial and demand similarity\n        route_pairs = []\n        for i in range(len(new_solution)):\n            for j in range(i+1, len(new_solution)):\n                route1, route2 = new_solution[i], new_solution[j]\n                # Spatial distance between last node of route1 and first node of route2\n                spatial_dist = distance_matrix[route1[-2], route2[1]]\n                # Demand similarity\n                demand_diff = abs(np.sum(demand[route1[1:-1]]) - np.sum(demand[route2[1:-1]]))\n                similarity_score = spatial_dist * demand_diff\n                route_pairs.append((similarity_score, (i, j)))\n\n        if not route_pairs:\n            continue\n\n        # Select pair with lowest similarity score\n        _, (i, j) = min(route_pairs)\n        route1, route2 = new_solution[i], new_solution[j]\n\n        # Check if merging is feasible\n        total_demand = np.sum(demand[route1[1:-1]]) + np.sum(demand[route2[1:-1]])\n        if total_demand <= capacity:\n            # Merge routes\n            merged_route = np.concatenate([route1[:-1], route2[1:]])\n            new_solution[i] = merged_route\n            del new_solution[j]\n\n    # Final cleanup\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 308,
        "algorithm": "The algorithm selects high-demand-density solutions from the archive and applies a hybrid local search combining route merging (prioritized spatially and demand-balanced) and demand-aware route splitting, with operator weights dynamically adjusted based on archive diversity to balance distance reduction and feasibility. It ensures capacity constraints through continuous validation of merged/split routes.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    demand_densities = []\n    for sol, _ in archive:\n        total_demand = sum(np.sum(demand[route[1:-1]]) for route in sol)\n        density = total_demand / (sum(len(route) - 1 for route in sol) + 1e-6)\n        demand_densities.append(density)\n\n    selected_idx = np.argmax(demand_densities)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    if len(archive) > 1:\n        distances = np.array([obj[0] for _, obj in archive])\n        crowding = (np.max(distances) - np.min(distances)) / (np.mean(distances) + 1e-6)\n        merge_weight = 0.7 + 0.2 * crowding\n        split_weight = 0.3 - 0.2 * crowding\n    else:\n        merge_weight = 0.7\n        split_weight = 0.3\n\n    if np.random.random() < merge_weight:\n        for _ in range(3):\n            if len(new_solution) < 2:\n                break\n\n            route_pairs = []\n            for i in range(len(new_solution)):\n                for j in range(i+1, len(new_solution)):\n                    route1, route2 = new_solution[i], new_solution[j]\n                    spatial_dist = distance_matrix[route1[-2], route2[1]]\n                    demand_similarity = 1 - abs(np.sum(demand[route1[1:-1]]) - np.sum(demand[route2[1:-1]])) / capacity\n                    score = spatial_dist * (1 - demand_similarity)\n                    route_pairs.append((score, (i, j)))\n\n            if not route_pairs:\n                continue\n\n            _, (i, j) = min(route_pairs)\n            route1, route2 = new_solution[i], new_solution[j]\n\n            total_demand = np.sum(demand[route1[1:-1]]) + np.sum(demand[route2[1:-1]])\n            if total_demand <= capacity:\n                merged_route = np.concatenate([route1[:-1], route2[1:]])\n                new_solution[i] = merged_route\n                del new_solution[j]\n\n    else:\n        for _ in range(2):\n            if len(new_solution) < 1:\n                break\n\n            demand_sums = [np.sum(demand[route[1:-1]]) for route in new_solution]\n            route_idx = np.argmax(demand_sums)\n            route = new_solution[route_idx]\n\n            if len(route) <= 3:\n                continue\n\n            demands = demand[route[1:-1]]\n            cumulative_demand = np.cumsum(demands)\n            total_demand = cumulative_demand[-1]\n\n            split_pos = np.argmin(np.abs(cumulative_demand - total_demand/2)) + 1\n\n            if split_pos > 1 and split_pos < len(route) - 1:\n                fragment = route[split_pos:]\n                remaining = route[:split_pos]\n\n                if (np.sum(demand[fragment[1:-1]]) <= capacity and\n                    np.sum(demand[remaining[1:-1]]) <= capacity):\n                    new_solution[route_idx] = remaining\n                    new_solution.append(fragment)\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n",
        "score": [
            -0.7046777599106558,
            1.2864362299442291
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    demand_densities = []\n    for sol, _ in archive:\n        total_demand = sum(np.sum(demand[route[1:-1]]) for route in sol)\n        density = total_demand / (sum(len(route) - 1 for route in sol) + 1e-6)\n        demand_densities.append(density)\n\n    selected_idx = np.argmax(demand_densities)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    if len(archive) > 1:\n        distances = np.array([obj[0] for _, obj in archive])\n        crowding = (np.max(distances) - np.min(distances)) / (np.mean(distances) + 1e-6)\n        merge_weight = 0.7 + 0.2 * crowding\n        split_weight = 0.3 - 0.2 * crowding\n    else:\n        merge_weight = 0.7\n        split_weight = 0.3\n\n    if np.random.random() < merge_weight:\n        for _ in range(3):\n            if len(new_solution) < 2:\n                break\n\n            route_pairs = []\n            for i in range(len(new_solution)):\n                for j in range(i+1, len(new_solution)):\n                    route1, route2 = new_solution[i], new_solution[j]\n                    spatial_dist = distance_matrix[route1[-2], route2[1]]\n                    demand_similarity = 1 - abs(np.sum(demand[route1[1:-1]]) - np.sum(demand[route2[1:-1]])) / capacity\n                    score = spatial_dist * (1 - demand_similarity)\n                    route_pairs.append((score, (i, j)))\n\n            if not route_pairs:\n                continue\n\n            _, (i, j) = min(route_pairs)\n            route1, route2 = new_solution[i], new_solution[j]\n\n            total_demand = np.sum(demand[route1[1:-1]]) + np.sum(demand[route2[1:-1]])\n            if total_demand <= capacity:\n                merged_route = np.concatenate([route1[:-1], route2[1:]])\n                new_solution[i] = merged_route\n                del new_solution[j]\n\n    else:\n        for _ in range(2):\n            if len(new_solution) < 1:\n                break\n\n            demand_sums = [np.sum(demand[route[1:-1]]) for route in new_solution]\n            route_idx = np.argmax(demand_sums)\n            route = new_solution[route_idx]\n\n            if len(route) <= 3:\n                continue\n\n            demands = demand[route[1:-1]]\n            cumulative_demand = np.cumsum(demands)\n            total_demand = cumulative_demand[-1]\n\n            split_pos = np.argmin(np.abs(cumulative_demand - total_demand/2)) + 1\n\n            if split_pos > 1 and split_pos < len(route) - 1:\n                fragment = route[split_pos:]\n                remaining = route[:split_pos]\n\n                if (np.sum(demand[fragment[1:-1]]) <= capacity and\n                    np.sum(demand[remaining[1:-1]]) <= capacity):\n                    new_solution[route_idx] = remaining\n                    new_solution.append(fragment)\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Capacitated Vehicle Routing Problem (Bi-CVRP), where a single depot and multiple customers are located in 2D space. Each customer has a positive demand, and all vehicles in the fleet have identical capacity limits. The objective is to construct a set of routes, each starting and ending at the depot, such that all customers are served, vehicle capacities are not exceeded on any route, and two conflicting objectives are minimized: (1) the total travel distance across all routes, and (2) the makespan, defined as the length of the longest individual route. Each solution in the archive is represented as a list of NumPy arrays, where each array denotes a single route (starting and ending with depot index 0), and is paired with a tuple of two objective values (total_distance, makespan). Your task is to implement a function named 'select_neighbor' that selects one promising solution from the archive and apply a novel or hybrid local search operator to generate a feasible neighbor solution from it. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself. Avoid standard methods like pure 2-opt; instead, invent or combine transformations, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. Ensure that the returned neighbor solution remains feasible under the vehicle capacity constraint. The function should return the new neighbor solution.\n            I have 6 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm implements a demand-aware hybrid local search strategy that first selects extreme solutions (high makespan or demand density) and then dynamically blends capacity-balanced route splitting (60% weight) with spatial-demand cluster merging (40% weight), adjusting operator weights based on archive diversity to balance distance and makespan minimization while maintaining feasibility through continuous demand and spatial validation. The selection prioritizes routes with high demand concentration near capacity for splitting, while merging focuses on spatially and demand-similar route pairs to reduce fragmentation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    demand_densities = []\n    makespans = []\n    for sol, obj in archive:\n        total_demand = sum(np.sum(demand[route[1:-1]]) for route in sol)\n        density = total_demand / (obj[0] + 1e-6)\n        demand_densities.append(density)\n        makespans.append(obj[1])\n\n    extreme_scores = np.array(demand_densities) * np.array(makespans)\n    selected_idx = np.argmax(extreme_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Step 2: Dynamic operator weights based on archive diversity\n    if len(archive) > 1:\n        distances = np.array([obj[0] for _, obj in archive])\n        crowding = (np.max(distances) - np.min(distances)) / (np.mean(distances) + 1e-6)\n        split_weight = 0.6 + 0.3 * crowding\n        merge_weight = 0.4 - 0.3 * crowding\n    else:\n        split_weight = 0.6\n        merge_weight = 0.4\n\n    # Step 3: Capacity-balanced route splitting\n    for _ in range(2):\n        if len(new_solution) < 1:\n            break\n\n        # Find route with highest demand concentration near capacity\n        demand_sums = [np.sum(demand[route[1:-1]]) for route in new_solution]\n        route_idx = np.argmax(demand_sums)\n        route = new_solution[route_idx]\n\n        if len(route) <= 3:\n            continue\n\n        # Calculate demand distribution\n        demands = demand[route[1:-1]]\n        cumulative_demand = np.cumsum(demands)\n        total_demand = cumulative_demand[-1]\n\n        # Find split point that balances capacity\n        target_demand = total_demand / 2\n        split_pos = np.argmin(np.abs(cumulative_demand - target_demand)) + 1  # +1 for route index\n\n        if split_pos > 1 and split_pos < len(route) - 1:\n            fragment = route[split_pos:]\n            remaining = route[:split_pos]\n\n            if (np.sum(demand[fragment[1:-1]]) <= capacity and\n                np.sum(demand[remaining[1:-1]]) <= capacity):\n                new_solution[route_idx] = remaining\n                new_solution.append(fragment)\n\n    # Step 4: Spatial-demand cluster merging\n    for _ in range(3):\n        if len(new_solution) < 2:\n            break\n\n        # Find closest route pairs based on spatial and demand similarity\n        route_pairs = []\n        for i in range(len(new_solution)):\n            for j in range(i+1, len(new_solution)):\n                route1, route2 = new_solution[i], new_solution[j]\n                # Spatial distance between last node of route1 and first node of route2\n                spatial_dist = distance_matrix[route1[-2], route2[1]]\n                # Demand similarity\n                demand_diff = abs(np.sum(demand[route1[1:-1]]) - np.sum(demand[route2[1:-1]]))\n                similarity_score = spatial_dist * demand_diff\n                route_pairs.append((similarity_score, (i, j)))\n\n        if not route_pairs:\n            continue\n\n        # Select pair with lowest similarity score\n        _, (i, j) = min(route_pairs)\n        route1, route2 = new_solution[i], new_solution[j]\n\n        # Check if merging is feasible\n        total_demand = np.sum(demand[route1[1:-1]]) + np.sum(demand[route2[1:-1]])\n        if total_demand <= capacity:\n            # Merge routes\n            merged_route = np.concatenate([route1[:-1], route2[1:]])\n            new_solution[i] = merged_route\n            del new_solution[j]\n\n    # Final cleanup\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm combines extreme-solution targeting with adaptive demand-spatial clustering by prioritizing solutions with high demand density and makespan, then dynamically applies capacity-aware route splitting (70% weight) and spatial-demand hybrid swaps (30% weight) to balance distance and makespan while maintaining feasibility through continuous demand validation and spatial checks. The operator weights adjust based on archive diversity, with splitting favored in crowded archives and swaps in sparse ones.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    demand_densities = []\n    for sol, obj in archive:\n        total_demand = sum(np.sum(demand[route[1:-1]]) for route in sol)\n        density = total_demand / (obj[0] + 1e-6)\n        demand_densities.append(density)\n\n    # Combine with makespan to select extreme solution\n    makespans = np.array([obj[1] for _, obj in archive])\n    extreme_scores = np.array(demand_densities) * makespans\n    selected_idx = np.argmax(extreme_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Dynamic operator weights based on archive diversity\n    if len(archive) > 1:\n        distances = np.array([obj[0] for _, obj in archive])\n        crowding = (np.max(distances) - np.min(distances)) / (np.mean(distances) + 1e-6)\n        split_weight = 0.7 + 0.2 * crowding\n        swap_weight = 0.3 - 0.2 * crowding\n    else:\n        split_weight = 0.7\n        swap_weight = 0.3\n\n    # Phase 1: Capacity-aware demand hotspot splitting\n    for _ in range(2):\n        if len(new_solution) < 1:\n            break\n\n        # Find route with highest demand concentration near capacity\n        demand_sums = [np.sum(demand[route[1:-1]]) for route in new_solution]\n        route_idx = np.argmax(demand_sums)\n        route = new_solution[route_idx]\n\n        if len(route) <= 3:\n            continue\n\n        # Identify demand hotspot (top 30% demand nodes)\n        demands = demand[route[1:-1]]\n        sorted_idx = np.argsort(demands)[::-1]\n        hotspot_size = max(2, int(0.3 * len(demands)))\n        hotspot_nodes = route[sorted_idx[:hotspot_size] + 1]  # +1 for route index\n\n        # Split at first hotspot node\n        split_pos = np.where(route == hotspot_nodes[0])[0][0]\n        if split_pos > 1 and split_pos < len(route) - 1:\n            fragment = route[split_pos:]\n            remaining = route[:split_pos]\n\n            if (np.sum(demand[fragment[1:-1]]) <= capacity and\n                np.sum(demand[remaining[1:-1]]) <= capacity):\n                new_solution[route_idx] = remaining\n                new_solution.append(fragment)\n\n    # Phase 2: Spatial-demand hybrid swaps\n    for _ in range(3):\n        if len(new_solution) < 2:\n            break\n\n        # Select routes with high spatial-demand imbalance\n        route_pairs = []\n        for i in range(len(new_solution)):\n            for j in range(i+1, len(new_solution)):\n                route1, route2 = new_solution[i], new_solution[j]\n                last1, first2 = route1[-2], route2[1]\n                spatial_dist = distance_matrix[last1, first2]\n                demand_diff = abs(np.sum(demand[route1[1:-1]]) - np.sum(demand[route2[1:-1]]))\n                imbalance = spatial_dist * demand_diff\n                route_pairs.append((imbalance, (i, j)))\n\n        if not route_pairs:\n            continue\n\n        # Select pair with highest imbalance\n        _, (i, j) = max(route_pairs)\n        route1, route2 = new_solution[i], new_solution[j]\n\n        # Try demand-weighted node swaps\n        if len(route1) > 3 and len(route2) > 3:\n            # Find nodes with similar demand\n            route1_demands = demand[route1[1:-1]]\n            route2_demands = demand[route2[1:-1]]\n            median1, median2 = np.median(route1_demands), np.median(route2_demands)\n\n            if abs(median1 - median2) < 0.3 * (median1 + median2):\n                # Select random nodes\n                node1_pos = random.randint(1, len(route1)-2)\n                node2_pos = random.randint(1, len(route2)-2)\n                node1, node2 = route1[node1_pos], route2[node2_pos]\n\n                # Check capacity and spatial improvement\n                new_route1 = route1.copy()\n                new_route1[node1_pos] = node2\n                new_route2 = route2.copy()\n                new_route2[node2_pos] = node1\n\n                if (np.sum(demand[new_route1[1:-1]]) <= capacity and\n                    np.sum(demand[new_route2[1:-1]]) <= capacity):\n\n                    old_dist = (distance_matrix[route1[node1_pos-1], node1] +\n                                distance_matrix[node1, route1[node1_pos+1]] +\n                                distance_matrix[route2[node2_pos-1], node2] +\n                                distance_matrix[node2, route2[node2_pos+1]])\n\n                    new_dist = (distance_matrix[route1[node1_pos-1], node2] +\n                                distance_matrix[node2, route1[node1_pos+1]] +\n                                distance_matrix[route2[node2_pos-1], node1] +\n                                distance_matrix[node1, route2[node2_pos+1]])\n\n                    if new_dist < old_dist:\n                        new_solution[i] = new_route1\n                        new_solution[j] = new_route2\n\n    # Final cleanup\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm combines demand-aware route segmentation with spatial-demand hybrid optimization, prioritizing high-demand-density solutions and alternating between demand-based clustering and spatial-demand swaps to balance efficiency and route compactness while ensuring feasibility. It emphasizes demand patterns in clustering and spatial proximity in merging/swapping operations, with dynamic thresholds for demand differences and capacity checks. The multi-phase approach (segmentation \u2192 merging \u2192 node swaps) progressively refines solutions while maintaining feasibility.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    demand_densities = []\n    for sol, obj in archive:\n        total_demand = sum(np.sum(demand[route[1:-1]]) for route in sol)\n        total_distance = obj[0]\n        density = total_demand / total_distance if total_distance > 0 else float('inf')\n        demand_densities.append(density)\n\n    selected_idx = np.argmax(demand_densities)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Phase 1: Demand-aware route segmentation\n    for route_idx in range(len(new_solution)):\n        route = new_solution[route_idx]\n        if len(route) <= 4:\n            continue\n\n        # Find demand clusters in the route\n        demands = demand[route[1:-1]]\n        sorted_indices = np.argsort(demands)\n        clusters = []\n        current_cluster = [route[sorted_indices[0] + 1]]  # +1 to convert to route index\n\n        for i in range(1, len(sorted_indices)):\n            prev_idx = sorted_indices[i-1] + 1\n            curr_idx = sorted_indices[i] + 1\n\n            # Check if demand difference exceeds threshold\n            if demands[sorted_indices[i]] - demands[sorted_indices[i-1]] > 0.2 * np.mean(demands):\n                clusters.append(current_cluster)\n                current_cluster = [curr_idx]\n            else:\n                current_cluster.append(curr_idx)\n\n        if current_cluster:\n            clusters.append(current_cluster)\n\n        # Reconstruct route with demand-based segments\n        if len(clusters) > 1:\n            new_route = [0]\n            for cluster in clusters:\n                # Find best insertion point for the cluster\n                best_pos = 1\n                best_cost = float('inf')\n\n                for pos in range(1, len(new_route)):\n                    # Calculate insertion cost\n                    cost = (distance_matrix[new_route[pos-1], cluster[0]] +\n                            distance_matrix[cluster[-1], new_route[pos]] -\n                            distance_matrix[new_route[pos-1], new_route[pos]])\n\n                    if cost < best_cost:\n                        best_cost = cost\n                        best_pos = pos\n\n                new_route = new_route[:best_pos] + cluster + new_route[best_pos:]\n\n            new_route.append(0)\n            new_solution[route_idx] = np.array(new_route)\n\n    # Phase 2: Spatial-demand hybrid optimization\n    for _ in range(3):\n        if len(new_solution) < 2:\n            break\n\n        # Select two routes for potential merging\n        route_indices = random.sample(range(len(new_solution)), 2)\n        route1, route2 = new_solution[route_indices[0]], new_solution[route_indices[1]]\n\n        # Check if merging is feasible\n        total_demand = np.sum(demand[route1[1:-1]]) + np.sum(demand[route2[1:-1]])\n        if total_demand > capacity:\n            continue\n\n        # Calculate spatial proximity\n        last_node1 = route1[-2]\n        first_node2 = route2[1]\n        spatial_dist = distance_matrix[last_node1, first_node2]\n\n        # Calculate demand balance\n        demand_diff = abs(np.sum(demand[route1[1:-1]]) - np.sum(demand[route2[1:-1]]))\n\n        # Merge if spatial proximity is good and demand balance is reasonable\n        if spatial_dist < np.mean(distance_matrix) * 0.7 and demand_diff < capacity * 0.3:\n            merged_route = np.concatenate([route1[:-1], route2[1:]])\n            new_solution[route_indices[0]] = merged_route\n            new_solution.pop(route_indices[1] if route_indices[1] > route_indices[0] else route_indices[0])\n\n    # Phase 3: Demand-patterned node swaps\n    for _ in range(5):\n        if len(new_solution) < 2:\n            break\n\n        route_indices = random.sample(range(len(new_solution)), 2)\n        route1, route2 = new_solution[route_indices[0]], new_solution[route_indices[1]]\n\n        if len(route1) <= 3 or len(route2) <= 3:\n            continue\n\n        # Find nodes with similar demand patterns\n        route1_demands = demand[route1[1:-1]]\n        route2_demands = demand[route2[1:-1]]\n\n        if len(route1_demands) == 0 or len(route2_demands) == 0:\n            continue\n\n        # Find nodes with similar demand in both routes\n        median1 = np.median(route1_demands)\n        median2 = np.median(route2_demands)\n\n        if abs(median1 - median2) > 0.2 * (median1 + median2):\n            continue\n\n        # Select random nodes from each route\n        node1_pos = random.randint(1, len(route1)-2)\n        node2_pos = random.randint(1, len(route2)-2)\n        node1 = route1[node1_pos]\n        node2 = route2[node2_pos]\n\n        # Check capacity constraints\n        new_route1 = route1.copy()\n        new_route1[node1_pos] = node2\n        new_route2 = route2.copy()\n        new_route2[node2_pos] = node1\n\n        if (np.sum(demand[new_route1[1:-1]]) <= capacity and\n            np.sum(demand[new_route2[1:-1]]) <= capacity):\n\n            # Calculate spatial improvement\n            old_dist = (distance_matrix[route1[node1_pos-1], node1] +\n                         distance_matrix[node1, route1[node1_pos+1]] +\n                         distance_matrix[route2[node2_pos-1], node2] +\n                         distance_matrix[node2, route2[node2_pos+1]])\n\n            new_dist = (distance_matrix[route1[node1_pos-1], node2] +\n                         distance_matrix[node2, route1[node1_pos+1]] +\n                         distance_matrix[route2[node2_pos-1], node1] +\n                         distance_matrix[node1, route2[node2_pos+1]])\n\n            if new_dist < old_dist:\n                new_solution[route_indices[0]] = new_route1\n                new_solution[route_indices[1]] = new_route2\n\n    # Final cleanup\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]) / (1 + abs(x[1][0] - x[1][1])))\n    selected_idx = min(3, len(archive_sorted) - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Multi-stage local search\n    for _ in range(4):  # Perform 4 iterations of the multi-stage operator\n        # Stage 1: Route splitting with demand-aware fragmentation\n        if len(new_solution) > 1:\n            route_idx = random.randint(0, len(new_solution) - 1)\n            route = new_solution[route_idx]\n\n            if len(route) > 4:  # Only split if route is long enough\n                # Find split point that balances demand\n                total_demand = np.sum(demand[route[1:-1]])\n                half_demand = total_demand / 2\n                current_demand = 0\n                split_pos = 1\n\n                for i in range(1, len(route) - 1):\n                    current_demand += demand[route[i]]\n                    if current_demand >= half_demand:\n                        split_pos = i\n                        break\n\n                fragment1 = route[:split_pos+1]\n                fragment2 = np.concatenate([[0], route[split_pos+1:]])\n\n                if (np.sum(demand[fragment1[1:-1]]) <= capacity and\n                    np.sum(demand[fragment2[1:-1]]) <= capacity):\n                    new_solution[route_idx] = fragment1\n                    new_solution.append(fragment2)\n\n        # Stage 2: Customer reallocation with demand pattern matching\n        if len(new_solution) > 1:\n            route_idx = random.randint(0, len(new_solution) - 1)\n            route = new_solution[route_idx]\n\n            if len(route) > 3:\n                # Select customers with similar demand patterns\n                route_demand = demand[route[1:-1]]\n                median_demand = np.median(route_demand)\n                similar_customers = [i for i, d in enumerate(route_demand)\n                                   if abs(d - median_demand) <= median_demand * 0.3]\n\n                if similar_customers:\n                    customer_pos = random.choice(similar_customers) + 1  # +1 for route index\n                    customer = route[customer_pos]\n\n                    # Find best route to insert based on demand compatibility\n                    best_route_idx = -1\n                    best_pos = -1\n                    min_demand_diff = float('inf')\n\n                    for other_idx, other_route in enumerate(new_solution):\n                        if other_idx == route_idx:\n                            continue\n\n                        other_demand = np.sum(demand[other_route[1:-1]])\n                        if other_demand + demand[customer] > capacity:\n                            continue\n\n                        for pos in range(1, len(other_route)):\n                            # Prefer positions that maintain demand balance\n                            new_demand = other_demand + demand[customer]\n                            demand_diff = abs(new_demand - capacity/2)\n\n                            if demand_diff < min_demand_diff:\n                                min_demand_diff = demand_diff\n                                best_route_idx = other_idx\n                                best_pos = pos\n\n                    if best_route_idx != -1:\n                        # Move customer to best position\n                        other_route = new_solution[best_route_idx]\n                        new_other_route = np.concatenate([\n                            other_route[:best_pos],\n                            [customer],\n                            other_route[best_pos:]\n                        ])\n                        new_solution[best_route_idx] = new_other_route\n\n                        # Remove from original route\n                        new_route = np.concatenate([route[:customer_pos], route[customer_pos+1:]])\n                        new_solution[route_idx] = new_route\n\n        # Stage 3: Route merging with load balancing\n        if len(new_solution) > 1:\n            # Select two routes to potentially merge\n            routes_to_merge = random.sample(range(len(new_solution)), min(2, len(new_solution)))\n\n            route1 = new_solution[routes_to_merge[0]]\n            route2 = new_solution[routes_to_merge[1]]\n\n            # Check if merging is feasible and maintains balanced load\n            total_demand = np.sum(demand[route1[1:-1]]) + np.sum(demand[route2[1:-1]])\n            if total_demand <= capacity and len(route1) + len(route2) - 2 <= 25:  # Slightly larger route limit\n                # Create merged route\n                merged_route = np.concatenate([route1[:-1], route2[1:]])\n\n                # Update solution\n                new_solution = [route for i, route in enumerate(new_solution)\n                               if i not in routes_to_merge]\n                new_solution.append(merged_route)\n\n    # Final cleanup\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a weighted combination of normalized distance and makespan (60% distance, 40% makespan), then applies a hybrid local search combining route fragmentation, customer reallocation, and route merging. It iteratively fragments long routes, reallocates customers between routes with capacity checks, and merges small routes while limiting route length to 20 nodes. The solution is refined through 5 iterations and finally normalized to remove empty routes.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    weights = np.array([(obj[0] / max(1, obj[0]), obj[1] / max(1, obj[1])) for _, obj in archive])\n    scores = weights[:, 0] * 0.6 + weights[:, 1] * 0.4  # Weighted combination\n    selected_idx = np.argmin(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Hybrid local search: route fragmentation + customer reallocation + route merging\n    for _ in range(5):  # Perform 5 iterations\n        # Randomly select a route to fragment\n        route_idx = random.randint(0, len(new_solution) - 1)\n        route = new_solution[route_idx]\n\n        if len(route) <= 3:\n            continue\n\n        # Fragment route at random point\n        split_pos = random.randint(2, len(route) - 2)\n        fragment = route[split_pos:]\n        remaining = route[:split_pos]\n\n        # Check capacity feasibility for fragments\n        if np.sum(demand[fragment[1:-1]]) <= capacity and np.sum(demand[remaining[1:-1]]) <= capacity:\n            new_solution[route_idx] = remaining\n            new_solution.append(fragment)\n\n        # Customer reallocation: move customers between routes\n        if len(new_solution) > 1:\n            other_route_idx = random.choice([i for i in range(len(new_solution)) if i != route_idx])\n            other_route = new_solution[other_route_idx]\n\n            # Select customers to move (up to 2)\n            customers_to_move = random.sample(range(1, len(route) - 1), min(2, len(route) - 2))\n\n            for customer_pos in sorted(customers_to_move, reverse=True):\n                customer = route[customer_pos]\n\n                # Find best insertion position in other route\n                best_pos = 1\n                min_increase = float('inf')\n                for pos in range(1, len(other_route)):\n                    dist_increase = (distance_matrix[other_route[pos-1], customer] +\n                                   distance_matrix[customer, other_route[pos]] -\n                                   distance_matrix[other_route[pos-1], other_route[pos]])\n\n                    if dist_increase < min_increase:\n                        min_increase = dist_increase\n                        best_pos = pos\n\n                # Check capacity feasibility\n                if np.sum(demand[other_route[1:-1]]) + demand[customer] <= capacity:\n                    # Insert customer into other route\n                    new_other_route = np.concatenate([other_route[:best_pos], [customer], other_route[best_pos:]])\n                    new_solution[other_route_idx] = new_other_route\n\n                    # Remove customer from original route\n                    new_route = np.concatenate([route[:customer_pos], route[customer_pos+1:]])\n                    new_solution[route_idx] = new_route\n                    route = new_route\n\n        # Route merging: try to merge small routes\n        if len(new_solution) > 1:\n            # Select two routes to potentially merge\n            routes_to_merge = random.sample(range(len(new_solution)), min(2, len(new_solution)))\n\n            route1 = new_solution[routes_to_merge[0]]\n            route2 = new_solution[routes_to_merge[1]]\n\n            # Check if merging is feasible\n            if (np.sum(demand[route1[1:-1]]) + np.sum(demand[route2[1:-1]]) <= capacity and\n                len(route1) + len(route2) - 2 <= 20):  # Limit route length\n\n                # Create merged route (route1 + route2 without depot)\n                merged_route = np.concatenate([route1[:-1], route2[1:]])\n\n                # Update solution\n                new_solution = [route for i, route in enumerate(new_solution)\n                               if i not in routes_to_merge]\n                new_solution.append(merged_route)\n\n    # Remove empty routes and normalize\n    new_solution = [route for route in new_solution if len(route) > 2]\n    new_solution = [np.array(route) for route in new_solution]\n\n    return new_solution\n\n\nNo. 6 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with low total distance and makespan, then applies a hybrid local search combining route reversal and customer insertion to generate a neighbor solution while ensuring feasibility. It intelligently balances exploration and exploitation by iteratively modifying routes and customers, checking capacity constraints, and removing empty routes. The key design choices include prioritizing solutions with better objectives, combining 2-opt-like operations with customer relocations, and ensuring feasibility at each step.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0], x[1][1]))\n    selected_idx = min(5, len(archive_sorted) - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n\n    # Make a deep copy of the solution to modify\n    new_solution = [route.copy() for route in base_solution]\n\n    # Hybrid local search: combine route reversal and customer insertion\n    for _ in range(3):  # Perform 3 iterations of the hybrid operator\n        # Randomly select a route to modify\n        route_idx = random.randint(0, len(new_solution) - 1)\n        route = new_solution[route_idx]\n\n        if len(route) <= 3:  # Skip if route is too short\n            continue\n\n        # Apply route reversal (2-opt-like operation)\n        i, j = sorted(random.sample(range(1, len(route) - 1), 2))\n        reversed_segment = route[i:j+1][::-1]\n        new_route = np.concatenate([route[:i], reversed_segment, route[j+1:]])\n\n        # Check capacity feasibility\n        if np.sum(demand[new_route[1:-1]]) <= capacity:\n            new_solution[route_idx] = new_route\n            route = new_route\n\n        # Apply customer insertion (move a customer to another route)\n        if len(new_solution) > 1:\n            other_route_idx = random.choice([i for i in range(len(new_solution)) if i != route_idx])\n            other_route = new_solution[other_route_idx]\n\n            # Select a random customer to move\n            customer_pos = random.randint(1, len(route) - 2)\n            customer = route[customer_pos]\n\n            # Find insertion position in other route\n            best_pos = 1\n            min_increase = float('inf')\n            for pos in range(1, len(other_route)):\n                # Calculate distance increase\n                dist_increase = (distance_matrix[other_route[pos-1], customer] +\n                                distance_matrix[customer, other_route[pos]] -\n                                distance_matrix[other_route[pos-1], other_route[pos]])\n\n                if dist_increase < min_increase:\n                    min_increase = dist_increase\n                    best_pos = pos\n\n            # Check capacity feasibility\n            if np.sum(demand[other_route[1:-1]]) + demand[customer] <= capacity:\n                # Insert customer into other route\n                new_other_route = np.concatenate([other_route[:best_pos], [customer], other_route[best_pos:]])\n                new_solution[other_route_idx] = new_other_route\n\n                # Remove customer from original route\n                new_route = np.concatenate([route[:customer_pos], route[customer_pos+1:]])\n                new_solution[route_idx] = new_route\n\n    # Remove empty routes\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### Keywords:\n- **Adaptive demand-distance clustering**\n- **Multi-objective hybrid reinsertion**\n- **Dynamic operator fusion**\n- **Extreme-solution targeting**\n\n### Advice:\n1. **Cluster customers by demand and spatial proximity**, prioritizing extreme routes (high distance/makespan) for focused improvement.\n2. **Dynamically fuse operators**: 70% demand-aware reinsertion + 30% capacity-gap reversal, weighted by archive diversity.\n3. **Break-and-repair routes** at depot-proximal capacity gaps, balancing spatial and demand efficiency.\n4. **Adjust operator weights** based on archive diversity (e.g., increase splitting in crowded regions).\n\n### Avoid:\n- Static demand thresholds\n- Rigid operator sequences\n- Single-stage reinsertion\n- Uniform extreme-solution selection\n\n### Explanation:\nThis hybrid approach balances demand and spatial efficiency, dynamically adapts operators to archive needs, and ensures feasible neighbors while exploring Pareto trade-offs. Extreme-solution targeting drives multi-objective improvement, while adaptive operator fusion maintains diversity.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 309,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    weights = np.array([(obj[0] / max(1, obj[0]), obj[1] / max(1, obj[1])) for _, obj in archive])\n    scores = weights[:, 0] * 0.7 + weights[:, 1] * 0.3\n    selected_idx = np.argmin(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate archive diversity metrics\n    distances = np.array([obj[0] for _, obj in archive])\n    makespans = np.array([obj[1] for _, obj in archive])\n    dist_crowding = (np.max(distances) - np.min(distances)) / (np.mean(distances) + 1e-6)\n    makespan_crowding = (np.max(makespans) - np.min(makespans)) / (np.mean(makespans) + 1e-6)\n\n    # Dynamic operator weights based on archive diversity\n    operator_weight = 0.7 - 0.3 * dist_crowding\n    reinsert_weight = 0.3 + 0.3 * makespan_crowding\n\n    # Hybrid local search: 4 iterations with adaptive operators\n    for _ in range(4):\n        # Phase 1: Capacity-gap reversal (weighted by archive diversity)\n        if random.random() < operator_weight:\n            if len(new_solution) > 1:\n                # Select route with highest demand concentration near capacity\n                demand_sums = [np.sum(demand[route[1:-1]]) for route in new_solution]\n                route_idx = np.argmax(demand_sums)\n                route = new_solution[route_idx]\n\n                if len(route) > 4:\n                    # Find demand hotspot (top 30% demand nodes)\n                    demands = demand[route[1:-1]]\n                    sorted_idx = np.argsort(demands)[::-1]\n                    hotspot_size = max(2, int(0.3 * len(demands)))\n                    hotspot_nodes = route[sorted_idx[:hotspot_size] + 1]\n\n                    # Split at first hotspot node\n                    split_pos = np.where(route == hotspot_nodes[0])[0][0]\n                    if split_pos > 1 and split_pos < len(route) - 1:\n                        fragment = route[split_pos:]\n                        remaining = route[:split_pos]\n\n                        if (np.sum(demand[fragment[1:-1]]) <= capacity and\n                            np.sum(demand[remaining[1:-1]]) <= capacity):\n                            new_solution[route_idx] = remaining\n                            new_solution.append(fragment)\n\n        # Phase 2: Demand-aware reinsertion (weighted by makespan diversity)\n        if random.random() < reinsert_weight:\n            if len(new_solution) > 1:\n                # Select route with high spatial-demand imbalance\n                route_pairs = []\n                for i in range(len(new_solution)):\n                    for j in range(i+1, len(new_solution)):\n                        route1, route2 = new_solution[i], new_solution[j]\n                        last1, first2 = route1[-2], route2[1]\n                        spatial_dist = distance_matrix[last1, first2]\n                        demand_diff = abs(np.sum(demand[route1[1:-1]]) - np.sum(demand[route2[1:-1]]))\n                        imbalance = spatial_dist * demand_diff\n                        route_pairs.append((imbalance, (i, j)))\n\n                if route_pairs:\n                    _, (i, j) = max(route_pairs)\n                    route1, route2 = new_solution[i], new_solution[j]\n\n                    # Try demand-weighted node reinsertion\n                    if len(route1) > 3 and len(route2) > 3:\n                        route1_demands = demand[route1[1:-1]]\n                        route2_demands = demand[route2[1:-1]]\n                        median1, median2 = np.median(route1_demands), np.median(route2_demands)\n\n                        if abs(median1 - median2) < 0.3 * (median1 + median2):\n                            node1_pos = random.randint(1, len(route1)-2)\n                            node2_pos = random.randint(1, len(route2)-2)\n                            node1, node2 = route1[node1_pos], route2[node2_pos]\n\n                            # Check capacity and spatial improvement\n                            new_route1 = route1.copy()\n                            new_route1[node1_pos] = node2\n                            new_route2 = route2.copy()\n                            new_route2[node2_pos] = node1\n\n                            if (np.sum(demand[new_route1[1:-1]]) <= capacity and\n                                np.sum(demand[new_route2[1:-1]]) <= capacity):\n                                old_dist = (distance_matrix[route1[node1_pos-1], node1] +\n                                           distance_matrix[node1, route1[node1_pos+1]] +\n                                           distance_matrix[route2[node2_pos-1], node2] +\n                                           distance_matrix[node2, route2[node2_pos+1]])\n\n                                new_dist = (distance_matrix[route1[node1_pos-1], node2] +\n                                           distance_matrix[node2, route1[node1_pos+1]] +\n                                           distance_matrix[route2[node2_pos-1], node1] +\n                                           distance_matrix[node1, route2[node2_pos+1]])\n\n                                if new_dist < old_dist:\n                                    new_solution[i] = new_route1\n                                    new_solution[j] = new_route2\n\n        # Phase 3: Spatial-demand cluster merging (when both operators fail)\n        if len(new_solution) > 1:\n            # Find closest route pairs based on spatial and demand similarity\n            route_pairs = []\n            for i in range(len(new_solution)):\n                for j in range(i+1, len(new_solution)):\n                    route1, route2 = new_solution[i], new_solution[j]\n                    spatial_dist = distance_matrix[route1[-2], route2[1]]\n                    demand_diff = abs(np.sum(demand[route1[1:-1]]) - np.sum(demand[route2[1:-1]]))\n                    similarity_score = spatial_dist * demand_diff\n                    route_pairs.append((similarity_score, (i, j)))\n\n            if route_pairs:\n                _, (i, j) = min(route_pairs)\n                route1, route2 = new_solution[i], new_solution[j]\n\n                # Check if merging is feasible\n                total_demand = np.sum(demand[route1[1:-1]]) + np.sum(demand[route2[1:-1]])\n                if total_demand <= capacity:\n                    merged_route = np.concatenate([route1[:-1], route2[1:]])\n                    new_solution[i] = merged_route\n                    del new_solution[j]\n\n    # Final cleanup\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n",
        "score": [
            -0.7193702026584836,
            2.8721887469291687
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    weights = np.array([(obj[0] / max(1, obj[0]), obj[1] / max(1, obj[1])) for _, obj in archive])\n    scores = weights[:, 0] * 0.7 + weights[:, 1] * 0.3\n    selected_idx = np.argmin(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate archive diversity metrics\n    distances = np.array([obj[0] for _, obj in archive])\n    makespans = np.array([obj[1] for _, obj in archive])\n    dist_crowding = (np.max(distances) - np.min(distances)) / (np.mean(distances) + 1e-6)\n    makespan_crowding = (np.max(makespans) - np.min(makespans)) / (np.mean(makespans) + 1e-6)\n\n    # Dynamic operator weights based on archive diversity\n    operator_weight = 0.7 - 0.3 * dist_crowding\n    reinsert_weight = 0.3 + 0.3 * makespan_crowding\n\n    # Hybrid local search: 4 iterations with adaptive operators\n    for _ in range(4):\n        # Phase 1: Capacity-gap reversal (weighted by archive diversity)\n        if random.random() < operator_weight:\n            if len(new_solution) > 1:\n                # Select route with highest demand concentration near capacity\n                demand_sums = [np.sum(demand[route[1:-1]]) for route in new_solution]\n                route_idx = np.argmax(demand_sums)\n                route = new_solution[route_idx]\n\n                if len(route) > 4:\n                    # Find demand hotspot (top 30% demand nodes)\n                    demands = demand[route[1:-1]]\n                    sorted_idx = np.argsort(demands)[::-1]\n                    hotspot_size = max(2, int(0.3 * len(demands)))\n                    hotspot_nodes = route[sorted_idx[:hotspot_size] + 1]\n\n                    # Split at first hotspot node\n                    split_pos = np.where(route == hotspot_nodes[0])[0][0]\n                    if split_pos > 1 and split_pos < len(route) - 1:\n                        fragment = route[split_pos:]\n                        remaining = route[:split_pos]\n\n                        if (np.sum(demand[fragment[1:-1]]) <= capacity and\n                            np.sum(demand[remaining[1:-1]]) <= capacity):\n                            new_solution[route_idx] = remaining\n                            new_solution.append(fragment)\n\n        # Phase 2: Demand-aware reinsertion (weighted by makespan diversity)\n        if random.random() < reinsert_weight:\n            if len(new_solution) > 1:\n                # Select route with high spatial-demand imbalance\n                route_pairs = []\n                for i in range(len(new_solution)):\n                    for j in range(i+1, len(new_solution)):\n                        route1, route2 = new_solution[i], new_solution[j]\n                        last1, first2 = route1[-2], route2[1]\n                        spatial_dist = distance_matrix[last1, first2]\n                        demand_diff = abs(np.sum(demand[route1[1:-1]]) - np.sum(demand[route2[1:-1]]))\n                        imbalance = spatial_dist * demand_diff\n                        route_pairs.append((imbalance, (i, j)))\n\n                if route_pairs:\n                    _, (i, j) = max(route_pairs)\n                    route1, route2 = new_solution[i], new_solution[j]\n\n                    # Try demand-weighted node reinsertion\n                    if len(route1) > 3 and len(route2) > 3:\n                        route1_demands = demand[route1[1:-1]]\n                        route2_demands = demand[route2[1:-1]]\n                        median1, median2 = np.median(route1_demands), np.median(route2_demands)\n\n                        if abs(median1 - median2) < 0.3 * (median1 + median2):\n                            node1_pos = random.randint(1, len(route1)-2)\n                            node2_pos = random.randint(1, len(route2)-2)\n                            node1, node2 = route1[node1_pos], route2[node2_pos]\n\n                            # Check capacity and spatial improvement\n                            new_route1 = route1.copy()\n                            new_route1[node1_pos] = node2\n                            new_route2 = route2.copy()\n                            new_route2[node2_pos] = node1\n\n                            if (np.sum(demand[new_route1[1:-1]]) <= capacity and\n                                np.sum(demand[new_route2[1:-1]]) <= capacity):\n                                old_dist = (distance_matrix[route1[node1_pos-1], node1] +\n                                           distance_matrix[node1, route1[node1_pos+1]] +\n                                           distance_matrix[route2[node2_pos-1], node2] +\n                                           distance_matrix[node2, route2[node2_pos+1]])\n\n                                new_dist = (distance_matrix[route1[node1_pos-1], node2] +\n                                           distance_matrix[node2, route1[node1_pos+1]] +\n                                           distance_matrix[route2[node2_pos-1], node1] +\n                                           distance_matrix[node1, route2[node2_pos+1]])\n\n                                if new_dist < old_dist:\n                                    new_solution[i] = new_route1\n                                    new_solution[j] = new_route2\n\n        # Phase 3: Spatial-demand cluster merging (when both operators fail)\n        if len(new_solution) > 1:\n            # Find closest route pairs based on spatial and demand similarity\n            route_pairs = []\n            for i in range(len(new_solution)):\n                for j in range(i+1, len(new_solution)):\n                    route1, route2 = new_solution[i], new_solution[j]\n                    spatial_dist = distance_matrix[route1[-2], route2[1]]\n                    demand_diff = abs(np.sum(demand[route1[1:-1]]) - np.sum(demand[route2[1:-1]]))\n                    similarity_score = spatial_dist * demand_diff\n                    route_pairs.append((similarity_score, (i, j)))\n\n            if route_pairs:\n                _, (i, j) = min(route_pairs)\n                route1, route2 = new_solution[i], new_solution[j]\n\n                # Check if merging is feasible\n                total_demand = np.sum(demand[route1[1:-1]]) + np.sum(demand[route2[1:-1]])\n                if total_demand <= capacity:\n                    merged_route = np.concatenate([route1[:-1], route2[1:]])\n                    new_solution[i] = merged_route\n                    del new_solution[j]\n\n    # Final cleanup\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Capacitated Vehicle Routing Problem (Bi-CVRP), where a single depot and multiple customers are located in 2D space. Each customer has a positive demand, and all vehicles in the fleet have identical capacity limits. The objective is to construct a set of routes, each starting and ending at the depot, such that all customers are served, vehicle capacities are not exceeded on any route, and two conflicting objectives are minimized: (1) the total travel distance across all routes, and (2) the makespan, defined as the length of the longest individual route. Each solution in the archive is represented as a list of NumPy arrays, where each array denotes a single route (starting and ending with depot index 0), and is paired with a tuple of two objective values (total_distance, makespan). Your task is to implement a function named 'select_neighbor' that selects one promising solution from the archive and apply a novel or hybrid local search operator to generate a feasible neighbor solution from it. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself. Avoid standard methods like pure 2-opt; instead, invent or combine transformations, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. Ensure that the returned neighbor solution remains feasible under the vehicle capacity constraint. The function should return the new neighbor solution.\n        I have 6 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with low total distance and makespan, then applies a hybrid local search combining route reversal and customer insertion to generate a neighbor solution while ensuring feasibility. It intelligently balances exploration and exploitation by iteratively modifying routes and customers, checking capacity constraints, and removing empty routes. The key design choices include prioritizing solutions with better objectives, combining 2-opt-like operations with customer relocations, and ensuring feasibility at each step.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0], x[1][1]))\n    selected_idx = min(5, len(archive_sorted) - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n\n    # Make a deep copy of the solution to modify\n    new_solution = [route.copy() for route in base_solution]\n\n    # Hybrid local search: combine route reversal and customer insertion\n    for _ in range(3):  # Perform 3 iterations of the hybrid operator\n        # Randomly select a route to modify\n        route_idx = random.randint(0, len(new_solution) - 1)\n        route = new_solution[route_idx]\n\n        if len(route) <= 3:  # Skip if route is too short\n            continue\n\n        # Apply route reversal (2-opt-like operation)\n        i, j = sorted(random.sample(range(1, len(route) - 1), 2))\n        reversed_segment = route[i:j+1][::-1]\n        new_route = np.concatenate([route[:i], reversed_segment, route[j+1:]])\n\n        # Check capacity feasibility\n        if np.sum(demand[new_route[1:-1]]) <= capacity:\n            new_solution[route_idx] = new_route\n            route = new_route\n\n        # Apply customer insertion (move a customer to another route)\n        if len(new_solution) > 1:\n            other_route_idx = random.choice([i for i in range(len(new_solution)) if i != route_idx])\n            other_route = new_solution[other_route_idx]\n\n            # Select a random customer to move\n            customer_pos = random.randint(1, len(route) - 2)\n            customer = route[customer_pos]\n\n            # Find insertion position in other route\n            best_pos = 1\n            min_increase = float('inf')\n            for pos in range(1, len(other_route)):\n                # Calculate distance increase\n                dist_increase = (distance_matrix[other_route[pos-1], customer] +\n                                distance_matrix[customer, other_route[pos]] -\n                                distance_matrix[other_route[pos-1], other_route[pos]])\n\n                if dist_increase < min_increase:\n                    min_increase = dist_increase\n                    best_pos = pos\n\n            # Check capacity feasibility\n            if np.sum(demand[other_route[1:-1]]) + demand[customer] <= capacity:\n                # Insert customer into other route\n                new_other_route = np.concatenate([other_route[:best_pos], [customer], other_route[best_pos:]])\n                new_solution[other_route_idx] = new_other_route\n\n                # Remove customer from original route\n                new_route = np.concatenate([route[:customer_pos], route[customer_pos+1:]])\n                new_solution[route_idx] = new_route\n\n    # Remove empty routes\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a balanced solution from the archive, then applies a dynamic hybrid local search combining demand-aware spatial clustering, load-balanced route fragmentation, and multi-objective hybrid reinsertion, adaptively adjusting operator probabilities based on operator success rates while maintaining feasibility through continuous capacity checks. It prioritizes operators that show recent success (e.g., increasing weights for merge/split if successful) and focuses on spatial proximity and demand compatibility for route modifications.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    archive_sorted = sorted(archive, key=lambda x: abs(x[1][0] - x[1][1]))\n    selected_idx = min(2, len(archive_sorted) - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate route statistics and centroids\n    route_stats = []\n    route_centroids = []\n    for route in new_solution:\n        if len(route) <= 2:\n            route_stats.append((0, 0, 0, 0))\n            route_centroids.append(np.zeros(2))\n            continue\n        customers = route[1:-1]\n        total_demand = np.sum(demand[customers])\n        total_distance = sum(distance_matrix[route[i], route[i+1]] for i in range(len(route)-1))\n        centroid = np.mean(coords[customers], axis=0)\n        route_stats.append((total_demand, total_distance, centroid, len(customers)))\n        route_centroids.append(centroid)\n\n    # Dynamic hybrid local search\n    operators = ['merge', 'split', 'reverse', 'insert']\n    operator_weights = [0.3, 0.3, 0.2, 0.2]  # Initial weights\n\n    for _ in range(5):  # Perform 5 iterations\n        # Select operator based on current weights\n        operator = random.choices(operators, weights=operator_weights, k=1)[0]\n\n        if operator == 'merge' and len(new_solution) >= 2:\n            # Find closest pair of routes\n            min_dist = float('inf')\n            best_pair = None\n            for i in range(len(new_solution)):\n                for j in range(i+1, len(new_solution)):\n                    dist = np.linalg.norm(route_centroids[i] - route_centroids[j])\n                    if dist < min_dist:\n                        min_dist = dist\n                        best_pair = (i, j)\n\n            if best_pair:\n                i, j = best_pair\n                route1, route2 = new_solution[i], new_solution[j]\n                total_demand = route_stats[i][0] + route_stats[j][0]\n                if total_demand <= capacity:\n                    merged_route = np.concatenate([route1[:-1], route2[1:]])\n                    new_solution[i] = merged_route\n                    new_solution.pop(j)\n                    route_stats.pop(j)\n                    route_centroids.pop(j)\n                    if len(merged_route) > 2:\n                        customers = merged_route[1:-1]\n                        route_stats[i] = (np.sum(demand[customers]),\n                                         sum(distance_matrix[merged_route[k], merged_route[k+1]] for k in range(len(merged_route)-1)),\n                                         np.mean(coords[customers], axis=0),\n                                         len(customers))\n                        route_centroids[i] = route_stats[i][2]\n                    else:\n                        route_stats[i] = (0, 0, np.zeros(2), 0)\n                        route_centroids[i] = np.zeros(2)\n                    # Update weights to favor merge more if successful\n                    operator_weights = [w * 1.1 if op == 'merge' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'split' and len(new_solution) > 1:\n            # Find longest route with high demand\n            longest_idx = max(range(len(new_solution)), key=lambda i: route_stats[i][0])\n            route = new_solution[longest_idx]\n            if len(route) > 4:\n                customers = route[1:-1]\n                total_demand = route_stats[longest_idx][0]\n                best_split = None\n                min_diff = float('inf')\n\n                for j in range(2, len(route)-2):\n                    left_demand = np.sum(demand[route[1:j+1]])\n                    right_demand = total_demand - left_demand\n                    if left_demand <= capacity and right_demand <= capacity:\n                        diff = abs(left_demand - right_demand)\n                        if diff < min_diff:\n                            min_diff = diff\n                            best_split = j\n\n                if best_split:\n                    j = best_split\n                    first_part = route[:j+1] + [0]\n                    second_part = [0] + route[j+1:]\n\n                    new_solution[longest_idx] = first_part\n                    new_solution.append(second_part)\n\n                    # Update stats for both parts\n                    for k, part in enumerate([first_part, second_part]):\n                        if len(part) > 2:\n                            customers = part[1:-1]\n                            stats = (np.sum(demand[customers]),\n                                   sum(distance_matrix[part[i], part[i+1]] for i in range(len(part)-1)),\n                                   np.mean(coords[customers], axis=0),\n                                   len(customers))\n                            if k == 0:\n                                route_stats[longest_idx] = stats\n                                route_centroids[longest_idx] = stats[2]\n                            else:\n                                route_stats.append(stats)\n                                route_centroids.append(stats[2])\n                        else:\n                            if k == 0:\n                                route_stats[longest_idx] = (0, 0, np.zeros(2), 0)\n                                route_centroids[longest_idx] = np.zeros(2)\n                            else:\n                                route_stats.append((0, 0, np.zeros(2), 0))\n                                route_centroids.append(np.zeros(2))\n                    # Update weights to favor split more if successful\n                    operator_weights = [w * 1.1 if op == 'split' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'reverse' and len(new_solution) > 0:\n            # Select a route to reverse\n            route_idx = random.randint(0, len(new_solution) - 1)\n            route = new_solution[route_idx]\n            if len(route) > 3:\n                i, j = sorted(random.sample(range(1, len(route) - 1), 2))\n                reversed_segment = route[i:j+1][::-1]\n                new_route = np.concatenate([route[:i], reversed_segment, route[j+1:]])\n\n                if np.sum(demand[new_route[1:-1]]) <= capacity:\n                    new_solution[route_idx] = new_route\n                    customers = new_route[1:-1]\n                    route_stats[route_idx] = (np.sum(demand[customers]),\n                                             sum(distance_matrix[new_route[k], new_route[k+1]] for k in range(len(new_route)-1)),\n                                             np.mean(coords[customers], axis=0),\n                                             len(customers))\n                    route_centroids[route_idx] = route_stats[route_idx][2]\n                    # Update weights to favor reverse more if successful\n                    operator_weights = [w * 1.1 if op == 'reverse' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'insert' and len(new_solution) > 1:\n            # Select two different routes\n            route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n            route1, route2 = new_solution[route1_idx], new_solution[route2_idx]\n\n            if len(route1) > 3 and len(route2) > 2:\n                # Select a customer to move\n                customer_pos = random.randint(1, len(route1) - 2)\n                customer = route1[customer_pos]\n\n                # Find best insertion position in route2\n                best_pos = 1\n                min_increase = float('inf')\n                for pos in range(1, len(route2)):\n                    dist_increase = (distance_matrix[route2[pos-1], customer] +\n                                   distance_matrix[customer, route2[pos]] -\n                                   distance_matrix[route2[pos-1], route2[pos]])\n\n                    if dist_increase < min_increase:\n                        min_increase = dist_increase\n                        best_pos = pos\n\n                # Check capacity feasibility\n                if route_stats[route2_idx][0] + demand[customer] <= capacity:\n                    # Insert customer into route2\n                    new_route2 = np.concatenate([route2[:best_pos], [customer], route2[best_pos:]])\n                    new_solution[route2_idx] = new_route2\n\n                    # Remove customer from route1\n                    new_route1 = np.concatenate([route1[:customer_pos], route1[customer_pos+1:]])\n                    new_solution[route1_idx] = new_route1\n\n                    # Update stats for both routes\n                    for k, route in enumerate([new_route1, new_route2]):\n                        if len(route) > 2:\n                            customers = route[1:-1]\n                            stats = (np.sum(demand[customers]),\n                                   sum(distance_matrix[route[i], route[i+1]] for i in range(len(route)-1)),\n                                   np.mean(coords[customers], axis=0),\n                                   len(customers))\n                            if k == 0:\n                                route_stats[route1_idx] = stats\n                                route_centroids[route1_idx] = stats[2]\n                            else:\n                                route_stats[route2_idx] = stats\n                                route_centroids[route2_idx] = stats[2]\n                        else:\n                            if k == 0:\n                                route_stats[route1_idx] = (0, 0, np.zeros(2), 0)\n                                route_centroids[route1_idx] = np.zeros(2)\n                            else:\n                                route_stats[route2_idx] = (0, 0, np.zeros(2), 0)\n                                route_centroids[route2_idx] = np.zeros(2)\n                    # Update weights to favor insert more if successful\n                    operator_weights = [w * 1.1 if op == 'insert' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n    # Remove empty routes\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using adaptive extreme-solution targeting, then applies a multi-stage hybrid local search combining demand-aware spatial clustering, dynamic operator fusion, and weighted multi-objective reinsertion to generate a neighbor solution while maintaining feasibility. It prioritizes operators that improve both objectives (distance and makespan) through weighted scoring, with higher weights for successful operators, and balances improvements between routes based on demand clusters. The algorithm dynamically adjusts operator weights and focuses on demand-aware transformations to balance the bi-objective optimization.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    archive_sorted = sorted(archive, key=lambda x: max(x[1][0], x[1][1]), reverse=True)\n    selected_idx = min(3, len(archive_sorted) - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate route statistics and demand clusters\n    route_stats = []\n    demand_clusters = []\n    for route in new_solution:\n        if len(route) <= 2:\n            route_stats.append((0, 0, 0, 0))\n            demand_clusters.append(0)\n            continue\n        customers = route[1:-1]\n        total_demand = np.sum(demand[customers])\n        total_distance = sum(distance_matrix[route[i], route[i+1]] for i in range(len(route)-1))\n        demand_cluster = np.mean(demand[customers])\n        route_stats.append((total_demand, total_distance, demand_cluster, len(customers)))\n        demand_clusters.append(demand_cluster)\n\n    # Dynamic operator fusion\n    operators = ['cluster_merge', 'demand_split', 'reverse', 'weighted_insert']\n    operator_weights = [0.3, 0.3, 0.2, 0.2]\n\n    for _ in range(5):\n        operator = random.choices(operators, weights=operator_weights, k=1)[0]\n\n        if operator == 'cluster_merge' and len(new_solution) >= 2:\n            # Merge routes from the same demand cluster\n            cluster_routes = {}\n            for i, route in enumerate(new_solution):\n                if len(route) > 2:\n                    cluster = route_stats[i][2]\n                    if cluster not in cluster_routes:\n                        cluster_routes[cluster] = []\n                    cluster_routes[cluster].append(i)\n\n            for cluster, routes in cluster_routes.items():\n                if len(routes) >= 2:\n                    i, j = sorted(routes[:2])\n                    route1, route2 = new_solution[i], new_solution[j]\n                    total_demand = route_stats[i][0] + route_stats[j][0]\n                    if total_demand <= capacity:\n                        merged_route = np.concatenate([route1[:-1], route2[1:]])\n                        new_solution[i] = merged_route\n                        new_solution.pop(j)\n                        route_stats.pop(j)\n                        demand_clusters.pop(j)\n                        if len(merged_route) > 2:\n                            customers = merged_route[1:-1]\n                            route_stats[i] = (np.sum(demand[customers]),\n                                            sum(distance_matrix[merged_route[k], merged_route[k+1]] for k in range(len(merged_route)-1)),\n                                            np.mean(demand[customers]),\n                                            len(customers))\n                            demand_clusters[i] = route_stats[i][2]\n                        else:\n                            route_stats[i] = (0, 0, 0, 0)\n                            demand_clusters[i] = 0\n                        operator_weights = [w * 1.1 if op == 'cluster_merge' else w * 0.9 for w, op in zip(operator_weights, operators)]\n                        break\n\n        elif operator == 'demand_split' and len(new_solution) > 1:\n            # Split routes based on demand balance\n            longest_idx = max(range(len(new_solution)), key=lambda i: route_stats[i][0])\n            route = new_solution[longest_idx]\n            if len(route) > 4:\n                customers = route[1:-1]\n                total_demand = route_stats[longest_idx][0]\n                best_split = None\n                min_diff = float('inf')\n\n                for j in range(2, len(route)-2):\n                    left_demand = np.sum(demand[route[1:j+1]])\n                    right_demand = total_demand - left_demand\n                    if left_demand <= capacity and right_demand <= capacity:\n                        diff = abs(left_demand - right_demand)\n                        if diff < min_diff:\n                            min_diff = diff\n                            best_split = j\n\n                if best_split:\n                    j = best_split\n                    first_part = route[:j+1] + [0]\n                    second_part = [0] + route[j+1:]\n\n                    new_solution[longest_idx] = first_part\n                    new_solution.append(second_part)\n\n                    for k, part in enumerate([first_part, second_part]):\n                        if len(part) > 2:\n                            customers = part[1:-1]\n                            stats = (np.sum(demand[customers]),\n                                   sum(distance_matrix[part[i], part[i+1]] for i in range(len(part)-1)),\n                                   np.mean(demand[customers]),\n                                   len(customers))\n                            if k == 0:\n                                route_stats[longest_idx] = stats\n                                demand_clusters[longest_idx] = stats[2]\n                            else:\n                                route_stats.append(stats)\n                                demand_clusters.append(stats[2])\n                        else:\n                            if k == 0:\n                                route_stats[longest_idx] = (0, 0, 0, 0)\n                                demand_clusters[longest_idx] = 0\n                            else:\n                                route_stats.append((0, 0, 0, 0))\n                                demand_clusters.append(0)\n                    operator_weights = [w * 1.1 if op == 'demand_split' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'reverse' and len(new_solution) > 0:\n            # Reverse route segment with demand-aware selection\n            route_idx = random.randint(0, len(new_solution) - 1)\n            route = new_solution[route_idx]\n            if len(route) > 3:\n                i, j = sorted(random.sample(range(1, len(route) - 1), 2))\n                reversed_segment = route[i:j+1][::-1]\n                new_route = np.concatenate([route[:i], reversed_segment, route[j+1:]])\n\n                if np.sum(demand[new_route[1:-1]]) <= capacity:\n                    new_solution[route_idx] = new_route\n                    customers = new_route[1:-1]\n                    route_stats[route_idx] = (np.sum(demand[customers]),\n                                           sum(distance_matrix[new_route[k], new_route[k+1]] for k in range(len(new_route)-1)),\n                                           np.mean(demand[customers]),\n                                           len(customers))\n                    demand_clusters[route_idx] = route_stats[route_idx][2]\n                    operator_weights = [w * 1.1 if op == 'reverse' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'weighted_insert' and len(new_solution) > 1:\n            # Weighted multi-objective reinsertion\n            route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n            route1, route2 = new_solution[route1_idx], new_solution[route2_idx]\n\n            if len(route1) > 3 and len(route2) > 2:\n                customer_pos = random.randint(1, len(route1) - 2)\n                customer = route1[customer_pos]\n\n                best_pos = 1\n                min_score = float('inf')\n                for pos in range(1, len(route2)):\n                    dist_increase = distance_matrix[route2[pos-1], customer] + distance_matrix[customer, route2[pos]] - distance_matrix[route2[pos-1], route2[pos]]\n                    makespan_increase = max(0, dist_increase - (route_stats[route2_idx][1] - distance_matrix[route2[pos-1], route2[pos]]))\n                    weighted_score = 0.7 * dist_increase + 0.3 * makespan_increase\n\n                    if weighted_score < min_score:\n                        min_score = weighted_score\n                        best_pos = pos\n\n                if route_stats[route2_idx][0] + demand[customer] <= capacity:\n                    new_route2 = np.concatenate([route2[:best_pos], [customer], route2[best_pos:]])\n                    new_solution[route2_idx] = new_route2\n\n                    new_route1 = np.concatenate([route1[:customer_pos], route1[customer_pos+1:]])\n                    new_solution[route1_idx] = new_route1\n\n                    for k, route in enumerate([new_route1, new_route2]):\n                        if len(route) > 2:\n                            customers = route[1:-1]\n                            stats = (np.sum(demand[customers]),\n                                   sum(distance_matrix[route[i], route[i+1]] for i in range(len(route)-1)),\n                                   np.mean(demand[customers]),\n                                   len(customers))\n                            if k == 0:\n                                route_stats[route1_idx] = stats\n                                demand_clusters[route1_idx] = stats[2]\n                            else:\n                                route_stats[route2_idx] = stats\n                                demand_clusters[route2_idx] = stats[2]\n                        else:\n                            if k == 0:\n                                route_stats[route1_idx] = (0, 0, 0, 0)\n                                demand_clusters[route1_idx] = 0\n                            else:\n                                route_stats[route2_idx] = (0, 0, 0, 0)\n                                demand_clusters[route2_idx] = 0\n                    operator_weights = [w * 1.1 if op == 'weighted_insert' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive demand-spatial clustering with extreme-solution targeting to prioritize reallocating customers from overloaded routes, using a weighted hybrid local search approach that dynamically adjusts operator probabilities based on success rates and archive diversity, while maintaining feasibility through capacity checks and spatial proximity constraints. It selectively applies demand-aware spatial reinsertion, capacity-balanced fragmentation, and demand-balanced swaps to extreme routes, breaking and repairing routes at capacity gaps to balance spatial efficiency and demand distribution. The algorithm emphasizes high-demand regions, spatial coherence, and capacity balance while adapting operator selection based on performance feedback.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0], x[1][1]), reverse=True)\n    selected_idx = min(2, len(archive_sorted) - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    all_customers = []\n    for route in new_solution:\n        if len(route) > 2:\n            all_customers.extend(route[1:-1])\n\n    if not all_customers:\n        return new_solution\n\n    demand_clusters = []\n    for route in new_solution:\n        if len(route) > 2:\n            customers = route[1:-1]\n            total_demand = np.sum(demand[customers])\n            demand_density = total_demand / len(customers)\n            demand_clusters.append((total_demand, demand_density))\n        else:\n            demand_clusters.append((0, 0))\n\n    operators = ['spatial_reinsert', 'capacity_fragment', 'demand_balance']\n    operator_weights = [0.4, 0.3, 0.3]\n\n    for _ in range(5):\n        operator = random.choices(operators, weights=operator_weights, k=1)[0]\n\n        if operator == 'spatial_reinsert' and len(new_solution) > 1:\n            route_idx = max(range(len(new_solution)), key=lambda i: demand_clusters[i][0] if len(new_solution[i]) > 2 else 0)\n            route = new_solution[route_idx]\n\n            if len(route) > 3:\n                customer_pos = random.randint(1, len(route)-2)\n                customer = route[customer_pos]\n\n                best_route = None\n                best_pos = None\n                min_distance = float('inf')\n\n                for r_idx in range(len(new_solution)):\n                    if r_idx == route_idx or len(new_solution[r_idx]) < 2:\n                        continue\n\n                    target_route = new_solution[r_idx]\n                    for pos in range(1, len(target_route)):\n                        new_demand = demand_clusters[r_idx][0] + demand[customer]\n                        if new_demand > capacity:\n                            continue\n\n                        distance_score = distance_matrix[target_route[pos-1], customer] + distance_matrix[customer, target_route[pos]] - distance_matrix[target_route[pos-1], target_route[pos]]\n                        spatial_score = np.linalg.norm(coords[customer] - np.mean(coords[target_route[1:-1]], axis=0))\n                        total_score = 0.6 * distance_score + 0.4 * spatial_score\n\n                        if total_score < min_distance:\n                            min_distance = total_score\n                            best_route = r_idx\n                            best_pos = pos\n\n                if best_route is not None:\n                    target_route = new_solution[best_route]\n                    new_target_route = np.concatenate([target_route[:best_pos], [customer], target_route[best_pos:]])\n                    new_solution[best_route] = new_target_route\n\n                    new_route = np.concatenate([route[:customer_pos], route[customer_pos+1:]])\n                    new_solution[route_idx] = new_route\n\n                    for r in [route_idx, best_route]:\n                        if len(new_solution[r]) > 2:\n                            customers = new_solution[r][1:-1]\n                            total_demand = np.sum(demand[customers])\n                            demand_density = total_demand / len(customers)\n                            demand_clusters[r] = (total_demand, demand_density)\n                        else:\n                            demand_clusters[r] = (0, 0)\n\n                    operator_weights = [w * 1.2 if op == 'spatial_reinsert' else w * 0.8 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'capacity_fragment' and len(new_solution) > 0:\n            route_idx = max(range(len(new_solution)), key=lambda i: demand_clusters[i][0] if len(new_solution[i]) > 2 else 0)\n            route = new_solution[route_idx]\n\n            if len(route) > 4:\n                best_split = None\n                min_diff = float('inf')\n\n                for j in range(2, len(route)-2):\n                    left_demand = np.sum(demand[route[1:j+1]])\n                    right_demand = np.sum(demand[route[j+1:-1]])\n                    if left_demand <= capacity and right_demand <= capacity:\n                        diff = abs(left_demand - right_demand)\n                        if diff < min_diff:\n                            min_diff = diff\n                            best_split = j\n\n                if best_split:\n                    j = best_split\n                    first_part = np.concatenate([route[:j+1], [0]])\n                    second_part = np.concatenate([[0], route[j+1:]])\n\n                    new_solution[route_idx] = first_part\n                    new_solution.append(second_part)\n\n                    for part in [first_part, second_part]:\n                        if len(part) > 2:\n                            customers = part[1:-1]\n                            total_demand = np.sum(demand[customers])\n                            demand_density = total_demand / len(customers)\n                            demand_clusters.append((total_demand, demand_density))\n                        else:\n                            demand_clusters.append((0, 0))\n\n                    operator_weights = [w * 1.2 if op == 'capacity_fragment' else w * 0.8 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'demand_balance' and len(new_solution) > 1:\n            min_diff = float('inf')\n            best_pair = None\n            for i in range(len(new_solution)):\n                for j in range(i+1, len(new_solution)):\n                    if len(new_solution[i]) > 2 and len(new_solution[j]) > 2:\n                        diff = abs(demand_clusters[i][0] - demand_clusters[j][0])\n                        if diff < min_diff:\n                            min_diff = diff\n                            best_pair = (i, j)\n\n            if best_pair:\n                i, j = best_pair\n                route1, route2 = new_solution[i], new_solution[j]\n\n                if len(route1) > 3 and len(route2) > 3:\n                    customer1_pos = random.randint(1, len(route1)-2)\n                    customer2_pos = random.randint(1, len(route2)-2)\n                    customer1, customer2 = route1[customer1_pos], route2[customer2_pos]\n\n                    new_demand1 = demand_clusters[i][0] - demand[customer1] + demand[customer2]\n                    new_demand2 = demand_clusters[j][0] - demand[customer2] + demand[customer1]\n\n                    if new_demand1 <= capacity and new_demand2 <= capacity:\n                        new_route1 = route1.copy()\n                        new_route1[customer1_pos] = customer2\n                        new_route2 = route2.copy()\n                        new_route2[customer2_pos] = customer1\n\n                        new_solution[i] = new_route1\n                        new_solution[j] = new_route2\n\n                        for r in [i, j]:\n                            customers = new_solution[r][1:-1]\n                            total_demand = np.sum(demand[customers])\n                            demand_density = total_demand / len(customers)\n                            demand_clusters[r] = (total_demand, demand_density)\n\n                        operator_weights = [w * 1.2 if op == 'demand_balance' else w * 0.8 for w, op in zip(operator_weights, operators)]\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm implements a multi-stage, demand-aware local search strategy that first selects a promising solution from the archive using crowding distance metrics, then applies a hybrid of demand-based route fragmentation (70% probability) and route reversal (30% probability) to generate neighbors while respecting capacity constraints. It prioritizes solutions with high crowding distances and dynamically adjusts operator weights to balance exploration and exploitation, ensuring feasible solutions through continuous demand checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    if len(archive) > 1:\n        distances = np.array([obj[0] for _, obj in archive])\n        makespans = np.array([obj[1] for _, obj in archive])\n        norm_dist = (distances - np.min(distances)) / (np.max(distances) - np.min(distances) + 1e-6)\n        norm_makespan = (makespans - np.min(makespans)) / (np.max(makespans) - np.min(makespans) + 1e-6)\n        crowding = np.zeros(len(archive))\n        for i in range(len(archive)):\n            left = i - 1 if i > 0 else 0\n            right = i + 1 if i < len(archive) - 1 else len(archive) - 1\n            crowding[i] = norm_dist[right] - norm_dist[left] + norm_makespan[right] - norm_makespan[left]\n        selected_idx = np.argmax(crowding)\n    else:\n        selected_idx = 0\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    for _ in range(3):\n        if len(new_solution) > 1:\n            route_idx = random.choice(range(len(new_solution)))\n            route = new_solution[route_idx]\n            if len(route) > 3:\n                demands = demand[route[1:-1]]\n                mean_demand = np.mean(demands)\n                split_pos = 1\n                current_demand = 0\n                for i in range(1, len(route)-1):\n                    current_demand += demand[route[i]]\n                    if current_demand >= mean_demand * (len(route)-2) / 2:\n                        split_pos = i\n                        break\n                fragment = route[split_pos:]\n                remaining = route[:split_pos]\n                if np.sum(demand[fragment[1:-1]]) <= capacity and np.sum(demand[remaining[1:-1]]) <= capacity:\n                    new_solution[route_idx] = remaining\n                    new_solution.append(fragment)\n\n        if len(new_solution) > 1 and random.random() < 0.3:\n            route_idx = random.choice(range(len(new_solution)))\n            route = new_solution[route_idx]\n            if len(route) > 4:\n                i, j = sorted(random.sample(range(1, len(route)-1), 2))\n                reversed_segment = route[i:j+1][::-1]\n                new_route = np.concatenate([route[:i], reversed_segment, route[j+1:]])\n                if np.sum(demand[new_route[1:-1]]) <= capacity:\n                    new_solution[route_idx] = new_route\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n    return new_solution\n\n\nNo. 6 algorithm's description and the corresponding code are:\nThis algorithm implements an adaptive multi-objective local search for the Bi-CVRP that combines four specialized operators (fragmentation, reallocation, hybrid insertion, and swapping) with dynamic weighting based on operator success. It prioritizes solutions with high potential for Pareto improvement by selectively breaking and repairing routes at capacity gaps, balancing spatial efficiency with demand compatibility through probabilistic transformations, and adjusts operator probabilities based on recent success rates. The method maintains feasibility through continuous capacity checks while targeting both total distance and makespan minimization.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] * 0.5 + x[1][1] * 0.5) / (1 + 0.3 * abs(x[1][0] - x[1][1])))\n    selected_idx = min(1, len(archive_sorted) - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    route_stats = []\n    for route in new_solution:\n        customers = route[1:-1]\n        total_demand = np.sum(demand[customers])\n        total_distance = sum(distance_matrix[route[i], route[i+1]] for i in range(len(route)-1))\n        route_stats.append((total_demand, total_distance))\n\n    operators = ['fragment', 'reallocate', 'hybrid_insert', 'swap']\n    operator_weights = [0.25, 0.25, 0.25, 0.25]\n\n    for _ in range(5):\n        operator = random.choices(operators, weights=operator_weights, k=1)[0]\n\n        if operator == 'fragment' and len(new_solution) > 1:\n            target_idx = np.argmax([stats[1] for stats in route_stats])\n            route = new_solution[target_idx]\n            if len(route) > 4:\n                split_pos = len(route) // 2\n                fragment1 = route[:split_pos+1]\n                fragment2 = np.concatenate([[0], route[split_pos+1:]])\n\n                if (np.sum(demand[fragment1[1:-1]]) <= capacity and\n                    np.sum(demand[fragment2[1:-1]]) <= capacity):\n                    new_solution[target_idx] = fragment1\n                    new_solution.append(fragment2)\n                    route_stats[target_idx] = (np.sum(demand[fragment1[1:-1]]),\n                                             sum(distance_matrix[fragment1[i], fragment1[i+1]] for i in range(len(fragment1)-1)))\n                    route_stats.append((np.sum(demand[fragment2[1:-1]]),\n                                      sum(distance_matrix[fragment2[i], fragment2[i+1]] for i in range(len(fragment2)-1))))\n                    operator_weights = [w * 1.1 if op == 'fragment' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'reallocate' and len(new_solution) > 1:\n            target_idx = np.argmax([stats[0] for stats in route_stats])\n            route = new_solution[target_idx]\n            if len(route) > 3:\n                customers = route[1:-1]\n                if len(customers) > 0:\n                    demand_weights = np.abs(demand[customers] - np.mean(demand[route[1:-1]]))\n                    selected_customer_idx = np.argmax(demand_weights)\n                    customer = customers[selected_customer_idx]\n                    customer_pos = np.where(route == customer)[0][0]\n\n                    best_route_idx = -1\n                    best_score = float('inf')\n\n                    for other_idx, other_route in enumerate(new_solution):\n                        if other_idx == target_idx:\n                            continue\n\n                        other_demand = route_stats[other_idx][0]\n                        if other_demand + demand[customer] > capacity:\n                            continue\n\n                        spatial_dist = distance_matrix[other_route[-2], customer]\n                        demand_score = abs(other_demand + demand[customer] - capacity * 0.6)\n\n                        total_score = spatial_dist * 0.4 + demand_score * 0.6\n\n                        if total_score < best_score:\n                            best_score = total_score\n                            best_route_idx = other_idx\n\n                    if best_route_idx != -1:\n                        other_route = new_solution[best_route_idx]\n                        new_other_route = np.concatenate([other_route[:-1], [customer], [0]])\n                        new_solution[best_route_idx] = new_other_route\n                        route_stats[best_route_idx] = (route_stats[best_route_idx][0] + demand[customer],\n                                                      route_stats[best_route_idx][1] + distance_matrix[other_route[-2], customer])\n\n                        new_route = np.concatenate([route[:customer_pos], route[customer_pos+1:]])\n                        new_solution[target_idx] = new_route\n                        route_stats[target_idx] = (route_stats[target_idx][0] - demand[customer],\n                                                  route_stats[target_idx][1] - distance_matrix[route[customer_pos-1], route[customer_pos]] - distance_matrix[route[customer_pos], route[customer_pos+1]] + distance_matrix[route[customer_pos-1], route[customer_pos+1]])\n                        operator_weights = [w * 1.1 if op == 'reallocate' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'hybrid_insert' and len(new_solution) > 1:\n            target_idx = random.randint(0, len(new_solution) - 1)\n            route = new_solution[target_idx]\n            if len(route) > 3:\n                customers = route[1:-1]\n                if len(customers) > 0:\n                    demand_weights = np.abs(demand[customers] - np.mean(demand[route[1:-1]]))\n                    selected_customer_idx = np.argmin(demand_weights)\n                    customer = customers[selected_customer_idx]\n                    customer_pos = np.where(route == customer)[0][0]\n\n                    best_route_idx = -1\n                    best_pos = -1\n                    best_score = float('inf')\n\n                    for other_idx, other_route in enumerate(new_solution):\n                        if other_idx == target_idx:\n                            continue\n\n                        other_demand = route_stats[other_idx][0]\n                        if other_demand + demand[customer] > capacity:\n                            continue\n\n                        for pos in range(1, len(other_route)):\n                            dist_increase = (distance_matrix[other_route[pos-1], customer] +\n                                           distance_matrix[customer, other_route[pos]] -\n                                           distance_matrix[other_route[pos-1], other_route[pos]])\n\n                            demand_score = abs(other_demand + demand[customer] - capacity * 0.5)\n\n                            total_score = dist_increase * 0.6 + demand_score * 0.4\n\n                            if total_score < best_score:\n                                best_score = total_score\n                                best_route_idx = other_idx\n                                best_pos = pos\n\n                    if best_route_idx != -1:\n                        other_route = new_solution[best_route_idx]\n                        new_other_route = np.concatenate([other_route[:best_pos], [customer], other_route[best_pos:]])\n                        new_solution[best_route_idx] = new_other_route\n                        route_stats[best_route_idx] = (route_stats[best_route_idx][0] + demand[customer],\n                                                      route_stats[best_route_idx][1] + best_score)\n\n                        new_route = np.concatenate([route[:customer_pos], route[customer_pos+1:]])\n                        new_solution[target_idx] = new_route\n                        route_stats[target_idx] = (route_stats[target_idx][0] - demand[customer],\n                                                  route_stats[target_idx][1] - best_score)\n                        operator_weights = [w * 1.1 if op == 'hybrid_insert' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'swap' and len(new_solution) > 1:\n            route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n            route1, route2 = new_solution[route1_idx], new_solution[route2_idx]\n\n            if len(route1) > 3 and len(route2) > 3:\n                customer1_pos = random.randint(1, len(route1) - 2)\n                customer2_pos = random.randint(1, len(route2) - 2)\n                customer1, customer2 = route1[customer1_pos], route2[customer2_pos]\n\n                if (route_stats[route1_idx][0] - demand[customer1] + demand[customer2] <= capacity and\n                    route_stats[route2_idx][0] - demand[customer2] + demand[customer1] <= capacity):\n\n                    route1[customer1_pos], route2[customer2_pos] = customer2, customer1\n\n                    dist1_change = (distance_matrix[route1[customer1_pos-1], customer2] +\n                                  distance_matrix[customer2, route1[customer1_pos+1]] -\n                                  distance_matrix[route1[customer1_pos-1], customer1] -\n                                  distance_matrix[customer1, route1[customer1_pos+1]])\n\n                    dist2_change = (distance_matrix[route2[customer2_pos-1], customer1] +\n                                  distance_matrix[customer1, route2[customer2_pos+1]] -\n                                  distance_matrix[route2[customer2_pos-1], customer2] -\n                                  distance_matrix[customer2, route2[customer2_pos+1]])\n\n                    route_stats[route1_idx] = (route_stats[route1_idx][0] - demand[customer1] + demand[customer2],\n                                             route_stats[route1_idx][1] + dist1_change)\n                    route_stats[route2_idx] = (route_stats[route2_idx][0] - demand[customer2] + demand[customer1],\n                                             route_stats[route2_idx][1] + dist2_change)\n                    operator_weights = [w * 1.1 if op == 'swap' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: ### Keywords:\n- **Adaptive demand-spatial clustering**\n- **Multi-objective hybrid reinsertion**\n- **Dynamic operator fusion**\n- **Extreme-solution targeting**\n\n### Advice:\n1. **Cluster customers by demand and spatial proximity**, prioritizing extreme routes (high distance/makespan) for focused improvement.\n2. **Dynamically fuse operators**: 70% demand-aware reinsertion + 30% capacity-gap reversal, weighted by archive diversity.\n3. **Break-and-repair routes** at depot-proximal capacity gaps, balancing spatial and demand efficiency.\n4. **Adjust operator weights** based on archive diversity (e.g., increase splitting in crowded regions).\n\n### Avoid:\n- Static demand thresholds\n- Rigid operator sequences\n- Single-stage reinsertion\n- Uniform extreme-solution selection\n\n### Explanation:\nThis hybrid approach balances demand and spatial efficiency, dynamically adapts operators to archive needs, and ensures feasible neighbors while exploring Pareto trade-offs. Extreme-solution targeting drives multi-objective improvement, while adaptive operator fusion maintains diversity.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 310,
        "algorithm": "The algorithm implements an adaptive local search that prioritizes routes with high demand variance for demand-aware reinsertion (70% weight) and routes with capacity gaps near the depot for capacity-gap reversal (30% weight), dynamically adjusting operator weights based on performance. It balances spatial efficiency and demand compatibility by considering distance, demand compatibility, and spatial proximity when selecting moves, while maintaining feasibility through continuous capacity checks. The selection of solutions from the archive is based on crowding distance to focus improvement on less explored regions of the Pareto front.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    if len(archive) > 1:\n        distances = np.array([obj[0] for _, obj in archive])\n        makespans = np.array([obj[1] for _, obj in archive])\n        norm_dist = (distances - np.min(distances)) / (np.max(distances) - np.min(distances) + 1e-6)\n        norm_makespan = (makespans - np.min(makespans)) / (np.max(makespans) - np.min(makespans) + 1e-6)\n        crowding = np.zeros(len(archive))\n        for i in range(len(archive)):\n            left = i - 1 if i > 0 else 0\n            right = i + 1 if i < len(archive) - 1 else len(archive) - 1\n            crowding[i] = norm_dist[right] - norm_dist[left] + norm_makespan[right] - norm_makespan[left]\n        selected_idx = np.argmax(crowding)\n    else:\n        selected_idx = 0\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate route statistics and demand clusters\n    route_stats = []\n    demand_clusters = []\n    for route in new_solution:\n        if len(route) <= 2:\n            route_stats.append((0, 0, 0, 0))\n            demand_clusters.append(0)\n            continue\n        customers = route[1:-1]\n        total_demand = np.sum(demand[customers])\n        total_distance = sum(distance_matrix[route[i], route[i+1]] for i in range(len(route)-1))\n        demand_cluster = np.mean(demand[customers])\n        centroid = np.mean(coords[customers], axis=0)\n        route_stats.append((total_demand, total_distance, demand_cluster, centroid))\n        demand_clusters.append(demand_cluster)\n\n    # Dynamic operator fusion: 70% demand-aware reinsertion, 30% capacity-gap reversal\n    operators = ['demand_reinsert', 'capacity_reverse']\n    operator_weights = [0.7, 0.3]\n\n    for _ in range(5):\n        operator = random.choices(operators, weights=operator_weights, k=1)[0]\n\n        if operator == 'demand_reinsert' and len(new_solution) > 1:\n            # Prioritize routes with high demand variance\n            route_idx = max(range(len(new_solution)), key=lambda i: np.var(demand[new_solution[i][1:-1]]) if len(new_solution[i]) > 2 else 0)\n            route = new_solution[route_idx]\n\n            if len(route) > 3:\n                # Select customer with demand most different from route average\n                customers = route[1:-1]\n                avg_demand = np.mean(demand[customers])\n                demand_diff = np.abs(demand[customers] - avg_demand)\n                customer_pos = np.argmax(demand_diff) + 1\n                customer = route[customer_pos]\n\n                # Find best target route based on demand compatibility and spatial proximity\n                best_route_idx = -1\n                best_pos = -1\n                best_score = float('inf')\n\n                for other_idx, other_route in enumerate(new_solution):\n                    if other_idx == route_idx:\n                        continue\n\n                    other_demand = route_stats[other_idx][0]\n                    if other_demand + demand[customer] > capacity:\n                        continue\n\n                    # Calculate demand compatibility score\n                    demand_score = abs(other_demand + demand[customer] - capacity * 0.5)\n\n                    # Calculate spatial proximity score\n                    if len(other_route) > 2:\n                        spatial_score = np.linalg.norm(route_stats[route_idx][3] - route_stats[other_idx][3])\n                    else:\n                        spatial_score = np.linalg.norm(coords[customer] - coords[0])\n\n                    # Find best insertion position\n                    for pos in range(1, len(other_route)):\n                        dist_increase = (distance_matrix[other_route[pos-1], customer] +\n                                       distance_matrix[customer, other_route[pos]] -\n                                       distance_matrix[other_route[pos-1], other_route[pos]])\n\n                        total_score = 0.6 * dist_increase + 0.3 * demand_score + 0.1 * spatial_score\n\n                        if total_score < best_score:\n                            best_score = total_score\n                            best_route_idx = other_idx\n                            best_pos = pos\n\n                if best_route_idx != -1:\n                    other_route = new_solution[best_route_idx]\n                    new_other_route = np.concatenate([other_route[:best_pos], [customer], other_route[best_pos:]])\n                    new_solution[best_route_idx] = new_other_route\n\n                    new_route = np.concatenate([route[:customer_pos], route[customer_pos+1:]])\n                    new_solution[route_idx] = new_route\n\n                    # Update statistics\n                    for k, idx in enumerate([route_idx, best_route_idx]):\n                        if len(new_solution[idx]) > 2:\n                            customers = new_solution[idx][1:-1]\n                            total_demand = np.sum(demand[customers])\n                            total_distance = sum(distance_matrix[new_solution[idx][i], new_solution[idx][i+1]] for i in range(len(new_solution[idx])-1))\n                            demand_cluster = np.mean(demand[customers])\n                            centroid = np.mean(coords[customers], axis=0)\n                            route_stats[idx] = (total_demand, total_distance, demand_cluster, centroid)\n                            demand_clusters[idx] = demand_cluster\n                        else:\n                            route_stats[idx] = (0, 0, 0, 0)\n                            demand_clusters[idx] = 0\n\n                    # Update operator weights\n                    operator_weights = [w * 1.1 if op == 'demand_reinsert' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'capacity_reverse' and len(new_solution) > 0:\n            # Prioritize routes with capacity gaps near depot\n            route_idx = max(range(len(new_solution)), key=lambda i: (capacity - route_stats[i][0]) * np.linalg.norm(route_stats[i][3] - coords[0]) if len(new_solution[i]) > 2 else 0)\n            route = new_solution[route_idx]\n\n            if len(route) > 4:\n                # Find segment to reverse that creates a better capacity balance\n                best_i, best_j = -1, -1\n                best_balance = float('inf')\n\n                for i in range(1, len(route)-3):\n                    for j in range(i+1, len(route)-1):\n                        segment = route[i:j+1]\n                        reversed_segment = segment[::-1]\n                        new_route = np.concatenate([route[:i], reversed_segment, route[j+1:]])\n\n                        if np.sum(demand[new_route[1:-1]]) > capacity:\n                            continue\n\n                        # Calculate capacity balance score\n                        left_demand = np.sum(demand[new_route[1:i+1]])\n                        right_demand = np.sum(demand[new_route[j:]])\n                        balance_score = abs(left_demand - right_demand)\n\n                        if balance_score < best_balance:\n                            best_balance = balance_score\n                            best_i, best_j = i, j\n\n                if best_i != -1:\n                    i, j = best_i, best_j\n                    reversed_segment = route[i:j+1][::-1]\n                    new_route = np.concatenate([route[:i], reversed_segment, route[j+1:]])\n                    new_solution[route_idx] = new_route\n\n                    # Update statistics\n                    if len(new_route) > 2:\n                        customers = new_route[1:-1]\n                        total_demand = np.sum(demand[customers])\n                        total_distance = sum(distance_matrix[new_route[i], new_route[i+1]] for i in range(len(new_route)-1))\n                        demand_cluster = np.mean(demand[customers])\n                        centroid = np.mean(coords[customers], axis=0)\n                        route_stats[route_idx] = (total_demand, total_distance, demand_cluster, centroid)\n                        demand_clusters[route_idx] = demand_cluster\n                    else:\n                        route_stats[route_idx] = (0, 0, 0, 0)\n                        demand_clusters[route_idx] = 0\n\n                    # Update operator weights\n                    operator_weights = [w * 1.1 if op == 'capacity_reverse' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n    # Remove empty routes\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n",
        "score": [
            -0.6911375034302518,
            1.9773191511631012
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    if len(archive) > 1:\n        distances = np.array([obj[0] for _, obj in archive])\n        makespans = np.array([obj[1] for _, obj in archive])\n        norm_dist = (distances - np.min(distances)) / (np.max(distances) - np.min(distances) + 1e-6)\n        norm_makespan = (makespans - np.min(makespans)) / (np.max(makespans) - np.min(makespans) + 1e-6)\n        crowding = np.zeros(len(archive))\n        for i in range(len(archive)):\n            left = i - 1 if i > 0 else 0\n            right = i + 1 if i < len(archive) - 1 else len(archive) - 1\n            crowding[i] = norm_dist[right] - norm_dist[left] + norm_makespan[right] - norm_makespan[left]\n        selected_idx = np.argmax(crowding)\n    else:\n        selected_idx = 0\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Calculate route statistics and demand clusters\n    route_stats = []\n    demand_clusters = []\n    for route in new_solution:\n        if len(route) <= 2:\n            route_stats.append((0, 0, 0, 0))\n            demand_clusters.append(0)\n            continue\n        customers = route[1:-1]\n        total_demand = np.sum(demand[customers])\n        total_distance = sum(distance_matrix[route[i], route[i+1]] for i in range(len(route)-1))\n        demand_cluster = np.mean(demand[customers])\n        centroid = np.mean(coords[customers], axis=0)\n        route_stats.append((total_demand, total_distance, demand_cluster, centroid))\n        demand_clusters.append(demand_cluster)\n\n    # Dynamic operator fusion: 70% demand-aware reinsertion, 30% capacity-gap reversal\n    operators = ['demand_reinsert', 'capacity_reverse']\n    operator_weights = [0.7, 0.3]\n\n    for _ in range(5):\n        operator = random.choices(operators, weights=operator_weights, k=1)[0]\n\n        if operator == 'demand_reinsert' and len(new_solution) > 1:\n            # Prioritize routes with high demand variance\n            route_idx = max(range(len(new_solution)), key=lambda i: np.var(demand[new_solution[i][1:-1]]) if len(new_solution[i]) > 2 else 0)\n            route = new_solution[route_idx]\n\n            if len(route) > 3:\n                # Select customer with demand most different from route average\n                customers = route[1:-1]\n                avg_demand = np.mean(demand[customers])\n                demand_diff = np.abs(demand[customers] - avg_demand)\n                customer_pos = np.argmax(demand_diff) + 1\n                customer = route[customer_pos]\n\n                # Find best target route based on demand compatibility and spatial proximity\n                best_route_idx = -1\n                best_pos = -1\n                best_score = float('inf')\n\n                for other_idx, other_route in enumerate(new_solution):\n                    if other_idx == route_idx:\n                        continue\n\n                    other_demand = route_stats[other_idx][0]\n                    if other_demand + demand[customer] > capacity:\n                        continue\n\n                    # Calculate demand compatibility score\n                    demand_score = abs(other_demand + demand[customer] - capacity * 0.5)\n\n                    # Calculate spatial proximity score\n                    if len(other_route) > 2:\n                        spatial_score = np.linalg.norm(route_stats[route_idx][3] - route_stats[other_idx][3])\n                    else:\n                        spatial_score = np.linalg.norm(coords[customer] - coords[0])\n\n                    # Find best insertion position\n                    for pos in range(1, len(other_route)):\n                        dist_increase = (distance_matrix[other_route[pos-1], customer] +\n                                       distance_matrix[customer, other_route[pos]] -\n                                       distance_matrix[other_route[pos-1], other_route[pos]])\n\n                        total_score = 0.6 * dist_increase + 0.3 * demand_score + 0.1 * spatial_score\n\n                        if total_score < best_score:\n                            best_score = total_score\n                            best_route_idx = other_idx\n                            best_pos = pos\n\n                if best_route_idx != -1:\n                    other_route = new_solution[best_route_idx]\n                    new_other_route = np.concatenate([other_route[:best_pos], [customer], other_route[best_pos:]])\n                    new_solution[best_route_idx] = new_other_route\n\n                    new_route = np.concatenate([route[:customer_pos], route[customer_pos+1:]])\n                    new_solution[route_idx] = new_route\n\n                    # Update statistics\n                    for k, idx in enumerate([route_idx, best_route_idx]):\n                        if len(new_solution[idx]) > 2:\n                            customers = new_solution[idx][1:-1]\n                            total_demand = np.sum(demand[customers])\n                            total_distance = sum(distance_matrix[new_solution[idx][i], new_solution[idx][i+1]] for i in range(len(new_solution[idx])-1))\n                            demand_cluster = np.mean(demand[customers])\n                            centroid = np.mean(coords[customers], axis=0)\n                            route_stats[idx] = (total_demand, total_distance, demand_cluster, centroid)\n                            demand_clusters[idx] = demand_cluster\n                        else:\n                            route_stats[idx] = (0, 0, 0, 0)\n                            demand_clusters[idx] = 0\n\n                    # Update operator weights\n                    operator_weights = [w * 1.1 if op == 'demand_reinsert' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n        elif operator == 'capacity_reverse' and len(new_solution) > 0:\n            # Prioritize routes with capacity gaps near depot\n            route_idx = max(range(len(new_solution)), key=lambda i: (capacity - route_stats[i][0]) * np.linalg.norm(route_stats[i][3] - coords[0]) if len(new_solution[i]) > 2 else 0)\n            route = new_solution[route_idx]\n\n            if len(route) > 4:\n                # Find segment to reverse that creates a better capacity balance\n                best_i, best_j = -1, -1\n                best_balance = float('inf')\n\n                for i in range(1, len(route)-3):\n                    for j in range(i+1, len(route)-1):\n                        segment = route[i:j+1]\n                        reversed_segment = segment[::-1]\n                        new_route = np.concatenate([route[:i], reversed_segment, route[j+1:]])\n\n                        if np.sum(demand[new_route[1:-1]]) > capacity:\n                            continue\n\n                        # Calculate capacity balance score\n                        left_demand = np.sum(demand[new_route[1:i+1]])\n                        right_demand = np.sum(demand[new_route[j:]])\n                        balance_score = abs(left_demand - right_demand)\n\n                        if balance_score < best_balance:\n                            best_balance = balance_score\n                            best_i, best_j = i, j\n\n                if best_i != -1:\n                    i, j = best_i, best_j\n                    reversed_segment = route[i:j+1][::-1]\n                    new_route = np.concatenate([route[:i], reversed_segment, route[j+1:]])\n                    new_solution[route_idx] = new_route\n\n                    # Update statistics\n                    if len(new_route) > 2:\n                        customers = new_route[1:-1]\n                        total_demand = np.sum(demand[customers])\n                        total_distance = sum(distance_matrix[new_route[i], new_route[i+1]] for i in range(len(new_route)-1))\n                        demand_cluster = np.mean(demand[customers])\n                        centroid = np.mean(coords[customers], axis=0)\n                        route_stats[route_idx] = (total_demand, total_distance, demand_cluster, centroid)\n                        demand_clusters[route_idx] = demand_cluster\n                    else:\n                        route_stats[route_idx] = (0, 0, 0, 0)\n                        demand_clusters[route_idx] = 0\n\n                    # Update operator weights\n                    operator_weights = [w * 1.1 if op == 'capacity_reverse' else w * 0.9 for w, op in zip(operator_weights, operators)]\n\n    # Remove empty routes\n    new_solution = [route for route in new_solution if len(route) > 2]\n\n    return new_solution\n\n",
        "operation": "elitist"
    }
]