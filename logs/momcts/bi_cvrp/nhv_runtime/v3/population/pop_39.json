[
    {
        "algorithm": "The algorithm selects the solution with the smallest makespan from the archive to prioritize reducing the longest route, then applies a hybrid local search that randomly splits long routes or performs 2-opt exchanges while ensuring demand feasibility. The method balances exploration (random selection) and exploitation (demand checks) to generate feasible neighbor solutions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    selected_solution = min(archive, key=lambda x: x[1][1])[0].copy()\n\n    # Create a copy of the selected solution for modification\n    new_solution = [route.copy() for route in selected_solution]\n\n    # Hybrid local search: Split long routes and apply 2-opt with demand checks\n    for i in range(len(new_solution)):\n        route = new_solution[i]\n        if len(route) <= 3:  # Skip trivial routes\n            continue\n\n        # Try splitting the route at a random position\n        split_pos = np.random.randint(1, len(route)-1)\n        part1 = route[:split_pos+1]\n        part2 = route[split_pos:]\n\n        # Check if split is feasible\n        if np.sum(demand[part1[1:-1]]) <= capacity and np.sum(demand[part2[1:-1]]) <= capacity:\n            new_solution[i] = part1\n            new_solution.append(part2)\n            continue\n\n        # If split not feasible, try 2-opt with demand checks\n        for _ in range(3):  # Try a few 2-opt attempts\n            a, b = np.random.choice(len(route)-2, 2, replace=False)\n            a, b = min(a, b), max(a, b)\n\n            # Reverse the segment between a and b\n            new_route = np.concatenate([route[:a+1], route[a+1:b+1][::-1], route[b+1:]])\n\n            # Check demand feasibility\n            if np.sum(demand[new_route[1:-1]]) <= capacity:\n                new_solution[i] = new_route\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.6387737338342709,
            0.11363464593887329
        ]
    },
    {
        "algorithm": "The algorithm selects the solution with the highest total distance from the archive to prioritize reducing travel distance, then applies a hybrid local search combining 3-opt exchanges and route merging, ensuring capacity constraints are met. It balances exploration (random selection) and exploitation (demand checks) to generate improved solutions, favoring longer routes for distance reduction while occasionally merging routes to balance makespan.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    selected_solution = max(archive, key=lambda x: x[1][0])[0].copy()\n    new_solution = [route.copy() for route in selected_solution]\n\n    for i in range(len(new_solution)):\n        route = new_solution[i]\n        if len(route) <= 3:\n            continue\n\n        # Try 3-opt exchange\n        for _ in range(2):\n            a, b, c = np.random.choice(len(route)-2, 3, replace=False)\n            a, b, c = sorted([a, b, c])\n\n            # Reverse segments between a-b and b-c\n            new_route = np.concatenate([route[:a+1], route[a+1:b+1][::-1], route[b+1:c+1][::-1], route[c+1:]])\n\n            if np.sum(demand[new_route[1:-1]]) <= capacity:\n                new_solution[i] = new_route\n                break\n\n        # Try merging with another route if possible\n        if len(new_solution) > 1 and np.random.rand() < 0.3:\n            j = np.random.randint(0, len(new_solution))\n            if i != j:\n                merged_route = np.concatenate([new_solution[i][:-1], new_solution[j][1:]])\n                if np.sum(demand[merged_route[1:-1]]) <= capacity:\n                    new_solution[i] = merged_route\n                    new_solution.pop(j)\n\n    return new_solution\n\n",
        "score": [
            -0.9086821471873222,
            0.2986367642879486
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using a hybrid selection criterion that balances normalized total distance and makespan, then applies a novel route-merging and demand-balanced splitting operator to generate a neighbor solution by intelligently redistributing customers while respecting capacity constraints and improving both objectives. It prioritizes solutions with better balance between distance and makespan (weighted 70% distance, 30% makespan) and performs local improvements through capacity-constrained customer swaps. The selection prioritizes solutions with better balance between objectives, while the local search focuses on route merging/splitting and customer reordering to improve both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    total_distances = np.array([obj[0] for _, obj in archive])\n    makespans = np.array([obj[1] for _, obj in archive])\n\n    norm_dist = (total_distances - total_distances.min()) / (total_distances.max() - total_distances.min() + 1e-6)\n    norm_makespan = (makespans - makespans.min()) / (makespans.max() - makespans.min() + 1e-6)\n\n    weights = 0.7  # Prefer solutions with better balance between distance and makespan\n    scores = weights * norm_dist + (1 - weights) * norm_makespan\n    probabilities = 1 / (scores + 1e-6)\n    probabilities /= probabilities.sum()\n\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Novel route-merging and demand-balanced splitting operator\n    if len(new_solution) > 1:\n        # Select two routes to merge\n        route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n        route1, route2 = new_solution[route1_idx], new_solution[route2_idx]\n\n        # Combine the routes (excluding depots)\n        combined_route = np.concatenate([route1[1:-1], route2[1:-1]])\n        combined_demand = np.sum(demand[combined_route])\n\n        # Split into new routes while balancing demand\n        if combined_demand <= capacity:\n            # Simple case: merge into one route if possible\n            new_route = np.concatenate([[0], combined_route, [0]])\n            new_solution[route1_idx] = new_route\n            del new_solution[route2_idx]\n        else:\n            # More complex case: split into two balanced routes\n            sorted_indices = np.argsort(combined_route)\n            sorted_route = combined_route[sorted_indices]\n            sorted_demands = demand[sorted_route]\n\n            # Find split point that balances demand\n            cumulative_demand = np.cumsum(sorted_demands)\n            split_pos = np.argmax(cumulative_demand <= capacity) + 1\n\n            route1_new = np.concatenate([[0], sorted_route[:split_pos], [0]])\n            route2_new = np.concatenate([[0], sorted_route[split_pos:], [0]])\n\n            new_solution[route1_idx] = route1_new\n            new_solution[route2_idx] = route2_new\n\n    # Additional local improvements with capacity checks\n    for route in new_solution:\n        if len(route) > 3:\n            # Try to improve by moving customers between consecutive positions\n            for _ in range(3):\n                a = random.randint(1, len(route)-2)\n                b = a + 1 if a < len(route)-2 else a - 1\n\n                # Swap positions if feasible\n                new_route = route.copy()\n                new_route[a], new_route[b] = new_route[b], new_route[a]\n\n                if np.sum(demand[new_route[1:-1]]) <= capacity:\n                    route[:] = new_route\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.8224852005278709,
            0.1528381109237671
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive with higher probability if it has a lower makespan (using inverse weighting), then performs spatial-aware route merging (combining two routes if their combined demand fits capacity) or demand-balanced splitting (if not, splitting the merged route into two balanced segments). It then applies limited random swaps within routes to further refine the solution while ensuring feasibility. The method prioritizes makespan reduction and capacity constraints, with secondary focus on distance via implicit route merging.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    makespans = np.array([obj[1] for _, obj in archive])\n    probabilities = 1 / (makespans + 1e-6)\n    probabilities /= probabilities.sum()\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    if len(new_solution) > 1:\n        route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n        route1, route2 = new_solution[route1_idx], new_solution[route2_idx]\n\n        combined_route = np.concatenate([route1[1:-1], route2[1:-1]])\n        combined_demand = np.sum(demand[combined_route])\n\n        if combined_demand <= capacity:\n            new_route = np.concatenate([[0], combined_route, [0]])\n            new_solution[route1_idx] = new_route\n            del new_solution[route2_idx]\n        else:\n            sorted_indices = np.argsort(combined_route)\n            sorted_route = combined_route[sorted_indices]\n            sorted_demands = demand[sorted_route]\n            cumulative_demand = np.cumsum(sorted_demands)\n            split_pos = np.argmax(cumulative_demand <= capacity) + 1\n\n            route1_new = np.concatenate([[0], sorted_route[:split_pos], [0]])\n            route2_new = np.concatenate([[0], sorted_route[split_pos:], [0]])\n\n            new_solution[route1_idx] = route1_new\n            new_solution[route2_idx] = route2_new\n\n    for route in new_solution:\n        if len(route) > 3:\n            for _ in range(3):\n                a = random.randint(1, len(route)-2)\n                b = a + 1 if a < len(route)-2 else a - 1\n                new_route = route.copy()\n                new_route[a], new_route[b] = new_route[b], new_route[a]\n                if np.sum(demand[new_route[1:-1]]) <= capacity:\n                    route[:] = new_route\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.7595606897925501,
            0.12860560417175293
        ]
    },
    {
        "algorithm": "The algorithm selects promising solutions from the archive (prioritizing shorter total distances) and applies a hybrid local search combining demand-based route clustering, spatial inversions, and probabilistic segment exchanges to balance objectives while ensuring capacity feasibility. It dynamically merges and splits routes using demand similarity and spatial proximity, with optional spatial inversions for demand balancing, and guarantees all nodes are visited through capacity-checked additions. The approach emphasizes intelligent route segmentation and demand-aware transformations to improve both total distance and makespan objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    distances = [obj[0] for _, obj in archive]\n    weights = [1/(d+1e-6) for d in distances]\n    weights = [w/sum(weights) for w in weights]\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Step 1: Cluster routes by demand similarity and spatial proximity\n    clusters = []\n    for route in new_solution:\n        if len(route) <= 3:\n            clusters.append([route])\n            continue\n\n        route_demands = demand[route[1:-1]]\n        demand_mean = np.mean(route_demands)\n        demand_std = np.std(route_demands)\n\n        route_coords = coords[route[1:-1]]\n        centroid = np.mean(route_coords, axis=0)\n        distances = [np.linalg.norm(coords[node] - centroid) for node in route[1:-1]]\n\n        # Split into clusters based on demand deviation and spatial distance\n        cluster_points = [0]\n        for i in range(1, len(route)-2):\n            if (abs(route_demands[i] - demand_mean) > demand_std or\n                distances[i] > np.mean(distances) * 1.2):\n                cluster_points.append(i)\n        cluster_points.append(len(route)-2)\n\n        route_clusters = []\n        for j in range(len(cluster_points)-1):\n            start, end = cluster_points[j], cluster_points[j+1]\n            cluster = route[start:end+1]\n            route_clusters.append(cluster)\n        clusters.append(route_clusters)\n\n    # Step 2: Perform demand-based route merging with spatial considerations\n    all_segments = [seg for route_clusters in clusters for seg in route_clusters]\n    np.random.shuffle(all_segments)\n\n    merged_routes = []\n    current_route = [0]\n    current_demand = 0\n\n    for seg in all_segments:\n        seg_demand = np.sum(demand[seg[1:-1]])\n        if current_demand + seg_demand <= capacity * 0.95:  # Tighter capacity utilization\n            current_route.extend(seg[1:-1])\n            current_demand += seg_demand\n        else:\n            current_route.append(0)\n            merged_routes.append(np.array(current_route))\n            current_route = [0, *seg[1:-1]]\n            current_demand = seg_demand\n\n    if len(current_route) > 1:\n        current_route.append(0)\n        merged_routes.append(np.array(current_route))\n\n    # Step 3: Optional spatial inversion with demand balancing\n    if np.random.rand() < 0.35 and len(merged_routes) > 1:\n        i = np.random.randint(len(merged_routes))\n        if len(merged_routes[i]) > 5:\n            route = merged_routes[i]\n            route_demands = demand[route[1:-1]]\n            demand_diff = np.abs(route_demands - np.mean(route_demands))\n\n            split_pos = np.argmax(demand_diff) + 1\n\n            new_route = np.concatenate([route[:split_pos+1], route[split_pos+1:][::-1], [0]])\n            if np.sum(demand[new_route[1:-1]]) <= capacity:\n                merged_routes[i] = new_route\n\n    # Step 4: Ensure all nodes are visited with capacity check\n    all_nodes = set(range(1, len(coords)))\n    visited_nodes = set()\n    for route in merged_routes:\n        visited_nodes.update(route[1:-1])\n    missing_nodes = all_nodes - visited_nodes\n\n    if missing_nodes:\n        for node in missing_nodes:\n            new_route = np.array([0, node, 0])\n            if demand[node] <= capacity:\n                merged_routes.append(new_route)\n            else:\n                # Split demand if node exceeds capacity\n                remaining = demand[node]\n                while remaining > 0:\n                    take = min(remaining, capacity)\n                    new_route = np.array([0, node, 0])\n                    merged_routes.append(new_route)\n                    remaining -= take\n\n    return merged_routes\n\n",
        "score": [
            -0.921322653271166,
            1.6885297894477844
        ]
    },
    {
        "algorithm": "The algorithm selects solutions from the archive with higher probability for longer routes (inverse makespan weighting), then performs demand-balanced cross-route merges and spatial-aware swaps to improve both objectives while ensuring feasibility. It prioritizes route combination when demands fit within capacity, otherwise splits routes to maintain feasibility, and applies limited swaps to refine individual routes. The selection bias toward longer routes (makespan) targets the primary objective, while the demand-aware operations ensure capacity constraints are respected.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    makespans = np.array([obj[1] for _, obj in archive])\n    probabilities = 1 / (makespans + 1e-6)\n    probabilities /= probabilities.sum()\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    if len(new_solution) > 1:\n        route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n        route1, route2 = new_solution[route1_idx], new_solution[route2_idx]\n\n        combined_route = np.concatenate([route1[1:-1], route2[1:-1]])\n        combined_demand = np.sum(demand[combined_route])\n\n        if combined_demand <= capacity:\n            new_route = np.concatenate([[0], combined_route, [0]])\n            new_solution[route1_idx] = new_route\n            del new_solution[route2_idx]\n        else:\n            sorted_indices = np.argsort(combined_route)\n            sorted_route = combined_route[sorted_indices]\n            sorted_demands = demand[sorted_route]\n            cumulative_demand = np.cumsum(sorted_demands)\n            split_pos = np.argmax(cumulative_demand <= capacity) + 1\n\n            route1_new = np.concatenate([[0], sorted_route[:split_pos], [0]])\n            route2_new = np.concatenate([[0], sorted_route[split_pos:], [0]])\n\n            new_solution[route1_idx] = route1_new\n            new_solution[route2_idx] = route2_new\n\n    for route in new_solution:\n        if len(route) > 3:\n            for _ in range(3):\n                a = random.randint(1, len(route)-2)\n                b = a + 1 if a < len(route)-2 else a - 1\n                new_route = route.copy()\n                new_route[a], new_route[b] = new_route[b], new_route[a]\n                if np.sum(demand[new_route[1:-1]]) <= capacity:\n                    route[:] = new_route\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.6963052980381321,
            0.12817811965942383
        ]
    },
    {
        "algorithm": "The algorithm combines adaptive demand-driven route decomposition with spatial-temporal harmony search, prioritizing high-demand nodes and balancing distance reduction with makespan optimization through probabilistic segment reassembly and geometric transformations while maintaining capacity constraints. It first fragments routes based on demand clusters, then reassembles them using a harmony-based approach that probabilistically selects segments to maximize geometric harmony (minimizing insertion cost) while dynamically adjusting to capacity limits, and finally applies geometric transformations for exploration. The solution emphasizes demand-aware decomposition and harmony-driven reassembly, with capacity constraints enforced throughout.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    selected_solution = max(archive, key=lambda x: x[1][1])[0].copy()\n    new_solution = [route.copy() for route in selected_solution]\n\n    # Calculate demand clusters\n    demand_threshold = 0.3 * capacity\n    high_demand_nodes = np.where(demand > demand_threshold)[0]\n\n    # Fragment routes based on demand clusters\n    fragmented_segments = []\n    for route in new_solution:\n        if len(route) <= 3:\n            fragmented_segments.append([route])\n            continue\n\n        segments = [route[:1]]\n        current_segment = [route[0]]\n        current_demand = 0\n\n        for node in route[1:-1]:\n            current_demand += demand[node]\n            current_segment.append(node)\n\n            # Split if current segment is too large or contains high-demand node\n            if (current_demand > demand_threshold or node in high_demand_nodes) and len(current_segment) > 2:\n                current_segment.append(route[0])\n                segments.append(np.array(current_segment))\n                current_segment = [route[0]]\n                current_demand = 0\n\n        if len(current_segment) > 1:\n            current_segment.append(route[0])\n            segments.append(np.array(current_segment))\n\n        fragmented_segments.append(segments)\n\n    # Flatten and shuffle segments\n    all_segments = [seg for seg_list in fragmented_segments for seg in seg_list if len(seg) > 2]\n    np.random.shuffle(all_segments)\n\n    # Reassemble using harmony search approach\n    reassembled_routes = []\n    current_route = [0]\n    current_demand = 0\n\n    for segment in all_segments:\n        segment_demand = np.sum(demand[segment[1:-1]])\n\n        # Calculate geometric harmony score\n        if len(current_route) > 1:\n            last_node = current_route[-1]\n            first_segment_node = segment[1]\n            harmony_score = 1 / (1 + distance_matrix[last_node, first_segment_node] *\n                                (1 + abs(current_demand + segment_demand - capacity/2)))\n        else:\n            harmony_score = 1.0\n\n        # Probabilistically add segment\n        if (current_demand + segment_demand <= capacity and\n            (len(current_route) == 1 or np.random.rand() < harmony_score * 0.7)):\n            current_route.extend(segment[1:-1])\n            current_demand += segment_demand\n        else:\n            if len(current_route) > 1:\n                current_route.append(0)\n                reassembled_routes.append(np.array(current_route))\n            current_route = [0] if segment[0] == 0 else [0, *segment[1:-1]]\n            current_demand = 0 if segment[0] == 0 else segment_demand\n\n    if len(current_route) > 1:\n        current_route.append(0)\n        reassembled_routes.append(np.array(current_route))\n\n    # Apply geometric transformation for exploration\n    if len(reassembled_routes) > 1 and np.random.rand() < 0.4:\n        i = np.random.randint(len(reassembled_routes))\n        if len(reassembled_routes[i]) > 3:\n            route = reassembled_routes[i]\n            # Find two points to create a geometric transformation\n            a, b = sorted(np.random.choice(len(route)-2, 2, replace=False))\n            # Create a new segment by connecting points with straight line\n            new_segment = [route[a], route[b]]\n            # Check if this creates a valid route\n            if a + 1 < b:\n                new_route = np.concatenate([route[:a+1], new_segment, route[b+1:]])\n                if np.sum(demand[new_route[1:-1]]) <= capacity:\n                    reassembled_routes[i] = new_route\n\n    return reassembled_routes\n\n",
        "score": [
            -0.8853941871874763,
            0.6955144107341766
        ]
    },
    {
        "algorithm": "The algorithm combines **spatial-temporal clustering with demand-aware route segmentation**, using **inverse distance weights** to prioritize fragmentation of longer routes, **probabilistic segment merges** for controlled reassembly, and **capacity-constrained inversions** to exploit demand similarity for local improvements. It balances exploration (route fragmentation) and exploitation (segment merging/inversion) while ensuring feasibility through strict capacity checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    selected_solution = max(archive, key=lambda x: x[1][0])[0].copy()\n    new_solution = [route.copy() for route in selected_solution]\n\n    # Calculate inverse distance weights for fragmentation\n    distance_weights = []\n    for route in new_solution:\n        if len(route) > 2:\n            route_distances = distance_matrix[route[:-1], route[1:]]\n            avg_distance = np.mean(route_distances)\n            distance_weights.append(1.0 / avg_distance if avg_distance > 0 else 0)\n        else:\n            distance_weights.append(0)\n\n    total_weight = sum(distance_weights) if sum(distance_weights) > 0 else 1\n    frag_probs = [w/total_weight for w in distance_weights]\n\n    # Fragment routes with higher inverse distance probability\n    fragmented_segments = []\n    for i, route in enumerate(new_solution):\n        if len(route) <= 3:\n            fragmented_segments.append([route])\n            continue\n\n        if np.random.rand() < frag_probs[i]:\n            # Split at highest demand node\n            demands = demand[route[1:-1]]\n            split_idx = np.argmax(demands) + 1\n            segments = [\n                route[:split_idx+1],\n                route[split_idx:]\n            ]\n        else:\n            segments = [route]\n\n        fragmented_segments.append(segments)\n\n    # Reassemble with probabilistic merges\n    all_segments = [seg for seg_list in fragmented_segments for seg in seg_list]\n    np.random.shuffle(all_segments)\n\n    reassembled_routes = []\n    current_route = [0]\n    current_demand = 0\n\n    for segment in all_segments:\n        segment_demand = np.sum(demand[segment[1:-1]])\n        if current_demand + segment_demand <= capacity and np.random.rand() < 0.7:\n            current_route.extend(segment[1:-1])\n            current_demand += segment_demand\n        else:\n            current_route.append(0)\n            reassembled_routes.append(np.array(current_route))\n            current_route = [0, *segment[1:-1]]\n            current_demand = segment_demand\n\n    if len(current_route) > 1:\n        current_route.append(0)\n        reassembled_routes.append(np.array(current_route))\n\n    # Apply capacity-constrained inversions\n    if np.random.rand() < 0.4 and len(reassembled_routes) > 1:\n        i = np.random.randint(len(reassembled_routes))\n        if len(reassembled_routes[i]) > 4:\n            route = reassembled_routes[i]\n            # Find two points with similar demands\n            demands = demand[route[1:-1]]\n            diffs = np.abs(demands[:, None] - demands[None, :])\n            a, b = np.unravel_index(np.argmin(diffs), diffs.shape)\n            a, b = sorted([a, b])\n            new_route = np.concatenate([route[:a+1], route[a+1:b+1][::-1], route[b+1:]])\n            if np.sum(demand[new_route[1:-1]]) <= capacity:\n                reassembled_routes[i] = new_route\n\n    return reassembled_routes\n\n",
        "score": [
            -0.7879906998656968,
            0.21043884754180908
        ]
    },
    {
        "algorithm": "The algorithm selects solutions from the archive with higher probability for longer routes (inverse makespan weighting), then performs a hybrid local search combining route merging, demand-balanced splitting, and adaptive swaps to improve both objectives while ensuring capacity constraints. It prioritizes longer routes for exploration and uses spatial-aware and demand-balanced transformations to generate feasible neighbors. The code highlights critical design choices like inverse makespan selection, route merging/splitting, and adaptive swaps to balance objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n    Args:\n        archive: A list of tuples, where each tuple contains:\n            - solution: A list of numpy arrays, each representing a vehicle route. \n                        Each route starts and ends at the depot (node index 0), e.g., [0, 3, 5, 0].\n            - objective: A tuple of two float values (total_distance, makespan), \n                        representing the two objective values of the solution.\n        \n        coords: A numpy array of shape (n_nodes, 2), representing (x, y) coordinates of each node (depot + customers).\n        demand: A numpy array of shape (n_nodes,), where demand[i] is the demand of node i. The depot has demand 0.\n        distance_matrix: A numpy array of shape (n_nodes, n_nodes), where [i][j] is the Euclidean distance between node i and j.\n        capacity: A float representing the maximum capacity of each vehicle.\n\n    Returns:\n        A new neighbor solution.\n    \"\"\"\n    makespans = np.array([obj[1] for _, obj in archive])\n    probabilities = 1 / (makespans + 1e-6)\n    probabilities /= probabilities.sum()\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    if len(new_solution) > 1:\n        route1_idx, route2_idx = random.sample(range(len(new_solution)), 2)\n        route1, route2 = new_solution[route1_idx], new_solution[route2_idx]\n\n        combined_route = np.concatenate([route1[1:-1], route2[1:-1]])\n        combined_demand = np.sum(demand[combined_route])\n\n        if combined_demand <= capacity:\n            new_route = np.concatenate([[0], combined_route, [0]])\n            new_solution[route1_idx] = new_route\n            del new_solution[route2_idx]\n        else:\n            sorted_indices = np.argsort(combined_route)\n            sorted_route = combined_route[sorted_indices]\n            sorted_demands = demand[sorted_route]\n            cumulative_demand = np.cumsum(sorted_demands)\n            split_pos = np.argmax(cumulative_demand <= capacity) + 1\n\n            route1_new = np.concatenate([[0], sorted_route[:split_pos], [0]])\n            route2_new = np.concatenate([[0], sorted_route[split_pos:], [0]])\n\n            new_solution[route1_idx] = route1_new\n            new_solution[route2_idx] = route2_new\n\n    for route in new_solution:\n        if len(route) > 3:\n            for _ in range(3):\n                a = random.randint(1, len(route)-2)\n                b = a + 1 if a < len(route)-2 else a - 1\n                new_route = route.copy()\n                new_route[a], new_route[b] = new_route[b], new_route[a]\n                if np.sum(demand[new_route[1:-1]]) <= capacity:\n                    route[:] = new_route\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.7413080466287215,
            0.13152247667312622
        ]
    },
    {
        "algorithm": "The algorithm combines adaptive demand clustering with spatial-aware segment swaps, prioritizing solutions with high makespan and demand variance by probabilistically transferring route segments between clusters while maintaining feasibility through capacity checks and optional spatial inversions. It balances exploration (random segment transfers) and exploitation (demand-constrained swaps) to improve both distance and makespan, with a 50% chance of spatial inversion for further optimization. The selection process weights solutions based on makespan and demand variance, ensuring diverse exploration of the solution space.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], coords: np.ndarray, demand: np.ndarray, distance_matrix: np.ndarray, capacity: float) -> np.ndarray:\n    makespans = [obj[1] for _, obj in archive]\n    demand_vars = [np.var([np.sum(demand[route[1:-1]]) for route in sol[0]]) for sol in archive]\n    weights = [makespans[i] * demand_vars[i] for i in range(len(archive))]\n    weights = [w / sum(weights) if sum(weights) > 0 else 1/len(weights) for w in weights]\n\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = [route.copy() for route in base_solution]\n\n    # Step 2: Cluster routes by spatial proximity and demand\n    clusters = []\n    for route in new_solution:\n        if len(route) <= 3:\n            clusters.append([route])\n            continue\n\n        route_coords = coords[route[1:-1]]\n        centroid = np.mean(route_coords, axis=0)\n        distances = [np.linalg.norm(coords[node] - centroid) for node in route[1:-1]]\n\n        # Split into clusters based on demand and spatial distance\n        cluster_points = [0]\n        for i in range(1, len(route)-2):\n            if distances[i] > np.mean(distances) and np.random.rand() < demand[route[i+1]]/np.sum(demand[route[1:-1]]):\n                cluster_points.append(i)\n\n        cluster_points.append(len(route)-2)\n        route_clusters = []\n        for j in range(len(cluster_points)-1):\n            start, end = cluster_points[j], cluster_points[j+1]\n            cluster = route[start:end+1]\n            route_clusters.append(cluster)\n        clusters.append(route_clusters)\n\n    # Step 3: Cross-route segment swaps with adaptive probabilistic transfers\n    all_segments = [seg for route_clusters in clusters for seg in route_clusters]\n    np.random.shuffle(all_segments)\n\n    reassembled_routes = []\n    current_route = [0]\n    current_demand = 0\n\n    for i, seg in enumerate(all_segments):\n        seg_demand = np.sum(demand[seg[1:-1]])\n        if current_demand + seg_demand <= capacity:\n            current_route.extend(seg[1:-1])\n            current_demand += seg_demand\n        else:\n            current_route.append(0)\n            reassembled_routes.append(np.array(current_route))\n            current_route = [0, *seg[1:-1]]\n            current_demand = seg_demand\n\n        # Probabilistically transfer segments between routes\n        if np.random.rand() < 0.6 and i < len(all_segments)-1:\n            next_seg = all_segments[i+1]\n            next_demand = np.sum(demand[next_seg[1:-1]])\n            if current_demand + next_demand <= capacity:\n                current_route.extend(next_seg[1:-1])\n                current_demand += next_demand\n                i += 1\n\n    if len(current_route) > 1:\n        current_route.append(0)\n        reassembled_routes.append(np.array(current_route))\n\n    # Step 4: Spatial inversion for exploration\n    if np.random.rand() < 0.5 and len(reassembled_routes) > 1:\n        i = np.random.randint(len(reassembled_routes))\n        if len(reassembled_routes[i]) > 4:\n            route = reassembled_routes[i]\n            route_coords = coords[route[1:-1]]\n            centroid = np.mean(route_coords, axis=0)\n            distances = [np.linalg.norm(coords[node] - centroid) for node in route[1:-1]]\n            split_pos = np.argmax(distances) + 1\n\n            new_route = np.concatenate([route[:split_pos+1], route[split_pos+1:][::-1], [0]])\n            if np.sum(demand[new_route[1:-1]]) <= capacity:\n                reassembled_routes[i] = new_route\n\n    # Ensure all nodes are visited\n    all_nodes = set(range(1, len(coords)))\n    visited_nodes = set()\n    for route in reassembled_routes:\n        visited_nodes.update(route[1:-1])\n    missing_nodes = all_nodes - visited_nodes\n\n    if missing_nodes:\n        for node in missing_nodes:\n            new_route = np.array([0, node, 0])\n            if demand[node] <= capacity:\n                reassembled_routes.append(new_route)\n\n    return reassembled_routes\n\n",
        "score": [
            -0.8995357040918754,
            2.078373044729233
        ]
    }
]