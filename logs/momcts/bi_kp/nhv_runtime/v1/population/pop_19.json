[
    {
        "algorithm": "The algorithm selects a random solution from the archive and applies a hybrid local search combining probabilistic flips and item swaps, prioritizing item swaps to ensure feasibility while occasionally flipping items based on their value-to-weight ratio. It iteratively refines the solution by attempting up to 10 feasible moves, breaking early if a valid swap is found, to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution from the archive\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution, _ = archive[selected_idx]\n    base_solution = selected_solution.copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: probabilistic flips and item swaps\n    for _ in range(10):  # Number of attempts to find a feasible neighbor\n        # Try probabilistic flip: randomly flip items with probability based on their value-to-weight ratio\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = random.choice(flip_candidates)\n            if random.random() < 0.5:  # 50% chance to flip\n                new_weight = current_weight - weight_lst[flip_idx]\n                if new_weight <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight = new_weight\n\n        # Try item swap: swap an item in with one out\n        out_items = np.where(new_solution == 1)[0]\n        in_items = np.where(new_solution == 0)[0]\n\n        if len(out_items) > 0 and len(in_items) > 0:\n            out_idx = random.choice(out_items)\n            in_idx = random.choice(in_items)\n\n            # Check if swap is feasible\n            new_weight = current_weight - weight_lst[out_idx] + weight_lst[in_idx]\n            if new_weight <= capacity:\n                new_solution[out_idx] = 0\n                new_solution[in_idx] = 1\n                current_weight = new_weight\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.5069312012465736,
            0.26115044951438904
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from an archive by prioritizing those with high normalized objective values, then applies a hybrid local search that evaluates flipping a random subset of items to maximize combined objective improvements while ensuring feasibility. If no improving move is found, it performs a random valid flip to maintain diversity. The selection and improvement criteria balance both objectives through a weighted sum, with weight normalization to avoid bias.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if len(archive) == 1:\n        base_solution = archive[0][0].copy()\n    else:\n        # Sort solutions by the sum of normalized objectives to prioritize promising ones\n        normalized_scores = []\n        max_v1 = max(obj[0] for _, obj in archive)\n        max_v2 = max(obj[1] for _, obj in archive)\n        for sol, obj in archive:\n            norm_v1 = obj[0] / max_v1 if max_v1 > 0 else 0\n            norm_v2 = obj[1] / max_v2 if max_v2 > 0 else 0\n            normalized_scores.append(norm_v1 + norm_v2)\n        # Select top 30% of solutions and choose randomly among them\n        threshold = np.percentile(normalized_scores, 70)\n        candidates = [sol for (sol, _), score in zip(archive, normalized_scores) if score >= threshold]\n        base_solution = random.choice(candidates).copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to potentially swap\n    # 2. Evaluate potential improvements in both objectives\n    # 3. Apply a greedy selection based on the combined objective improvement\n\n    # Step 1: Random subset selection\n    subset_size = max(1, int(len(new_solution) * 0.2))  # 20% of items\n    subset_indices = np.random.choice(len(new_solution), size=subset_size, replace=False)\n\n    # Step 2: Evaluate potential improvements\n    best_improvement = 0\n    best_candidate = None\n\n    for idx in subset_indices:\n        # Try flipping the item\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n\n        # Calculate new weight\n        new_weight = current_weight\n        if temp_solution[idx] == 1:\n            new_weight += weight_lst[idx]\n        else:\n            new_weight -= weight_lst[idx]\n\n        # Check feasibility\n        if new_weight > capacity:\n            continue\n\n        # Calculate objective improvements\n        delta_v1 = value1_lst[idx] if temp_solution[idx] == 1 else -value1_lst[idx]\n        delta_v2 = value2_lst[idx] if temp_solution[idx] == 1 else -value2_lst[idx]\n\n        # Use a weighted sum of improvements as the selection criterion\n        improvement = (delta_v1 + delta_v2) / (weight_lst[idx] + 1e-6)  # Avoid division by zero\n\n        if improvement > best_improvement:\n            best_improvement = improvement\n            best_candidate = temp_solution\n\n    # Step 3: Apply the best candidate if found\n    if best_candidate is not None:\n        new_solution = best_candidate\n    else:\n        # If no improvement found, perform a random valid flip\n        valid_indices = [i for i in range(len(new_solution)) if\n                        (new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                        (new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if valid_indices:\n            idx = random.choice(valid_indices)\n            new_solution[idx] = 1 - new_solution[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.954731742570925,
            0.796350508928299
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Step 1: Adaptive selection - prioritize solutions with high crowding distance and normalized objective diversity\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.zeros(len(archive))\n    for obj_idx in range(2):\n        sorted_indices = np.argsort(objectives[:, obj_idx])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for i in range(1, len(archive) - 1):\n            if objectives[sorted_indices[-1], obj_idx] == objectives[sorted_indices[0], obj_idx]:\n                crowding_distances[sorted_indices[i]] = np.inf\n            else:\n                crowding_distances[sorted_indices[i]] += (objectives[sorted_indices[i+1], obj_idx] - objectives[sorted_indices[i-1], obj_idx]) / (objectives[sorted_indices[-1], obj_idx] - objectives[sorted_indices[0], obj_idx])\n\n    # Combine crowding distance with normalized objective diversity\n    max_v1, max_v2 = np.max(objectives, axis=0)\n    normalized_diversity = np.zeros(len(archive))\n    for i, (v1, v2) in enumerate(objectives):\n        normalized_diversity[i] = (v1 / max_v1 + v2 / max_v2) if max_v1 > 0 and max_v2 > 0 else 0\n\n    selection_scores = crowding_distances * normalized_diversity\n    selected_idx = np.argmax(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Step 2: Hybrid local search - adaptive subset flips with objective-weighted improvements\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Dynamic neighborhood size based on solution quality\n    neighborhood_size = min(5, max(1, int(n_items * 0.1 * (1 - current_weight / capacity))))\n\n    # Strategy 1: Adaptive subset flip with objective-weighted selection\n    for _ in range(neighborhood_size):\n        # Select a random subset of items to consider\n        subset_size = min(3, max(1, int(n_items * 0.2)))\n        subset_indices = np.random.choice(n_items, size=subset_size, replace=False)\n\n        best_improvement = 0\n        best_candidate = None\n\n        for idx in subset_indices:\n            # Try flipping the item\n            temp_solution = new_solution.copy()\n            temp_solution[idx] = 1 - temp_solution[idx]\n\n            # Calculate new weight\n            new_weight = current_weight\n            if temp_solution[idx] == 1:\n                new_weight += weight_lst[idx]\n            else:\n                new_weight -= weight_lst[idx]\n\n            # Check feasibility\n            if new_weight > capacity:\n                continue\n\n            # Calculate objective improvements\n            delta_v1 = value1_lst[idx] if temp_solution[idx] == 1 else -value1_lst[idx]\n            delta_v2 = value2_lst[idx] if temp_solution[idx] == 1 else -value2_lst[idx]\n\n            # Objective-weighted improvement\n            improvement = (delta_v1 + delta_v2) / (weight_lst[idx] + 1e-6)\n\n            if improvement > best_improvement:\n                best_improvement = improvement\n                best_candidate = temp_solution\n\n        if best_candidate is not None:\n            new_solution = best_candidate\n            current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Strategy 2: Objective-weighted item swaps if no improvement found\n    if best_improvement == 0:\n        for _ in range(neighborhood_size):\n            out_items = np.where(new_solution == 1)[0]\n            in_items = np.where(new_solution == 0)[0]\n\n            if len(out_items) > 0 and len(in_items) > 0:\n                out_idx = np.random.choice(out_items)\n                in_idx = np.random.choice(in_items)\n\n                new_weight = current_weight - weight_lst[out_idx] + weight_lst[in_idx]\n                if new_weight <= capacity:\n                    # Objective-weighted swap decision\n                    delta_v1 = value1_lst[in_idx] - value1_lst[out_idx]\n                    delta_v2 = value2_lst[in_idx] - value2_lst[out_idx]\n                    if (delta_v1 + delta_v2) > 0:\n                        new_solution[out_idx] = 0\n                        new_solution[in_idx] = 1\n                        current_weight = new_weight\n                        break\n\n    return new_solution\n\n",
        "score": [
            -0.9603317168957264,
            1.4646897912025452
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using Pareto-ranked crowding-distance metrics, then applies a hybrid local search combining adaptive subset flips and objective-weighted swaps to generate a neighbor solution while dynamically adjusting the neighborhood size based on solution quality and feasibility. It prioritizes high-crowding-distance solutions for exploration and uses objective-weighted improvements to guide flips, falling back to strategic swaps when no flips yield improvements. The neighborhood size adapts to the current solution's weight relative to capacity, balancing exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Step 1: Pareto-ranked selection with crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.zeros(len(archive))\n    for obj_idx in range(2):\n        sorted_indices = np.argsort(objectives[:, obj_idx])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for i in range(1, len(archive) - 1):\n            if objectives[sorted_indices[-1], obj_idx] == objectives[sorted_indices[0], obj_idx]:\n                crowding_distances[sorted_indices[i]] = np.inf\n            else:\n                crowding_distances[sorted_indices[i]] += (objectives[sorted_indices[i+1], obj_idx] - objectives[sorted_indices[i-1], obj_idx]) / (objectives[sorted_indices[-1], obj_idx] - objectives[sorted_indices[0], obj_idx])\n\n    # Combine with Pareto rank (higher rank = more promising)\n    pareto_rank = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        dominated = False\n        for j, (_, other_obj) in enumerate(archive):\n            if i != j and other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_rank[i] = 1  # Non-dominated (frontier)\n\n    # Select by weighted crowding distance and Pareto rank\n    selection_scores = crowding_distances * pareto_rank\n    selected_idx = np.argmax(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Step 2: Hybrid local search with adaptive operators\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Dynamic neighborhood size (larger for low-crowding solutions)\n    neighborhood_size = min(5, max(1, int(n_items * 0.1 * (1 - current_weight / capacity))))\n\n    # Strategy 1: Adaptive subset flips with objective-weighted selection\n    for _ in range(neighborhood_size):\n        subset_size = min(5, max(1, int(n_items * 0.3)))\n        subset_indices = np.random.choice(n_items, size=subset_size, replace=False)\n\n        best_improvement = 0\n        best_candidate = None\n\n        for idx in subset_indices:\n            temp_solution = new_solution.copy()\n            temp_solution[idx] = 1 - temp_solution[idx]\n\n            new_weight = current_weight\n            if temp_solution[idx] == 1:\n                new_weight += weight_lst[idx]\n            else:\n                new_weight -= weight_lst[idx]\n\n            if new_weight > capacity:\n                continue\n\n            delta_v1 = value1_lst[idx] if temp_solution[idx] == 1 else -value1_lst[idx]\n            delta_v2 = value2_lst[idx] if temp_solution[idx] == 1 else -value2_lst[idx]\n\n            # Objective-weighted improvement (normalized by weight)\n            improvement = (delta_v1 + delta_v2) / (weight_lst[idx] + 1e-6)\n\n            if improvement > best_improvement:\n                best_improvement = improvement\n                best_candidate = temp_solution\n\n        if best_candidate is not None:\n            new_solution = best_candidate\n            current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Strategy 2: Objective-weighted swaps if no improvement\n    if best_improvement == 0:\n        for _ in range(neighborhood_size):\n            out_items = np.where(new_solution == 1)[0]\n            in_items = np.where(new_solution == 0)[0]\n\n            if len(out_items) > 0 and len(in_items) > 0:\n                out_idx = np.random.choice(out_items)\n                in_idx = np.random.choice(in_items)\n\n                new_weight = current_weight - weight_lst[out_idx] + weight_lst[in_idx]\n                if new_weight <= capacity:\n                    # Objective-weighted swap decision\n                    delta_v1 = value1_lst[in_idx] - value1_lst[out_idx]\n                    delta_v2 = value2_lst[in_idx] - value2_lst[out_idx]\n                    if (delta_v1 + delta_v2) > 0:\n                        new_solution[out_idx] = 0\n                        new_solution[in_idx] = 1\n                        current_weight = new_weight\n                        break\n\n    return new_solution\n\n",
        "score": [
            -0.769524318436092,
            0.6605959534645081
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with high normalized objective values and low dominance counts, then applies a hybrid local search that dynamically adjusts weights based on objective ratios and item diversity, exploring neighborhoods through weighted improvements and adaptive swaps while ensuring feasibility through capacity checks. The method balances greedy improvements with diversification by considering both individual item flips and strategic swaps, using diversity-aware weights to guide the search toward high-quality, non-dominated solutions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if len(archive) == 1:\n        base_solution = archive[0][0].copy()\n    else:\n        # Select solution with highest sum of normalized objectives and lowest dominance count\n        normalized_scores = []\n        dominance_counts = []\n        max_v1 = max(obj[0] for _, obj in archive)\n        max_v2 = max(obj[1] for _, obj in archive)\n\n        for sol, obj in archive:\n            norm_v1 = obj[0] / max_v1 if max_v1 > 0 else 0\n            norm_v2 = obj[1] / max_v2 if max_v2 > 0 else 0\n            normalized_scores.append(norm_v1 + norm_v2)\n\n            # Calculate dominance count (number of solutions that dominate this one)\n            dominance = 0\n            for _, other_obj in archive:\n                if (other_obj[0] >= obj[0] and other_obj[1] > obj[1]) or (other_obj[0] > obj[0] and other_obj[1] >= obj[1]):\n                    dominance += 1\n            dominance_counts.append(dominance)\n\n        # Select top 20% of solutions with lowest dominance counts\n        sorted_indices = sorted(range(len(normalized_scores)), key=lambda i: (-normalized_scores[i], dominance_counts[i]))\n        candidate_indices = sorted_indices[:max(1, int(0.2 * len(archive)))]\n        selected_idx = random.choice(candidate_indices)\n        base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Dynamic weight adjustment based on objective ratios and solution diversity\n    total_v1 = np.sum(value1_lst[new_solution == 1])\n    total_v2 = np.sum(value2_lst[new_solution == 1])\n    ratio_v1 = total_v1 / (total_v2 + 1e-6) if total_v2 > 0 else 1.0\n    ratio_v2 = total_v2 / (total_v1 + 1e-6) if total_v1 > 0 else 1.0\n\n    # Calculate diversity-aware weights\n    item_diversity = np.zeros(len(new_solution))\n    for i in range(len(new_solution)):\n        inclusion_rate = sum(sol[i] for sol, _ in archive) / len(archive)\n        item_diversity[i] = 1 - inclusion_rate\n\n    weight_v1 = ratio_v2 * (1 + item_diversity)\n    weight_v2 = ratio_v1 * (1 + item_diversity)\n\n    # Hybrid neighborhood exploration\n    subset_size = max(1, int(len(new_solution) * 0.4))  # 40% of items\n    subset_indices = np.random.choice(len(new_solution), size=subset_size, replace=False)\n\n    best_improvement = -float('inf')\n    best_candidate = None\n\n    for idx in subset_indices:\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n\n        new_weight = current_weight\n        if temp_solution[idx] == 1:\n            new_weight += weight_lst[idx]\n        else:\n            new_weight -= weight_lst[idx]\n\n        if new_weight > capacity:\n            continue\n\n        delta_v1 = value1_lst[idx] if temp_solution[idx] == 1 else -value1_lst[idx]\n        delta_v2 = value2_lst[idx] if temp_solution[idx] == 1 else -value2_lst[idx]\n\n        # Weighted improvement with diversity bonus\n        improvement = (weight_v1[idx] * delta_v1 + weight_v2[idx] * delta_v2) * (1 + 0.5 * item_diversity[idx])\n\n        if improvement > best_improvement:\n            best_improvement = improvement\n            best_candidate = temp_solution\n\n    if best_candidate is not None:\n        new_solution = best_candidate\n    else:\n        # Adaptive swap operation for diversification\n        valid_pairs = []\n        for i in range(len(new_solution)):\n            if new_solution[i] == 1:\n                for j in range(len(new_solution)):\n                    if new_solution[j] == 0 and weight_lst[j] <= weight_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                        valid_pairs.append((i, j))\n\n        if valid_pairs:\n            # Select pair with highest combined weighted improvement\n            best_pair = None\n            best_pair_improvement = -float('inf')\n\n            for i, j in valid_pairs:\n                delta_v1 = value1_lst[j] - value1_lst[i]\n                delta_v2 = value2_lst[j] - value2_lst[i]\n                improvement = weight_v1[j] * delta_v1 + weight_v2[j] * delta_v2\n\n                if improvement > best_pair_improvement:\n                    best_pair_improvement = improvement\n                    best_pair = (i, j)\n\n            if best_pair:\n                i, j = best_pair\n                new_solution[i] = 0\n                new_solution[j] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.9089630759814984,
            3.7565543055534363
        ]
    },
    {
        "algorithm": "The algorithm selects the most promising solution from the archive (based on average value-to-weight density) and applies a hybrid local search strategy that prioritizes swapping low-value items for high-value ones while ensuring feasibility through adaptive perturbations. If no swaps are feasible, it randomly removes items to free up capacity. The approach balances exploration (via adaptive swaps) and exploitation (via value-to-weight ratios) to improve both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution from the archive\n    # Calculate the density (value/weight) for each objective\n    densities = []\n    for sol, (v1, v2) in archive:\n        included = sol == 1\n        total_weight = np.sum(weight_lst[included])\n        if total_weight == 0:\n            density1 = density2 = 0\n        else:\n            density1 = np.sum(value1_lst[included]) / total_weight\n            density2 = np.sum(value2_lst[included]) / total_weight\n        densities.append((density1 + density2) / 2)  # Average density\n\n    # Select the solution with the highest density (most promising for improvement)\n    best_idx = np.argmax(densities)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Apply novel local search operator\n    # Hybrid strategy: adaptive item swaps and perturbations\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Adaptive swap: replace a low-value item with a high-value item\n        # Calculate value-to-weight ratio for included items\n        included_ratios = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n        worst_included = included_items[np.argmin(included_ratios)]\n\n        # Calculate value-to-weight ratio for excluded items\n        excluded_ratios = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n        best_excluded = excluded_items[np.argmax(excluded_ratios)]\n\n        # Check if swap is feasible\n        current_weight = np.sum(weight_lst[new_solution == 1])\n        swap_weight_diff = weight_lst[best_excluded] - weight_lst[worst_included]\n\n        if current_weight + swap_weight_diff <= capacity:\n            new_solution[worst_included] = 0\n            new_solution[best_excluded] = 1\n        else:\n            # If swap is not feasible, perform a perturbation\n            # Randomly flip a small number of items to find a feasible solution\n            max_perturbations = min(3, len(included_items))\n            for _ in range(max_perturbations):\n                candidate = random.choice(included_items)\n                if current_weight - weight_lst[candidate] <= capacity:\n                    new_solution[candidate] = 0\n                    current_weight -= weight_lst[candidate]\n                    break\n\n    # If no items are included, add the best item if possible\n    elif len(included_items) == 0 and len(excluded_items) > 0:\n        # Add the item with the highest value-to-weight ratio\n        excluded_ratios = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n        best_excluded = excluded_items[np.argmax(excluded_ratios)]\n\n        if weight_lst[best_excluded] <= capacity:\n            new_solution[best_excluded] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.41552698679575917,
            0.3817824423313141
        ]
    },
    {
        "algorithm": "The algorithm intelligently selects a solution from the archive by prioritizing those with high objective diversity (via crowding distance) and applies a hybrid local search combining item swaps and subset replacements to generate a feasible neighbor solution while ensuring weight constraints are not violated. It first evaluates solutions based on their crowding distances to identify promising candidates, then performs targeted swaps and subset operations to explore the neighborhood while maintaining feasibility. The algorithm balances exploration and exploitation by focusing on high-diversity regions of the Pareto front while dynamically adjusting the search based on the current solution's characteristics.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution (high objective diversity and low crowding distance)\n    # Calculate crowding distances for solutions in the archive\n    objectives = np.array([obj for _, obj in archive])\n    sorted_indices = np.argsort(objectives[:, 0])\n    objectives_sorted = objectives[sorted_indices]\n\n    # Compute crowding distances\n    crowding_distances = np.zeros(len(archive))\n    for obj_idx in range(2):\n        sorted_indices = np.argsort(objectives[:, obj_idx])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for i in range(1, len(archive) - 1):\n            if objectives[sorted_indices[-1], obj_idx] == objectives[sorted_indices[0], obj_idx]:\n                crowding_distances[sorted_indices[i]] = np.inf\n            else:\n                crowding_distances[sorted_indices[i]] += (objectives[sorted_indices[i+1], obj_idx] - objectives[sorted_indices[i-1], obj_idx]) / (objectives[sorted_indices[-1], obj_idx] - objectives[sorted_indices[0], obj_idx])\n\n    # Select the solution with the highest crowding distance (most promising for improvement)\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Step 2: Generate a neighbor solution using hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Strategy 1: Randomly swap items if feasible\n    for _ in range(min(5, n_items // 2)):\n        i, j = np.random.choice(n_items, 2, replace=False)\n        if new_solution[i] != new_solution[j]:\n            if new_solution[i] == 1 and new_solution[j] == 0:\n                new_weight = current_weight + weight_lst[j] - weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                    current_weight = new_weight\n            elif new_solution[i] == 0 and new_solution[j] == 1:\n                new_weight = current_weight + weight_lst[i] - weight_lst[j]\n                if new_weight <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                    current_weight = new_weight\n\n    # Strategy 2: Replace a subset of items with new ones if feasible\n    subset_size = min(3, n_items // 4)\n    if subset_size > 0:\n        # Remove a subset of items\n        remove_indices = np.where(new_solution == 1)[0]\n        if len(remove_indices) > 0:\n            remove_subset = np.random.choice(remove_indices, size=min(subset_size, len(remove_indices)), replace=False)\n            new_solution[remove_subset] = 0\n            current_weight -= np.sum(weight_lst[remove_subset])\n\n        # Add a subset of new items\n        add_indices = np.where(new_solution == 0)[0]\n        if len(add_indices) > 0:\n            add_subset = np.random.choice(add_indices, size=min(subset_size, len(add_indices)), replace=False)\n            potential_weight = current_weight + np.sum(weight_lst[add_subset])\n            if potential_weight <= capacity:\n                new_solution[add_subset] = 1\n                current_weight = potential_weight\n\n    return new_solution\n\n",
        "score": [
            -0.7196288894938169,
            0.7204856276512146
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with high normalized objective values, then applies a hybrid local search that dynamically adjusts weights based on the solution's dominance and evaluates flipping a random subset of items to maximize a weighted sum of both objectives, falling back to probabilistic flips if no improvement is found. It ensures feasibility by checking weight constraints and dynamically balances exploration/exploitation through weighted contributions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if len(archive) == 1:\n        base_solution = archive[0][0].copy()\n    else:\n        # Sort solutions by the sum of normalized objectives to prioritize promising ones\n        normalized_scores = []\n        max_v1 = max(obj[0] for _, obj in archive)\n        max_v2 = max(obj[1] for _, obj in archive)\n        for sol, obj in archive:\n            norm_v1 = obj[0] / max_v1 if max_v1 > 0 else 0\n            norm_v2 = obj[1] / max_v2 if max_v2 > 0 else 0\n            normalized_scores.append(norm_v1 + norm_v2)\n        # Select top 30% of solutions and choose randomly among them\n        threshold = np.percentile(normalized_scores, 70)\n        candidates = [sol for (sol, _), score in zip(archive, normalized_scores) if score >= threshold]\n        base_solution = random.choice(candidates).copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Dynamic weight adjustment based on current solution's dominance\n    total_v1 = np.sum(value1_lst[new_solution == 1])\n    total_v2 = np.sum(value2_lst[new_solution == 1])\n    weight_v1 = total_v2 / (total_v1 + total_v2 + 1e-6) if (total_v1 + total_v2) > 0 else 0.5\n    weight_v2 = total_v1 / (total_v1 + total_v2 + 1e-6) if (total_v1 + total_v2) > 0 else 0.5\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to potentially swap\n    # 2. Evaluate potential improvements in both objectives with dynamic weights\n    # 3. Apply a greedy selection based on the weighted combined objective improvement\n\n    subset_size = max(1, int(len(new_solution) * 0.3))  # 30% of items\n    subset_indices = np.random.choice(len(new_solution), size=subset_size, replace=False)\n\n    best_improvement = -float('inf')\n    best_candidate = None\n\n    for idx in subset_indices:\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n\n        new_weight = current_weight\n        if temp_solution[idx] == 1:\n            new_weight += weight_lst[idx]\n        else:\n            new_weight -= weight_lst[idx]\n\n        if new_weight > capacity:\n            continue\n\n        delta_v1 = value1_lst[idx] if temp_solution[idx] == 1 else -value1_lst[idx]\n        delta_v2 = value2_lst[idx] if temp_solution[idx] == 1 else -value2_lst[idx]\n\n        improvement = weight_v1 * delta_v1 + weight_v2 * delta_v2\n\n        if improvement > best_improvement:\n            best_improvement = improvement\n            best_candidate = temp_solution\n\n    if best_candidate is not None:\n        new_solution = best_candidate\n    else:\n        # Probabilistic flip based on potential contribution\n        valid_indices = [i for i in range(len(new_solution)) if\n                        (new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                        (new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if valid_indices:\n            # Calculate potential contributions\n            contributions = []\n            for i in valid_indices:\n                potential_v1 = value1_lst[i] if new_solution[i] == 0 else -value1_lst[i]\n                potential_v2 = value2_lst[i] if new_solution[i] == 0 else -value2_lst[i]\n                contribution = weight_v1 * potential_v1 + weight_v2 * potential_v2\n                contributions.append(contribution)\n            # Select with probability proportional to contribution\n            if sum(contributions) > 0:\n                probabilities = [c / sum(contributions) for c in contributions]\n                idx = np.random.choice(valid_indices, p=probabilities)\n            else:\n                idx = random.choice(valid_indices)\n            new_solution[idx] = 1 - new_solution[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9062541463556129,
            1.3094992935657501
        ]
    },
    {
        "algorithm": "This algorithm selects a promising solution from the archive by prioritizing those with high value ratios (value1/value2), then applies a weighted local search where items are flipped based on their potential to improve a dynamically adjusted weighted combination of the two objectives. If no immediate improvement is found, it probabilistically flips items based on their potential contribution, ensuring feasibility by checking weight constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if len(archive) == 1:\n        base_solution = archive[0][0].copy()\n    else:\n        # Sort solutions by the ratio of objectives to prioritize diverse solutions\n        ratios = []\n        for _, obj in archive:\n            ratio = obj[0] / (obj[1] + 1e-6) if obj[1] > 0 else float('inf')\n            ratios.append(ratio)\n        # Select top 20% of solutions and choose randomly among them\n        threshold = np.percentile(ratios, 80)\n        candidates = [sol for (sol, _), r in zip(archive, ratios) if r >= threshold]\n        base_solution = random.choice(candidates).copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Dynamic weight adjustment based on current solution's ratio\n    total_v1 = np.sum(value1_lst[new_solution == 1])\n    total_v2 = np.sum(value2_lst[new_solution == 1])\n    ratio = total_v1 / (total_v2 + 1e-6) if total_v2 > 0 else float('inf')\n    weight_v1 = 0.7 if ratio > 1 else 0.3\n    weight_v2 = 1 - weight_v1\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to potentially flip\n    # 2. Evaluate potential improvements with dynamic weights\n    # 3. Apply a greedy selection based on the weighted combined objective improvement\n\n    subset_size = max(1, int(len(new_solution) * 0.2))  # 20% of items\n    subset_indices = np.random.choice(len(new_solution), size=subset_size, replace=False)\n\n    best_improvement = -float('inf')\n    best_candidate = None\n\n    for idx in subset_indices:\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n\n        new_weight = current_weight\n        if temp_solution[idx] == 1:\n            new_weight += weight_lst[idx]\n        else:\n            new_weight -= weight_lst[idx]\n\n        if new_weight > capacity:\n            continue\n\n        delta_v1 = value1_lst[idx] if temp_solution[idx] == 1 else -value1_lst[idx]\n        delta_v2 = value2_lst[idx] if temp_solution[idx] == 1 else -value2_lst[idx]\n\n        improvement = weight_v1 * delta_v1 + weight_v2 * delta_v2\n\n        if improvement > best_improvement:\n            best_improvement = improvement\n            best_candidate = temp_solution\n\n    if best_candidate is not None:\n        new_solution = best_candidate\n    else:\n        # Probabilistic flip based on potential contribution\n        valid_indices = [i for i in range(len(new_solution)) if\n                        (new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                        (new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if valid_indices:\n            # Calculate potential contributions with adjusted weights\n            contributions = []\n            for i in valid_indices:\n                potential_v1 = value1_lst[i] if new_solution[i] == 0 else -value1_lst[i]\n                potential_v2 = value2_lst[i] if new_solution[i] == 0 else -value2_lst[idx]\n                contribution = weight_v1 * potential_v1 + weight_v2 * potential_v2\n                contributions.append(contribution)\n            # Select with probability proportional to contribution\n            if sum(contributions) > 0:\n                probabilities = [c / sum(contributions) for c in contributions]\n                idx = np.random.choice(valid_indices, p=probabilities)\n            else:\n                idx = random.choice(valid_indices)\n            new_solution[idx] = 1 - new_solution[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.850898917536525,
            0.9733171164989471
        ]
    },
    {
        "algorithm": "The algorithm selects a non-dominated solution from the archive using a Pareto-ranked crowding-distance metric, then applies an adaptive hybrid local search that combines subset flips and objective-weighted swaps to explore high-quality neighbors while ensuring feasibility. It prioritizes items with higher combined value-to-weight ratios and dynamically adjusts neighborhood size based on solution quality and capacity utilization. The search alternates between flipping subsets of items and performing targeted swaps when no improvements are found in the first phase.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution with high Pareto-ranked crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.zeros(len(archive))\n    for obj_idx in range(2):\n        sorted_indices = np.argsort(objectives[:, obj_idx])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for i in range(1, len(archive) - 1):\n            if objectives[sorted_indices[-1], obj_idx] == objectives[sorted_indices[0], obj_idx]:\n                crowding_distances[sorted_indices[i]] = np.inf\n            else:\n                crowding_distances[sorted_indices[i]] += (objectives[sorted_indices[i+1], obj_idx] - objectives[sorted_indices[i-1], obj_idx]) / (objectives[sorted_indices[-1], obj_idx] - objectives[sorted_indices[0], obj_idx])\n\n    # Combine crowding distance with Pareto ranking\n    pareto_rank = np.zeros(len(archive))\n    for i in range(len(archive)):\n        dominated = False\n        for j in range(len(archive)):\n            if i != j and objectives[j, 0] >= objectives[i, 0] and objectives[j, 1] >= objectives[i, 1] and (objectives[j, 0] > objectives[i, 0] or objectives[j, 1] > objectives[i, 1]):\n                dominated = True\n                break\n        pareto_rank[i] = 0 if dominated else 1\n\n    selection_scores = crowding_distances * pareto_rank\n    selected_idx = np.argmax(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Step 2: Adaptive hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Dynamic neighborhood size based on solution quality\n    neighborhood_size = min(5, max(1, int(n_items * 0.1 * (1 - current_weight / capacity))))\n\n    # Strategy 1: Adaptive subset flip with objective-weighted selection\n    for _ in range(neighborhood_size):\n        subset_size = min(3, max(1, int(n_items * 0.2)))\n        subset_indices = np.random.choice(n_items, size=subset_size, replace=False)\n\n        best_improvement = 0\n        best_candidate = None\n\n        for idx in subset_indices:\n            temp_solution = new_solution.copy()\n            temp_solution[idx] = 1 - temp_solution[idx]\n\n            new_weight = current_weight\n            if temp_solution[idx] == 1:\n                new_weight += weight_lst[idx]\n            else:\n                new_weight -= weight_lst[idx]\n\n            if new_weight > capacity:\n                continue\n\n            delta_v1 = value1_lst[idx] if temp_solution[idx] == 1 else -value1_lst[idx]\n            delta_v2 = value2_lst[idx] if temp_solution[idx] == 1 else -value2_lst[idx]\n\n            improvement = (delta_v1 + delta_v2) / (weight_lst[idx] + 1e-6)\n\n            if improvement > best_improvement:\n                best_improvement = improvement\n                best_candidate = temp_solution\n\n        if best_candidate is not None:\n            new_solution = best_candidate\n            current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Strategy 2: Objective-weighted item swaps if no improvement found\n    if best_improvement == 0:\n        for _ in range(neighborhood_size):\n            out_items = np.where(new_solution == 1)[0]\n            in_items = np.where(new_solution == 0)[0]\n\n            if len(out_items) > 0 and len(in_items) > 0:\n                out_idx = np.random.choice(out_items)\n                in_idx = np.random.choice(in_items)\n\n                new_weight = current_weight - weight_lst[out_idx] + weight_lst[in_idx]\n                if new_weight <= capacity:\n                    delta_v1 = value1_lst[in_idx] - value1_lst[out_idx]\n                    delta_v2 = value2_lst[in_idx] - value2_lst[out_idx]\n                    if (delta_v1 + delta_v2) > 0:\n                        new_solution[out_idx] = 0\n                        new_solution[in_idx] = 1\n                        current_weight = new_weight\n                        break\n\n    return new_solution\n\n",
        "score": [
            -0.759328923213639,
            0.8390093743801117
        ]
    }
]