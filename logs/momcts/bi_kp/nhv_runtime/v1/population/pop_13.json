[
    {
        "algorithm": "The algorithm intelligently selects a solution from the archive by prioritizing those with high objective diversity (via crowding distance) and applies a hybrid local search combining item swaps and subset replacements to generate a feasible neighbor solution while ensuring weight constraints are not violated. It first evaluates solutions based on their crowding distances to identify promising candidates, then performs targeted swaps and subset operations to explore the neighborhood while maintaining feasibility. The algorithm balances exploration and exploitation by focusing on high-diversity regions of the Pareto front while dynamically adjusting the search based on the current solution's characteristics.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution (high objective diversity and low crowding distance)\n    # Calculate crowding distances for solutions in the archive\n    objectives = np.array([obj for _, obj in archive])\n    sorted_indices = np.argsort(objectives[:, 0])\n    objectives_sorted = objectives[sorted_indices]\n\n    # Compute crowding distances\n    crowding_distances = np.zeros(len(archive))\n    for obj_idx in range(2):\n        sorted_indices = np.argsort(objectives[:, obj_idx])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for i in range(1, len(archive) - 1):\n            if objectives[sorted_indices[-1], obj_idx] == objectives[sorted_indices[0], obj_idx]:\n                crowding_distances[sorted_indices[i]] = np.inf\n            else:\n                crowding_distances[sorted_indices[i]] += (objectives[sorted_indices[i+1], obj_idx] - objectives[sorted_indices[i-1], obj_idx]) / (objectives[sorted_indices[-1], obj_idx] - objectives[sorted_indices[0], obj_idx])\n\n    # Select the solution with the highest crowding distance (most promising for improvement)\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Step 2: Generate a neighbor solution using hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Strategy 1: Randomly swap items if feasible\n    for _ in range(min(5, n_items // 2)):\n        i, j = np.random.choice(n_items, 2, replace=False)\n        if new_solution[i] != new_solution[j]:\n            if new_solution[i] == 1 and new_solution[j] == 0:\n                new_weight = current_weight + weight_lst[j] - weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                    current_weight = new_weight\n            elif new_solution[i] == 0 and new_solution[j] == 1:\n                new_weight = current_weight + weight_lst[i] - weight_lst[j]\n                if new_weight <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                    current_weight = new_weight\n\n    # Strategy 2: Replace a subset of items with new ones if feasible\n    subset_size = min(3, n_items // 4)\n    if subset_size > 0:\n        # Remove a subset of items\n        remove_indices = np.where(new_solution == 1)[0]\n        if len(remove_indices) > 0:\n            remove_subset = np.random.choice(remove_indices, size=min(subset_size, len(remove_indices)), replace=False)\n            new_solution[remove_subset] = 0\n            current_weight -= np.sum(weight_lst[remove_subset])\n\n        # Add a subset of new items\n        add_indices = np.where(new_solution == 0)[0]\n        if len(add_indices) > 0:\n            add_subset = np.random.choice(add_indices, size=min(subset_size, len(add_indices)), replace=False)\n            potential_weight = current_weight + np.sum(weight_lst[add_subset])\n            if potential_weight <= capacity:\n                new_solution[add_subset] = 1\n                current_weight = potential_weight\n\n    return new_solution\n\n",
        "score": [
            -0.7196288894938169,
            0.7204856276512146
        ]
    },
    {
        "algorithm": "The algorithm selects a random solution from the archive and applies a hybrid local search combining probabilistic flips and item swaps, prioritizing item swaps to ensure feasibility while occasionally flipping items based on their value-to-weight ratio. It iteratively refines the solution by attempting up to 10 feasible moves, breaking early if a valid swap is found, to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution from the archive\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution, _ = archive[selected_idx]\n    base_solution = selected_solution.copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: probabilistic flips and item swaps\n    for _ in range(10):  # Number of attempts to find a feasible neighbor\n        # Try probabilistic flip: randomly flip items with probability based on their value-to-weight ratio\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = random.choice(flip_candidates)\n            if random.random() < 0.5:  # 50% chance to flip\n                new_weight = current_weight - weight_lst[flip_idx]\n                if new_weight <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight = new_weight\n\n        # Try item swap: swap an item in with one out\n        out_items = np.where(new_solution == 1)[0]\n        in_items = np.where(new_solution == 0)[0]\n\n        if len(out_items) > 0 and len(in_items) > 0:\n            out_idx = random.choice(out_items)\n            in_idx = random.choice(in_items)\n\n            # Check if swap is feasible\n            new_weight = current_weight - weight_lst[out_idx] + weight_lst[in_idx]\n            if new_weight <= capacity:\n                new_solution[out_idx] = 0\n                new_solution[in_idx] = 1\n                current_weight = new_weight\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.5069312012465736,
            0.26115044951438904
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from an archive by prioritizing those with high normalized objective values, then applies a hybrid local search that evaluates flipping a random subset of items to maximize combined objective improvements while ensuring feasibility. If no improving move is found, it performs a random valid flip to maintain diversity. The selection and improvement criteria balance both objectives through a weighted sum, with weight normalization to avoid bias.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if len(archive) == 1:\n        base_solution = archive[0][0].copy()\n    else:\n        # Sort solutions by the sum of normalized objectives to prioritize promising ones\n        normalized_scores = []\n        max_v1 = max(obj[0] for _, obj in archive)\n        max_v2 = max(obj[1] for _, obj in archive)\n        for sol, obj in archive:\n            norm_v1 = obj[0] / max_v1 if max_v1 > 0 else 0\n            norm_v2 = obj[1] / max_v2 if max_v2 > 0 else 0\n            normalized_scores.append(norm_v1 + norm_v2)\n        # Select top 30% of solutions and choose randomly among them\n        threshold = np.percentile(normalized_scores, 70)\n        candidates = [sol for (sol, _), score in zip(archive, normalized_scores) if score >= threshold]\n        base_solution = random.choice(candidates).copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to potentially swap\n    # 2. Evaluate potential improvements in both objectives\n    # 3. Apply a greedy selection based on the combined objective improvement\n\n    # Step 1: Random subset selection\n    subset_size = max(1, int(len(new_solution) * 0.2))  # 20% of items\n    subset_indices = np.random.choice(len(new_solution), size=subset_size, replace=False)\n\n    # Step 2: Evaluate potential improvements\n    best_improvement = 0\n    best_candidate = None\n\n    for idx in subset_indices:\n        # Try flipping the item\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n\n        # Calculate new weight\n        new_weight = current_weight\n        if temp_solution[idx] == 1:\n            new_weight += weight_lst[idx]\n        else:\n            new_weight -= weight_lst[idx]\n\n        # Check feasibility\n        if new_weight > capacity:\n            continue\n\n        # Calculate objective improvements\n        delta_v1 = value1_lst[idx] if temp_solution[idx] == 1 else -value1_lst[idx]\n        delta_v2 = value2_lst[idx] if temp_solution[idx] == 1 else -value2_lst[idx]\n\n        # Use a weighted sum of improvements as the selection criterion\n        improvement = (delta_v1 + delta_v2) / (weight_lst[idx] + 1e-6)  # Avoid division by zero\n\n        if improvement > best_improvement:\n            best_improvement = improvement\n            best_candidate = temp_solution\n\n    # Step 3: Apply the best candidate if found\n    if best_candidate is not None:\n        new_solution = best_candidate\n    else:\n        # If no improvement found, perform a random valid flip\n        valid_indices = [i for i in range(len(new_solution)) if\n                        (new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                        (new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if valid_indices:\n            idx = random.choice(valid_indices)\n            new_solution[idx] = 1 - new_solution[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.954731742570925,
            0.796350508928299
        ]
    },
    {
        "algorithm": "The algorithm selects the most promising solution from the archive (based on average value-to-weight density) and applies a hybrid local search strategy that prioritizes swapping low-value items for high-value ones while ensuring feasibility through adaptive perturbations. If no swaps are feasible, it randomly removes items to free up capacity. The approach balances exploration (via adaptive swaps) and exploitation (via value-to-weight ratios) to improve both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution from the archive\n    # Calculate the density (value/weight) for each objective\n    densities = []\n    for sol, (v1, v2) in archive:\n        included = sol == 1\n        total_weight = np.sum(weight_lst[included])\n        if total_weight == 0:\n            density1 = density2 = 0\n        else:\n            density1 = np.sum(value1_lst[included]) / total_weight\n            density2 = np.sum(value2_lst[included]) / total_weight\n        densities.append((density1 + density2) / 2)  # Average density\n\n    # Select the solution with the highest density (most promising for improvement)\n    best_idx = np.argmax(densities)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Apply novel local search operator\n    # Hybrid strategy: adaptive item swaps and perturbations\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Adaptive swap: replace a low-value item with a high-value item\n        # Calculate value-to-weight ratio for included items\n        included_ratios = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n        worst_included = included_items[np.argmin(included_ratios)]\n\n        # Calculate value-to-weight ratio for excluded items\n        excluded_ratios = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n        best_excluded = excluded_items[np.argmax(excluded_ratios)]\n\n        # Check if swap is feasible\n        current_weight = np.sum(weight_lst[new_solution == 1])\n        swap_weight_diff = weight_lst[best_excluded] - weight_lst[worst_included]\n\n        if current_weight + swap_weight_diff <= capacity:\n            new_solution[worst_included] = 0\n            new_solution[best_excluded] = 1\n        else:\n            # If swap is not feasible, perform a perturbation\n            # Randomly flip a small number of items to find a feasible solution\n            max_perturbations = min(3, len(included_items))\n            for _ in range(max_perturbations):\n                candidate = random.choice(included_items)\n                if current_weight - weight_lst[candidate] <= capacity:\n                    new_solution[candidate] = 0\n                    current_weight -= weight_lst[candidate]\n                    break\n\n    # If no items are included, add the best item if possible\n    elif len(included_items) == 0 and len(excluded_items) > 0:\n        # Add the item with the highest value-to-weight ratio\n        excluded_ratios = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n        best_excluded = excluded_items[np.argmax(excluded_ratios)]\n\n        if weight_lst[best_excluded] <= capacity:\n            new_solution[best_excluded] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.41552698679575917,
            0.3817824423313141
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with high normalized objective values, then applies a hybrid local search that dynamically adjusts weights based on the solution's dominance and evaluates flipping a random subset of items to maximize a weighted sum of both objectives, falling back to probabilistic flips if no improvement is found. It ensures feasibility by checking weight constraints and dynamically balances exploration/exploitation through weighted contributions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) == 1:\n        base_solution = archive[0][0].copy()\n    else:\n        # Sort solutions by the sum of normalized objectives to prioritize promising ones\n        normalized_scores = []\n        max_v1 = max(obj[0] for _, obj in archive)\n        max_v2 = max(obj[1] for _, obj in archive)\n        for sol, obj in archive:\n            norm_v1 = obj[0] / max_v1 if max_v1 > 0 else 0\n            norm_v2 = obj[1] / max_v2 if max_v2 > 0 else 0\n            normalized_scores.append(norm_v1 + norm_v2)\n        # Select top 30% of solutions and choose randomly among them\n        threshold = np.percentile(normalized_scores, 70)\n        candidates = [sol for (sol, _), score in zip(archive, normalized_scores) if score >= threshold]\n        base_solution = random.choice(candidates).copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Dynamic weight adjustment based on current solution's dominance\n    total_v1 = np.sum(value1_lst[new_solution == 1])\n    total_v2 = np.sum(value2_lst[new_solution == 1])\n    weight_v1 = total_v2 / (total_v1 + total_v2 + 1e-6) if (total_v1 + total_v2) > 0 else 0.5\n    weight_v2 = total_v1 / (total_v1 + total_v2 + 1e-6) if (total_v1 + total_v2) > 0 else 0.5\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to potentially swap\n    # 2. Evaluate potential improvements in both objectives with dynamic weights\n    # 3. Apply a greedy selection based on the weighted combined objective improvement\n\n    subset_size = max(1, int(len(new_solution) * 0.3))  # 30% of items\n    subset_indices = np.random.choice(len(new_solution), size=subset_size, replace=False)\n\n    best_improvement = -float('inf')\n    best_candidate = None\n\n    for idx in subset_indices:\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n\n        new_weight = current_weight\n        if temp_solution[idx] == 1:\n            new_weight += weight_lst[idx]\n        else:\n            new_weight -= weight_lst[idx]\n\n        if new_weight > capacity:\n            continue\n\n        delta_v1 = value1_lst[idx] if temp_solution[idx] == 1 else -value1_lst[idx]\n        delta_v2 = value2_lst[idx] if temp_solution[idx] == 1 else -value2_lst[idx]\n\n        improvement = weight_v1 * delta_v1 + weight_v2 * delta_v2\n\n        if improvement > best_improvement:\n            best_improvement = improvement\n            best_candidate = temp_solution\n\n    if best_candidate is not None:\n        new_solution = best_candidate\n    else:\n        # Probabilistic flip based on potential contribution\n        valid_indices = [i for i in range(len(new_solution)) if\n                        (new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                        (new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if valid_indices:\n            # Calculate potential contributions\n            contributions = []\n            for i in valid_indices:\n                potential_v1 = value1_lst[i] if new_solution[i] == 0 else -value1_lst[i]\n                potential_v2 = value2_lst[i] if new_solution[i] == 0 else -value2_lst[i]\n                contribution = weight_v1 * potential_v1 + weight_v2 * potential_v2\n                contributions.append(contribution)\n            # Select with probability proportional to contribution\n            if sum(contributions) > 0:\n                probabilities = [c / sum(contributions) for c in contributions]\n                idx = np.random.choice(valid_indices, p=probabilities)\n            else:\n                idx = random.choice(valid_indices)\n            new_solution[idx] = 1 - new_solution[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9062541463556129,
            1.3094992935657501
        ]
    },
    {
        "algorithm": "The algorithm selects promising solutions from the archive based on hypervolume contributions, then applies a dynamic local search that flips items in a subset size proportional to solution quality, using adaptive weights to balance objective improvements. It prioritizes flips that maximize a weighted sum of normalized objective gains while ensuring feasibility, falling back to random valid flips if no improvement is found. The subset size and weights adjust based on solution quality and current objective values, enabling focused exploration of high-potential regions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) == 1:\n        base_solution = archive[0][0].copy()\n    else:\n        # Sort solutions by hypervolume contribution to prioritize promising ones\n        hypervolumes = []\n        max_v1 = max(obj[0] for _, obj in archive)\n        max_v2 = max(obj[1] for _, obj in archive)\n        for sol, obj in archive:\n            norm_v1 = obj[0] / max_v1 if max_v1 > 0 else 0\n            norm_v2 = obj[1] / max_v2 if max_v2 > 0 else 0\n            hypervolumes.append(norm_v1 * norm_v2)  # Hypervolume approximation\n        # Select top 20% of solutions and choose randomly among them\n        threshold = np.percentile(hypervolumes, 80)\n        candidates = [sol for (sol, _), hv in zip(archive, hypervolumes) if hv >= threshold]\n        base_solution = random.choice(candidates).copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Dynamic subset size based on solution quality\n    total_items = len(new_solution)\n    solution_quality = np.sum(value1_lst[new_solution == 1]) + np.sum(value2_lst[new_solution == 1])\n    max_quality = np.sum(value1_lst) + np.sum(value2_lst)\n    subset_size = max(1, int(total_items * (1 - (solution_quality / max_quality)) * 0.5))  # Larger subset for lower quality solutions\n\n    subset_indices = np.random.choice(total_items, size=subset_size, replace=False)\n\n    # Evaluate potential improvements with adaptive weights\n    best_improvement = 0\n    best_candidate = None\n\n    for idx in subset_indices:\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n\n        new_weight = current_weight\n        if temp_solution[idx] == 1:\n            new_weight += weight_lst[idx]\n        else:\n            new_weight -= weight_lst[idx]\n\n        if new_weight > capacity:\n            continue\n\n        delta_v1 = value1_lst[idx] if temp_solution[idx] == 1 else -value1_lst[idx]\n        delta_v2 = value2_lst[idx] if temp_solution[idx] == 1 else -value2_lst[idx]\n\n        # Adaptive weights based on current solution's objective values\n        current_v1 = np.sum(value1_lst[new_solution == 1])\n        current_v2 = np.sum(value2_lst[new_solution == 1])\n        w1 = current_v2 / (current_v1 + current_v2 + 1e-6) if (current_v1 + current_v2) > 0 else 0.5\n        w2 = current_v1 / (current_v1 + current_v2 + 1e-6) if (current_v1 + current_v2) > 0 else 0.5\n\n        improvement = (w1 * delta_v1 + w2 * delta_v2) / (weight_lst[idx] + 1e-6)\n\n        if improvement > best_improvement:\n            best_improvement = improvement\n            best_candidate = temp_solution\n\n    if best_candidate is not None:\n        new_solution = best_candidate\n    else:\n        # If no improvement found, perform a random valid flip\n        valid_indices = [i for i in range(len(new_solution)) if\n                        (new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                        (new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if valid_indices:\n            idx = random.choice(valid_indices)\n            new_solution[idx] = 1 - new_solution[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9040388126076564,
            1.946214199066162
        ]
    },
    {
        "algorithm": "The algorithm dynamically selects a promising solution from the archive using a hybrid of crowding distance and adaptive weighting, then applies a novel local search combining probabilistic swaps (prioritizing high-value-to-weight ratio items) and Pareto-aware subset replacements to generate high-quality neighbors while ensuring feasibility. The selection prioritizes solutions with high crowding distances and normalized objective values, while the local search focuses on swapping items and replacing subsets to explore the solution space effectively.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Hybrid selection (crowding distance + adaptive weighting)\n    objectives = np.array([obj for _, obj in archive])\n    sorted_indices = np.argsort(objectives[:, 0])\n\n    # Compute crowding distances\n    crowding_distances = np.zeros(len(archive))\n    for obj_idx in range(2):\n        sorted_indices = np.argsort(objectives[:, obj_idx])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for i in range(1, len(archive) - 1):\n            if objectives[sorted_indices[-1], obj_idx] == objectives[sorted_indices[0], obj_idx]:\n                crowding_distances[sorted_indices[i]] = np.inf\n            else:\n                crowding_distances[sorted_indices[i]] += (objectives[sorted_indices[i+1], obj_idx] - objectives[sorted_indices[i-1], obj_idx]) / (objectives[sorted_indices[-1], obj_idx] - objectives[sorted_indices[0], obj_idx])\n\n    # Adaptive weighting: prioritize solutions with high crowding distance and high normalized objectives\n    max_v1, max_v2 = np.max(objectives, axis=0)\n    normalized_scores = np.array([(obj[0]/max_v1 if max_v1 > 0 else 0) + (obj[1]/max_v2 if max_v2 > 0 else 0) for obj in objectives])\n    weighted_scores = crowding_distances * normalized_scores\n    selected_idx = np.argmax(weighted_scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n\n    # Step 2: Novel local search (probabilistic swaps + Pareto-aware subset replacements)\n    n_items = len(weight_lst)\n    subset_size = min(5, n_items // 3)\n\n    # Probabilistic swaps (prioritize high-value-to-weight ratio items)\n    value_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n    for _ in range(min(10, n_items // 2)):\n        if np.random.random() < 0.7:  # Higher probability for swaps\n            candidates = np.argsort(value_ratios)[-subset_size:]  # Top subset_size items by value ratio\n            i, j = np.random.choice(candidates, 2, replace=False)\n            if new_solution[i] != new_solution[j]:\n                if new_solution[i] == 1 and new_solution[j] == 0:\n                    new_weight = current_weight + weight_lst[j] - weight_lst[i]\n                    if new_weight <= capacity:\n                        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                        current_weight = new_weight\n                elif new_solution[i] == 0 and new_solution[j] == 1:\n                    new_weight = current_weight + weight_lst[i] - weight_lst[j]\n                    if new_weight <= capacity:\n                        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                        current_weight = new_weight\n        else:  # Subset replacement\n            remove_indices = np.where(new_solution == 1)[0]\n            if len(remove_indices) > 0:\n                remove_subset = np.random.choice(remove_indices, size=min(subset_size, len(remove_indices)), replace=False)\n                new_solution[remove_subset] = 0\n                current_weight -= np.sum(weight_lst[remove_subset])\n\n                add_indices = np.where(new_solution == 0)[0]\n                if len(add_indices) > 0:\n                    add_subset = np.random.choice(add_indices, size=min(subset_size, len(add_indices)), replace=False)\n                    potential_weight = current_weight + np.sum(weight_lst[add_subset])\n                    if potential_weight <= capacity:\n                        new_solution[add_subset] = 1\n                        current_weight = potential_weight\n\n    return new_solution\n\n",
        "score": [
            -0.7730586733889593,
            1.4795197546482086
        ]
    },
    {
        "algorithm": "The algorithm combines normalized objective prioritization with a dynamic weighted local search, where solutions are first selected based on their combined normalized objective scores, then improved by evaluating single-item flips with weights adjusted to the current solution's balance between objectives, occasionally escaping local optima with random moves while ensuring feasibility. The dynamic weights (weight_v1, weight_v2) bias improvements toward under-represented objectives, and the hybrid strategy balances greedy improvement with exploration.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) == 1:\n        base_solution = archive[0][0].copy()\n    else:\n        # Sort solutions by the sum of normalized objectives to prioritize promising ones\n        normalized_scores = []\n        max_v1 = max(obj[0] for _, obj in archive)\n        max_v2 = max(obj[1] for _, obj in archive)\n        for sol, obj in archive:\n            norm_v1 = obj[0] / max_v1 if max_v1 > 0 else 0\n            norm_v2 = obj[1] / max_v2 if max_v2 > 0 else 0\n            normalized_scores.append(norm_v1 + norm_v2)\n        # Select top 30% of solutions and choose randomly among them\n        threshold = np.percentile(normalized_scores, 70)\n        candidates = [sol for (sol, _), score in zip(archive, normalized_scores) if score >= threshold]\n        base_solution = random.choice(candidates).copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Dynamic weight between objectives based on current solution's balance\n    current_v1 = np.sum(value1_lst[new_solution == 1])\n    current_v2 = np.sum(value2_lst[new_solution == 1])\n    total_v1 = np.sum(value1_lst)\n    total_v2 = np.sum(value2_lst)\n\n    # Calculate dynamic weights (0.5 if balanced, else biased towards under-represented objective)\n    if total_v1 > 0 and total_v2 > 0:\n        weight_v1 = 0.5 * (1 + (current_v1 / total_v1 - current_v2 / total_v2))\n        weight_v2 = 1 - weight_v1\n    else:\n        weight_v1 = weight_v2 = 0.5\n\n    # Hybrid local search strategy:\n    # 1. Evaluate all possible single-item flips\n    # 2. Select the move with the highest weighted improvement\n    # 3. Occasionally perform a random move with probability 0.1\n\n    best_improvement = -float('inf')\n    best_candidate = None\n\n    for idx in range(len(new_solution)):\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n\n        # Calculate new weight\n        new_weight = current_weight\n        if temp_solution[idx] == 1:\n            new_weight += weight_lst[idx]\n        else:\n            new_weight -= weight_lst[idx]\n\n        # Check feasibility\n        if new_weight > capacity:\n            continue\n\n        # Calculate objective improvements\n        delta_v1 = value1_lst[idx] if temp_solution[idx] == 1 else -value1_lst[idx]\n        delta_v2 = value2_lst[idx] if temp_solution[idx] == 1 else -value2_lst[idx]\n\n        # Weighted improvement\n        improvement = weight_v1 * delta_v1 + weight_v2 * delta_v2\n\n        if improvement > best_improvement:\n            best_improvement = improvement\n            best_candidate = temp_solution\n\n    # Apply the best candidate if found, otherwise perform a random move\n    if best_candidate is not None and (best_improvement > 0 or random.random() < 0.1):\n        new_solution = best_candidate\n    else:\n        # Perform a random valid flip\n        valid_indices = [i for i in range(len(new_solution)) if\n                        (new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                        (new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if valid_indices:\n            idx = random.choice(valid_indices)\n            new_solution[idx] = 1 - new_solution[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8239236056587971,
            1.9472983479499817
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive (top 30% by combined value) and applies a hybrid local search: 70% chance for a random item swap (ensuring feasibility) or 30% chance for flipping items based on high value-to-weight density, prioritizing items with the best combined value density. It ensures feasibility by checking weight constraints before applying changes.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort archive by total value (sum of value1 and value2) in descending order\n        archive_sorted = sorted(archive, key=lambda x: x[1][0] + x[1][1], reverse=True)\n        # Select top 30% of solutions and pick one randomly\n        candidate_indices = min(3, len(archive_sorted))  # Ensure at least 1 candidate\n        selected_idx = np.random.randint(0, candidate_indices)\n        base_solution = archive_sorted[selected_idx][0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: randomly swap items or flip items based on value density\n    if np.random.rand() < 0.7:  # 70% chance for random swap\n        # Randomly select two items to swap\n        item_indices = np.where(new_solution == 1)[0]\n        if len(item_indices) >= 2:\n            i, j = np.random.choice(item_indices, 2, replace=False)\n            # Check if swapping is feasible (no weight violation)\n            if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n    else:  # 30% chance for value-based flip\n        # Calculate value density (value1 + value2) / weight for each item\n        value_density = (value1_lst + value2_lst) / weight_lst\n        # Sort items by value density in descending order\n        sorted_items = np.argsort(value_density)[::-1]\n        # Try to flip the most valuable items first\n        for item in sorted_items:\n            if new_solution[item] == 0:\n                if current_weight + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                    current_weight += weight_lst[item]\n                    break\n            else:\n                if current_weight - weight_lst[item] >= 0:\n                    new_solution[item] = 0\n                    current_weight -= weight_lst[item]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.4045771915310815,
            10.611218482255936
        ]
    },
    {
        "algorithm": "The algorithm selects high-performing solutions from the archive (top 30% by normalized objective sum), then applies a three-phase local search: first flipping high value-to-weight ratio items, then probabilistically swapping low-value items for high-value-to-weight items, and finally random diversification if no improvement is found. It ensures feasibility by strict capacity checks at each step, prioritizing items with combined high values and balancing objectives through adaptive selection criteria.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Selection phase: prioritize solutions with high combined normalized objectives\n    max_v1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_v2 = max(obj[1] for _, obj in archive) if archive else 1\n    normalized_scores = [(obj[0]/max_v1 + obj[1]/max_v2) for _, obj in archive]\n    threshold = np.percentile(normalized_scores, 70)\n    candidates = [sol for (sol, obj), score in zip(archive, normalized_scores) if score >= threshold]\n    base_solution = random.choice(candidates).copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Local search phase 1: Flip items with high value-to-weight ratio\n    vw_ratio = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(-vw_ratio)\n    for idx in sorted_indices[:max(1, len(sorted_indices)//5)]:\n        if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n            break\n\n    # Local search phase 2: Probabilistic swap considering both objectives\n    for _ in range(5):\n        out_items = np.where(new_solution == 1)[0]\n        in_items = np.where(new_solution == 0)[0]\n\n        if len(out_items) > 0 and len(in_items) > 0:\n            # Select out item with low combined value\n            out_candidates = sorted(out_items, key=lambda x: value1_lst[x] + value2_lst[x])\n            out_idx = out_candidates[0]\n\n            # Select in item with high value-to-weight ratio\n            in_candidates = sorted(in_items, key=lambda x: -(value1_lst[x] + value2_lst[x])/weight_lst[x])\n            in_idx = in_candidates[0] if in_candidates else -1\n\n            if in_idx != -1 and current_weight - weight_lst[out_idx] + weight_lst[in_idx] <= capacity:\n                new_solution[out_idx] = 0\n                new_solution[in_idx] = 1\n                current_weight = current_weight - weight_lst[out_idx] + weight_lst[in_idx]\n                break\n\n    # Diversification phase: Random valid flip if no improvement found\n    if new_solution.tolist() == base_solution.tolist():\n        valid_indices = [i for i in range(len(new_solution)) if\n                        (new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                        (new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if valid_indices:\n            idx = random.choice(valid_indices)\n            new_solution[idx] = 1 - new_solution[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3334021766381675,
            5.786891281604767
        ]
    }
]