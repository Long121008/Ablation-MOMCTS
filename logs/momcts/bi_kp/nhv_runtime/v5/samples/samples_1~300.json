[
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 1,
        "algorithm": "The algorithm intelligently selects a non-dominated solution from the archive by prioritizing those with high marginal gains, then applies a hybrid local search combining probabilistic item flips and swaps to explore the solution space while ensuring feasibility. The selection is weighted probabilistically, favoring later entries in the archive, and the local search iteratively modifies the solution by flipping or swapping items, checking feasibility at each step. The key design ideas are prioritized selection and hybrid local search with feasibility checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution (prioritize those with high marginal gains)\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution, (base_value1, base_value2) = archive[selected_idx]\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Hybrid local search: probabilistic item flips and swaps\n    for _ in range(5):  # Number of local search iterations\n        # Probabilistic flip: flip a random item if feasible\n        flip_idx = np.random.randint(0, n_items)\n        if new_solution[flip_idx] == 1:\n            if np.sum(weight_lst[new_solution == 1] - weight_lst[flip_idx]) <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if np.sum(weight_lst[new_solution == 1] + weight_lst[flip_idx]) <= capacity:\n                new_solution[flip_idx] = 1\n\n        # Item swap: swap two random items if feasible\n        swap_idx1, swap_idx2 = np.random.choice(n_items, 2, replace=False)\n        if new_solution[swap_idx1] != new_solution[swap_idx2]:\n            if new_solution[swap_idx1] == 1:\n                if np.sum(weight_lst[new_solution == 1] - weight_lst[swap_idx1] + weight_lst[swap_idx2]) <= capacity:\n                    new_solution[swap_idx1] = 0\n                    new_solution[swap_idx2] = 1\n            else:\n                if np.sum(weight_lst[new_solution == 1] - weight_lst[swap_idx2] + weight_lst[swap_idx1]) <= capacity:\n                    new_solution[swap_idx1] = 1\n                    new_solution[swap_idx2] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.3688356342738096,
            0.4918815791606903
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution (prioritize those with high marginal gains)\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution, (base_value1, base_value2) = archive[selected_idx]\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Hybrid local search: probabilistic item flips and swaps\n    for _ in range(5):  # Number of local search iterations\n        # Probabilistic flip: flip a random item if feasible\n        flip_idx = np.random.randint(0, n_items)\n        if new_solution[flip_idx] == 1:\n            if np.sum(weight_lst[new_solution == 1] - weight_lst[flip_idx]) <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if np.sum(weight_lst[new_solution == 1] + weight_lst[flip_idx]) <= capacity:\n                new_solution[flip_idx] = 1\n\n        # Item swap: swap two random items if feasible\n        swap_idx1, swap_idx2 = np.random.choice(n_items, 2, replace=False)\n        if new_solution[swap_idx1] != new_solution[swap_idx2]:\n            if new_solution[swap_idx1] == 1:\n                if np.sum(weight_lst[new_solution == 1] - weight_lst[swap_idx1] + weight_lst[swap_idx2]) <= capacity:\n                    new_solution[swap_idx1] = 0\n                    new_solution[swap_idx2] = 1\n            else:\n                if np.sum(weight_lst[new_solution == 1] - weight_lst[swap_idx2] + weight_lst[swap_idx1]) <= capacity:\n                    new_solution[swap_idx1] = 1\n                    new_solution[swap_idx2] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 1,
        "algorithm": "The algorithm intelligently selects a non-dominated solution from the archive by prioritizing those with high marginal gains, then applies a hybrid local search combining probabilistic item flips and swaps to explore the solution space while ensuring feasibility. The selection is weighted probabilistically, favoring later entries in the archive, and the local search iteratively modifies the solution by flipping or swapping items, checking feasibility at each step. The key design ideas are prioritized selection and hybrid local search with feasibility checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution (prioritize those with high marginal gains)\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution, (base_value1, base_value2) = archive[selected_idx]\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Hybrid local search: probabilistic item flips and swaps\n    for _ in range(5):  # Number of local search iterations\n        # Probabilistic flip: flip a random item if feasible\n        flip_idx = np.random.randint(0, n_items)\n        if new_solution[flip_idx] == 1:\n            if np.sum(weight_lst[new_solution == 1] - weight_lst[flip_idx]) <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if np.sum(weight_lst[new_solution == 1] + weight_lst[flip_idx]) <= capacity:\n                new_solution[flip_idx] = 1\n\n        # Item swap: swap two random items if feasible\n        swap_idx1, swap_idx2 = np.random.choice(n_items, 2, replace=False)\n        if new_solution[swap_idx1] != new_solution[swap_idx2]:\n            if new_solution[swap_idx1] == 1:\n                if np.sum(weight_lst[new_solution == 1] - weight_lst[swap_idx1] + weight_lst[swap_idx2]) <= capacity:\n                    new_solution[swap_idx1] = 0\n                    new_solution[swap_idx2] = 1\n            else:\n                if np.sum(weight_lst[new_solution == 1] - weight_lst[swap_idx2] + weight_lst[swap_idx1]) <= capacity:\n                    new_solution[swap_idx1] = 1\n                    new_solution[swap_idx2] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.3688356342738096,
            0.4918815791606903
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution (prioritize those with high marginal gains)\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution, (base_value1, base_value2) = archive[selected_idx]\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Hybrid local search: probabilistic item flips and swaps\n    for _ in range(5):  # Number of local search iterations\n        # Probabilistic flip: flip a random item if feasible\n        flip_idx = np.random.randint(0, n_items)\n        if new_solution[flip_idx] == 1:\n            if np.sum(weight_lst[new_solution == 1] - weight_lst[flip_idx]) <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if np.sum(weight_lst[new_solution == 1] + weight_lst[flip_idx]) <= capacity:\n                new_solution[flip_idx] = 1\n\n        # Item swap: swap two random items if feasible\n        swap_idx1, swap_idx2 = np.random.choice(n_items, 2, replace=False)\n        if new_solution[swap_idx1] != new_solution[swap_idx2]:\n            if new_solution[swap_idx1] == 1:\n                if np.sum(weight_lst[new_solution == 1] - weight_lst[swap_idx1] + weight_lst[swap_idx2]) <= capacity:\n                    new_solution[swap_idx1] = 0\n                    new_solution[swap_idx2] = 1\n            else:\n                if np.sum(weight_lst[new_solution == 1] - weight_lst[swap_idx2] + weight_lst[swap_idx1]) <= capacity:\n                    new_solution[swap_idx1] = 1\n                    new_solution[swap_idx2] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 1,
        "algorithm": "The algorithm intelligently selects a non-dominated solution from the archive by prioritizing those with high marginal gains, then applies a hybrid local search combining probabilistic item flips and swaps to explore the solution space while ensuring feasibility. The selection is weighted probabilistically, favoring later entries in the archive, and the local search iteratively modifies the solution by flipping or swapping items, checking feasibility at each step. The key design ideas are prioritized selection and hybrid local search with feasibility checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution (prioritize those with high marginal gains)\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution, (base_value1, base_value2) = archive[selected_idx]\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Hybrid local search: probabilistic item flips and swaps\n    for _ in range(5):  # Number of local search iterations\n        # Probabilistic flip: flip a random item if feasible\n        flip_idx = np.random.randint(0, n_items)\n        if new_solution[flip_idx] == 1:\n            if np.sum(weight_lst[new_solution == 1] - weight_lst[flip_idx]) <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if np.sum(weight_lst[new_solution == 1] + weight_lst[flip_idx]) <= capacity:\n                new_solution[flip_idx] = 1\n\n        # Item swap: swap two random items if feasible\n        swap_idx1, swap_idx2 = np.random.choice(n_items, 2, replace=False)\n        if new_solution[swap_idx1] != new_solution[swap_idx2]:\n            if new_solution[swap_idx1] == 1:\n                if np.sum(weight_lst[new_solution == 1] - weight_lst[swap_idx1] + weight_lst[swap_idx2]) <= capacity:\n                    new_solution[swap_idx1] = 0\n                    new_solution[swap_idx2] = 1\n            else:\n                if np.sum(weight_lst[new_solution == 1] - weight_lst[swap_idx2] + weight_lst[swap_idx1]) <= capacity:\n                    new_solution[swap_idx1] = 1\n                    new_solution[swap_idx2] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.3688356342738096,
            0.4918815791606903
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution (prioritize those with high marginal gains)\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution, (base_value1, base_value2) = archive[selected_idx]\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Hybrid local search: probabilistic item flips and swaps\n    for _ in range(5):  # Number of local search iterations\n        # Probabilistic flip: flip a random item if feasible\n        flip_idx = np.random.randint(0, n_items)\n        if new_solution[flip_idx] == 1:\n            if np.sum(weight_lst[new_solution == 1] - weight_lst[flip_idx]) <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if np.sum(weight_lst[new_solution == 1] + weight_lst[flip_idx]) <= capacity:\n                new_solution[flip_idx] = 1\n\n        # Item swap: swap two random items if feasible\n        swap_idx1, swap_idx2 = np.random.choice(n_items, 2, replace=False)\n        if new_solution[swap_idx1] != new_solution[swap_idx2]:\n            if new_solution[swap_idx1] == 1:\n                if np.sum(weight_lst[new_solution == 1] - weight_lst[swap_idx1] + weight_lst[swap_idx2]) <= capacity:\n                    new_solution[swap_idx1] = 0\n                    new_solution[swap_idx2] = 1\n            else:\n                if np.sum(weight_lst[new_solution == 1] - weight_lst[swap_idx2] + weight_lst[swap_idx1]) <= capacity:\n                    new_solution[swap_idx1] = 1\n                    new_solution[swap_idx2] = 0\n\n    return new_solution\n\n",
        "operation": "i1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 2,
        "algorithm": "The algorithm selects a random solution from the archive, applies a hybrid local search by flipping a small random subset of items (with feasibility checks), and then performs a greedy improvement step to add items that improve at least one objective. The design prioritizes diversity and local optimization while ensuring feasibility, using a combination of randomness and greedy selection to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    import random\n    import numpy as np\n\n    # Select a promising solution from the archive (here, we select a random one for diversity)\n    selected_solution, _ = random.choice(archive)\n    new_solution = selected_solution.copy()\n\n    # Apply a hybrid local search: flip a random subset of items and then perform a greedy improvement\n    num_items = len(new_solution)\n    flip_indices = random.sample(range(num_items), min(3, num_items))  # Flip up to 3 random items\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            # Only flip to 1 if it doesn't exceed capacity\n            current_weight = np.sum(new_solution * weight_lst)\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Greedy improvement: try to add items that improve at least one objective\n    for idx in range(num_items):\n        if new_solution[idx] == 0:\n            current_weight = np.sum(new_solution * weight_lst)\n            if current_weight + weight_lst[idx] <= capacity:\n                # Simulate adding the item\n                temp_solution = new_solution.copy()\n                temp_solution[idx] = 1\n                temp_value1 = np.sum(temp_solution * value1_lst)\n                temp_value2 = np.sum(temp_solution * value2_lst)\n                current_value1 = np.sum(new_solution * value1_lst)\n                current_value2 = np.sum(new_solution * value2_lst)\n\n                # Accept if at least one objective improves\n                if (temp_value1 > current_value1) or (temp_value2 > current_value2):\n                    new_solution[idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.3743656696571226,
            1.5071693360805511
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    import random\n    import numpy as np\n\n    # Select a promising solution from the archive (here, we select a random one for diversity)\n    selected_solution, _ = random.choice(archive)\n    new_solution = selected_solution.copy()\n\n    # Apply a hybrid local search: flip a random subset of items and then perform a greedy improvement\n    num_items = len(new_solution)\n    flip_indices = random.sample(range(num_items), min(3, num_items))  # Flip up to 3 random items\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            # Only flip to 1 if it doesn't exceed capacity\n            current_weight = np.sum(new_solution * weight_lst)\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Greedy improvement: try to add items that improve at least one objective\n    for idx in range(num_items):\n        if new_solution[idx] == 0:\n            current_weight = np.sum(new_solution * weight_lst)\n            if current_weight + weight_lst[idx] <= capacity:\n                # Simulate adding the item\n                temp_solution = new_solution.copy()\n                temp_solution[idx] = 1\n                temp_value1 = np.sum(temp_solution * value1_lst)\n                temp_value2 = np.sum(temp_solution * value2_lst)\n                current_value1 = np.sum(new_solution * value1_lst)\n                current_value2 = np.sum(new_solution * value2_lst)\n\n                # Accept if at least one objective improves\n                if (temp_value1 > current_value1) or (temp_value2 > current_value2):\n                    new_solution[idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 2,
        "algorithm": "The algorithm selects a random solution from the archive, applies a hybrid local search by flipping a small random subset of items (with feasibility checks), and then performs a greedy improvement step to add items that improve at least one objective. The design prioritizes diversity and local optimization while ensuring feasibility, using a combination of randomness and greedy selection to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    import random\n    import numpy as np\n\n    # Select a promising solution from the archive (here, we select a random one for diversity)\n    selected_solution, _ = random.choice(archive)\n    new_solution = selected_solution.copy()\n\n    # Apply a hybrid local search: flip a random subset of items and then perform a greedy improvement\n    num_items = len(new_solution)\n    flip_indices = random.sample(range(num_items), min(3, num_items))  # Flip up to 3 random items\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            # Only flip to 1 if it doesn't exceed capacity\n            current_weight = np.sum(new_solution * weight_lst)\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Greedy improvement: try to add items that improve at least one objective\n    for idx in range(num_items):\n        if new_solution[idx] == 0:\n            current_weight = np.sum(new_solution * weight_lst)\n            if current_weight + weight_lst[idx] <= capacity:\n                # Simulate adding the item\n                temp_solution = new_solution.copy()\n                temp_solution[idx] = 1\n                temp_value1 = np.sum(temp_solution * value1_lst)\n                temp_value2 = np.sum(temp_solution * value2_lst)\n                current_value1 = np.sum(new_solution * value1_lst)\n                current_value2 = np.sum(new_solution * value2_lst)\n\n                # Accept if at least one objective improves\n                if (temp_value1 > current_value1) or (temp_value2 > current_value2):\n                    new_solution[idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.3743656696571226,
            1.5071693360805511
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    import random\n    import numpy as np\n\n    # Select a promising solution from the archive (here, we select a random one for diversity)\n    selected_solution, _ = random.choice(archive)\n    new_solution = selected_solution.copy()\n\n    # Apply a hybrid local search: flip a random subset of items and then perform a greedy improvement\n    num_items = len(new_solution)\n    flip_indices = random.sample(range(num_items), min(3, num_items))  # Flip up to 3 random items\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            # Only flip to 1 if it doesn't exceed capacity\n            current_weight = np.sum(new_solution * weight_lst)\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Greedy improvement: try to add items that improve at least one objective\n    for idx in range(num_items):\n        if new_solution[idx] == 0:\n            current_weight = np.sum(new_solution * weight_lst)\n            if current_weight + weight_lst[idx] <= capacity:\n                # Simulate adding the item\n                temp_solution = new_solution.copy()\n                temp_solution[idx] = 1\n                temp_value1 = np.sum(temp_solution * value1_lst)\n                temp_value2 = np.sum(temp_solution * value2_lst)\n                current_value1 = np.sum(new_solution * value1_lst)\n                current_value2 = np.sum(new_solution * value2_lst)\n\n                # Accept if at least one objective improves\n                if (temp_value1 > current_value1) or (temp_value2 > current_value2):\n                    new_solution[idx] = 1\n\n    return new_solution\n\n",
        "operation": "i1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 3,
        "algorithm": "The algorithm selects a random solution from the archive and performs a hybrid local search by swapping items with a focus on improving either objective while ensuring feasibility. It prioritizes swaps that increase at least one objective value and maintains the solution's weight within capacity. The method uses a value-to-weight ratio consideration to guide the swaps and limits the search to 10 attempts for efficiency.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: random swaps with value-to-weight ratio consideration\n    for _ in range(10):  # Number of attempts to find a feasible neighbor\n        # Select two random items\n        item1, item2 = np.random.choice(len(new_solution), size=2, replace=False)\n\n        # Calculate potential weight change\n        if new_solution[item1] == 1 and new_solution[item2] == 0:\n            delta_weight = weight_lst[item2] - weight_lst[item1]\n        elif new_solution[item1] == 0 and new_solution[item2] == 1:\n            delta_weight = weight_lst[item1] - weight_lst[item2]\n        else:\n            continue  # No change in weight\n\n        # Check feasibility\n        if current_weight + delta_weight <= capacity:\n            # Perform swap if it improves at least one objective\n            value1_delta = (value1_lst[item1] - value1_lst[item2]) if new_solution[item1] == 1 else (value1_lst[item2] - value1_lst[item1])\n            value2_delta = (value2_lst[item1] - value2_lst[item2]) if new_solution[item1] == 1 else (value2_lst[item2] - value2_lst[item1])\n\n            if value1_delta > 0 or value2_delta > 0:\n                new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n                current_weight += delta_weight\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.49864606700041164,
            0.321457177400589
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: random swaps with value-to-weight ratio consideration\n    for _ in range(10):  # Number of attempts to find a feasible neighbor\n        # Select two random items\n        item1, item2 = np.random.choice(len(new_solution), size=2, replace=False)\n\n        # Calculate potential weight change\n        if new_solution[item1] == 1 and new_solution[item2] == 0:\n            delta_weight = weight_lst[item2] - weight_lst[item1]\n        elif new_solution[item1] == 0 and new_solution[item2] == 1:\n            delta_weight = weight_lst[item1] - weight_lst[item2]\n        else:\n            continue  # No change in weight\n\n        # Check feasibility\n        if current_weight + delta_weight <= capacity:\n            # Perform swap if it improves at least one objective\n            value1_delta = (value1_lst[item1] - value1_lst[item2]) if new_solution[item1] == 1 else (value1_lst[item2] - value1_lst[item1])\n            value2_delta = (value2_lst[item1] - value2_lst[item2]) if new_solution[item1] == 1 else (value2_lst[item2] - value2_lst[item1])\n\n            if value1_delta > 0 or value2_delta > 0:\n                new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n                current_weight += delta_weight\n                break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 3,
        "algorithm": "The algorithm selects a random solution from the archive and performs a hybrid local search by swapping items with a focus on improving either objective while ensuring feasibility. It prioritizes swaps that increase at least one objective value and maintains the solution's weight within capacity. The method uses a value-to-weight ratio consideration to guide the swaps and limits the search to 10 attempts for efficiency.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: random swaps with value-to-weight ratio consideration\n    for _ in range(10):  # Number of attempts to find a feasible neighbor\n        # Select two random items\n        item1, item2 = np.random.choice(len(new_solution), size=2, replace=False)\n\n        # Calculate potential weight change\n        if new_solution[item1] == 1 and new_solution[item2] == 0:\n            delta_weight = weight_lst[item2] - weight_lst[item1]\n        elif new_solution[item1] == 0 and new_solution[item2] == 1:\n            delta_weight = weight_lst[item1] - weight_lst[item2]\n        else:\n            continue  # No change in weight\n\n        # Check feasibility\n        if current_weight + delta_weight <= capacity:\n            # Perform swap if it improves at least one objective\n            value1_delta = (value1_lst[item1] - value1_lst[item2]) if new_solution[item1] == 1 else (value1_lst[item2] - value1_lst[item1])\n            value2_delta = (value2_lst[item1] - value2_lst[item2]) if new_solution[item1] == 1 else (value2_lst[item2] - value2_lst[item1])\n\n            if value1_delta > 0 or value2_delta > 0:\n                new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n                current_weight += delta_weight\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.49864606700041164,
            0.321457177400589
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: random swaps with value-to-weight ratio consideration\n    for _ in range(10):  # Number of attempts to find a feasible neighbor\n        # Select two random items\n        item1, item2 = np.random.choice(len(new_solution), size=2, replace=False)\n\n        # Calculate potential weight change\n        if new_solution[item1] == 1 and new_solution[item2] == 0:\n            delta_weight = weight_lst[item2] - weight_lst[item1]\n        elif new_solution[item1] == 0 and new_solution[item2] == 1:\n            delta_weight = weight_lst[item1] - weight_lst[item2]\n        else:\n            continue  # No change in weight\n\n        # Check feasibility\n        if current_weight + delta_weight <= capacity:\n            # Perform swap if it improves at least one objective\n            value1_delta = (value1_lst[item1] - value1_lst[item2]) if new_solution[item1] == 1 else (value1_lst[item2] - value1_lst[item1])\n            value2_delta = (value2_lst[item1] - value2_lst[item2]) if new_solution[item1] == 1 else (value2_lst[item2] - value2_lst[item1])\n\n            if value1_delta > 0 or value2_delta > 0:\n                new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n                current_weight += delta_weight\n                break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 3,
        "algorithm": "The algorithm selects a random solution from the archive and performs a hybrid local search by swapping items with a focus on improving either objective while ensuring feasibility. It prioritizes swaps that increase at least one objective value and maintains the solution's weight within capacity. The method uses a value-to-weight ratio consideration to guide the swaps and limits the search to 10 attempts for efficiency.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: random swaps with value-to-weight ratio consideration\n    for _ in range(10):  # Number of attempts to find a feasible neighbor\n        # Select two random items\n        item1, item2 = np.random.choice(len(new_solution), size=2, replace=False)\n\n        # Calculate potential weight change\n        if new_solution[item1] == 1 and new_solution[item2] == 0:\n            delta_weight = weight_lst[item2] - weight_lst[item1]\n        elif new_solution[item1] == 0 and new_solution[item2] == 1:\n            delta_weight = weight_lst[item1] - weight_lst[item2]\n        else:\n            continue  # No change in weight\n\n        # Check feasibility\n        if current_weight + delta_weight <= capacity:\n            # Perform swap if it improves at least one objective\n            value1_delta = (value1_lst[item1] - value1_lst[item2]) if new_solution[item1] == 1 else (value1_lst[item2] - value1_lst[item1])\n            value2_delta = (value2_lst[item1] - value2_lst[item2]) if new_solution[item1] == 1 else (value2_lst[item2] - value2_lst[item1])\n\n            if value1_delta > 0 or value2_delta > 0:\n                new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n                current_weight += delta_weight\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.49864606700041164,
            0.321457177400589
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: random swaps with value-to-weight ratio consideration\n    for _ in range(10):  # Number of attempts to find a feasible neighbor\n        # Select two random items\n        item1, item2 = np.random.choice(len(new_solution), size=2, replace=False)\n\n        # Calculate potential weight change\n        if new_solution[item1] == 1 and new_solution[item2] == 0:\n            delta_weight = weight_lst[item2] - weight_lst[item1]\n        elif new_solution[item1] == 0 and new_solution[item2] == 1:\n            delta_weight = weight_lst[item1] - weight_lst[item2]\n        else:\n            continue  # No change in weight\n\n        # Check feasibility\n        if current_weight + delta_weight <= capacity:\n            # Perform swap if it improves at least one objective\n            value1_delta = (value1_lst[item1] - value1_lst[item2]) if new_solution[item1] == 1 else (value1_lst[item2] - value1_lst[item1])\n            value2_delta = (value2_lst[item1] - value2_lst[item2]) if new_solution[item1] == 1 else (value2_lst[item2] - value2_lst[item1])\n\n            if value1_delta > 0 or value2_delta > 0:\n                new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n                current_weight += delta_weight\n                break\n\n    return new_solution\n\n",
        "operation": "i1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 4,
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3202108423479148,
            0.2685256004333496
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 4,
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3202108423479148,
            0.2685256004333496
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "i1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 5,
        "algorithm": "The algorithm selects a random solution from the archive and applies a hybrid local search strategy that prioritizes items with high marginal value (combined from both objectives) while ensuring feasibility, followed by random flips to explore diversity. It balances exploitation (targeting high-value items) with exploration (random perturbations) to generate improved neighbor solutions. The approach avoids standard local search methods like 2-opt by focusing on value-weighted flips and controlled randomness.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: Flip items based on marginal contribution and diversity\n    new_solution = base_solution.copy()\n\n    # Step 1: Identify items with high marginal contribution (value/weight ratio)\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Step 2: Flip items with high marginal contribution if feasible\n    for i in np.argsort(-combined_marginal):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Step 3: Randomly flip additional items to explore diversity\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.6371576377229591,
            0.4495231509208679
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: Flip items based on marginal contribution and diversity\n    new_solution = base_solution.copy()\n\n    # Step 1: Identify items with high marginal contribution (value/weight ratio)\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Step 2: Flip items with high marginal contribution if feasible\n    for i in np.argsort(-combined_marginal):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Step 3: Randomly flip additional items to explore diversity\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 5,
        "algorithm": "The algorithm selects a random solution from the archive and applies a hybrid local search strategy that prioritizes items with high marginal value (combined from both objectives) while ensuring feasibility, followed by random flips to explore diversity. It balances exploitation (targeting high-value items) with exploration (random perturbations) to generate improved neighbor solutions. The approach avoids standard local search methods like 2-opt by focusing on value-weighted flips and controlled randomness.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: Flip items based on marginal contribution and diversity\n    new_solution = base_solution.copy()\n\n    # Step 1: Identify items with high marginal contribution (value/weight ratio)\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Step 2: Flip items with high marginal contribution if feasible\n    for i in np.argsort(-combined_marginal):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Step 3: Randomly flip additional items to explore diversity\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.6371576377229591,
            0.4495231509208679
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: Flip items based on marginal contribution and diversity\n    new_solution = base_solution.copy()\n\n    # Step 1: Identify items with high marginal contribution (value/weight ratio)\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Step 2: Flip items with high marginal contribution if feasible\n    for i in np.argsort(-combined_marginal):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Step 3: Randomly flip additional items to explore diversity\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    return new_solution\n\n",
        "operation": "i1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a random solution from the archive and applies a hybrid local search strategy that prioritizes items with high marginal value (combined from both objectives) while ensuring feasibility, followed by random flips to explore diversity. It balances exploitation (targeting high-value items) with exploration (random perturbations) to generate improved neighbor solutions. The approach avoids standard local search methods like 2-opt by focusing on value-weighted flips and controlled randomness.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: Flip items based on marginal contribution and diversity\n    new_solution = base_solution.copy()\n\n    # Step 1: Identify items with high marginal contribution (value/weight ratio)\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Step 2: Flip items with high marginal contribution if feasible\n    for i in np.argsort(-combined_marginal):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Step 3: Randomly flip additional items to explore diversity\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            \n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 6,
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with high normalized scores (combining both objectives), then applies a \"value-balancing\" local search: it removes items where one objective's marginal contribution is significantly higher than the other to rebalance trade-offs, and adds high-marginal-value items that improve underperforming objectives while ensuring feasibility. The selection balances exploration and exploitation, while the local search intelligently adjusts items to enhance both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objectives\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal contributions for both objectives\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n\n    # Identify items where one objective's marginal contribution is significantly higher than the other\n    imbalance_threshold = 1.5  # Threshold to identify disproportionate contributions\n    for i in range(len(base_solution)):\n        if marginal_value1[i] > imbalance_threshold * marginal_value2[i]:\n            # If value1 is significantly higher, consider removing the item\n            if base_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n        elif marginal_value2[i] > imbalance_threshold * marginal_value1[i]:\n            # If value2 is significantly higher, consider removing the item\n            if base_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n\n    # Add items that could improve the underperforming objective\n    combined_marginal = marginal_value1 + marginal_value2\n    for i in np.argsort(-combined_marginal):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.2885691204801242,
            0.5224335193634033
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objectives\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal contributions for both objectives\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n\n    # Identify items where one objective's marginal contribution is significantly higher than the other\n    imbalance_threshold = 1.5  # Threshold to identify disproportionate contributions\n    for i in range(len(base_solution)):\n        if marginal_value1[i] > imbalance_threshold * marginal_value2[i]:\n            # If value1 is significantly higher, consider removing the item\n            if base_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n        elif marginal_value2[i] > imbalance_threshold * marginal_value1[i]:\n            # If value2 is significantly higher, consider removing the item\n            if base_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n\n    # Add items that could improve the underperforming objective\n    combined_marginal = marginal_value1 + marginal_value2\n    for i in np.argsort(-combined_marginal):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a random solution from the archive, applies a hybrid local search by flipping a small random subset of items (with feasibility checks), and then performs a greedy improvement step to add items that improve at least one objective. The design prioritizes diversity and local optimization while ensuring feasibility, using a combination of randomness and greedy selection to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    import random\n    import numpy as np\n\n    # Select a promising solution from the archive (here, we select a random one for diversity)\n    selected_solution, _ = random.choice(archive)\n    new_solution = selected_solution.copy()\n\n    # Apply a hybrid local search: flip a random subset of items and then perform a greedy improvement\n    num_items = len(new_solution)\n    flip_indices = random.sample(range(num_items), min(3, num_items))  # Flip up to 3 random items\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            # Only flip to 1 if it doesn't exceed capacity\n            current_weight = np.sum(new_solution * weight_lst)\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Greedy improvement: try to add items that improve at least one objective\n    for idx in range(num_items):\n        if new_solution[idx] == 0:\n            current_weight = np.sum(new_solution * weight_lst)\n            if current_weight + weight_lst[idx] <= capacity:\n                # Simulate adding the item\n                temp_solution = new_solution.copy()\n                temp_solution[idx] = 1\n                temp_value1 = np.sum(temp_solution * value1_lst)\n                temp_value2 = np.sum(temp_solution * value2_lst)\n                current_value1 = np.sum(new_solution * value1_lst)\n                current_value2 = np.sum(new_solution * value2_lst)\n\n                # Accept if at least one objective improves\n                if (temp_value1 > current_value1) or (temp_value2 > current_value2):\n                    new_solution[idx] = 1\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a random solution from the archive and applies a hybrid local search strategy that prioritizes items with high marginal value (combined from both objectives) while ensuring feasibility, followed by random flips to explore diversity. It balances exploitation (targeting high-value items) with exploration (random perturbations) to generate improved neighbor solutions. The approach avoids standard local search methods like 2-opt by focusing on value-weighted flips and controlled randomness.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: Flip items based on marginal contribution and diversity\n    new_solution = base_solution.copy()\n\n    # Step 1: Identify items with high marginal contribution (value/weight ratio)\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Step 2: Flip items with high marginal contribution if feasible\n    for i in np.argsort(-combined_marginal):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Step 3: Randomly flip additional items to explore diversity\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            \n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 7,
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with potential for improvement (items that can be added without exceeding capacity), then applies a hybrid approach combining value-weighted greedy selection (prioritizing items with highest combined marginal value) and adaptive random perturbations (flipping items probabilistically, with flip probability adjusted based on archive diversity). Finally, it ensures feasibility through greedy backtracking by removing low-marginal-value items if the weight exceeds capacity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    import random\n    import numpy as np\n\n    # Select a solution with potential for improvement by considering both value and archive diversity\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(sol * weight_lst)\n        remaining_capacity = capacity - current_weight\n        potential_items = np.where((sol == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(potential_items) > 0:\n            candidates.append(sol)\n\n    if not candidates:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        selected_solution = random.choice(candidates).copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Step 1: Value-weighted greedy selection\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    for i in np.argsort(-combined_marginal):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    # Step 2: Adaptive random perturbation based on solution quality\n    num_items = len(new_solution)\n    flip_prob = 0.3  # Base flip probability\n    if len(archive) > 1:\n        # Adjust flip probability based on archive diversity\n        archive_weights = np.array([sol[0] for sol, _ in archive])\n        diversity = np.mean(np.std(archive_weights, axis=0))\n        flip_prob = min(0.5, flip_prob + 0.2 * diversity)\n\n    flip_indices = [i for i in range(num_items) if random.random() < flip_prob]\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    # Step 3: Greedy backtracking to maintain feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess_weight = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest marginal value contribution\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        remove_idx = removable_items[np.argmin(marginal_contrib[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8698856534598612,
            0.7990563213825226
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    import random\n    import numpy as np\n\n    # Select a solution with potential for improvement by considering both value and archive diversity\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(sol * weight_lst)\n        remaining_capacity = capacity - current_weight\n        potential_items = np.where((sol == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(potential_items) > 0:\n            candidates.append(sol)\n\n    if not candidates:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        selected_solution = random.choice(candidates).copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Step 1: Value-weighted greedy selection\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    for i in np.argsort(-combined_marginal):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    # Step 2: Adaptive random perturbation based on solution quality\n    num_items = len(new_solution)\n    flip_prob = 0.3  # Base flip probability\n    if len(archive) > 1:\n        # Adjust flip probability based on archive diversity\n        archive_weights = np.array([sol[0] for sol, _ in archive])\n        diversity = np.mean(np.std(archive_weights, axis=0))\n        flip_prob = min(0.5, flip_prob + 0.2 * diversity)\n\n    flip_indices = [i for i in range(num_items) if random.random() < flip_prob]\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    # Step 3: Greedy backtracking to maintain feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess_weight = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest marginal value contribution\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        remove_idx = removable_items[np.argmin(marginal_contrib[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a random solution from the archive, applies a hybrid local search by flipping a small random subset of items (with feasibility checks), and then performs a greedy improvement step to add items that improve at least one objective. The design prioritizes diversity and local optimization while ensuring feasibility, using a combination of randomness and greedy selection to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    import random\n    import numpy as np\n\n    # Select a promising solution from the archive (here, we select a random one for diversity)\n    selected_solution, _ = random.choice(archive)\n    new_solution = selected_solution.copy()\n\n    # Apply a hybrid local search: flip a random subset of items and then perform a greedy improvement\n    num_items = len(new_solution)\n    flip_indices = random.sample(range(num_items), min(3, num_items))  # Flip up to 3 random items\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            # Only flip to 1 if it doesn't exceed capacity\n            current_weight = np.sum(new_solution * weight_lst)\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Greedy improvement: try to add items that improve at least one objective\n    for idx in range(num_items):\n        if new_solution[idx] == 0:\n            current_weight = np.sum(new_solution * weight_lst)\n            if current_weight + weight_lst[idx] <= capacity:\n                # Simulate adding the item\n                temp_solution = new_solution.copy()\n                temp_solution[idx] = 1\n                temp_value1 = np.sum(temp_solution * value1_lst)\n                temp_value2 = np.sum(temp_solution * value2_lst)\n                current_value1 = np.sum(new_solution * value1_lst)\n                current_value2 = np.sum(new_solution * value2_lst)\n\n                # Accept if at least one objective improves\n                if (temp_value1 > current_value1) or (temp_value2 > current_value2):\n                    new_solution[idx] = 1\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a random solution from the archive and applies a hybrid local search strategy that prioritizes items with high marginal value (combined from both objectives) while ensuring feasibility, followed by random flips to explore diversity. It balances exploitation (targeting high-value items) with exploration (random perturbations) to generate improved neighbor solutions. The approach avoids standard local search methods like 2-opt by focusing on value-weighted flips and controlled randomness.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: Flip items based on marginal contribution and diversity\n    new_solution = base_solution.copy()\n\n    # Step 1: Identify items with high marginal contribution (value/weight ratio)\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Step 2: Flip items with high marginal contribution if feasible\n    for i in np.argsort(-combined_marginal):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Step 3: Randomly flip additional items to explore diversity\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            \n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 7,
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with potential for improvement (items that can be added without exceeding capacity), then applies a hybrid approach combining value-weighted greedy selection (prioritizing items with highest combined marginal value) and adaptive random perturbations (flipping items probabilistically, with flip probability adjusted based on archive diversity). Finally, it ensures feasibility through greedy backtracking by removing low-marginal-value items if the weight exceeds capacity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    import random\n    import numpy as np\n\n    # Select a solution with potential for improvement by considering both value and archive diversity\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(sol * weight_lst)\n        remaining_capacity = capacity - current_weight\n        potential_items = np.where((sol == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(potential_items) > 0:\n            candidates.append(sol)\n\n    if not candidates:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        selected_solution = random.choice(candidates).copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Step 1: Value-weighted greedy selection\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    for i in np.argsort(-combined_marginal):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    # Step 2: Adaptive random perturbation based on solution quality\n    num_items = len(new_solution)\n    flip_prob = 0.3  # Base flip probability\n    if len(archive) > 1:\n        # Adjust flip probability based on archive diversity\n        archive_weights = np.array([sol[0] for sol, _ in archive])\n        diversity = np.mean(np.std(archive_weights, axis=0))\n        flip_prob = min(0.5, flip_prob + 0.2 * diversity)\n\n    flip_indices = [i for i in range(num_items) if random.random() < flip_prob]\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    # Step 3: Greedy backtracking to maintain feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess_weight = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest marginal value contribution\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        remove_idx = removable_items[np.argmin(marginal_contrib[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8698856534598612,
            0.7990563213825226
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    import random\n    import numpy as np\n\n    # Select a solution with potential for improvement by considering both value and archive diversity\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(sol * weight_lst)\n        remaining_capacity = capacity - current_weight\n        potential_items = np.where((sol == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(potential_items) > 0:\n            candidates.append(sol)\n\n    if not candidates:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        selected_solution = random.choice(candidates).copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Step 1: Value-weighted greedy selection\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    for i in np.argsort(-combined_marginal):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    # Step 2: Adaptive random perturbation based on solution quality\n    num_items = len(new_solution)\n    flip_prob = 0.3  # Base flip probability\n    if len(archive) > 1:\n        # Adjust flip probability based on archive diversity\n        archive_weights = np.array([sol[0] for sol, _ in archive])\n        diversity = np.mean(np.std(archive_weights, axis=0))\n        flip_prob = min(0.5, flip_prob + 0.2 * diversity)\n\n    flip_indices = [i for i in range(num_items) if random.random() < flip_prob]\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    # Step 3: Greedy backtracking to maintain feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess_weight = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest marginal value contribution\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        remove_idx = removable_items[np.argmin(marginal_contrib[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a random solution from the archive and applies a hybrid local search strategy that prioritizes items with high marginal value (combined from both objectives) while ensuring feasibility, followed by random flips to explore diversity. It balances exploitation (targeting high-value items) with exploration (random perturbations) to generate improved neighbor solutions. The approach avoids standard local search methods like 2-opt by focusing on value-weighted flips and controlled randomness.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: Flip items based on marginal contribution and diversity\n    new_solution = base_solution.copy()\n\n    # Step 1: Identify items with high marginal contribution (value/weight ratio)\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Step 2: Flip items with high marginal contribution if feasible\n    for i in np.argsort(-combined_marginal):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Step 3: Randomly flip additional items to explore diversity\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 8,
        "algorithm": "The algorithm dynamically selects a solution from the archive based on a weighted combination of objective values (prioritizing one objective more when its variance is higher), then applies a value-weighted flip strategy with adaptive randomness to generate a neighbor. It also incorporates crowding-aware perturbations to balance exploration and exploitation while ensuring feasibility. The key design ideas are: dynamic objective weighting, adaptive marginal value-based flips, and crowding-aware perturbations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    obj1_weights = np.array([obj[0] for _, obj in archive])\n    obj2_weights = np.array([obj[1] for _, obj in archive])\n    obj1_std = np.std(obj1_weights)\n    obj2_std = np.std(obj2_weights)\n    alpha = obj2_std / (obj1_std + obj2_std + 1e-10)  # Weighting factor\n\n    # Select solution with highest weighted score\n    scores = alpha * obj1_weights + (1 - alpha) * obj2_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate adaptive marginal values\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = (alpha * marginal_value1 + (1 - alpha) * marginal_value2) / (1 + 0.1 * np.random.rand(len(weight_lst)))\n\n    # Flip items based on adaptive marginal values\n    new_solution = base_solution.copy()\n    for i in np.argsort(-combined_marginal):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Crowding-aware perturbation\n    if len(archive) > 1:\n        distances = np.zeros(len(archive))\n        for i, (sol, _) in enumerate(archive):\n            distances[i] = np.sum(np.abs(sol - new_solution))\n        min_dist_idx = np.argmin(distances)\n        if min_dist_idx != selected_idx:\n            crowding_factor = 1 - distances[min_dist_idx] / (np.sum(distances) + 1e-10)\n            perturb_indices = np.random.choice(len(new_solution), size=int(crowding_factor * len(new_solution)), replace=False)\n            for i in perturb_indices:\n                if np.random.rand() < 0.3:  # 30% chance to flip\n                    if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                        new_solution[i] = 1\n                    elif new_solution[i] == 1:\n                        new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.5133315916615483,
            0.7007046043872833
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    obj1_weights = np.array([obj[0] for _, obj in archive])\n    obj2_weights = np.array([obj[1] for _, obj in archive])\n    obj1_std = np.std(obj1_weights)\n    obj2_std = np.std(obj2_weights)\n    alpha = obj2_std / (obj1_std + obj2_std + 1e-10)  # Weighting factor\n\n    # Select solution with highest weighted score\n    scores = alpha * obj1_weights + (1 - alpha) * obj2_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate adaptive marginal values\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = (alpha * marginal_value1 + (1 - alpha) * marginal_value2) / (1 + 0.1 * np.random.rand(len(weight_lst)))\n\n    # Flip items based on adaptive marginal values\n    new_solution = base_solution.copy()\n    for i in np.argsort(-combined_marginal):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Crowding-aware perturbation\n    if len(archive) > 1:\n        distances = np.zeros(len(archive))\n        for i, (sol, _) in enumerate(archive):\n            distances[i] = np.sum(np.abs(sol - new_solution))\n        min_dist_idx = np.argmin(distances)\n        if min_dist_idx != selected_idx:\n            crowding_factor = 1 - distances[min_dist_idx] / (np.sum(distances) + 1e-10)\n            perturb_indices = np.random.choice(len(new_solution), size=int(crowding_factor * len(new_solution)), replace=False)\n            for i in perturb_indices:\n                if np.random.rand() < 0.3:  # 30% chance to flip\n                    if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                        new_solution[i] = 1\n                    elif new_solution[i] == 1:\n                        new_solution[i] = 0\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a random solution from the archive and applies a hybrid local search strategy that prioritizes items with high marginal value (combined from both objectives) while ensuring feasibility, followed by random flips to explore diversity. It balances exploitation (targeting high-value items) with exploration (random perturbations) to generate improved neighbor solutions. The approach avoids standard local search methods like 2-opt by focusing on value-weighted flips and controlled randomness.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: Flip items based on marginal contribution and diversity\n    new_solution = base_solution.copy()\n\n    # Step 1: Identify items with high marginal contribution (value/weight ratio)\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Step 2: Flip items with high marginal contribution if feasible\n    for i in np.argsort(-combined_marginal):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Step 3: Randomly flip additional items to explore diversity\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 9,
        "algorithm": "The algorithm selects the most promising solution from the archive based on combined marginal value (sum of normalized value1 and value2 per unit weight), then applies a two-phase local search: first flipping items with highest marginal contributions (sorted by combined value) to maximize value, followed by controlled random flips to introduce diversity while ensuring feasibility. The first phase prioritizes high-value items, while the second adds exploration through probabilistic flips.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    marginal_values = []\n    for sol, _ in archive:\n        current_weight = np.sum(weight_lst * sol)\n        marginal_value1 = np.sum(value1_lst * sol) / (current_weight + 1e-10)\n        marginal_value2 = np.sum(value2_lst * sol) / (current_weight + 1e-10)\n        marginal_values.append(marginal_value1 + marginal_value2)\n    selected_idx = np.argmax(marginal_values)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: Flip items based on value-weighted bias and controlled randomness\n    new_solution = base_solution.copy()\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Step 1: Flip items with high marginal contribution if feasible\n    for i in np.argsort(-combined_marginal):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1 and (current_weight - weight_lst[i]) >= 0:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Step 2: Controlled random flip to introduce diversity\n    flip_prob = 0.2\n    for i in range(len(new_solution)):\n        if np.random.rand() < flip_prob:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n            elif new_solution[i] == 1 and (current_weight - weight_lst[i]) >= 0:\n                new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.35983047757157505,
            0.8351807594299316
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    marginal_values = []\n    for sol, _ in archive:\n        current_weight = np.sum(weight_lst * sol)\n        marginal_value1 = np.sum(value1_lst * sol) / (current_weight + 1e-10)\n        marginal_value2 = np.sum(value2_lst * sol) / (current_weight + 1e-10)\n        marginal_values.append(marginal_value1 + marginal_value2)\n    selected_idx = np.argmax(marginal_values)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: Flip items based on value-weighted bias and controlled randomness\n    new_solution = base_solution.copy()\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Step 1: Flip items with high marginal contribution if feasible\n    for i in np.argsort(-combined_marginal):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1 and (current_weight - weight_lst[i]) >= 0:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Step 2: Controlled random flip to introduce diversity\n    flip_prob = 0.2\n    for i in range(len(new_solution)):\n        if np.random.rand() < flip_prob:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n            elif new_solution[i] == 1 and (current_weight - weight_lst[i]) >= 0:\n                new_solution[i] = 0\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 3 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a random solution from the archive and performs a hybrid local search by swapping items with a focus on improving either objective while ensuring feasibility. It prioritizes swaps that increase at least one objective value and maintains the solution's weight within capacity. The method uses a value-to-weight ratio consideration to guide the swaps and limits the search to 10 attempts for efficiency.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: random swaps with value-to-weight ratio consideration\n    for _ in range(10):  # Number of attempts to find a feasible neighbor\n        # Select two random items\n        item1, item2 = np.random.choice(len(new_solution), size=2, replace=False)\n\n        # Calculate potential weight change\n        if new_solution[item1] == 1 and new_solution[item2] == 0:\n            delta_weight = weight_lst[item2] - weight_lst[item1]\n        elif new_solution[item1] == 0 and new_solution[item2] == 1:\n            delta_weight = weight_lst[item1] - weight_lst[item2]\n        else:\n            continue  # No change in weight\n\n        # Check feasibility\n        if current_weight + delta_weight <= capacity:\n            # Perform swap if it improves at least one objective\n            value1_delta = (value1_lst[item1] - value1_lst[item2]) if new_solution[item1] == 1 else (value1_lst[item2] - value1_lst[item1])\n            value2_delta = (value2_lst[item1] - value2_lst[item2]) if new_solution[item1] == 1 else (value2_lst[item2] - value2_lst[item1])\n\n            if value1_delta > 0 or value2_delta > 0:\n                new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n                current_weight += delta_weight\n                break\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a random solution from the archive and applies a hybrid local search strategy that prioritizes items with high marginal value (combined from both objectives) while ensuring feasibility, followed by random flips to explore diversity. It balances exploitation (targeting high-value items) with exploration (random perturbations) to generate improved neighbor solutions. The approach avoids standard local search methods like 2-opt by focusing on value-weighted flips and controlled randomness.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: Flip items based on marginal contribution and diversity\n    new_solution = base_solution.copy()\n\n    # Step 1: Identify items with high marginal contribution (value/weight ratio)\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Step 2: Flip items with high marginal contribution if feasible\n    for i in np.argsort(-combined_marginal):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Step 3: Randomly flip additional items to explore diversity\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: ### Ineffective Self-Reflection\n- **Keywords**: Randomness, marginal value, objective dominance, neighborhood diversity.\n- **Advice**: Prioritize solutions with high combined objective scores but ensure perturbation is targeted (e.g., flip items with marginal gains in one objective while preserving feasibility).\n- **Avoid**: Overly aggressive flipping (e.g., flipping all items) or excessive randomness that disrupts progress.\n- **Explanation**: Balancing exploitation (marginal gains) and exploration (controlled perturbation) prevents stagnation while ensuring feasibility. Aggressive methods risk losing gains from local improvements.\n\n### Next Steps\n1. **Selection**: Rank solutions by normalized sum of objectives and select top 20%.\n2. **Local Search**: Flip items with highest marginal gain in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Validation**: Reject neighbors violating capacity; repeat until valid neighbor found.\n4. **Iteration**: Repeat for 5-10 iterations per solution to refine the archive.\n\nThis avoids pure randomness or greediness while ensuring progress.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 10,
        "algorithm": "The algorithm selects top-performing solutions (top 20%) from the archive based on normalized objective sums, then applies a targeted local search prioritizing items with high marginal gains in either objective, followed by 1-2 random flips to maintain diversity while ensuring feasibility. It first evaluates items by their marginal gains (value-to-weight ratio) for both objectives, flipping the most promising ones, and then introduces randomness to escape local optima. The solution always remains feasible by checking weight constraints before each flip.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.choice(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for each objective\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Flip items with highest marginal gains in either objective\n    for i in np.argsort(-np.maximum(marginal_gain1, marginal_gain2)):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1 and (current_weight - weight_lst[i]) <= capacity:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Add 1-2 random flips to maintain diversity\n    flip_indices = np.random.choice(len(new_solution), size=np.random.randint(1, 3), replace=False)\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1 and (current_weight - weight_lst[i]) <= capacity:\n            new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.7693802282111715,
            0.48120638728141785
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.choice(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for each objective\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Flip items with highest marginal gains in either objective\n    for i in np.argsort(-np.maximum(marginal_gain1, marginal_gain2)):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1 and (current_weight - weight_lst[i]) <= capacity:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Add 1-2 random flips to maintain diversity\n    flip_indices = np.random.choice(len(new_solution), size=np.random.randint(1, 3), replace=False)\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1 and (current_weight - weight_lst[i]) <= capacity:\n            new_solution[i] = 0\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm dynamically selects a solution from the archive based on a weighted combination of objective values (prioritizing one objective more when its variance is higher), then applies a value-weighted flip strategy with adaptive randomness to generate a neighbor. It also incorporates crowding-aware perturbations to balance exploration and exploitation while ensuring feasibility. The key design ideas are: dynamic objective weighting, adaptive marginal value-based flips, and crowding-aware perturbations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    obj1_weights = np.array([obj[0] for _, obj in archive])\n    obj2_weights = np.array([obj[1] for _, obj in archive])\n    obj1_std = np.std(obj1_weights)\n    obj2_std = np.std(obj2_weights)\n    alpha = obj2_std / (obj1_std + obj2_std + 1e-10)  # Weighting factor\n\n    # Select solution with highest weighted score\n    scores = alpha * obj1_weights + (1 - alpha) * obj2_weights\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate adaptive marginal values\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = (alpha * marginal_value1 + (1 - alpha) * marginal_value2) / (1 + 0.1 * np.random.rand(len(weight_lst)))\n\n    # Flip items based on adaptive marginal values\n    new_solution = base_solution.copy()\n    for i in np.argsort(-combined_marginal):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Crowding-aware perturbation\n    if len(archive) > 1:\n        distances = np.zeros(len(archive))\n        for i, (sol, _) in enumerate(archive):\n            distances[i] = np.sum(np.abs(sol - new_solution))\n        min_dist_idx = np.argmin(distances)\n        if min_dist_idx != selected_idx:\n            crowding_factor = 1 - distances[min_dist_idx] / (np.sum(distances) + 1e-10)\n            perturb_indices = np.random.choice(len(new_solution), size=int(crowding_factor * len(new_solution)), replace=False)\n            for i in perturb_indices:\n                if np.random.rand() < 0.3:  # 30% chance to flip\n                    if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                        new_solution[i] = 1\n                    elif new_solution[i] == 1:\n                        new_solution[i] = 0\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### Ineffective Self-Reflection\n- **Keywords**: Randomness, marginal value, objective dominance, neighborhood diversity.\n- **Advice**: Prioritize solutions with high combined objective scores but ensure perturbation is targeted (e.g., flip items with marginal gains in one objective while preserving feasibility).\n- **Avoid**: Overly aggressive flipping (e.g., flipping all items) or excessive randomness that disrupts progress.\n- **Explanation**: Balancing exploitation (marginal gains) and exploration (controlled perturbation) prevents stagnation while ensuring feasibility. Aggressive methods risk losing gains from local improvements.\n\n### Next Steps\n1. **Selection**: Rank solutions by normalized sum of objectives and select top 20%.\n2. **Local Search**: Flip items with highest marginal gain in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Validation**: Reject neighbors violating capacity; repeat until valid neighbor found.\n4. **Iteration**: Repeat for 5-10 iterations per solution to refine the archive.\n\nThis avoids pure randomness or greediness while ensuring progress.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 11,
        "algorithm": "The algorithm selects top 20% solutions from the archive based on normalized objective scores, prioritizes less-dominant objectives for flipping items, and performs random flips on low-contribution items to escape local optima while ensuring feasibility. It uses crowding distance to balance diversity and exploitation, and validates feasibility through weighted random removal of excess items. The two-phase approach first improves marginal contributions and then introduces randomness for better exploration.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n\n        # Select solution with probability inversely proportional to crowding distance\n        crowding_distances = []\n        for idx in top_indices:\n            sol = archive[idx][0]\n            distances = [np.sum(np.abs(sol - other_sol)) for other_sol, _ in archive if other_sol is not sol]\n            crowding_distances.append(np.mean(distances) if distances else 1)\n        inv_distances = [1/(d+1e-10) for d in crowding_distances]\n        selected_local_idx = np.random.choice(len(top_indices), p=np.array(inv_distances)/np.sum(inv_distances))\n        selected_idx = top_indices[selected_local_idx]\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Flip items with highest marginal contribution to less dominant objective\n    obj1, obj2 = archive[selected_idx][1]\n    less_dominant = 1 if obj1 > obj2 else 2\n    marginal_values = value1_lst if less_dominant == 1 else value2_lst\n    marginal_contribution = marginal_values / (weight_lst + 1e-10)\n\n    for i in np.argsort(-marginal_contribution):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Phase 2: Random flips on low marginal contribution items (1-2 flips)\n    low_contrib_mask = (value1_lst + value2_lst) / (weight_lst + 1e-10) < np.percentile((value1_lst + value2_lst)/(weight_lst + 1e-10), 30)\n    low_contrib_indices = np.where(low_contrib_mask)[0]\n    np.random.shuffle(low_contrib_indices)\n    for i in low_contrib_indices[:np.random.randint(1, 3)]:\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif base_solution[i] == 1:\n            new_solution[i] = 0\n\n    # Validate feasibility\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess = np.sum(weight_lst * new_solution) - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        if len(excess_items) == 0:\n            break\n        remove_idx = np.random.choice(excess_items)\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.6433115363420745,
            1.4424501955509186
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n\n        # Select solution with probability inversely proportional to crowding distance\n        crowding_distances = []\n        for idx in top_indices:\n            sol = archive[idx][0]\n            distances = [np.sum(np.abs(sol - other_sol)) for other_sol, _ in archive if other_sol is not sol]\n            crowding_distances.append(np.mean(distances) if distances else 1)\n        inv_distances = [1/(d+1e-10) for d in crowding_distances]\n        selected_local_idx = np.random.choice(len(top_indices), p=np.array(inv_distances)/np.sum(inv_distances))\n        selected_idx = top_indices[selected_local_idx]\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Flip items with highest marginal contribution to less dominant objective\n    obj1, obj2 = archive[selected_idx][1]\n    less_dominant = 1 if obj1 > obj2 else 2\n    marginal_values = value1_lst if less_dominant == 1 else value2_lst\n    marginal_contribution = marginal_values / (weight_lst + 1e-10)\n\n    for i in np.argsort(-marginal_contribution):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Phase 2: Random flips on low marginal contribution items (1-2 flips)\n    low_contrib_mask = (value1_lst + value2_lst) / (weight_lst + 1e-10) < np.percentile((value1_lst + value2_lst)/(weight_lst + 1e-10), 30)\n    low_contrib_indices = np.where(low_contrib_mask)[0]\n    np.random.shuffle(low_contrib_indices)\n    for i in low_contrib_indices[:np.random.randint(1, 3)]:\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif base_solution[i] == 1:\n            new_solution[i] = 0\n\n    # Validate feasibility\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess = np.sum(weight_lst * new_solution) - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        if len(excess_items) == 0:\n            break\n        remove_idx = np.random.choice(excess_items)\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a random solution from the archive, applies a hybrid local search by flipping a small random subset of items (with feasibility checks), and then performs a greedy improvement step to add items that improve at least one objective. The design prioritizes diversity and local optimization while ensuring feasibility, using a combination of randomness and greedy selection to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    import random\n    import numpy as np\n\n    # Select a promising solution from the archive (here, we select a random one for diversity)\n    selected_solution, _ = random.choice(archive)\n    new_solution = selected_solution.copy()\n\n    # Apply a hybrid local search: flip a random subset of items and then perform a greedy improvement\n    num_items = len(new_solution)\n    flip_indices = random.sample(range(num_items), min(3, num_items))  # Flip up to 3 random items\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            # Only flip to 1 if it doesn't exceed capacity\n            current_weight = np.sum(new_solution * weight_lst)\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Greedy improvement: try to add items that improve at least one objective\n    for idx in range(num_items):\n        if new_solution[idx] == 0:\n            current_weight = np.sum(new_solution * weight_lst)\n            if current_weight + weight_lst[idx] <= capacity:\n                # Simulate adding the item\n                temp_solution = new_solution.copy()\n                temp_solution[idx] = 1\n                temp_value1 = np.sum(temp_solution * value1_lst)\n                temp_value2 = np.sum(temp_solution * value2_lst)\n                current_value1 = np.sum(new_solution * value1_lst)\n                current_value2 = np.sum(new_solution * value2_lst)\n\n                # Accept if at least one objective improves\n                if (temp_value1 > current_value1) or (temp_value2 > current_value2):\n                    new_solution[idx] = 1\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### Ineffective Self-Reflection\n- **Keywords**: Randomness, marginal value, objective dominance, neighborhood diversity.\n- **Advice**: Prioritize solutions with high combined objective scores but ensure perturbation is targeted (e.g., flip items with marginal gains in one objective while preserving feasibility).\n- **Avoid**: Overly aggressive flipping (e.g., flipping all items) or excessive randomness that disrupts progress.\n- **Explanation**: Balancing exploitation (marginal gains) and exploration (controlled perturbation) prevents stagnation while ensuring feasibility. Aggressive methods risk losing gains from local improvements.\n\n### Next Steps\n1. **Selection**: Rank solutions by normalized sum of objectives and select top 20%.\n2. **Local Search**: Flip items with highest marginal gain in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Validation**: Reject neighbors violating capacity; repeat until valid neighbor found.\n4. **Iteration**: Repeat for 5-10 iterations per solution to refine the archive.\n\nThis avoids pure randomness or greediness while ensuring progress.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 12,
        "algorithm": "The algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7809195178124401,
            1.0582151114940643
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 13,
        "algorithm": "The algorithm selects a high-performing solution from the archive by prioritizing those with normalized objective values, then applies a hybrid local search combining adaptive bit-flipping (prioritizing high value-to-weight ratio items), probabilistic value-based perturbations (removing low-value, high-weight items), and dynamic weight adjustments (temporarily scaling weights for exploration), ensuring feasibility by strict capacity checks at each step. The approach balances exploitation (value optimization) and exploration (perturbations) while maintaining solution feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with high normalized objective values\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive bit-flipping based on value-to-weight ratio\n    value_ratio = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(value_ratio)[::-1]  # Highest ratio first\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Value-based perturbation: flip items with low value but high weight\n    if np.random.rand() < 0.4:\n        low_value_high_weight = (value1_lst < np.median(value1_lst)) & (value2_lst < np.median(value2_lst)) & (weight_lst > np.median(weight_lst))\n        perturb_indices = np.where(low_value_high_weight)[0]\n        for idx in perturb_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Dynamic weight adjustment: scale weights temporarily for perturbation\n    if np.random.rand() < 0.3:\n        temp_weights = weight_lst * (1 + 0.1 * np.random.randn(n_items))\n        for idx in np.random.choice(n_items, size=min(3, n_items), replace=False):\n            if base_solution[idx] == 0 and current_weight + temp_weights[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += temp_weights[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8304688143210642,
            0.25333505868911743
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with high normalized objective values\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive bit-flipping based on value-to-weight ratio\n    value_ratio = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(value_ratio)[::-1]  # Highest ratio first\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Value-based perturbation: flip items with low value but high weight\n    if np.random.rand() < 0.4:\n        low_value_high_weight = (value1_lst < np.median(value1_lst)) & (value2_lst < np.median(value2_lst)) & (weight_lst > np.median(weight_lst))\n        perturb_indices = np.where(low_value_high_weight)[0]\n        for idx in perturb_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Dynamic weight adjustment: scale weights temporarily for perturbation\n    if np.random.rand() < 0.3:\n        temp_weights = weight_lst * (1 + 0.1 * np.random.randn(n_items))\n        for idx in np.random.choice(n_items, size=min(3, n_items), replace=False):\n            if base_solution[idx] == 0 and current_weight + temp_weights[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += temp_weights[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 13,
        "algorithm": "The algorithm selects a high-performing solution from the archive by prioritizing those with normalized objective values, then applies a hybrid local search combining adaptive bit-flipping (prioritizing high value-to-weight ratio items), probabilistic value-based perturbations (removing low-value, high-weight items), and dynamic weight adjustments (temporarily scaling weights for exploration), ensuring feasibility by strict capacity checks at each step. The approach balances exploitation (value optimization) and exploration (perturbations) while maintaining solution feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with high normalized objective values\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive bit-flipping based on value-to-weight ratio\n    value_ratio = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(value_ratio)[::-1]  # Highest ratio first\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Value-based perturbation: flip items with low value but high weight\n    if np.random.rand() < 0.4:\n        low_value_high_weight = (value1_lst < np.median(value1_lst)) & (value2_lst < np.median(value2_lst)) & (weight_lst > np.median(weight_lst))\n        perturb_indices = np.where(low_value_high_weight)[0]\n        for idx in perturb_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Dynamic weight adjustment: scale weights temporarily for perturbation\n    if np.random.rand() < 0.3:\n        temp_weights = weight_lst * (1 + 0.1 * np.random.randn(n_items))\n        for idx in np.random.choice(n_items, size=min(3, n_items), replace=False):\n            if base_solution[idx] == 0 and current_weight + temp_weights[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += temp_weights[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8304688143210642,
            0.25333505868911743
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with high normalized objective values\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive bit-flipping based on value-to-weight ratio\n    value_ratio = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(value_ratio)[::-1]  # Highest ratio first\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Value-based perturbation: flip items with low value but high weight\n    if np.random.rand() < 0.4:\n        low_value_high_weight = (value1_lst < np.median(value1_lst)) & (value2_lst < np.median(value2_lst)) & (weight_lst > np.median(weight_lst))\n        perturb_indices = np.where(low_value_high_weight)[0]\n        for idx in perturb_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Dynamic weight adjustment: scale weights temporarily for perturbation\n    if np.random.rand() < 0.3:\n        temp_weights = weight_lst * (1 + 0.1 * np.random.randn(n_items))\n        for idx in np.random.choice(n_items, size=min(3, n_items), replace=False):\n            if base_solution[idx] == 0 and current_weight + temp_weights[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += temp_weights[idx]\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 14,
        "algorithm": "The algorithm selects a promising solution from the archive based on normalized objective product scores, then applies a hybrid local search that first prioritizes high-marginal-contribution items for targeted bit-flips and occasionally perturbs low-contribution items with stochastic probability to escape local optima while maintaining feasibility. It balances exploitation (high-contribution items) with exploration (low-contribution perturbations) to improve both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives using product to favor balanced solutions\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: targeted bit-flipping with stochastic perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Targeted bit-flip - prioritize high-marginal-contribution items\n    marginal_contribution = (value1_lst + value2_lst) / weight_lst\n    high_contrib_indices = np.argsort(marginal_contribution)[-max(1, n_items // 3):]\n    for idx in high_contrib_indices:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 2: Stochastic perturbation - flip low-contribution items with probability\n    low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n    for idx in low_contrib_indices:\n        if np.random.rand() < 0.2:  # 20% chance per low-contribution item\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.49723235786746045,
            0.3195430338382721
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives using product to favor balanced solutions\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: targeted bit-flipping with stochastic perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Targeted bit-flip - prioritize high-marginal-contribution items\n    marginal_contribution = (value1_lst + value2_lst) / weight_lst\n    high_contrib_indices = np.argsort(marginal_contribution)[-max(1, n_items // 3):]\n    for idx in high_contrib_indices:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 2: Stochastic perturbation - flip low-contribution items with probability\n    low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n    for idx in low_contrib_indices:\n        if np.random.rand() < 0.2:  # 20% chance per low-contribution item\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 5 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a random solution from the archive and performs a hybrid local search by swapping items with a focus on improving either objective while ensuring feasibility. It prioritizes swaps that increase at least one objective value and maintains the solution's weight within capacity. The method uses a value-to-weight ratio consideration to guide the swaps and limits the search to 10 attempts for efficiency.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: random swaps with value-to-weight ratio consideration\n    for _ in range(10):  # Number of attempts to find a feasible neighbor\n        # Select two random items\n        item1, item2 = np.random.choice(len(new_solution), size=2, replace=False)\n\n        # Calculate potential weight change\n        if new_solution[item1] == 1 and new_solution[item2] == 0:\n            delta_weight = weight_lst[item2] - weight_lst[item1]\n        elif new_solution[item1] == 0 and new_solution[item2] == 1:\n            delta_weight = weight_lst[item1] - weight_lst[item2]\n        else:\n            continue  # No change in weight\n\n        # Check feasibility\n        if current_weight + delta_weight <= capacity:\n            # Perform swap if it improves at least one objective\n            value1_delta = (value1_lst[item1] - value1_lst[item2]) if new_solution[item1] == 1 else (value1_lst[item2] - value1_lst[item1])\n            value2_delta = (value2_lst[item1] - value2_lst[item2]) if new_solution[item1] == 1 else (value2_lst[item2] - value2_lst[item1])\n\n            if value1_delta > 0 or value2_delta > 0:\n                new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n                current_weight += delta_weight\n                break\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a random solution from the archive and applies a hybrid local search strategy that prioritizes items with high marginal value (combined from both objectives) while ensuring feasibility, followed by random flips to explore diversity. It balances exploitation (targeting high-value items) with exploration (random perturbations) to generate improved neighbor solutions. The approach avoids standard local search methods like 2-opt by focusing on value-weighted flips and controlled randomness.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: Flip items based on marginal contribution and diversity\n    new_solution = base_solution.copy()\n\n    # Step 1: Identify items with high marginal contribution (value/weight ratio)\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Step 2: Flip items with high marginal contribution if feasible\n    for i in np.argsort(-combined_marginal):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Step 3: Randomly flip additional items to explore diversity\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with potential for improvement (items that can be added without exceeding capacity), then applies a hybrid approach combining value-weighted greedy selection (prioritizing items with highest combined marginal value) and adaptive random perturbations (flipping items probabilistically, with flip probability adjusted based on archive diversity). Finally, it ensures feasibility through greedy backtracking by removing low-marginal-value items if the weight exceeds capacity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    import random\n    import numpy as np\n\n    # Select a solution with potential for improvement by considering both value and archive diversity\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(sol * weight_lst)\n        remaining_capacity = capacity - current_weight\n        potential_items = np.where((sol == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(potential_items) > 0:\n            candidates.append(sol)\n\n    if not candidates:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        selected_solution = random.choice(candidates).copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Step 1: Value-weighted greedy selection\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    for i in np.argsort(-combined_marginal):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    # Step 2: Adaptive random perturbation based on solution quality\n    num_items = len(new_solution)\n    flip_prob = 0.3  # Base flip probability\n    if len(archive) > 1:\n        # Adjust flip probability based on archive diversity\n        archive_weights = np.array([sol[0] for sol, _ in archive])\n        diversity = np.mean(np.std(archive_weights, axis=0))\n        flip_prob = min(0.5, flip_prob + 0.2 * diversity)\n\n    flip_indices = [i for i in range(num_items) if random.random() < flip_prob]\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    # Step 3: Greedy backtracking to maintain feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess_weight = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest marginal value contribution\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        remove_idx = removable_items[np.argmin(marginal_contrib[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm selects top-performing solutions (top 20%) from the archive based on normalized objective sums, then applies a targeted local search prioritizing items with high marginal gains in either objective, followed by 1-2 random flips to maintain diversity while ensuring feasibility. It first evaluates items by their marginal gains (value-to-weight ratio) for both objectives, flipping the most promising ones, and then introduces randomness to escape local optima. The solution always remains feasible by checking weight constraints before each flip.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.choice(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for each objective\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Flip items with highest marginal gains in either objective\n    for i in np.argsort(-np.maximum(marginal_gain1, marginal_gain2)):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1 and (current_weight - weight_lst[i]) <= capacity:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Add 1-2 random flips to maintain diversity\n    flip_indices = np.random.choice(len(new_solution), size=np.random.randint(1, 3), replace=False)\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1 and (current_weight - weight_lst[i]) <= capacity:\n            new_solution[i] = 0\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: ### Keywords:\n- **Adaptive perturbation**, **marginal gain**, **feasibility**, **diversity preservation**.\n\n### Advice:\n- **Prioritize** solutions with high normalized objective sums but **dynamically adjust** perturbation intensity (e.g., flip top 10% marginal items + 1-2 random flips).\n- **Ensure feasibility** by validating weight constraints after each flip.\n\n### Avoid:\n- **Excessive randomness** (e.g., flipping all items) or **greedy backtracking** that ignores other objectives.\n\n### Explanation:\nBalancing **targeted marginal gains** and **controlled randomness** ensures progress while preventing stagnation. Adaptive perturbation maintains archive diversity, and feasibility checks preserve solution quality.\n\n*(Word count: ~90)*\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 15,
        "algorithm": "The algorithm selects promising solutions from the archive (top 20% by normalized objective sum) and applies a hybrid local search prioritizing items with high marginal gains in either objective, while ensuring feasibility. It then performs adaptive random flips to escape local optima, with flip probability dynamically adjusted based on archive diversity. The key design choices emphasize marginal gain prioritization and diversity-aware exploration.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.choice(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for each objective\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Flip items with highest marginal gains in either objective\n    for i in np.argsort(-np.maximum(marginal_gain1, marginal_gain2)):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1 and (current_weight - weight_lst[i]) <= capacity:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Adaptive random flips based on archive diversity\n    flip_prob = 0.3\n    if len(archive) > 1:\n        archive_weights = np.array([sol[0] for sol, _ in archive])\n        diversity = np.mean(np.std(archive_weights, axis=0))\n        flip_prob = min(0.5, flip_prob + 0.2 * diversity)\n\n    flip_indices = [i for i in range(len(new_solution)) if np.random.rand() < flip_prob]\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1 and (current_weight - weight_lst[i]) <= capacity:\n            new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.36219431459395346,
            0.723431408405304
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.choice(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for each objective\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Flip items with highest marginal gains in either objective\n    for i in np.argsort(-np.maximum(marginal_gain1, marginal_gain2)):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1 and (current_weight - weight_lst[i]) <= capacity:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Adaptive random flips based on archive diversity\n    flip_prob = 0.3\n    if len(archive) > 1:\n        archive_weights = np.array([sol[0] for sol, _ in archive])\n        diversity = np.mean(np.std(archive_weights, axis=0))\n        flip_prob = min(0.5, flip_prob + 0.2 * diversity)\n\n    flip_indices = [i for i in range(len(new_solution)) if np.random.rand() < flip_prob]\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1 and (current_weight - weight_lst[i]) <= capacity:\n            new_solution[i] = 0\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects top-performing solutions (top 20%) from the archive based on normalized objective sums, then applies a targeted local search prioritizing items with high marginal gains in either objective, followed by 1-2 random flips to maintain diversity while ensuring feasibility. It first evaluates items by their marginal gains (value-to-weight ratio) for both objectives, flipping the most promising ones, and then introduces randomness to escape local optima. The solution always remains feasible by checking weight constraints before each flip.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.choice(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for each objective\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Flip items with highest marginal gains in either objective\n    for i in np.argsort(-np.maximum(marginal_gain1, marginal_gain2)):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1 and (current_weight - weight_lst[i]) <= capacity:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Add 1-2 random flips to maintain diversity\n    flip_indices = np.random.choice(len(new_solution), size=np.random.randint(1, 3), replace=False)\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1 and (current_weight - weight_lst[i]) <= capacity:\n            new_solution[i] = 0\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a random solution from the archive and performs a hybrid local search by swapping items with a focus on improving either objective while ensuring feasibility. It prioritizes swaps that increase at least one objective value and maintains the solution's weight within capacity. The method uses a value-to-weight ratio consideration to guide the swaps and limits the search to 10 attempts for efficiency.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: random swaps with value-to-weight ratio consideration\n    for _ in range(10):  # Number of attempts to find a feasible neighbor\n        # Select two random items\n        item1, item2 = np.random.choice(len(new_solution), size=2, replace=False)\n\n        # Calculate potential weight change\n        if new_solution[item1] == 1 and new_solution[item2] == 0:\n            delta_weight = weight_lst[item2] - weight_lst[item1]\n        elif new_solution[item1] == 0 and new_solution[item2] == 1:\n            delta_weight = weight_lst[item1] - weight_lst[item2]\n        else:\n            continue  # No change in weight\n\n        # Check feasibility\n        if current_weight + delta_weight <= capacity:\n            # Perform swap if it improves at least one objective\n            value1_delta = (value1_lst[item1] - value1_lst[item2]) if new_solution[item1] == 1 else (value1_lst[item2] - value1_lst[item1])\n            value2_delta = (value2_lst[item1] - value2_lst[item2]) if new_solution[item1] == 1 else (value2_lst[item2] - value2_lst[item1])\n\n            if value1_delta > 0 or value2_delta > 0:\n                new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n                current_weight += delta_weight\n                break\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### Keywords:\n- **Adaptive perturbation**, **marginal gain**, **feasibility**, **diversity preservation**.\n\n### Advice:\n- **Prioritize** solutions with high normalized objective sums but **dynamically adjust** perturbation intensity (e.g., flip top 10% marginal items + 1-2 random flips).\n- **Ensure feasibility** by validating weight constraints after each flip.\n\n### Avoid:\n- **Excessive randomness** (e.g., flipping all items) or **greedy backtracking** that ignores other objectives.\n\n### Explanation:\nBalancing **targeted marginal gains** and **controlled randomness** ensures progress while preventing stagnation. Adaptive perturbation maintains archive diversity, and feasibility checks preserve solution quality.\n\n*(Word count: ~90)*\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 16,
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with high normalized objective scores, then performs a multi-phase local search: first flipping items with highest combined marginal gains for both objectives, followed by adaptive perturbations based on individual objective marginal gains, and finally a controlled random flip to escape local optima while maintaining feasibility. The solution is always kept feasible by checking weight constraints before each flip operation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.choice(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate combined marginal gains\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Flip items with highest combined marginal gains first\n    flip_order = np.argsort(-combined_gain)\n    for i in flip_order:\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1 and (current_weight - weight_lst[i]) <= capacity:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Adaptive perturbation: flip items with high marginal gains in either objective\n    for i in np.argsort(-np.maximum(marginal_gain1, marginal_gain2)):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif new_solution[i] == 1 and (current_weight - weight_lst[i]) <= capacity:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Controlled random flip to maintain diversity\n    if np.random.rand() < 0.3:  # 30% chance of random flip\n        candidates = np.where(new_solution == 0)[0] if np.random.rand() < 0.5 else np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            flip_idx = np.random.choice(candidates)\n            if new_solution[flip_idx] == 0 and (current_weight + weight_lst[flip_idx]) <= capacity:\n                new_solution[flip_idx] = 1\n            elif new_solution[flip_idx] == 1 and (current_weight - weight_lst[flip_idx]) <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.4792512680051688,
            0.7443999350070953
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.choice(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate combined marginal gains\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Flip items with highest combined marginal gains first\n    flip_order = np.argsort(-combined_gain)\n    for i in flip_order:\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1 and (current_weight - weight_lst[i]) <= capacity:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Adaptive perturbation: flip items with high marginal gains in either objective\n    for i in np.argsort(-np.maximum(marginal_gain1, marginal_gain2)):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif new_solution[i] == 1 and (current_weight - weight_lst[i]) <= capacity:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Controlled random flip to maintain diversity\n    if np.random.rand() < 0.3:  # 30% chance of random flip\n        candidates = np.where(new_solution == 0)[0] if np.random.rand() < 0.5 else np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            flip_idx = np.random.choice(candidates)\n            if new_solution[flip_idx] == 0 and (current_weight + weight_lst[flip_idx]) <= capacity:\n                new_solution[flip_idx] = 1\n            elif new_solution[flip_idx] == 1 and (current_weight - weight_lst[flip_idx]) <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a random solution from the archive and performs a hybrid local search by swapping items with a focus on improving either objective while ensuring feasibility. It prioritizes swaps that increase at least one objective value and maintains the solution's weight within capacity. The method uses a value-to-weight ratio consideration to guide the swaps and limits the search to 10 attempts for efficiency.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: random swaps with value-to-weight ratio consideration\n    for _ in range(10):  # Number of attempts to find a feasible neighbor\n        # Select two random items\n        item1, item2 = np.random.choice(len(new_solution), size=2, replace=False)\n\n        # Calculate potential weight change\n        if new_solution[item1] == 1 and new_solution[item2] == 0:\n            delta_weight = weight_lst[item2] - weight_lst[item1]\n        elif new_solution[item1] == 0 and new_solution[item2] == 1:\n            delta_weight = weight_lst[item1] - weight_lst[item2]\n        else:\n            continue  # No change in weight\n\n        # Check feasibility\n        if current_weight + delta_weight <= capacity:\n            # Perform swap if it improves at least one objective\n            value1_delta = (value1_lst[item1] - value1_lst[item2]) if new_solution[item1] == 1 else (value1_lst[item2] - value1_lst[item1])\n            value2_delta = (value2_lst[item1] - value2_lst[item2]) if new_solution[item1] == 1 else (value2_lst[item2] - value2_lst[item1])\n\n            if value1_delta > 0 or value2_delta > 0:\n                new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n                current_weight += delta_weight\n                break\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### Keywords:\n- **Adaptive perturbation**, **marginal gain**, **feasibility**, **diversity preservation**.\n\n### Advice:\n- **Prioritize** solutions with high normalized objective sums but **dynamically adjust** perturbation intensity (e.g., flip top 10% marginal items + 1-2 random flips).\n- **Ensure feasibility** by validating weight constraints after each flip.\n\n### Avoid:\n- **Excessive randomness** (e.g., flipping all items) or **greedy backtracking** that ignores other objectives.\n\n### Explanation:\nBalancing **targeted marginal gains** and **controlled randomness** ensures progress while preventing stagnation. Adaptive perturbation maintains archive diversity, and feasibility checks preserve solution quality.\n\n*(Word count: ~90)*\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 17,
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7633290724762323,
            0.17913395166397095
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a random solution from the archive and performs a hybrid local search by swapping items with a focus on improving either objective while ensuring feasibility. It prioritizes swaps that increase at least one objective value and maintains the solution's weight within capacity. The method uses a value-to-weight ratio consideration to guide the swaps and limits the search to 10 attempts for efficiency.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: random swaps with value-to-weight ratio consideration\n    for _ in range(10):  # Number of attempts to find a feasible neighbor\n        # Select two random items\n        item1, item2 = np.random.choice(len(new_solution), size=2, replace=False)\n\n        # Calculate potential weight change\n        if new_solution[item1] == 1 and new_solution[item2] == 0:\n            delta_weight = weight_lst[item2] - weight_lst[item1]\n        elif new_solution[item1] == 0 and new_solution[item2] == 1:\n            delta_weight = weight_lst[item1] - weight_lst[item2]\n        else:\n            continue  # No change in weight\n\n        # Check feasibility\n        if current_weight + delta_weight <= capacity:\n            # Perform swap if it improves at least one objective\n            value1_delta = (value1_lst[item1] - value1_lst[item2]) if new_solution[item1] == 1 else (value1_lst[item2] - value1_lst[item1])\n            value2_delta = (value2_lst[item1] - value2_lst[item2]) if new_solution[item1] == 1 else (value2_lst[item2] - value2_lst[item1])\n\n            if value1_delta > 0 or value2_delta > 0:\n                new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n                current_weight += delta_weight\n                break\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### Keywords:\n- **Adaptive perturbation**, **marginal gain**, **feasibility**, **diversity preservation**.\n\n### Advice:\n- **Prioritize** solutions with high normalized objective sums but **dynamically adjust** perturbation intensity (e.g., flip top 10% marginal items + 1-2 random flips).\n- **Ensure feasibility** by validating weight constraints after each flip.\n\n### Avoid:\n- **Excessive randomness** (e.g., flipping all items) or **greedy backtracking** that ignores other objectives.\n\n### Explanation:\nBalancing **targeted marginal gains** and **controlled randomness** ensures progress while preventing stagnation. Adaptive perturbation maintains archive diversity, and feasibility checks preserve solution quality.\n\n*(Word count: ~90)*\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 17,
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7633290724762323,
            0.17913395166397095
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a random solution from the archive and performs a hybrid local search by swapping items with a focus on improving either objective while ensuring feasibility. It prioritizes swaps that increase at least one objective value and maintains the solution's weight within capacity. The method uses a value-to-weight ratio consideration to guide the swaps and limits the search to 10 attempts for efficiency.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: random swaps with value-to-weight ratio consideration\n    for _ in range(10):  # Number of attempts to find a feasible neighbor\n        # Select two random items\n        item1, item2 = np.random.choice(len(new_solution), size=2, replace=False)\n\n        # Calculate potential weight change\n        if new_solution[item1] == 1 and new_solution[item2] == 0:\n            delta_weight = weight_lst[item2] - weight_lst[item1]\n        elif new_solution[item1] == 0 and new_solution[item2] == 1:\n            delta_weight = weight_lst[item1] - weight_lst[item2]\n        else:\n            continue  # No change in weight\n\n        # Check feasibility\n        if current_weight + delta_weight <= capacity:\n            # Perform swap if it improves at least one objective\n            value1_delta = (value1_lst[item1] - value1_lst[item2]) if new_solution[item1] == 1 else (value1_lst[item2] - value1_lst[item1])\n            value2_delta = (value2_lst[item1] - value2_lst[item2]) if new_solution[item1] == 1 else (value2_lst[item2] - value2_lst[item1])\n\n            if value1_delta > 0 or value2_delta > 0:\n                new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n                current_weight += delta_weight\n                break\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 18,
        "algorithm": "This algorithm selects a promising solution from the archive using weighted random selection based on combined objective values, then performs a local search by iteratively replacing the least valuable item in the knapsack with a randomly chosen external item, ensuring feasibility and potentially improving both objectives. The method prioritizes items with lower combined values for removal and randomly explores additions to diversify the search while maintaining feasibility constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    objectives = np.array([obj[0] + obj[1] for _, obj in archive])\n    probabilities = objectives / np.sum(objectives)\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    current_value1 = np.sum(value1_lst[new_solution == 1])\n    current_value2 = np.sum(value2_lst[new_solution == 1])\n\n    # Get indices of items in and out of the knapsack\n    in_knapsack = np.where(new_solution == 1)[0]\n    out_knapsack = np.where(new_solution == 0)[0]\n\n    # Local search: replace least valuable items with promising external items\n    for _ in range(10):\n        if len(in_knapsack) == 0 or len(out_knapsack) == 0:\n            break\n\n        # Find least valuable item in knapsack (considering both objectives)\n        combined_values = value1_lst[in_knapsack] + value2_lst[in_knapsack]\n        least_val_idx = np.argmin(combined_values)\n        item_to_remove = in_knapsack[least_val_idx]\n\n        # Randomly select an item to add from outside\n        item_to_add = np.random.choice(out_knapsack)\n\n        # Calculate potential weight change\n        delta_weight = weight_lst[item_to_add] - weight_lst[item_to_remove]\n\n        # Check feasibility\n        if current_weight + delta_weight <= capacity:\n            # Perform replacement\n            new_solution[item_to_remove] = 0\n            new_solution[item_to_add] = 1\n            current_weight += delta_weight\n\n            # Update in/out knapsack indices\n            in_knapsack = np.where(new_solution == 1)[0]\n            out_knapsack = np.where(new_solution == 0)[0]\n\n    return new_solution\n\n",
        "score": [
            -0.3484379930971764,
            3.6669998466968536
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    objectives = np.array([obj[0] + obj[1] for _, obj in archive])\n    probabilities = objectives / np.sum(objectives)\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    current_value1 = np.sum(value1_lst[new_solution == 1])\n    current_value2 = np.sum(value2_lst[new_solution == 1])\n\n    # Get indices of items in and out of the knapsack\n    in_knapsack = np.where(new_solution == 1)[0]\n    out_knapsack = np.where(new_solution == 0)[0]\n\n    # Local search: replace least valuable items with promising external items\n    for _ in range(10):\n        if len(in_knapsack) == 0 or len(out_knapsack) == 0:\n            break\n\n        # Find least valuable item in knapsack (considering both objectives)\n        combined_values = value1_lst[in_knapsack] + value2_lst[in_knapsack]\n        least_val_idx = np.argmin(combined_values)\n        item_to_remove = in_knapsack[least_val_idx]\n\n        # Randomly select an item to add from outside\n        item_to_add = np.random.choice(out_knapsack)\n\n        # Calculate potential weight change\n        delta_weight = weight_lst[item_to_add] - weight_lst[item_to_remove]\n\n        # Check feasibility\n        if current_weight + delta_weight <= capacity:\n            # Perform replacement\n            new_solution[item_to_remove] = 0\n            new_solution[item_to_add] = 1\n            current_weight += delta_weight\n\n            # Update in/out knapsack indices\n            in_knapsack = np.where(new_solution == 1)[0]\n            out_knapsack = np.where(new_solution == 0)[0]\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a random solution from the archive and performs a hybrid local search by swapping items with a focus on improving either objective while ensuring feasibility. It prioritizes swaps that increase at least one objective value and maintains the solution's weight within capacity. The method uses a value-to-weight ratio consideration to guide the swaps and limits the search to 10 attempts for efficiency.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: random swaps with value-to-weight ratio consideration\n    for _ in range(10):  # Number of attempts to find a feasible neighbor\n        # Select two random items\n        item1, item2 = np.random.choice(len(new_solution), size=2, replace=False)\n\n        # Calculate potential weight change\n        if new_solution[item1] == 1 and new_solution[item2] == 0:\n            delta_weight = weight_lst[item2] - weight_lst[item1]\n        elif new_solution[item1] == 0 and new_solution[item2] == 1:\n            delta_weight = weight_lst[item1] - weight_lst[item2]\n        else:\n            continue  # No change in weight\n\n        # Check feasibility\n        if current_weight + delta_weight <= capacity:\n            # Perform swap if it improves at least one objective\n            value1_delta = (value1_lst[item1] - value1_lst[item2]) if new_solution[item1] == 1 else (value1_lst[item2] - value1_lst[item1])\n            value2_delta = (value2_lst[item1] - value2_lst[item2]) if new_solution[item1] == 1 else (value2_lst[item2] - value2_lst[item1])\n\n            if value1_delta > 0 or value2_delta > 0:\n                new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n                current_weight += delta_weight\n                break\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 19,
        "algorithm": "The algorithm selects a high-potential solution from the archive based on combined value-to-weight ratios, then performs a 3-opt local search to explore cyclic swaps among randomly chosen items while ensuring feasibility and potential objective improvements. It prioritizes solutions with better value-to-weight ratios and focuses on improving at least one objective through strategic item swaps.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    ratios = [(np.sum(value1_lst[sol[0] == 1]) + np.sum(value2_lst[sol[0] == 1])) / np.sum(weight_lst[sol[0] == 1]) for sol in archive]\n    selected_idx = np.argmax(ratios)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # 3-opt local search\n    for _ in range(5):  # Number of attempts\n        # Select three distinct random items\n        items = np.random.choice(len(new_solution), size=3, replace=False)\n\n        # Calculate potential weight change\n        current_items = new_solution[items]\n        new_items = np.roll(current_items, 1)  # Cyclic permutation\n\n        delta_weight = np.sum(weight_lst[items][new_items == 1] - weight_lst[items][current_items == 1])\n\n        # Check feasibility\n        if current_weight + delta_weight <= capacity:\n            # Perform swap if it improves at least one objective\n            delta_value1 = np.sum(value1_lst[items][new_items == 1] - value1_lst[items][current_items == 1])\n            delta_value2 = np.sum(value2_lst[items][new_items == 1] - value2_lst[items][current_items == 1])\n\n            if delta_value1 > 0 or delta_value2 > 0:\n                new_solution[items] = new_items\n                current_weight += delta_weight\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.47642275714622234,
            2.280549854040146
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    ratios = [(np.sum(value1_lst[sol[0] == 1]) + np.sum(value2_lst[sol[0] == 1])) / np.sum(weight_lst[sol[0] == 1]) for sol in archive]\n    selected_idx = np.argmax(ratios)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # 3-opt local search\n    for _ in range(5):  # Number of attempts\n        # Select three distinct random items\n        items = np.random.choice(len(new_solution), size=3, replace=False)\n\n        # Calculate potential weight change\n        current_items = new_solution[items]\n        new_items = np.roll(current_items, 1)  # Cyclic permutation\n\n        delta_weight = np.sum(weight_lst[items][new_items == 1] - weight_lst[items][current_items == 1])\n\n        # Check feasibility\n        if current_weight + delta_weight <= capacity:\n            # Perform swap if it improves at least one objective\n            delta_value1 = np.sum(value1_lst[items][new_items == 1] - value1_lst[items][current_items == 1])\n            delta_value2 = np.sum(value2_lst[items][new_items == 1] - value2_lst[items][current_items == 1])\n\n            if delta_value1 > 0 or delta_value2 > 0:\n                new_solution[items] = new_items\n                current_weight += delta_weight\n                break\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 2 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with potential for improvement (items that can be added without exceeding capacity), then applies a hybrid approach combining value-weighted greedy selection (prioritizing items with highest combined marginal value) and adaptive random perturbations (flipping items probabilistically, with flip probability adjusted based on archive diversity). Finally, it ensures feasibility through greedy backtracking by removing low-marginal-value items if the weight exceeds capacity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    import random\n    import numpy as np\n\n    # Select a solution with potential for improvement by considering both value and archive diversity\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(sol * weight_lst)\n        remaining_capacity = capacity - current_weight\n        potential_items = np.where((sol == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(potential_items) > 0:\n            candidates.append(sol)\n\n    if not candidates:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        selected_solution = random.choice(candidates).copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Step 1: Value-weighted greedy selection\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    for i in np.argsort(-combined_marginal):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    # Step 2: Adaptive random perturbation based on solution quality\n    num_items = len(new_solution)\n    flip_prob = 0.3  # Base flip probability\n    if len(archive) > 1:\n        # Adjust flip probability based on archive diversity\n        archive_weights = np.array([sol[0] for sol, _ in archive])\n        diversity = np.mean(np.std(archive_weights, axis=0))\n        flip_prob = min(0.5, flip_prob + 0.2 * diversity)\n\n    flip_indices = [i for i in range(num_items) if random.random() < flip_prob]\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    # Step 3: Greedy backtracking to maintain feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess_weight = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest marginal value contribution\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        remove_idx = removable_items[np.argmin(marginal_contrib[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a high-performing solution from the archive by prioritizing those with normalized objective values, then applies a hybrid local search combining adaptive bit-flipping (prioritizing high value-to-weight ratio items), probabilistic value-based perturbations (removing low-value, high-weight items), and dynamic weight adjustments (temporarily scaling weights for exploration), ensuring feasibility by strict capacity checks at each step. The approach balances exploitation (value optimization) and exploration (perturbations) while maintaining solution feasibility.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with high normalized objective values\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive bit-flipping based on value-to-weight ratio\n    value_ratio = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(value_ratio)[::-1]  # Highest ratio first\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Value-based perturbation: flip items with low value but high weight\n    if np.random.rand() < 0.4:\n        low_value_high_weight = (value1_lst < np.median(value1_lst)) & (value2_lst < np.median(value2_lst)) & (weight_lst > np.median(weight_lst))\n        perturb_indices = np.where(low_value_high_weight)[0]\n        for idx in perturb_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Dynamic weight adjustment: scale weights temporarily for perturbation\n    if np.random.rand() < 0.3:\n        temp_weights = weight_lst * (1 + 0.1 * np.random.randn(n_items))\n        for idx in np.random.choice(n_items, size=min(3, n_items), replace=False):\n            if base_solution[idx] == 0 and current_weight + temp_weights[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += temp_weights[idx]\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: ### **Keywords**:\n- **Adaptive marginal gain**, **feasibility-aware flipping**, **objective-balanced perturbation**, **diversity-aware selection**.\n\n### **Advice**:\n- **Select** solutions with high normalized objective sums but **flip items** offering the largest marginal gains in either objective.\n- **Augment** with **1-2 random flips** to escape local optima while ensuring feasibility.\n- **Reject** neighbors violating capacity; **repeat** until a valid neighbor is found.\n- **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~80)*\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 20,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_solution = archive[np.argmax(normalized_scores)][0].copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Flip items with highest combined marginal gain\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(-combined_gain)\n\n    for i in sorted_indices[:min(5, len(weight_lst))]:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif new_solution[i] == 1 and (current_weight - weight_lst[i]) <= capacity:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Apply 1-2 random feasibility-aware flips\n    flip_attempts = random.randint(1, 2)\n    for _ in range(flip_attempts):\n        candidates = [i for i in range(len(weight_lst)) if (new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity) or\n                     (new_solution[i] == 1 and (current_weight - weight_lst[i]) <= capacity)]\n        if candidates:\n            i = random.choice(candidates)\n            new_solution[i] = 1 - new_solution[i]\n            current_weight += weight_lst[i] if new_solution[i] == 1 else -weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.7425244058303352,
            0.47512391209602356
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_solution = archive[np.argmax(normalized_scores)][0].copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Flip items with highest combined marginal gain\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(-combined_gain)\n\n    for i in sorted_indices[:min(5, len(weight_lst))]:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif new_solution[i] == 1 and (current_weight - weight_lst[i]) <= capacity:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Apply 1-2 random feasibility-aware flips\n    flip_attempts = random.randint(1, 2)\n    for _ in range(flip_attempts):\n        candidates = [i for i in range(len(weight_lst)) if (new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity) or\n                     (new_solution[i] == 1 and (current_weight - weight_lst[i]) <= capacity)]\n        if candidates:\n            i = random.choice(candidates)\n            new_solution[i] = 1 - new_solution[i]\n            current_weight += weight_lst[i] if new_solution[i] == 1 else -weight_lst[i]\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a random solution from the archive and applies a hybrid local search strategy that prioritizes items with high marginal value (combined from both objectives) while ensuring feasibility, followed by random flips to explore diversity. It balances exploitation (targeting high-value items) with exploration (random perturbations) to generate improved neighbor solutions. The approach avoids standard local search methods like 2-opt by focusing on value-weighted flips and controlled randomness.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: Flip items based on marginal contribution and diversity\n    new_solution = base_solution.copy()\n\n    # Step 1: Identify items with high marginal contribution (value/weight ratio)\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Step 2: Flip items with high marginal contribution if feasible\n    for i in np.argsort(-combined_marginal):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Step 3: Randomly flip additional items to explore diversity\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with potential for improvement (items that can be added without exceeding capacity), then applies a hybrid approach combining value-weighted greedy selection (prioritizing items with highest combined marginal value) and adaptive random perturbations (flipping items probabilistically, with flip probability adjusted based on archive diversity). Finally, it ensures feasibility through greedy backtracking by removing low-marginal-value items if the weight exceeds capacity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    import random\n    import numpy as np\n\n    # Select a solution with potential for improvement by considering both value and archive diversity\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(sol * weight_lst)\n        remaining_capacity = capacity - current_weight\n        potential_items = np.where((sol == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(potential_items) > 0:\n            candidates.append(sol)\n\n    if not candidates:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        selected_solution = random.choice(candidates).copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Step 1: Value-weighted greedy selection\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    for i in np.argsort(-combined_marginal):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    # Step 2: Adaptive random perturbation based on solution quality\n    num_items = len(new_solution)\n    flip_prob = 0.3  # Base flip probability\n    if len(archive) > 1:\n        # Adjust flip probability based on archive diversity\n        archive_weights = np.array([sol[0] for sol, _ in archive])\n        diversity = np.mean(np.std(archive_weights, axis=0))\n        flip_prob = min(0.5, flip_prob + 0.2 * diversity)\n\n    flip_indices = [i for i in range(num_items) if random.random() < flip_prob]\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    # Step 3: Greedy backtracking to maintain feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess_weight = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest marginal value contribution\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        remove_idx = removable_items[np.argmin(marginal_contrib[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Keywords**:\n- **Adaptive marginal gain**, **feasibility-aware flipping**, **objective-balanced perturbation**, **diversity-aware selection**.\n\n### **Advice**:\n- **Select** solutions with high normalized objective sums but **flip items** offering the largest marginal gains in either objective.\n- **Augment** with **1-2 random flips** to escape local optima while ensuring feasibility.\n- **Reject** neighbors violating capacity; **repeat** until a valid neighbor is found.\n- **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~80)*\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 21,
        "algorithm": "The algorithm selects a high-potential solution from the archive by evaluating both objective values and diversity, then applies a hybrid local search that first performs value-weighted greedy additions, followed by adaptive probabilistic flips based on the solution's position relative to the Pareto front, with feasibility ensured through greedy backtracking and targeted flips near the trade-off curve. The method prioritizes combined marginal gains for both objectives while dynamically adjusting exploration/exploitation through flip probabilities and trade-off-aware refinements.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    import random\n    import numpy as np\n\n    # Select a solution with high potential for improvement by considering both objective values and archive diversity\n    objectives = np.array([obj for _, obj in archive])\n    max_obj = np.max(objectives, axis=0)\n    normalized_obj = objectives / (max_obj + 1e-10)\n    potential_scores = np.sum(normalized_obj, axis=1)\n    selected_idx = np.argmax(potential_scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Step 1: Value-weighted greedy selection\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    for i in np.argsort(-combined_marginal):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    # Step 2: Adaptive probabilistic flipping based on objective trade-off\n    flip_prob = 0.1  # Base flip probability\n    if len(archive) > 1:\n        # Adjust flip probability based on solution's position in objective space\n        obj1, obj2 = current_obj\n        archive_obj1 = np.array([obj[0] for _, obj in archive])\n        archive_obj2 = np.array([obj[1] for _, obj in archive])\n        # Calculate how close the solution is to the Pareto front\n        is_dominated = np.any((archive_obj1 >= obj1) & (archive_obj2 >= obj2) & ((archive_obj1 > obj1) | (archive_obj2 > obj2)))\n        if is_dominated:\n            flip_prob = min(0.5, flip_prob + 0.2)\n\n    flip_indices = [i for i in range(len(new_solution)) if random.random() < flip_prob]\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    # Step 3: Greedy backtracking to maintain feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess_weight = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        remove_idx = removable_items[np.argmin(marginal_contrib[removable_items])]\n        new_solution[remove_idx] = 0\n\n    # Step 4: Targeted flips near the trade-off curve\n    if len(archive) > 1:\n        # Find items near the trade-off curve of the selected solution\n        obj1, obj2 = current_obj\n        trade_off_ratio = obj1 / (obj2 + 1e-10)\n        item_ratios = value1_lst / (value2_lst + 1e-10)\n        target_items = np.where(np.abs(item_ratios - trade_off_ratio) < 0.2)[0]\n        if len(target_items) > 0:\n            target_flip = np.random.choice(target_items)\n            if new_solution[target_flip] == 0 and (current_weight + weight_lst[target_flip]) <= capacity:\n                new_solution[target_flip] = 1\n            elif new_solution[target_flip] == 1:\n                new_solution[target_flip] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.47739993588755425,
            0.41691771149635315
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    import random\n    import numpy as np\n\n    # Select a solution with high potential for improvement by considering both objective values and archive diversity\n    objectives = np.array([obj for _, obj in archive])\n    max_obj = np.max(objectives, axis=0)\n    normalized_obj = objectives / (max_obj + 1e-10)\n    potential_scores = np.sum(normalized_obj, axis=1)\n    selected_idx = np.argmax(potential_scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Step 1: Value-weighted greedy selection\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    for i in np.argsort(-combined_marginal):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    # Step 2: Adaptive probabilistic flipping based on objective trade-off\n    flip_prob = 0.1  # Base flip probability\n    if len(archive) > 1:\n        # Adjust flip probability based on solution's position in objective space\n        obj1, obj2 = current_obj\n        archive_obj1 = np.array([obj[0] for _, obj in archive])\n        archive_obj2 = np.array([obj[1] for _, obj in archive])\n        # Calculate how close the solution is to the Pareto front\n        is_dominated = np.any((archive_obj1 >= obj1) & (archive_obj2 >= obj2) & ((archive_obj1 > obj1) | (archive_obj2 > obj2)))\n        if is_dominated:\n            flip_prob = min(0.5, flip_prob + 0.2)\n\n    flip_indices = [i for i in range(len(new_solution)) if random.random() < flip_prob]\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    # Step 3: Greedy backtracking to maintain feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess_weight = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        remove_idx = removable_items[np.argmin(marginal_contrib[removable_items])]\n        new_solution[remove_idx] = 0\n\n    # Step 4: Targeted flips near the trade-off curve\n    if len(archive) > 1:\n        # Find items near the trade-off curve of the selected solution\n        obj1, obj2 = current_obj\n        trade_off_ratio = obj1 / (obj2 + 1e-10)\n        item_ratios = value1_lst / (value2_lst + 1e-10)\n        target_items = np.where(np.abs(item_ratios - trade_off_ratio) < 0.2)[0]\n        if len(target_items) > 0:\n            target_flip = np.random.choice(target_items)\n            if new_solution[target_flip] == 0 and (current_weight + weight_lst[target_flip]) <= capacity:\n                new_solution[target_flip] = 1\n            elif new_solution[target_flip] == 1:\n                new_solution[target_flip] = 0\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with potential for improvement (items that can be added without exceeding capacity), then applies a hybrid approach combining value-weighted greedy selection (prioritizing items with highest combined marginal value) and adaptive random perturbations (flipping items probabilistically, with flip probability adjusted based on archive diversity). Finally, it ensures feasibility through greedy backtracking by removing low-marginal-value items if the weight exceeds capacity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    import random\n    import numpy as np\n\n    # Select a solution with potential for improvement by considering both value and archive diversity\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(sol * weight_lst)\n        remaining_capacity = capacity - current_weight\n        potential_items = np.where((sol == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(potential_items) > 0:\n            candidates.append(sol)\n\n    if not candidates:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        selected_solution = random.choice(candidates).copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Step 1: Value-weighted greedy selection\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    for i in np.argsort(-combined_marginal):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    # Step 2: Adaptive random perturbation based on solution quality\n    num_items = len(new_solution)\n    flip_prob = 0.3  # Base flip probability\n    if len(archive) > 1:\n        # Adjust flip probability based on archive diversity\n        archive_weights = np.array([sol[0] for sol, _ in archive])\n        diversity = np.mean(np.std(archive_weights, axis=0))\n        flip_prob = min(0.5, flip_prob + 0.2 * diversity)\n\n    flip_indices = [i for i in range(num_items) if random.random() < flip_prob]\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    # Step 3: Greedy backtracking to maintain feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess_weight = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest marginal value contribution\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        remove_idx = removable_items[np.argmin(marginal_contrib[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Keywords**:\n- **Adaptive marginal gain**, **feasibility-aware flipping**, **objective-balanced perturbation**, **diversity-aware selection**.\n\n### **Advice**:\n- **Select** solutions with high normalized objective sums but **flip items** offering the largest marginal gains in either objective.\n- **Augment** with **1-2 random flips** to escape local optima while ensuring feasibility.\n- **Reject** neighbors violating capacity; **repeat** until a valid neighbor is found.\n- **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~80)*\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 22,
        "algorithm": "The algorithm first clusters solutions in the archive by selecting those in the top 75th percentile of combined objective values, then performs adaptive greedy swaps prioritizing items with highest marginal gains in either objective, occasionally removing items randomly to escape local optima, and finally ensures feasibility by iteratively removing low-contribution items if capacity is exceeded. The algorithm balances exploration (via randomness) and exploitation (via greedy marginal gains) while maintaining feasibility through dynamic adjustments.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Cluster solutions into regions with high potential for improvement\n    obj1_vals = np.array([obj[0] for _, obj in archive])\n    obj2_vals = np.array([obj[1] for _, obj in archive])\n    combined_scores = obj1_vals + obj2_vals\n    top_percentile = np.percentile(combined_scores, 75)\n    promising_indices = np.where(combined_scores >= top_percentile)[0]\n\n    if len(promising_indices) == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        selected_idx = np.random.choice(promising_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive greedy swaps with controlled randomness\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Prioritize items with highest marginal gains\n    sorted_indices = np.argsort(-combined_gain)\n\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1 and np.random.rand() < 0.2:  # 20% chance to remove\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Ensure feasibility by removing low-contribution items\n    while current_weight > capacity:\n        excess_weight = current_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest marginal contribution\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        remove_idx = removable_items[np.argmin(marginal_contrib[removable_items])]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.4744290380877938,
            0.5756101310253143
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Cluster solutions into regions with high potential for improvement\n    obj1_vals = np.array([obj[0] for _, obj in archive])\n    obj2_vals = np.array([obj[1] for _, obj in archive])\n    combined_scores = obj1_vals + obj2_vals\n    top_percentile = np.percentile(combined_scores, 75)\n    promising_indices = np.where(combined_scores >= top_percentile)[0]\n\n    if len(promising_indices) == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        selected_idx = np.random.choice(promising_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive greedy swaps with controlled randomness\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Prioritize items with highest marginal gains\n    sorted_indices = np.argsort(-combined_gain)\n\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1 and np.random.rand() < 0.2:  # 20% chance to remove\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Ensure feasibility by removing low-contribution items\n    while current_weight > capacity:\n        excess_weight = current_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest marginal contribution\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        remove_idx = removable_items[np.argmin(marginal_contrib[removable_items])]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the archive by prioritizing those with potential for improvement (items that can be added without exceeding capacity), then applies a hybrid approach combining value-weighted greedy selection (prioritizing items with highest combined marginal value) and adaptive random perturbations (flipping items probabilistically, with flip probability adjusted based on archive diversity). Finally, it ensures feasibility through greedy backtracking by removing low-marginal-value items if the weight exceeds capacity.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    import random\n    import numpy as np\n\n    # Select a solution with potential for improvement by considering both value and archive diversity\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(sol * weight_lst)\n        remaining_capacity = capacity - current_weight\n        potential_items = np.where((sol == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(potential_items) > 0:\n            candidates.append(sol)\n\n    if not candidates:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        selected_solution = random.choice(candidates).copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Step 1: Value-weighted greedy selection\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    for i in np.argsort(-combined_marginal):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    # Step 2: Adaptive random perturbation based on solution quality\n    num_items = len(new_solution)\n    flip_prob = 0.3  # Base flip probability\n    if len(archive) > 1:\n        # Adjust flip probability based on archive diversity\n        archive_weights = np.array([sol[0] for sol, _ in archive])\n        diversity = np.mean(np.std(archive_weights, axis=0))\n        flip_prob = min(0.5, flip_prob + 0.2 * diversity)\n\n    flip_indices = [i for i in range(num_items) if random.random() < flip_prob]\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    # Step 3: Greedy backtracking to maintain feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess_weight = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest marginal value contribution\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        remove_idx = removable_items[np.argmin(marginal_contrib[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 23,
        "algorithm": "The algorithm selects a solution from the archive based on dominance scores (prioritizing less-dominated solutions) and then applies a hybrid local search: first adding items that improve the most solutions in the archive, followed by probabilistic swaps, and finally ensuring feasibility by removing low-value-to-weight items. It balances exploration (via probabilistic swaps) with exploitation (via dominance-based item selection) while strictly maintaining feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    import random\n    import numpy as np\n\n    # Select solution based on value dominance and archive diversity\n    if not archive:\n        return np.zeros_like(weight_lst)\n\n    # Calculate dominance scores for each solution\n    dominance_scores = []\n    for sol, (val1, val2) in archive:\n        dominated = 0\n        for _, (other_val1, other_val2) in archive:\n            if (val1 < other_val1 and val2 <= other_val2) or (val1 <= other_val1 and val2 < other_val2):\n                dominated += 1\n        dominance_scores.append(dominated)\n\n    # Select solution with highest dominance score (least dominated)\n    selected_idx = np.argmax(dominance_scores)\n    selected_solution = archive[selected_idx][0].copy()\n    new_solution = selected_solution.copy()\n\n    # Calculate current weight and remaining capacity\n    current_weight = np.sum(new_solution * weight_lst)\n    remaining_capacity = capacity - current_weight\n\n    # Step 1: Value-dominance weighted selection\n    value_ratio1 = value1_lst / (weight_lst + 1e-10)\n    value_ratio2 = value2_lst / (weight_lst + 1e-10)\n\n    # Calculate combined dominance score for each item\n    dominance_scores = []\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 0 and weight_lst[i] <= remaining_capacity:\n            # Count how many solutions in archive would be improved by adding this item\n            improvement_count = 0\n            for sol, (val1, val2) in archive:\n                if sol[i] == 0:\n                    new_val1 = val1 + value1_lst[i]\n                    new_val2 = val2 + value2_lst[i]\n                    for _, (other_val1, other_val2) in archive:\n                        if (new_val1 > other_val1 and new_val2 >= other_val2) or (new_val1 >= other_val1 and new_val2 > other_val2):\n                            improvement_count += 1\n            dominance_scores.append(improvement_count)\n        else:\n            dominance_scores.append(-1)\n\n    # Add items with highest dominance scores first\n    for i in np.argsort(-np.array(dominance_scores)):\n        if dominance_scores[i] >= 0 and new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n            remaining_capacity = capacity - current_weight\n\n    # Step 2: Adaptive probabilistic item swaps\n    swap_prob = 0.4  # Base probability\n    if len(archive) > 1:\n        # Adjust based on solution diversity\n        archive_matrix = np.array([sol[0] for sol in archive])\n        diversity = np.mean(np.std(archive_matrix, axis=0))\n        swap_prob = min(0.6, swap_prob + 0.2 * diversity)\n\n    # Identify items that could be swapped (either add or remove)\n    for i in range(len(weight_lst)):\n        if random.random() < swap_prob:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n            elif new_solution[i] == 1:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n\n    # Step 3: Feasibility preservation with value-to-weight ratio\n    while current_weight > capacity:\n        # Find items to remove with lowest value-to-weight ratio\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n\n        # Calculate value-to-weight ratios for included items\n        ratios = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-10)\n        remove_idx = included_items[np.argmin(ratios)]\n\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.4398252051730404,
            0.76126429438591
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    import random\n    import numpy as np\n\n    # Select solution based on value dominance and archive diversity\n    if not archive:\n        return np.zeros_like(weight_lst)\n\n    # Calculate dominance scores for each solution\n    dominance_scores = []\n    for sol, (val1, val2) in archive:\n        dominated = 0\n        for _, (other_val1, other_val2) in archive:\n            if (val1 < other_val1 and val2 <= other_val2) or (val1 <= other_val1 and val2 < other_val2):\n                dominated += 1\n        dominance_scores.append(dominated)\n\n    # Select solution with highest dominance score (least dominated)\n    selected_idx = np.argmax(dominance_scores)\n    selected_solution = archive[selected_idx][0].copy()\n    new_solution = selected_solution.copy()\n\n    # Calculate current weight and remaining capacity\n    current_weight = np.sum(new_solution * weight_lst)\n    remaining_capacity = capacity - current_weight\n\n    # Step 1: Value-dominance weighted selection\n    value_ratio1 = value1_lst / (weight_lst + 1e-10)\n    value_ratio2 = value2_lst / (weight_lst + 1e-10)\n\n    # Calculate combined dominance score for each item\n    dominance_scores = []\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 0 and weight_lst[i] <= remaining_capacity:\n            # Count how many solutions in archive would be improved by adding this item\n            improvement_count = 0\n            for sol, (val1, val2) in archive:\n                if sol[i] == 0:\n                    new_val1 = val1 + value1_lst[i]\n                    new_val2 = val2 + value2_lst[i]\n                    for _, (other_val1, other_val2) in archive:\n                        if (new_val1 > other_val1 and new_val2 >= other_val2) or (new_val1 >= other_val1 and new_val2 > other_val2):\n                            improvement_count += 1\n            dominance_scores.append(improvement_count)\n        else:\n            dominance_scores.append(-1)\n\n    # Add items with highest dominance scores first\n    for i in np.argsort(-np.array(dominance_scores)):\n        if dominance_scores[i] >= 0 and new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n            remaining_capacity = capacity - current_weight\n\n    # Step 2: Adaptive probabilistic item swaps\n    swap_prob = 0.4  # Base probability\n    if len(archive) > 1:\n        # Adjust based on solution diversity\n        archive_matrix = np.array([sol[0] for sol in archive])\n        diversity = np.mean(np.std(archive_matrix, axis=0))\n        swap_prob = min(0.6, swap_prob + 0.2 * diversity)\n\n    # Identify items that could be swapped (either add or remove)\n    for i in range(len(weight_lst)):\n        if random.random() < swap_prob:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n            elif new_solution[i] == 1:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n\n    # Step 3: Feasibility preservation with value-to-weight ratio\n    while current_weight > capacity:\n        # Find items to remove with lowest value-to-weight ratio\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n\n        # Calculate value-to-weight ratios for included items\n        ratios = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-10)\n        remove_idx = included_items[np.argmin(ratios)]\n\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the archive by prioritizing those with potential for improvement (items that can be added without exceeding capacity), then applies a hybrid approach combining value-weighted greedy selection (prioritizing items with highest combined marginal value) and adaptive random perturbations (flipping items probabilistically, with flip probability adjusted based on archive diversity). Finally, it ensures feasibility through greedy backtracking by removing low-marginal-value items if the weight exceeds capacity.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    import random\n    import numpy as np\n\n    # Select a solution with potential for improvement by considering both value and archive diversity\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(sol * weight_lst)\n        remaining_capacity = capacity - current_weight\n        potential_items = np.where((sol == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(potential_items) > 0:\n            candidates.append(sol)\n\n    if not candidates:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        selected_solution = random.choice(candidates).copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Step 1: Value-weighted greedy selection\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    for i in np.argsort(-combined_marginal):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    # Step 2: Adaptive random perturbation based on solution quality\n    num_items = len(new_solution)\n    flip_prob = 0.3  # Base flip probability\n    if len(archive) > 1:\n        # Adjust flip probability based on archive diversity\n        archive_weights = np.array([sol[0] for sol, _ in archive])\n        diversity = np.mean(np.std(archive_weights, axis=0))\n        flip_prob = min(0.5, flip_prob + 0.2 * diversity)\n\n    flip_indices = [i for i in range(num_items) if random.random() < flip_prob]\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    # Step 3: Greedy backtracking to maintain feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess_weight = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest marginal value contribution\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        remove_idx = removable_items[np.argmin(marginal_contrib[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 24,
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with high marginal value potential and weight diversity, then applies a hybrid approach combining marginal value-based addition, adaptive probabilistic swaps, and weighted removal to generate a feasible neighbor solution. It balances exploration and exploitation by adjusting swap probabilities based on archive diversity and ensures feasibility through targeted item removal when capacity is exceeded. The critical design choices include prioritizing items with high combined marginal value, favoring weight-diverse items, and dynamically adjusting exploration intensity based on solution quality.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    import random\n    import numpy as np\n\n    # Select the solution with the highest potential for improvement\n    best_candidate = None\n    max_potential = -1\n    for sol, _ in archive:\n        current_weight = np.sum(sol * weight_lst)\n        remaining_capacity = capacity - current_weight\n        potential_items = np.where((sol == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(potential_items) > 0:\n            # Calculate potential based on combined marginal value and weight diversity\n            marginal_value1 = value1_lst[potential_items] / (weight_lst[potential_items] + 1e-10)\n            marginal_value2 = value2_lst[potential_items] / (weight_lst[potential_items] + 1e-10)\n            combined_marginal = marginal_value1 + marginal_value2\n            weight_diversity = np.std(weight_lst[potential_items])\n            potential = np.sum(combined_marginal) * (1 + weight_diversity)\n            if potential > max_potential:\n                max_potential = potential\n                best_candidate = sol\n\n    if best_candidate is None:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        selected_solution = best_candidate.copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Step 1: Marginal value-based selection with weight diversity consideration\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n    weight_diversity = np.std(weight_lst)\n\n    for i in np.argsort(-combined_marginal):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            # Add item with higher probability if it's part of diverse weight range\n            add_prob = 0.7 if (weight_lst[i] > np.percentile(weight_lst, 30) and weight_lst[i] < np.percentile(weight_lst, 70)) else 0.4\n            if random.random() < add_prob:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Step 2: Adaptive probabilistic swaps based on solution quality and diversity\n    num_items = len(new_solution)\n    swap_prob = 0.2  # Base swap probability\n    if len(archive) > 1:\n        # Adjust swap probability based on archive diversity and solution quality\n        archive_weights = np.array([sol[0] for sol, _ in archive])\n        diversity = np.mean(np.std(archive_weights, axis=0))\n        swap_prob = min(0.4, swap_prob + 0.15 * diversity)\n\n    for i in range(num_items):\n        if random.random() < swap_prob:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n            elif new_solution[i] == 1:\n                new_solution[i] = 0\n\n    # Step 3: Weighted removal to maintain feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest weighted marginal value contribution\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        weights = weight_lst[removable_items]\n        weighted_contrib = marginal_contrib[removable_items] * weights\n        remove_idx = removable_items[np.argmin(weighted_contrib)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8803102034567545,
            0.8085598945617676
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    import random\n    import numpy as np\n\n    # Select the solution with the highest potential for improvement\n    best_candidate = None\n    max_potential = -1\n    for sol, _ in archive:\n        current_weight = np.sum(sol * weight_lst)\n        remaining_capacity = capacity - current_weight\n        potential_items = np.where((sol == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(potential_items) > 0:\n            # Calculate potential based on combined marginal value and weight diversity\n            marginal_value1 = value1_lst[potential_items] / (weight_lst[potential_items] + 1e-10)\n            marginal_value2 = value2_lst[potential_items] / (weight_lst[potential_items] + 1e-10)\n            combined_marginal = marginal_value1 + marginal_value2\n            weight_diversity = np.std(weight_lst[potential_items])\n            potential = np.sum(combined_marginal) * (1 + weight_diversity)\n            if potential > max_potential:\n                max_potential = potential\n                best_candidate = sol\n\n    if best_candidate is None:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        selected_solution = best_candidate.copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Step 1: Marginal value-based selection with weight diversity consideration\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n    weight_diversity = np.std(weight_lst)\n\n    for i in np.argsort(-combined_marginal):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            # Add item with higher probability if it's part of diverse weight range\n            add_prob = 0.7 if (weight_lst[i] > np.percentile(weight_lst, 30) and weight_lst[i] < np.percentile(weight_lst, 70)) else 0.4\n            if random.random() < add_prob:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Step 2: Adaptive probabilistic swaps based on solution quality and diversity\n    num_items = len(new_solution)\n    swap_prob = 0.2  # Base swap probability\n    if len(archive) > 1:\n        # Adjust swap probability based on archive diversity and solution quality\n        archive_weights = np.array([sol[0] for sol, _ in archive])\n        diversity = np.mean(np.std(archive_weights, axis=0))\n        swap_prob = min(0.4, swap_prob + 0.15 * diversity)\n\n    for i in range(num_items):\n        if random.random() < swap_prob:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n            elif new_solution[i] == 1:\n                new_solution[i] = 0\n\n    # Step 3: Weighted removal to maintain feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest weighted marginal value contribution\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        weights = weight_lst[removable_items]\n        weighted_contrib = marginal_contrib[removable_items] * weights\n        remove_idx = removable_items[np.argmin(weighted_contrib)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the archive by prioritizing those with potential for improvement (items that can be added without exceeding capacity), then applies a hybrid approach combining value-weighted greedy selection (prioritizing items with highest combined marginal value) and adaptive random perturbations (flipping items probabilistically, with flip probability adjusted based on archive diversity). Finally, it ensures feasibility through greedy backtracking by removing low-marginal-value items if the weight exceeds capacity.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    import random\n    import numpy as np\n\n    # Select a solution with potential for improvement by considering both value and archive diversity\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(sol * weight_lst)\n        remaining_capacity = capacity - current_weight\n        potential_items = np.where((sol == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(potential_items) > 0:\n            candidates.append(sol)\n\n    if not candidates:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        selected_solution = random.choice(candidates).copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Step 1: Value-weighted greedy selection\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    for i in np.argsort(-combined_marginal):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    # Step 2: Adaptive random perturbation based on solution quality\n    num_items = len(new_solution)\n    flip_prob = 0.3  # Base flip probability\n    if len(archive) > 1:\n        # Adjust flip probability based on archive diversity\n        archive_weights = np.array([sol[0] for sol, _ in archive])\n        diversity = np.mean(np.std(archive_weights, axis=0))\n        flip_prob = min(0.5, flip_prob + 0.2 * diversity)\n\n    flip_indices = [i for i in range(num_items) if random.random() < flip_prob]\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    # Step 3: Greedy backtracking to maintain feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess_weight = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest marginal value contribution\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        remove_idx = removable_items[np.argmin(marginal_contrib[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 24,
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with high marginal value potential and weight diversity, then applies a hybrid approach combining marginal value-based addition, adaptive probabilistic swaps, and weighted removal to generate a feasible neighbor solution. It balances exploration and exploitation by adjusting swap probabilities based on archive diversity and ensures feasibility through targeted item removal when capacity is exceeded. The critical design choices include prioritizing items with high combined marginal value, favoring weight-diverse items, and dynamically adjusting exploration intensity based on solution quality.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    import random\n    import numpy as np\n\n    # Select the solution with the highest potential for improvement\n    best_candidate = None\n    max_potential = -1\n    for sol, _ in archive:\n        current_weight = np.sum(sol * weight_lst)\n        remaining_capacity = capacity - current_weight\n        potential_items = np.where((sol == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(potential_items) > 0:\n            # Calculate potential based on combined marginal value and weight diversity\n            marginal_value1 = value1_lst[potential_items] / (weight_lst[potential_items] + 1e-10)\n            marginal_value2 = value2_lst[potential_items] / (weight_lst[potential_items] + 1e-10)\n            combined_marginal = marginal_value1 + marginal_value2\n            weight_diversity = np.std(weight_lst[potential_items])\n            potential = np.sum(combined_marginal) * (1 + weight_diversity)\n            if potential > max_potential:\n                max_potential = potential\n                best_candidate = sol\n\n    if best_candidate is None:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        selected_solution = best_candidate.copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Step 1: Marginal value-based selection with weight diversity consideration\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n    weight_diversity = np.std(weight_lst)\n\n    for i in np.argsort(-combined_marginal):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            # Add item with higher probability if it's part of diverse weight range\n            add_prob = 0.7 if (weight_lst[i] > np.percentile(weight_lst, 30) and weight_lst[i] < np.percentile(weight_lst, 70)) else 0.4\n            if random.random() < add_prob:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Step 2: Adaptive probabilistic swaps based on solution quality and diversity\n    num_items = len(new_solution)\n    swap_prob = 0.2  # Base swap probability\n    if len(archive) > 1:\n        # Adjust swap probability based on archive diversity and solution quality\n        archive_weights = np.array([sol[0] for sol, _ in archive])\n        diversity = np.mean(np.std(archive_weights, axis=0))\n        swap_prob = min(0.4, swap_prob + 0.15 * diversity)\n\n    for i in range(num_items):\n        if random.random() < swap_prob:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n            elif new_solution[i] == 1:\n                new_solution[i] = 0\n\n    # Step 3: Weighted removal to maintain feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest weighted marginal value contribution\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        weights = weight_lst[removable_items]\n        weighted_contrib = marginal_contrib[removable_items] * weights\n        remove_idx = removable_items[np.argmin(weighted_contrib)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8803102034567545,
            0.8085598945617676
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    import random\n    import numpy as np\n\n    # Select the solution with the highest potential for improvement\n    best_candidate = None\n    max_potential = -1\n    for sol, _ in archive:\n        current_weight = np.sum(sol * weight_lst)\n        remaining_capacity = capacity - current_weight\n        potential_items = np.where((sol == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(potential_items) > 0:\n            # Calculate potential based on combined marginal value and weight diversity\n            marginal_value1 = value1_lst[potential_items] / (weight_lst[potential_items] + 1e-10)\n            marginal_value2 = value2_lst[potential_items] / (weight_lst[potential_items] + 1e-10)\n            combined_marginal = marginal_value1 + marginal_value2\n            weight_diversity = np.std(weight_lst[potential_items])\n            potential = np.sum(combined_marginal) * (1 + weight_diversity)\n            if potential > max_potential:\n                max_potential = potential\n                best_candidate = sol\n\n    if best_candidate is None:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        selected_solution = best_candidate.copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Step 1: Marginal value-based selection with weight diversity consideration\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n    weight_diversity = np.std(weight_lst)\n\n    for i in np.argsort(-combined_marginal):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            # Add item with higher probability if it's part of diverse weight range\n            add_prob = 0.7 if (weight_lst[i] > np.percentile(weight_lst, 30) and weight_lst[i] < np.percentile(weight_lst, 70)) else 0.4\n            if random.random() < add_prob:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Step 2: Adaptive probabilistic swaps based on solution quality and diversity\n    num_items = len(new_solution)\n    swap_prob = 0.2  # Base swap probability\n    if len(archive) > 1:\n        # Adjust swap probability based on archive diversity and solution quality\n        archive_weights = np.array([sol[0] for sol, _ in archive])\n        diversity = np.mean(np.std(archive_weights, axis=0))\n        swap_prob = min(0.4, swap_prob + 0.15 * diversity)\n\n    for i in range(num_items):\n        if random.random() < swap_prob:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n            elif new_solution[i] == 1:\n                new_solution[i] = 0\n\n    # Step 3: Weighted removal to maintain feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest weighted marginal value contribution\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        weights = weight_lst[removable_items]\n        weighted_contrib = marginal_contrib[removable_items] * weights\n        remove_idx = removable_items[np.argmin(weighted_contrib)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with potential for improvement (items that can be added without exceeding capacity), then applies a hybrid approach combining value-weighted greedy selection (prioritizing items with highest combined marginal value) and adaptive random perturbations (flipping items probabilistically, with flip probability adjusted based on archive diversity). Finally, it ensures feasibility through greedy backtracking by removing low-marginal-value items if the weight exceeds capacity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    import random\n    import numpy as np\n\n    # Select a solution with potential for improvement by considering both value and archive diversity\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(sol * weight_lst)\n        remaining_capacity = capacity - current_weight\n        potential_items = np.where((sol == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(potential_items) > 0:\n            candidates.append(sol)\n\n    if not candidates:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        selected_solution = random.choice(candidates).copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Step 1: Value-weighted greedy selection\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    for i in np.argsort(-combined_marginal):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    # Step 2: Adaptive random perturbation based on solution quality\n    num_items = len(new_solution)\n    flip_prob = 0.3  # Base flip probability\n    if len(archive) > 1:\n        # Adjust flip probability based on archive diversity\n        archive_weights = np.array([sol[0] for sol, _ in archive])\n        diversity = np.mean(np.std(archive_weights, axis=0))\n        flip_prob = min(0.5, flip_prob + 0.2 * diversity)\n\n    flip_indices = [i for i in range(num_items) if random.random() < flip_prob]\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    # Step 3: Greedy backtracking to maintain feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess_weight = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest marginal value contribution\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        remove_idx = removable_items[np.argmin(marginal_contrib[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a random solution from the archive and applies a hybrid local search strategy that prioritizes items with high marginal value (combined from both objectives) while ensuring feasibility, followed by random flips to explore diversity. It balances exploitation (targeting high-value items) with exploration (random perturbations) to generate improved neighbor solutions. The approach avoids standard local search methods like 2-opt by focusing on value-weighted flips and controlled randomness.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: Flip items based on marginal contribution and diversity\n    new_solution = base_solution.copy()\n\n    # Step 1: Identify items with high marginal contribution (value/weight ratio)\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Step 2: Flip items with high marginal contribution if feasible\n    for i in np.argsort(-combined_marginal):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Step 3: Randomly flip additional items to explore diversity\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Keywords**:\n- **Adaptive marginal gain**, **feasibility-aware flipping**, **objective-balanced perturbation**, **diversity-aware selection**.\n\n### **Advice**:\n- **Select** solutions with high normalized objective sums but **flip items** offering the largest marginal gains in either objective.\n- **Augment** with **1-2 random flips** to escape local optima while ensuring feasibility.\n- **Reject** neighbors violating capacity; **repeat** until a valid neighbor is found.\n- **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~80)*\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 25,
        "algorithm": "The algorithm selects a high-performing solution from the archive (based on normalized objective sums), then iteratively refines it by flipping items with the largest marginal gains (prioritizing those that improve either objective) and performing random flips (1-2 items) to explore diversity, while always maintaining feasibility through greedy backtracking. It balances exploitation (targeted flips) and exploration (random flips) over 5-10 iterations to generate high-quality neighbors.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    import random\n    import numpy as np\n\n    # Select a solution with high normalized objective sums\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = np.array([obj for _, obj in archive])\n    normalized_sums = np.sum(archive_objectives / (np.max(archive_objectives, axis=0) + 1e-10), axis=1)\n    selected_solution = archive_solutions[np.argmax(normalized_sums)].copy()\n\n    # Initialize neighbor solution\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Iterative refinement (5-10 times)\n    for _ in range(5):\n        # Step 1: Flip items with largest marginal gains in either objective\n        marginal_value1 = value1_lst / (weight_lst + 1e-10)\n        marginal_value2 = value2_lst / (weight_lst + 1e-10)\n\n        for i in np.argsort(-np.maximum(marginal_value1, marginal_value2)):\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n            elif new_solution[i] == 1:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n\n        # Step 2: Random flips (1-2 items) to explore diversity\n        flip_indices = random.sample(range(len(new_solution)), min(2, len(new_solution)))\n        for i in flip_indices:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n            elif new_solution[i] == 1:\n                new_solution[i] = 0\n\n        # Step 3: Greedy backtracking to maintain feasibility\n        while np.sum(new_solution * weight_lst) > capacity:\n            excess_weight = np.sum(new_solution * weight_lst) - capacity\n            removable_items = np.where(new_solution == 1)[0]\n            if len(removable_items) == 0:\n                break\n            marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n            remove_idx = removable_items[np.argmin(marginal_contrib[removable_items])]\n            new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.4518885311160839,
            1.5691930949687958
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    import random\n    import numpy as np\n\n    # Select a solution with high normalized objective sums\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = np.array([obj for _, obj in archive])\n    normalized_sums = np.sum(archive_objectives / (np.max(archive_objectives, axis=0) + 1e-10), axis=1)\n    selected_solution = archive_solutions[np.argmax(normalized_sums)].copy()\n\n    # Initialize neighbor solution\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Iterative refinement (5-10 times)\n    for _ in range(5):\n        # Step 1: Flip items with largest marginal gains in either objective\n        marginal_value1 = value1_lst / (weight_lst + 1e-10)\n        marginal_value2 = value2_lst / (weight_lst + 1e-10)\n\n        for i in np.argsort(-np.maximum(marginal_value1, marginal_value2)):\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n            elif new_solution[i] == 1:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n\n        # Step 2: Random flips (1-2 items) to explore diversity\n        flip_indices = random.sample(range(len(new_solution)), min(2, len(new_solution)))\n        for i in flip_indices:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n            elif new_solution[i] == 1:\n                new_solution[i] = 0\n\n        # Step 3: Greedy backtracking to maintain feasibility\n        while np.sum(new_solution * weight_lst) > capacity:\n            excess_weight = np.sum(new_solution * weight_lst) - capacity\n            removable_items = np.where(new_solution == 1)[0]\n            if len(removable_items) == 0:\n                break\n            marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n            remove_idx = removable_items[np.argmin(marginal_contrib[removable_items])]\n            new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 3 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with potential for improvement (items that can be added without exceeding capacity), then applies a hybrid approach combining value-weighted greedy selection (prioritizing items with highest combined marginal value) and adaptive random perturbations (flipping items probabilistically, with flip probability adjusted based on archive diversity). Finally, it ensures feasibility through greedy backtracking by removing low-marginal-value items if the weight exceeds capacity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    import random\n    import numpy as np\n\n    # Select a solution with potential for improvement by considering both value and archive diversity\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(sol * weight_lst)\n        remaining_capacity = capacity - current_weight\n        potential_items = np.where((sol == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(potential_items) > 0:\n            candidates.append(sol)\n\n    if not candidates:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        selected_solution = random.choice(candidates).copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Step 1: Value-weighted greedy selection\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    for i in np.argsort(-combined_marginal):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    # Step 2: Adaptive random perturbation based on solution quality\n    num_items = len(new_solution)\n    flip_prob = 0.3  # Base flip probability\n    if len(archive) > 1:\n        # Adjust flip probability based on archive diversity\n        archive_weights = np.array([sol[0] for sol, _ in archive])\n        diversity = np.mean(np.std(archive_weights, axis=0))\n        flip_prob = min(0.5, flip_prob + 0.2 * diversity)\n\n    flip_indices = [i for i in range(num_items) if random.random() < flip_prob]\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    # Step 3: Greedy backtracking to maintain feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess_weight = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest marginal value contribution\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        remove_idx = removable_items[np.argmin(marginal_contrib[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a high-performing solution from the archive by prioritizing those with normalized objective values, then applies a hybrid local search combining adaptive bit-flipping (prioritizing high value-to-weight ratio items), probabilistic value-based perturbations (removing low-value, high-weight items), and dynamic weight adjustments (temporarily scaling weights for exploration), ensuring feasibility by strict capacity checks at each step. The approach balances exploitation (value optimization) and exploration (perturbations) while maintaining solution feasibility.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with high normalized objective values\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive bit-flipping based on value-to-weight ratio\n    value_ratio = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(value_ratio)[::-1]  # Highest ratio first\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Value-based perturbation: flip items with low value but high weight\n    if np.random.rand() < 0.4:\n        low_value_high_weight = (value1_lst < np.median(value1_lst)) & (value2_lst < np.median(value2_lst)) & (weight_lst > np.median(weight_lst))\n        perturb_indices = np.where(low_value_high_weight)[0]\n        for idx in perturb_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Dynamic weight adjustment: scale weights temporarily for perturbation\n    if np.random.rand() < 0.3:\n        temp_weights = weight_lst * (1 + 0.1 * np.random.randn(n_items))\n        for idx in np.random.choice(n_items, size=min(3, n_items), replace=False):\n            if base_solution[idx] == 0 and current_weight + temp_weights[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += temp_weights[idx]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n- **Select** solutions with high normalized objective sums but **flip items** offering the largest marginal gains in either objective.\n- **Augment** with **1-2 random flips** to escape local optima while ensuring feasibility.\n- **Reject** neighbors violating capacity; **repeat** until a valid neighbor is found.\n- **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~80)*\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 26,
        "algorithm": "The algorithm selects a promising solution from the archive using a normalized combined objective score, then applies a hybrid local search that flips items with high marginal gains for each objective while maintaining feasibility. It also includes a probabilistic random perturbation step to escape local optima. The selection prioritizes solutions with better normalized scores, while the local search focuses on objective-specific item flips and adaptive random changes.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest normalized combined objective value\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: objective-specific marginal gain flips\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Flip items with highest marginal gain for each objective\n    for gain, obj in [(marginal_gain1, 1), (marginal_gain2, 2)]:\n        top_indices = np.argsort(gain)[-3:]  # Top 3 items per objective\n        for idx in top_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Adaptive random perturbation (20% probability)\n    if np.random.rand() < 0.2:\n        perturb_indices = np.random.choice(len(weight_lst), size=2, replace=False)\n        for idx in perturb_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7439505675889477,
            0.21176332235336304
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest normalized combined objective value\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: objective-specific marginal gain flips\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Flip items with highest marginal gain for each objective\n    for gain, obj in [(marginal_gain1, 1), (marginal_gain2, 2)]:\n        top_indices = np.argsort(gain)[-3:]  # Top 3 items per objective\n        for idx in top_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Adaptive random perturbation (20% probability)\n    if np.random.rand() < 0.2:\n        perturb_indices = np.random.choice(len(weight_lst), size=2, replace=False)\n        for idx in perturb_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a normalized combined objective score, then applies a hybrid local search that flips items with high marginal gains for each objective while maintaining feasibility. It also includes a probabilistic random perturbation step to escape local optima. The selection prioritizes solutions with better normalized scores, while the local search focuses on objective-specific item flips and adaptive random changes.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest normalized combined objective value\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: objective-specific marginal gain flips\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Flip items with highest marginal gain for each objective\n    for gain, obj in [(marginal_gain1, 1), (marginal_gain2, 2)]:\n        top_indices = np.argsort(gain)[-3:]  # Top 3 items per objective\n        for idx in top_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Adaptive random perturbation (20% probability)\n    if np.random.rand() < 0.2:\n        perturb_indices = np.random.choice(len(weight_lst), size=2, replace=False)\n        for idx in perturb_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a high-performing solution from the archive by prioritizing those with normalized objective values, then applies a hybrid local search combining adaptive bit-flipping (prioritizing high value-to-weight ratio items), probabilistic value-based perturbations (removing low-value, high-weight items), and dynamic weight adjustments (temporarily scaling weights for exploration), ensuring feasibility by strict capacity checks at each step. The approach balances exploitation (value optimization) and exploration (perturbations) while maintaining solution feasibility.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with high normalized objective values\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive bit-flipping based on value-to-weight ratio\n    value_ratio = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(value_ratio)[::-1]  # Highest ratio first\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Value-based perturbation: flip items with low value but high weight\n    if np.random.rand() < 0.4:\n        low_value_high_weight = (value1_lst < np.median(value1_lst)) & (value2_lst < np.median(value2_lst)) & (weight_lst > np.median(weight_lst))\n        perturb_indices = np.where(low_value_high_weight)[0]\n        for idx in perturb_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Dynamic weight adjustment: scale weights temporarily for perturbation\n    if np.random.rand() < 0.3:\n        temp_weights = weight_lst * (1 + 0.1 * np.random.randn(n_items))\n        for idx in np.random.choice(n_items, size=min(3, n_items), replace=False):\n            if base_solution[idx] == 0 and current_weight + temp_weights[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += temp_weights[idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n- **Select** solutions with high normalized objective sums but **flip items** offering the largest marginal gains in either objective.\n- **Augment** with **1-2 random flips** to escape local optima while ensuring feasibility.\n- **Reject** neighbors violating capacity; **repeat** until a valid neighbor is found.\n- **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~80)*\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 27,
        "algorithm": "The algorithm selects a solution from the archive based on a diversity-aware normalized score, then applies a three-phase local search: first flipping items with high marginal gains for both objectives, followed by targeted perturbations of low value-to-weight ratio items, and finally dynamic weight scaling for exploration, all while maintaining feasibility. The selection prioritizes solutions with high normalized scores but also considers their potential for improvement through adaptive perturbations, with the first phase focusing on objective-maximizing flips, the second on low-value items, and the third on dynamic weight adjustments.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with high diversity-aware normalized score\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Normalized score with diversity consideration\n        normalized_scores = []\n        for sol, obj in archive:\n            normalized_score = (obj[0]/max_obj1 + obj[1]/max_obj2) * (1 + 0.1 * (np.sum(sol) / len(sol)))\n            normalized_scores.append(normalized_score)\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    n_items = len(weight_lst)\n\n    # Phase 1: Marginal gain flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    for gain in [marginal_gain1, marginal_gain2]:\n        top_indices = np.argsort(gain)[-5:]  # Top 5 items per objective\n        for idx in top_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Targeted perturbations (low value-to-weight ratio)\n    value_ratio = (value1_lst + value2_lst) / weight_lst\n    low_ratio_indices = np.where(value_ratio < np.median(value_ratio))[0]\n    if np.random.rand() < 0.3 and len(low_ratio_indices) > 0:\n        perturb_indices = np.random.choice(low_ratio_indices, size=min(3, len(low_ratio_indices)), replace=False)\n        for idx in perturb_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Phase 3: Dynamic weight scaling for exploration\n    if np.random.rand() < 0.2:\n        temp_weights = weight_lst * (1 + 0.1 * np.random.randn(n_items))\n        for idx in np.random.choice(n_items, size=min(2, n_items), replace=False):\n            if base_solution[idx] == 0 and current_weight + temp_weights[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += temp_weights[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8161294309538617,
            0.382090300321579
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with high diversity-aware normalized score\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Normalized score with diversity consideration\n        normalized_scores = []\n        for sol, obj in archive:\n            normalized_score = (obj[0]/max_obj1 + obj[1]/max_obj2) * (1 + 0.1 * (np.sum(sol) / len(sol)))\n            normalized_scores.append(normalized_score)\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    n_items = len(weight_lst)\n\n    # Phase 1: Marginal gain flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    for gain in [marginal_gain1, marginal_gain2]:\n        top_indices = np.argsort(gain)[-5:]  # Top 5 items per objective\n        for idx in top_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Targeted perturbations (low value-to-weight ratio)\n    value_ratio = (value1_lst + value2_lst) / weight_lst\n    low_ratio_indices = np.where(value_ratio < np.median(value_ratio))[0]\n    if np.random.rand() < 0.3 and len(low_ratio_indices) > 0:\n        perturb_indices = np.random.choice(low_ratio_indices, size=min(3, len(low_ratio_indices)), replace=False)\n        for idx in perturb_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Phase 3: Dynamic weight scaling for exploration\n    if np.random.rand() < 0.2:\n        temp_weights = weight_lst * (1 + 0.1 * np.random.randn(n_items))\n        for idx in np.random.choice(n_items, size=min(2, n_items), replace=False):\n            if base_solution[idx] == 0 and current_weight + temp_weights[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += temp_weights[idx]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a high-performing solution from the archive by prioritizing those with normalized objective values, then applies a hybrid local search combining adaptive bit-flipping (prioritizing high value-to-weight ratio items), probabilistic value-based perturbations (removing low-value, high-weight items), and dynamic weight adjustments (temporarily scaling weights for exploration), ensuring feasibility by strict capacity checks at each step. The approach balances exploitation (value optimization) and exploration (perturbations) while maintaining solution feasibility.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with high normalized objective values\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive bit-flipping based on value-to-weight ratio\n    value_ratio = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(value_ratio)[::-1]  # Highest ratio first\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Value-based perturbation: flip items with low value but high weight\n    if np.random.rand() < 0.4:\n        low_value_high_weight = (value1_lst < np.median(value1_lst)) & (value2_lst < np.median(value2_lst)) & (weight_lst > np.median(weight_lst))\n        perturb_indices = np.where(low_value_high_weight)[0]\n        for idx in perturb_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Dynamic weight adjustment: scale weights temporarily for perturbation\n    if np.random.rand() < 0.3:\n        temp_weights = weight_lst * (1 + 0.1 * np.random.randn(n_items))\n        for idx in np.random.choice(n_items, size=min(3, n_items), replace=False):\n            if base_solution[idx] == 0 and current_weight + temp_weights[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += temp_weights[idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n- **Select** solutions with high normalized objective sums but **flip items** offering the largest marginal gains in either objective.\n- **Augment** with **1-2 random flips** to escape local optima while ensuring feasibility.\n- **Reject** neighbors violating capacity; **repeat** until a valid neighbor is found.\n- **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~80)*\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 28,
        "algorithm": "The algorithm selects a high-performing solution from the archive based on normalized combined objective values, then applies a hybrid local search combining adaptive value-weighted flipping (prioritizing items with high combined value-to-weight ratios) and probabilistic diversity-aware perturbations (randomly removing low-value items with a probability inversely proportional to their weight-to-value ratio), while ensuring feasibility through dynamic capacity checks and iterative refinement.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high normalized combined objective values\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive value-weighted flipping\n    value_ratio1 = value1_lst / (weight_lst + 1e-6)\n    value_ratio2 = value2_lst / (weight_lst + 1e-6)\n    combined_ratio = value_ratio1 + value_ratio2\n    sorted_indices = np.argsort(combined_ratio)[::-1]\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Probabilistic diversity-aware perturbations\n    if np.random.rand() < 0.5:\n        low_value_items = (value1_lst < np.percentile(value1_lst, 30)) & (value2_lst < np.percentile(value2_lst, 30))\n        perturb_indices = np.where(low_value_items)[0]\n        for idx in perturb_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                if np.random.rand() < (weight_lst[idx] / (value1_lst[idx] + value2_lst[idx] + 1e-6)):\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n\n    # Iterative refinement\n    for _ in range(3):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.5857095992787877,
            0.34616318345069885
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high normalized combined objective values\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive value-weighted flipping\n    value_ratio1 = value1_lst / (weight_lst + 1e-6)\n    value_ratio2 = value2_lst / (weight_lst + 1e-6)\n    combined_ratio = value_ratio1 + value_ratio2\n    sorted_indices = np.argsort(combined_ratio)[::-1]\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Probabilistic diversity-aware perturbations\n    if np.random.rand() < 0.5:\n        low_value_items = (value1_lst < np.percentile(value1_lst, 30)) & (value2_lst < np.percentile(value2_lst, 30))\n        perturb_indices = np.where(low_value_items)[0]\n        for idx in perturb_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                if np.random.rand() < (weight_lst[idx] / (value1_lst[idx] + value2_lst[idx] + 1e-6)):\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n\n    # Iterative refinement\n    for _ in range(3):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a high-performing solution from the archive by prioritizing those with normalized objective values, then applies a hybrid local search combining adaptive bit-flipping (prioritizing high value-to-weight ratio items), probabilistic value-based perturbations (removing low-value, high-weight items), and dynamic weight adjustments (temporarily scaling weights for exploration), ensuring feasibility by strict capacity checks at each step. The approach balances exploitation (value optimization) and exploration (perturbations) while maintaining solution feasibility.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with high normalized objective values\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive bit-flipping based on value-to-weight ratio\n    value_ratio = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(value_ratio)[::-1]  # Highest ratio first\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Value-based perturbation: flip items with low value but high weight\n    if np.random.rand() < 0.4:\n        low_value_high_weight = (value1_lst < np.median(value1_lst)) & (value2_lst < np.median(value2_lst)) & (weight_lst > np.median(weight_lst))\n        perturb_indices = np.where(low_value_high_weight)[0]\n        for idx in perturb_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Dynamic weight adjustment: scale weights temporarily for perturbation\n    if np.random.rand() < 0.3:\n        temp_weights = weight_lst * (1 + 0.1 * np.random.randn(n_items))\n        for idx in np.random.choice(n_items, size=min(3, n_items), replace=False):\n            if base_solution[idx] == 0 and current_weight + temp_weights[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += temp_weights[idx]\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 29,
        "algorithm": "The algorithm selects a high-performing solution from the archive using a weighted sum of normalized objectives, then applies a hybrid local search combining value-weighted flipping (prioritizing high-value items), diversity-aware perturbations (removing items from solutions with low diversity), and adaptive capacity utilization (probabilistically adding items based on remaining capacity). The method ensures feasibility by dynamically checking weight constraints at each step.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest weighted sum of normalized objectives\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        weights = [0.6, 0.4]  # Weighting for objectives\n        scores = [(obj[0]/max_obj1 * weights[0] + obj[1]/max_obj2 * weights[1]) for _, obj in archive]\n        selected_idx = np.argmax(scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Value-weighted flipping: prioritize items with high combined value\n    combined_value = value1_lst + value2_lst\n    value_weights = combined_value / np.sum(combined_value)\n    sorted_indices = np.argsort(value_weights)[::-1]\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Diversity-aware perturbation: flip items that are in many similar solutions\n    if np.random.rand() < 0.5:\n        solution_matrix = np.array([sol[0] for sol in archive])\n        item_diversity = np.std(solution_matrix, axis=0)\n        perturb_indices = np.where((item_diversity > 0.3) & (base_solution == 1))[0]\n        for idx in perturb_indices:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Adaptive capacity utilization: adjust flip probability based on remaining capacity\n    remaining_capacity = capacity - current_weight\n    flip_prob = min(0.7, remaining_capacity / capacity * 0.9)\n\n    if np.random.rand() < flip_prob:\n        candidate_indices = np.where(base_solution == 0)[0]\n        if len(candidate_indices) > 0:\n            idx = np.random.choice(candidate_indices)\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.6749668075587771,
            4.327523827552795
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest weighted sum of normalized objectives\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        weights = [0.6, 0.4]  # Weighting for objectives\n        scores = [(obj[0]/max_obj1 * weights[0] + obj[1]/max_obj2 * weights[1]) for _, obj in archive]\n        selected_idx = np.argmax(scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Value-weighted flipping: prioritize items with high combined value\n    combined_value = value1_lst + value2_lst\n    value_weights = combined_value / np.sum(combined_value)\n    sorted_indices = np.argsort(value_weights)[::-1]\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Diversity-aware perturbation: flip items that are in many similar solutions\n    if np.random.rand() < 0.5:\n        solution_matrix = np.array([sol[0] for sol in archive])\n        item_diversity = np.std(solution_matrix, axis=0)\n        perturb_indices = np.where((item_diversity > 0.3) & (base_solution == 1))[0]\n        for idx in perturb_indices:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Adaptive capacity utilization: adjust flip probability based on remaining capacity\n    remaining_capacity = capacity - current_weight\n    flip_prob = min(0.7, remaining_capacity / capacity * 0.9)\n\n    if np.random.rand() < flip_prob:\n        candidate_indices = np.where(base_solution == 0)[0]\n        if len(candidate_indices) > 0:\n            idx = np.random.choice(candidate_indices)\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a high-performing solution from the archive by prioritizing those with normalized objective values, then applies a hybrid local search combining adaptive bit-flipping (prioritizing high value-to-weight ratio items), probabilistic value-based perturbations (removing low-value, high-weight items), and dynamic weight adjustments (temporarily scaling weights for exploration), ensuring feasibility by strict capacity checks at each step. The approach balances exploitation (value optimization) and exploration (perturbations) while maintaining solution feasibility.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with high normalized objective values\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive bit-flipping based on value-to-weight ratio\n    value_ratio = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(value_ratio)[::-1]  # Highest ratio first\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Value-based perturbation: flip items with low value but high weight\n    if np.random.rand() < 0.4:\n        low_value_high_weight = (value1_lst < np.median(value1_lst)) & (value2_lst < np.median(value2_lst)) & (weight_lst > np.median(weight_lst))\n        perturb_indices = np.where(low_value_high_weight)[0]\n        for idx in perturb_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Dynamic weight adjustment: scale weights temporarily for perturbation\n    if np.random.rand() < 0.3:\n        temp_weights = weight_lst * (1 + 0.1 * np.random.randn(n_items))\n        for idx in np.random.choice(n_items, size=min(3, n_items), replace=False):\n            if base_solution[idx] == 0 and current_weight + temp_weights[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += temp_weights[idx]\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 30,
        "algorithm": "The algorithm selects a balanced solution from the archive (prioritizing solutions with similar objective values) and applies a hybrid local search combining value-weighted bit-flipping (focusing on high-value-weight items), probabilistic objective-space perturbations (randomly flipping items based on individual objective ratios), and adaptive capacity-aware swaps (swapping critical items while respecting capacity). It ensures feasibility by dynamically checking weight constraints during each operation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced objectives\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    balance_scores = np.abs(obj1_scores - obj2_scores)\n    selected_idx = np.argmin(balance_scores) if np.random.rand() < 0.7 else np.argmax(balance_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Value-weighted bit-flipping\n    combined_value = value1_lst + value2_lst\n    value_weight_ratio = combined_value / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(value_weight_ratio)[::-1]\n\n    for idx in sorted_indices[:min(7, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Objective-space perturbation\n    if np.random.rand() < 0.5:\n        obj1_ratio = value1_lst / (weight_lst + 1e-6)\n        obj2_ratio = value2_lst / (weight_lst + 1e-6)\n        obj1_indices = np.argsort(obj1_ratio)[::-1]\n        obj2_indices = np.argsort(obj2_ratio)[::-1]\n\n        for idx in obj1_indices[:min(3, n_items)]:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        for idx in obj2_indices[:min(3, n_items)]:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive capacity-aware swaps\n    if np.random.rand() < 0.4:\n        item_criticality = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        sorted_critical = np.argsort(item_criticality)[::-1]\n\n        for i in range(min(5, n_items)):\n            for j in range(i+1, min(i+5, n_items)):\n                if base_solution[sorted_critical[i]] == 1 and base_solution[sorted_critical[j]] == 0:\n                    weight_diff = weight_lst[sorted_critical[j]] - weight_lst[sorted_critical[i]]\n                    if current_weight + weight_diff <= capacity:\n                        new_solution[sorted_critical[i]] = 0\n                        new_solution[sorted_critical[j]] = 1\n                        current_weight += weight_diff\n                        break\n\n    return new_solution\n\n",
        "score": [
            -0.796088654335021,
            0.20981630682945251
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced objectives\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    balance_scores = np.abs(obj1_scores - obj2_scores)\n    selected_idx = np.argmin(balance_scores) if np.random.rand() < 0.7 else np.argmax(balance_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Value-weighted bit-flipping\n    combined_value = value1_lst + value2_lst\n    value_weight_ratio = combined_value / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(value_weight_ratio)[::-1]\n\n    for idx in sorted_indices[:min(7, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Objective-space perturbation\n    if np.random.rand() < 0.5:\n        obj1_ratio = value1_lst / (weight_lst + 1e-6)\n        obj2_ratio = value2_lst / (weight_lst + 1e-6)\n        obj1_indices = np.argsort(obj1_ratio)[::-1]\n        obj2_indices = np.argsort(obj2_ratio)[::-1]\n\n        for idx in obj1_indices[:min(3, n_items)]:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        for idx in obj2_indices[:min(3, n_items)]:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive capacity-aware swaps\n    if np.random.rand() < 0.4:\n        item_criticality = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        sorted_critical = np.argsort(item_criticality)[::-1]\n\n        for i in range(min(5, n_items)):\n            for j in range(i+1, min(i+5, n_items)):\n                if base_solution[sorted_critical[i]] == 1 and base_solution[sorted_critical[j]] == 0:\n                    weight_diff = weight_lst[sorted_critical[j]] - weight_lst[sorted_critical[i]]\n                    if current_weight + weight_diff <= capacity:\n                        new_solution[sorted_critical[i]] = 0\n                        new_solution[sorted_critical[j]] = 1\n                        current_weight += weight_diff\n                        break\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a high-performing solution from the archive by prioritizing those with normalized objective values, then applies a hybrid local search combining adaptive bit-flipping (prioritizing high value-to-weight ratio items), probabilistic value-based perturbations (removing low-value, high-weight items), and dynamic weight adjustments (temporarily scaling weights for exploration), ensuring feasibility by strict capacity checks at each step. The approach balances exploitation (value optimization) and exploration (perturbations) while maintaining solution feasibility.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with high normalized objective values\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive bit-flipping based on value-to-weight ratio\n    value_ratio = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(value_ratio)[::-1]  # Highest ratio first\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Value-based perturbation: flip items with low value but high weight\n    if np.random.rand() < 0.4:\n        low_value_high_weight = (value1_lst < np.median(value1_lst)) & (value2_lst < np.median(value2_lst)) & (weight_lst > np.median(weight_lst))\n        perturb_indices = np.where(low_value_high_weight)[0]\n        for idx in perturb_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Dynamic weight adjustment: scale weights temporarily for perturbation\n    if np.random.rand() < 0.3:\n        temp_weights = weight_lst * (1 + 0.1 * np.random.randn(n_items))\n        for idx in np.random.choice(n_items, size=min(3, n_items), replace=False):\n            if base_solution[idx] == 0 and current_weight + temp_weights[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += temp_weights[idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n- **Select** solutions with high normalized objective sums but **flip items** offering the largest marginal gains in either objective.\n- **Augment** with **1-2 random flips** to escape local optima while ensuring feasibility.\n- **Reject** neighbors violating capacity; **repeat** until a valid neighbor is found.\n- **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~80)*\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 31,
        "algorithm": "The algorithm selects a promising solution from the archive by normalizing objective sums, then applies a hybrid local search combining targeted flips of high value-to-weight ratio items, adaptive perturbations of low-marginal-contribution items, and dynamic weight adjustments for exploration, while ensuring feasibility at each step. It prioritizes items with the highest combined value-to-weight ratios and occasionally perturbs low-contribution items to escape local optima. The method balances exploitation and exploration through weighted randomness and iterative refinement.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted flips: high value-to-weight ratio items\n    value_ratio = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(value_ratio)[::-1]\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Adaptive perturbation: flip low marginal contribution items\n    if np.random.rand() < 0.4:\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 5)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Dynamic weight adjustment for exploration\n    if np.random.rand() < 0.3:\n        temp_weights = weight_lst * (1 + 0.1 * np.random.randn(n_items))\n        for idx in np.random.choice(n_items, size=min(3, n_items), replace=False):\n            if base_solution[idx] == 0 and current_weight + temp_weights[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += temp_weights[idx]\n\n    # Iterative refinement: additional random flips\n    for _ in range(min(2, n_items)):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.498320809846788,
            0.22736230492591858
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted flips: high value-to-weight ratio items\n    value_ratio = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(value_ratio)[::-1]\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Adaptive perturbation: flip low marginal contribution items\n    if np.random.rand() < 0.4:\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 5)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Dynamic weight adjustment for exploration\n    if np.random.rand() < 0.3:\n        temp_weights = weight_lst * (1 + 0.1 * np.random.randn(n_items))\n        for idx in np.random.choice(n_items, size=min(3, n_items), replace=False):\n            if base_solution[idx] == 0 and current_weight + temp_weights[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += temp_weights[idx]\n\n    # Iterative refinement: additional random flips\n    for _ in range(min(2, n_items)):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 4 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with potential for improvement (items that can be added without exceeding capacity), then applies a hybrid approach combining value-weighted greedy selection (prioritizing items with highest combined marginal value) and adaptive random perturbations (flipping items probabilistically, with flip probability adjusted based on archive diversity). Finally, it ensures feasibility through greedy backtracking by removing low-marginal-value items if the weight exceeds capacity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    import random\n    import numpy as np\n\n    # Select a solution with potential for improvement by considering both value and archive diversity\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(sol * weight_lst)\n        remaining_capacity = capacity - current_weight\n        potential_items = np.where((sol == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(potential_items) > 0:\n            candidates.append(sol)\n\n    if not candidates:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        selected_solution = random.choice(candidates).copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Step 1: Value-weighted greedy selection\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    for i in np.argsort(-combined_marginal):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    # Step 2: Adaptive random perturbation based on solution quality\n    num_items = len(new_solution)\n    flip_prob = 0.3  # Base flip probability\n    if len(archive) > 1:\n        # Adjust flip probability based on archive diversity\n        archive_weights = np.array([sol[0] for sol, _ in archive])\n        diversity = np.mean(np.std(archive_weights, axis=0))\n        flip_prob = min(0.5, flip_prob + 0.2 * diversity)\n\n    flip_indices = [i for i in range(num_items) if random.random() < flip_prob]\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    # Step 3: Greedy backtracking to maintain feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess_weight = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest marginal value contribution\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        remove_idx = removable_items[np.argmin(marginal_contrib[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a high-performing solution from the archive by prioritizing those with normalized objective values, then applies a hybrid local search combining adaptive bit-flipping (prioritizing high value-to-weight ratio items), probabilistic value-based perturbations (removing low-value, high-weight items), and dynamic weight adjustments (temporarily scaling weights for exploration), ensuring feasibility by strict capacity checks at each step. The approach balances exploitation (value optimization) and exploration (perturbations) while maintaining solution feasibility.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with high normalized objective values\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive bit-flipping based on value-to-weight ratio\n    value_ratio = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(value_ratio)[::-1]  # Highest ratio first\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Value-based perturbation: flip items with low value but high weight\n    if np.random.rand() < 0.4:\n        low_value_high_weight = (value1_lst < np.median(value1_lst)) & (value2_lst < np.median(value2_lst)) & (weight_lst > np.median(weight_lst))\n        perturb_indices = np.where(low_value_high_weight)[0]\n        for idx in perturb_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Dynamic weight adjustment: scale weights temporarily for perturbation\n    if np.random.rand() < 0.3:\n        temp_weights = weight_lst * (1 + 0.1 * np.random.randn(n_items))\n        for idx in np.random.choice(n_items, size=min(3, n_items), replace=False):\n            if base_solution[idx] == 0 and current_weight + temp_weights[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += temp_weights[idx]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with high marginal value potential and weight diversity, then applies a hybrid approach combining marginal value-based addition, adaptive probabilistic swaps, and weighted removal to generate a feasible neighbor solution. It balances exploration and exploitation by adjusting swap probabilities based on archive diversity and ensures feasibility through targeted item removal when capacity is exceeded. The critical design choices include prioritizing items with high combined marginal value, favoring weight-diverse items, and dynamically adjusting exploration intensity based on solution quality.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    import random\n    import numpy as np\n\n    # Select the solution with the highest potential for improvement\n    best_candidate = None\n    max_potential = -1\n    for sol, _ in archive:\n        current_weight = np.sum(sol * weight_lst)\n        remaining_capacity = capacity - current_weight\n        potential_items = np.where((sol == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(potential_items) > 0:\n            # Calculate potential based on combined marginal value and weight diversity\n            marginal_value1 = value1_lst[potential_items] / (weight_lst[potential_items] + 1e-10)\n            marginal_value2 = value2_lst[potential_items] / (weight_lst[potential_items] + 1e-10)\n            combined_marginal = marginal_value1 + marginal_value2\n            weight_diversity = np.std(weight_lst[potential_items])\n            potential = np.sum(combined_marginal) * (1 + weight_diversity)\n            if potential > max_potential:\n                max_potential = potential\n                best_candidate = sol\n\n    if best_candidate is None:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        selected_solution = best_candidate.copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Step 1: Marginal value-based selection with weight diversity consideration\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n    weight_diversity = np.std(weight_lst)\n\n    for i in np.argsort(-combined_marginal):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            # Add item with higher probability if it's part of diverse weight range\n            add_prob = 0.7 if (weight_lst[i] > np.percentile(weight_lst, 30) and weight_lst[i] < np.percentile(weight_lst, 70)) else 0.4\n            if random.random() < add_prob:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Step 2: Adaptive probabilistic swaps based on solution quality and diversity\n    num_items = len(new_solution)\n    swap_prob = 0.2  # Base swap probability\n    if len(archive) > 1:\n        # Adjust swap probability based on archive diversity and solution quality\n        archive_weights = np.array([sol[0] for sol, _ in archive])\n        diversity = np.mean(np.std(archive_weights, axis=0))\n        swap_prob = min(0.4, swap_prob + 0.15 * diversity)\n\n    for i in range(num_items):\n        if random.random() < swap_prob:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n            elif new_solution[i] == 1:\n                new_solution[i] = 0\n\n    # Step 3: Weighted removal to maintain feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest weighted marginal value contribution\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        weights = weight_lst[removable_items]\n        weighted_contrib = marginal_contrib[removable_items] * weights\n        remove_idx = removable_items[np.argmin(weighted_contrib)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** neighbors violating capacity; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~80)*\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 32,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) + 1e-10)\n    scores = np.sum(normalized_obj, axis=1)\n    top_indices = np.argsort(-scores)[:max(1, len(archive) // 5)]\n    selected_solution = archive[np.random.choice(top_indices)][0].copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Iterate 5-10 times to refine the solution\n    for _ in range(np.random.randint(5, 11)):\n        # Flip items with highest marginal gains in either objective\n        marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n        marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n        combined_gain = marginal_gain1 + marginal_gain2\n        top_gain_indices = np.argsort(-combined_gain)[:min(3, len(weight_lst))]\n\n        for idx in top_gain_indices:\n            if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif new_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n        # Add 1-2 random flips\n        for _ in range(np.random.randint(1, 3)):\n            candidate_idx = np.random.randint(len(weight_lst))\n            if new_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n            elif new_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n        # Ensure feasibility\n        while current_weight > capacity:\n            removable_items = np.where(new_solution == 1)[0]\n            if len(removable_items) == 0:\n                break\n            # Remove item with smallest marginal contribution\n            marginal_contrib = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n            remove_idx = removable_items[np.argmin(marginal_contrib[removable_items])]\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.31702555991114156,
            0.5195860862731934
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) + 1e-10)\n    scores = np.sum(normalized_obj, axis=1)\n    top_indices = np.argsort(-scores)[:max(1, len(archive) // 5)]\n    selected_solution = archive[np.random.choice(top_indices)][0].copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Iterate 5-10 times to refine the solution\n    for _ in range(np.random.randint(5, 11)):\n        # Flip items with highest marginal gains in either objective\n        marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n        marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n        combined_gain = marginal_gain1 + marginal_gain2\n        top_gain_indices = np.argsort(-combined_gain)[:min(3, len(weight_lst))]\n\n        for idx in top_gain_indices:\n            if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif new_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n        # Add 1-2 random flips\n        for _ in range(np.random.randint(1, 3)):\n            candidate_idx = np.random.randint(len(weight_lst))\n            if new_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n            elif new_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n        # Ensure feasibility\n        while current_weight > capacity:\n            removable_items = np.where(new_solution == 1)[0]\n            if len(removable_items) == 0:\n                break\n            # Remove item with smallest marginal contribution\n            marginal_contrib = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n            remove_idx = removable_items[np.argmin(marginal_contrib[removable_items])]\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with potential for improvement (items that can be added without exceeding capacity), then applies a hybrid approach combining value-weighted greedy selection (prioritizing items with highest combined marginal value) and adaptive random perturbations (flipping items probabilistically, with flip probability adjusted based on archive diversity). Finally, it ensures feasibility through greedy backtracking by removing low-marginal-value items if the weight exceeds capacity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    import random\n    import numpy as np\n\n    # Select a solution with potential for improvement by considering both value and archive diversity\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(sol * weight_lst)\n        remaining_capacity = capacity - current_weight\n        potential_items = np.where((sol == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(potential_items) > 0:\n            candidates.append(sol)\n\n    if not candidates:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        selected_solution = random.choice(candidates).copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Step 1: Value-weighted greedy selection\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    for i in np.argsort(-combined_marginal):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    # Step 2: Adaptive random perturbation based on solution quality\n    num_items = len(new_solution)\n    flip_prob = 0.3  # Base flip probability\n    if len(archive) > 1:\n        # Adjust flip probability based on archive diversity\n        archive_weights = np.array([sol[0] for sol, _ in archive])\n        diversity = np.mean(np.std(archive_weights, axis=0))\n        flip_prob = min(0.5, flip_prob + 0.2 * diversity)\n\n    flip_indices = [i for i in range(num_items) if random.random() < flip_prob]\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    # Step 3: Greedy backtracking to maintain feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess_weight = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest marginal value contribution\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        remove_idx = removable_items[np.argmin(marginal_contrib[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** neighbors violating capacity; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~80)*\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 33,
        "algorithm": "The algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.8399822123976359,
            0.2032187581062317
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive by normalizing objective sums, then applies a hybrid local search combining targeted flips of high value-to-weight ratio items, adaptive perturbations of low-marginal-contribution items, and dynamic weight adjustments for exploration, while ensuring feasibility at each step. It prioritizes items with the highest combined value-to-weight ratios and occasionally perturbs low-contribution items to escape local optima. The method balances exploitation and exploration through weighted randomness and iterative refinement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted flips: high value-to-weight ratio items\n    value_ratio = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(value_ratio)[::-1]\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Adaptive perturbation: flip low marginal contribution items\n    if np.random.rand() < 0.4:\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 5)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Dynamic weight adjustment for exploration\n    if np.random.rand() < 0.3:\n        temp_weights = weight_lst * (1 + 0.1 * np.random.randn(n_items))\n        for idx in np.random.choice(n_items, size=min(3, n_items), replace=False):\n            if base_solution[idx] == 0 and current_weight + temp_weights[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += temp_weights[idx]\n\n    # Iterative refinement: additional random flips\n    for _ in range(min(2, n_items)):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** neighbors violating capacity; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~80)*\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 34,
        "algorithm": "This algorithm prioritizes high-performance solutions (top 20% by normalized objective sums) and enhances them through a diversity-aware local search that strategically flips items based on combined marginal gains and crowding distance, while maintaining feasibility through capacity checks. It further diversifies by replacing low-contribution items with high-potential alternatives, balancing exploration and exploitation to improve multi-objective trade-offs.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate crowding distance for diversity-aware selection\n    objectives = np.array([obj for _, obj in archive])\n    n_solutions = len(objectives)\n    crowding_dist = np.zeros(n_solutions)\n\n    for m in range(2):  # For each objective\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding_dist[sorted_idx[0]] = crowding_dist[sorted_idx[-1]] = np.inf  # Boundary solutions\n        for i in range(1, n_solutions - 1):\n            crowding_dist[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (max_obj1 if m == 0 else max_obj2)\n\n    # Prioritize flipping items based on multi-objective marginal gains and crowding distance\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = (marginal_gain1 + marginal_gain2) * (1 + crowding_dist[selected_idx] / (np.max(crowding_dist) + 1e-6))\n\n    # Flip top 3 high-gain items\n    high_gain_indices = np.argsort(-combined_gain)[:min(3, len(weight_lst))]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled diversification: replace low-contribution items with high-potential alternatives\n    if np.random.rand() < 0.4:\n        low_contrib_indices = np.argsort(combined_gain)[:min(2, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            # Try adding a high-potential item\n            candidate_idx = np.random.choice(np.where(base_solution == 0)[0])\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.41987026288705726,
            0.8043969869613647
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate crowding distance for diversity-aware selection\n    objectives = np.array([obj for _, obj in archive])\n    n_solutions = len(objectives)\n    crowding_dist = np.zeros(n_solutions)\n\n    for m in range(2):  # For each objective\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding_dist[sorted_idx[0]] = crowding_dist[sorted_idx[-1]] = np.inf  # Boundary solutions\n        for i in range(1, n_solutions - 1):\n            crowding_dist[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (max_obj1 if m == 0 else max_obj2)\n\n    # Prioritize flipping items based on multi-objective marginal gains and crowding distance\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = (marginal_gain1 + marginal_gain2) * (1 + crowding_dist[selected_idx] / (np.max(crowding_dist) + 1e-6))\n\n    # Flip top 3 high-gain items\n    high_gain_indices = np.argsort(-combined_gain)[:min(3, len(weight_lst))]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled diversification: replace low-contribution items with high-potential alternatives\n    if np.random.rand() < 0.4:\n        low_contrib_indices = np.argsort(combined_gain)[:min(2, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            # Try adding a high-potential item\n            candidate_idx = np.random.choice(np.where(base_solution == 0)[0])\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 35,
        "algorithm": "The algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9295394386064582,
            0.5756343901157379
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 35,
        "algorithm": "The algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9295394386064582,
            0.5756343901157379
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 36,
        "algorithm": "The algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9223724891724746,
            0.21610364317893982
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** neighbors violating capacity; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~80)*\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 37,
        "algorithm": "The algorithm selects a promising solution from the top 20% of the archive (based on normalized objective sums) and applies a hybrid local search combining targeted flipping of high-marginal-gain items (prioritizing both objectives), adaptive perturbation of low-marginal-contribution items, and controlled random bit-flips, all while ensuring feasibility through strict capacity checks. The process repeats for 3 rounds to iteratively refine the solution, balancing exploitation of high-value items with exploration of low-contribution items.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search with multiple iterations\n    for _ in range(3):  # Perform 3 rounds of refinement\n        # Targeted flipping: high marginal gain items (considering both objectives)\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n        combined_gain = marginal_gain1 + marginal_gain2\n        high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Adaptive perturbation: low marginal contribution items\n        if np.random.rand() < 0.4:  # Higher perturbation probability\n            low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n            for idx in low_gain_indices:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Random bit-flip with limited attempts\n        for _ in range(2):  # Limit to 2 random flips\n            candidate_idx = np.random.randint(len(weight_lst))\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7167571300866709,
            0.3098699748516083
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search with multiple iterations\n    for _ in range(3):  # Perform 3 rounds of refinement\n        # Targeted flipping: high marginal gain items (considering both objectives)\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n        combined_gain = marginal_gain1 + marginal_gain2\n        high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Adaptive perturbation: low marginal contribution items\n        if np.random.rand() < 0.4:  # Higher perturbation probability\n            low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n            for idx in low_gain_indices:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Random bit-flip with limited attempts\n        for _ in range(2):  # Limit to 2 random flips\n            candidate_idx = np.random.randint(len(weight_lst))\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 5 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with potential for improvement (items that can be added without exceeding capacity), then applies a hybrid approach combining value-weighted greedy selection (prioritizing items with highest combined marginal value) and adaptive random perturbations (flipping items probabilistically, with flip probability adjusted based on archive diversity). Finally, it ensures feasibility through greedy backtracking by removing low-marginal-value items if the weight exceeds capacity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    import random\n    import numpy as np\n\n    # Select a solution with potential for improvement by considering both value and archive diversity\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(sol * weight_lst)\n        remaining_capacity = capacity - current_weight\n        potential_items = np.where((sol == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(potential_items) > 0:\n            candidates.append(sol)\n\n    if not candidates:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        selected_solution = random.choice(candidates).copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Step 1: Value-weighted greedy selection\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    for i in np.argsort(-combined_marginal):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    # Step 2: Adaptive random perturbation based on solution quality\n    num_items = len(new_solution)\n    flip_prob = 0.3  # Base flip probability\n    if len(archive) > 1:\n        # Adjust flip probability based on archive diversity\n        archive_weights = np.array([sol[0] for sol, _ in archive])\n        diversity = np.mean(np.std(archive_weights, axis=0))\n        flip_prob = min(0.5, flip_prob + 0.2 * diversity)\n\n    flip_indices = [i for i in range(num_items) if random.random() < flip_prob]\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    # Step 3: Greedy backtracking to maintain feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess_weight = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest marginal value contribution\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        remove_idx = removable_items[np.argmin(marginal_contrib[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a high-performing solution from the archive by prioritizing those with normalized objective values, then applies a hybrid local search combining adaptive bit-flipping (prioritizing high value-to-weight ratio items), probabilistic value-based perturbations (removing low-value, high-weight items), and dynamic weight adjustments (temporarily scaling weights for exploration), ensuring feasibility by strict capacity checks at each step. The approach balances exploitation (value optimization) and exploration (perturbations) while maintaining solution feasibility.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with high normalized objective values\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive bit-flipping based on value-to-weight ratio\n    value_ratio = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(value_ratio)[::-1]  # Highest ratio first\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Value-based perturbation: flip items with low value but high weight\n    if np.random.rand() < 0.4:\n        low_value_high_weight = (value1_lst < np.median(value1_lst)) & (value2_lst < np.median(value2_lst)) & (weight_lst > np.median(weight_lst))\n        perturb_indices = np.where(low_value_high_weight)[0]\n        for idx in perturb_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Dynamic weight adjustment: scale weights temporarily for perturbation\n    if np.random.rand() < 0.3:\n        temp_weights = weight_lst * (1 + 0.1 * np.random.randn(n_items))\n        for idx in np.random.choice(n_items, size=min(3, n_items), replace=False):\n            if base_solution[idx] == 0 and current_weight + temp_weights[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += temp_weights[idx]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with high marginal value potential and weight diversity, then applies a hybrid approach combining marginal value-based addition, adaptive probabilistic swaps, and weighted removal to generate a feasible neighbor solution. It balances exploration and exploitation by adjusting swap probabilities based on archive diversity and ensures feasibility through targeted item removal when capacity is exceeded. The critical design choices include prioritizing items with high combined marginal value, favoring weight-diverse items, and dynamically adjusting exploration intensity based on solution quality.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    import random\n    import numpy as np\n\n    # Select the solution with the highest potential for improvement\n    best_candidate = None\n    max_potential = -1\n    for sol, _ in archive:\n        current_weight = np.sum(sol * weight_lst)\n        remaining_capacity = capacity - current_weight\n        potential_items = np.where((sol == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(potential_items) > 0:\n            # Calculate potential based on combined marginal value and weight diversity\n            marginal_value1 = value1_lst[potential_items] / (weight_lst[potential_items] + 1e-10)\n            marginal_value2 = value2_lst[potential_items] / (weight_lst[potential_items] + 1e-10)\n            combined_marginal = marginal_value1 + marginal_value2\n            weight_diversity = np.std(weight_lst[potential_items])\n            potential = np.sum(combined_marginal) * (1 + weight_diversity)\n            if potential > max_potential:\n                max_potential = potential\n                best_candidate = sol\n\n    if best_candidate is None:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        selected_solution = best_candidate.copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Step 1: Marginal value-based selection with weight diversity consideration\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n    weight_diversity = np.std(weight_lst)\n\n    for i in np.argsort(-combined_marginal):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            # Add item with higher probability if it's part of diverse weight range\n            add_prob = 0.7 if (weight_lst[i] > np.percentile(weight_lst, 30) and weight_lst[i] < np.percentile(weight_lst, 70)) else 0.4\n            if random.random() < add_prob:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Step 2: Adaptive probabilistic swaps based on solution quality and diversity\n    num_items = len(new_solution)\n    swap_prob = 0.2  # Base swap probability\n    if len(archive) > 1:\n        # Adjust swap probability based on archive diversity and solution quality\n        archive_weights = np.array([sol[0] for sol, _ in archive])\n        diversity = np.mean(np.std(archive_weights, axis=0))\n        swap_prob = min(0.4, swap_prob + 0.15 * diversity)\n\n    for i in range(num_items):\n        if random.random() < swap_prob:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n            elif new_solution[i] == 1:\n                new_solution[i] = 0\n\n    # Step 3: Weighted removal to maintain feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest weighted marginal value contribution\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        weights = weight_lst[removable_items]\n        weighted_contrib = marginal_contrib[removable_items] * weights\n        remove_idx = removable_items[np.argmin(weighted_contrib)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm selects a balanced solution from the archive (prioritizing solutions with similar objective values) and applies a hybrid local search combining value-weighted bit-flipping (focusing on high-value-weight items), probabilistic objective-space perturbations (randomly flipping items based on individual objective ratios), and adaptive capacity-aware swaps (swapping critical items while respecting capacity). It ensures feasibility by dynamically checking weight constraints during each operation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced objectives\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    balance_scores = np.abs(obj1_scores - obj2_scores)\n    selected_idx = np.argmin(balance_scores) if np.random.rand() < 0.7 else np.argmax(balance_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Value-weighted bit-flipping\n    combined_value = value1_lst + value2_lst\n    value_weight_ratio = combined_value / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(value_weight_ratio)[::-1]\n\n    for idx in sorted_indices[:min(7, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Objective-space perturbation\n    if np.random.rand() < 0.5:\n        obj1_ratio = value1_lst / (weight_lst + 1e-6)\n        obj2_ratio = value2_lst / (weight_lst + 1e-6)\n        obj1_indices = np.argsort(obj1_ratio)[::-1]\n        obj2_indices = np.argsort(obj2_ratio)[::-1]\n\n        for idx in obj1_indices[:min(3, n_items)]:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        for idx in obj2_indices[:min(3, n_items)]:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive capacity-aware swaps\n    if np.random.rand() < 0.4:\n        item_criticality = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        sorted_critical = np.argsort(item_criticality)[::-1]\n\n        for i in range(min(5, n_items)):\n            for j in range(i+1, min(i+5, n_items)):\n                if base_solution[sorted_critical[i]] == 1 and base_solution[sorted_critical[j]] == 0:\n                    weight_diff = weight_lst[sorted_critical[j]] - weight_lst[sorted_critical[i]]\n                    if current_weight + weight_diff <= capacity:\n                        new_solution[sorted_critical[i]] = 0\n                        new_solution[sorted_critical[j]] = 1\n                        current_weight += weight_diff\n                        break\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** neighbors violating capacity; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~80)*\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 38,
        "algorithm": "The algorithm selects promising solutions from the top 20% of the archive (based on normalized objective sums) and generates neighbors by flipping items with high marginal gains for both objectives, followed by 1-2 random feasible flips, while ensuring feasibility through iterative refinement by removing the lightest items when needed. It prioritizes items with combined high marginal gains for both objectives while maintaining diversity through random flips.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain-based flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add 1-2 random feasible flips\n    for _ in range(np.random.randint(1, 3)):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.7986965115457588,
            0.24817776679992676
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain-based flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add 1-2 random feasible flips\n    for _ in range(np.random.randint(1, 3)):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a balanced solution from the archive (prioritizing solutions with similar objective values) and applies a hybrid local search combining value-weighted bit-flipping (focusing on high-value-weight items), probabilistic objective-space perturbations (randomly flipping items based on individual objective ratios), and adaptive capacity-aware swaps (swapping critical items while respecting capacity). It ensures feasibility by dynamically checking weight constraints during each operation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced objectives\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    balance_scores = np.abs(obj1_scores - obj2_scores)\n    selected_idx = np.argmin(balance_scores) if np.random.rand() < 0.7 else np.argmax(balance_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Value-weighted bit-flipping\n    combined_value = value1_lst + value2_lst\n    value_weight_ratio = combined_value / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(value_weight_ratio)[::-1]\n\n    for idx in sorted_indices[:min(7, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Objective-space perturbation\n    if np.random.rand() < 0.5:\n        obj1_ratio = value1_lst / (weight_lst + 1e-6)\n        obj2_ratio = value2_lst / (weight_lst + 1e-6)\n        obj1_indices = np.argsort(obj1_ratio)[::-1]\n        obj2_indices = np.argsort(obj2_ratio)[::-1]\n\n        for idx in obj1_indices[:min(3, n_items)]:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        for idx in obj2_indices[:min(3, n_items)]:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive capacity-aware swaps\n    if np.random.rand() < 0.4:\n        item_criticality = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        sorted_critical = np.argsort(item_criticality)[::-1]\n\n        for i in range(min(5, n_items)):\n            for j in range(i+1, min(i+5, n_items)):\n                if base_solution[sorted_critical[i]] == 1 and base_solution[sorted_critical[j]] == 0:\n                    weight_diff = weight_lst[sorted_critical[j]] - weight_lst[sorted_critical[i]]\n                    if current_weight + weight_diff <= capacity:\n                        new_solution[sorted_critical[i]] = 0\n                        new_solution[sorted_critical[j]] = 1\n                        current_weight += weight_diff\n                        break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** neighbors violating capacity; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~80)*\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 39,
        "algorithm": "The algorithm first selects promising solutions from the top 20% of the archive based on normalized objective sums, then iteratively refines them by strategically flipping high-marginal-gain items (prioritizing either objective) while ensuring feasibility, followed by controlled random flips of low-value items to maintain diversity. The process repeats 5 times per solution to balance exploitation and exploration. The marginal gains are calculated as the maximum of the two objective values per item, and low-value items are identified by the minimum of the two objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    objectives = np.array([obj for _, obj in archive])\n    normalized_sums = (objectives[:, 0] + objectives[:, 1]) / (np.sum(weight_lst) + 1e-6)\n    selected_indices = np.argsort(normalized_sums)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(selected_indices)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    for _ in range(5):  # Iterate 5 times for refinement\n        new_solution = base_solution.copy()\n\n        # Flip items with highest marginal gains in either objective\n        marginal_gains = np.maximum(value1_lst, value2_lst) / (weight_lst + 1e-6)\n        sorted_indices = np.argsort(-marginal_gains)\n\n        for idx in sorted_indices[:min(5, len(weight_lst))]:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n        # Add 1-2 random flips of low-value items\n        low_value_indices = np.argsort(np.minimum(value1_lst, value2_lst))[:min(3, len(weight_lst))]\n        for _ in range(np.random.randint(1, 3)):\n            idx = np.random.choice(low_value_indices)\n            if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif new_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n        base_solution = new_solution\n\n    return base_solution\n\n",
        "score": [
            -0.7001313103675526,
            0.5601722896099091
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    objectives = np.array([obj for _, obj in archive])\n    normalized_sums = (objectives[:, 0] + objectives[:, 1]) / (np.sum(weight_lst) + 1e-6)\n    selected_indices = np.argsort(normalized_sums)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(selected_indices)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    for _ in range(5):  # Iterate 5 times for refinement\n        new_solution = base_solution.copy()\n\n        # Flip items with highest marginal gains in either objective\n        marginal_gains = np.maximum(value1_lst, value2_lst) / (weight_lst + 1e-6)\n        sorted_indices = np.argsort(-marginal_gains)\n\n        for idx in sorted_indices[:min(5, len(weight_lst))]:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n        # Add 1-2 random flips of low-value items\n        low_value_indices = np.argsort(np.minimum(value1_lst, value2_lst))[:min(3, len(weight_lst))]\n        for _ in range(np.random.randint(1, 3)):\n            idx = np.random.choice(low_value_indices)\n            if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif new_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n        base_solution = new_solution\n\n    return base_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** neighbors violating capacity; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~80)*\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 40,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solutions with high crowding distance and high normalized objective sums\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Calculate normalized objective sums\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        normalized_scores = np.ones(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0]/max_obj1 + objectives[:, 1]/max_obj2)\n\n    # Combine crowding and normalized scores\n    combined_scores = crowding * normalized_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate multi-objective marginal gains\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n\n    # Select top items with highest combined marginal gains\n    top_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    # Greedy flips for top gain items\n    for idx in top_gain_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Adaptive perturbation based on solution's position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.4\n        num_perturbations = 2\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n        num_perturbations = 1\n\n    if np.random.rand() < perturbation_prob:\n        # Select items with low combined marginal gains for perturbation\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        selected_perturbations = np.random.choice(low_gain_indices, min(num_perturbations, len(low_gain_indices)), replace=False)\n\n        for idx in selected_perturbations:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Final feasibility check and refinement\n    for _ in range(3):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n        else:\n            # Remove heaviest items to make feasible\n            excess = temp_weight - capacity\n            while excess > 0 and np.any(temp_solution):\n                heaviest_idx = np.argmax(weight_lst * temp_solution)\n                if temp_solution[heaviest_idx] == 1:\n                    temp_solution[heaviest_idx] = 0\n                    excess -= weight_lst[heaviest_idx]\n            new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -0.8757989809123614,
            0.4065599739551544
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solutions with high crowding distance and high normalized objective sums\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Calculate normalized objective sums\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        normalized_scores = np.ones(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0]/max_obj1 + objectives[:, 1]/max_obj2)\n\n    # Combine crowding and normalized scores\n    combined_scores = crowding * normalized_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate multi-objective marginal gains\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n\n    # Select top items with highest combined marginal gains\n    top_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    # Greedy flips for top gain items\n    for idx in top_gain_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Adaptive perturbation based on solution's position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.4\n        num_perturbations = 2\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n        num_perturbations = 1\n\n    if np.random.rand() < perturbation_prob:\n        # Select items with low combined marginal gains for perturbation\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        selected_perturbations = np.random.choice(low_gain_indices, min(num_perturbations, len(low_gain_indices)), replace=False)\n\n        for idx in selected_perturbations:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Final feasibility check and refinement\n    for _ in range(3):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n        else:\n            # Remove heaviest items to make feasible\n            excess = temp_weight - capacity\n            while excess > 0 and np.any(temp_solution):\n                heaviest_idx = np.argmax(weight_lst * temp_solution)\n                if temp_solution[heaviest_idx] == 1:\n                    temp_solution[heaviest_idx] = 0\n                    excess -= weight_lst[heaviest_idx]\n            new_solution = temp_solution\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 41,
        "algorithm": "The algorithm selects a promising solution from the archive using a hybrid of crowding distance and objective trade-off analysis, then applies a novel local search that alternates between targeted item swaps (prioritizing high-value items with trade-off considerations) and probabilistic flips (removing low-value items with dynamic probability), while ensuring feasibility through constrained capacity checks. The selection prioritizes solutions with high crowding distance (indicating potential for improvement) and adjusts perturbation probabilities based on the solution's position in the Pareto front and its objective trade-offs.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine objective dominance and adaptive crowding\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate normalized crowding distances\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate objective trade-offs\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    avg_trade_off = np.mean(trade_off)\n\n    # Alternating objective improvement with trade-off consideration\n    if np.random.rand() < 0.5 or trade_off[selected_idx] < avg_trade_off:\n        # Improve first objective with trade-off consideration\n        gain = (value1_lst + 0.3 * value2_lst) / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective with trade-off consideration\n        gain = (value2_lst + 0.3 * value1_lst) / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Targeted item swaps with feasibility check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position and trade-off\n    perturbation_prob = 0.3 if trade_off[selected_idx] < avg_trade_off else 0.6\n    if np.random.rand() < perturbation_prob:\n        # Select items with poor value-to-weight ratio for potential removal\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        poor_ratio_indices = np.argsort(value_ratio)[:min(5, len(weight_lst))]\n        for idx in poor_ratio_indices:\n            if np.random.rand() < 0.5 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9265764495419105,
            0.6385702192783356
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine objective dominance and adaptive crowding\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate normalized crowding distances\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate objective trade-offs\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    avg_trade_off = np.mean(trade_off)\n\n    # Alternating objective improvement with trade-off consideration\n    if np.random.rand() < 0.5 or trade_off[selected_idx] < avg_trade_off:\n        # Improve first objective with trade-off consideration\n        gain = (value1_lst + 0.3 * value2_lst) / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective with trade-off consideration\n        gain = (value2_lst + 0.3 * value1_lst) / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Targeted item swaps with feasibility check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position and trade-off\n    perturbation_prob = 0.3 if trade_off[selected_idx] < avg_trade_off else 0.6\n    if np.random.rand() < perturbation_prob:\n        # Select items with poor value-to-weight ratio for potential removal\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        poor_ratio_indices = np.argsort(value_ratio)[:min(5, len(weight_lst))]\n        for idx in poor_ratio_indices:\n            if np.random.rand() < 0.5 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 42,
        "algorithm": "The algorithm selects a solution from the archive using a hybrid metric combining dominance rank and entropy, then applies a novel local search that alternates between objective-specific greedy improvements (weighted by entropy) and entropy-driven perturbations (with adaptive probabilities based on solution entropy). It ensures feasibility through capacity checks and dynamic flips, prioritizing low-entropy items in perturbations to escape local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine dominance and entropy\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate dominance ranks\n    dom_counts = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] > objectives[j, 1]) or \\\n                   (objectives[i, 0] > objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]):\n                    dom_counts[i] += 1\n\n    # Calculate entropy of solutions\n    entropy = np.zeros(len(archive))\n    for i in range(len(archive)):\n        prob = np.mean(solutions[i])\n        if prob == 0 or prob == 1:\n            entropy[i] = 0\n        else:\n            entropy[i] = -prob * np.log2(prob) - (1 - prob) * np.log2(1 - prob)\n\n    # Combine metrics for selection\n    selection_scores = entropy + (1 / (1 + dom_counts))\n    selected_idx = np.argmax(selection_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement with entropy consideration\n    if np.random.rand() < 0.5:\n        # Improve first objective with entropy consideration\n        gain = (value1_lst / weight_lst) * (1 + 0.5 * entropy[selected_idx])\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective with entropy consideration\n        gain = (value2_lst / weight_lst) * (1 + 0.5 * entropy[selected_idx])\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's entropy\n    if entropy[selected_idx] < np.median(entropy):\n        # More aggressive perturbation for low-entropy solutions\n        perturbation_prob = 0.6\n    else:\n        # More conservative perturbation for high-entropy solutions\n        perturbation_prob = 0.3\n\n    if np.random.rand() < perturbation_prob:\n        # Flip items with higher probability for those with low entropy\n        item_entropy = np.zeros(len(weight_lst))\n        for i in range(len(weight_lst)):\n            prob = np.mean([sol[i] for sol, _ in archive])\n            if prob == 0 or prob == 1:\n                item_entropy[i] = 0\n            else:\n                item_entropy[i] = -prob * np.log2(prob) - (1 - prob) * np.log2(1 - prob)\n\n        low_entropy_indices = np.argsort(item_entropy)[:min(5, len(weight_lst))]\n        for idx in low_entropy_indices:\n            if np.random.rand() < 0.5:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9137392630423333,
            3.88927760720253
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine dominance and entropy\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate dominance ranks\n    dom_counts = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] > objectives[j, 1]) or \\\n                   (objectives[i, 0] > objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]):\n                    dom_counts[i] += 1\n\n    # Calculate entropy of solutions\n    entropy = np.zeros(len(archive))\n    for i in range(len(archive)):\n        prob = np.mean(solutions[i])\n        if prob == 0 or prob == 1:\n            entropy[i] = 0\n        else:\n            entropy[i] = -prob * np.log2(prob) - (1 - prob) * np.log2(1 - prob)\n\n    # Combine metrics for selection\n    selection_scores = entropy + (1 / (1 + dom_counts))\n    selected_idx = np.argmax(selection_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement with entropy consideration\n    if np.random.rand() < 0.5:\n        # Improve first objective with entropy consideration\n        gain = (value1_lst / weight_lst) * (1 + 0.5 * entropy[selected_idx])\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective with entropy consideration\n        gain = (value2_lst / weight_lst) * (1 + 0.5 * entropy[selected_idx])\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's entropy\n    if entropy[selected_idx] < np.median(entropy):\n        # More aggressive perturbation for low-entropy solutions\n        perturbation_prob = 0.6\n    else:\n        # More conservative perturbation for high-entropy solutions\n        perturbation_prob = 0.3\n\n    if np.random.rand() < perturbation_prob:\n        # Flip items with higher probability for those with low entropy\n        item_entropy = np.zeros(len(weight_lst))\n        for i in range(len(weight_lst)):\n            prob = np.mean([sol[i] for sol, _ in archive])\n            if prob == 0 or prob == 1:\n                item_entropy[i] = 0\n            else:\n                item_entropy[i] = -prob * np.log2(prob) - (1 - prob) * np.log2(1 - prob)\n\n        low_entropy_indices = np.argsort(item_entropy)[:min(5, len(weight_lst))]\n        for idx in low_entropy_indices:\n            if np.random.rand() < 0.5:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 3 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** neighbors violating capacity; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~80)*\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 43,
        "algorithm": "The algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a hybrid local search that prioritizes flipping high-marginal-gain items (targeted improvements) while occasionally perturbing low-contribution items (exploration) to escape local optima, all while maintaining feasibility through strict capacity checks. The selection balances both objectives, and the local search intelligently modifies the solution by combining targeted improvements with controlled random perturbations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n\n    # Targeted flipping of high-marginal-gain items\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation of low-marginal-contribution items\n    marginal_contribution = (value1_lst + value2_lst) / weight_lst\n    low_contrib_indices = np.argsort(marginal_contribution)[:max(1, len(weight_lst) // 4)]\n    for idx in low_contrib_indices:\n        if np.random.rand() < 0.3:  # 30% chance for low-contribution items\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Additional random flips to ensure exploration\n    n_items = len(weight_lst)\n    for _ in range(min(2, n_items)):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.4670206869627718,
            0.28124305605888367
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n\n    # Targeted flipping of high-marginal-gain items\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation of low-marginal-contribution items\n    marginal_contribution = (value1_lst + value2_lst) / weight_lst\n    low_contrib_indices = np.argsort(marginal_contribution)[:max(1, len(weight_lst) // 4)]\n    for idx in low_contrib_indices:\n        if np.random.rand() < 0.3:  # 30% chance for low-contribution items\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Additional random flips to ensure exploration\n    n_items = len(weight_lst)\n    for _ in range(min(2, n_items)):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 4 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~80)*\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 44,
        "algorithm": "The algorithm selects the top 20% of solutions from the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items first, followed by controlled random flips of low-marginal-gain items to ensure feasibility. It iteratively refines the solution by rejecting infeasible neighbors, prioritizing items with higher marginal gains while maintaining diversity through random perturbations. The key design choices are the prioritization of high-marginal-gain items, controlled randomness for exploration, and iterative feasibility checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip 1-2 low-marginal-contribution items\n    num_flips = np.random.randint(1, 3)\n    low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n    for _ in range(num_flips):\n        idx = np.random.choice(low_gain_indices)\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.832844514398914,
            0.25744909048080444
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip 1-2 low-marginal-contribution items\n    num_flips = np.random.randint(1, 3)\n    low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n    for _ in range(num_flips):\n        idx = np.random.choice(low_gain_indices)\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a balanced solution from the archive (prioritizing solutions with similar objective values) and applies a hybrid local search combining value-weighted bit-flipping (focusing on high-value-weight items), probabilistic objective-space perturbations (randomly flipping items based on individual objective ratios), and adaptive capacity-aware swaps (swapping critical items while respecting capacity). It ensures feasibility by dynamically checking weight constraints during each operation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced objectives\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    balance_scores = np.abs(obj1_scores - obj2_scores)\n    selected_idx = np.argmin(balance_scores) if np.random.rand() < 0.7 else np.argmax(balance_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Value-weighted bit-flipping\n    combined_value = value1_lst + value2_lst\n    value_weight_ratio = combined_value / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(value_weight_ratio)[::-1]\n\n    for idx in sorted_indices[:min(7, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Objective-space perturbation\n    if np.random.rand() < 0.5:\n        obj1_ratio = value1_lst / (weight_lst + 1e-6)\n        obj2_ratio = value2_lst / (weight_lst + 1e-6)\n        obj1_indices = np.argsort(obj1_ratio)[::-1]\n        obj2_indices = np.argsort(obj2_ratio)[::-1]\n\n        for idx in obj1_indices[:min(3, n_items)]:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        for idx in obj2_indices[:min(3, n_items)]:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive capacity-aware swaps\n    if np.random.rand() < 0.4:\n        item_criticality = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        sorted_critical = np.argsort(item_criticality)[::-1]\n\n        for i in range(min(5, n_items)):\n            for j in range(i+1, min(i+5, n_items)):\n                if base_solution[sorted_critical[i]] == 1 and base_solution[sorted_critical[j]] == 0:\n                    weight_diff = weight_lst[sorted_critical[j]] - weight_lst[sorted_critical[i]]\n                    if current_weight + weight_diff <= capacity:\n                        new_solution[sorted_critical[i]] = 0\n                        new_solution[sorted_critical[j]] = 1\n                        current_weight += weight_diff\n                        break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~80)*\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 45,
        "algorithm": "The algorithm selects a promising solution from the top 20% of the archive (based on a combined normalized objective score), then performs a dynamic local search that prioritizes high-marginal-gain items while occasionally flipping low-contribution items with adaptive probability, ensuring feasibility through iterative refinement. It balances exploitation (targeting high-gain items) and exploration (controlled random flips) while maintaining capacity constraints. The search focuses on maximizing either objective's marginal gains and occasionally explores flips based on current inclusion status.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by combined normalized objective score\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        combined_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(combined_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    n_items = len(weight_lst)\n\n    # Dynamic local search with marginal gains and controlled randomness\n    marginal_gain1 = value1_lst / (weight_lst + 1e-6)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n\n    # Prioritize items with high marginal gains in either objective\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, n_items)]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random flips based on inclusion status\n    flip_prob = 0.3 if current_weight < capacity * 0.7 else 0.5\n    for idx in range(n_items):\n        if np.random.rand() < flip_prob:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Iterative refinement to ensure feasibility\n    max_iter = 5\n    for _ in range(max_iter):\n        if current_weight <= capacity:\n            break\n        excess_weight = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        if len(excess_items) > 0:\n            remove_idx = np.random.choice(excess_items)\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.32877519469061267,
            0.443596750497818
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by combined normalized objective score\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        combined_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(combined_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    n_items = len(weight_lst)\n\n    # Dynamic local search with marginal gains and controlled randomness\n    marginal_gain1 = value1_lst / (weight_lst + 1e-6)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n\n    # Prioritize items with high marginal gains in either objective\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, n_items)]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random flips based on inclusion status\n    flip_prob = 0.3 if current_weight < capacity * 0.7 else 0.5\n    for idx in range(n_items):\n        if np.random.rand() < flip_prob:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Iterative refinement to ensure feasibility\n    max_iter = 5\n    for _ in range(max_iter):\n        if current_weight <= capacity:\n            break\n        excess_weight = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        if len(excess_items) > 0:\n            remove_idx = np.random.choice(excess_items)\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid of crowding distance and objective trade-off analysis, then applies a novel local search that alternates between targeted item swaps (prioritizing high-value items with trade-off considerations) and probabilistic flips (removing low-value items with dynamic probability), while ensuring feasibility through constrained capacity checks. The selection prioritizes solutions with high crowding distance (indicating potential for improvement) and adjusts perturbation probabilities based on the solution's position in the Pareto front and its objective trade-offs.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine objective dominance and adaptive crowding\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate normalized crowding distances\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate objective trade-offs\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    avg_trade_off = np.mean(trade_off)\n\n    # Alternating objective improvement with trade-off consideration\n    if np.random.rand() < 0.5 or trade_off[selected_idx] < avg_trade_off:\n        # Improve first objective with trade-off consideration\n        gain = (value1_lst + 0.3 * value2_lst) / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective with trade-off consideration\n        gain = (value2_lst + 0.3 * value1_lst) / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Targeted item swaps with feasibility check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position and trade-off\n    perturbation_prob = 0.3 if trade_off[selected_idx] < avg_trade_off else 0.6\n    if np.random.rand() < perturbation_prob:\n        # Select items with poor value-to-weight ratio for potential removal\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        poor_ratio_indices = np.argsort(value_ratio)[:min(5, len(weight_lst))]\n        for idx in poor_ratio_indices:\n            if np.random.rand() < 0.5 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~80)*\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 46,
        "algorithm": "The algorithm selects top 20% solutions by normalized objective sums, then applies a hybrid local search combining targeted flips of high-marginal-gain items (prioritizing objective 1 with 60% weight) and adaptive random flips of low-contribution items, with perturbation probability dynamically adjusted based on trade-offs and crowding distance. It iteratively refines solutions while ensuring feasibility through constrained capacity checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate objective trade-offs and crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    avg_trade_off = np.mean(trade_off)\n\n    # Dynamic perturbation probability based on trade-off and crowding\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    perturbation_prob = 0.4 if trade_off[selected_idx] < avg_trade_off else 0.7\n    crowding_factor = crowding[selected_idx] / (np.max(crowding) + 1e-10)\n    perturbation_prob = min(0.9, perturbation_prob + 0.2 * crowding_factor)\n\n    # Targeted flips for high-marginal-gain items\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.6 * marginal_gain1 + 0.4 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(10, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Adaptive random flips for low-contribution items\n    if np.random.rand() < perturbation_prob:\n        low_gain_indices = np.argsort(combined_gain)[:min(8, len(weight_lst))]\n        for idx in low_gain_indices:\n            if np.random.rand() < 0.5 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif np.random.rand() < 0.5 and base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement (5-10 iterations)\n    for _ in range(np.random.randint(5, 11)):\n        if np.random.rand() < 0.3:\n            # Small random flip\n            idx = np.random.randint(len(weight_lst))\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.5791986805700147,
            0.4502891004085541
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate objective trade-offs and crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    avg_trade_off = np.mean(trade_off)\n\n    # Dynamic perturbation probability based on trade-off and crowding\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    perturbation_prob = 0.4 if trade_off[selected_idx] < avg_trade_off else 0.7\n    crowding_factor = crowding[selected_idx] / (np.max(crowding) + 1e-10)\n    perturbation_prob = min(0.9, perturbation_prob + 0.2 * crowding_factor)\n\n    # Targeted flips for high-marginal-gain items\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.6 * marginal_gain1 + 0.4 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(10, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Adaptive random flips for low-contribution items\n    if np.random.rand() < perturbation_prob:\n        low_gain_indices = np.argsort(combined_gain)[:min(8, len(weight_lst))]\n        for idx in low_gain_indices:\n            if np.random.rand() < 0.5 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif np.random.rand() < 0.5 and base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement (5-10 iterations)\n    for _ in range(np.random.randint(5, 11)):\n        if np.random.rand() < 0.3:\n            # Small random flip\n            idx = np.random.randint(len(weight_lst))\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 47,
        "algorithm": "The algorithm selects a promising solution from the archive using a hybrid criterion that balances normalized objective values and diversity, then performs a targeted local search by flipping high-marginal-gain items (with 60% weight on value1 and 40% on value2) and occasionally perturbing low-contribution items with dynamic probability, while ensuring feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine normalized objectives with diversity consideration\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = []\n        for i, (sol, obj) in enumerate(archive):\n            # Calculate diversity score (distance to other solutions)\n            diversity = 0\n            for j, (other_sol, _) in enumerate(archive):\n                if i != j:\n                    diversity += np.sum(sol != other_sol)\n            weighted_score = 0.5 * (0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) + 0.5 * (diversity / len(archive))\n            normalized_scores.append(weighted_score)\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search with multi-objective gain calculation\n    marginal_gain1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n    combined_gain = 0.6 * marginal_gain1 + 0.4 * marginal_gain2\n\n    # Dynamic selection of items to flip based on solution quality\n    solution_quality = (archive[selected_idx][1][0] + archive[selected_idx][1][1]) / (max_obj1 + max_obj2 + 1e-6)\n    num_high_gain = max(1, int(5 * (1 - solution_quality)))  # More flips for lower-quality solutions\n    high_gain_indices = np.argsort(-combined_gain)[:min(num_high_gain, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Dynamic perturbation probability\n    perturbation_prob = 0.3 + 0.4 * (1 - solution_quality)\n    if np.random.rand() < perturbation_prob:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8149492407042668,
            2.7628703713417053
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine normalized objectives with diversity consideration\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = []\n        for i, (sol, obj) in enumerate(archive):\n            # Calculate diversity score (distance to other solutions)\n            diversity = 0\n            for j, (other_sol, _) in enumerate(archive):\n                if i != j:\n                    diversity += np.sum(sol != other_sol)\n            weighted_score = 0.5 * (0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) + 0.5 * (diversity / len(archive))\n            normalized_scores.append(weighted_score)\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search with multi-objective gain calculation\n    marginal_gain1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n    combined_gain = 0.6 * marginal_gain1 + 0.4 * marginal_gain2\n\n    # Dynamic selection of items to flip based on solution quality\n    solution_quality = (archive[selected_idx][1][0] + archive[selected_idx][1][1]) / (max_obj1 + max_obj2 + 1e-6)\n    num_high_gain = max(1, int(5 * (1 - solution_quality)))  # More flips for lower-quality solutions\n    high_gain_indices = np.argsort(-combined_gain)[:min(num_high_gain, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Dynamic perturbation probability\n    perturbation_prob = 0.3 + 0.4 * (1 - solution_quality)\n    if np.random.rand() < perturbation_prob:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 48,
        "algorithm": "The algorithm selects from the top 20% of non-dominated solutions (weighted equally on normalized objectives) and performs a local search by flipping high-gain items (60% prioritizing value1, 40% prioritizing value2) while occasionally perturbing low-gain items (30% probability) to balance exploration and exploitation, always ensuring feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by equally weighted normalized objectives\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.5 * obj[0]/max_obj1 + 0.5 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Local search: flip items with highest combined gain (60% value1, 40% value2)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.6 * marginal_gain1 + 0.4 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-gain items with 30% probability\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7786288219507125,
            0.20604312419891357
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by equally weighted normalized objectives\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.5 * obj[0]/max_obj1 + 0.5 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Local search: flip items with highest combined gain (60% value1, 40% value2)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.6 * marginal_gain1 + 0.4 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-gain items with 30% probability\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 3 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~80)*\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 49,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums (from reflection and algorithm 2)\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives (from algorithm 1 and 2)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.6 * marginal_gain1 + 0.4 * marginal_gain2  # Weighted combination (from algorithm 1)\n\n    # Targeted local search: flip items with highest combined marginal gains (from all algorithms)\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips to encourage exploration (from reflection)\n    n_random_flips = np.random.randint(1, 3)\n    available_indices = [i for i in range(len(weight_lst)) if i not in high_gain_indices]\n    if available_indices:\n        random_indices = np.random.choice(available_indices, size=min(n_random_flips, len(available_indices)), replace=False)\n        for idx in random_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive perturbation: flip low-marginal-contribution items with 30% probability (from algorithm 3)\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Ensure at least one change was made (from reflection)\n    if np.array_equal(new_solution, base_solution):\n        # If no changes were made, force a small change\n        available_indices = [i for i in range(len(weight_lst)) if weight_lst[i] <= capacity - current_weight]\n        if available_indices:\n            idx = np.random.choice(available_indices)\n            new_solution[idx] = 1 - new_solution[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.6007031496847042,
            1.4503102004528046
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums (from reflection and algorithm 2)\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives (from algorithm 1 and 2)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.6 * marginal_gain1 + 0.4 * marginal_gain2  # Weighted combination (from algorithm 1)\n\n    # Targeted local search: flip items with highest combined marginal gains (from all algorithms)\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips to encourage exploration (from reflection)\n    n_random_flips = np.random.randint(1, 3)\n    available_indices = [i for i in range(len(weight_lst)) if i not in high_gain_indices]\n    if available_indices:\n        random_indices = np.random.choice(available_indices, size=min(n_random_flips, len(available_indices)), replace=False)\n        for idx in random_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive perturbation: flip low-marginal-contribution items with 30% probability (from algorithm 3)\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Ensure at least one change was made (from reflection)\n    if np.array_equal(new_solution, base_solution):\n        # If no changes were made, force a small change\n        available_indices = [i for i in range(len(weight_lst)) if weight_lst[i] <= capacity - current_weight]\n        if available_indices:\n            idx = np.random.choice(available_indices)\n            new_solution[idx] = 1 - new_solution[idx]\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 4 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 50,
        "algorithm": "The algorithm selects top-performing solutions (top 20% by normalized objective sums) from the archive, then performs a targeted local search by flipping high-marginal-gain items (either value1 or value2) while ensuring feasibility, followed by 1-2 random flips of low-marginal-contribution items. It iteratively refines the solution to reject infeasible neighbors, prioritizing items with the highest marginal gains in either objective while maintaining diversity through controlled random perturbations. The key design ideas are prioritizing high-marginal-gain items, balancing exploitation and exploration through random flips, and ensuring feasibility through iterative refinement.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip 1-2 low-marginal-contribution items\n    num_random_flips = np.random.randint(1, 3)\n    low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n    for _ in range(num_random_flips):\n        idx = np.random.choice(low_gain_indices)\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.7844373430493545,
            0.25509023666381836
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip 1-2 low-marginal-contribution items\n    num_random_flips = np.random.randint(1, 3)\n    low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n    for _ in range(num_random_flips):\n        idx = np.random.choice(low_gain_indices)\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects the top 20% of solutions from the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items first, followed by controlled random flips of low-marginal-gain items to ensure feasibility. It iteratively refines the solution by rejecting infeasible neighbors, prioritizing items with higher marginal gains while maintaining diversity through random perturbations. The key design choices are the prioritization of high-marginal-gain items, controlled randomness for exploration, and iterative feasibility checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip 1-2 low-marginal-contribution items\n    num_flips = np.random.randint(1, 3)\n    low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n    for _ in range(num_flips):\n        idx = np.random.choice(low_gain_indices)\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 51,
        "algorithm": "The algorithm selects promising solutions from the archive using a hybrid of Pareto dominance and hypervolume contribution, then applies a novel \"weighted marginal exchange\" to trade high-marginal-gain items in one objective for low-marginal-gain items in the other, followed by controlled random perturbations of near-zero marginal items while ensuring feasibility through iterative refinement. Key design priorities include prioritizing hypervolume-contributing solutions, favoring high-marginal-gain items in one objective while sacrificing low-marginal-gain items in the other, and adaptively adjusting the solution space through controlled random flips of near-zero marginal items.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: top 20% by hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    if len(objectives) == 1:\n        selected_idx = 0\n    else:\n        # Simple hypervolume approximation (area under the Pareto front)\n        sorted_indices = np.argsort(objectives[:, 0])\n        sorted_objectives = objectives[sorted_indices]\n        hypervolumes = []\n        for i in range(len(sorted_objectives)):\n            if i == 0:\n                hypervolumes.append(sorted_objectives[i, 0] * sorted_objectives[i, 1])\n            else:\n                hypervolumes.append(\n                    (sorted_objectives[i, 0] - sorted_objectives[i-1, 0]) * sorted_objectives[i, 1]\n                )\n        hypervolumes = np.array(hypervolumes)\n        top_indices = sorted_indices[np.argsort(hypervolumes)[-max(1, len(archive)//5):]]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Weighted marginal exchange: trade high-marginal items in one objective for low-marginal items in the other\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain1_indices = np.argsort(-marginal_gain1)[:min(3, len(weight_lst))]\n    low_gain2_indices = np.argsort(marginal_gain2)[:min(3, len(weight_lst))]\n\n    for idx1, idx2 in zip(high_gain1_indices, low_gain2_indices):\n        if base_solution[idx1] == 1 and base_solution[idx2] == 0:\n            if current_weight - weight_lst[idx1] + weight_lst[idx2] <= capacity:\n                new_solution[idx1] = 0\n                new_solution[idx2] = 1\n                current_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n\n    # Controlled random perturbation: flip near-zero marginal items with adaptive probability\n    near_zero_indices = np.where((np.abs(marginal_gain1) < 0.1) & (np.abs(marginal_gain2) < 0.1))[0]\n    if len(near_zero_indices) > 0:\n        num_flips = np.random.randint(1, min(3, len(near_zero_indices)) + 1)\n        for _ in range(num_flips):\n            idx = np.random.choice(near_zero_indices)\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement with adaptive step size\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.4525056949873181,
            10.68599358201027
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: top 20% by hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    if len(objectives) == 1:\n        selected_idx = 0\n    else:\n        # Simple hypervolume approximation (area under the Pareto front)\n        sorted_indices = np.argsort(objectives[:, 0])\n        sorted_objectives = objectives[sorted_indices]\n        hypervolumes = []\n        for i in range(len(sorted_objectives)):\n            if i == 0:\n                hypervolumes.append(sorted_objectives[i, 0] * sorted_objectives[i, 1])\n            else:\n                hypervolumes.append(\n                    (sorted_objectives[i, 0] - sorted_objectives[i-1, 0]) * sorted_objectives[i, 1]\n                )\n        hypervolumes = np.array(hypervolumes)\n        top_indices = sorted_indices[np.argsort(hypervolumes)[-max(1, len(archive)//5):]]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Weighted marginal exchange: trade high-marginal items in one objective for low-marginal items in the other\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain1_indices = np.argsort(-marginal_gain1)[:min(3, len(weight_lst))]\n    low_gain2_indices = np.argsort(marginal_gain2)[:min(3, len(weight_lst))]\n\n    for idx1, idx2 in zip(high_gain1_indices, low_gain2_indices):\n        if base_solution[idx1] == 1 and base_solution[idx2] == 0:\n            if current_weight - weight_lst[idx1] + weight_lst[idx2] <= capacity:\n                new_solution[idx1] = 0\n                new_solution[idx2] = 1\n                current_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n\n    # Controlled random perturbation: flip near-zero marginal items with adaptive probability\n    near_zero_indices = np.where((np.abs(marginal_gain1) < 0.1) & (np.abs(marginal_gain2) < 0.1))[0]\n    if len(near_zero_indices) > 0:\n        num_flips = np.random.randint(1, min(3, len(near_zero_indices)) + 1)\n        for _ in range(num_flips):\n            idx = np.random.choice(near_zero_indices)\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement with adaptive step size\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solutions with high crowding distance and high normalized objective sums\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Calculate normalized objective sums\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        normalized_scores = np.ones(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0]/max_obj1 + objectives[:, 1]/max_obj2)\n\n    # Combine crowding and normalized scores\n    combined_scores = crowding * normalized_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate multi-objective marginal gains\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n\n    # Select top items with highest combined marginal gains\n    top_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    # Greedy flips for top gain items\n    for idx in top_gain_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Adaptive perturbation based on solution's position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.4\n        num_perturbations = 2\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n        num_perturbations = 1\n\n    if np.random.rand() < perturbation_prob:\n        # Select items with low combined marginal gains for perturbation\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        selected_perturbations = np.random.choice(low_gain_indices, min(num_perturbations, len(low_gain_indices)), replace=False)\n\n        for idx in selected_perturbations:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Final feasibility check and refinement\n    for _ in range(3):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n        else:\n            # Remove heaviest items to make feasible\n            excess = temp_weight - capacity\n            while excess > 0 and np.any(temp_solution):\n                heaviest_idx = np.argmax(weight_lst * temp_solution)\n                if temp_solution[heaviest_idx] == 1:\n                    temp_solution[heaviest_idx] = 0\n                    excess -= weight_lst[heaviest_idx]\n            new_solution = temp_solution\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 52,
        "algorithm": "The algorithm selects a promising solution from the archive based on diversity and objective balance, then generates a neighbor by flipping high-marginal-gain items while dynamically adjusting perturbation intensity based on solution quality, ensuring feasibility through iterative refinement. It prioritizes items with higher combined marginal gains for exploitation and selectively perturbs lower-gain items for exploration, with more aggressive changes for high-quality solutions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solutions with high diversity and balanced objectives\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate diversity scores using Euclidean distance\n    diversity_scores = np.zeros(len(archive))\n    for i in range(len(archive)):\n        distances = np.linalg.norm(objectives - objectives[i], axis=1)\n        diversity_scores[i] = np.mean(distances)\n\n    # Calculate normalized objective scores\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        normalized_scores = np.ones(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0]/max_obj1 + objectives[:, 1]/max_obj2)\n\n    # Combine diversity and normalized scores\n    combined_scores = diversity_scores * normalized_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate multi-objective marginal gains\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n\n    # Select items with highest combined marginal gains\n    top_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    # Hybrid local search: flip items with high marginal gains\n    for idx in top_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution quality\n    solution_quality = normalized_scores[selected_idx]\n    if solution_quality > 0.7:\n        # More aggressive perturbation for high-quality solutions\n        perturbation_prob = 0.5\n        num_perturbations = 3\n    else:\n        # More conservative perturbation for lower-quality solutions\n        perturbation_prob = 0.3\n        num_perturbations = 2\n\n    if np.random.rand() < perturbation_prob:\n        # Select items with low marginal gains for perturbation\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        selected_perturbations = np.random.choice(low_gain_indices, min(num_perturbations, len(low_gain_indices)), replace=False)\n\n        for idx in selected_perturbations:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement to ensure feasibility\n    for _ in range(3):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n        else:\n            # Remove heaviest items to make feasible\n            excess = temp_weight - capacity\n            while excess > 0 and np.any(temp_solution):\n                heaviest_idx = np.argmax(weight_lst * temp_solution)\n                if temp_solution[heaviest_idx] == 1:\n                    temp_solution[heaviest_idx] = 0\n                    excess -= weight_lst[heaviest_idx]\n            new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -0.7885465715281638,
            0.6170002818107605
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solutions with high diversity and balanced objectives\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate diversity scores using Euclidean distance\n    diversity_scores = np.zeros(len(archive))\n    for i in range(len(archive)):\n        distances = np.linalg.norm(objectives - objectives[i], axis=1)\n        diversity_scores[i] = np.mean(distances)\n\n    # Calculate normalized objective scores\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        normalized_scores = np.ones(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0]/max_obj1 + objectives[:, 1]/max_obj2)\n\n    # Combine diversity and normalized scores\n    combined_scores = diversity_scores * normalized_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate multi-objective marginal gains\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n\n    # Select items with highest combined marginal gains\n    top_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    # Hybrid local search: flip items with high marginal gains\n    for idx in top_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution quality\n    solution_quality = normalized_scores[selected_idx]\n    if solution_quality > 0.7:\n        # More aggressive perturbation for high-quality solutions\n        perturbation_prob = 0.5\n        num_perturbations = 3\n    else:\n        # More conservative perturbation for lower-quality solutions\n        perturbation_prob = 0.3\n        num_perturbations = 2\n\n    if np.random.rand() < perturbation_prob:\n        # Select items with low marginal gains for perturbation\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        selected_perturbations = np.random.choice(low_gain_indices, min(num_perturbations, len(low_gain_indices)), replace=False)\n\n        for idx in selected_perturbations:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement to ensure feasibility\n    for _ in range(3):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n        else:\n            # Remove heaviest items to make feasible\n            excess = temp_weight - capacity\n            while excess > 0 and np.any(temp_solution):\n                heaviest_idx = np.argmax(weight_lst * temp_solution)\n                if temp_solution[heaviest_idx] == 1:\n                    temp_solution[heaviest_idx] = 0\n                    excess -= weight_lst[heaviest_idx]\n            new_solution = temp_solution\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 53,
        "algorithm": "The algorithm selects promising solutions from the archive using a hybrid metric that combines objective dominance and feasibility, then applies a three-phase local search: Phase 1 flips high-marginal-gain items, Phase 2 performs objective-biased flipping, and Phase 3 introduces dynamic perturbations to escape local optima while maintaining feasibility. The method prioritizes items with higher combined marginal gains for both objectives, balances exploration with exploitation through probabilistic flipping, and dynamically adjusts perturbation strength based on current weight utilization.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine objective dominance and feasibility\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = np.max(objectives, axis=0)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Calculate dominance score and feasibility score\n        dominance_scores = objectives[:, 0]/max_obj1 + objectives[:, 1]/max_obj2\n        feasibility_scores = np.array([np.sum(weight_lst * sol) <= capacity for sol, _ in archive])\n        hybrid_scores = dominance_scores * feasibility_scores\n        top_indices = np.argsort(hybrid_scores)[-max(1, len(archive)//4):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: High-marginal-gain flipping with objective bias\n    marginal_gain1 = value1_lst / (weight_lst + 1e-6)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n    combined_gain = marginal_gain1 + marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(10, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Objective-biased flipping\n    if np.random.rand() < 0.4:\n        obj1_weight = np.random.rand()\n        obj1_indices = np.argsort(-marginal_gain1)[:min(5, len(weight_lst))]\n        obj2_indices = np.argsort(-marginal_gain2)[:min(5, len(weight_lst))]\n\n        for idx in obj1_indices:\n            if np.random.rand() < obj1_weight and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif np.random.rand() >= obj1_weight and base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        for idx in obj2_indices:\n            if np.random.rand() >= obj1_weight and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif np.random.rand() < obj1_weight and base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 3: Dynamic perturbation\n    perturbation_prob = 0.2 + 0.1 * (1 - (current_weight / capacity))\n    if np.random.rand() < perturbation_prob:\n        low_gain_indices = np.argsort(combined_gain)[:min(4, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Feasibility check and repair\n    temp_weight = np.sum(weight_lst * new_solution)\n    if temp_weight > capacity:\n        # Remove items in random order until feasible\n        excess = temp_weight - capacity\n        removable_indices = np.where(new_solution == 1)[0]\n        np.random.shuffle(removable_indices)\n        for idx in removable_indices:\n            if excess <= 0:\n                break\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8315280447744329,
            0.4164285957813263
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine objective dominance and feasibility\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = np.max(objectives, axis=0)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Calculate dominance score and feasibility score\n        dominance_scores = objectives[:, 0]/max_obj1 + objectives[:, 1]/max_obj2\n        feasibility_scores = np.array([np.sum(weight_lst * sol) <= capacity for sol, _ in archive])\n        hybrid_scores = dominance_scores * feasibility_scores\n        top_indices = np.argsort(hybrid_scores)[-max(1, len(archive)//4):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: High-marginal-gain flipping with objective bias\n    marginal_gain1 = value1_lst / (weight_lst + 1e-6)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n    combined_gain = marginal_gain1 + marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(10, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Objective-biased flipping\n    if np.random.rand() < 0.4:\n        obj1_weight = np.random.rand()\n        obj1_indices = np.argsort(-marginal_gain1)[:min(5, len(weight_lst))]\n        obj2_indices = np.argsort(-marginal_gain2)[:min(5, len(weight_lst))]\n\n        for idx in obj1_indices:\n            if np.random.rand() < obj1_weight and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif np.random.rand() >= obj1_weight and base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        for idx in obj2_indices:\n            if np.random.rand() >= obj1_weight and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif np.random.rand() < obj1_weight and base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 3: Dynamic perturbation\n    perturbation_prob = 0.2 + 0.1 * (1 - (current_weight / capacity))\n    if np.random.rand() < perturbation_prob:\n        low_gain_indices = np.argsort(combined_gain)[:min(4, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Feasibility check and repair\n    temp_weight = np.sum(weight_lst * new_solution)\n    if temp_weight > capacity:\n        # Remove items in random order until feasible\n        excess = temp_weight - capacity\n        removable_indices = np.where(new_solution == 1)[0]\n        np.random.shuffle(removable_indices)\n        for idx in removable_indices:\n            if excess <= 0:\n                break\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 54,
        "algorithm": "The algorithm selects top 30% solutions from the archive based on normalized objective products, then performs a hybrid local search by prioritizing high-marginal items (20% chance) or low-marginal items (40% chance) to generate neighbors while ensuring feasibility through iterative refinement. It emphasizes balanced exploration of both objectives by flipping items with either high or low marginal gains, rejecting infeasible solutions, and maintaining diversity in the search process.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: flip high-marginal items (20% probability) or low-marginal items (40% probability)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n    low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n\n    if np.random.rand() < 0.2:  # 20% chance for high-marginal flips\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n    elif np.random.rand() < 0.4:  # 40% chance for low-marginal flips\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.37333096189524223,
            6.679305166006088
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: flip high-marginal items (20% probability) or low-marginal items (40% probability)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n    low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n\n    if np.random.rand() < 0.2:  # 20% chance for high-marginal flips\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n    elif np.random.rand() < 0.4:  # 40% chance for low-marginal flips\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 3 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 55,
        "algorithm": "The algorithm selects top-performing solutions from the archive (based on normalized objective sums) and applies a hybrid local search strategy that prioritizes high-marginal-gain items while adaptively perturbing low-contribution items to balance exploitation and exploration, ensuring feasibility through iterative refinement and dynamic capacity checks. It emphasizes quality items first (via marginal gains) while occasionally flipping low-contribution items to escape local optima, with controlled randomness to avoid excessive computation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.4:  # Higher probability than existing algorithms\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_gain_indices = np.argsort(marginal_contribution)[:min(4, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Dynamic random flips based on current marginal gains\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidate_indices = np.where((weight_lst <= remaining_capacity) | (base_solution == 1))[0]\n        if len(candidate_indices) > 0:\n            for _ in range(min(2, len(candidate_indices))):  # Limit flips to avoid excessive computation\n                idx = np.random.choice(candidate_indices)\n                if base_solution[idx] == 1:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                else:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.6626976107183106,
            0.3013682961463928
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.4:  # Higher probability than existing algorithms\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_gain_indices = np.argsort(marginal_contribution)[:min(4, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Dynamic random flips based on current marginal gains\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidate_indices = np.where((weight_lst <= remaining_capacity) | (base_solution == 1))[0]\n        if len(candidate_indices) > 0:\n            for _ in range(min(2, len(candidate_indices))):  # Limit flips to avoid excessive computation\n                idx = np.random.choice(candidate_indices)\n                if base_solution[idx] == 1:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                else:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 4 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 56,
        "algorithm": "The algorithm selects top 20% solutions by normalized objective sums, performs targeted flips of high-marginal-gain items (prioritizing both objectives) followed by 1-2 random flips, and ensures feasibility through iterative refinement and rejection of infeasible neighbors. High-marginal-gain items (combining both objectives) are prioritized for flips, while random flips help escape local optima, and infeasible solutions are rejected through iterative checks. The algorithm balances exploration (random flips) and exploitation (targeted high-gain flips) to generate high-quality neighbor solutions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted flips: high-marginal-gain items (prioritizing both objectives)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Random flips: 1-2 items to escape local optima\n    random_flips = np.random.randint(1, 3)\n    for _ in range(random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement: reject infeasible neighbors\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.7178577523985398,
            0.2200905978679657
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted flips: high-marginal-gain items (prioritizing both objectives)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Random flips: 1-2 items to escape local optima\n    random_flips = np.random.randint(1, 3)\n    for _ in range(random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement: reject infeasible neighbors\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid of crowding distance and objective trade-off analysis, then applies a novel local search that alternates between targeted item swaps (prioritizing high-value items with trade-off considerations) and probabilistic flips (removing low-value items with dynamic probability), while ensuring feasibility through constrained capacity checks. The selection prioritizes solutions with high crowding distance (indicating potential for improvement) and adjusts perturbation probabilities based on the solution's position in the Pareto front and its objective trade-offs.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine objective dominance and adaptive crowding\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate normalized crowding distances\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate objective trade-offs\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    avg_trade_off = np.mean(trade_off)\n\n    # Alternating objective improvement with trade-off consideration\n    if np.random.rand() < 0.5 or trade_off[selected_idx] < avg_trade_off:\n        # Improve first objective with trade-off consideration\n        gain = (value1_lst + 0.3 * value2_lst) / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective with trade-off consideration\n        gain = (value2_lst + 0.3 * value1_lst) / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Targeted item swaps with feasibility check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position and trade-off\n    perturbation_prob = 0.3 if trade_off[selected_idx] < avg_trade_off else 0.6\n    if np.random.rand() < perturbation_prob:\n        # Select items with poor value-to-weight ratio for potential removal\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        poor_ratio_indices = np.argsort(value_ratio)[:min(5, len(weight_lst))]\n        for idx in poor_ratio_indices:\n            if np.random.rand() < 0.5 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive (based on normalized objective sums) and generates neighbors by flipping items with high marginal gains for both objectives, followed by 1-2 random feasible flips, while ensuring feasibility through iterative refinement by removing the lightest items when needed. It prioritizes items with combined high marginal gains for both objectives while maintaining diversity through random flips.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain-based flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add 1-2 random feasible flips\n    for _ in range(np.random.randint(1, 3)):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 57,
        "algorithm": "The algorithm first selects promising solutions from the top 30% of the archive based on normalized trade-offs, then prioritizes those with high crowding distances for further improvement. It generates neighbors by flipping items with the highest combined marginal gains for both objectives, followed by a dynamic number of random flips (scaled inversely to crowding distance), and finally ensures feasibility through iterative removal of the least valuable items when capacity is exceeded. The solution prioritizes exploration in crowded regions while maintaining high-quality improvements through marginal gain-based flips.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by normalized trade-offs\n    objectives = np.array([obj for _, obj in archive])\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    top_indices = np.argsort(trade_off)[-max(1, len(archive) // 3):]\n\n    # Calculate crowding distances for selected solutions\n    selected_objectives = objectives[top_indices]\n    normalized_objectives = (selected_objectives - np.min(selected_objectives, axis=0)) / (np.max(selected_objectives, axis=0) - np.min(selected_objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(top_indices))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(top_indices)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = top_indices[np.argmax(crowding)]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain-based flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (inverse to crowding distance)\n    n_random_flips = max(1, int(10 * (1 / (crowding[np.argmax(crowding)] + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove least valuable item (min of value1 and value2)\n        remove_idx = removable_items[np.argmin(np.minimum(value1_lst[removable_items], value2_lst[removable_items]))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8536157901902661,
            0.28181490302085876
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by normalized trade-offs\n    objectives = np.array([obj for _, obj in archive])\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    top_indices = np.argsort(trade_off)[-max(1, len(archive) // 3):]\n\n    # Calculate crowding distances for selected solutions\n    selected_objectives = objectives[top_indices]\n    normalized_objectives = (selected_objectives - np.min(selected_objectives, axis=0)) / (np.max(selected_objectives, axis=0) - np.min(selected_objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(top_indices))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(top_indices)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = top_indices[np.argmax(crowding)]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain-based flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (inverse to crowding distance)\n    n_random_flips = max(1, int(10 * (1 / (crowding[np.argmax(crowding)] + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove least valuable item (min of value1 and value2)\n        remove_idx = removable_items[np.argmin(np.minimum(value1_lst[removable_items], value2_lst[removable_items]))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive (based on normalized objective sums) and generates neighbors by flipping items with high marginal gains for both objectives, followed by 1-2 random feasible flips, while ensuring feasibility through iterative refinement by removing the lightest items when needed. It prioritizes items with combined high marginal gains for both objectives while maintaining diversity through random flips.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain-based flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add 1-2 random feasible flips\n    for _ in range(np.random.randint(1, 3)):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 58,
        "algorithm": "The algorithm selects promising solutions from the archive by prioritizing those with high normalized objective values, then generates neighbors by first flipping items with the highest combined marginal gains for both objectives, followed by a probabilistic phase that flips items based on marginal gains relative to their weights, with a bias toward excluded items. It ensures feasibility by dynamically adjusting perturbation probabilities and iteratively removing the lightest items if capacity is exceeded. The method balances exploration and exploitation through a dynamic perturbation probability that increases with consecutive feasible flips.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain-based flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Probabilistic flips based on marginal gains relative to weights\n    perturbation_prob = 0.5\n    consecutive_feasible = 0\n    for idx in np.random.permutation(n_items):\n        if np.random.rand() < perturbation_prob:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                consecutive_feasible += 1\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                consecutive_feasible += 1\n            else:\n                consecutive_feasible = 0\n        perturbation_prob = min(0.9, 0.5 + 0.1 * consecutive_feasible)\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.3347420337906792,
            0.6619268655776978
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain-based flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Probabilistic flips based on marginal gains relative to weights\n    perturbation_prob = 0.5\n    consecutive_feasible = 0\n    for idx in np.random.permutation(n_items):\n        if np.random.rand() < perturbation_prob:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                consecutive_feasible += 1\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                consecutive_feasible += 1\n            else:\n                consecutive_feasible = 0\n        perturbation_prob = min(0.9, 0.5 + 0.1 * consecutive_feasible)\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects promising solutions from the top 20% of the archive (based on normalized objective sums) and generates neighbors by flipping items with high marginal gains for both objectives, followed by 1-2 random feasible flips, while ensuring feasibility through iterative refinement by removing the lightest items when needed. It prioritizes items with combined high marginal gains for both objectives while maintaining diversity through random flips.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain-based flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add 1-2 random feasible flips\n    for _ in range(np.random.randint(1, 3)):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 59,
        "algorithm": "The algorithm selects top 30% solutions from the archive based on a weighted sum of normalized objectives (60% weight for value1, 40% for value2), then generates neighbors by flipping items with highest marginal gains (adjusted by current weight utilization) followed by dynamic random flips, ensuring feasibility through adaptive item removal based on marginal gain ratios. It prioritizes high-value items early while maintaining diversity through weighted selection and utilization-aware flipping.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (0.6 * obj1_scores / max_obj1) + (0.4 * obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n    current_utilization = current_weight / capacity\n\n    # Calculate marginal gains with weight sensitivity\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = (1 - current_utilization) * marginal_gain1 + current_utilization * marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    # Flip items with highest combined gains\n    for idx in sorted_indices[:min(7, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips based on current utilization\n    num_flips = max(1, int(3 * (1 - current_utilization)))\n    for _ in range(num_flips):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Adaptive feasibility maintenance\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n\n        if len(removable_items) == 0:\n            break\n\n        # Remove item with lowest marginal gain ratio\n        removal_criteria = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(removal_criteria)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8552214925232527,
            0.2515418827533722
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (0.6 * obj1_scores / max_obj1) + (0.4 * obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n    current_utilization = current_weight / capacity\n\n    # Calculate marginal gains with weight sensitivity\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = (1 - current_utilization) * marginal_gain1 + current_utilization * marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    # Flip items with highest combined gains\n    for idx in sorted_indices[:min(7, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips based on current utilization\n    num_flips = max(1, int(3 * (1 - current_utilization)))\n    for _ in range(num_flips):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Adaptive feasibility maintenance\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n\n        if len(removable_items) == 0:\n            break\n\n        # Remove item with lowest marginal gain ratio\n        removal_criteria = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(removal_criteria)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects promising solutions from the top 20% of the archive (based on normalized objective sums) and generates neighbors by flipping items with high marginal gains for both objectives, followed by 1-2 random feasible flips, while ensuring feasibility through iterative refinement by removing the lightest items when needed. It prioritizes items with combined high marginal gains for both objectives while maintaining diversity through random flips.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain-based flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add 1-2 random feasible flips\n    for _ in range(np.random.randint(1, 3)):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 60,
        "algorithm": "The algorithm selects top-performing solutions from the archive (30% with highest weighted objective scores) and generates neighbors by prioritizing items with high combined normalized gains (70% value1, 30% value2, minus weight penalty), followed by 2-3 strategic flips that balance inclusion/exclusion based on value-weight ratios, with iterative feasibility checks to ensure weight constraints are met. It emphasizes value-driven selection while strategically adjusting the knapsack contents to maintain balance between objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        weighted_scores = 0.6 * (obj1_scores / max_obj1) + 0.4 * (obj2_scores / max_obj2)\n        top_indices = np.argsort(weighted_scores)[-max(1, len(archive) // 3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate normalized marginal gains\n    norm_value1 = value1_lst / np.max(value1_lst)\n    norm_value2 = value2_lst / np.max(value2_lst)\n    norm_weight = weight_lst / np.max(weight_lst)\n    combined_gain = 0.7 * norm_value1 + 0.3 * norm_value2 - 0.5 * norm_weight\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    # Prioritize high-gain flips\n    for idx in sorted_indices[:min(8, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add 2-3 strategic flips\n    for _ in range(np.random.randint(2, 4)):\n        # Balance between including light valuable items and excluding heavy ones\n        if np.random.random() < 0.7:\n            # Prefer including items with high value/weight ratio\n            candidates = np.where(base_solution == 0)[0]\n            if len(candidates) > 0:\n                candidate_idx = candidates[np.argmax(value1_lst[candidates] / (weight_lst[candidates] + 1e-10))]\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n        else:\n            # Prefer excluding heavy items\n            candidates = np.where(base_solution == 1)[0]\n            if len(candidates) > 0:\n                candidate_idx = candidates[np.argmax(weight_lst[candidates])]\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove items with lowest value/weight ratio\n        ratios = value1_lst[removable_items] / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(ratios)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.7763191370016793,
            0.3186597526073456
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        weighted_scores = 0.6 * (obj1_scores / max_obj1) + 0.4 * (obj2_scores / max_obj2)\n        top_indices = np.argsort(weighted_scores)[-max(1, len(archive) // 3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate normalized marginal gains\n    norm_value1 = value1_lst / np.max(value1_lst)\n    norm_value2 = value2_lst / np.max(value2_lst)\n    norm_weight = weight_lst / np.max(weight_lst)\n    combined_gain = 0.7 * norm_value1 + 0.3 * norm_value2 - 0.5 * norm_weight\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    # Prioritize high-gain flips\n    for idx in sorted_indices[:min(8, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add 2-3 strategic flips\n    for _ in range(np.random.randint(2, 4)):\n        # Balance between including light valuable items and excluding heavy ones\n        if np.random.random() < 0.7:\n            # Prefer including items with high value/weight ratio\n            candidates = np.where(base_solution == 0)[0]\n            if len(candidates) > 0:\n                candidate_idx = candidates[np.argmax(value1_lst[candidates] / (weight_lst[candidates] + 1e-10))]\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n        else:\n            # Prefer excluding heavy items\n            candidates = np.where(base_solution == 1)[0]\n            if len(candidates) > 0:\n                candidate_idx = candidates[np.argmax(weight_lst[candidates])]\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove items with lowest value/weight ratio\n        ratios = value1_lst[removable_items] / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(ratios)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 3 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive (based on normalized objective sums) and generates neighbors by flipping items with high marginal gains for both objectives, followed by 1-2 random feasible flips, while ensuring feasibility through iterative refinement by removing the lightest items when needed. It prioritizes items with combined high marginal gains for both objectives while maintaining diversity through random flips.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain-based flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add 1-2 random feasible flips\n    for _ in range(np.random.randint(1, 3)):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 61,
        "algorithm": "The algorithm selects a promising solution from the top 20% of the archive (based on normalized objective sums) and applies a hybrid local search: first flipping high-marginal-gain items (prioritized by combined value-to-weight ratios) and then randomly flipping low-marginal-contribution items (with 30% probability), while ensuring feasibility through iterative removal of the lightest items if capacity is exceeded. The method balances exploitation (targeted flips) and exploration (random flips) while limiting iterations to 5-10 per solution.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    n_items = len(weight_lst)\n\n    # Targeted flipping of high-marginal-gain items\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    high_gain_indices = np.argsort(combined_gain)[::-1][:min(5, n_items)]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random flips of low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, n_items)]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.826961791986931,
            0.2329617738723755
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    n_items = len(weight_lst)\n\n    # Targeted flipping of high-marginal-gain items\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    high_gain_indices = np.argsort(combined_gain)[::-1][:min(5, n_items)]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random flips of low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, n_items)]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 4 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 62,
        "algorithm": "The algorithm selects promising solutions from the top 20% of the archive (based on normalized objective sums) and applies a targeted local search by prioritizing flips of high-marginal-gain items, followed by 1-2 random flips to escape local optima, while ensuring feasibility through iterative refinement. High-marginal-gain items (based on value-to-weight ratios) are given higher priority, and the algorithm balances exploitation (focused flips) with exploration (random flips) to improve solution quality.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips to escape local optima\n    num_random_flips = np.random.randint(1, 3)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.7943566467977887,
            0.2194809913635254
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips to escape local optima\n    num_random_flips = np.random.randint(1, 3)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solutions with high crowding distance and high normalized objective sums\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Calculate normalized objective sums\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        normalized_scores = np.ones(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0]/max_obj1 + objectives[:, 1]/max_obj2)\n\n    # Combine crowding and normalized scores\n    combined_scores = crowding * normalized_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate multi-objective marginal gains\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n\n    # Select top items with highest combined marginal gains\n    top_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    # Greedy flips for top gain items\n    for idx in top_gain_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Adaptive perturbation based on solution's position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.4\n        num_perturbations = 2\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n        num_perturbations = 1\n\n    if np.random.rand() < perturbation_prob:\n        # Select items with low combined marginal gains for perturbation\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        selected_perturbations = np.random.choice(low_gain_indices, min(num_perturbations, len(low_gain_indices)), replace=False)\n\n        for idx in selected_perturbations:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Final feasibility check and refinement\n    for _ in range(3):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n        else:\n            # Remove heaviest items to make feasible\n            excess = temp_weight - capacity\n            while excess > 0 and np.any(temp_solution):\n                heaviest_idx = np.argmax(weight_lst * temp_solution)\n                if temp_solution[heaviest_idx] == 1:\n                    temp_solution[heaviest_idx] = 0\n                    excess -= weight_lst[heaviest_idx]\n            new_solution = temp_solution\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 63,
        "algorithm": "The algorithm selects the top 20% of solutions from the archive based on a weighted normalized score (60% value1, 40% value2) and performs a hybrid local search: first flipping high-marginal-gain items, then occasionally adding random low-marginal-gain flips, while ensuring feasibility by iteratively removing heaviest items if capacity is exceeded. The method balances exploration (random flips) and exploitation (marginal gains) to generate high-quality neighbor solutions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (0.6 * objectives[:, 0] / max_obj1 + 0.4 * objectives[:, 1] / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.6 * marginal_gain1 + 0.4 * marginal_gain2\n\n    # Flip items with highest marginal gains in either objective\n    top_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n    for idx in top_gain_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips from low-marginal-gain items with 30% probability\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        num_flips = np.random.randint(1, 3)\n        selected_flips = np.random.choice(low_gain_indices, min(num_flips, len(low_gain_indices)), replace=False)\n        for idx in selected_flips:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Ensure feasibility and refine if needed\n    for _ in range(3):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n        else:\n            excess = temp_weight - capacity\n            while excess > 0 and np.any(temp_solution):\n                heaviest_idx = np.argmax(weight_lst * temp_solution)\n                if temp_solution[heaviest_idx] == 1:\n                    temp_solution[heaviest_idx] = 0\n                    excess -= weight_lst[heaviest_idx]\n            new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -0.8176691736995297,
            0.24340370297431946
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (0.6 * objectives[:, 0] / max_obj1 + 0.4 * objectives[:, 1] / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.6 * marginal_gain1 + 0.4 * marginal_gain2\n\n    # Flip items with highest marginal gains in either objective\n    top_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n    for idx in top_gain_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips from low-marginal-gain items with 30% probability\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        num_flips = np.random.randint(1, 3)\n        selected_flips = np.random.choice(low_gain_indices, min(num_flips, len(low_gain_indices)), replace=False)\n        for idx in selected_flips:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Ensure feasibility and refine if needed\n    for _ in range(3):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n        else:\n            excess = temp_weight - capacity\n            while excess > 0 and np.any(temp_solution):\n                heaviest_idx = np.argmax(weight_lst * temp_solution)\n                if temp_solution[heaviest_idx] == 1:\n                    temp_solution[heaviest_idx] = 0\n                    excess -= weight_lst[heaviest_idx]\n            new_solution = temp_solution\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid of crowding distance and objective trade-off analysis, then applies a novel local search that alternates between targeted item swaps (prioritizing high-value items with trade-off considerations) and probabilistic flips (removing low-value items with dynamic probability), while ensuring feasibility through constrained capacity checks. The selection prioritizes solutions with high crowding distance (indicating potential for improvement) and adjusts perturbation probabilities based on the solution's position in the Pareto front and its objective trade-offs.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine objective dominance and adaptive crowding\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate normalized crowding distances\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate objective trade-offs\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    avg_trade_off = np.mean(trade_off)\n\n    # Alternating objective improvement with trade-off consideration\n    if np.random.rand() < 0.5 or trade_off[selected_idx] < avg_trade_off:\n        # Improve first objective with trade-off consideration\n        gain = (value1_lst + 0.3 * value2_lst) / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective with trade-off consideration\n        gain = (value2_lst + 0.3 * value1_lst) / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Targeted item swaps with feasibility check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position and trade-off\n    perturbation_prob = 0.3 if trade_off[selected_idx] < avg_trade_off else 0.6\n    if np.random.rand() < perturbation_prob:\n        # Select items with poor value-to-weight ratio for potential removal\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        poor_ratio_indices = np.argsort(value_ratio)[:min(5, len(weight_lst))]\n        for idx in poor_ratio_indices:\n            if np.random.rand() < 0.5 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solutions with high crowding distance and high normalized objective sums\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Calculate normalized objective sums\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        normalized_scores = np.ones(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0]/max_obj1 + objectives[:, 1]/max_obj2)\n\n    # Combine crowding and normalized scores\n    combined_scores = crowding * normalized_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate multi-objective marginal gains\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n\n    # Select top items with highest combined marginal gains\n    top_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    # Greedy flips for top gain items\n    for idx in top_gain_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Adaptive perturbation based on solution's position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.4\n        num_perturbations = 2\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n        num_perturbations = 1\n\n    if np.random.rand() < perturbation_prob:\n        # Select items with low combined marginal gains for perturbation\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        selected_perturbations = np.random.choice(low_gain_indices, min(num_perturbations, len(low_gain_indices)), replace=False)\n\n        for idx in selected_perturbations:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Final feasibility check and refinement\n    for _ in range(3):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n        else:\n            # Remove heaviest items to make feasible\n            excess = temp_weight - capacity\n            while excess > 0 and np.any(temp_solution):\n                heaviest_idx = np.argmax(weight_lst * temp_solution)\n                if temp_solution[heaviest_idx] == 1:\n                    temp_solution[heaviest_idx] = 0\n                    excess -= weight_lst[heaviest_idx]\n            new_solution = temp_solution\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 64,
        "algorithm": "The algorithm selects top 20% solutions by normalized objective sums, then iteratively refines them by either flipping high-marginal-gain items (70% probability) or performing 1-2 random flips (30% probability), while ensuring feasibility through constrained checks and excess weight removal. It prioritizes objective-specific item selection (based on marginal gains) while maintaining solution quality through controlled perturbations and iterative refinement.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        normalized_scores = np.ones(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0]/max_obj1 + objectives[:, 1]/max_obj2)\n    top_indices = np.argsort(-normalized_scores)[:max(1, len(archive)//5)]\n    selected_idx = np.random.choice(top_indices)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Iterative refinement (5 iterations)\n    for _ in range(5):\n        # Calculate marginal gains\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n\n        # With 70% probability: flip highest marginal gain items\n        if np.random.rand() < 0.7:\n            # Prioritize objective with higher marginal gain\n            if np.sum(marginal_gain1) > np.sum(marginal_gain2):\n                sorted_indices = np.argsort(-marginal_gain1)\n            else:\n                sorted_indices = np.argsort(-marginal_gain2)\n\n            for idx in sorted_indices:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n        # With 30% probability: perform 1-2 random flips\n        else:\n            num_flips = np.random.choice([1, 2])\n            flip_indices = np.random.choice(len(weight_lst), size=num_flips, replace=False)\n            for idx in flip_indices:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Feasibility check\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight > capacity:\n            # Remove heaviest items to make feasible\n            excess = temp_weight - capacity\n            while excess > 0 and np.any(new_solution):\n                heaviest_idx = np.argmax(weight_lst * new_solution)\n                if new_solution[heaviest_idx] == 1:\n                    new_solution[heaviest_idx] = 0\n                    excess -= weight_lst[heaviest_idx]\n            current_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n",
        "score": [
            -0.29246815308582486,
            1.4151331186294556
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        normalized_scores = np.ones(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0]/max_obj1 + objectives[:, 1]/max_obj2)\n    top_indices = np.argsort(-normalized_scores)[:max(1, len(archive)//5)]\n    selected_idx = np.random.choice(top_indices)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Iterative refinement (5 iterations)\n    for _ in range(5):\n        # Calculate marginal gains\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n\n        # With 70% probability: flip highest marginal gain items\n        if np.random.rand() < 0.7:\n            # Prioritize objective with higher marginal gain\n            if np.sum(marginal_gain1) > np.sum(marginal_gain2):\n                sorted_indices = np.argsort(-marginal_gain1)\n            else:\n                sorted_indices = np.argsort(-marginal_gain2)\n\n            for idx in sorted_indices:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n        # With 30% probability: perform 1-2 random flips\n        else:\n            num_flips = np.random.choice([1, 2])\n            flip_indices = np.random.choice(len(weight_lst), size=num_flips, replace=False)\n            for idx in flip_indices:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Feasibility check\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight > capacity:\n            # Remove heaviest items to make feasible\n            excess = temp_weight - capacity\n            while excess > 0 and np.any(new_solution):\n                heaviest_idx = np.argmax(weight_lst * new_solution)\n                if new_solution[heaviest_idx] == 1:\n                    new_solution[heaviest_idx] = 0\n                    excess -= weight_lst[heaviest_idx]\n            current_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        None\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solutions with high crowding distance and high normalized objective sums\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Calculate normalized objective sums\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        normalized_scores = np.ones(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0]/max_obj1 + objectives[:, 1]/max_obj2)\n\n    # Combine crowding and normalized scores\n    combined_scores = crowding * normalized_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate multi-objective marginal gains\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n\n    # Select top items with highest combined marginal gains\n    top_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    # Greedy flips for top gain items\n    for idx in top_gain_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Adaptive perturbation based on solution's position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.4\n        num_perturbations = 2\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n        num_perturbations = 1\n\n    if np.random.rand() < perturbation_prob:\n        # Select items with low combined marginal gains for perturbation\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        selected_perturbations = np.random.choice(low_gain_indices, min(num_perturbations, len(low_gain_indices)), replace=False)\n\n        for idx in selected_perturbations:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Final feasibility check and refinement\n    for _ in range(3):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n        else:\n            # Remove heaviest items to make feasible\n            excess = temp_weight - capacity\n            while excess > 0 and np.any(temp_solution):\n                heaviest_idx = np.argmax(weight_lst * temp_solution)\n                if temp_solution[heaviest_idx] == 1:\n                    temp_solution[heaviest_idx] = 0\n                    excess -= weight_lst[heaviest_idx]\n            new_solution = temp_solution\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 65,
        "algorithm": "This algorithm selects a promising solution from the archive based on dominance and diversity scores, then applies a hybrid local search combining greedy flips (targeting high-marginal-gain items), adaptive perturbation (for less dominant solutions), and multi-stage feasibility checks. It prioritizes items with maximum combined marginal gains for flips while ensuring feasibility through targeted removals of low-value items when necessary.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solutions with high dominance and diversity\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate dominance ranks\n    dominance = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] > objectives[j, 1]) or \\\n                   (objectives[i, 0] > objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]):\n                    dominance[i] += 1\n\n    # Calculate diversity scores\n    diversity = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                diversity[i] += np.linalg.norm(objectives[i] - objectives[j])\n\n    # Combine dominance and diversity\n    combined_scores = dominance * diversity\n    selected_idx = np.argmax(combined_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate normalized marginal gains\n    marginal_gain1 = value1_lst / (weight_lst + 1e-6)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n\n    # Select top items with highest combined marginal gains\n    top_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    # Hybrid flip strategy\n    for idx in top_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive perturbation based on solution's dominance\n    if dominance[selected_idx] > np.median(dominance):\n        perturbation_prob = 0.3\n        num_perturbations = 3\n    else:\n        perturbation_prob = 0.1\n        num_perturbations = 2\n\n    if np.random.rand() < perturbation_prob:\n        # Select items with low combined marginal gains for perturbation\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        selected_perturbations = np.random.choice(low_gain_indices, min(num_perturbations, len(low_gain_indices)), replace=False)\n\n        for idx in selected_perturbations:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Final feasibility check and refinement\n    for _ in range(3):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n        else:\n            # Remove items with lowest marginal gain to make feasible\n            excess = temp_weight - capacity\n            while excess > 0 and np.any(temp_solution):\n                lowest_gain_idx = np.argmin(combined_gain * temp_solution)\n                if temp_solution[lowest_gain_idx] == 1:\n                    temp_solution[lowest_gain_idx] = 0\n                    excess -= weight_lst[lowest_gain_idx]\n            new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -0.864988433514853,
            3.437459409236908
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solutions with high dominance and diversity\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate dominance ranks\n    dominance = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] > objectives[j, 1]) or \\\n                   (objectives[i, 0] > objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]):\n                    dominance[i] += 1\n\n    # Calculate diversity scores\n    diversity = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                diversity[i] += np.linalg.norm(objectives[i] - objectives[j])\n\n    # Combine dominance and diversity\n    combined_scores = dominance * diversity\n    selected_idx = np.argmax(combined_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate normalized marginal gains\n    marginal_gain1 = value1_lst / (weight_lst + 1e-6)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n\n    # Select top items with highest combined marginal gains\n    top_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    # Hybrid flip strategy\n    for idx in top_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive perturbation based on solution's dominance\n    if dominance[selected_idx] > np.median(dominance):\n        perturbation_prob = 0.3\n        num_perturbations = 3\n    else:\n        perturbation_prob = 0.1\n        num_perturbations = 2\n\n    if np.random.rand() < perturbation_prob:\n        # Select items with low combined marginal gains for perturbation\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        selected_perturbations = np.random.choice(low_gain_indices, min(num_perturbations, len(low_gain_indices)), replace=False)\n\n        for idx in selected_perturbations:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Final feasibility check and refinement\n    for _ in range(3):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n        else:\n            # Remove items with lowest marginal gain to make feasible\n            excess = temp_weight - capacity\n            while excess > 0 and np.any(temp_solution):\n                lowest_gain_idx = np.argmin(combined_gain * temp_solution)\n                if temp_solution[lowest_gain_idx] == 1:\n                    temp_solution[lowest_gain_idx] = 0\n                    excess -= weight_lst[lowest_gain_idx]\n            new_solution = temp_solution\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        None\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solutions with high crowding distance and high normalized objective sums\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Calculate normalized objective sums\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        normalized_scores = np.ones(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0]/max_obj1 + objectives[:, 1]/max_obj2)\n\n    # Combine crowding and normalized scores\n    combined_scores = crowding * normalized_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate multi-objective marginal gains\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n\n    # Select top items with highest combined marginal gains\n    top_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    # Greedy flips for top gain items\n    for idx in top_gain_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Adaptive perturbation based on solution's position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.4\n        num_perturbations = 2\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n        num_perturbations = 1\n\n    if np.random.rand() < perturbation_prob:\n        # Select items with low combined marginal gains for perturbation\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        selected_perturbations = np.random.choice(low_gain_indices, min(num_perturbations, len(low_gain_indices)), replace=False)\n\n        for idx in selected_perturbations:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Final feasibility check and refinement\n    for _ in range(3):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n        else:\n            # Remove heaviest items to make feasible\n            excess = temp_weight - capacity\n            while excess > 0 and np.any(temp_solution):\n                heaviest_idx = np.argmax(weight_lst * temp_solution)\n                if temp_solution[heaviest_idx] == 1:\n                    temp_solution[heaviest_idx] = 0\n                    excess -= weight_lst[heaviest_idx]\n            new_solution = temp_solution\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 66,
        "algorithm": "This algorithm selects a promising solution from an archive by combining diversity and normalized objective scores, then applies a hybrid local search that greedily flips high-marginal-gain items and adaptively perturbs low-marginal-gain items, while ensuring feasibility through iterative refinement. The selection prioritizes solutions with high diversity and normalized objective products, while the local search balances aggressive and conservative perturbations based on solution dominance. The algorithm emphasizes multi-objective marginal gains (60% weight for objective 1, 40% for objective 2) and refines solutions through iterative feasibility checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solutions with high diversity and high normalized objective products\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate diversity scores using Euclidean distance\n    diversity = np.zeros(len(archive))\n    for i in range(len(archive)):\n        distances = np.linalg.norm(objectives - objectives[i], axis=1)\n        diversity[i] = np.mean(distances)\n\n    # Calculate normalized objective products\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        normalized_scores = np.ones(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0]/max_obj1) * (objectives[:, 1]/max_obj2)\n\n    # Combine diversity and normalized scores\n    combined_scores = diversity * normalized_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate multi-objective marginal gains with weight normalization\n    marginal_gain1 = value1_lst / (weight_lst + 1e-6)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n    combined_gain = 0.6 * marginal_gain1 + 0.4 * marginal_gain2\n\n    # Select top items with highest combined marginal gains\n    top_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    # Greedy flips for top gain items with probability\n    for idx in top_gain_indices:\n        if np.random.rand() < 0.7:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive perturbation based on solution's dominance rank\n    dominance_rank = np.zeros(len(archive))\n    for i in range(len(archive)):\n        dominated = 0\n        for j in range(len(archive)):\n            if i != j and all(objectives[j] >= objectives[i]):\n                dominated += 1\n        dominance_rank[i] = dominated\n\n    if dominance_rank[selected_idx] < np.median(dominance_rank):\n        # More aggressive perturbation for non-dominated solutions\n        perturbation_prob = 0.5\n        num_perturbations = 3\n    else:\n        # More conservative perturbation for dominated solutions\n        perturbation_prob = 0.3\n        num_perturbations = 2\n\n    if np.random.rand() < perturbation_prob:\n        # Select items with low combined marginal gains for perturbation\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        selected_perturbations = np.random.choice(low_gain_indices, min(num_perturbations, len(low_gain_indices)), replace=False)\n\n        for idx in selected_perturbations:\n            if np.random.rand() < 0.6:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Final feasibility check and refinement\n    for _ in range(3):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n        else:\n            # Remove items with lowest value/weight ratio to make feasible\n            value_ratio = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_indices = np.argsort(value_ratio)\n            excess = temp_weight - capacity\n            for idx in sorted_indices:\n                if temp_solution[idx] == 1:\n                    temp_solution[idx] = 0\n                    excess -= weight_lst[idx]\n                    if excess <= 0:\n                        break\n            new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -0.5327047107404536,
            0.6955554485321045
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solutions with high diversity and high normalized objective products\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate diversity scores using Euclidean distance\n    diversity = np.zeros(len(archive))\n    for i in range(len(archive)):\n        distances = np.linalg.norm(objectives - objectives[i], axis=1)\n        diversity[i] = np.mean(distances)\n\n    # Calculate normalized objective products\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        normalized_scores = np.ones(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0]/max_obj1) * (objectives[:, 1]/max_obj2)\n\n    # Combine diversity and normalized scores\n    combined_scores = diversity * normalized_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate multi-objective marginal gains with weight normalization\n    marginal_gain1 = value1_lst / (weight_lst + 1e-6)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n    combined_gain = 0.6 * marginal_gain1 + 0.4 * marginal_gain2\n\n    # Select top items with highest combined marginal gains\n    top_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    # Greedy flips for top gain items with probability\n    for idx in top_gain_indices:\n        if np.random.rand() < 0.7:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive perturbation based on solution's dominance rank\n    dominance_rank = np.zeros(len(archive))\n    for i in range(len(archive)):\n        dominated = 0\n        for j in range(len(archive)):\n            if i != j and all(objectives[j] >= objectives[i]):\n                dominated += 1\n        dominance_rank[i] = dominated\n\n    if dominance_rank[selected_idx] < np.median(dominance_rank):\n        # More aggressive perturbation for non-dominated solutions\n        perturbation_prob = 0.5\n        num_perturbations = 3\n    else:\n        # More conservative perturbation for dominated solutions\n        perturbation_prob = 0.3\n        num_perturbations = 2\n\n    if np.random.rand() < perturbation_prob:\n        # Select items with low combined marginal gains for perturbation\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        selected_perturbations = np.random.choice(low_gain_indices, min(num_perturbations, len(low_gain_indices)), replace=False)\n\n        for idx in selected_perturbations:\n            if np.random.rand() < 0.6:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Final feasibility check and refinement\n    for _ in range(3):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n        else:\n            # Remove items with lowest value/weight ratio to make feasible\n            value_ratio = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            sorted_indices = np.argsort(value_ratio)\n            excess = temp_weight - capacity\n            for idx in sorted_indices:\n                if temp_solution[idx] == 1:\n                    temp_solution[idx] = 0\n                    excess -= weight_lst[idx]\n                    if excess <= 0:\n                        break\n            new_solution = temp_solution\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 4 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solutions with high crowding distance and high normalized objective sums\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Calculate normalized objective sums\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        normalized_scores = np.ones(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0]/max_obj1 + objectives[:, 1]/max_obj2)\n\n    # Combine crowding and normalized scores\n    combined_scores = crowding * normalized_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate multi-objective marginal gains\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n\n    # Select top items with highest combined marginal gains\n    top_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    # Greedy flips for top gain items\n    for idx in top_gain_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Adaptive perturbation based on solution's position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.4\n        num_perturbations = 2\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n        num_perturbations = 1\n\n    if np.random.rand() < perturbation_prob:\n        # Select items with low combined marginal gains for perturbation\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        selected_perturbations = np.random.choice(low_gain_indices, min(num_perturbations, len(low_gain_indices)), replace=False)\n\n        for idx in selected_perturbations:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Final feasibility check and refinement\n    for _ in range(3):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n        else:\n            # Remove heaviest items to make feasible\n            excess = temp_weight - capacity\n            while excess > 0 and np.any(temp_solution):\n                heaviest_idx = np.argmax(weight_lst * temp_solution)\n                if temp_solution[heaviest_idx] == 1:\n                    temp_solution[heaviest_idx] = 0\n                    excess -= weight_lst[heaviest_idx]\n            new_solution = temp_solution\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 67,
        "algorithm": "The algorithm selects promising solutions from the top 20% of the archive (based on normalized objective sums) and performs a hybrid local search by iteratively flipping items with high marginal gains (considering both objectives) while ensuring feasibility. It also includes adaptive perturbations (30% chance) to flip low-marginal-gain items to escape local optima, repeating this process 3-5 times per solution. The method prioritizes high-value items first but balances exploration with exploitation through randomness in selection and perturbation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Repeat local search steps 3-5 times\n    for _ in range(np.random.randint(3, 6)):\n        # Calculate marginal gains for both objectives\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n        combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n\n        # Flip top 3-5 highest marginal gain items\n        top_gain_indices = np.argsort(-combined_gain)[:np.random.randint(3, 6)]\n        for idx in top_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        # Adaptive perturbation: flip 1-2 low marginal gain items with 30% probability\n        if np.random.rand() < 0.3:\n            low_gain_indices = np.argsort(combined_gain)[:np.random.randint(1, 3)]\n            for idx in low_gain_indices:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.35994862372352143,
            0.3100021183490753
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Repeat local search steps 3-5 times\n    for _ in range(np.random.randint(3, 6)):\n        # Calculate marginal gains for both objectives\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n        combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n\n        # Flip top 3-5 highest marginal gain items\n        top_gain_indices = np.argsort(-combined_gain)[:np.random.randint(3, 6)]\n        for idx in top_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        # Adaptive perturbation: flip 1-2 low marginal gain items with 30% probability\n        if np.random.rand() < 0.3:\n            low_gain_indices = np.argsort(combined_gain)[:np.random.randint(1, 3)]\n            for idx in low_gain_indices:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 4 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s a refined heuristic design for the BI-KP:\n\n### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 68,
        "algorithm": "The algorithm selects top 20% of solutions from the archive based on normalized objective sums, then performs targeted local search by flipping high-marginal-gain items (prioritizing combined value/weight ratios) while occasionally adding random feasible flips to escape local optima, with iterative refinement to ensure feasibility. It emphasizes high-potential items through marginal gain analysis while maintaining diversity through controlled randomness.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: add 1-2 random feasible flips\n    if np.random.rand() < 0.4:\n        num_random_flips = np.random.randint(1, 3)\n        for _ in range(num_random_flips):\n            candidate_idx = np.random.randint(len(weight_lst))\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.6011800490563799,
            0.2303050458431244
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: add 1-2 random feasible flips\n    if np.random.rand() < 0.4:\n        num_random_flips = np.random.randint(1, 3)\n        for _ in range(num_random_flips):\n            candidate_idx = np.random.randint(len(weight_lst))\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the top 20% of the archive (based on normalized objective sums) and applies a hybrid local search combining targeted flipping of high-marginal-gain items (prioritizing both objectives), adaptive perturbation of low-marginal-contribution items, and controlled random bit-flips, all while ensuring feasibility through strict capacity checks. The process repeats for 3 rounds to iteratively refine the solution, balancing exploitation of high-value items with exploration of low-contribution items.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search with multiple iterations\n    for _ in range(3):  # Perform 3 rounds of refinement\n        # Targeted flipping: high marginal gain items (considering both objectives)\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n        combined_gain = marginal_gain1 + marginal_gain2\n        high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Adaptive perturbation: low marginal contribution items\n        if np.random.rand() < 0.4:  # Higher perturbation probability\n            low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n            for idx in low_gain_indices:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Random bit-flip with limited attempts\n        for _ in range(2):  # Limit to 2 random flips\n            candidate_idx = np.random.randint(len(weight_lst))\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s a refined heuristic design for the BI-KP:\n\n### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 69,
        "algorithm": "The algorithm selects a top-performing solution from the archive (top 20% by normalized objective sums) and applies a multi-phase local search: first flipping high-marginal-gain items, then adaptively removing low-contribution items, and finally perturbing based on balanced contributions to both objectives, all while strictly maintaining feasibility. The process repeats for 4 rounds to iteratively refine the solution.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Multi-phase local search\n    for _ in range(4):  # Perform 4 rounds of refinement\n        # Phase 1: Flip items with highest marginal gains in either objective\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n        high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Phase 2: Adaptive removal of low-marginal-contribution items (40% probability)\n        if np.random.rand() < 0.4:\n            low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n            for idx in low_gain_indices:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n\n        # Phase 3: Objective-balanced perturbation (flip items based on normalized contributions)\n        normalized_contrib1 = value1_lst / (np.sum(value1_lst) + 1e-10)\n        normalized_contrib2 = value2_lst / (np.sum(value2_lst) + 1e-10)\n        combined_contrib = normalized_contrib1 + normalized_contrib2\n        perturbation_indices = np.argsort(-combined_contrib)[:min(2, len(weight_lst))]\n\n        for idx in perturbation_indices:\n            if np.random.rand() < combined_contrib[idx] * 0.5:  # Higher probability for higher contributions\n                if base_solution[idx] == 1:\n                    if current_weight - weight_lst[idx] <= capacity:\n                        new_solution[idx] = 0\n                        current_weight -= weight_lst[idx]\n                else:\n                    if current_weight + weight_lst[idx] <= capacity:\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7488381077168287,
            0.6945831775665283
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Multi-phase local search\n    for _ in range(4):  # Perform 4 rounds of refinement\n        # Phase 1: Flip items with highest marginal gains in either objective\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n        high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Phase 2: Adaptive removal of low-marginal-contribution items (40% probability)\n        if np.random.rand() < 0.4:\n            low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n            for idx in low_gain_indices:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n\n        # Phase 3: Objective-balanced perturbation (flip items based on normalized contributions)\n        normalized_contrib1 = value1_lst / (np.sum(value1_lst) + 1e-10)\n        normalized_contrib2 = value2_lst / (np.sum(value2_lst) + 1e-10)\n        combined_contrib = normalized_contrib1 + normalized_contrib2\n        perturbation_indices = np.argsort(-combined_contrib)[:min(2, len(weight_lst))]\n\n        for idx in perturbation_indices:\n            if np.random.rand() < combined_contrib[idx] * 0.5:  # Higher probability for higher contributions\n                if base_solution[idx] == 1:\n                    if current_weight - weight_lst[idx] <= capacity:\n                        new_solution[idx] = 0\n                        current_weight -= weight_lst[idx]\n                else:\n                    if current_weight + weight_lst[idx] <= capacity:\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive (based on normalized objective sums) and applies a targeted local search by prioritizing flips of high-marginal-gain items, followed by 1-2 random flips to escape local optima, while ensuring feasibility through iterative refinement. High-marginal-gain items (based on value-to-weight ratios) are given higher priority, and the algorithm balances exploitation (focused flips) with exploration (random flips) to improve solution quality.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips to escape local optima\n    num_random_flips = np.random.randint(1, 3)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the top 20% of the archive (based on normalized objective sums) and applies a hybrid local search combining targeted flipping of high-marginal-gain items (prioritizing both objectives), adaptive perturbation of low-marginal-contribution items, and controlled random bit-flips, all while ensuring feasibility through strict capacity checks. The process repeats for 3 rounds to iteratively refine the solution, balancing exploitation of high-value items with exploration of low-contribution items.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search with multiple iterations\n    for _ in range(3):  # Perform 3 rounds of refinement\n        # Targeted flipping: high marginal gain items (considering both objectives)\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n        combined_gain = marginal_gain1 + marginal_gain2\n        high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Adaptive perturbation: low marginal contribution items\n        if np.random.rand() < 0.4:  # Higher perturbation probability\n            low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n            for idx in low_gain_indices:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Random bit-flip with limited attempts\n        for _ in range(2):  # Limit to 2 random flips\n            candidate_idx = np.random.randint(len(weight_lst))\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s a refined heuristic design for the BI-KP:\n\n### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 70,
        "algorithm": "The algorithm selects a solution from a cluster with high objective variance, then generates a neighbor by flipping boundary items (high marginal gains) and introducing diversity through low-frequency items in the cluster, while ensuring feasibility through iterative weight checks. It prioritizes cluster boundaries and underrepresented items for exploration, balancing exploitation and diversification.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Cluster solutions by objective profiles\n    objectives = np.array([obj for _, obj in archive])\n    if len(objectives) < 2:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        from sklearn.cluster import KMeans\n        n_clusters = min(3, len(archive) // 5)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(objectives)\n        cluster_labels = kmeans.labels_\n        cluster_centers = kmeans.cluster_centers_\n\n        # Select a solution from the cluster with the highest variance in objectives\n        cluster_variances = [np.var(objectives[cluster_labels == i]) for i in range(n_clusters)]\n        selected_cluster = np.argmax(cluster_variances)\n        cluster_indices = np.where(cluster_labels == selected_cluster)[0]\n        selected_idx = np.random.choice(cluster_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Identify boundary items (high marginal gains in either objective)\n    marginal_gain1 = value1_lst / (weight_lst + 1e-8)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-8)\n    boundary_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    # Flip boundary items to explore cluster boundaries\n    for idx in boundary_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Introduce controlled diversity by flipping low-marginal-gain items within the cluster\n    cluster_solutions = [archive[i][0] for i in cluster_indices]\n    if len(cluster_solutions) > 1:\n        cluster_solutions = np.array(cluster_solutions)\n        item_frequencies = np.mean(cluster_solutions, axis=0)\n        low_freq_indices = np.where(item_frequencies < 0.3)[0]  # Items rarely included in the cluster\n\n        for idx in low_freq_indices:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Ensure feasibility and iterative refinement\n    for _ in range(3):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.8328862964508936,
            3.553450286388397
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Cluster solutions by objective profiles\n    objectives = np.array([obj for _, obj in archive])\n    if len(objectives) < 2:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        from sklearn.cluster import KMeans\n        n_clusters = min(3, len(archive) // 5)\n        kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(objectives)\n        cluster_labels = kmeans.labels_\n        cluster_centers = kmeans.cluster_centers_\n\n        # Select a solution from the cluster with the highest variance in objectives\n        cluster_variances = [np.var(objectives[cluster_labels == i]) for i in range(n_clusters)]\n        selected_cluster = np.argmax(cluster_variances)\n        cluster_indices = np.where(cluster_labels == selected_cluster)[0]\n        selected_idx = np.random.choice(cluster_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Identify boundary items (high marginal gains in either objective)\n    marginal_gain1 = value1_lst / (weight_lst + 1e-8)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-8)\n    boundary_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    # Flip boundary items to explore cluster boundaries\n    for idx in boundary_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Introduce controlled diversity by flipping low-marginal-gain items within the cluster\n    cluster_solutions = [archive[i][0] for i in cluster_indices]\n    if len(cluster_solutions) > 1:\n        cluster_solutions = np.array(cluster_solutions)\n        item_frequencies = np.mean(cluster_solutions, axis=0)\n        low_freq_indices = np.where(item_frequencies < 0.3)[0]  # Items rarely included in the cluster\n\n        for idx in low_freq_indices:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Ensure feasibility and iterative refinement\n    for _ in range(3):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the top 20% of the archive (based on normalized objective sums) and applies a hybrid local search combining targeted flipping of high-marginal-gain items (prioritizing both objectives), adaptive perturbation of low-marginal-contribution items, and controlled random bit-flips, all while ensuring feasibility through strict capacity checks. The process repeats for 3 rounds to iteratively refine the solution, balancing exploitation of high-value items with exploration of low-contribution items.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search with multiple iterations\n    for _ in range(3):  # Perform 3 rounds of refinement\n        # Targeted flipping: high marginal gain items (considering both objectives)\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n        combined_gain = marginal_gain1 + marginal_gain2\n        high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Adaptive perturbation: low marginal contribution items\n        if np.random.rand() < 0.4:  # Higher perturbation probability\n            low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n            for idx in low_gain_indices:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Random bit-flip with limited attempts\n        for _ in range(2):  # Limit to 2 random flips\n            candidate_idx = np.random.randint(len(weight_lst))\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 71,
        "algorithm": "The algorithm selects promising solutions from the top 30% of the archive based on a weighted objective score that prioritizes less dominant objectives, then applies a hybrid local search combining targeted flipping of high-gain items, adaptive perturbation of low-gain items with dynamic probabilities, and controlled random swaps while maintaining feasibility through strict capacity checks. The weighted score balances objectives, while the local search focuses on high-impact items and controlled randomness to explore the solution space efficiently.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions based on weighted objective score (prioritize less dominant objective)\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Weighted score prioritizing the less dominant objective\n        weights = np.where(obj1_scores/max_obj1 < obj2_scores/max_obj2, 0.7, 0.3)\n        weighted_scores = (obj1_scores/max_obj1 * weights) + (obj2_scores/max_obj2 * (1 - weights))\n        top_indices = np.argsort(weighted_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search with novel components\n    for _ in range(2):  # Two rounds of refinement\n        # Targeted flipping: high normalized gain items\n        normalized_gain = (value1_lst * (max_obj2 - obj2_scores[selected_idx]) + value2_lst * (max_obj1 - obj1_scores[selected_idx])) / weight_lst\n        high_gain_indices = np.argsort(-normalized_gain)[:min(5, len(weight_lst))]\n\n        for idx in high_gain_indices:\n            if np.random.rand() < 0.6:  # Higher probability for high-gain items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Adaptive perturbation: low gain items with dynamic probability\n        low_gain_threshold = np.percentile(normalized_gain, 30)\n        low_gain_indices = np.where(normalized_gain < low_gain_threshold)[0]\n\n        for idx in low_gain_indices:\n            perturbation_prob = min(0.5, 0.1 + 0.4 * (1 - normalized_gain[idx]/np.max(normalized_gain)))\n            if np.random.rand() < perturbation_prob:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Controlled random walk with capacity-aware swaps\n        for _ in range(3):\n            # Select a pair of items to swap\n            swap_candidates = np.random.choice(len(weight_lst), size=2, replace=False)\n            i, j = swap_candidates\n\n            # Calculate potential weight change\n            weight_change = (weight_lst[j] - weight_lst[i]) if base_solution[i] == 1 else (weight_lst[i] - weight_lst[j])\n\n            if current_weight + weight_change <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                current_weight += weight_change\n\n    return new_solution\n\n",
        "score": [
            -0.47469396407772624,
            1.7376534044742584
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions based on weighted objective score (prioritize less dominant objective)\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Weighted score prioritizing the less dominant objective\n        weights = np.where(obj1_scores/max_obj1 < obj2_scores/max_obj2, 0.7, 0.3)\n        weighted_scores = (obj1_scores/max_obj1 * weights) + (obj2_scores/max_obj2 * (1 - weights))\n        top_indices = np.argsort(weighted_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search with novel components\n    for _ in range(2):  # Two rounds of refinement\n        # Targeted flipping: high normalized gain items\n        normalized_gain = (value1_lst * (max_obj2 - obj2_scores[selected_idx]) + value2_lst * (max_obj1 - obj1_scores[selected_idx])) / weight_lst\n        high_gain_indices = np.argsort(-normalized_gain)[:min(5, len(weight_lst))]\n\n        for idx in high_gain_indices:\n            if np.random.rand() < 0.6:  # Higher probability for high-gain items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Adaptive perturbation: low gain items with dynamic probability\n        low_gain_threshold = np.percentile(normalized_gain, 30)\n        low_gain_indices = np.where(normalized_gain < low_gain_threshold)[0]\n\n        for idx in low_gain_indices:\n            perturbation_prob = min(0.5, 0.1 + 0.4 * (1 - normalized_gain[idx]/np.max(normalized_gain)))\n            if np.random.rand() < perturbation_prob:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Controlled random walk with capacity-aware swaps\n        for _ in range(3):\n            # Select a pair of items to swap\n            swap_candidates = np.random.choice(len(weight_lst), size=2, replace=False)\n            i, j = swap_candidates\n\n            # Calculate potential weight change\n            weight_change = (weight_lst[j] - weight_lst[i]) if base_solution[i] == 1 else (weight_lst[i] - weight_lst[j])\n\n            if current_weight + weight_change <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                current_weight += weight_change\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the top 20% of the archive (based on normalized objective sums) and applies a hybrid local search combining targeted flipping of high-marginal-gain items (prioritizing both objectives), adaptive perturbation of low-marginal-contribution items, and controlled random bit-flips, all while ensuring feasibility through strict capacity checks. The process repeats for 3 rounds to iteratively refine the solution, balancing exploitation of high-value items with exploration of low-contribution items.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search with multiple iterations\n    for _ in range(3):  # Perform 3 rounds of refinement\n        # Targeted flipping: high marginal gain items (considering both objectives)\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n        combined_gain = marginal_gain1 + marginal_gain2\n        high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Adaptive perturbation: low marginal contribution items\n        if np.random.rand() < 0.4:  # Higher perturbation probability\n            low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n            for idx in low_gain_indices:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Random bit-flip with limited attempts\n        for _ in range(2):  # Limit to 2 random flips\n            candidate_idx = np.random.randint(len(weight_lst))\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 72,
        "algorithm": "The algorithm selects a promising solution from the top 30% of the archive (based on Pareto dominance counts) and applies a hybrid local search combining targeted flipping of high-marginal-gain items (weighted 60% for objective 1 and 40% for objective 2), adaptive perturbation of low-marginal-contribution items with decreasing probability, and controlled random bit-flips, all while ensuring feasibility. It performs 4 refinement rounds to iteratively refine the solution, balancing exploitation of high-value items with exploration of low-contribution items.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by Pareto dominance counts\n    dominance_counts = [0] * len(archive)\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (archive[i][1][0] >= archive[j][1][0] and archive[i][1][1] > archive[j][1][1]) or \\\n                   (archive[i][1][0] > archive[j][1][0] and archive[i][1][1] >= archive[j][1][1]):\n                    dominance_counts[i] += 1\n\n    top_indices = np.argsort(dominance_counts)[-max(1, len(archive)//3):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search with multiple iterations\n    for _ in range(4):  # Perform 4 rounds of refinement\n        # Targeted flipping: high marginal gain items (weighted by objective values)\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n        combined_gain = 0.6 * marginal_gain1 + 0.4 * marginal_gain2  # Weighted gain\n        high_gain_indices = np.argsort(-combined_gain)[:min(6, len(weight_lst))]\n\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Adaptive perturbation: low marginal contribution items with dynamic probability\n        perturbation_prob = 0.5 - 0.1 * (_ + 1)  # Decrease probability over rounds\n        if np.random.rand() < perturbation_prob:\n            low_gain_indices = np.argsort(combined_gain)[:min(4, len(weight_lst))]\n            for idx in low_gain_indices:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Random bit-flip with limited attempts\n        for _ in range(3):  # Limit to 3 random flips\n            candidate_idx = np.random.randint(len(weight_lst))\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.36606839085304343,
            0.4214068651199341
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by Pareto dominance counts\n    dominance_counts = [0] * len(archive)\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (archive[i][1][0] >= archive[j][1][0] and archive[i][1][1] > archive[j][1][1]) or \\\n                   (archive[i][1][0] > archive[j][1][0] and archive[i][1][1] >= archive[j][1][1]):\n                    dominance_counts[i] += 1\n\n    top_indices = np.argsort(dominance_counts)[-max(1, len(archive)//3):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search with multiple iterations\n    for _ in range(4):  # Perform 4 rounds of refinement\n        # Targeted flipping: high marginal gain items (weighted by objective values)\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n        combined_gain = 0.6 * marginal_gain1 + 0.4 * marginal_gain2  # Weighted gain\n        high_gain_indices = np.argsort(-combined_gain)[:min(6, len(weight_lst))]\n\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Adaptive perturbation: low marginal contribution items with dynamic probability\n        perturbation_prob = 0.5 - 0.1 * (_ + 1)  # Decrease probability over rounds\n        if np.random.rand() < perturbation_prob:\n            low_gain_indices = np.argsort(combined_gain)[:min(4, len(weight_lst))]\n            for idx in low_gain_indices:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Random bit-flip with limited attempts\n        for _ in range(3):  # Limit to 3 random flips\n            candidate_idx = np.random.randint(len(weight_lst))\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 3 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the top 20% of the archive (based on normalized objective sums) and applies a hybrid local search combining targeted flipping of high-marginal-gain items (prioritizing both objectives), adaptive perturbation of low-marginal-contribution items, and controlled random bit-flips, all while ensuring feasibility through strict capacity checks. The process repeats for 3 rounds to iteratively refine the solution, balancing exploitation of high-value items with exploration of low-contribution items.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search with multiple iterations\n    for _ in range(3):  # Perform 3 rounds of refinement\n        # Targeted flipping: high marginal gain items (considering both objectives)\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n        combined_gain = marginal_gain1 + marginal_gain2\n        high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Adaptive perturbation: low marginal contribution items\n        if np.random.rand() < 0.4:  # Higher perturbation probability\n            low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n            for idx in low_gain_indices:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Random bit-flip with limited attempts\n        for _ in range(2):  # Limit to 2 random flips\n            candidate_idx = np.random.randint(len(weight_lst))\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s a refined heuristic design for the BI-KP:\n\n### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 73,
        "algorithm": "The algorithm selects top 20% solutions from the archive based on normalized objective sums, then iteratively refines each by flipping high-marginal-gain items (prioritizing both objectives) and performing 1-2 controlled random flips of low-marginal items to escape local optima while ensuring feasibility. The process repeats for 5 rounds per solution to balance exploitation and exploration, ultimately returning the best-refined neighbor solution.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Iterative refinement (5 rounds)\n    for _ in range(5):\n        # Flip top 3 high-marginal-gain items in either objective\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n        combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n        high_gain_indices = np.argsort(-combined_gain)[:min(3, len(weight_lst))]\n\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Controlled random flips of low-marginal-contribution items (1-2 flips)\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        num_random_flips = np.random.randint(1, 3)\n        for _ in range(num_random_flips):\n            if len(low_gain_indices) == 0:\n                break\n            idx = np.random.choice(low_gain_indices)\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7672496518481793,
            0.46966344118118286
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Iterative refinement (5 rounds)\n    for _ in range(5):\n        # Flip top 3 high-marginal-gain items in either objective\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n        combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n        high_gain_indices = np.argsort(-combined_gain)[:min(3, len(weight_lst))]\n\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Controlled random flips of low-marginal-contribution items (1-2 flips)\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        num_random_flips = np.random.randint(1, 3)\n        for _ in range(num_random_flips):\n            if len(low_gain_indices) == 0:\n                break\n            idx = np.random.choice(low_gain_indices)\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 4 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s the refined heuristic design for the BI-KP:\n\n### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 74,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips to escape local optima\n    random_flips = np.random.randint(1, 3)\n    for _ in range(random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.7964384358864955,
            0.23818635940551758
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips to escape local optima\n    random_flips = np.random.randint(1, 3)\n    for _ in range(random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects top 30% solutions from the archive based on a weighted sum of normalized objectives (60% weight for value1, 40% for value2), then generates neighbors by flipping items with highest marginal gains (adjusted by current weight utilization) followed by dynamic random flips, ensuring feasibility through adaptive item removal based on marginal gain ratios. It prioritizes high-value items early while maintaining diversity through weighted selection and utilization-aware flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (0.6 * obj1_scores / max_obj1) + (0.4 * obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n    current_utilization = current_weight / capacity\n\n    # Calculate marginal gains with weight sensitivity\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = (1 - current_utilization) * marginal_gain1 + current_utilization * marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    # Flip items with highest combined gains\n    for idx in sorted_indices[:min(7, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips based on current utilization\n    num_flips = max(1, int(3 * (1 - current_utilization)))\n    for _ in range(num_flips):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Adaptive feasibility maintenance\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n\n        if len(removable_items) == 0:\n            break\n\n        # Remove item with lowest marginal gain ratio\n        removal_criteria = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(removal_criteria)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP:\n\n### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 75,
        "algorithm": "The algorithm selects the top 20% of non-dominated solutions from the archive based on a balanced normalized objective sum (equal weight for both objectives), then generates neighbors by flipping items with the highest marginal gains in either objective, followed by 1-2 random flips to escape local optima while ensuring feasibility through dynamic adjustments. It iterates 5-10 times per solution to refine the archive, prioritizing high-margin items while maintaining feasibility through strict capacity checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by balanced normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (0.5 * obj1_scores / max_obj1) + (0.5 * obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Iterate 5-10 times to refine the solution\n    for _ in range(np.random.randint(5, 11)):\n        # Calculate marginal gains for each objective\n        marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n        marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n        # Flip items with highest marginal gains in either objective\n        for obj in [1, 2]:\n            if obj == 1:\n                marginal_gain = marginal_gain1\n            else:\n                marginal_gain = marginal_gain2\n\n            sorted_indices = np.argsort(marginal_gain)[::-1]\n            for idx in sorted_indices[:min(3, n_items)]:\n                if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n\n        # Add 1-2 random flips\n        num_flips = np.random.randint(1, 3)\n        for _ in range(num_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n            elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n        # Reject infeasible solutions\n        if np.sum(new_solution * weight_lst) > capacity:\n            new_solution = base_solution.copy()\n            current_weight = np.sum(weight_lst * base_solution)\n\n    return new_solution\n\n",
        "score": [
            -0.5658836013527027,
            0.7645628452301025
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by balanced normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (0.5 * obj1_scores / max_obj1) + (0.5 * obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Iterate 5-10 times to refine the solution\n    for _ in range(np.random.randint(5, 11)):\n        # Calculate marginal gains for each objective\n        marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n        marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n        # Flip items with highest marginal gains in either objective\n        for obj in [1, 2]:\n            if obj == 1:\n                marginal_gain = marginal_gain1\n            else:\n                marginal_gain = marginal_gain2\n\n            sorted_indices = np.argsort(marginal_gain)[::-1]\n            for idx in sorted_indices[:min(3, n_items)]:\n                if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n\n        # Add 1-2 random flips\n        num_flips = np.random.randint(1, 3)\n        for _ in range(num_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n            elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n        # Reject infeasible solutions\n        if np.sum(new_solution * weight_lst) > capacity:\n            new_solution = base_solution.copy()\n            current_weight = np.sum(weight_lst * base_solution)\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects top 30% solutions from the archive based on a weighted sum of normalized objectives (60% weight for value1, 40% for value2), then generates neighbors by flipping items with highest marginal gains (adjusted by current weight utilization) followed by dynamic random flips, ensuring feasibility through adaptive item removal based on marginal gain ratios. It prioritizes high-value items early while maintaining diversity through weighted selection and utilization-aware flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (0.6 * obj1_scores / max_obj1) + (0.4 * obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n    current_utilization = current_weight / capacity\n\n    # Calculate marginal gains with weight sensitivity\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = (1 - current_utilization) * marginal_gain1 + current_utilization * marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    # Flip items with highest combined gains\n    for idx in sorted_indices[:min(7, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips based on current utilization\n    num_flips = max(1, int(3 * (1 - current_utilization)))\n    for _ in range(num_flips):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Adaptive feasibility maintenance\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n\n        if len(removable_items) == 0:\n            break\n\n        # Remove item with lowest marginal gain ratio\n        removal_criteria = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(removal_criteria)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP:\n\n### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 76,
        "algorithm": "The algorithm combines adaptive solution selection (focusing on top 20% normalized dominance scores) with a hybrid local search that prioritizes high-marginal-gain flips (60% weight on value1, 40% on value2) and weight-sensitive random perturbations, while dynamically adjusting flip probabilities and ensuring feasibility through iterative removal of least valuable items. The method balances exploitation of promising regions with exploration via constrained randomness, dynamically adjusting exploration intensity based on current solution quality and capacity utilization.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective dominance\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        dominance_scores = (obj1_scores / max_obj1) * (obj2_scores / max_obj2)\n        top_indices = np.argsort(dominance_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains with objective balance\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = 0.6 * marginal_gain1 + 0.4 * marginal_gain2\n\n    # Targeted flips: prioritize high-gain items in either objective\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, n_items)]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Constrained random flips: weight-sensitive probability\n    utilization = current_weight / capacity\n    flip_prob = min(0.3, 0.1 + 0.2 * (1 - utilization))\n    for idx in np.random.permutation(n_items):\n        if np.random.rand() < flip_prob:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Dynamic feasibility check and repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n\n        if len(removable_items) == 0:\n            break\n\n        # Remove item with lowest combined marginal gain\n        removal_criteria = 0.6 * (value1_lst[removable_items] / (weight_lst[removable_items] + 1e-10)) + 0.4 * (value2_lst[removable_items] / (weight_lst[removable_items] + 1e-10))\n        remove_idx = removable_items[np.argmin(removal_criteria)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.4284872747375792,
            0.4416930675506592
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective dominance\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        dominance_scores = (obj1_scores / max_obj1) * (obj2_scores / max_obj2)\n        top_indices = np.argsort(dominance_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains with objective balance\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = 0.6 * marginal_gain1 + 0.4 * marginal_gain2\n\n    # Targeted flips: prioritize high-gain items in either objective\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, n_items)]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Constrained random flips: weight-sensitive probability\n    utilization = current_weight / capacity\n    flip_prob = min(0.3, 0.1 + 0.2 * (1 - utilization))\n    for idx in np.random.permutation(n_items):\n        if np.random.rand() < flip_prob:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Dynamic feasibility check and repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n\n        if len(removable_items) == 0:\n            break\n\n        # Remove item with lowest combined marginal gain\n        removal_criteria = 0.6 * (value1_lst[removable_items] / (weight_lst[removable_items] + 1e-10)) + 0.4 * (value2_lst[removable_items] / (weight_lst[removable_items] + 1e-10))\n        remove_idx = removable_items[np.argmin(removal_criteria)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects top 30% solutions from the archive based on a weighted sum of normalized objectives (60% weight for value1, 40% for value2), then generates neighbors by flipping items with highest marginal gains (adjusted by current weight utilization) followed by dynamic random flips, ensuring feasibility through adaptive item removal based on marginal gain ratios. It prioritizes high-value items early while maintaining diversity through weighted selection and utilization-aware flipping.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (0.6 * obj1_scores / max_obj1) + (0.4 * obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n    current_utilization = current_weight / capacity\n\n    # Calculate marginal gains with weight sensitivity\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = (1 - current_utilization) * marginal_gain1 + current_utilization * marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    # Flip items with highest combined gains\n    for idx in sorted_indices[:min(7, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips based on current utilization\n    num_flips = max(1, int(3 * (1 - current_utilization)))\n    for _ in range(num_flips):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Adaptive feasibility maintenance\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n\n        if len(removable_items) == 0:\n            break\n\n        # Remove item with lowest marginal gain ratio\n        removal_criteria = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(removal_criteria)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 77,
        "algorithm": "The algorithm selects top 20% solutions from the archive using a dynamic weighted sum of objectives (prioritizing value1 at 70% and value2 at 30%), then applies a hybrid local search combining greedy flips for top marginal-gain items and probabilistic swaps, while maintaining feasibility through a multi-criteria removal strategy that balances value-weight ratios and weight penalties. The search adapts exploration/exploitation based on current solution utilization, favoring marginal gains in underutilized knapsacks and probabilistic swaps in overutilized ones.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions using dynamic weighted objective sum\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Dynamic weighting based on solution quality diversity\n        quality_diversity = np.std(obj1_scores) + np.std(obj2_scores)\n        weight1 = 0.7 - 0.1 * (quality_diversity / (max_obj1 + max_obj2 + 1e-10))\n        weight2 = 1 - weight1\n        normalized_scores = (weight1 * obj1_scores / max_obj1) + (weight2 * obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n    current_utilization = current_weight / capacity\n\n    # Hybrid local search with marginal gain and probabilistic swaps\n    # Calculate utilization-aware marginal gains\n    utilization_factor = 1 - (current_utilization ** 2)\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = (utilization_factor * marginal_gain1) + ((1 - utilization_factor) * marginal_gain2)\n\n    # Greedy flips for top 5 items\n    sorted_indices = np.argsort(combined_gain)[::-1]\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Probabilistic swaps based on marginal gains\n    swap_prob = 0.3 * (1 - current_utilization)\n    for idx in range(n_items):\n        if np.random.random() < swap_prob:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Multi-criteria feasibility maintenance\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n\n        if len(removable_items) == 0:\n            break\n\n        # Remove items with lowest value-weight ratio or highest weight\n        value_weight_ratio = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        weight_penalty = weight_lst[removable_items] / capacity\n        removal_score = value_weight_ratio - 2 * weight_penalty\n        remove_idx = removable_items[np.argmin(removal_score)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8838241777896173,
            0.5048092305660248
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions using dynamic weighted objective sum\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Dynamic weighting based on solution quality diversity\n        quality_diversity = np.std(obj1_scores) + np.std(obj2_scores)\n        weight1 = 0.7 - 0.1 * (quality_diversity / (max_obj1 + max_obj2 + 1e-10))\n        weight2 = 1 - weight1\n        normalized_scores = (weight1 * obj1_scores / max_obj1) + (weight2 * obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n    current_utilization = current_weight / capacity\n\n    # Hybrid local search with marginal gain and probabilistic swaps\n    # Calculate utilization-aware marginal gains\n    utilization_factor = 1 - (current_utilization ** 2)\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = (utilization_factor * marginal_gain1) + ((1 - utilization_factor) * marginal_gain2)\n\n    # Greedy flips for top 5 items\n    sorted_indices = np.argsort(combined_gain)[::-1]\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Probabilistic swaps based on marginal gains\n    swap_prob = 0.3 * (1 - current_utilization)\n    for idx in range(n_items):\n        if np.random.random() < swap_prob:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Multi-criteria feasibility maintenance\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n\n        if len(removable_items) == 0:\n            break\n\n        # Remove items with lowest value-weight ratio or highest weight\n        value_weight_ratio = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        weight_penalty = weight_lst[removable_items] / capacity\n        removal_score = value_weight_ratio - 2 * weight_penalty\n        remove_idx = removable_items[np.argmin(removal_score)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects top 30% solutions from the archive based on a weighted sum of normalized objectives (60% weight for value1, 40% for value2), then generates neighbors by flipping items with highest marginal gains (adjusted by current weight utilization) followed by dynamic random flips, ensuring feasibility through adaptive item removal based on marginal gain ratios. It prioritizes high-value items early while maintaining diversity through weighted selection and utilization-aware flipping.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (0.6 * obj1_scores / max_obj1) + (0.4 * obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n    current_utilization = current_weight / capacity\n\n    # Calculate marginal gains with weight sensitivity\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = (1 - current_utilization) * marginal_gain1 + current_utilization * marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    # Flip items with highest combined gains\n    for idx in sorted_indices[:min(7, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips based on current utilization\n    num_flips = max(1, int(3 * (1 - current_utilization)))\n    for _ in range(num_flips):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Adaptive feasibility maintenance\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n\n        if len(removable_items) == 0:\n            break\n\n        # Remove item with lowest marginal gain ratio\n        removal_criteria = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(removal_criteria)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 78,
        "algorithm": "The algorithm selects promising solutions from the archive (top 50% by a weighted objective score) and generates neighbors by intelligently flipping items based on marginal gains adjusted for current weight utilization. It prioritizes high-value items late in the process and ensures feasibility through adaptive item removal, with dynamic random flips to maintain diversity. The weighted selection (70% value1, 30% value2) and utilization-aware flipping are key design elements.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 50% solutions by weighted normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (0.7 * obj1_scores / max_obj1) + (0.3 * obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 2):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n    current_utilization = current_weight / capacity\n\n    # Calculate marginal gains with weight sensitivity\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = (1 - current_utilization) * marginal_gain2 + current_utilization * marginal_gain1\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    # Flip items with highest combined gains\n    for idx in sorted_indices[:min(10, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips based on current utilization\n    num_flips = max(1, int(5 * current_utilization))\n    for _ in range(num_flips):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Adaptive feasibility maintenance\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n\n        if len(removable_items) == 0:\n            break\n\n        # Remove item with lowest marginal gain ratio\n        removal_criteria = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmax(removal_criteria)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.7792425064012445,
            0.2775285840034485
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 50% solutions by weighted normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (0.7 * obj1_scores / max_obj1) + (0.3 * obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 2):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n    current_utilization = current_weight / capacity\n\n    # Calculate marginal gains with weight sensitivity\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = (1 - current_utilization) * marginal_gain2 + current_utilization * marginal_gain1\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    # Flip items with highest combined gains\n    for idx in sorted_indices[:min(10, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips based on current utilization\n    num_flips = max(1, int(5 * current_utilization))\n    for _ in range(num_flips):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Adaptive feasibility maintenance\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n\n        if len(removable_items) == 0:\n            break\n\n        # Remove item with lowest marginal gain ratio\n        removal_criteria = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmax(removal_criteria)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 4 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects top 30% solutions from the archive based on a weighted sum of normalized objectives (60% weight for value1, 40% for value2), then generates neighbors by flipping items with highest marginal gains (adjusted by current weight utilization) followed by dynamic random flips, ensuring feasibility through adaptive item removal based on marginal gain ratios. It prioritizes high-value items early while maintaining diversity through weighted selection and utilization-aware flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (0.6 * obj1_scores / max_obj1) + (0.4 * obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n    current_utilization = current_weight / capacity\n\n    # Calculate marginal gains with weight sensitivity\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = (1 - current_utilization) * marginal_gain1 + current_utilization * marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    # Flip items with highest combined gains\n    for idx in sorted_indices[:min(7, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips based on current utilization\n    num_flips = max(1, int(3 * (1 - current_utilization)))\n    for _ in range(num_flips):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Adaptive feasibility maintenance\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n\n        if len(removable_items) == 0:\n            break\n\n        # Remove item with lowest marginal gain ratio\n        removal_criteria = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(removal_criteria)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive (based on normalized objective sums) and generates neighbors by flipping items with high marginal gains for both objectives, followed by 1-2 random feasible flips, while ensuring feasibility through iterative refinement by removing the lightest items when needed. It prioritizes items with combined high marginal gains for both objectives while maintaining diversity through random flips.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain-based flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add 1-2 random feasible flips\n    for _ in range(np.random.randint(1, 3)):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP:\n\n### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 79,
        "algorithm": "The algorithm selects promising solutions from the archive (top 20% by normalized objective sums) and generates neighbors by prioritizing items with high marginal gains (adjusting for current weight utilization), adding 1-2 random feasible flips, and perturbing low-contribution items with 30% probability. It ensures feasibility through iterative refinement by removing least valuable items, repeating the process up to 5 times to refine solutions while balancing diversification and quality. Marginal gains are dynamically weighted based on current capacity utilization, with objective 1 prioritized when underutilized and objective 2 when near capacity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n    current_utilization = current_weight / capacity\n\n    # Marginal gain-based flips\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = (1 - current_utilization) * marginal_gain1 + current_utilization * marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add 1-2 random feasible flips\n    for _ in range(np.random.randint(1, 3)):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Adaptive perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        marginal_contribution = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        removal_criteria = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(removal_criteria)]\n        new_solution[remove_idx] = 0\n\n    # Repeat the process up to 5 times for refinement\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = current_weight\n\n        # Marginal gain-based flips\n        combined_gain = (1 - temp_weight / capacity) * marginal_gain1 + (temp_weight / capacity) * marginal_gain2\n        sorted_indices = np.argsort(combined_gain)[::-1]\n\n        for idx in sorted_indices[:min(3, n_items)]:\n            if temp_solution[idx] == 0 and temp_weight + weight_lst[idx] <= capacity:\n                temp_solution[idx] = 1\n                temp_weight += weight_lst[idx]\n            elif temp_solution[idx] == 1 and temp_weight - weight_lst[idx] <= capacity:\n                temp_solution[idx] = 0\n                temp_weight -= weight_lst[idx]\n\n        # Check if improved\n        if np.sum(temp_solution * weight_lst) <= capacity:\n            new_solution = temp_solution\n            current_weight = temp_weight\n\n    return new_solution\n\n",
        "score": [
            -0.48756641448386295,
            0.4683283269405365
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n    current_utilization = current_weight / capacity\n\n    # Marginal gain-based flips\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = (1 - current_utilization) * marginal_gain1 + current_utilization * marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add 1-2 random feasible flips\n    for _ in range(np.random.randint(1, 3)):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Adaptive perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        marginal_contribution = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        removal_criteria = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(removal_criteria)]\n        new_solution[remove_idx] = 0\n\n    # Repeat the process up to 5 times for refinement\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = current_weight\n\n        # Marginal gain-based flips\n        combined_gain = (1 - temp_weight / capacity) * marginal_gain1 + (temp_weight / capacity) * marginal_gain2\n        sorted_indices = np.argsort(combined_gain)[::-1]\n\n        for idx in sorted_indices[:min(3, n_items)]:\n            if temp_solution[idx] == 0 and temp_weight + weight_lst[idx] <= capacity:\n                temp_solution[idx] = 1\n                temp_weight += weight_lst[idx]\n            elif temp_solution[idx] == 1 and temp_weight - weight_lst[idx] <= capacity:\n                temp_solution[idx] = 0\n                temp_weight -= weight_lst[idx]\n\n        # Check if improved\n        if np.sum(temp_solution * weight_lst) <= capacity:\n            new_solution = temp_solution\n            current_weight = temp_weight\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 4 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 80,
        "algorithm": "The algorithm selects high-quality solutions from the archive (top 20% by normalized objective sums) and performs a hybrid local search by flipping high-marginal-gain items in either objective while occasionally adding random flips (with feasibility checks). It iteratively refines the solution to balance exploitation (targeted flips) and exploration (random perturbations). The method prioritizes items with high marginal gains in either objective while ensuring feasibility through controlled random flips and iterative refinement.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: add 1-2 random flips\n    if np.random.rand() < 0.4:\n        num_random_flips = np.random.randint(1, 3)\n        candidate_indices = np.random.choice(len(weight_lst), size=num_random_flips, replace=False)\n        for idx in candidate_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.49567831541776974,
            0.22831761837005615
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: add 1-2 random flips\n    if np.random.rand() < 0.4:\n        num_random_flips = np.random.randint(1, 3)\n        candidate_indices = np.random.choice(len(weight_lst), size=num_random_flips, replace=False)\n        for idx in candidate_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid of crowding distance and objective trade-off analysis, then applies a novel local search that alternates between targeted item swaps (prioritizing high-value items with trade-off considerations) and probabilistic flips (removing low-value items with dynamic probability), while ensuring feasibility through constrained capacity checks. The selection prioritizes solutions with high crowding distance (indicating potential for improvement) and adjusts perturbation probabilities based on the solution's position in the Pareto front and its objective trade-offs.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine objective dominance and adaptive crowding\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate normalized crowding distances\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate objective trade-offs\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    avg_trade_off = np.mean(trade_off)\n\n    # Alternating objective improvement with trade-off consideration\n    if np.random.rand() < 0.5 or trade_off[selected_idx] < avg_trade_off:\n        # Improve first objective with trade-off consideration\n        gain = (value1_lst + 0.3 * value2_lst) / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective with trade-off consideration\n        gain = (value2_lst + 0.3 * value1_lst) / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Targeted item swaps with feasibility check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position and trade-off\n    perturbation_prob = 0.3 if trade_off[selected_idx] < avg_trade_off else 0.6\n    if np.random.rand() < perturbation_prob:\n        # Select items with poor value-to-weight ratio for potential removal\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        poor_ratio_indices = np.argsort(value_ratio)[:min(5, len(weight_lst))]\n        for idx in poor_ratio_indices:\n            if np.random.rand() < 0.5 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 81,
        "algorithm": "The algorithm selects the top 20% of solutions from the archive based on a hybrid score combining normalized objectives (70% value1, 30% value2) and crowding distance. It then performs a two-phase local search: first flipping the top 5 items with highest combined marginal gains (weighted 60% for value1, 40% for value2), followed by probabilistically flipping 1-3 low-marginal-gain items (each with 30% chance) to maintain diversity, while always ensuring feasibility by enforcing capacity constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hybrid score (objective + crowding)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_obj[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_obj[sorted_idx[-1], m] != normalized_obj[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_obj[sorted_idx[i+1], m] - normalized_obj[sorted_idx[i-1], m]) / (normalized_obj[sorted_idx[-1], m] - normalized_obj[sorted_idx[0], m])\n    hybrid_score = 0.7 * normalized_obj[:, 0] + 0.3 * normalized_obj[:, 1] + 0.5 * crowding / (np.max(crowding) + 1e-10)\n    top_indices = np.argsort(-hybrid_score)[:max(1, len(archive)//5)]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Flip top 5 high-marginal-gain items\n    combined_gain = 0.6 * (value1_lst / weight_lst) + 0.4 * (value2_lst / weight_lst)\n    high_gain_indices = np.argsort(-combined_gain)[:5]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Probabilistic flip of low-marginal-gain items\n    low_gain_indices = np.argsort(combined_gain)[:min(10, len(weight_lst))]\n    for idx in np.random.permutation(low_gain_indices):\n        if np.random.rand() < 0.3:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8352162536368212,
            0.4825643301010132
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hybrid score (objective + crowding)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_obj[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_obj[sorted_idx[-1], m] != normalized_obj[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_obj[sorted_idx[i+1], m] - normalized_obj[sorted_idx[i-1], m]) / (normalized_obj[sorted_idx[-1], m] - normalized_obj[sorted_idx[0], m])\n    hybrid_score = 0.7 * normalized_obj[:, 0] + 0.3 * normalized_obj[:, 1] + 0.5 * crowding / (np.max(crowding) + 1e-10)\n    top_indices = np.argsort(-hybrid_score)[:max(1, len(archive)//5)]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Flip top 5 high-marginal-gain items\n    combined_gain = 0.6 * (value1_lst / weight_lst) + 0.4 * (value2_lst / weight_lst)\n    high_gain_indices = np.argsort(-combined_gain)[:5]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Probabilistic flip of low-marginal-gain items\n    low_gain_indices = np.argsort(combined_gain)[:min(10, len(weight_lst))]\n    for idx in np.random.permutation(low_gain_indices):\n        if np.random.rand() < 0.3:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects from the top 20% of non-dominated solutions (weighted equally on normalized objectives) and performs a local search by flipping high-gain items (60% prioritizing value1, 40% prioritizing value2) while occasionally perturbing low-gain items (30% probability) to balance exploration and exploitation, always ensuring feasibility.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by equally weighted normalized objectives\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.5 * obj[0]/max_obj1 + 0.5 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Local search: flip items with highest combined gain (60% value1, 40% value2)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.6 * marginal_gain1 + 0.4 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-gain items with 30% probability\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid of crowding distance and objective trade-off analysis, then applies a novel local search that alternates between targeted item swaps (prioritizing high-value items with trade-off considerations) and probabilistic flips (removing low-value items with dynamic probability), while ensuring feasibility through constrained capacity checks. The selection prioritizes solutions with high crowding distance (indicating potential for improvement) and adjusts perturbation probabilities based on the solution's position in the Pareto front and its objective trade-offs.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine objective dominance and adaptive crowding\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate normalized crowding distances\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate objective trade-offs\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    avg_trade_off = np.mean(trade_off)\n\n    # Alternating objective improvement with trade-off consideration\n    if np.random.rand() < 0.5 or trade_off[selected_idx] < avg_trade_off:\n        # Improve first objective with trade-off consideration\n        gain = (value1_lst + 0.3 * value2_lst) / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective with trade-off consideration\n        gain = (value2_lst + 0.3 * value1_lst) / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Targeted item swaps with feasibility check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position and trade-off\n    perturbation_prob = 0.3 if trade_off[selected_idx] < avg_trade_off else 0.6\n    if np.random.rand() < perturbation_prob:\n        # Select items with poor value-to-weight ratio for potential removal\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        poor_ratio_indices = np.argsort(value_ratio)[:min(5, len(weight_lst))]\n        for idx in poor_ratio_indices:\n            if np.random.rand() < 0.5 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 82,
        "algorithm": "The algorithm selects a promising solution from the archive by combining crowding distance and dominance, then applies a hybrid local search that first removes low-value items (below a dynamic threshold) and greedily adds high-value items (alternating between objectives), followed by controlled perturbations to refine the solution while maintaining feasibility. The selection prioritizes solutions with high crowding distance, and the local search balances exploration and exploitation through dynamic thresholding, greedy addition, and probabilistic perturbations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine objective dominance and crowding distance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate normalized crowding distances\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate dynamic threshold for low-value items\n    min_value1, min_value2 = np.min(value1_lst), np.min(value2_lst)\n    threshold = (min_value1 + min_value2) / 2\n\n    # Remove low-value items below threshold\n    for idx in range(len(weight_lst)):\n        if base_solution[idx] == 1 and (value1_lst[idx] < threshold or value2_lst[idx] < threshold):\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Add high-value items greedily, alternating objectives\n    for _ in range(2):  # Perform two passes for better coverage\n        if np.random.rand() < 0.5:\n            # Prioritize value1\n            gain = value1_lst / (weight_lst + 1e-10)\n        else:\n            # Prioritize value2\n            gain = value2_lst / (weight_lst + 1e-10)\n\n        sorted_indices = np.argsort(-gain)\n        for idx in sorted_indices:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                break  # Add one item per pass to control changes\n\n    # Controlled perturbation: flip 1-3 random items with decreasing probability\n    perturbation_prob = 0.4 if crowding[selected_idx] > np.mean(crowding) else 0.2\n    if np.random.rand() < perturbation_prob:\n        num_flips = np.random.randint(1, 4)\n        flip_indices = np.random.choice(len(weight_lst), size=num_flips, replace=False)\n        for idx in flip_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.6541565064432359,
            2.4649773836135864
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine objective dominance and crowding distance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate normalized crowding distances\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate dynamic threshold for low-value items\n    min_value1, min_value2 = np.min(value1_lst), np.min(value2_lst)\n    threshold = (min_value1 + min_value2) / 2\n\n    # Remove low-value items below threshold\n    for idx in range(len(weight_lst)):\n        if base_solution[idx] == 1 and (value1_lst[idx] < threshold or value2_lst[idx] < threshold):\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Add high-value items greedily, alternating objectives\n    for _ in range(2):  # Perform two passes for better coverage\n        if np.random.rand() < 0.5:\n            # Prioritize value1\n            gain = value1_lst / (weight_lst + 1e-10)\n        else:\n            # Prioritize value2\n            gain = value2_lst / (weight_lst + 1e-10)\n\n        sorted_indices = np.argsort(-gain)\n        for idx in sorted_indices:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                break  # Add one item per pass to control changes\n\n    # Controlled perturbation: flip 1-3 random items with decreasing probability\n    perturbation_prob = 0.4 if crowding[selected_idx] > np.mean(crowding) else 0.2\n    if np.random.rand() < perturbation_prob:\n        num_flips = np.random.randint(1, 4)\n        flip_indices = np.random.choice(len(weight_lst), size=num_flips, replace=False)\n        for idx in flip_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the archive using a hybrid of crowding distance and objective trade-off analysis, then applies a novel local search that alternates between targeted item swaps (prioritizing high-value items with trade-off considerations) and probabilistic flips (removing low-value items with dynamic probability), while ensuring feasibility through constrained capacity checks. The selection prioritizes solutions with high crowding distance (indicating potential for improvement) and adjusts perturbation probabilities based on the solution's position in the Pareto front and its objective trade-offs.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine objective dominance and adaptive crowding\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate normalized crowding distances\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate objective trade-offs\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    avg_trade_off = np.mean(trade_off)\n\n    # Alternating objective improvement with trade-off consideration\n    if np.random.rand() < 0.5 or trade_off[selected_idx] < avg_trade_off:\n        # Improve first objective with trade-off consideration\n        gain = (value1_lst + 0.3 * value2_lst) / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective with trade-off consideration\n        gain = (value2_lst + 0.3 * value1_lst) / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Targeted item swaps with feasibility check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position and trade-off\n    perturbation_prob = 0.3 if trade_off[selected_idx] < avg_trade_off else 0.6\n    if np.random.rand() < perturbation_prob:\n        # Select items with poor value-to-weight ratio for potential removal\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        poor_ratio_indices = np.argsort(value_ratio)[:min(5, len(weight_lst))]\n        for idx in poor_ratio_indices:\n            if np.random.rand() < 0.5 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 83,
        "algorithm": "The algorithm selects a solution from the archive using an adaptive weighted crowding distance metric that balances dominance rank and objective trade-offs, then applies a hybrid local search combining targeted item swaps (prioritizing high-value items with dynamic weights) and probabilistic flips (removing low-value items with solution-specific probabilities), while ensuring feasibility through capacity checks. The selection prioritizes solutions near the Pareto front (lower dominance rank) and those with high crowding distance, while the local search dynamically adjusts trade-off weights based on the solution's position in the objective space.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive weighted crowding selection\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate dominance ranks\n    dominance = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]) and \\\n                   (objectives[i, 0] > objectives[j, 0] or objectives[i, 1] > objectives[j, 1]):\n                    dominance[i] += 1\n\n    # Normalize objectives and calculate weighted crowding\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1 / (1 + dominance)\n    weighted_crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_obj[:, m])\n        weighted_crowding[sorted_idx[0]] = np.inf\n        weighted_crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_obj[sorted_idx[-1], m] != normalized_obj[sorted_idx[0], m]:\n                weighted_crowding[sorted_idx[i]] += weights[sorted_idx[i]] * (normalized_obj[sorted_idx[i+1], m] - normalized_obj[sorted_idx[i-1], m]) / (normalized_obj[sorted_idx[-1], m] - normalized_obj[sorted_idx[0], m])\n\n    # Select solution with highest weighted crowding\n    selected_idx = np.argmax(weighted_crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dynamic trade-off weights based on solution's position\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    avg_trade_off = np.mean(trade_off)\n    w1 = 0.7 if trade_off[selected_idx] < avg_trade_off else 0.3\n    w2 = 1 - w1\n\n    # Targeted item swaps with dynamic weights\n    gain = (w1 * value1_lst + w2 * value2_lst) / weight_lst\n    sorted_indices = np.argsort(-gain)\n\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Solution-specific perturbation\n    perturbation_prob = 0.4 - 0.2 * (objectives[selected_idx, 0] + objectives[selected_idx, 1]) / (np.max(objectives) + 1e-10)\n    if np.random.rand() < perturbation_prob:\n        value_ratio = (value1_lst + value2_lst) / (2 * weight_lst)\n        poor_ratio_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in poor_ratio_indices:\n            if np.random.rand() < 0.6 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8320493502157111,
            1.20793417096138
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive weighted crowding selection\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate dominance ranks\n    dominance = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]) and \\\n                   (objectives[i, 0] > objectives[j, 0] or objectives[i, 1] > objectives[j, 1]):\n                    dominance[i] += 1\n\n    # Normalize objectives and calculate weighted crowding\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1 / (1 + dominance)\n    weighted_crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_obj[:, m])\n        weighted_crowding[sorted_idx[0]] = np.inf\n        weighted_crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_obj[sorted_idx[-1], m] != normalized_obj[sorted_idx[0], m]:\n                weighted_crowding[sorted_idx[i]] += weights[sorted_idx[i]] * (normalized_obj[sorted_idx[i+1], m] - normalized_obj[sorted_idx[i-1], m]) / (normalized_obj[sorted_idx[-1], m] - normalized_obj[sorted_idx[0], m])\n\n    # Select solution with highest weighted crowding\n    selected_idx = np.argmax(weighted_crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dynamic trade-off weights based on solution's position\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    avg_trade_off = np.mean(trade_off)\n    w1 = 0.7 if trade_off[selected_idx] < avg_trade_off else 0.3\n    w2 = 1 - w1\n\n    # Targeted item swaps with dynamic weights\n    gain = (w1 * value1_lst + w2 * value2_lst) / weight_lst\n    sorted_indices = np.argsort(-gain)\n\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Solution-specific perturbation\n    perturbation_prob = 0.4 - 0.2 * (objectives[selected_idx, 0] + objectives[selected_idx, 1]) / (np.max(objectives) + 1e-10)\n    if np.random.rand() < perturbation_prob:\n        value_ratio = (value1_lst + value2_lst) / (2 * weight_lst)\n        poor_ratio_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in poor_ratio_indices:\n            if np.random.rand() < 0.6 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the archive using a hybrid of crowding distance and objective trade-off analysis, then applies a novel local search that alternates between targeted item swaps (prioritizing high-value items with trade-off considerations) and probabilistic flips (removing low-value items with dynamic probability), while ensuring feasibility through constrained capacity checks. The selection prioritizes solutions with high crowding distance (indicating potential for improvement) and adjusts perturbation probabilities based on the solution's position in the Pareto front and its objective trade-offs.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine objective dominance and adaptive crowding\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate normalized crowding distances\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate objective trade-offs\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    avg_trade_off = np.mean(trade_off)\n\n    # Alternating objective improvement with trade-off consideration\n    if np.random.rand() < 0.5 or trade_off[selected_idx] < avg_trade_off:\n        # Improve first objective with trade-off consideration\n        gain = (value1_lst + 0.3 * value2_lst) / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective with trade-off consideration\n        gain = (value2_lst + 0.3 * value1_lst) / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Targeted item swaps with feasibility check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position and trade-off\n    perturbation_prob = 0.3 if trade_off[selected_idx] < avg_trade_off else 0.6\n    if np.random.rand() < perturbation_prob:\n        # Select items with poor value-to-weight ratio for potential removal\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        poor_ratio_indices = np.argsort(value_ratio)[:min(5, len(weight_lst))]\n        for idx in poor_ratio_indices:\n            if np.random.rand() < 0.5 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 84,
        "algorithm": "The algorithm selects a solution from the archive by first clustering the objectives using k-means (with k=min(3, archive size)), then choosing the most dominant solution in the smallest cluster. It applies a hybrid local search that prioritizes either balanced improvements (high value correlation) or objective-specific gains (low correlation) via targeted item replacements, while dynamically perturbing solutions based on their centrality in the Pareto front to avoid local optima. Feasibility is maintained through adaptive capacity checks during all operations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Cluster-based selection (k-means on objectives)\n    from sklearn.cluster import KMeans\n    k = min(3, len(archive))\n    kmeans = KMeans(n_clusters=k, random_state=42).fit(objectives)\n    cluster_sizes = np.bincount(kmeans.labels_)\n    selected_cluster = np.argmin(cluster_sizes)\n    cluster_indices = np.where(kmeans.labels_ == selected_cluster)[0]\n\n    # Select solution with best dominance in its cluster\n    cluster_objectives = objectives[cluster_indices]\n    dominance_counts = np.zeros(len(cluster_indices))\n    for i in range(len(cluster_indices)):\n        for j in range(len(cluster_indices)):\n            if i != j:\n                if (cluster_objectives[i, 0] >= cluster_objectives[j, 0] and cluster_objectives[i, 1] > cluster_objectives[j, 1]) or \\\n                   (cluster_objectives[i, 0] > cluster_objectives[j, 0] and cluster_objectives[i, 1] >= cluster_objectives[j, 1]):\n                    dominance_counts[i] += 1\n    selected_idx = cluster_indices[np.argmax(dominance_counts)]\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate value correlation and centrality\n    value_correlation = np.corrcoef(value1_lst, value2_lst)[0, 1]\n    centroid = np.mean(objectives, axis=0)\n    distance_to_centroid = np.linalg.norm(objectives[selected_idx] - centroid)\n\n    # Targeted replacement based on value correlation and position\n    if value_correlation > 0.7:\n        # High correlation: prioritize balanced improvement\n        gain = (value1_lst + value2_lst) / weight_lst\n    else:\n        # Low correlation: prioritize objective with higher trade-off\n        trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n        if trade_off[selected_idx] > np.median(trade_off):\n            gain = value2_lst / weight_lst\n        else:\n            gain = value1_lst / weight_lst\n    sorted_indices = np.argsort(-gain)\n\n    # Perform replacements with feasibility check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on centrality\n    perturbation_prob = 0.4 if distance_to_centroid < np.median(np.linalg.norm(objectives - centroid, axis=1)) else 0.7\n    if np.random.rand() < perturbation_prob:\n        # Remove items with low utility for both objectives\n        utility = (value1_lst + value2_lst) / weight_lst\n        poor_utility_indices = np.argsort(utility)[:min(3, len(weight_lst))]\n        for idx in poor_utility_indices:\n            if np.random.rand() < 0.6 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.89766986884098,
            4.2130453288555145
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Cluster-based selection (k-means on objectives)\n    from sklearn.cluster import KMeans\n    k = min(3, len(archive))\n    kmeans = KMeans(n_clusters=k, random_state=42).fit(objectives)\n    cluster_sizes = np.bincount(kmeans.labels_)\n    selected_cluster = np.argmin(cluster_sizes)\n    cluster_indices = np.where(kmeans.labels_ == selected_cluster)[0]\n\n    # Select solution with best dominance in its cluster\n    cluster_objectives = objectives[cluster_indices]\n    dominance_counts = np.zeros(len(cluster_indices))\n    for i in range(len(cluster_indices)):\n        for j in range(len(cluster_indices)):\n            if i != j:\n                if (cluster_objectives[i, 0] >= cluster_objectives[j, 0] and cluster_objectives[i, 1] > cluster_objectives[j, 1]) or \\\n                   (cluster_objectives[i, 0] > cluster_objectives[j, 0] and cluster_objectives[i, 1] >= cluster_objectives[j, 1]):\n                    dominance_counts[i] += 1\n    selected_idx = cluster_indices[np.argmax(dominance_counts)]\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate value correlation and centrality\n    value_correlation = np.corrcoef(value1_lst, value2_lst)[0, 1]\n    centroid = np.mean(objectives, axis=0)\n    distance_to_centroid = np.linalg.norm(objectives[selected_idx] - centroid)\n\n    # Targeted replacement based on value correlation and position\n    if value_correlation > 0.7:\n        # High correlation: prioritize balanced improvement\n        gain = (value1_lst + value2_lst) / weight_lst\n    else:\n        # Low correlation: prioritize objective with higher trade-off\n        trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n        if trade_off[selected_idx] > np.median(trade_off):\n            gain = value2_lst / weight_lst\n        else:\n            gain = value1_lst / weight_lst\n    sorted_indices = np.argsort(-gain)\n\n    # Perform replacements with feasibility check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on centrality\n    perturbation_prob = 0.4 if distance_to_centroid < np.median(np.linalg.norm(objectives - centroid, axis=1)) else 0.7\n    if np.random.rand() < perturbation_prob:\n        # Remove items with low utility for both objectives\n        utility = (value1_lst + value2_lst) / weight_lst\n        poor_utility_indices = np.argsort(utility)[:min(3, len(weight_lst))]\n        for idx in poor_utility_indices:\n            if np.random.rand() < 0.6 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 4 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid of crowding distance and objective trade-off analysis, then applies a novel local search that alternates between targeted item swaps (prioritizing high-value items with trade-off considerations) and probabilistic flips (removing low-value items with dynamic probability), while ensuring feasibility through constrained capacity checks. The selection prioritizes solutions with high crowding distance (indicating potential for improvement) and adjusts perturbation probabilities based on the solution's position in the Pareto front and its objective trade-offs.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine objective dominance and adaptive crowding\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate normalized crowding distances\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate objective trade-offs\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    avg_trade_off = np.mean(trade_off)\n\n    # Alternating objective improvement with trade-off consideration\n    if np.random.rand() < 0.5 or trade_off[selected_idx] < avg_trade_off:\n        # Improve first objective with trade-off consideration\n        gain = (value1_lst + 0.3 * value2_lst) / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective with trade-off consideration\n        gain = (value2_lst + 0.3 * value1_lst) / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Targeted item swaps with feasibility check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position and trade-off\n    perturbation_prob = 0.3 if trade_off[selected_idx] < avg_trade_off else 0.6\n    if np.random.rand() < perturbation_prob:\n        # Select items with poor value-to-weight ratio for potential removal\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        poor_ratio_indices = np.argsort(value_ratio)[:min(5, len(weight_lst))]\n        for idx in poor_ratio_indices:\n            if np.random.rand() < 0.5 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 85,
        "algorithm": "The algorithm first selects promising solutions from the archive by prioritizing those with high normalized objective sums and crowding distances, then performs 3-5 rounds of local search that combines targeted flips of high-marginal-gain items with random flips of low-marginal-gain items, ensuring feasibility at each step. The key design ideas are balancing exploitation (focusing on high-gain items) and exploration (randomizing low-gain flips) while maintaining solution quality through iterative refinement.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate crowding distances for selection refinement\n    objectives = np.array([obj for _, obj in archive])\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Perform 3-5 rounds of local search\n    for _ in range(np.random.randint(3, 6)):\n        # Calculate combined marginal gains considering both objectives\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n        combined_gain = (marginal_gain1 + marginal_gain2) / 2\n\n        # Flip top 3 items with highest combined marginal gains\n        high_gain_indices = np.argsort(-combined_gain)[:min(3, len(weight_lst))]\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        # Add 1-2 random flips of low-marginal-contribution items\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for _ in range(np.random.randint(1, 3)):\n            idx = np.random.choice(low_gain_indices)\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7397502970219244,
            0.6040510535240173
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate crowding distances for selection refinement\n    objectives = np.array([obj for _, obj in archive])\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Perform 3-5 rounds of local search\n    for _ in range(np.random.randint(3, 6)):\n        # Calculate combined marginal gains considering both objectives\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n        combined_gain = (marginal_gain1 + marginal_gain2) / 2\n\n        # Flip top 3 items with highest combined marginal gains\n        high_gain_indices = np.argsort(-combined_gain)[:min(3, len(weight_lst))]\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        # Add 1-2 random flips of low-marginal-contribution items\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for _ in range(np.random.randint(1, 3)):\n            idx = np.random.choice(low_gain_indices)\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 4 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 86,
        "algorithm": "The algorithm selects top 20% solutions by normalized objective sums, then performs targeted flips of high-marginal-gain items for either objective, followed by random flips of low-marginal-gain items, ensuring feasibility through iterative refinement. High-marginal-gain items are prioritized for flips to maximize potential improvement, while low-marginal-gain items are flipped randomly (30% chance) to explore diverse neighbors, with infeasible solutions rejected after 5 attempts.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted flips: high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Random flips: low marginal gains\n    low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(2, len(weight_lst))]\n    for idx in low_gain_indices:\n        if np.random.rand() < 0.3:  # 30% chance for random flip\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.8182086208824446,
            0.22115978598594666
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted flips: high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Random flips: low marginal gains\n    low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(2, len(weight_lst))]\n    for idx in low_gain_indices:\n        if np.random.rand() < 0.3:  # 30% chance for random flip\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive using a dynamic weighted sum of objectives (prioritizing value1 at 70% and value2 at 30%), then applies a hybrid local search combining greedy flips for top marginal-gain items and probabilistic swaps, while maintaining feasibility through a multi-criteria removal strategy that balances value-weight ratios and weight penalties. The search adapts exploration/exploitation based on current solution utilization, favoring marginal gains in underutilized knapsacks and probabilistic swaps in overutilized ones.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions using dynamic weighted objective sum\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Dynamic weighting based on solution quality diversity\n        quality_diversity = np.std(obj1_scores) + np.std(obj2_scores)\n        weight1 = 0.7 - 0.1 * (quality_diversity / (max_obj1 + max_obj2 + 1e-10))\n        weight2 = 1 - weight1\n        normalized_scores = (weight1 * obj1_scores / max_obj1) + (weight2 * obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n    current_utilization = current_weight / capacity\n\n    # Hybrid local search with marginal gain and probabilistic swaps\n    # Calculate utilization-aware marginal gains\n    utilization_factor = 1 - (current_utilization ** 2)\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = (utilization_factor * marginal_gain1) + ((1 - utilization_factor) * marginal_gain2)\n\n    # Greedy flips for top 5 items\n    sorted_indices = np.argsort(combined_gain)[::-1]\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Probabilistic swaps based on marginal gains\n    swap_prob = 0.3 * (1 - current_utilization)\n    for idx in range(n_items):\n        if np.random.random() < swap_prob:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Multi-criteria feasibility maintenance\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n\n        if len(removable_items) == 0:\n            break\n\n        # Remove items with lowest value-weight ratio or highest weight\n        value_weight_ratio = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        weight_penalty = weight_lst[removable_items] / capacity\n        removal_score = value_weight_ratio - 2 * weight_penalty\n        remove_idx = removable_items[np.argmin(removal_score)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a solution from the archive using a hybrid metric combining dominance rank and entropy, then applies a novel local search that alternates between objective-specific greedy improvements (weighted by entropy) and entropy-driven perturbations (with adaptive probabilities based on solution entropy). It ensures feasibility through capacity checks and dynamic flips, prioritizing low-entropy items in perturbations to escape local optima.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine dominance and entropy\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate dominance ranks\n    dom_counts = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] > objectives[j, 1]) or \\\n                   (objectives[i, 0] > objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]):\n                    dom_counts[i] += 1\n\n    # Calculate entropy of solutions\n    entropy = np.zeros(len(archive))\n    for i in range(len(archive)):\n        prob = np.mean(solutions[i])\n        if prob == 0 or prob == 1:\n            entropy[i] = 0\n        else:\n            entropy[i] = -prob * np.log2(prob) - (1 - prob) * np.log2(1 - prob)\n\n    # Combine metrics for selection\n    selection_scores = entropy + (1 / (1 + dom_counts))\n    selected_idx = np.argmax(selection_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement with entropy consideration\n    if np.random.rand() < 0.5:\n        # Improve first objective with entropy consideration\n        gain = (value1_lst / weight_lst) * (1 + 0.5 * entropy[selected_idx])\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective with entropy consideration\n        gain = (value2_lst / weight_lst) * (1 + 0.5 * entropy[selected_idx])\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's entropy\n    if entropy[selected_idx] < np.median(entropy):\n        # More aggressive perturbation for low-entropy solutions\n        perturbation_prob = 0.6\n    else:\n        # More conservative perturbation for high-entropy solutions\n        perturbation_prob = 0.3\n\n    if np.random.rand() < perturbation_prob:\n        # Flip items with higher probability for those with low entropy\n        item_entropy = np.zeros(len(weight_lst))\n        for i in range(len(weight_lst)):\n            prob = np.mean([sol[i] for sol, _ in archive])\n            if prob == 0 or prob == 1:\n                item_entropy[i] = 0\n            else:\n                item_entropy[i] = -prob * np.log2(prob) - (1 - prob) * np.log2(1 - prob)\n\n        low_entropy_indices = np.argsort(item_entropy)[:min(5, len(weight_lst))]\n        for idx in low_entropy_indices:\n            if np.random.rand() < 0.5:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 87,
        "algorithm": "The algorithm selects top 20% solutions from the archive using a dynamic trade-off between objectives, then applies a two-phase local search: first, it performs objective-specific greedy flips based on marginal gains, followed by an entropy-driven perturbation phase to escape local optima while maintaining feasibility. The perturbation phase flips low-entropy items with probabilities proportional to their entropy, balancing exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions using dynamic objective trade-off\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Dynamic trade-off based on solution quality diversity\n        quality_diversity = np.std(obj1_scores) + np.std(obj2_scores)\n        weight1 = 0.7 - 0.1 * (quality_diversity / (max_obj1 + max_obj2 + 1e-10))\n        weight2 = 1 - weight1\n        normalized_scores = (weight1 * obj1_scores / max_obj1) + (weight2 * obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Objective-specific greedy flips\n    if np.random.rand() < 0.5:\n        # Focus on objective 1\n        marginal_gain = value1_lst / (weight_lst + 1e-10)\n    else:\n        # Focus on objective 2\n        marginal_gain = value2_lst / (weight_lst + 1e-10)\n\n    sorted_indices = np.argsort(-marginal_gain)\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Phase 2: Controlled perturbation based on entropy\n    # Calculate item entropy in the archive\n    archive_solutions = np.array([sol for sol, _ in archive])\n    item_prob = np.mean(archive_solutions, axis=0)\n    item_entropy = np.zeros(len(weight_lst))\n    for i in range(len(weight_lst)):\n        prob = item_prob[i]\n        if prob == 0 or prob == 1:\n            item_entropy[i] = 0\n        else:\n            item_entropy[i] = -prob * np.log2(prob) - (1 - prob) * np.log2(1 - prob)\n\n    # Flip low-entropy items with probability proportional to their entropy\n    low_entropy_indices = np.argsort(item_entropy)[:min(3, len(weight_lst))]\n    for idx in low_entropy_indices:\n        flip_prob = item_entropy[idx] / (np.max(item_entropy) + 1e-10)\n        if np.random.rand() < flip_prob:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove items with lowest value-weight ratio\n        value_weight_ratio = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(value_weight_ratio)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9147020802838755,
            1.2648839056491852
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions using dynamic objective trade-off\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Dynamic trade-off based on solution quality diversity\n        quality_diversity = np.std(obj1_scores) + np.std(obj2_scores)\n        weight1 = 0.7 - 0.1 * (quality_diversity / (max_obj1 + max_obj2 + 1e-10))\n        weight2 = 1 - weight1\n        normalized_scores = (weight1 * obj1_scores / max_obj1) + (weight2 * obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Objective-specific greedy flips\n    if np.random.rand() < 0.5:\n        # Focus on objective 1\n        marginal_gain = value1_lst / (weight_lst + 1e-10)\n    else:\n        # Focus on objective 2\n        marginal_gain = value2_lst / (weight_lst + 1e-10)\n\n    sorted_indices = np.argsort(-marginal_gain)\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Phase 2: Controlled perturbation based on entropy\n    # Calculate item entropy in the archive\n    archive_solutions = np.array([sol for sol, _ in archive])\n    item_prob = np.mean(archive_solutions, axis=0)\n    item_entropy = np.zeros(len(weight_lst))\n    for i in range(len(weight_lst)):\n        prob = item_prob[i]\n        if prob == 0 or prob == 1:\n            item_entropy[i] = 0\n        else:\n            item_entropy[i] = -prob * np.log2(prob) - (1 - prob) * np.log2(1 - prob)\n\n    # Flip low-entropy items with probability proportional to their entropy\n    low_entropy_indices = np.argsort(item_entropy)[:min(3, len(weight_lst))]\n    for idx in low_entropy_indices:\n        flip_prob = item_entropy[idx] / (np.max(item_entropy) + 1e-10)\n        if np.random.rand() < flip_prob:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove items with lowest value-weight ratio\n        value_weight_ratio = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(value_weight_ratio)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects top 20% solutions by normalized objective sums, then performs targeted flips of high-marginal-gain items for either objective, followed by random flips of low-marginal-gain items, ensuring feasibility through iterative refinement. High-marginal-gain items are prioritized for flips to maximize potential improvement, while low-marginal-gain items are flipped randomly (30% chance) to explore diverse neighbors, with infeasible solutions rejected after 5 attempts.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted flips: high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Random flips: low marginal gains\n    low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(2, len(weight_lst))]\n    for idx in low_gain_indices:\n        if np.random.rand() < 0.3:  # 30% chance for random flip\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a solution from the archive using a hybrid metric combining dominance rank and entropy, then applies a novel local search that alternates between objective-specific greedy improvements (weighted by entropy) and entropy-driven perturbations (with adaptive probabilities based on solution entropy). It ensures feasibility through capacity checks and dynamic flips, prioritizing low-entropy items in perturbations to escape local optima.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine dominance and entropy\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate dominance ranks\n    dom_counts = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] > objectives[j, 1]) or \\\n                   (objectives[i, 0] > objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]):\n                    dom_counts[i] += 1\n\n    # Calculate entropy of solutions\n    entropy = np.zeros(len(archive))\n    for i in range(len(archive)):\n        prob = np.mean(solutions[i])\n        if prob == 0 or prob == 1:\n            entropy[i] = 0\n        else:\n            entropy[i] = -prob * np.log2(prob) - (1 - prob) * np.log2(1 - prob)\n\n    # Combine metrics for selection\n    selection_scores = entropy + (1 / (1 + dom_counts))\n    selected_idx = np.argmax(selection_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement with entropy consideration\n    if np.random.rand() < 0.5:\n        # Improve first objective with entropy consideration\n        gain = (value1_lst / weight_lst) * (1 + 0.5 * entropy[selected_idx])\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective with entropy consideration\n        gain = (value2_lst / weight_lst) * (1 + 0.5 * entropy[selected_idx])\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's entropy\n    if entropy[selected_idx] < np.median(entropy):\n        # More aggressive perturbation for low-entropy solutions\n        perturbation_prob = 0.6\n    else:\n        # More conservative perturbation for high-entropy solutions\n        perturbation_prob = 0.3\n\n    if np.random.rand() < perturbation_prob:\n        # Flip items with higher probability for those with low entropy\n        item_entropy = np.zeros(len(weight_lst))\n        for i in range(len(weight_lst)):\n            prob = np.mean([sol[i] for sol, _ in archive])\n            if prob == 0 or prob == 1:\n                item_entropy[i] = 0\n            else:\n                item_entropy[i] = -prob * np.log2(prob) - (1 - prob) * np.log2(1 - prob)\n\n        low_entropy_indices = np.argsort(item_entropy)[:min(5, len(weight_lst))]\n        for idx in low_entropy_indices:\n            if np.random.rand() < 0.5:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 88,
        "algorithm": "The algorithm combines a hybrid selection mechanism that prioritizes high-potential solutions (top 25%) based on normalized objectives and entropy, followed by a two-phase local search: first, it performs targeted flips of items with the highest marginal gains in either objective, weighted by dominance, and second, it applies entropy-aware perturbations to low-entropy items with adaptive probabilities to escape local optima while ensuring feasibility through iterative refinement. The selection balances exploitation (focused flips) and exploration (perturbations), dynamically adjusting emphasis based on objective dominance and solution diversity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine normalized objectives and entropy\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Normalize objectives\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        normalized_scores = np.ones(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0]/max_obj1 + objectives[:, 1]/max_obj2)\n\n    # Calculate entropy of solutions\n    entropy = np.zeros(len(archive))\n    for i in range(len(archive)):\n        prob = np.mean(solutions[i])\n        if prob == 0 or prob == 1:\n            entropy[i] = 0\n        else:\n            entropy[i] = -prob * np.log2(prob) - (1 - prob) * np.log2(1 - prob)\n\n    # Combine metrics for selection (top 25%)\n    combined_scores = normalized_scores * (1 + 0.5 * entropy)\n    top_indices = np.argsort(-combined_scores)[:max(1, len(archive) // 4)]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Targeted flips based on marginal gains\n    # Calculate marginal gains weighted by dominance\n    obj1_dominance = np.sum(objectives[:, 0] >= objectives[selected_idx, 0])\n    obj2_dominance = np.sum(objectives[:, 1] >= objectives[selected_idx, 1])\n\n    if obj1_dominance > obj2_dominance:\n        # More emphasis on objective 1\n        marginal_gain = (value1_lst * (1.2 if obj1_dominance > obj2_dominance * 1.5 else 1.0)) / weight_lst\n    else:\n        # More emphasis on objective 2\n        marginal_gain = (value2_lst * (1.2 if obj2_dominance > obj1_dominance * 1.5 else 1.0)) / weight_lst\n\n    sorted_indices = np.argsort(-marginal_gain)\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Entropy-aware perturbation\n    # Calculate item entropies\n    item_entropy = np.zeros(len(weight_lst))\n    for i in range(len(weight_lst)):\n        prob = np.mean([sol[i] for sol, _ in archive])\n        if prob == 0 or prob == 1:\n            item_entropy[i] = 0\n        else:\n            item_entropy[i] = -prob * np.log2(prob) - (1 - prob) * np.log2(1 - prob)\n\n    # Adaptive perturbation probability based on solution entropy\n    perturbation_prob = 0.4 if entropy[selected_idx] < np.median(entropy) else 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Perturb low-entropy items first\n        low_entropy_indices = np.argsort(item_entropy)[:min(3, len(weight_lst))]\n        for idx in low_entropy_indices:\n            if np.random.rand() < 0.4:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Final feasibility check\n    temp_weight = np.sum(weight_lst * new_solution)\n    if temp_weight > capacity:\n        # If still infeasible, perform greedy repair\n        excess = temp_weight - capacity\n        sorted_weights = np.argsort(weight_lst * new_solution)\n        for idx in sorted_weights:\n            if new_solution[idx] == 1 and excess <= 0:\n                break\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8834126081970515,
            5.019087433815002
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine normalized objectives and entropy\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Normalize objectives\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        normalized_scores = np.ones(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0]/max_obj1 + objectives[:, 1]/max_obj2)\n\n    # Calculate entropy of solutions\n    entropy = np.zeros(len(archive))\n    for i in range(len(archive)):\n        prob = np.mean(solutions[i])\n        if prob == 0 or prob == 1:\n            entropy[i] = 0\n        else:\n            entropy[i] = -prob * np.log2(prob) - (1 - prob) * np.log2(1 - prob)\n\n    # Combine metrics for selection (top 25%)\n    combined_scores = normalized_scores * (1 + 0.5 * entropy)\n    top_indices = np.argsort(-combined_scores)[:max(1, len(archive) // 4)]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Targeted flips based on marginal gains\n    # Calculate marginal gains weighted by dominance\n    obj1_dominance = np.sum(objectives[:, 0] >= objectives[selected_idx, 0])\n    obj2_dominance = np.sum(objectives[:, 1] >= objectives[selected_idx, 1])\n\n    if obj1_dominance > obj2_dominance:\n        # More emphasis on objective 1\n        marginal_gain = (value1_lst * (1.2 if obj1_dominance > obj2_dominance * 1.5 else 1.0)) / weight_lst\n    else:\n        # More emphasis on objective 2\n        marginal_gain = (value2_lst * (1.2 if obj2_dominance > obj1_dominance * 1.5 else 1.0)) / weight_lst\n\n    sorted_indices = np.argsort(-marginal_gain)\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Entropy-aware perturbation\n    # Calculate item entropies\n    item_entropy = np.zeros(len(weight_lst))\n    for i in range(len(weight_lst)):\n        prob = np.mean([sol[i] for sol, _ in archive])\n        if prob == 0 or prob == 1:\n            item_entropy[i] = 0\n        else:\n            item_entropy[i] = -prob * np.log2(prob) - (1 - prob) * np.log2(1 - prob)\n\n    # Adaptive perturbation probability based on solution entropy\n    perturbation_prob = 0.4 if entropy[selected_idx] < np.median(entropy) else 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Perturb low-entropy items first\n        low_entropy_indices = np.argsort(item_entropy)[:min(3, len(weight_lst))]\n        for idx in low_entropy_indices:\n            if np.random.rand() < 0.4:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Final feasibility check\n    temp_weight = np.sum(weight_lst * new_solution)\n    if temp_weight > capacity:\n        # If still infeasible, perform greedy repair\n        excess = temp_weight - capacity\n        sorted_weights = np.argsort(weight_lst * new_solution)\n        for idx in sorted_weights:\n            if new_solution[idx] == 1 and excess <= 0:\n                break\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a solution from the archive using a hybrid metric combining dominance rank and entropy, then applies a novel local search that alternates between objective-specific greedy improvements (weighted by entropy) and entropy-driven perturbations (with adaptive probabilities based on solution entropy). It ensures feasibility through capacity checks and dynamic flips, prioritizing low-entropy items in perturbations to escape local optima.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine dominance and entropy\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate dominance ranks\n    dom_counts = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] > objectives[j, 1]) or \\\n                   (objectives[i, 0] > objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]):\n                    dom_counts[i] += 1\n\n    # Calculate entropy of solutions\n    entropy = np.zeros(len(archive))\n    for i in range(len(archive)):\n        prob = np.mean(solutions[i])\n        if prob == 0 or prob == 1:\n            entropy[i] = 0\n        else:\n            entropy[i] = -prob * np.log2(prob) - (1 - prob) * np.log2(1 - prob)\n\n    # Combine metrics for selection\n    selection_scores = entropy + (1 / (1 + dom_counts))\n    selected_idx = np.argmax(selection_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement with entropy consideration\n    if np.random.rand() < 0.5:\n        # Improve first objective with entropy consideration\n        gain = (value1_lst / weight_lst) * (1 + 0.5 * entropy[selected_idx])\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective with entropy consideration\n        gain = (value2_lst / weight_lst) * (1 + 0.5 * entropy[selected_idx])\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's entropy\n    if entropy[selected_idx] < np.median(entropy):\n        # More aggressive perturbation for low-entropy solutions\n        perturbation_prob = 0.6\n    else:\n        # More conservative perturbation for high-entropy solutions\n        perturbation_prob = 0.3\n\n    if np.random.rand() < perturbation_prob:\n        # Flip items with higher probability for those with low entropy\n        item_entropy = np.zeros(len(weight_lst))\n        for i in range(len(weight_lst)):\n            prob = np.mean([sol[i] for sol, _ in archive])\n            if prob == 0 or prob == 1:\n                item_entropy[i] = 0\n            else:\n                item_entropy[i] = -prob * np.log2(prob) - (1 - prob) * np.log2(1 - prob)\n\n        low_entropy_indices = np.argsort(item_entropy)[:min(5, len(weight_lst))]\n        for idx in low_entropy_indices:\n            if np.random.rand() < 0.5:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 89,
        "algorithm": "The algorithm selects a solution from the archive using crowding-distance-based selection to prioritize diverse solutions, then applies a hybrid local search that combines objective-driven greedy improvements (weighted by item entropy) with entropy-aware perturbations to generate a feasible neighbor solution while balancing exploration and exploitation. The entropy weighting ensures perturbations focus on items with high uncertainty, while the greedy flips prioritize high-value, low-weight items.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate crowding distances for selection\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.zeros(len(archive))\n\n    # Normalize objectives\n    min_obj = np.min(objectives, axis=0)\n    max_obj = np.max(objectives, axis=0)\n    normalized_obj = (objectives - min_obj) / (max_obj - min_obj + 1e-8)\n\n    # Sort by each objective and calculate crowding distance\n    for i in range(2):\n        sorted_indices = np.argsort(normalized_obj[:, i])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(sorted_indices)-1):\n            crowding_distances[sorted_indices[j]] += (normalized_obj[sorted_indices[j+1], i] - normalized_obj[sorted_indices[j-1], i])\n\n    # Select solution with highest crowding distance (most diverse)\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate item entropies\n    item_entropies = np.zeros(len(weight_lst))\n    for i in range(len(weight_lst)):\n        prob = np.mean([sol[i] for sol, _ in archive])\n        if prob == 0 or prob == 1:\n            item_entropies[i] = 0\n        else:\n            item_entropies[i] = -prob * np.log2(prob) - (1 - prob) * np.log2(1 - prob)\n\n    # Objective-driven improvement with entropy weighting\n    if np.random.rand() < 0.5:\n        # Improve first objective with entropy weighting\n        gain = (value1_lst / (weight_lst + 1e-8)) * (1 + 0.3 * (1 - item_entropies))\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective with entropy weighting\n        gain = (value2_lst / (weight_lst + 1e-8)) * (1 + 0.3 * (1 - item_entropies))\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Entropy-aware perturbation\n    perturbation_strength = 0.4 + 0.2 * (1 - item_entropies)\n    for i in range(len(weight_lst)):\n        if np.random.rand() < perturbation_strength[i]:\n            if base_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n            elif base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.8063964205314256,
            5.326396733522415
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate crowding distances for selection\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.zeros(len(archive))\n\n    # Normalize objectives\n    min_obj = np.min(objectives, axis=0)\n    max_obj = np.max(objectives, axis=0)\n    normalized_obj = (objectives - min_obj) / (max_obj - min_obj + 1e-8)\n\n    # Sort by each objective and calculate crowding distance\n    for i in range(2):\n        sorted_indices = np.argsort(normalized_obj[:, i])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(sorted_indices)-1):\n            crowding_distances[sorted_indices[j]] += (normalized_obj[sorted_indices[j+1], i] - normalized_obj[sorted_indices[j-1], i])\n\n    # Select solution with highest crowding distance (most diverse)\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate item entropies\n    item_entropies = np.zeros(len(weight_lst))\n    for i in range(len(weight_lst)):\n        prob = np.mean([sol[i] for sol, _ in archive])\n        if prob == 0 or prob == 1:\n            item_entropies[i] = 0\n        else:\n            item_entropies[i] = -prob * np.log2(prob) - (1 - prob) * np.log2(1 - prob)\n\n    # Objective-driven improvement with entropy weighting\n    if np.random.rand() < 0.5:\n        # Improve first objective with entropy weighting\n        gain = (value1_lst / (weight_lst + 1e-8)) * (1 + 0.3 * (1 - item_entropies))\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective with entropy weighting\n        gain = (value2_lst / (weight_lst + 1e-8)) * (1 + 0.3 * (1 - item_entropies))\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Entropy-aware perturbation\n    perturbation_strength = 0.4 + 0.2 * (1 - item_entropies)\n    for i in range(len(weight_lst)):\n        if np.random.rand() < perturbation_strength[i]:\n            if base_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n            elif base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a solution from the archive using a hybrid metric combining dominance rank and entropy, then applies a novel local search that alternates between objective-specific greedy improvements (weighted by entropy) and entropy-driven perturbations (with adaptive probabilities based on solution entropy). It ensures feasibility through capacity checks and dynamic flips, prioritizing low-entropy items in perturbations to escape local optima.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine dominance and entropy\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate dominance ranks\n    dom_counts = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] > objectives[j, 1]) or \\\n                   (objectives[i, 0] > objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]):\n                    dom_counts[i] += 1\n\n    # Calculate entropy of solutions\n    entropy = np.zeros(len(archive))\n    for i in range(len(archive)):\n        prob = np.mean(solutions[i])\n        if prob == 0 or prob == 1:\n            entropy[i] = 0\n        else:\n            entropy[i] = -prob * np.log2(prob) - (1 - prob) * np.log2(1 - prob)\n\n    # Combine metrics for selection\n    selection_scores = entropy + (1 / (1 + dom_counts))\n    selected_idx = np.argmax(selection_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement with entropy consideration\n    if np.random.rand() < 0.5:\n        # Improve first objective with entropy consideration\n        gain = (value1_lst / weight_lst) * (1 + 0.5 * entropy[selected_idx])\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective with entropy consideration\n        gain = (value2_lst / weight_lst) * (1 + 0.5 * entropy[selected_idx])\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's entropy\n    if entropy[selected_idx] < np.median(entropy):\n        # More aggressive perturbation for low-entropy solutions\n        perturbation_prob = 0.6\n    else:\n        # More conservative perturbation for high-entropy solutions\n        perturbation_prob = 0.3\n\n    if np.random.rand() < perturbation_prob:\n        # Flip items with higher probability for those with low entropy\n        item_entropy = np.zeros(len(weight_lst))\n        for i in range(len(weight_lst)):\n            prob = np.mean([sol[i] for sol, _ in archive])\n            if prob == 0 or prob == 1:\n                item_entropy[i] = 0\n            else:\n                item_entropy[i] = -prob * np.log2(prob) - (1 - prob) * np.log2(1 - prob)\n\n        low_entropy_indices = np.argsort(item_entropy)[:min(5, len(weight_lst))]\n        for idx in low_entropy_indices:\n            if np.random.rand() < 0.5:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 90,
        "algorithm": "This algorithm selects promising solutions from the archive using a hybrid metric combining dominance rank and diversity, then applies a two-phase local search: first improving one objective while considering diversity, followed by adaptive perturbations. It prioritizes items with higher value-to-weight ratios and adjusts perturbation intensity based on solution diversity, ensuring feasibility with dynamic capacity checks. The selection emphasizes solutions with balanced dominance and diversity, while the local search alternates between objective improvement and diversity-driven exploration.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine dominance and diversity\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate dominance ranks\n    dom_counts = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] > objectives[j, 1]) or \\\n                   (objectives[i, 0] > objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]):\n                    dom_counts[i] += 1\n\n    # Calculate solution diversity\n    diversity = np.zeros(len(archive))\n    for i in range(len(archive)):\n        diversity[i] = np.mean([np.sum(np.abs(solutions[i] - sol)) for sol in solutions if not np.array_equal(solutions[i], sol)])\n\n    # Combine metrics for selection\n    selection_scores = diversity + (1 / (1 + dom_counts))\n    selected_idx = np.argmax(selection_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement with diversity consideration\n    if np.random.rand() < 0.6:\n        # Improve first objective with diversity consideration\n        gain = (value1_lst / weight_lst) * (1 + 0.3 * diversity[selected_idx])\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective with diversity consideration\n        gain = (value2_lst / weight_lst) * (1 + 0.3 * diversity[selected_idx])\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's diversity\n    if diversity[selected_idx] < np.median(diversity):\n        # More aggressive perturbation for low-diversity solutions\n        perturbation_prob = 0.7\n    else:\n        # More conservative perturbation for high-diversity solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip items with higher probability for those with high diversity\n        item_diversity = np.zeros(len(weight_lst))\n        for i in range(len(weight_lst)):\n            item_diversity[i] = np.mean([sol[i] for sol, _ in archive])\n\n        high_diversity_indices = np.argsort(-item_diversity)[:min(5, len(weight_lst))]\n        for idx in high_diversity_indices:\n            if np.random.rand() < 0.6:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8470635634435694,
            7.176049143075943
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine dominance and diversity\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate dominance ranks\n    dom_counts = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] > objectives[j, 1]) or \\\n                   (objectives[i, 0] > objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]):\n                    dom_counts[i] += 1\n\n    # Calculate solution diversity\n    diversity = np.zeros(len(archive))\n    for i in range(len(archive)):\n        diversity[i] = np.mean([np.sum(np.abs(solutions[i] - sol)) for sol in solutions if not np.array_equal(solutions[i], sol)])\n\n    # Combine metrics for selection\n    selection_scores = diversity + (1 / (1 + dom_counts))\n    selected_idx = np.argmax(selection_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement with diversity consideration\n    if np.random.rand() < 0.6:\n        # Improve first objective with diversity consideration\n        gain = (value1_lst / weight_lst) * (1 + 0.3 * diversity[selected_idx])\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective with diversity consideration\n        gain = (value2_lst / weight_lst) * (1 + 0.3 * diversity[selected_idx])\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's diversity\n    if diversity[selected_idx] < np.median(diversity):\n        # More aggressive perturbation for low-diversity solutions\n        perturbation_prob = 0.7\n    else:\n        # More conservative perturbation for high-diversity solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip items with higher probability for those with high diversity\n        item_diversity = np.zeros(len(weight_lst))\n        for i in range(len(weight_lst)):\n            item_diversity[i] = np.mean([sol[i] for sol, _ in archive])\n\n        high_diversity_indices = np.argsort(-item_diversity)[:min(5, len(weight_lst))]\n        for idx in high_diversity_indices:\n            if np.random.rand() < 0.6:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 4 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive using a hybrid metric combining dominance rank and entropy, then applies a novel local search that alternates between objective-specific greedy improvements (weighted by entropy) and entropy-driven perturbations (with adaptive probabilities based on solution entropy). It ensures feasibility through capacity checks and dynamic flips, prioritizing low-entropy items in perturbations to escape local optima.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine dominance and entropy\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate dominance ranks\n    dom_counts = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] > objectives[j, 1]) or \\\n                   (objectives[i, 0] > objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]):\n                    dom_counts[i] += 1\n\n    # Calculate entropy of solutions\n    entropy = np.zeros(len(archive))\n    for i in range(len(archive)):\n        prob = np.mean(solutions[i])\n        if prob == 0 or prob == 1:\n            entropy[i] = 0\n        else:\n            entropy[i] = -prob * np.log2(prob) - (1 - prob) * np.log2(1 - prob)\n\n    # Combine metrics for selection\n    selection_scores = entropy + (1 / (1 + dom_counts))\n    selected_idx = np.argmax(selection_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement with entropy consideration\n    if np.random.rand() < 0.5:\n        # Improve first objective with entropy consideration\n        gain = (value1_lst / weight_lst) * (1 + 0.5 * entropy[selected_idx])\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective with entropy consideration\n        gain = (value2_lst / weight_lst) * (1 + 0.5 * entropy[selected_idx])\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's entropy\n    if entropy[selected_idx] < np.median(entropy):\n        # More aggressive perturbation for low-entropy solutions\n        perturbation_prob = 0.6\n    else:\n        # More conservative perturbation for high-entropy solutions\n        perturbation_prob = 0.3\n\n    if np.random.rand() < perturbation_prob:\n        # Flip items with higher probability for those with low entropy\n        item_entropy = np.zeros(len(weight_lst))\n        for i in range(len(weight_lst)):\n            prob = np.mean([sol[i] for sol, _ in archive])\n            if prob == 0 or prob == 1:\n                item_entropy[i] = 0\n            else:\n                item_entropy[i] = -prob * np.log2(prob) - (1 - prob) * np.log2(1 - prob)\n\n        low_entropy_indices = np.argsort(item_entropy)[:min(5, len(weight_lst))]\n        for idx in low_entropy_indices:\n            if np.random.rand() < 0.5:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Keywords**:\n- **Multi-objective marginal gain**, **adaptive perturbation**, **feasibility-aware flipping**, **diversity-aware selection**.\n\n### **Advice**:\n1. **Select** top 20% solutions by normalized objective sums.\n2. **Flip** items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility).\n3. **Reject** infeasible neighbors; repeat until valid.\n4. **Iterate** 5-10 times per solution to refine the archive.\n\n### **Avoid**:\n- **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Ignoring feasibility checks** after perturbations.\n\n### **Explanation**:\nBalancing **targeted exploitation** (marginal gains) and **controlled exploration** (random flips) ensures progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 91,
        "algorithm": "The algorithm selects a promising solution from the top 20% of the archive (based on normalized objective sums) and applies a hybrid local search that prioritizes flipping high-marginal-gain items (based on value-to-weight ratios) while occasionally perturbing low-contribution items to balance exploration and exploitation. It ensures feasibility by strictly checking capacity constraints and refines the solution iteratively (5-10 times) to improve both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: alternate between high-marginal-gain flips and random perturbations\n    for _ in range(5):  # Iterative refinement\n        # Flip high-marginal-gain items\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n        high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Random perturbation: flip low-marginal-contribution items\n        if np.random.rand() < 0.3:\n            marginal_contribution = (value1_lst + value2_lst) / weight_lst\n            low_contrib_indices = np.argsort(marginal_contribution)[:max(1, len(weight_lst) // 4)]\n            for idx in low_contrib_indices:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.551761936838046,
            0.3561323583126068
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: alternate between high-marginal-gain flips and random perturbations\n    for _ in range(5):  # Iterative refinement\n        # Flip high-marginal-gain items\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n        high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Random perturbation: flip low-marginal-contribution items\n        if np.random.rand() < 0.3:\n            marginal_contribution = (value1_lst + value2_lst) / weight_lst\n            low_contrib_indices = np.argsort(marginal_contribution)[:max(1, len(weight_lst) // 4)]\n            for idx in low_contrib_indices:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 4 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: - **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 92,
        "algorithm": "The algorithm selects promising solutions from the archive based on normalized objective sums, then applies a hybrid local search that prioritizes flipping high-marginal-gain items while ensuring feasibility, followed by random flips and iterative refinement. It balances exploration (random flips) with exploitation (targeted high-gain items) to generate high-quality neighbors.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Flip items with highest marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips while maintaining feasibility\n    num_random_flips = np.random.randint(1, 3)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n\n    # Iterate 5-10 times to refine the solution\n    for _ in range(np.random.randint(5, 11)):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.7218168730529766,
            0.2304130494594574
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Flip items with highest marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips while maintaining feasibility\n    num_random_flips = np.random.randint(1, 3)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n\n    # Iterate 5-10 times to refine the solution\n    for _ in range(np.random.randint(5, 11)):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 5 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\nThe algorithm selects a random solution from the archive and performs a hybrid local search by swapping items with a focus on improving either objective while ensuring feasibility. It prioritizes swaps that increase at least one objective value and maintains the solution's weight within capacity. The method uses a value-to-weight ratio consideration to guide the swaps and limits the search to 10 attempts for efficiency.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: random swaps with value-to-weight ratio consideration\n    for _ in range(10):  # Number of attempts to find a feasible neighbor\n        # Select two random items\n        item1, item2 = np.random.choice(len(new_solution), size=2, replace=False)\n\n        # Calculate potential weight change\n        if new_solution[item1] == 1 and new_solution[item2] == 0:\n            delta_weight = weight_lst[item2] - weight_lst[item1]\n        elif new_solution[item1] == 0 and new_solution[item2] == 1:\n            delta_weight = weight_lst[item1] - weight_lst[item2]\n        else:\n            continue  # No change in weight\n\n        # Check feasibility\n        if current_weight + delta_weight <= capacity:\n            # Perform swap if it improves at least one objective\n            value1_delta = (value1_lst[item1] - value1_lst[item2]) if new_solution[item1] == 1 else (value1_lst[item2] - value1_lst[item1])\n            value2_delta = (value2_lst[item1] - value2_lst[item2]) if new_solution[item1] == 1 else (value2_lst[item2] - value2_lst[item1])\n\n            if value1_delta > 0 or value2_delta > 0:\n                new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n                current_weight += delta_weight\n                break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\nNo. 3 algorithm and the corresponding code are:\nThe algorithm selects a random solution from the archive and applies a hybrid local search strategy that prioritizes items with high marginal value (combined from both objectives) while ensuring feasibility, followed by random flips to explore diversity. It balances exploitation (targeting high-value items) with exploration (random perturbations) to generate improved neighbor solutions. The approach avoids standard local search methods like 2-opt by focusing on value-weighted flips and controlled randomness.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: Flip items based on marginal contribution and diversity\n    new_solution = base_solution.copy()\n\n    # Step 1: Identify items with high marginal contribution (value/weight ratio)\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Step 2: Flip items with high marginal contribution if feasible\n    for i in np.argsort(-combined_marginal):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Step 3: Randomly flip additional items to explore diversity\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    return new_solution\n\nNo. 4 algorithm and the corresponding code are:\nThe algorithm intelligently selects a non-dominated solution from the archive by prioritizing those with high marginal gains, then applies a hybrid local search combining probabilistic item flips and swaps to explore the solution space while ensuring feasibility. The selection is weighted probabilistically, favoring later entries in the archive, and the local search iteratively modifies the solution by flipping or swapping items, checking feasibility at each step. The key design ideas are prioritized selection and hybrid local search with feasibility checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution (prioritize those with high marginal gains)\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution, (base_value1, base_value2) = archive[selected_idx]\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Hybrid local search: probabilistic item flips and swaps\n    for _ in range(5):  # Number of local search iterations\n        # Probabilistic flip: flip a random item if feasible\n        flip_idx = np.random.randint(0, n_items)\n        if new_solution[flip_idx] == 1:\n            if np.sum(weight_lst[new_solution == 1] - weight_lst[flip_idx]) <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if np.sum(weight_lst[new_solution == 1] + weight_lst[flip_idx]) <= capacity:\n                new_solution[flip_idx] = 1\n\n        # Item swap: swap two random items if feasible\n        swap_idx1, swap_idx2 = np.random.choice(n_items, 2, replace=False)\n        if new_solution[swap_idx1] != new_solution[swap_idx2]:\n            if new_solution[swap_idx1] == 1:\n                if np.sum(weight_lst[new_solution == 1] - weight_lst[swap_idx1] + weight_lst[swap_idx2]) <= capacity:\n                    new_solution[swap_idx1] = 0\n                    new_solution[swap_idx2] = 1\n            else:\n                if np.sum(weight_lst[new_solution == 1] - weight_lst[swap_idx2] + weight_lst[swap_idx1]) <= capacity:\n                    new_solution[swap_idx1] = 1\n                    new_solution[swap_idx2] = 0\n\n    return new_solution\n\nNo. 5 algorithm and the corresponding code are:\nThe algorithm selects a random solution from the archive, applies a hybrid local search by flipping a small random subset of items (with feasibility checks), and then performs a greedy improvement step to add items that improve at least one objective. The design prioritizes diversity and local optimization while ensuring feasibility, using a combination of randomness and greedy selection to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    import random\n    import numpy as np\n\n    # Select a promising solution from the archive (here, we select a random one for diversity)\n    selected_solution, _ = random.choice(archive)\n    new_solution = selected_solution.copy()\n\n    # Apply a hybrid local search: flip a random subset of items and then perform a greedy improvement\n    num_items = len(new_solution)\n    flip_indices = random.sample(range(num_items), min(3, num_items))  # Flip up to 3 random items\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            # Only flip to 1 if it doesn't exceed capacity\n            current_weight = np.sum(new_solution * weight_lst)\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Greedy improvement: try to add items that improve at least one objective\n    for idx in range(num_items):\n        if new_solution[idx] == 0:\n            current_weight = np.sum(new_solution * weight_lst)\n            if current_weight + weight_lst[idx] <= capacity:\n                # Simulate adding the item\n                temp_solution = new_solution.copy()\n                temp_solution[idx] = 1\n                temp_value1 = np.sum(temp_solution * value1_lst)\n                temp_value2 = np.sum(temp_solution * value2_lst)\n                current_value1 = np.sum(new_solution * value1_lst)\n                current_value2 = np.sum(new_solution * value2_lst)\n\n                # Accept if at least one objective improves\n                if (temp_value1 > current_value1) or (temp_value2 > current_value2):\n                    new_solution[idx] = 1\n\n    return new_solution\n\n\n\nAnalyze the logic of all the given code snippets carefully. Then identify the two code snippets whose logic is most different from each other\nand create a new algorithm that totally different in logic and form from both of them.\n1. First, describe your new algorithm and main steps in one long, detail sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 93,
        "algorithm": "The algorithm selects a promising solution from the archive by weighting choices based on normalized objective values, then applies a hybrid local search that clusters items by value-to-weight ratios and correlation with the current solution's objectives, performing targeted flips and swaps within clusters while occasionally perturbing the solution to escape local optima. The selection prioritizes high-performing solutions, and the local search intelligently explores the neighborhood by focusing on cluster-specific improvements, ensuring feasibility and diversity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive (weighted by normalized objectives)\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.random.choice(len(archive), p=np.array(normalized_scores)/sum(normalized_scores))\n\n    base_solution, (base_obj1, base_obj2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Cluster items based on value-to-weight ratios and correlation with objectives\n    value_ratio1 = value1_lst / (weight_lst + 1e-10)\n    value_ratio2 = value2_lst / (weight_lst + 1e-10)\n    correlation = (value_ratio1 * base_obj1 + value_ratio2 * base_obj2) / (np.sqrt(value_ratio1**2 + value_ratio2**2) + 1e-10)\n\n    # Sort items by correlation and value ratios\n    sorted_indices = np.argsort(-correlation)\n    clusters = [sorted_indices[i:i+5] for i in range(0, len(sorted_indices), 5)]  # Create clusters of 5 items\n\n    # Hybrid local search: cluster-based flips and swaps\n    for cluster in clusters:\n        # Probabilistic flip within cluster\n        if np.random.rand() < 0.5:\n            flip_idx = np.random.choice(cluster)\n            if base_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n        # Probabilistic swap within cluster\n        if np.random.rand() < 0.3 and len(cluster) > 1:\n            swap_idx1, swap_idx2 = np.random.choice(cluster, 2, replace=False)\n            if new_solution[swap_idx1] != new_solution[swap_idx2]:\n                if new_solution[swap_idx1] == 1:\n                    if current_weight - weight_lst[swap_idx1] + weight_lst[swap_idx2] <= capacity:\n                        new_solution[swap_idx1] = 0\n                        new_solution[swap_idx2] = 1\n                else:\n                    if current_weight - weight_lst[swap_idx2] + weight_lst[swap_idx1] <= capacity:\n                        new_solution[swap_idx1] = 1\n                        new_solution[swap_idx2] = 0\n\n    # Occasional perturbation to escape local optima\n    if np.random.rand() < 0.2:\n        perturb_idx = np.random.randint(len(new_solution))\n        if new_solution[perturb_idx] == 1:\n            if current_weight - weight_lst[perturb_idx] <= capacity:\n                new_solution[perturb_idx] = 0\n        else:\n            if current_weight + weight_lst[perturb_idx] <= capacity:\n                new_solution[perturb_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.3356073887165535,
            0.8533963263034821
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive (weighted by normalized objectives)\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.random.choice(len(archive), p=np.array(normalized_scores)/sum(normalized_scores))\n\n    base_solution, (base_obj1, base_obj2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Cluster items based on value-to-weight ratios and correlation with objectives\n    value_ratio1 = value1_lst / (weight_lst + 1e-10)\n    value_ratio2 = value2_lst / (weight_lst + 1e-10)\n    correlation = (value_ratio1 * base_obj1 + value_ratio2 * base_obj2) / (np.sqrt(value_ratio1**2 + value_ratio2**2) + 1e-10)\n\n    # Sort items by correlation and value ratios\n    sorted_indices = np.argsort(-correlation)\n    clusters = [sorted_indices[i:i+5] for i in range(0, len(sorted_indices), 5)]  # Create clusters of 5 items\n\n    # Hybrid local search: cluster-based flips and swaps\n    for cluster in clusters:\n        # Probabilistic flip within cluster\n        if np.random.rand() < 0.5:\n            flip_idx = np.random.choice(cluster)\n            if base_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n        # Probabilistic swap within cluster\n        if np.random.rand() < 0.3 and len(cluster) > 1:\n            swap_idx1, swap_idx2 = np.random.choice(cluster, 2, replace=False)\n            if new_solution[swap_idx1] != new_solution[swap_idx2]:\n                if new_solution[swap_idx1] == 1:\n                    if current_weight - weight_lst[swap_idx1] + weight_lst[swap_idx2] <= capacity:\n                        new_solution[swap_idx1] = 0\n                        new_solution[swap_idx2] = 1\n                else:\n                    if current_weight - weight_lst[swap_idx2] + weight_lst[swap_idx1] <= capacity:\n                        new_solution[swap_idx1] = 1\n                        new_solution[swap_idx2] = 0\n\n    # Occasional perturbation to escape local optima\n    if np.random.rand() < 0.2:\n        perturb_idx = np.random.randint(len(new_solution))\n        if new_solution[perturb_idx] == 1:\n            if current_weight - weight_lst[perturb_idx] <= capacity:\n                new_solution[perturb_idx] = 0\n        else:\n            if current_weight + weight_lst[perturb_idx] <= capacity:\n                new_solution[perturb_idx] = 1\n\n    return new_solution\n\n",
        "operation": "e1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects top 20% solutions by normalized objective sums, then performs targeted flips of high-marginal-gain items for either objective, followed by random flips of low-marginal-gain items, ensuring feasibility through iterative refinement. High-marginal-gain items are prioritized for flips to maximize potential improvement, while low-marginal-gain items are flipped randomly (30% chance) to explore diverse neighbors, with infeasible solutions rejected after 5 attempts.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted flips: high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Random flips: low marginal gains\n    low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(2, len(weight_lst))]\n    for idx in low_gain_indices:\n        if np.random.rand() < 0.3:  # 30% chance for random flip\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects the top 20% of solutions from the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items first, followed by controlled random flips of low-marginal-gain items to ensure feasibility. It iteratively refines the solution by rejecting infeasible neighbors, prioritizing items with higher marginal gains while maintaining diversity through random perturbations. The key design choices are the prioritization of high-marginal-gain items, controlled randomness for exploration, and iterative feasibility checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip 1-2 low-marginal-contribution items\n    num_flips = np.random.randint(1, 3)\n    low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n    for _ in range(num_flips):\n        idx = np.random.choice(low_gain_indices)\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 94,
        "algorithm": "The algorithm combines targeted exploitation with adaptive perturbation: it selects top 20% solutions by normalized objective sums, prioritizes flipping high-marginal-gain items, and introduces controlled randomness by flipping low-marginal-gain items with probability inversely proportional to their contribution, while ensuring feasibility through iterative refinement. High-priority items are flipped first, followed by selective perturbations to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n\n    # Flip items with highest marginal gains first\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Adaptive perturbation: flip low-marginal-gain items with probability inversely proportional to their current contribution\n    low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n    for idx in low_gain_indices:\n        current_contribution = (base_solution[idx] * value1_lst[idx] + base_solution[idx] * value2_lst[idx]) / (current_weight + 1e-6)\n        flip_prob = 0.1 / (1 + current_contribution)  # Higher contribution = lower flip probability\n        if np.random.rand() < flip_prob:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.7628385509421811,
            0.22508922219276428
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n\n    # Flip items with highest marginal gains first\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Adaptive perturbation: flip low-marginal-gain items with probability inversely proportional to their current contribution\n    low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n    for idx in low_gain_indices:\n        current_contribution = (base_solution[idx] * value1_lst[idx] + base_solution[idx] * value2_lst[idx]) / (current_weight + 1e-6)\n        flip_prob = 0.1 / (1 + current_contribution)  # Higher contribution = lower flip probability\n        if np.random.rand() < flip_prob:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects the top 20% of solutions from the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items first, followed by controlled random flips of low-marginal-gain items to ensure feasibility. It iteratively refines the solution by rejecting infeasible neighbors, prioritizing items with higher marginal gains while maintaining diversity through random perturbations. The key design choices are the prioritization of high-marginal-gain items, controlled randomness for exploration, and iterative feasibility checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip 1-2 low-marginal-contribution items\n    num_flips = np.random.randint(1, 3)\n    low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n    for _ in range(num_flips):\n        idx = np.random.choice(low_gain_indices)\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 95,
        "algorithm": "The heuristic algorithm prioritizes top-performing solutions from the archive (selected based on normalized objective sums) and applies a dynamic flip strategy that alternates between adding high-balanced-gain items and removing low-contribution items, while maintaining feasibility through adaptive capacity checks and incorporating a diversity-aware perturbation mechanism to balance exploitation and exploration. The balanced marginal gains and probabilistic flipping ensure both objectives are considered, while the perturbation mechanism helps escape local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate balanced marginal gains\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    balanced_gain = (marginal_gain1 + marginal_gain2) / 2\n    sorted_indices = np.argsort(-balanced_gain)\n\n    # Dynamic flip strategy\n    for idx in sorted_indices:\n        if np.random.rand() < 0.7:  # Higher probability for balanced items\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Diversity-aware perturbation\n    if np.random.rand() < 0.3:  # 30% chance for perturbation\n        # Flip low-contribution items more aggressively\n        low_contribution = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_indices = np.argsort(low_contribution)[:min(3, len(weight_lst))]\n        for idx in low_indices:\n            if np.random.rand() < 0.5:  # Higher probability for low-contribution items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.6130154554112507,
            0.5439688563346863
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate balanced marginal gains\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    balanced_gain = (marginal_gain1 + marginal_gain2) / 2\n    sorted_indices = np.argsort(-balanced_gain)\n\n    # Dynamic flip strategy\n    for idx in sorted_indices:\n        if np.random.rand() < 0.7:  # Higher probability for balanced items\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Diversity-aware perturbation\n    if np.random.rand() < 0.3:  # 30% chance for perturbation\n        # Flip low-contribution items more aggressively\n        low_contribution = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_indices = np.argsort(low_contribution)[:min(3, len(weight_lst))]\n        for idx in low_indices:\n            if np.random.rand() < 0.5:  # Higher probability for low-contribution items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects the top 20% of solutions from the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items first, followed by controlled random flips of low-marginal-gain items to ensure feasibility. It iteratively refines the solution by rejecting infeasible neighbors, prioritizing items with higher marginal gains while maintaining diversity through random perturbations. The key design choices are the prioritization of high-marginal-gain items, controlled randomness for exploration, and iterative feasibility checks.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip 1-2 low-marginal-contribution items\n    num_flips = np.random.randint(1, 3)\n    low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n    for _ in range(num_flips):\n        idx = np.random.choice(low_gain_indices)\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 96,
        "algorithm": "The algorithm selects top 25% solutions from the archive based on a hybrid score combining normalized objective values and diversity, then performs two-phase local search: first prioritizing items with high combined marginal gains in both objectives while maintaining feasibility, followed by diversity-preserving random flips to explore the solution space. It always ensures the generated neighbor solution remains feasible by adjusting weights if necessary. The algorithm balances exploitation (via trade-off aware flips) and exploration (via diversity-preserving random flips) while giving higher priority to items with significant combined value-to-weight ratios.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 25% solutions using hybrid objective score (normalized values + diversity)\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        diversity_scores = [np.sum(np.abs(archive[i][0] - archive[j][0])) for i in range(len(archive)) for j in range(i+1, len(archive))]\n        avg_diversity = np.mean(diversity_scores) if diversity_scores else 0\n        hybrid_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2 + 0.5 * (np.sum(np.abs(sol - archive[i][0])) / avg_diversity if avg_diversity > 0 else 0))\n                         for i, (sol, obj) in enumerate(archive)]\n        top_indices = np.argsort(hybrid_scores)[-max(1, len(archive)//4):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Trade-off aware marginal gain flips\n    combined_gain = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(-combined_gain)\n\n    for idx in sorted_indices[:min(10, len(weight_lst))]:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Diversity-preserving random flips\n    diversity_flips = min(2, len(weight_lst) // 5)\n    candidate_indices = np.where(np.abs(weight_lst - np.mean(weight_lst)) > np.std(weight_lst))[0]\n\n    for _ in range(diversity_flips):\n        if len(candidate_indices) > 0:\n            idx = np.random.choice(candidate_indices)\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Feasibility check and refinement\n    temp_weight = np.sum(weight_lst * new_solution)\n    if temp_weight > capacity:\n        excess_weight = temp_weight - capacity\n        sorted_indices = np.argsort(weight_lst * new_solution)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and excess_weight <= 0:\n                break\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8103755351035422,
            2.1505949795246124
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 25% solutions using hybrid objective score (normalized values + diversity)\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        diversity_scores = [np.sum(np.abs(archive[i][0] - archive[j][0])) for i in range(len(archive)) for j in range(i+1, len(archive))]\n        avg_diversity = np.mean(diversity_scores) if diversity_scores else 0\n        hybrid_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2 + 0.5 * (np.sum(np.abs(sol - archive[i][0])) / avg_diversity if avg_diversity > 0 else 0))\n                         for i, (sol, obj) in enumerate(archive)]\n        top_indices = np.argsort(hybrid_scores)[-max(1, len(archive)//4):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Trade-off aware marginal gain flips\n    combined_gain = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(-combined_gain)\n\n    for idx in sorted_indices[:min(10, len(weight_lst))]:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Diversity-preserving random flips\n    diversity_flips = min(2, len(weight_lst) // 5)\n    candidate_indices = np.where(np.abs(weight_lst - np.mean(weight_lst)) > np.std(weight_lst))[0]\n\n    for _ in range(diversity_flips):\n        if len(candidate_indices) > 0:\n            idx = np.random.choice(candidate_indices)\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Feasibility check and refinement\n    temp_weight = np.sum(weight_lst * new_solution)\n    if temp_weight > capacity:\n        excess_weight = temp_weight - capacity\n        sorted_indices = np.argsort(weight_lst * new_solution)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and excess_weight <= 0:\n                break\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects the top 20% of solutions from the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items first, followed by controlled random flips of low-marginal-gain items to ensure feasibility. It iteratively refines the solution by rejecting infeasible neighbors, prioritizing items with higher marginal gains while maintaining diversity through random perturbations. The key design choices are the prioritization of high-marginal-gain items, controlled randomness for exploration, and iterative feasibility checks.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip 1-2 low-marginal-contribution items\n    num_flips = np.random.randint(1, 3)\n    low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n    for _ in range(num_flips):\n        idx = np.random.choice(low_gain_indices)\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 97,
        "algorithm": "The algorithm selects top 30% solutions from the archive based on normalized objective product, then performs a hybrid local search: first flipping items with high marginal gains (either objective) in a greedy manner, followed by controlled random flips of items with balanced marginal gains to maintain diversity, while ensuring feasibility through iterative refinement. The method prioritizes items with high marginal gains first, then balances exploration with controlled randomness to avoid local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1) * (obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip 2-3 items with balanced marginal gains\n    num_flips = np.random.randint(2, 4)\n    balanced_gain_indices = np.argsort(np.abs(marginal_gain1 - marginal_gain2))[:min(5, len(weight_lst))]\n    for _ in range(num_flips):\n        idx = np.random.choice(balanced_gain_indices)\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.7878988636486597,
            0.4233342409133911
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1) * (obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip 2-3 items with balanced marginal gains\n    num_flips = np.random.randint(2, 4)\n    balanced_gain_indices = np.argsort(np.abs(marginal_gain1 - marginal_gain2))[:min(5, len(weight_lst))]\n    for _ in range(num_flips):\n        idx = np.random.choice(balanced_gain_indices)\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 4 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects the top 20% of solutions from the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items first, followed by controlled random flips of low-marginal-gain items to ensure feasibility. It iteratively refines the solution by rejecting infeasible neighbors, prioritizing items with higher marginal gains while maintaining diversity through random perturbations. The key design choices are the prioritization of high-marginal-gain items, controlled randomness for exploration, and iterative feasibility checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip 1-2 low-marginal-contribution items\n    num_flips = np.random.randint(1, 3)\n    low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n    for _ in range(num_flips):\n        idx = np.random.choice(low_gain_indices)\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 98,
        "algorithm": "The algorithm selects promising solutions from the top 20% of the archive (based on normalized objective sums) and applies a hybrid local search that alternates between improving each objective, prioritizes flipping high-marginal-gain items while controlling perturbations of low-contribution items with crowding-distance-based probabilities to ensure feasibility. The search iteratively refines solutions through 5 rounds of controlled flips, balancing exploitation of high-value items and exploration of low-contribution items.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate crowding distances for perturbation control\n    objectives = np.array([obj for _, obj in archive])\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Hybrid local search with alternating objective improvement\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = current_weight\n\n        # Alternate between objectives\n        if np.random.rand() < 0.5:\n            # Improve first objective\n            gain = value1_lst / weight_lst\n        else:\n            # Improve second objective\n            gain = value2_lst / weight_lst\n\n        # Flip high-marginal-gain items first\n        high_gain_indices = np.argsort(-gain)[:min(5, len(weight_lst))]\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if temp_weight - weight_lst[idx] <= capacity:\n                    temp_solution[idx] = 0\n                    temp_weight -= weight_lst[idx]\n            else:\n                if temp_weight + weight_lst[idx] <= capacity:\n                    temp_solution[idx] = 1\n                    temp_weight += weight_lst[idx]\n\n        # Controlled random perturbation of low-marginal-contribution items\n        perturbation_prob = 0.3 if crowding[selected_idx] > np.median(crowding) else 0.1\n        if np.random.rand() < perturbation_prob:\n            marginal_contribution = (value1_lst + value2_lst) / weight_lst\n            low_contrib_indices = np.argsort(marginal_contribution)[:min(3, len(weight_lst))]\n            for _ in range(np.random.randint(1, 3)):\n                idx = np.random.choice(low_contrib_indices)\n                if base_solution[idx] == 1 and temp_weight - weight_lst[idx] <= capacity:\n                    temp_solution[idx] = 0\n                    temp_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and temp_weight + weight_lst[idx] <= capacity:\n                    temp_solution[idx] = 1\n                    temp_weight += weight_lst[idx]\n\n        # Update if feasible\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            current_weight = temp_weight\n\n    return new_solution\n\n",
        "score": [
            -0.7032871698345758,
            0.681488037109375
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate crowding distances for perturbation control\n    objectives = np.array([obj for _, obj in archive])\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Hybrid local search with alternating objective improvement\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = current_weight\n\n        # Alternate between objectives\n        if np.random.rand() < 0.5:\n            # Improve first objective\n            gain = value1_lst / weight_lst\n        else:\n            # Improve second objective\n            gain = value2_lst / weight_lst\n\n        # Flip high-marginal-gain items first\n        high_gain_indices = np.argsort(-gain)[:min(5, len(weight_lst))]\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if temp_weight - weight_lst[idx] <= capacity:\n                    temp_solution[idx] = 0\n                    temp_weight -= weight_lst[idx]\n            else:\n                if temp_weight + weight_lst[idx] <= capacity:\n                    temp_solution[idx] = 1\n                    temp_weight += weight_lst[idx]\n\n        # Controlled random perturbation of low-marginal-contribution items\n        perturbation_prob = 0.3 if crowding[selected_idx] > np.median(crowding) else 0.1\n        if np.random.rand() < perturbation_prob:\n            marginal_contribution = (value1_lst + value2_lst) / weight_lst\n            low_contrib_indices = np.argsort(marginal_contribution)[:min(3, len(weight_lst))]\n            for _ in range(np.random.randint(1, 3)):\n                idx = np.random.choice(low_contrib_indices)\n                if base_solution[idx] == 1 and temp_weight - weight_lst[idx] <= capacity:\n                    temp_solution[idx] = 0\n                    temp_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and temp_weight + weight_lst[idx] <= capacity:\n                    temp_solution[idx] = 1\n                    temp_weight += weight_lst[idx]\n\n        # Update if feasible\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            current_weight = temp_weight\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 4 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s the refined heuristic design for the BI-KP:\n\n- **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 99,
        "algorithm": "The algorithm selects top 20% solutions by normalized objective sums, performs iterative improvement by flipping items with highest marginal gains in either objective, and adds random feasible flips to balance exploration and exploitation while ensuring feasibility. It prioritizes items with higher combined marginal gains (value/weight) and randomly perturbs the solution to escape local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Iterative improvement with 5-10 iterations\n    for _ in range(np.random.randint(5, 11)):\n        # Flip items with highest marginal gains in either objective\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n        combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n        top_indices = np.argsort(-combined_gain)[:min(3, len(weight_lst))]\n\n        for idx in top_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Add 1-2 random feasible flips\n        for _ in range(np.random.randint(1, 3)):\n            candidate_idx = np.random.randint(len(weight_lst))\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3359412062984143,
            0.4297870993614197
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Iterative improvement with 5-10 iterations\n    for _ in range(np.random.randint(5, 11)):\n        # Flip items with highest marginal gains in either objective\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n        combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n        top_indices = np.argsort(-combined_gain)[:min(3, len(weight_lst))]\n\n        for idx in top_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Add 1-2 random feasible flips\n        for _ in range(np.random.randint(1, 3)):\n            candidate_idx = np.random.randint(len(weight_lst))\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm first selects promising solutions from the top 20% of the archive based on normalized objective sums, then iteratively refines them by strategically flipping high-marginal-gain items (prioritizing either objective) while ensuring feasibility, followed by controlled random flips of low-value items to maintain diversity. The process repeats 5 times per solution to balance exploitation and exploration. The marginal gains are calculated as the maximum of the two objective values per item, and low-value items are identified by the minimum of the two objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    objectives = np.array([obj for _, obj in archive])\n    normalized_sums = (objectives[:, 0] + objectives[:, 1]) / (np.sum(weight_lst) + 1e-6)\n    selected_indices = np.argsort(normalized_sums)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(selected_indices)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    for _ in range(5):  # Iterate 5 times for refinement\n        new_solution = base_solution.copy()\n\n        # Flip items with highest marginal gains in either objective\n        marginal_gains = np.maximum(value1_lst, value2_lst) / (weight_lst + 1e-6)\n        sorted_indices = np.argsort(-marginal_gains)\n\n        for idx in sorted_indices[:min(5, len(weight_lst))]:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n        # Add 1-2 random flips of low-value items\n        low_value_indices = np.argsort(np.minimum(value1_lst, value2_lst))[:min(3, len(weight_lst))]\n        for _ in range(np.random.randint(1, 3)):\n            idx = np.random.choice(low_value_indices)\n            if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif new_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n        base_solution = new_solution\n\n    return base_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP:\n\n- **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 100,
        "algorithm": "The algorithm selects top 20% of solutions from the archive based on normalized objective sums, then applies a 5-phase hybrid local search that prioritizes high-marginal-gain items while probabilistically flipping low-value items to balance exploitation and exploration, ensuring feasibility through adaptive capacity checks. The selection process emphasizes items with maximum value/weight ratios, followed by controlled random perturbations of low-value items to escape local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    objectives = np.array([obj for _, obj in archive])\n    normalized_sums = (objectives[:, 0] + objectives[:, 1]) / (np.sum(weight_lst) + 1e-6)\n    selected_indices = np.argsort(normalized_sums)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(selected_indices)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    for _ in range(5):  # Iterate 5 times for refinement\n        new_solution = base_solution.copy()\n\n        # Phase 1: Flip items with highest marginal gains in either objective\n        marginal_gains = np.maximum(value1_lst, value2_lst) / (weight_lst + 1e-6)\n        sorted_indices = np.argsort(-marginal_gains)\n\n        for idx in sorted_indices[:min(5, len(weight_lst))]:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n        # Phase 2: Add probabilistic flips of low-value items\n        low_value_indices = np.argsort(np.minimum(value1_lst, value2_lst))[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.3:  # 30% probability for low-value items\n                if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                elif new_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n\n        base_solution = new_solution\n\n    return base_solution\n\n",
        "score": [
            -0.5747086778141292,
            0.3927622139453888
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    objectives = np.array([obj for _, obj in archive])\n    normalized_sums = (objectives[:, 0] + objectives[:, 1]) / (np.sum(weight_lst) + 1e-6)\n    selected_indices = np.argsort(normalized_sums)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(selected_indices)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    for _ in range(5):  # Iterate 5 times for refinement\n        new_solution = base_solution.copy()\n\n        # Phase 1: Flip items with highest marginal gains in either objective\n        marginal_gains = np.maximum(value1_lst, value2_lst) / (weight_lst + 1e-6)\n        sorted_indices = np.argsort(-marginal_gains)\n\n        for idx in sorted_indices[:min(5, len(weight_lst))]:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n        # Phase 2: Add probabilistic flips of low-value items\n        low_value_indices = np.argsort(np.minimum(value1_lst, value2_lst))[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.3:  # 30% probability for low-value items\n                if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                elif new_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n\n        base_solution = new_solution\n\n    return base_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive using a dynamic weighted sum of objectives (prioritizing value1 at 70% and value2 at 30%), then applies a hybrid local search combining greedy flips for top marginal-gain items and probabilistic swaps, while maintaining feasibility through a multi-criteria removal strategy that balances value-weight ratios and weight penalties. The search adapts exploration/exploitation based on current solution utilization, favoring marginal gains in underutilized knapsacks and probabilistic swaps in overutilized ones.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions using dynamic weighted objective sum\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Dynamic weighting based on solution quality diversity\n        quality_diversity = np.std(obj1_scores) + np.std(obj2_scores)\n        weight1 = 0.7 - 0.1 * (quality_diversity / (max_obj1 + max_obj2 + 1e-10))\n        weight2 = 1 - weight1\n        normalized_scores = (weight1 * obj1_scores / max_obj1) + (weight2 * obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n    current_utilization = current_weight / capacity\n\n    # Hybrid local search with marginal gain and probabilistic swaps\n    # Calculate utilization-aware marginal gains\n    utilization_factor = 1 - (current_utilization ** 2)\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = (utilization_factor * marginal_gain1) + ((1 - utilization_factor) * marginal_gain2)\n\n    # Greedy flips for top 5 items\n    sorted_indices = np.argsort(combined_gain)[::-1]\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Probabilistic swaps based on marginal gains\n    swap_prob = 0.3 * (1 - current_utilization)\n    for idx in range(n_items):\n        if np.random.random() < swap_prob:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Multi-criteria feasibility maintenance\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n\n        if len(removable_items) == 0:\n            break\n\n        # Remove items with lowest value-weight ratio or highest weight\n        value_weight_ratio = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        weight_penalty = weight_lst[removable_items] / capacity\n        removal_score = value_weight_ratio - 2 * weight_penalty\n        remove_idx = removable_items[np.argmin(removal_score)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm first selects promising solutions from the top 20% of the archive based on normalized objective sums, then iteratively refines them by strategically flipping high-marginal-gain items (prioritizing either objective) while ensuring feasibility, followed by controlled random flips of low-value items to maintain diversity. The process repeats 5 times per solution to balance exploitation and exploration. The marginal gains are calculated as the maximum of the two objective values per item, and low-value items are identified by the minimum of the two objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    objectives = np.array([obj for _, obj in archive])\n    normalized_sums = (objectives[:, 0] + objectives[:, 1]) / (np.sum(weight_lst) + 1e-6)\n    selected_indices = np.argsort(normalized_sums)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(selected_indices)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    for _ in range(5):  # Iterate 5 times for refinement\n        new_solution = base_solution.copy()\n\n        # Flip items with highest marginal gains in either objective\n        marginal_gains = np.maximum(value1_lst, value2_lst) / (weight_lst + 1e-6)\n        sorted_indices = np.argsort(-marginal_gains)\n\n        for idx in sorted_indices[:min(5, len(weight_lst))]:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n        # Add 1-2 random flips of low-value items\n        low_value_indices = np.argsort(np.minimum(value1_lst, value2_lst))[:min(3, len(weight_lst))]\n        for _ in range(np.random.randint(1, 3)):\n            idx = np.random.choice(low_value_indices)\n            if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif new_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n        base_solution = new_solution\n\n    return base_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP:\n\n- **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 101,
        "algorithm": "The algorithm selects top 20% solutions from the archive using adaptive objective prioritization, then applies a hybrid local search alternating between value-focused flips (prioritizing high marginal gain items) and weight-balanced swaps (focusing on balanced value-weight ratios), with utilization-aware perturbations and multi-criteria feasibility checks to ensure feasible solutions. It dynamically adjusts search focus based on current utilization and marginal gains, iterating 5-10 times per solution while maintaining feasibility through excess weight removal.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by adaptive objective prioritization\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Dynamic objective prioritization based on current archive diversity\n        diversity = np.std(obj1_scores) + np.std(obj2_scores)\n        weight1 = 0.5 + 0.2 * (diversity / (max_obj1 + max_obj2 + 1e-10))\n        weight2 = 1 - weight1\n        normalized_scores = (weight1 * obj1_scores / max_obj1) + (weight2 * obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    current_utilization = current_weight / capacity\n\n    for _ in range(np.random.randint(5, 10)):\n        # Alternate between value-focused and weight-balanced operations\n        if np.random.random() < 0.6:\n            # Value-focused flips (prioritize high marginal gain items)\n            marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n            marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n            combined_gain = (0.6 * marginal_gain1) + (0.4 * marginal_gain2)\n            sorted_indices = np.argsort(-combined_gain)\n\n            for idx in sorted_indices[:min(3, len(weight_lst))]:\n                if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n        else:\n            # Weight-balanced swaps (prioritize items with balanced value/weight ratios)\n            value_weight_ratio = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n            normalized_ratio = value_weight_ratio / (np.max(value_weight_ratio) + 1e-10)\n            sorted_indices = np.argsort(-normalized_ratio)\n\n            for idx in sorted_indices[:min(2, len(weight_lst))]:\n                if np.random.random() < 0.4:\n                    if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                    elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                        new_solution[idx] = 0\n                        current_weight -= weight_lst[idx]\n\n        # Utilization-aware perturbation\n        perturbation_prob = 0.3 * (1 - current_utilization)\n        for idx in range(len(weight_lst)):\n            if np.random.random() < perturbation_prob:\n                if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n\n        # Feasibility check and multi-criteria removal\n        while np.sum(new_solution * weight_lst) > capacity:\n            excess = np.sum(new_solution * weight_lst) - capacity\n            removable_items = np.where(new_solution == 1)[0]\n\n            if len(removable_items) == 0:\n                break\n\n            # Remove items with lowest combined value-weight ratio and highest weight\n            combined_ratio = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n            weight_penalty = weight_lst[removable_items] / capacity\n            removal_score = combined_ratio - 2 * weight_penalty\n            remove_idx = removable_items[np.argmin(removal_score)]\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n        base_solution = new_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.4412699259111647,
            2.291119009256363
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by adaptive objective prioritization\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Dynamic objective prioritization based on current archive diversity\n        diversity = np.std(obj1_scores) + np.std(obj2_scores)\n        weight1 = 0.5 + 0.2 * (diversity / (max_obj1 + max_obj2 + 1e-10))\n        weight2 = 1 - weight1\n        normalized_scores = (weight1 * obj1_scores / max_obj1) + (weight2 * obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    current_utilization = current_weight / capacity\n\n    for _ in range(np.random.randint(5, 10)):\n        # Alternate between value-focused and weight-balanced operations\n        if np.random.random() < 0.6:\n            # Value-focused flips (prioritize high marginal gain items)\n            marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n            marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n            combined_gain = (0.6 * marginal_gain1) + (0.4 * marginal_gain2)\n            sorted_indices = np.argsort(-combined_gain)\n\n            for idx in sorted_indices[:min(3, len(weight_lst))]:\n                if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n        else:\n            # Weight-balanced swaps (prioritize items with balanced value/weight ratios)\n            value_weight_ratio = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n            normalized_ratio = value_weight_ratio / (np.max(value_weight_ratio) + 1e-10)\n            sorted_indices = np.argsort(-normalized_ratio)\n\n            for idx in sorted_indices[:min(2, len(weight_lst))]:\n                if np.random.random() < 0.4:\n                    if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                    elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                        new_solution[idx] = 0\n                        current_weight -= weight_lst[idx]\n\n        # Utilization-aware perturbation\n        perturbation_prob = 0.3 * (1 - current_utilization)\n        for idx in range(len(weight_lst)):\n            if np.random.random() < perturbation_prob:\n                if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n\n        # Feasibility check and multi-criteria removal\n        while np.sum(new_solution * weight_lst) > capacity:\n            excess = np.sum(new_solution * weight_lst) - capacity\n            removable_items = np.where(new_solution == 1)[0]\n\n            if len(removable_items) == 0:\n                break\n\n            # Remove items with lowest combined value-weight ratio and highest weight\n            combined_ratio = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n            weight_penalty = weight_lst[removable_items] / capacity\n            removal_score = combined_ratio - 2 * weight_penalty\n            remove_idx = removable_items[np.argmin(removal_score)]\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n        base_solution = new_solution.copy()\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm first selects promising solutions from the top 20% of the archive based on normalized objective sums, then iteratively refines them by strategically flipping high-marginal-gain items (prioritizing either objective) while ensuring feasibility, followed by controlled random flips of low-value items to maintain diversity. The process repeats 5 times per solution to balance exploitation and exploration. The marginal gains are calculated as the maximum of the two objective values per item, and low-value items are identified by the minimum of the two objectives.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    objectives = np.array([obj for _, obj in archive])\n    normalized_sums = (objectives[:, 0] + objectives[:, 1]) / (np.sum(weight_lst) + 1e-6)\n    selected_indices = np.argsort(normalized_sums)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(selected_indices)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    for _ in range(5):  # Iterate 5 times for refinement\n        new_solution = base_solution.copy()\n\n        # Flip items with highest marginal gains in either objective\n        marginal_gains = np.maximum(value1_lst, value2_lst) / (weight_lst + 1e-6)\n        sorted_indices = np.argsort(-marginal_gains)\n\n        for idx in sorted_indices[:min(5, len(weight_lst))]:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n        # Add 1-2 random flips of low-value items\n        low_value_indices = np.argsort(np.minimum(value1_lst, value2_lst))[:min(3, len(weight_lst))]\n        for _ in range(np.random.randint(1, 3)):\n            idx = np.random.choice(low_value_indices)\n            if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif new_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n        base_solution = new_solution\n\n    return base_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 102,
        "algorithm": "This algorithm selects a promising solution from an archive using a hybrid metric combining non-dominated status and diversity, then applies a three-phase local search: hypervolume-maximizing flips prioritize high-impact changes, adaptive neighborhood exploration targets sparse or dense regions, and random diversification introduces low-probability perturbations to escape local optima while maintaining feasibility. The selection prioritizes non-dominated solutions with high diversity, while the local search alternates between exploitation (hypervolume maximization) and exploration (adaptive neighborhood and randomization) to balance improvement and diversification.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine dominance ranking with diversity metric\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = np.ones(len(archive), dtype=bool)\n\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j and (objectives[j, 0] >= objectives[i, 0] and objectives[j, 1] >= objectives[i, 1]) and (objectives[j, 0] > objectives[i, 0] or objectives[j, 1] > objectives[i, 1]):\n                non_dominated[i] = False\n                break\n\n    # Calculate diversity metric (distance to nearest neighbor in objective space)\n    diversity = np.zeros(len(archive))\n    for i in range(len(archive)):\n        distances = np.sum(np.abs(objectives - objectives[i]), axis=1)\n        diversity[i] = np.min(distances[distances > 0]) if np.any(distances > 0) else 0\n\n    # Combine metrics: prioritize non-dominated solutions with good diversity\n    combined_score = np.where(non_dominated, diversity + 1, diversity / (np.sum(weight_lst) + 1e-6))\n    selected_idx = np.argmax(combined_score)\n\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Multi-phase local search\n    for phase in range(3):\n        new_solution = base_solution.copy()\n\n        if phase == 0:  # Hypervolume-maximizing flips\n            # Calculate potential hypervolume improvement\n            hv_improvement = np.zeros(len(weight_lst))\n            for i in range(len(weight_lst)):\n                if base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                    new_v1 = current_value1 + value1_lst[i]\n                    new_v2 = current_value2 + value2_lst[i]\n                    hv_improvement[i] = (new_v1 - current_value1) * (new_v2 - current_value2)\n                elif base_solution[i] == 1:\n                    new_v1 = current_value1 - value1_lst[i]\n                    new_v2 = current_value2 - value2_lst[i]\n                    hv_improvement[i] = (current_value1 - new_v1) * (current_value2 - new_v2)\n\n            sorted_indices = np.argsort(-hv_improvement)\n            for idx in sorted_indices[:min(3, len(weight_lst))]:\n                if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    current_value1 += value1_lst[idx]\n                    current_value2 += value2_lst[idx]\n                elif base_solution[idx] == 1:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    current_value1 -= value1_lst[idx]\n                    current_value2 -= value2_lst[idx]\n\n        elif phase == 1:  # Adaptive neighborhood exploration\n            # Calculate adaptive neighborhood based on current solution's characteristics\n            density = np.sum(base_solution) / len(base_solution)\n            if density > 0.5:  # Sparse neighborhood\n                candidates = np.where(base_solution == 1)[0]\n            else:  # Dense neighborhood\n                candidates = np.where(base_solution == 0)[0]\n\n            for idx in np.random.choice(candidates, min(3, len(candidates)), replace=False):\n                if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                elif base_solution[idx] == 1:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n\n        else:  # Random diversification\n            # Flip low-impact items with probability based on their marginal value\n            marginal_value = np.minimum(value1_lst, value2_lst) / (weight_lst + 1e-6)\n            flip_probs = marginal_value / (np.sum(marginal_value) + 1e-6)\n            for i in range(len(weight_lst)):\n                if np.random.rand() < flip_probs[i] * 0.3:  # Low probability for diversification\n                    if base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                        new_solution[i] = 1\n                    elif base_solution[i] == 1:\n                        new_solution[i] = 0\n\n        base_solution = new_solution\n\n    return base_solution\n\n",
        "score": [
            -0.39448683895160747,
            0.9710541069507599
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine dominance ranking with diversity metric\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = np.ones(len(archive), dtype=bool)\n\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j and (objectives[j, 0] >= objectives[i, 0] and objectives[j, 1] >= objectives[i, 1]) and (objectives[j, 0] > objectives[i, 0] or objectives[j, 1] > objectives[i, 1]):\n                non_dominated[i] = False\n                break\n\n    # Calculate diversity metric (distance to nearest neighbor in objective space)\n    diversity = np.zeros(len(archive))\n    for i in range(len(archive)):\n        distances = np.sum(np.abs(objectives - objectives[i]), axis=1)\n        diversity[i] = np.min(distances[distances > 0]) if np.any(distances > 0) else 0\n\n    # Combine metrics: prioritize non-dominated solutions with good diversity\n    combined_score = np.where(non_dominated, diversity + 1, diversity / (np.sum(weight_lst) + 1e-6))\n    selected_idx = np.argmax(combined_score)\n\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Multi-phase local search\n    for phase in range(3):\n        new_solution = base_solution.copy()\n\n        if phase == 0:  # Hypervolume-maximizing flips\n            # Calculate potential hypervolume improvement\n            hv_improvement = np.zeros(len(weight_lst))\n            for i in range(len(weight_lst)):\n                if base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                    new_v1 = current_value1 + value1_lst[i]\n                    new_v2 = current_value2 + value2_lst[i]\n                    hv_improvement[i] = (new_v1 - current_value1) * (new_v2 - current_value2)\n                elif base_solution[i] == 1:\n                    new_v1 = current_value1 - value1_lst[i]\n                    new_v2 = current_value2 - value2_lst[i]\n                    hv_improvement[i] = (current_value1 - new_v1) * (current_value2 - new_v2)\n\n            sorted_indices = np.argsort(-hv_improvement)\n            for idx in sorted_indices[:min(3, len(weight_lst))]:\n                if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    current_value1 += value1_lst[idx]\n                    current_value2 += value2_lst[idx]\n                elif base_solution[idx] == 1:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    current_value1 -= value1_lst[idx]\n                    current_value2 -= value2_lst[idx]\n\n        elif phase == 1:  # Adaptive neighborhood exploration\n            # Calculate adaptive neighborhood based on current solution's characteristics\n            density = np.sum(base_solution) / len(base_solution)\n            if density > 0.5:  # Sparse neighborhood\n                candidates = np.where(base_solution == 1)[0]\n            else:  # Dense neighborhood\n                candidates = np.where(base_solution == 0)[0]\n\n            for idx in np.random.choice(candidates, min(3, len(candidates)), replace=False):\n                if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                elif base_solution[idx] == 1:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n\n        else:  # Random diversification\n            # Flip low-impact items with probability based on their marginal value\n            marginal_value = np.minimum(value1_lst, value2_lst) / (weight_lst + 1e-6)\n            flip_probs = marginal_value / (np.sum(marginal_value) + 1e-6)\n            for i in range(len(weight_lst)):\n                if np.random.rand() < flip_probs[i] * 0.3:  # Low probability for diversification\n                    if base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                        new_solution[i] = 1\n                    elif base_solution[i] == 1:\n                        new_solution[i] = 0\n\n        base_solution = new_solution\n\n    return base_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm first selects promising solutions from the top 20% of the archive based on normalized objective sums, then iteratively refines them by strategically flipping high-marginal-gain items (prioritizing either objective) while ensuring feasibility, followed by controlled random flips of low-value items to maintain diversity. The process repeats 5 times per solution to balance exploitation and exploration. The marginal gains are calculated as the maximum of the two objective values per item, and low-value items are identified by the minimum of the two objectives.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    objectives = np.array([obj for _, obj in archive])\n    normalized_sums = (objectives[:, 0] + objectives[:, 1]) / (np.sum(weight_lst) + 1e-6)\n    selected_indices = np.argsort(normalized_sums)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(selected_indices)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    for _ in range(5):  # Iterate 5 times for refinement\n        new_solution = base_solution.copy()\n\n        # Flip items with highest marginal gains in either objective\n        marginal_gains = np.maximum(value1_lst, value2_lst) / (weight_lst + 1e-6)\n        sorted_indices = np.argsort(-marginal_gains)\n\n        for idx in sorted_indices[:min(5, len(weight_lst))]:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n        # Add 1-2 random flips of low-value items\n        low_value_indices = np.argsort(np.minimum(value1_lst, value2_lst))[:min(3, len(weight_lst))]\n        for _ in range(np.random.randint(1, 3)):\n            idx = np.random.choice(low_value_indices)\n            if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif new_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n        base_solution = new_solution\n\n    return base_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 103,
        "algorithm": "The algorithm selects high-performing solutions (top 30% by normalized objective product) and refines them by iteratively flipping items with the highest marginal gains (prioritizing both objectives) while ensuring feasibility, followed by controlled random flips of low-weight items to maintain diversity. The process repeats 3 times per solution, balancing objective improvement and exploration.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by normalized objective products\n    objectives = np.array([obj for _, obj in archive])\n    normalized_products = (objectives[:, 0] * objectives[:, 1]) / (np.sum(weight_lst) + 1e-6)\n    selected_indices = np.argsort(normalized_products)[-max(1, len(archive) // 3):]\n    selected_idx = np.random.choice(selected_indices)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    for _ in range(3):  # Iterate 3 times for refinement\n        new_solution = base_solution.copy()\n\n        # Flip items with highest marginal gains in both objectives (weighted sum)\n        marginal_gains = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        sorted_indices = np.argsort(-marginal_gains)\n\n        for idx in sorted_indices[:min(5, len(weight_lst))]:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n        # Add 1-3 random flips of low-weight items\n        low_weight_indices = np.argsort(weight_lst)[:min(5, len(weight_lst))]\n        for _ in range(np.random.randint(1, 4)):\n            idx = np.random.choice(low_weight_indices)\n            if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif new_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n        base_solution = new_solution\n\n    return base_solution\n\n",
        "score": [
            -0.39065975287031907,
            0.6407807767391205
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by normalized objective products\n    objectives = np.array([obj for _, obj in archive])\n    normalized_products = (objectives[:, 0] * objectives[:, 1]) / (np.sum(weight_lst) + 1e-6)\n    selected_indices = np.argsort(normalized_products)[-max(1, len(archive) // 3):]\n    selected_idx = np.random.choice(selected_indices)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    for _ in range(3):  # Iterate 3 times for refinement\n        new_solution = base_solution.copy()\n\n        # Flip items with highest marginal gains in both objectives (weighted sum)\n        marginal_gains = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        sorted_indices = np.argsort(-marginal_gains)\n\n        for idx in sorted_indices[:min(5, len(weight_lst))]:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n        # Add 1-3 random flips of low-weight items\n        low_weight_indices = np.argsort(weight_lst)[:min(5, len(weight_lst))]\n        for _ in range(np.random.randint(1, 4)):\n            idx = np.random.choice(low_weight_indices)\n            if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif new_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n        base_solution = new_solution\n\n    return base_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 4 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm first selects promising solutions from the top 20% of the archive based on normalized objective sums, then iteratively refines them by strategically flipping high-marginal-gain items (prioritizing either objective) while ensuring feasibility, followed by controlled random flips of low-value items to maintain diversity. The process repeats 5 times per solution to balance exploitation and exploration. The marginal gains are calculated as the maximum of the two objective values per item, and low-value items are identified by the minimum of the two objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    objectives = np.array([obj for _, obj in archive])\n    normalized_sums = (objectives[:, 0] + objectives[:, 1]) / (np.sum(weight_lst) + 1e-6)\n    selected_indices = np.argsort(normalized_sums)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(selected_indices)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    for _ in range(5):  # Iterate 5 times for refinement\n        new_solution = base_solution.copy()\n\n        # Flip items with highest marginal gains in either objective\n        marginal_gains = np.maximum(value1_lst, value2_lst) / (weight_lst + 1e-6)\n        sorted_indices = np.argsort(-marginal_gains)\n\n        for idx in sorted_indices[:min(5, len(weight_lst))]:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n        # Add 1-2 random flips of low-value items\n        low_value_indices = np.argsort(np.minimum(value1_lst, value2_lst))[:min(3, len(weight_lst))]\n        for _ in range(np.random.randint(1, 3)):\n            idx = np.random.choice(low_value_indices)\n            if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif new_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n        base_solution = new_solution\n\n    return base_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP:\n\n- **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 104,
        "algorithm": "The algorithm selects promising solutions from the top 20% of the archive based on normalized objective sums and crowding distance, then performs iterative refinement by flipping high-marginal-gain items (prioritizing those with maximum value-to-weight ratios) and adaptively perturbing low-marginal-contribution items, while dynamically adjusting perturbation probability based on crowding distance to balance exploration and exploitation. The method ensures feasibility by strictly checking capacity constraints during all operations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums and crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    normalized_sums = (objectives[:, 0] + objectives[:, 1]) / (np.sum(weight_lst) + 1e-6)\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Combine normalized sums and crowding distance for selection\n    selection_scores = normalized_sums * (1 + crowding / (np.max(crowding) + 1e-6))\n    selected_indices = np.argsort(selection_scores)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(selected_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Iterative refinement\n    for _ in range(5):\n        # Targeted flipping of high-marginal-gain items\n        marginal_gain1 = value1_lst / (weight_lst + 1e-6)\n        marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n        max_gain = np.maximum(marginal_gain1, marginal_gain2)\n        sorted_indices = np.argsort(-max_gain)\n\n        for idx in sorted_indices[:min(5, len(weight_lst))]:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n        # Adaptive perturbation based on marginal contribution\n        min_gain = np.minimum(marginal_gain1, marginal_gain2)\n        low_gain_indices = np.argsort(min_gain)[:min(3, len(weight_lst))]\n\n        # Dynamic perturbation probability based on crowding distance\n        perturbation_prob = 0.3 if crowding[selected_idx] > np.median(crowding) else 0.15\n        if np.random.rand() < perturbation_prob:\n            for idx in low_gain_indices:\n                if np.random.rand() < 0.4:  # Higher probability for low-gain items\n                    if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                    elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                        new_solution[idx] = 0\n                        current_weight -= weight_lst[idx]\n\n        base_solution = new_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.7609763663174733,
            0.6759214699268341
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums and crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    normalized_sums = (objectives[:, 0] + objectives[:, 1]) / (np.sum(weight_lst) + 1e-6)\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Combine normalized sums and crowding distance for selection\n    selection_scores = normalized_sums * (1 + crowding / (np.max(crowding) + 1e-6))\n    selected_indices = np.argsort(selection_scores)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(selected_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Iterative refinement\n    for _ in range(5):\n        # Targeted flipping of high-marginal-gain items\n        marginal_gain1 = value1_lst / (weight_lst + 1e-6)\n        marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n        max_gain = np.maximum(marginal_gain1, marginal_gain2)\n        sorted_indices = np.argsort(-max_gain)\n\n        for idx in sorted_indices[:min(5, len(weight_lst))]:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n        # Adaptive perturbation based on marginal contribution\n        min_gain = np.minimum(marginal_gain1, marginal_gain2)\n        low_gain_indices = np.argsort(min_gain)[:min(3, len(weight_lst))]\n\n        # Dynamic perturbation probability based on crowding distance\n        perturbation_prob = 0.3 if crowding[selected_idx] > np.median(crowding) else 0.15\n        if np.random.rand() < perturbation_prob:\n            for idx in low_gain_indices:\n                if np.random.rand() < 0.4:  # Higher probability for low-gain items\n                    if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                    elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                        new_solution[idx] = 0\n                        current_weight -= weight_lst[idx]\n\n        base_solution = new_solution.copy()\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 4 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s the refined heuristic design for the BI-KP:\n\n- **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~70)*\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 105,
        "algorithm": "The algorithm selects top 20% of solutions from the archive based on normalized objective sums, then performs targeted flips of high-marginal-gain items (prioritizing those with better value-to-weight ratios) followed by 1-2 random flips to maintain diversity, all while ensuring feasibility. The process repeats 5 times per solution to balance exploitation and exploration. The critical design choices are prioritizing high-marginal-gain items, controlled randomness for exploration, and iterative refinement while strictly maintaining feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Iterative improvement with controlled randomness\n    for _ in range(5):\n        # Targeted flips: highest marginal gains in either objective\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n        high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        # Random flips: 1-2 items to maintain diversity\n        if np.random.rand() < 0.5:\n            num_random_flips = np.random.randint(1, 3)\n            candidate_indices = np.random.choice(len(weight_lst), size=num_random_flips, replace=False)\n            for idx in candidate_indices:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Update base solution for next iteration\n        base_solution = new_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.45796954156778535,
            0.38354605436325073
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Iterative improvement with controlled randomness\n    for _ in range(5):\n        # Targeted flips: highest marginal gains in either objective\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n        high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        # Random flips: 1-2 items to maintain diversity\n        if np.random.rand() < 0.5:\n            num_random_flips = np.random.randint(1, 3)\n            candidate_indices = np.random.choice(len(weight_lst), size=num_random_flips, replace=False)\n            for idx in candidate_indices:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Update base solution for next iteration\n        base_solution = new_solution.copy()\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solutions with high crowding distance and high normalized objective sums\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Calculate normalized objective sums\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        normalized_scores = np.ones(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0]/max_obj1 + objectives[:, 1]/max_obj2)\n\n    # Combine crowding and normalized scores\n    combined_scores = crowding * normalized_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate multi-objective marginal gains\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n\n    # Select top items with highest combined marginal gains\n    top_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    # Greedy flips for top gain items\n    for idx in top_gain_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Adaptive perturbation based on solution's position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.4\n        num_perturbations = 2\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n        num_perturbations = 1\n\n    if np.random.rand() < perturbation_prob:\n        # Select items with low combined marginal gains for perturbation\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        selected_perturbations = np.random.choice(low_gain_indices, min(num_perturbations, len(low_gain_indices)), replace=False)\n\n        for idx in selected_perturbations:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Final feasibility check and refinement\n    for _ in range(3):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n        else:\n            # Remove heaviest items to make feasible\n            excess = temp_weight - capacity\n            while excess > 0 and np.any(temp_solution):\n                heaviest_idx = np.argmax(weight_lst * temp_solution)\n                if temp_solution[heaviest_idx] == 1:\n                    temp_solution[heaviest_idx] = 0\n                    excess -= weight_lst[heaviest_idx]\n            new_solution = temp_solution\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects the top 20% of solutions from the archive based on a hybrid score combining normalized objectives (70% value1, 30% value2) and crowding distance. It then performs a two-phase local search: first flipping the top 5 items with highest combined marginal gains (weighted 60% for value1, 40% for value2), followed by probabilistically flipping 1-3 low-marginal-gain items (each with 30% chance) to maintain diversity, while always ensuring feasibility by enforcing capacity constraints.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hybrid score (objective + crowding)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_obj[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_obj[sorted_idx[-1], m] != normalized_obj[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_obj[sorted_idx[i+1], m] - normalized_obj[sorted_idx[i-1], m]) / (normalized_obj[sorted_idx[-1], m] - normalized_obj[sorted_idx[0], m])\n    hybrid_score = 0.7 * normalized_obj[:, 0] + 0.3 * normalized_obj[:, 1] + 0.5 * crowding / (np.max(crowding) + 1e-10)\n    top_indices = np.argsort(-hybrid_score)[:max(1, len(archive)//5)]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Flip top 5 high-marginal-gain items\n    combined_gain = 0.6 * (value1_lst / weight_lst) + 0.4 * (value2_lst / weight_lst)\n    high_gain_indices = np.argsort(-combined_gain)[:5]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Probabilistic flip of low-marginal-gain items\n    low_gain_indices = np.argsort(combined_gain)[:min(10, len(weight_lst))]\n    for idx in np.random.permutation(low_gain_indices):\n        if np.random.rand() < 0.3:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP:\n\n- **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~70)*\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 106,
        "algorithm": "The algorithm prioritizes solutions with high weighted objective values (60% value1, 40% value2) and good crowding distances, then performs a three-phase local search: (1) flipping top-marginal-gain items, (2) probabilistically flipping low-marginal-gain items, and (3) adaptively perturbing with random flips or targeted swaps, all while ensuring feasibility through iterative weight checks. The process repeats 3-5 times to refine the solution.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 25% solutions by weighted objective + crowding\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weighted_obj = 0.6 * normalized_obj[:, 0] + 0.4 * normalized_obj[:, 1]\n\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_obj[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_obj[sorted_idx[-1], m] != normalized_obj[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_obj[sorted_idx[i+1], m] - normalized_obj[sorted_idx[i-1], m]) / (normalized_obj[sorted_idx[-1], m] - normalized_obj[sorted_idx[0], m])\n\n    combined_score = weighted_obj + 0.3 * crowding / (np.max(crowding) + 1e-10)\n    top_indices = np.argsort(-combined_score)[:max(1, len(archive)//4)]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n\n    # Phase 1: Flip top 3 high-marginal-gain items\n    high_gain_indices = np.argsort(-combined_gain)[:3]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 2: Probabilistic flip of low-marginal-gain items\n    low_gain_indices = np.argsort(combined_gain)[:min(8, len(weight_lst))]\n    selected_low = np.random.choice(low_gain_indices, min(4, len(low_gain_indices)), replace=False)\n    for idx in selected_low:\n        if np.random.rand() < 0.4:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 3: Adaptive perturbation\n    if np.random.rand() < 0.3:\n        # Random flip\n        candidate_indices = np.where(combined_gain < np.percentile(combined_gain, 30))[0]\n        if len(candidate_indices) > 0:\n            selected_perturb = np.random.choice(candidate_indices, min(2, len(candidate_indices)), replace=False)\n            for idx in selected_perturb:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n    else:\n        # Targeted swap\n        candidate_indices = np.where(combined_gain < np.percentile(combined_gain, 20))[0]\n        if len(candidate_indices) >= 2:\n            swap_indices = np.random.choice(candidate_indices, 2, replace=False)\n            if base_solution[swap_indices[0]] != base_solution[swap_indices[1]]:\n                if (base_solution[swap_indices[0]] == 1 and base_solution[swap_indices[1]] == 0 and\n                    current_weight - weight_lst[swap_indices[0]] + weight_lst[swap_indices[1]] <= capacity):\n                    new_solution[swap_indices[0]], new_solution[swap_indices[1]] = 0, 1\n                    current_weight = current_weight - weight_lst[swap_indices[0]] + weight_lst[swap_indices[1]]\n                elif (base_solution[swap_indices[0]] == 0 and base_solution[swap_indices[1]] == 1 and\n                      current_weight + weight_lst[swap_indices[0]] - weight_lst[swap_indices[1]] <= capacity):\n                    new_solution[swap_indices[0]], new_solution[swap_indices[1]] = 1, 0\n                    current_weight = current_weight + weight_lst[swap_indices[0]] - weight_lst[swap_indices[1]]\n\n    # Iterative refinement (3-5 times)\n    for _ in range(np.random.randint(3, 6)):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n        else:\n            # Remove heaviest items to make feasible\n            excess = temp_weight - capacity\n            while excess > 0 and np.any(temp_solution):\n                heaviest_idx = np.argmax(weight_lst * temp_solution)\n                if temp_solution[heaviest_idx] == 1:\n                    temp_solution[heaviest_idx] = 0\n                    excess -= weight_lst[heaviest_idx]\n            new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -0.8805217507143923,
            0.6601194441318512
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 25% solutions by weighted objective + crowding\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weighted_obj = 0.6 * normalized_obj[:, 0] + 0.4 * normalized_obj[:, 1]\n\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_obj[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_obj[sorted_idx[-1], m] != normalized_obj[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_obj[sorted_idx[i+1], m] - normalized_obj[sorted_idx[i-1], m]) / (normalized_obj[sorted_idx[-1], m] - normalized_obj[sorted_idx[0], m])\n\n    combined_score = weighted_obj + 0.3 * crowding / (np.max(crowding) + 1e-10)\n    top_indices = np.argsort(-combined_score)[:max(1, len(archive)//4)]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n\n    # Phase 1: Flip top 3 high-marginal-gain items\n    high_gain_indices = np.argsort(-combined_gain)[:3]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 2: Probabilistic flip of low-marginal-gain items\n    low_gain_indices = np.argsort(combined_gain)[:min(8, len(weight_lst))]\n    selected_low = np.random.choice(low_gain_indices, min(4, len(low_gain_indices)), replace=False)\n    for idx in selected_low:\n        if np.random.rand() < 0.4:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 3: Adaptive perturbation\n    if np.random.rand() < 0.3:\n        # Random flip\n        candidate_indices = np.where(combined_gain < np.percentile(combined_gain, 30))[0]\n        if len(candidate_indices) > 0:\n            selected_perturb = np.random.choice(candidate_indices, min(2, len(candidate_indices)), replace=False)\n            for idx in selected_perturb:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n    else:\n        # Targeted swap\n        candidate_indices = np.where(combined_gain < np.percentile(combined_gain, 20))[0]\n        if len(candidate_indices) >= 2:\n            swap_indices = np.random.choice(candidate_indices, 2, replace=False)\n            if base_solution[swap_indices[0]] != base_solution[swap_indices[1]]:\n                if (base_solution[swap_indices[0]] == 1 and base_solution[swap_indices[1]] == 0 and\n                    current_weight - weight_lst[swap_indices[0]] + weight_lst[swap_indices[1]] <= capacity):\n                    new_solution[swap_indices[0]], new_solution[swap_indices[1]] = 0, 1\n                    current_weight = current_weight - weight_lst[swap_indices[0]] + weight_lst[swap_indices[1]]\n                elif (base_solution[swap_indices[0]] == 0 and base_solution[swap_indices[1]] == 1 and\n                      current_weight + weight_lst[swap_indices[0]] - weight_lst[swap_indices[1]] <= capacity):\n                    new_solution[swap_indices[0]], new_solution[swap_indices[1]] = 1, 0\n                    current_weight = current_weight + weight_lst[swap_indices[0]] - weight_lst[swap_indices[1]]\n\n    # Iterative refinement (3-5 times)\n    for _ in range(np.random.randint(3, 6)):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n        else:\n            # Remove heaviest items to make feasible\n            excess = temp_weight - capacity\n            while excess > 0 and np.any(temp_solution):\n                heaviest_idx = np.argmax(weight_lst * temp_solution)\n                if temp_solution[heaviest_idx] == 1:\n                    temp_solution[heaviest_idx] = 0\n                    excess -= weight_lst[heaviest_idx]\n            new_solution = temp_solution\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solutions with high crowding distance and high normalized objective sums\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Calculate normalized objective sums\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        normalized_scores = np.ones(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0]/max_obj1 + objectives[:, 1]/max_obj2)\n\n    # Combine crowding and normalized scores\n    combined_scores = crowding * normalized_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate multi-objective marginal gains\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n\n    # Select top items with highest combined marginal gains\n    top_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    # Greedy flips for top gain items\n    for idx in top_gain_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Adaptive perturbation based on solution's position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.4\n        num_perturbations = 2\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n        num_perturbations = 1\n\n    if np.random.rand() < perturbation_prob:\n        # Select items with low combined marginal gains for perturbation\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        selected_perturbations = np.random.choice(low_gain_indices, min(num_perturbations, len(low_gain_indices)), replace=False)\n\n        for idx in selected_perturbations:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Final feasibility check and refinement\n    for _ in range(3):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n        else:\n            # Remove heaviest items to make feasible\n            excess = temp_weight - capacity\n            while excess > 0 and np.any(temp_solution):\n                heaviest_idx = np.argmax(weight_lst * temp_solution)\n                if temp_solution[heaviest_idx] == 1:\n                    temp_solution[heaviest_idx] = 0\n                    excess -= weight_lst[heaviest_idx]\n            new_solution = temp_solution\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects the top 20% of solutions from the archive based on a hybrid score combining normalized objectives (70% value1, 30% value2) and crowding distance. It then performs a two-phase local search: first flipping the top 5 items with highest combined marginal gains (weighted 60% for value1, 40% for value2), followed by probabilistically flipping 1-3 low-marginal-gain items (each with 30% chance) to maintain diversity, while always ensuring feasibility by enforcing capacity constraints.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hybrid score (objective + crowding)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_obj[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_obj[sorted_idx[-1], m] != normalized_obj[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_obj[sorted_idx[i+1], m] - normalized_obj[sorted_idx[i-1], m]) / (normalized_obj[sorted_idx[-1], m] - normalized_obj[sorted_idx[0], m])\n    hybrid_score = 0.7 * normalized_obj[:, 0] + 0.3 * normalized_obj[:, 1] + 0.5 * crowding / (np.max(crowding) + 1e-10)\n    top_indices = np.argsort(-hybrid_score)[:max(1, len(archive)//5)]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Flip top 5 high-marginal-gain items\n    combined_gain = 0.6 * (value1_lst / weight_lst) + 0.4 * (value2_lst / weight_lst)\n    high_gain_indices = np.argsort(-combined_gain)[:5]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Probabilistic flip of low-marginal-gain items\n    low_gain_indices = np.argsort(combined_gain)[:min(10, len(weight_lst))]\n    for idx in np.random.permutation(low_gain_indices):\n        if np.random.rand() < 0.3:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP:\n\n- **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~70)*\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 107,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solutions with high normalized objective sums and crowding distance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate normalized objective sums\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        normalized_scores = np.ones(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0]/max_obj1 + objectives[:, 1]/max_obj2)\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Combine scores and select top 20% solutions\n    combined_scores = normalized_scores * crowding\n    top_indices = np.argsort(-combined_scores)[:max(1, len(archive)//5)]\n    selected_idx = np.random.choice(top_indices)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate multi-objective marginal gains\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n\n    # Iterative refinement with 5-10 iterations\n    for _ in range(np.random.randint(5, 11)):\n        # Flip items with highest marginal gains\n        top_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n        for idx in top_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        # Add 1-2 random flips from low-marginal-gain items\n        low_gain_indices = np.argsort(combined_gain)[:min(10, len(weight_lst))]\n        random_flips = np.random.choice(low_gain_indices, min(2, len(low_gain_indices)), replace=False)\n        for idx in random_flips:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        # Ensure feasibility\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight > capacity:\n            excess = temp_weight - capacity\n            while excess > 0 and np.any(new_solution):\n                heaviest_idx = np.argmax(weight_lst * new_solution)\n                if new_solution[heaviest_idx] == 1:\n                    new_solution[heaviest_idx] = 0\n                    excess -= weight_lst[heaviest_idx]\n            current_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n",
        "score": [
            -0.6727930117073955,
            0.8259800374507904
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solutions with high normalized objective sums and crowding distance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate normalized objective sums\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        normalized_scores = np.ones(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0]/max_obj1 + objectives[:, 1]/max_obj2)\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Combine scores and select top 20% solutions\n    combined_scores = normalized_scores * crowding\n    top_indices = np.argsort(-combined_scores)[:max(1, len(archive)//5)]\n    selected_idx = np.random.choice(top_indices)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate multi-objective marginal gains\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n\n    # Iterative refinement with 5-10 iterations\n    for _ in range(np.random.randint(5, 11)):\n        # Flip items with highest marginal gains\n        top_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n        for idx in top_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        # Add 1-2 random flips from low-marginal-gain items\n        low_gain_indices = np.argsort(combined_gain)[:min(10, len(weight_lst))]\n        random_flips = np.random.choice(low_gain_indices, min(2, len(low_gain_indices)), replace=False)\n        for idx in random_flips:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        # Ensure feasibility\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight > capacity:\n            excess = temp_weight - capacity\n            while excess > 0 and np.any(new_solution):\n                heaviest_idx = np.argmax(weight_lst * new_solution)\n                if new_solution[heaviest_idx] == 1:\n                    new_solution[heaviest_idx] = 0\n                    excess -= weight_lst[heaviest_idx]\n            current_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects the top 20% of solutions from the archive based on a hybrid score combining normalized objectives (70% value1, 30% value2) and crowding distance. It then performs a two-phase local search: first flipping the top 5 items with highest combined marginal gains (weighted 60% for value1, 40% for value2), followed by probabilistically flipping 1-3 low-marginal-gain items (each with 30% chance) to maintain diversity, while always ensuring feasibility by enforcing capacity constraints.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hybrid score (objective + crowding)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_obj[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_obj[sorted_idx[-1], m] != normalized_obj[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_obj[sorted_idx[i+1], m] - normalized_obj[sorted_idx[i-1], m]) / (normalized_obj[sorted_idx[-1], m] - normalized_obj[sorted_idx[0], m])\n    hybrid_score = 0.7 * normalized_obj[:, 0] + 0.3 * normalized_obj[:, 1] + 0.5 * crowding / (np.max(crowding) + 1e-10)\n    top_indices = np.argsort(-hybrid_score)[:max(1, len(archive)//5)]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Flip top 5 high-marginal-gain items\n    combined_gain = 0.6 * (value1_lst / weight_lst) + 0.4 * (value2_lst / weight_lst)\n    high_gain_indices = np.argsort(-combined_gain)[:5]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Probabilistic flip of low-marginal-gain items\n    low_gain_indices = np.argsort(combined_gain)[:min(10, len(weight_lst))]\n    for idx in np.random.permutation(low_gain_indices):\n        if np.random.rand() < 0.3:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 108,
        "algorithm": "The algorithm selects the top 15% of non-dominated solutions from the archive based on a weighted combination of normalized objectives (60% value1, 40% value2) and diversity, then applies a three-phase local search: flipping high-marginal-gain items (Phase 1), low-marginal-gain items below a dynamic threshold (Phase 2), and probabilistically flipping near-zero-gain items (Phase 3) to balance exploration and exploitation while ensuring feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 15% solutions by dynamic weight score (objective + diversity)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    diversity = np.zeros(len(archive))\n    for i in range(len(archive)):\n        diversity[i] = np.sum([np.linalg.norm(archive[i][0] - archive[j][0]) for j in range(len(archive)) if i != j]) / (len(archive) - 1)\n    dynamic_score = 0.6 * normalized_obj[:, 0] + 0.4 * normalized_obj[:, 1] + 0.3 * (diversity / (np.max(diversity) + 1e-10))\n    top_indices = np.argsort(-dynamic_score)[:max(1, len(archive)//7)]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Flip top 3 high-marginal-gain items (50-50 weighted)\n    combined_gain = 0.5 * (value1_lst / weight_lst) + 0.5 * (value2_lst / weight_lst)\n    high_gain_indices = np.argsort(-combined_gain)[:3]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Flip items with marginal gains below dynamic threshold (20% of average gain)\n    avg_gain = np.mean(combined_gain)\n    threshold = 0.2 * avg_gain\n    low_gain_indices = np.where(combined_gain < threshold)[0]\n    for idx in np.random.permutation(low_gain_indices):\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 3: Probabilistic flip of items with gains closest to zero (50% chance each)\n    zero_gain_indices = np.argsort(np.abs(combined_gain))[:min(5, len(weight_lst))]\n    for idx in np.random.permutation(zero_gain_indices):\n        if np.random.rand() < 0.5:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.5220213935818387,
            1.1951468288898468
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 15% solutions by dynamic weight score (objective + diversity)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    diversity = np.zeros(len(archive))\n    for i in range(len(archive)):\n        diversity[i] = np.sum([np.linalg.norm(archive[i][0] - archive[j][0]) for j in range(len(archive)) if i != j]) / (len(archive) - 1)\n    dynamic_score = 0.6 * normalized_obj[:, 0] + 0.4 * normalized_obj[:, 1] + 0.3 * (diversity / (np.max(diversity) + 1e-10))\n    top_indices = np.argsort(-dynamic_score)[:max(1, len(archive)//7)]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Flip top 3 high-marginal-gain items (50-50 weighted)\n    combined_gain = 0.5 * (value1_lst / weight_lst) + 0.5 * (value2_lst / weight_lst)\n    high_gain_indices = np.argsort(-combined_gain)[:3]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Flip items with marginal gains below dynamic threshold (20% of average gain)\n    avg_gain = np.mean(combined_gain)\n    threshold = 0.2 * avg_gain\n    low_gain_indices = np.where(combined_gain < threshold)[0]\n    for idx in np.random.permutation(low_gain_indices):\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 3: Probabilistic flip of items with gains closest to zero (50% chance each)\n    zero_gain_indices = np.argsort(np.abs(combined_gain))[:min(5, len(weight_lst))]\n    for idx in np.random.permutation(zero_gain_indices):\n        if np.random.rand() < 0.5:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects the top 20% of solutions from the archive based on a hybrid score combining normalized objectives (70% value1, 30% value2) and crowding distance. It then performs a two-phase local search: first flipping the top 5 items with highest combined marginal gains (weighted 60% for value1, 40% for value2), followed by probabilistically flipping 1-3 low-marginal-gain items (each with 30% chance) to maintain diversity, while always ensuring feasibility by enforcing capacity constraints.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hybrid score (objective + crowding)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_obj[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_obj[sorted_idx[-1], m] != normalized_obj[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_obj[sorted_idx[i+1], m] - normalized_obj[sorted_idx[i-1], m]) / (normalized_obj[sorted_idx[-1], m] - normalized_obj[sorted_idx[0], m])\n    hybrid_score = 0.7 * normalized_obj[:, 0] + 0.3 * normalized_obj[:, 1] + 0.5 * crowding / (np.max(crowding) + 1e-10)\n    top_indices = np.argsort(-hybrid_score)[:max(1, len(archive)//5)]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Flip top 5 high-marginal-gain items\n    combined_gain = 0.6 * (value1_lst / weight_lst) + 0.4 * (value2_lst / weight_lst)\n    high_gain_indices = np.argsort(-combined_gain)[:5]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Probabilistic flip of low-marginal-gain items\n    low_gain_indices = np.argsort(combined_gain)[:min(10, len(weight_lst))]\n    for idx in np.random.permutation(low_gain_indices):\n        if np.random.rand() < 0.3:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 109,
        "algorithm": "The algorithm selects top 30% solutions from the archive based on a hybrid score combining normalized objectives (60% value1, 40% value2) and crowding distance, then performs a three-phase local search: first flipping high-marginal-gain items (weighted 50-50 for both objectives), followed by probabilistic flips of medium-marginal-gain items (40% chance), and finally flipping low-marginal-gain items (20% chance) to explore diverse neighborhoods while maintaining feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by hybrid score (objective + crowding)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_obj[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_obj[sorted_idx[-1], m] != normalized_obj[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_obj[sorted_idx[i+1], m] - normalized_obj[sorted_idx[i-1], m]) / (normalized_obj[sorted_idx[-1], m] - normalized_obj[sorted_idx[0], m])\n    hybrid_score = 0.6 * normalized_obj[:, 0] + 0.4 * normalized_obj[:, 1] + 0.5 * crowding / (np.max(crowding) + 1e-10)\n    top_indices = np.argsort(-hybrid_score)[:max(1, len(archive)//3)]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Flip top 8 high-marginal-gain items\n    combined_gain = 0.5 * (value1_lst / weight_lst) + 0.5 * (value2_lst / weight_lst)\n    high_gain_indices = np.argsort(-combined_gain)[:8]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Probabilistic flip of medium-marginal-gain items\n    medium_gain_indices = np.argsort(-combined_gain)[8:min(15, len(weight_lst))]\n    for idx in np.random.permutation(medium_gain_indices):\n        if np.random.rand() < 0.4:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 3: Probabilistic flip of low-marginal-gain items\n    low_gain_indices = np.argsort(combined_gain)[:min(10, len(weight_lst))]\n    for idx in np.random.permutation(low_gain_indices):\n        if np.random.rand() < 0.2:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8982746992300155,
            0.5107226371765137
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by hybrid score (objective + crowding)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_obj[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_obj[sorted_idx[-1], m] != normalized_obj[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_obj[sorted_idx[i+1], m] - normalized_obj[sorted_idx[i-1], m]) / (normalized_obj[sorted_idx[-1], m] - normalized_obj[sorted_idx[0], m])\n    hybrid_score = 0.6 * normalized_obj[:, 0] + 0.4 * normalized_obj[:, 1] + 0.5 * crowding / (np.max(crowding) + 1e-10)\n    top_indices = np.argsort(-hybrid_score)[:max(1, len(archive)//3)]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Flip top 8 high-marginal-gain items\n    combined_gain = 0.5 * (value1_lst / weight_lst) + 0.5 * (value2_lst / weight_lst)\n    high_gain_indices = np.argsort(-combined_gain)[:8]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Probabilistic flip of medium-marginal-gain items\n    medium_gain_indices = np.argsort(-combined_gain)[8:min(15, len(weight_lst))]\n    for idx in np.random.permutation(medium_gain_indices):\n        if np.random.rand() < 0.4:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 3: Probabilistic flip of low-marginal-gain items\n    low_gain_indices = np.argsort(combined_gain)[:min(10, len(weight_lst))]\n    for idx in np.random.permutation(low_gain_indices):\n        if np.random.rand() < 0.2:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 5 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects the top 20% of solutions from the archive based on a hybrid score combining normalized objectives (70% value1, 30% value2) and crowding distance. It then performs a two-phase local search: first flipping the top 5 items with highest combined marginal gains (weighted 60% for value1, 40% for value2), followed by probabilistically flipping 1-3 low-marginal-gain items (each with 30% chance) to maintain diversity, while always ensuring feasibility by enforcing capacity constraints.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hybrid score (objective + crowding)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_obj[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_obj[sorted_idx[-1], m] != normalized_obj[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_obj[sorted_idx[i+1], m] - normalized_obj[sorted_idx[i-1], m]) / (normalized_obj[sorted_idx[-1], m] - normalized_obj[sorted_idx[0], m])\n    hybrid_score = 0.7 * normalized_obj[:, 0] + 0.3 * normalized_obj[:, 1] + 0.5 * crowding / (np.max(crowding) + 1e-10)\n    top_indices = np.argsort(-hybrid_score)[:max(1, len(archive)//5)]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Flip top 5 high-marginal-gain items\n    combined_gain = 0.6 * (value1_lst / weight_lst) + 0.4 * (value2_lst / weight_lst)\n    high_gain_indices = np.argsort(-combined_gain)[:5]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Probabilistic flip of low-marginal-gain items\n    low_gain_indices = np.argsort(combined_gain)[:min(10, len(weight_lst))]\n    for idx in np.random.permutation(low_gain_indices):\n        if np.random.rand() < 0.3:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid of crowding distance and objective trade-off analysis, then applies a novel local search that alternates between targeted item swaps (prioritizing high-value items with trade-off considerations) and probabilistic flips (removing low-value items with dynamic probability), while ensuring feasibility through constrained capacity checks. The selection prioritizes solutions with high crowding distance (indicating potential for improvement) and adjusts perturbation probabilities based on the solution's position in the Pareto front and its objective trade-offs.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine objective dominance and adaptive crowding\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate normalized crowding distances\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate objective trade-offs\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    avg_trade_off = np.mean(trade_off)\n\n    # Alternating objective improvement with trade-off consideration\n    if np.random.rand() < 0.5 or trade_off[selected_idx] < avg_trade_off:\n        # Improve first objective with trade-off consideration\n        gain = (value1_lst + 0.3 * value2_lst) / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective with trade-off consideration\n        gain = (value2_lst + 0.3 * value1_lst) / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Targeted item swaps with feasibility check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position and trade-off\n    perturbation_prob = 0.3 if trade_off[selected_idx] < avg_trade_off else 0.6\n    if np.random.rand() < perturbation_prob:\n        # Select items with poor value-to-weight ratio for potential removal\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        poor_ratio_indices = np.argsort(value_ratio)[:min(5, len(weight_lst))]\n        for idx in poor_ratio_indices:\n            if np.random.rand() < 0.5 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP:\n\n- **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~70)*\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 110,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n\n    # Iterative refinement: perform 5-10 iterations of targeted flips\n    for _ in range(np.random.randint(5, 11)):\n        # Flip items with highest marginal gains first\n        high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Add 1-2 random flips to maintain diversity\n        for _ in range(np.random.randint(1, 3)):\n            candidate_idx = np.random.randint(len(weight_lst))\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3218856489990852,
            0.4444994628429413
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n\n    # Iterative refinement: perform 5-10 iterations of targeted flips\n    for _ in range(np.random.randint(5, 11)):\n        # Flip items with highest marginal gains first\n        high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Add 1-2 random flips to maintain diversity\n        for _ in range(np.random.randint(1, 3)):\n            candidate_idx = np.random.randint(len(weight_lst))\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 4 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s the refined heuristic design for the BI-KP:\n\n- **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~70)*\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 111,
        "algorithm": "The algorithm selects promising solutions from the top 20% of the archive (by normalized objective sums), prioritizes flipping items with high marginal gains (either objective), and adds 1-2 random flips while maintaining feasibility. It then iteratively refines the solution 5-10 times to balance exploitation and exploration, ensuring the neighbor solution remains feasible. The approach combines targeted local search with randomness to improve solution quality across both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips (ensuring feasibility)\n    num_random_flips = np.random.randint(1, 3)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement: repeat 5-10 times\n    for _ in range(np.random.randint(5, 11)):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.8821003413293171,
            0.22137275338172913
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips (ensuring feasibility)\n    num_random_flips = np.random.randint(1, 3)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement: repeat 5-10 times\n    for _ in range(np.random.randint(5, 11)):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP:\n\n- **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~70)*\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 112,
        "algorithm": "The algorithm combines a selection strategy favoring solutions with high normalized objective sums with a two-phase local search: first iteratively flipping high-marginal-gain items (prioritizing either objective 1 or 2 with 60% probability), followed by a controlled perturbation that flips low-contribution items with probabilistic checks to maintain feasibility. The method balances exploitation of high-value items with strategic exploration of low-contribution items to escape local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Iterative refinement with marginal gains\n    for _ in range(5):\n        # Calculate marginal gains for both objectives\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n\n        # Select items with highest marginal gains\n        if np.random.rand() < 0.6:\n            # Prioritize objective 1\n            sorted_indices = np.argsort(-marginal_gain1)\n        else:\n            # Prioritize objective 2\n            sorted_indices = np.argsort(-marginal_gain2)\n\n        # Flip top 20% items if feasible\n        flip_count = max(1, len(sorted_indices) // 5)\n        for idx in sorted_indices[:flip_count]:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled perturbation\n    if np.random.rand() < 0.4:\n        # Calculate marginal contributions\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        # Flip low-contribution items with higher probability\n        low_contrib_indices = np.argsort(marginal_contribution)[:len(weight_lst) // 2]\n        for idx in low_contrib_indices:\n            if np.random.rand() < 0.3 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif np.random.rand() < 0.3 and base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.5957586989522541,
            0.555633008480072
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Iterative refinement with marginal gains\n    for _ in range(5):\n        # Calculate marginal gains for both objectives\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n\n        # Select items with highest marginal gains\n        if np.random.rand() < 0.6:\n            # Prioritize objective 1\n            sorted_indices = np.argsort(-marginal_gain1)\n        else:\n            # Prioritize objective 2\n            sorted_indices = np.argsort(-marginal_gain2)\n\n        # Flip top 20% items if feasible\n        flip_count = max(1, len(sorted_indices) // 5)\n        for idx in sorted_indices[:flip_count]:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled perturbation\n    if np.random.rand() < 0.4:\n        # Calculate marginal contributions\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        # Flip low-contribution items with higher probability\n        low_contrib_indices = np.argsort(marginal_contribution)[:len(weight_lst) // 2]\n        for idx in low_contrib_indices:\n            if np.random.rand() < 0.3 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif np.random.rand() < 0.3 and base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a solution from the archive using an adaptive weighted crowding distance metric that balances dominance rank and objective trade-offs, then applies a hybrid local search combining targeted item swaps (prioritizing high-value items with dynamic weights) and probabilistic flips (removing low-value items with solution-specific probabilities), while ensuring feasibility through capacity checks. The selection prioritizes solutions near the Pareto front (lower dominance rank) and those with high crowding distance, while the local search dynamically adjusts trade-off weights based on the solution's position in the objective space.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive weighted crowding selection\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate dominance ranks\n    dominance = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]) and \\\n                   (objectives[i, 0] > objectives[j, 0] or objectives[i, 1] > objectives[j, 1]):\n                    dominance[i] += 1\n\n    # Normalize objectives and calculate weighted crowding\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1 / (1 + dominance)\n    weighted_crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_obj[:, m])\n        weighted_crowding[sorted_idx[0]] = np.inf\n        weighted_crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_obj[sorted_idx[-1], m] != normalized_obj[sorted_idx[0], m]:\n                weighted_crowding[sorted_idx[i]] += weights[sorted_idx[i]] * (normalized_obj[sorted_idx[i+1], m] - normalized_obj[sorted_idx[i-1], m]) / (normalized_obj[sorted_idx[-1], m] - normalized_obj[sorted_idx[0], m])\n\n    # Select solution with highest weighted crowding\n    selected_idx = np.argmax(weighted_crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dynamic trade-off weights based on solution's position\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    avg_trade_off = np.mean(trade_off)\n    w1 = 0.7 if trade_off[selected_idx] < avg_trade_off else 0.3\n    w2 = 1 - w1\n\n    # Targeted item swaps with dynamic weights\n    gain = (w1 * value1_lst + w2 * value2_lst) / weight_lst\n    sorted_indices = np.argsort(-gain)\n\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Solution-specific perturbation\n    perturbation_prob = 0.4 - 0.2 * (objectives[selected_idx, 0] + objectives[selected_idx, 1]) / (np.max(objectives) + 1e-10)\n    if np.random.rand() < perturbation_prob:\n        value_ratio = (value1_lst + value2_lst) / (2 * weight_lst)\n        poor_ratio_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in poor_ratio_indices:\n            if np.random.rand() < 0.6 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP:\n\n- **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~70)*\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 113,
        "algorithm": "The algorithm combines a selection strategy that prioritizes top 20% solutions by normalized objective sums with a novel \"marginal gain ratio tournament\" local search. It iteratively flips items based on their combined marginal gains (value1/weight + value2/weight) in a tournament-style competition, while dynamically adjusting perturbation probabilities to balance exploitation and exploration, and ensuring feasibility through capacity checks and occasional random flips (10% chance). The method emphasizes high-margin items while adaptively escaping local optima through quality-driven perturbations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    objective_sums = normalized_obj.sum(axis=1)\n    top_indices = np.argsort(objective_sums)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(top_indices)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain ratio tournament local search\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    n_items = len(weight_lst)\n\n    for _ in range(np.random.randint(3, 6)):\n        # Tournament selection\n        tournament_size = min(5, n_items)\n        candidates = np.random.choice(n_items, tournament_size, replace=False)\n        winner = candidates[np.argmax(combined_gain[candidates])]\n\n        # Flip the winner if feasible\n        if base_solution[winner] == 1:\n            if current_weight - weight_lst[winner] <= capacity:\n                new_solution[winner] = 0\n                current_weight -= weight_lst[winner]\n        else:\n            if current_weight + weight_lst[winner] <= capacity:\n                new_solution[winner] = 1\n                current_weight += weight_lst[winner]\n\n        # Dynamic perturbation (increase probability with solution quality)\n        perturbation_prob = 0.1 + 0.1 * (objectives[selected_idx, 0] + objectives[selected_idx, 1]) / (np.max(objectives) + 1e-10)\n        if np.random.rand() < perturbation_prob:\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.40596763028002636,
            0.39446622133255005
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    objective_sums = normalized_obj.sum(axis=1)\n    top_indices = np.argsort(objective_sums)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(top_indices)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain ratio tournament local search\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    n_items = len(weight_lst)\n\n    for _ in range(np.random.randint(3, 6)):\n        # Tournament selection\n        tournament_size = min(5, n_items)\n        candidates = np.random.choice(n_items, tournament_size, replace=False)\n        winner = candidates[np.argmax(combined_gain[candidates])]\n\n        # Flip the winner if feasible\n        if base_solution[winner] == 1:\n            if current_weight - weight_lst[winner] <= capacity:\n                new_solution[winner] = 0\n                current_weight -= weight_lst[winner]\n        else:\n            if current_weight + weight_lst[winner] <= capacity:\n                new_solution[winner] = 1\n                current_weight += weight_lst[winner]\n\n        # Dynamic perturbation (increase probability with solution quality)\n        perturbation_prob = 0.1 + 0.1 * (objectives[selected_idx, 0] + objectives[selected_idx, 1]) / (np.max(objectives) + 1e-10)\n        if np.random.rand() < perturbation_prob:\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a solution from the archive using an adaptive weighted crowding distance metric that balances dominance rank and objective trade-offs, then applies a hybrid local search combining targeted item swaps (prioritizing high-value items with dynamic weights) and probabilistic flips (removing low-value items with solution-specific probabilities), while ensuring feasibility through capacity checks. The selection prioritizes solutions near the Pareto front (lower dominance rank) and those with high crowding distance, while the local search dynamically adjusts trade-off weights based on the solution's position in the objective space.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive weighted crowding selection\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate dominance ranks\n    dominance = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]) and \\\n                   (objectives[i, 0] > objectives[j, 0] or objectives[i, 1] > objectives[j, 1]):\n                    dominance[i] += 1\n\n    # Normalize objectives and calculate weighted crowding\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1 / (1 + dominance)\n    weighted_crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_obj[:, m])\n        weighted_crowding[sorted_idx[0]] = np.inf\n        weighted_crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_obj[sorted_idx[-1], m] != normalized_obj[sorted_idx[0], m]:\n                weighted_crowding[sorted_idx[i]] += weights[sorted_idx[i]] * (normalized_obj[sorted_idx[i+1], m] - normalized_obj[sorted_idx[i-1], m]) / (normalized_obj[sorted_idx[-1], m] - normalized_obj[sorted_idx[0], m])\n\n    # Select solution with highest weighted crowding\n    selected_idx = np.argmax(weighted_crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dynamic trade-off weights based on solution's position\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    avg_trade_off = np.mean(trade_off)\n    w1 = 0.7 if trade_off[selected_idx] < avg_trade_off else 0.3\n    w2 = 1 - w1\n\n    # Targeted item swaps with dynamic weights\n    gain = (w1 * value1_lst + w2 * value2_lst) / weight_lst\n    sorted_indices = np.argsort(-gain)\n\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Solution-specific perturbation\n    perturbation_prob = 0.4 - 0.2 * (objectives[selected_idx, 0] + objectives[selected_idx, 1]) / (np.max(objectives) + 1e-10)\n    if np.random.rand() < perturbation_prob:\n        value_ratio = (value1_lst + value2_lst) / (2 * weight_lst)\n        poor_ratio_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in poor_ratio_indices:\n            if np.random.rand() < 0.6 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP:\n\n- **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~70)*\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 114,
        "algorithm": "The algorithm combines adaptive solution selection (prioritizing non-dominated solutions with high marginal gain diversity) with a hybrid local search that first flips high-marginal-gain items deterministically, then probabilistically flips low-marginal-gain items based on dynamic trade-off weights, while ensuring feasibility through iterative capacity checks. The selection emphasizes both dominance and gain diversity (70% dominance, 30% gain diversity), and the local search adapts flip probabilities based on solution quality and objective trade-offs.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate dominance ranks\n    dominance = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]) and \\\n                   (objectives[i, 0] > objectives[j, 0] or objectives[i, 1] > objectives[j, 1]):\n                    dominance[i] += 1\n\n    # Calculate marginal gain diversity\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    gain_diversity = np.zeros(len(archive))\n    for i in range(len(archive)):\n        selected_items = solutions[i]\n        gain_diversity[i] = np.std(marginal_gain1[selected_items == 1]) + np.std(marginal_gain2[selected_items == 1])\n\n    # Combine dominance and gain diversity for selection\n    combined_score = (1 - dominance / (len(archive) - 1)) * 0.7 + (gain_diversity / np.max(gain_diversity)) * 0.3\n    selected_idx = np.argmax(combined_score)\n\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dynamic trade-off weights based on solution's position\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    avg_trade_off = np.mean(trade_off)\n    w1 = 0.6 if trade_off[selected_idx] < avg_trade_off else 0.4\n    w2 = 1 - w1\n\n    # Targeted flips based on combined marginal gains\n    combined_gain = (w1 * marginal_gain1 + w2 * marginal_gain2)\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Controlled probabilistic flips of low-marginal-gain items\n    low_gain_mask = (combined_gain < np.percentile(combined_gain, 30))\n    low_gain_indices = np.where(low_gain_mask)[0]\n\n    for idx in low_gain_indices:\n        flip_prob = 0.2 * (1 - (objectives[selected_idx, 0] + objectives[selected_idx, 1]) / (np.max(objectives) + 1e-10))\n        if np.random.rand() < flip_prob:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement\n    for _ in range(3):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.9191392953515163,
            2.8886126577854156
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate dominance ranks\n    dominance = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]) and \\\n                   (objectives[i, 0] > objectives[j, 0] or objectives[i, 1] > objectives[j, 1]):\n                    dominance[i] += 1\n\n    # Calculate marginal gain diversity\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    gain_diversity = np.zeros(len(archive))\n    for i in range(len(archive)):\n        selected_items = solutions[i]\n        gain_diversity[i] = np.std(marginal_gain1[selected_items == 1]) + np.std(marginal_gain2[selected_items == 1])\n\n    # Combine dominance and gain diversity for selection\n    combined_score = (1 - dominance / (len(archive) - 1)) * 0.7 + (gain_diversity / np.max(gain_diversity)) * 0.3\n    selected_idx = np.argmax(combined_score)\n\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dynamic trade-off weights based on solution's position\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    avg_trade_off = np.mean(trade_off)\n    w1 = 0.6 if trade_off[selected_idx] < avg_trade_off else 0.4\n    w2 = 1 - w1\n\n    # Targeted flips based on combined marginal gains\n    combined_gain = (w1 * marginal_gain1 + w2 * marginal_gain2)\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Controlled probabilistic flips of low-marginal-gain items\n    low_gain_mask = (combined_gain < np.percentile(combined_gain, 30))\n    low_gain_indices = np.where(low_gain_mask)[0]\n\n    for idx in low_gain_indices:\n        flip_prob = 0.2 * (1 - (objectives[selected_idx, 0] + objectives[selected_idx, 1]) / (np.max(objectives) + 1e-10))\n        if np.random.rand() < flip_prob:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement\n    for _ in range(3):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a solution from the archive using an adaptive weighted crowding distance metric that balances dominance rank and objective trade-offs, then applies a hybrid local search combining targeted item swaps (prioritizing high-value items with dynamic weights) and probabilistic flips (removing low-value items with solution-specific probabilities), while ensuring feasibility through capacity checks. The selection prioritizes solutions near the Pareto front (lower dominance rank) and those with high crowding distance, while the local search dynamically adjusts trade-off weights based on the solution's position in the objective space.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive weighted crowding selection\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate dominance ranks\n    dominance = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]) and \\\n                   (objectives[i, 0] > objectives[j, 0] or objectives[i, 1] > objectives[j, 1]):\n                    dominance[i] += 1\n\n    # Normalize objectives and calculate weighted crowding\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1 / (1 + dominance)\n    weighted_crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_obj[:, m])\n        weighted_crowding[sorted_idx[0]] = np.inf\n        weighted_crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_obj[sorted_idx[-1], m] != normalized_obj[sorted_idx[0], m]:\n                weighted_crowding[sorted_idx[i]] += weights[sorted_idx[i]] * (normalized_obj[sorted_idx[i+1], m] - normalized_obj[sorted_idx[i-1], m]) / (normalized_obj[sorted_idx[-1], m] - normalized_obj[sorted_idx[0], m])\n\n    # Select solution with highest weighted crowding\n    selected_idx = np.argmax(weighted_crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dynamic trade-off weights based on solution's position\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    avg_trade_off = np.mean(trade_off)\n    w1 = 0.7 if trade_off[selected_idx] < avg_trade_off else 0.3\n    w2 = 1 - w1\n\n    # Targeted item swaps with dynamic weights\n    gain = (w1 * value1_lst + w2 * value2_lst) / weight_lst\n    sorted_indices = np.argsort(-gain)\n\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Solution-specific perturbation\n    perturbation_prob = 0.4 - 0.2 * (objectives[selected_idx, 0] + objectives[selected_idx, 1]) / (np.max(objectives) + 1e-10)\n    if np.random.rand() < perturbation_prob:\n        value_ratio = (value1_lst + value2_lst) / (2 * weight_lst)\n        poor_ratio_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in poor_ratio_indices:\n            if np.random.rand() < 0.6 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 115,
        "algorithm": "The algorithm selects a promising solution from the archive using a hybrid criterion combining dominance rank and objective trade-off entropy, then applies a dynamic local search that prioritizes items based on their marginal contribution to both objectives, with adaptive perturbation probabilities that depend on the solution's position in the Pareto front and its trade-off characteristics. It ensures feasibility by always checking weight constraints during modifications. The key innovations are the entropy-based selection and adaptive marginal contribution-based search with perturbation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection using dominance rank and objective trade-off entropy\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate dominance ranks\n    dominance = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]) and \\\n                   (objectives[i, 0] > objectives[j, 0] or objectives[i, 1] > objectives[j, 1]):\n                    dominance[i] += 1\n\n    # Calculate objective trade-off entropy\n    trade_offs = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    trade_off_probs = trade_offs / np.sum(trade_offs)\n    entropy = -np.sum(trade_off_probs * np.log(trade_off_probs + 1e-10))\n\n    # Hybrid selection score\n    selection_scores = (1 - dominance / np.max(dominance + 1e-10)) * (1 + entropy)\n    selected_idx = np.argmax(selection_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dynamic marginal contribution calculation\n    marginal_contrib = np.zeros(len(weight_lst))\n    for i in range(len(weight_lst)):\n        if base_solution[i] == 1:\n            marginal_contrib[i] = -weight_lst[i] * (value1_lst[i] + value2_lst[i])\n        else:\n            if current_weight + weight_lst[i] <= capacity:\n                marginal_contrib[i] = weight_lst[i] * (value1_lst[i] + value2_lst[i])\n            else:\n                marginal_contrib[i] = -np.inf\n\n    # Prioritize items with highest marginal contribution\n    sorted_indices = np.argsort(-marginal_contrib)\n    for idx in sorted_indices:\n        if marginal_contrib[idx] > 0:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Adaptive perturbation based on solution characteristics\n    front_distance = np.linalg.norm(objectives[selected_idx] - np.min(objectives, axis=0))\n    max_distance = np.linalg.norm(np.max(objectives, axis=0) - np.min(objectives, axis=0))\n    perturbation_prob = 0.3 * (1 - front_distance / (max_distance + 1e-10)) + 0.1\n\n    if np.random.rand() < perturbation_prob:\n        value_ratio = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        poor_ratio_indices = np.argsort(value_ratio)[:min(5, len(weight_lst))]\n        for idx in poor_ratio_indices:\n            if np.random.rand() < 0.5 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8943113067016399,
            1.0372830927371979
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection using dominance rank and objective trade-off entropy\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate dominance ranks\n    dominance = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]) and \\\n                   (objectives[i, 0] > objectives[j, 0] or objectives[i, 1] > objectives[j, 1]):\n                    dominance[i] += 1\n\n    # Calculate objective trade-off entropy\n    trade_offs = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    trade_off_probs = trade_offs / np.sum(trade_offs)\n    entropy = -np.sum(trade_off_probs * np.log(trade_off_probs + 1e-10))\n\n    # Hybrid selection score\n    selection_scores = (1 - dominance / np.max(dominance + 1e-10)) * (1 + entropy)\n    selected_idx = np.argmax(selection_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dynamic marginal contribution calculation\n    marginal_contrib = np.zeros(len(weight_lst))\n    for i in range(len(weight_lst)):\n        if base_solution[i] == 1:\n            marginal_contrib[i] = -weight_lst[i] * (value1_lst[i] + value2_lst[i])\n        else:\n            if current_weight + weight_lst[i] <= capacity:\n                marginal_contrib[i] = weight_lst[i] * (value1_lst[i] + value2_lst[i])\n            else:\n                marginal_contrib[i] = -np.inf\n\n    # Prioritize items with highest marginal contribution\n    sorted_indices = np.argsort(-marginal_contrib)\n    for idx in sorted_indices:\n        if marginal_contrib[idx] > 0:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Adaptive perturbation based on solution characteristics\n    front_distance = np.linalg.norm(objectives[selected_idx] - np.min(objectives, axis=0))\n    max_distance = np.linalg.norm(np.max(objectives, axis=0) - np.min(objectives, axis=0))\n    perturbation_prob = 0.3 * (1 - front_distance / (max_distance + 1e-10)) + 0.1\n\n    if np.random.rand() < perturbation_prob:\n        value_ratio = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        poor_ratio_indices = np.argsort(value_ratio)[:min(5, len(weight_lst))]\n        for idx in poor_ratio_indices:\n            if np.random.rand() < 0.5 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a solution from the archive using an adaptive weighted crowding distance metric that balances dominance rank and objective trade-offs, then applies a hybrid local search combining targeted item swaps (prioritizing high-value items with dynamic weights) and probabilistic flips (removing low-value items with solution-specific probabilities), while ensuring feasibility through capacity checks. The selection prioritizes solutions near the Pareto front (lower dominance rank) and those with high crowding distance, while the local search dynamically adjusts trade-off weights based on the solution's position in the objective space.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive weighted crowding selection\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate dominance ranks\n    dominance = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]) and \\\n                   (objectives[i, 0] > objectives[j, 0] or objectives[i, 1] > objectives[j, 1]):\n                    dominance[i] += 1\n\n    # Normalize objectives and calculate weighted crowding\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1 / (1 + dominance)\n    weighted_crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_obj[:, m])\n        weighted_crowding[sorted_idx[0]] = np.inf\n        weighted_crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_obj[sorted_idx[-1], m] != normalized_obj[sorted_idx[0], m]:\n                weighted_crowding[sorted_idx[i]] += weights[sorted_idx[i]] * (normalized_obj[sorted_idx[i+1], m] - normalized_obj[sorted_idx[i-1], m]) / (normalized_obj[sorted_idx[-1], m] - normalized_obj[sorted_idx[0], m])\n\n    # Select solution with highest weighted crowding\n    selected_idx = np.argmax(weighted_crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dynamic trade-off weights based on solution's position\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    avg_trade_off = np.mean(trade_off)\n    w1 = 0.7 if trade_off[selected_idx] < avg_trade_off else 0.3\n    w2 = 1 - w1\n\n    # Targeted item swaps with dynamic weights\n    gain = (w1 * value1_lst + w2 * value2_lst) / weight_lst\n    sorted_indices = np.argsort(-gain)\n\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Solution-specific perturbation\n    perturbation_prob = 0.4 - 0.2 * (objectives[selected_idx, 0] + objectives[selected_idx, 1]) / (np.max(objectives) + 1e-10)\n    if np.random.rand() < perturbation_prob:\n        value_ratio = (value1_lst + value2_lst) / (2 * weight_lst)\n        poor_ratio_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in poor_ratio_indices:\n            if np.random.rand() < 0.6 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 116,
        "algorithm": "This heuristic algorithm selects a promising solution from the archive using a hybrid metric combining dominance rank and objective-space partitioning, then applies a multi-phase local search that prioritizes items based on combined value gains and weight efficiency, with dynamic perturbations to escape local optima. The selection emphasizes non-dominated solutions in well-partitioned objective regions, while the local search aggressively optimizes both objectives and weight constraints through adaptive swaps and targeted perturbations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection metric combining dominance and objective-space partitioning\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate dominance ranks\n    dominance = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]) and \\\n                   (objectives[i, 0] > objectives[j, 0] or objectives[i, 1] > objectives[j, 1]):\n                    dominance[i] += 1\n\n    # Objective-space partitioning\n    max_obj = np.max(objectives, axis=0)\n    min_obj = np.min(objectives, axis=0)\n    partitions = np.zeros(len(archive))\n    for i in range(len(archive)):\n        partitions[i] = (objectives[i, 0] - min_obj[0]) / (max_obj[0] - min_obj[0] + 1e-10) * \\\n                       (objectives[i, 1] - min_obj[1]) / (max_obj[1] - min_obj[1] + 1e-10)\n\n    # Hybrid selection score\n    selection_score = (1 - dominance/len(archive)) * partitions\n    selected_idx = np.argmax(selection_score)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Multi-phase local search\n    # Phase 1: Adaptive item swaps based on both objectives\n    combined_gain = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n    sorted_indices = np.argsort(-combined_gain)\n\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 2: Weight efficiency-based swaps\n    weight_efficiency = (value1_lst * value2_lst) / (weight_lst + 1e-10)\n    sorted_indices = np.argsort(-weight_efficiency)\n\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 3: Dynamic perturbation based on weight utilization\n    weight_utilization = current_weight / capacity\n    perturbation_prob = 0.3 + 0.4 * (1 - weight_utilization)\n\n    if np.random.rand() < perturbation_prob:\n        # Remove low-value items with high probability\n        value_score = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        poor_indices = np.argsort(value_score)[:min(5, len(weight_lst))]\n        for idx in poor_indices:\n            if np.random.rand() < 0.5 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7647493488880726,
            1.23432457447052
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection metric combining dominance and objective-space partitioning\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate dominance ranks\n    dominance = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]) and \\\n                   (objectives[i, 0] > objectives[j, 0] or objectives[i, 1] > objectives[j, 1]):\n                    dominance[i] += 1\n\n    # Objective-space partitioning\n    max_obj = np.max(objectives, axis=0)\n    min_obj = np.min(objectives, axis=0)\n    partitions = np.zeros(len(archive))\n    for i in range(len(archive)):\n        partitions[i] = (objectives[i, 0] - min_obj[0]) / (max_obj[0] - min_obj[0] + 1e-10) * \\\n                       (objectives[i, 1] - min_obj[1]) / (max_obj[1] - min_obj[1] + 1e-10)\n\n    # Hybrid selection score\n    selection_score = (1 - dominance/len(archive)) * partitions\n    selected_idx = np.argmax(selection_score)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Multi-phase local search\n    # Phase 1: Adaptive item swaps based on both objectives\n    combined_gain = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n    sorted_indices = np.argsort(-combined_gain)\n\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 2: Weight efficiency-based swaps\n    weight_efficiency = (value1_lst * value2_lst) / (weight_lst + 1e-10)\n    sorted_indices = np.argsort(-weight_efficiency)\n\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 3: Dynamic perturbation based on weight utilization\n    weight_utilization = current_weight / capacity\n    perturbation_prob = 0.3 + 0.4 * (1 - weight_utilization)\n\n    if np.random.rand() < perturbation_prob:\n        # Remove low-value items with high probability\n        value_score = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        poor_indices = np.argsort(value_score)[:min(5, len(weight_lst))]\n        for idx in poor_indices:\n            if np.random.rand() < 0.5 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 5 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive using an adaptive weighted crowding distance metric that balances dominance rank and objective trade-offs, then applies a hybrid local search combining targeted item swaps (prioritizing high-value items with dynamic weights) and probabilistic flips (removing low-value items with solution-specific probabilities), while ensuring feasibility through capacity checks. The selection prioritizes solutions near the Pareto front (lower dominance rank) and those with high crowding distance, while the local search dynamically adjusts trade-off weights based on the solution's position in the objective space.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive weighted crowding selection\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate dominance ranks\n    dominance = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]) and \\\n                   (objectives[i, 0] > objectives[j, 0] or objectives[i, 1] > objectives[j, 1]):\n                    dominance[i] += 1\n\n    # Normalize objectives and calculate weighted crowding\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1 / (1 + dominance)\n    weighted_crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_obj[:, m])\n        weighted_crowding[sorted_idx[0]] = np.inf\n        weighted_crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_obj[sorted_idx[-1], m] != normalized_obj[sorted_idx[0], m]:\n                weighted_crowding[sorted_idx[i]] += weights[sorted_idx[i]] * (normalized_obj[sorted_idx[i+1], m] - normalized_obj[sorted_idx[i-1], m]) / (normalized_obj[sorted_idx[-1], m] - normalized_obj[sorted_idx[0], m])\n\n    # Select solution with highest weighted crowding\n    selected_idx = np.argmax(weighted_crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dynamic trade-off weights based on solution's position\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    avg_trade_off = np.mean(trade_off)\n    w1 = 0.7 if trade_off[selected_idx] < avg_trade_off else 0.3\n    w2 = 1 - w1\n\n    # Targeted item swaps with dynamic weights\n    gain = (w1 * value1_lst + w2 * value2_lst) / weight_lst\n    sorted_indices = np.argsort(-gain)\n\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Solution-specific perturbation\n    perturbation_prob = 0.4 - 0.2 * (objectives[selected_idx, 0] + objectives[selected_idx, 1]) / (np.max(objectives) + 1e-10)\n    if np.random.rand() < perturbation_prob:\n        value_ratio = (value1_lst + value2_lst) / (2 * weight_lst)\n        poor_ratio_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in poor_ratio_indices:\n            if np.random.rand() < 0.6 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid of crowding distance and objective trade-off analysis, then applies a novel local search that alternates between targeted item swaps (prioritizing high-value items with trade-off considerations) and probabilistic flips (removing low-value items with dynamic probability), while ensuring feasibility through constrained capacity checks. The selection prioritizes solutions with high crowding distance (indicating potential for improvement) and adjusts perturbation probabilities based on the solution's position in the Pareto front and its objective trade-offs.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine objective dominance and adaptive crowding\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate normalized crowding distances\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate objective trade-offs\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    avg_trade_off = np.mean(trade_off)\n\n    # Alternating objective improvement with trade-off consideration\n    if np.random.rand() < 0.5 or trade_off[selected_idx] < avg_trade_off:\n        # Improve first objective with trade-off consideration\n        gain = (value1_lst + 0.3 * value2_lst) / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective with trade-off consideration\n        gain = (value2_lst + 0.3 * value1_lst) / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Targeted item swaps with feasibility check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position and trade-off\n    perturbation_prob = 0.3 if trade_off[selected_idx] < avg_trade_off else 0.6\n    if np.random.rand() < perturbation_prob:\n        # Select items with poor value-to-weight ratio for potential removal\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        poor_ratio_indices = np.argsort(value_ratio)[:min(5, len(weight_lst))]\n        for idx in poor_ratio_indices:\n            if np.random.rand() < 0.5 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP:\n\n- **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~70)*\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 117,
        "algorithm": "The algorithm selects promising solutions from the top 20% (by normalized objective sums) and performs 5-7 iterations of local search, prioritizing high-marginal-gain item flips (70% chance) while adaptively perturbing low-marginal-contribution items (probability based on crowding distance). It strictly maintains feasibility by checking capacity constraints and limits flips (3-5 per iteration) to balance exploitation and exploration. The key variables are weighted by marginal gains (value/weight) and crowding distance to guide the search toward diverse, high-quality solutions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate crowding distance for perturbation probability\n    objectives = np.array([obj for _, obj in archive])\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Iterative local search (5-7 iterations)\n    for _ in range(np.random.randint(5, 8)):\n        # Targeted flips: prioritize high-marginal-gain items (70% chance)\n        if np.random.rand() < 0.7:\n            if np.random.rand() < 0.5:\n                marginal_gain = value1_lst / weight_lst\n            else:\n                marginal_gain = value2_lst / weight_lst\n            sorted_indices = np.argsort(-marginal_gain)[:min(5, len(weight_lst))]\n\n            for idx in sorted_indices:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n        else:\n            # Adaptive perturbation: flip low-marginal-contribution items\n            perturbation_prob = 0.3 if crowding[selected_idx] > np.median(crowding) else 0.6\n            if np.random.rand() < perturbation_prob:\n                marginal_contribution = (value1_lst + value2_lst) / weight_lst\n                low_contrib_indices = np.argsort(marginal_contribution)[:min(3, len(weight_lst))]\n                for idx in low_contrib_indices:\n                    if np.random.rand() < 0.5:\n                        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                            new_solution[idx] = 0\n                            current_weight -= weight_lst[idx]\n                        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                            new_solution[idx] = 1\n                            current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.45764966079481795,
            2.073205977678299
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate crowding distance for perturbation probability\n    objectives = np.array([obj for _, obj in archive])\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Iterative local search (5-7 iterations)\n    for _ in range(np.random.randint(5, 8)):\n        # Targeted flips: prioritize high-marginal-gain items (70% chance)\n        if np.random.rand() < 0.7:\n            if np.random.rand() < 0.5:\n                marginal_gain = value1_lst / weight_lst\n            else:\n                marginal_gain = value2_lst / weight_lst\n            sorted_indices = np.argsort(-marginal_gain)[:min(5, len(weight_lst))]\n\n            for idx in sorted_indices:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n        else:\n            # Adaptive perturbation: flip low-marginal-contribution items\n            perturbation_prob = 0.3 if crowding[selected_idx] > np.median(crowding) else 0.6\n            if np.random.rand() < perturbation_prob:\n                marginal_contribution = (value1_lst + value2_lst) / weight_lst\n                low_contrib_indices = np.argsort(marginal_contribution)[:min(3, len(weight_lst))]\n                for idx in low_contrib_indices:\n                    if np.random.rand() < 0.5:\n                        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                            new_solution[idx] = 0\n                            current_weight -= weight_lst[idx]\n                        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                            new_solution[idx] = 1\n                            current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 4 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s the refined heuristic design for the BI-KP:\n\n- **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~70)*\n\n### **Heuristic Function: `select_neighbor`**\n```python\nimport numpy as np\nfrom typing import List, Tuple\n\ndef select_neighbor(\n    archive: List[Tuple[np.ndarray, Tuple[float, float]]],\n    weights: np.ndarray,\n    capacity: float,\n    max_iter: int = 10\n) -> np.ndarray:\n    # Step 1: Select top 20% solutions by normalized objective sums\n    objectives = np.array([obj for _, obj in archive])\n    scores = np.sum(objectives * weights, axis=1)\n    top_indices = np.argsort(scores)[-max(1, len(archive) // 5):]\n    selected = np.random.choice(top_indices)\n\n    # Step 2: Local search with marginal gain + controlled randomness\n    current_sol, current_obj = archive[selected]\n    for _ in range(max_iter):\n        # Flip items with highest marginal gains in either objective\n        marginal_gains = np.zeros(len(current_sol))\n        for i in range(len(current_sol)):\n            new_sol = current_sol.copy()\n            new_sol[i] = 1 - new_sol[i]\n            if np.dot(new_sol, weights) <= capacity:\n                marginal_gains[i] = np.sum(objectives[selected] if current_sol[i] else objectives[selected])\n\n        # Targeted flips (top 20%)\n        flip_indices = np.argsort(marginal_gains)[-max(1, len(marginal_gains) // 5):]\n        for i in flip_indices:\n            new_sol = current_sol.copy()\n            new_sol[i] = 1 - new_sol[i]\n            if np.dot(new_sol, weights) <= capacity:\n                current_sol = new_sol\n\n        # Random flips (1-2) to avoid stagnation\n        random_flips = np.random.choice(len(current_sol), size=np.random.randint(1, 3), replace=False)\n        for i in random_flips:\n            new_sol = current_sol.copy()\n            new_sol[i] = 1 - new_sol[i]\n            if np.dot(new_sol, weights) <= capacity:\n                current_sol = new_sol\n\n    return current_sol\n```\n\n**Key Features**:\n1. **Diversity-aware selection**: Top 20% solutions by weighted objective sums.\n2. **Marginal gain flipping**: Targets items with highest gains in either objective.\n3. **Controlled randomness**: Adds 1-2 random flips per iteration to escape local optima.\n4. **Feasibility checks**: Ensures all generated neighbors are valid.\n\nThis heuristic balances exploitation (marginal gains) and exploration (random flips) while guaranteeing feasibility.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 118,
        "algorithm": "The algorithm selects promising solutions from the top 20% of the archive (based on normalized objective sums) and applies a hybrid local search strategy: it first flips high-marginal-gain items (prioritizing those with better combined value/weight ratios) and then adds controlled random flips (1-2 items) to escape local optima, while always ensuring feasibility through iterative refinement. The method balances exploitation (targeted flips) and exploration (random perturbations) to navigate the multi-objective solution space effectively.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = np.max(objectives, axis=0)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0]/max_obj1 + objectives[:, 1]/max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted flips: highest marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n    top_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    for idx in top_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbations (1-2 flips)\n    random_flips = np.random.choice(len(weight_lst), size=np.random.randint(1, 3), replace=False)\n    for idx in random_flips:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement (5 attempts)\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.8807196666091583,
            0.2453363537788391
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = np.max(objectives, axis=0)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0]/max_obj1 + objectives[:, 1]/max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted flips: highest marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n    top_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    for idx in top_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbations (1-2 flips)\n    random_flips = np.random.choice(len(weight_lst), size=np.random.randint(1, 3), replace=False)\n    for idx in random_flips:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement (5 attempts)\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a solution from the archive by first clustering the objectives using k-means (with k=min(3, archive size)), then choosing the most dominant solution in the smallest cluster. It applies a hybrid local search that prioritizes either balanced improvements (high value correlation) or objective-specific gains (low correlation) via targeted item replacements, while dynamically perturbing solutions based on their centrality in the Pareto front to avoid local optima. Feasibility is maintained through adaptive capacity checks during all operations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Cluster-based selection (k-means on objectives)\n    from sklearn.cluster import KMeans\n    k = min(3, len(archive))\n    kmeans = KMeans(n_clusters=k, random_state=42).fit(objectives)\n    cluster_sizes = np.bincount(kmeans.labels_)\n    selected_cluster = np.argmin(cluster_sizes)\n    cluster_indices = np.where(kmeans.labels_ == selected_cluster)[0]\n\n    # Select solution with best dominance in its cluster\n    cluster_objectives = objectives[cluster_indices]\n    dominance_counts = np.zeros(len(cluster_indices))\n    for i in range(len(cluster_indices)):\n        for j in range(len(cluster_indices)):\n            if i != j:\n                if (cluster_objectives[i, 0] >= cluster_objectives[j, 0] and cluster_objectives[i, 1] > cluster_objectives[j, 1]) or \\\n                   (cluster_objectives[i, 0] > cluster_objectives[j, 0] and cluster_objectives[i, 1] >= cluster_objectives[j, 1]):\n                    dominance_counts[i] += 1\n    selected_idx = cluster_indices[np.argmax(dominance_counts)]\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate value correlation and centrality\n    value_correlation = np.corrcoef(value1_lst, value2_lst)[0, 1]\n    centroid = np.mean(objectives, axis=0)\n    distance_to_centroid = np.linalg.norm(objectives[selected_idx] - centroid)\n\n    # Targeted replacement based on value correlation and position\n    if value_correlation > 0.7:\n        # High correlation: prioritize balanced improvement\n        gain = (value1_lst + value2_lst) / weight_lst\n    else:\n        # Low correlation: prioritize objective with higher trade-off\n        trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n        if trade_off[selected_idx] > np.median(trade_off):\n            gain = value2_lst / weight_lst\n        else:\n            gain = value1_lst / weight_lst\n    sorted_indices = np.argsort(-gain)\n\n    # Perform replacements with feasibility check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on centrality\n    perturbation_prob = 0.4 if distance_to_centroid < np.median(np.linalg.norm(objectives - centroid, axis=1)) else 0.7\n    if np.random.rand() < perturbation_prob:\n        # Remove items with low utility for both objectives\n        utility = (value1_lst + value2_lst) / weight_lst\n        poor_utility_indices = np.argsort(utility)[:min(3, len(weight_lst))]\n        for idx in poor_utility_indices:\n            if np.random.rand() < 0.6 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP:\n\n- **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~70)*\n\n### **Heuristic Function: `select_neighbor`**\n```python\nimport numpy as np\nfrom typing import List, Tuple\n\ndef select_neighbor(\n    archive: List[Tuple[np.ndarray, Tuple[float, float]]],\n    weights: np.ndarray,\n    capacity: float,\n    max_iter: int = 10\n) -> np.ndarray:\n    # Step 1: Select top 20% solutions by normalized objective sums\n    objectives = np.array([obj for _, obj in archive])\n    scores = np.sum(objectives * weights, axis=1)\n    top_indices = np.argsort(scores)[-max(1, len(archive) // 5):]\n    selected = np.random.choice(top_indices)\n\n    # Step 2: Local search with marginal gain + controlled randomness\n    current_sol, current_obj = archive[selected]\n    for _ in range(max_iter):\n        # Flip items with highest marginal gains in either objective\n        marginal_gains = np.zeros(len(current_sol))\n        for i in range(len(current_sol)):\n            new_sol = current_sol.copy()\n            new_sol[i] = 1 - new_sol[i]\n            if np.dot(new_sol, weights) <= capacity:\n                marginal_gains[i] = np.sum(objectives[selected] if current_sol[i] else objectives[selected])\n\n        # Targeted flips (top 20%)\n        flip_indices = np.argsort(marginal_gains)[-max(1, len(marginal_gains) // 5):]\n        for i in flip_indices:\n            new_sol = current_sol.copy()\n            new_sol[i] = 1 - new_sol[i]\n            if np.dot(new_sol, weights) <= capacity:\n                current_sol = new_sol\n\n        # Random flips (1-2) to avoid stagnation\n        random_flips = np.random.choice(len(current_sol), size=np.random.randint(1, 3), replace=False)\n        for i in random_flips:\n            new_sol = current_sol.copy()\n            new_sol[i] = 1 - new_sol[i]\n            if np.dot(new_sol, weights) <= capacity:\n                current_sol = new_sol\n\n    return current_sol\n```\n\n**Key Features**:\n1. **Diversity-aware selection**: Top 20% solutions by weighted objective sums.\n2. **Marginal gain flipping**: Targets items with highest gains in either objective.\n3. **Controlled randomness**: Adds 1-2 random flips per iteration to escape local optima.\n4. **Feasibility checks**: Ensures all generated neighbors are valid.\n\nThis heuristic balances exploitation (marginal gains) and exploration (random flips) while guaranteeing feasibility.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 119,
        "algorithm": "This heuristic combines marginal gain prioritization with adaptive perturbations to generate high-quality neighbors. It first selects top-performing solutions based on normalized objective sums, then flips items with the highest combined marginal gains while ensuring feasibility. Finally, it applies dynamic perturbations (removing low-utility items) and occasional random flips to escape local optima, with perturbation intensity adjusted by solution centrality in the Pareto front. The algorithm balances exploration and exploitation through iterative refinement and controlled randomness.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select top 20% solutions by normalized objective sums\n    objectives = np.array([obj for _, obj in archive])\n    normalized_scores = np.sum(objectives / (np.max(objectives, axis=0) + 1e-10), axis=1)\n    top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(top_indices)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Step 3: Perform targeted flips (top 20% by marginal gain)\n    flip_indices = np.argsort(combined_gain)[-max(1, len(combined_gain) // 5):]\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 4: Dynamic perturbation based on centrality\n    centroid = np.mean(objectives, axis=0)\n    distance_to_centroid = np.linalg.norm(objectives[selected_idx] - centroid)\n    median_distance = np.median(np.linalg.norm(objectives - centroid, axis=1))\n    perturbation_prob = 0.3 if distance_to_centroid < median_distance else 0.5\n\n    if np.random.rand() < perturbation_prob:\n        # Remove items with low utility in both objectives\n        utility = (value1_lst + value2_lst) / weight_lst\n        poor_utility_indices = np.argsort(utility)[:min(3, len(weight_lst))]\n        for idx in poor_utility_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Step 5: Add 1-2 random flips to escape local optima\n    random_flips = np.random.choice(len(new_solution), size=np.random.randint(1, 3), replace=False)\n    for idx in random_flips:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.40446553813524766,
            0.35819095373153687
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select top 20% solutions by normalized objective sums\n    objectives = np.array([obj for _, obj in archive])\n    normalized_scores = np.sum(objectives / (np.max(objectives, axis=0) + 1e-10), axis=1)\n    top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(top_indices)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Step 3: Perform targeted flips (top 20% by marginal gain)\n    flip_indices = np.argsort(combined_gain)[-max(1, len(combined_gain) // 5):]\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 4: Dynamic perturbation based on centrality\n    centroid = np.mean(objectives, axis=0)\n    distance_to_centroid = np.linalg.norm(objectives[selected_idx] - centroid)\n    median_distance = np.median(np.linalg.norm(objectives - centroid, axis=1))\n    perturbation_prob = 0.3 if distance_to_centroid < median_distance else 0.5\n\n    if np.random.rand() < perturbation_prob:\n        # Remove items with low utility in both objectives\n        utility = (value1_lst + value2_lst) / weight_lst\n        poor_utility_indices = np.argsort(utility)[:min(3, len(weight_lst))]\n        for idx in poor_utility_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Step 5: Add 1-2 random flips to escape local optima\n    random_flips = np.random.choice(len(new_solution), size=np.random.randint(1, 3), replace=False)\n    for idx in random_flips:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a solution from the archive by first clustering the objectives using k-means (with k=min(3, archive size)), then choosing the most dominant solution in the smallest cluster. It applies a hybrid local search that prioritizes either balanced improvements (high value correlation) or objective-specific gains (low correlation) via targeted item replacements, while dynamically perturbing solutions based on their centrality in the Pareto front to avoid local optima. Feasibility is maintained through adaptive capacity checks during all operations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Cluster-based selection (k-means on objectives)\n    from sklearn.cluster import KMeans\n    k = min(3, len(archive))\n    kmeans = KMeans(n_clusters=k, random_state=42).fit(objectives)\n    cluster_sizes = np.bincount(kmeans.labels_)\n    selected_cluster = np.argmin(cluster_sizes)\n    cluster_indices = np.where(kmeans.labels_ == selected_cluster)[0]\n\n    # Select solution with best dominance in its cluster\n    cluster_objectives = objectives[cluster_indices]\n    dominance_counts = np.zeros(len(cluster_indices))\n    for i in range(len(cluster_indices)):\n        for j in range(len(cluster_indices)):\n            if i != j:\n                if (cluster_objectives[i, 0] >= cluster_objectives[j, 0] and cluster_objectives[i, 1] > cluster_objectives[j, 1]) or \\\n                   (cluster_objectives[i, 0] > cluster_objectives[j, 0] and cluster_objectives[i, 1] >= cluster_objectives[j, 1]):\n                    dominance_counts[i] += 1\n    selected_idx = cluster_indices[np.argmax(dominance_counts)]\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate value correlation and centrality\n    value_correlation = np.corrcoef(value1_lst, value2_lst)[0, 1]\n    centroid = np.mean(objectives, axis=0)\n    distance_to_centroid = np.linalg.norm(objectives[selected_idx] - centroid)\n\n    # Targeted replacement based on value correlation and position\n    if value_correlation > 0.7:\n        # High correlation: prioritize balanced improvement\n        gain = (value1_lst + value2_lst) / weight_lst\n    else:\n        # Low correlation: prioritize objective with higher trade-off\n        trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n        if trade_off[selected_idx] > np.median(trade_off):\n            gain = value2_lst / weight_lst\n        else:\n            gain = value1_lst / weight_lst\n    sorted_indices = np.argsort(-gain)\n\n    # Perform replacements with feasibility check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on centrality\n    perturbation_prob = 0.4 if distance_to_centroid < np.median(np.linalg.norm(objectives - centroid, axis=1)) else 0.7\n    if np.random.rand() < perturbation_prob:\n        # Remove items with low utility for both objectives\n        utility = (value1_lst + value2_lst) / weight_lst\n        poor_utility_indices = np.argsort(utility)[:min(3, len(weight_lst))]\n        for idx in poor_utility_indices:\n            if np.random.rand() < 0.6 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP:\n\n- **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~70)*\n\n### **Heuristic Function: `select_neighbor`**\n```python\nimport numpy as np\nfrom typing import List, Tuple\n\ndef select_neighbor(\n    archive: List[Tuple[np.ndarray, Tuple[float, float]]],\n    weights: np.ndarray,\n    capacity: float,\n    max_iter: int = 10\n) -> np.ndarray:\n    # Step 1: Select top 20% solutions by normalized objective sums\n    objectives = np.array([obj for _, obj in archive])\n    scores = np.sum(objectives * weights, axis=1)\n    top_indices = np.argsort(scores)[-max(1, len(archive) // 5):]\n    selected = np.random.choice(top_indices)\n\n    # Step 2: Local search with marginal gain + controlled randomness\n    current_sol, current_obj = archive[selected]\n    for _ in range(max_iter):\n        # Flip items with highest marginal gains in either objective\n        marginal_gains = np.zeros(len(current_sol))\n        for i in range(len(current_sol)):\n            new_sol = current_sol.copy()\n            new_sol[i] = 1 - new_sol[i]\n            if np.dot(new_sol, weights) <= capacity:\n                marginal_gains[i] = np.sum(objectives[selected] if current_sol[i] else objectives[selected])\n\n        # Targeted flips (top 20%)\n        flip_indices = np.argsort(marginal_gains)[-max(1, len(marginal_gains) // 5):]\n        for i in flip_indices:\n            new_sol = current_sol.copy()\n            new_sol[i] = 1 - new_sol[i]\n            if np.dot(new_sol, weights) <= capacity:\n                current_sol = new_sol\n\n        # Random flips (1-2) to avoid stagnation\n        random_flips = np.random.choice(len(current_sol), size=np.random.randint(1, 3), replace=False)\n        for i in random_flips:\n            new_sol = current_sol.copy()\n            new_sol[i] = 1 - new_sol[i]\n            if np.dot(new_sol, weights) <= capacity:\n                current_sol = new_sol\n\n    return current_sol\n```\n\n**Key Features**:\n1. **Diversity-aware selection**: Top 20% solutions by weighted objective sums.\n2. **Marginal gain flipping**: Targets items with highest gains in either objective.\n3. **Controlled randomness**: Adds 1-2 random flips per iteration to escape local optima.\n4. **Feasibility checks**: Ensures all generated neighbors are valid.\n\nThis heuristic balances exploitation (marginal gains) and exploration (random flips) while guaranteeing feasibility.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 120,
        "algorithm": "The algorithm selects promising solutions from the Pareto frontier in the archive, prioritizes swaps of high-marginal-gain items, and applies dynamic perturbations based on solution centrality to balance exploration and exploitation while ensuring feasibility. It first identifies non-dominated solutions, then focuses on items with the highest combined marginal gains for both objectives, and finally adjusts the solution by probabilistically removing low-utility items based on the solution's distance from the objective centroid. The method ensures feasibility through iterative weight checks and balances exploration with exploitation via adaptive perturbation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select Pareto-frontier solutions\n    pareto_indices = []\n    objectives = np.array([obj for _, obj in archive])\n    for i in range(len(archive)):\n        dominated = False\n        for j in range(len(archive)):\n            if i != j and (objectives[j, 0] >= objectives[i, 0] and objectives[j, 1] >= objectives[i, 1]) and (objectives[j, 0] > objectives[i, 0] or objectives[j, 1] > objectives[i, 1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_indices.append(i)\n\n    if not pareto_indices:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        selected_idx = np.random.choice(pareto_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Prioritize high-impact swaps\n    sorted_indices = np.argsort(-combined_gain)\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution centrality\n    centroid = np.mean(objectives, axis=0)\n    distance = np.linalg.norm(objectives[selected_idx] - centroid)\n    max_distance = np.max(np.linalg.norm(objectives - centroid, axis=1))\n    perturbation_prob = 0.5 * (1 - distance / max_distance)\n\n    if np.random.rand() < perturbation_prob:\n        # Remove low-utility items\n        utility = (value1_lst + value2_lst) / weight_lst\n        poor_indices = np.argsort(utility)[:min(3, len(weight_lst))]\n        for idx in poor_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.778563860519599,
            0.3407134711742401
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select Pareto-frontier solutions\n    pareto_indices = []\n    objectives = np.array([obj for _, obj in archive])\n    for i in range(len(archive)):\n        dominated = False\n        for j in range(len(archive)):\n            if i != j and (objectives[j, 0] >= objectives[i, 0] and objectives[j, 1] >= objectives[i, 1]) and (objectives[j, 0] > objectives[i, 0] or objectives[j, 1] > objectives[i, 1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_indices.append(i)\n\n    if not pareto_indices:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        selected_idx = np.random.choice(pareto_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Prioritize high-impact swaps\n    sorted_indices = np.argsort(-combined_gain)\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution centrality\n    centroid = np.mean(objectives, axis=0)\n    distance = np.linalg.norm(objectives[selected_idx] - centroid)\n    max_distance = np.max(np.linalg.norm(objectives - centroid, axis=1))\n    perturbation_prob = 0.5 * (1 - distance / max_distance)\n\n    if np.random.rand() < perturbation_prob:\n        # Remove low-utility items\n        utility = (value1_lst + value2_lst) / weight_lst\n        poor_indices = np.argsort(utility)[:min(3, len(weight_lst))]\n        for idx in poor_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a solution from the archive by first clustering the objectives using k-means (with k=min(3, archive size)), then choosing the most dominant solution in the smallest cluster. It applies a hybrid local search that prioritizes either balanced improvements (high value correlation) or objective-specific gains (low correlation) via targeted item replacements, while dynamically perturbing solutions based on their centrality in the Pareto front to avoid local optima. Feasibility is maintained through adaptive capacity checks during all operations.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Cluster-based selection (k-means on objectives)\n    from sklearn.cluster import KMeans\n    k = min(3, len(archive))\n    kmeans = KMeans(n_clusters=k, random_state=42).fit(objectives)\n    cluster_sizes = np.bincount(kmeans.labels_)\n    selected_cluster = np.argmin(cluster_sizes)\n    cluster_indices = np.where(kmeans.labels_ == selected_cluster)[0]\n\n    # Select solution with best dominance in its cluster\n    cluster_objectives = objectives[cluster_indices]\n    dominance_counts = np.zeros(len(cluster_indices))\n    for i in range(len(cluster_indices)):\n        for j in range(len(cluster_indices)):\n            if i != j:\n                if (cluster_objectives[i, 0] >= cluster_objectives[j, 0] and cluster_objectives[i, 1] > cluster_objectives[j, 1]) or \\\n                   (cluster_objectives[i, 0] > cluster_objectives[j, 0] and cluster_objectives[i, 1] >= cluster_objectives[j, 1]):\n                    dominance_counts[i] += 1\n    selected_idx = cluster_indices[np.argmax(dominance_counts)]\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate value correlation and centrality\n    value_correlation = np.corrcoef(value1_lst, value2_lst)[0, 1]\n    centroid = np.mean(objectives, axis=0)\n    distance_to_centroid = np.linalg.norm(objectives[selected_idx] - centroid)\n\n    # Targeted replacement based on value correlation and position\n    if value_correlation > 0.7:\n        # High correlation: prioritize balanced improvement\n        gain = (value1_lst + value2_lst) / weight_lst\n    else:\n        # Low correlation: prioritize objective with higher trade-off\n        trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n        if trade_off[selected_idx] > np.median(trade_off):\n            gain = value2_lst / weight_lst\n        else:\n            gain = value1_lst / weight_lst\n    sorted_indices = np.argsort(-gain)\n\n    # Perform replacements with feasibility check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on centrality\n    perturbation_prob = 0.4 if distance_to_centroid < np.median(np.linalg.norm(objectives - centroid, axis=1)) else 0.7\n    if np.random.rand() < perturbation_prob:\n        # Remove items with low utility for both objectives\n        utility = (value1_lst + value2_lst) / weight_lst\n        poor_utility_indices = np.argsort(utility)[:min(3, len(weight_lst))]\n        for idx in poor_utility_indices:\n            if np.random.rand() < 0.6 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 121,
        "algorithm": "The algorithm selects a solution from the archive by first identifying the most underrepresented objective region using non-dominated sorting and crowding distance analysis, then applies a hybrid local search that dynamically adjusts value weights based on the solution's Pareto front position and performs item swaps while ensuring feasibility through adaptive capacity adjustment. The key variables prioritize items with higher combined value-to-weight ratios, while the dynamic weighting balances the two objectives based on the solution's front position.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Non-dominated sorting and crowding distance analysis\n    fronts = []\n    remaining = list(range(len(archive)))\n    while remaining:\n        front = []\n        for i in remaining:\n            dominated = False\n            for j in remaining:\n                if i != j and (objectives[j, 0] >= objectives[i, 0] and objectives[j, 1] >= objectives[i, 1] and\n                               (objectives[j, 0] > objectives[i, 0] or objectives[j, 1] > objectives[i, 1])):\n                    dominated = True\n                    break\n            if not dominated:\n                front.append(i)\n        fronts.append(front)\n        remaining = [i for i in remaining if i not in front]\n\n    # Identify the most underrepresented region\n    if len(fronts) > 1:\n        target_front = fronts[-2] if len(fronts) > 2 else fronts[1]\n    else:\n        target_front = fronts[0]\n\n    if not target_front:\n        target_front = [0]\n\n    # Select solution with highest crowding distance in target front\n    crowding_distances = np.zeros(len(target_front))\n    for m in range(2):\n        sorted_indices = np.argsort(objectives[target_front, m])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for i in range(1, len(target_front)-1):\n            crowding_distances[i] += (objectives[target_front[sorted_indices[i+1]], m] -\n                                      objectives[target_front[sorted_indices[i-1]], m])\n\n    selected_idx = target_front[np.argmax(crowding_distances)]\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dynamic value weighting based on position in Pareto front\n    front_idx = next(i for i, front in enumerate(fronts) if selected_idx in front)\n    total_fronts = len(fronts)\n    value_weight = 1.0 - (front_idx / (total_fronts + 1))  # Higher for better fronts\n\n    # Hybrid local search with item swapping\n    value_combined = value_weight * (value1_lst + value2_lst) + (1 - value_weight) * np.abs(value1_lst - value2_lst)\n    gain = value_combined / weight_lst\n    sorted_indices = np.argsort(-gain)\n\n    # Perform swaps with feasibility check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1:\n            # Try to remove item\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try to add item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        sorted_items = np.argsort(weight_lst)\n        for idx in sorted_items:\n            if new_solution[idx] == 1 and excess <= 0:\n                break\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8417361835746396,
            0.8757677972316742
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Non-dominated sorting and crowding distance analysis\n    fronts = []\n    remaining = list(range(len(archive)))\n    while remaining:\n        front = []\n        for i in remaining:\n            dominated = False\n            for j in remaining:\n                if i != j and (objectives[j, 0] >= objectives[i, 0] and objectives[j, 1] >= objectives[i, 1] and\n                               (objectives[j, 0] > objectives[i, 0] or objectives[j, 1] > objectives[i, 1])):\n                    dominated = True\n                    break\n            if not dominated:\n                front.append(i)\n        fronts.append(front)\n        remaining = [i for i in remaining if i not in front]\n\n    # Identify the most underrepresented region\n    if len(fronts) > 1:\n        target_front = fronts[-2] if len(fronts) > 2 else fronts[1]\n    else:\n        target_front = fronts[0]\n\n    if not target_front:\n        target_front = [0]\n\n    # Select solution with highest crowding distance in target front\n    crowding_distances = np.zeros(len(target_front))\n    for m in range(2):\n        sorted_indices = np.argsort(objectives[target_front, m])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for i in range(1, len(target_front)-1):\n            crowding_distances[i] += (objectives[target_front[sorted_indices[i+1]], m] -\n                                      objectives[target_front[sorted_indices[i-1]], m])\n\n    selected_idx = target_front[np.argmax(crowding_distances)]\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dynamic value weighting based on position in Pareto front\n    front_idx = next(i for i, front in enumerate(fronts) if selected_idx in front)\n    total_fronts = len(fronts)\n    value_weight = 1.0 - (front_idx / (total_fronts + 1))  # Higher for better fronts\n\n    # Hybrid local search with item swapping\n    value_combined = value_weight * (value1_lst + value2_lst) + (1 - value_weight) * np.abs(value1_lst - value2_lst)\n    gain = value_combined / weight_lst\n    sorted_indices = np.argsort(-gain)\n\n    # Perform swaps with feasibility check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1:\n            # Try to remove item\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try to add item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        sorted_items = np.argsort(weight_lst)\n        for idx in sorted_items:\n            if new_solution[idx] == 1 and excess <= 0:\n                break\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a solution from the archive by first clustering the objectives using k-means (with k=min(3, archive size)), then choosing the most dominant solution in the smallest cluster. It applies a hybrid local search that prioritizes either balanced improvements (high value correlation) or objective-specific gains (low correlation) via targeted item replacements, while dynamically perturbing solutions based on their centrality in the Pareto front to avoid local optima. Feasibility is maintained through adaptive capacity checks during all operations.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Cluster-based selection (k-means on objectives)\n    from sklearn.cluster import KMeans\n    k = min(3, len(archive))\n    kmeans = KMeans(n_clusters=k, random_state=42).fit(objectives)\n    cluster_sizes = np.bincount(kmeans.labels_)\n    selected_cluster = np.argmin(cluster_sizes)\n    cluster_indices = np.where(kmeans.labels_ == selected_cluster)[0]\n\n    # Select solution with best dominance in its cluster\n    cluster_objectives = objectives[cluster_indices]\n    dominance_counts = np.zeros(len(cluster_indices))\n    for i in range(len(cluster_indices)):\n        for j in range(len(cluster_indices)):\n            if i != j:\n                if (cluster_objectives[i, 0] >= cluster_objectives[j, 0] and cluster_objectives[i, 1] > cluster_objectives[j, 1]) or \\\n                   (cluster_objectives[i, 0] > cluster_objectives[j, 0] and cluster_objectives[i, 1] >= cluster_objectives[j, 1]):\n                    dominance_counts[i] += 1\n    selected_idx = cluster_indices[np.argmax(dominance_counts)]\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate value correlation and centrality\n    value_correlation = np.corrcoef(value1_lst, value2_lst)[0, 1]\n    centroid = np.mean(objectives, axis=0)\n    distance_to_centroid = np.linalg.norm(objectives[selected_idx] - centroid)\n\n    # Targeted replacement based on value correlation and position\n    if value_correlation > 0.7:\n        # High correlation: prioritize balanced improvement\n        gain = (value1_lst + value2_lst) / weight_lst\n    else:\n        # Low correlation: prioritize objective with higher trade-off\n        trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n        if trade_off[selected_idx] > np.median(trade_off):\n            gain = value2_lst / weight_lst\n        else:\n            gain = value1_lst / weight_lst\n    sorted_indices = np.argsort(-gain)\n\n    # Perform replacements with feasibility check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on centrality\n    perturbation_prob = 0.4 if distance_to_centroid < np.median(np.linalg.norm(objectives - centroid, axis=1)) else 0.7\n    if np.random.rand() < perturbation_prob:\n        # Remove items with low utility for both objectives\n        utility = (value1_lst + value2_lst) / weight_lst\n        poor_utility_indices = np.argsort(utility)[:min(3, len(weight_lst))]\n        for idx in poor_utility_indices:\n            if np.random.rand() < 0.6 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 122,
        "algorithm": "The algorithm selects a solution from the archive by prioritizing isolated points in the objective space (using DBSCAN clustering) to focus on under-explored regions, then applies a hybrid local search that alternates between objective-specific and balanced improvements based on value correlation, with dynamic perturbation controlled by solution density. It prioritizes items with high marginal utility (considering both objectives) while ensuring feasibility, and occasionally perturbs the solution to escape local optima by removing low-value items.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # DBSCAN-based selection to find isolated solutions\n    from sklearn.cluster import DBSCAN\n    dbscan = DBSCAN(eps=0.2, min_samples=2).fit(objectives)\n    labels = dbscan.labels_\n    noise_points = np.where(labels == -1)[0]\n\n    if len(noise_points) > 0:\n        # Select the most isolated solution\n        selected_idx = np.random.choice(noise_points)\n    else:\n        # If no noise points, select a random solution\n        selected_idx = np.random.randint(len(archive))\n\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate value correlation and solution density\n    value_correlation = np.corrcoef(value1_lst, value2_lst)[0, 1]\n    distances = np.linalg.norm(objectives - objectives[selected_idx], axis=1)\n    k_nearest = min(5, len(archive)-1)\n    kth_distance = np.partition(distances, k_nearest)[k_nearest]\n\n    # Alternating improvement strategy\n    if value_correlation > 0.6:\n        # High correlation: balanced improvement\n        gain = (value1_lst + value2_lst) / weight_lst\n    else:\n        # Low correlation: alternating objectives\n        if np.random.rand() < 0.5:\n            gain = value1_lst / weight_lst\n        else:\n            gain = value2_lst / weight_lst\n\n    sorted_indices = np.argsort(-gain)\n\n    # Perform replacements with feasibility check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution density\n    perturbation_prob = 0.3 if kth_distance > np.median(distances) else 0.6\n    if np.random.rand() < perturbation_prob:\n        # Remove items with low marginal utility\n        marginal_value = (value1_lst + value2_lst) / weight_lst\n        poor_items = np.argsort(marginal_value)[:min(5, len(weight_lst))]\n        for idx in poor_items:\n            if np.random.rand() < 0.5 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.6373417228974012,
            4.1226062178611755
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # DBSCAN-based selection to find isolated solutions\n    from sklearn.cluster import DBSCAN\n    dbscan = DBSCAN(eps=0.2, min_samples=2).fit(objectives)\n    labels = dbscan.labels_\n    noise_points = np.where(labels == -1)[0]\n\n    if len(noise_points) > 0:\n        # Select the most isolated solution\n        selected_idx = np.random.choice(noise_points)\n    else:\n        # If no noise points, select a random solution\n        selected_idx = np.random.randint(len(archive))\n\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate value correlation and solution density\n    value_correlation = np.corrcoef(value1_lst, value2_lst)[0, 1]\n    distances = np.linalg.norm(objectives - objectives[selected_idx], axis=1)\n    k_nearest = min(5, len(archive)-1)\n    kth_distance = np.partition(distances, k_nearest)[k_nearest]\n\n    # Alternating improvement strategy\n    if value_correlation > 0.6:\n        # High correlation: balanced improvement\n        gain = (value1_lst + value2_lst) / weight_lst\n    else:\n        # Low correlation: alternating objectives\n        if np.random.rand() < 0.5:\n            gain = value1_lst / weight_lst\n        else:\n            gain = value2_lst / weight_lst\n\n    sorted_indices = np.argsort(-gain)\n\n    # Perform replacements with feasibility check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution density\n    perturbation_prob = 0.3 if kth_distance > np.median(distances) else 0.6\n    if np.random.rand() < perturbation_prob:\n        # Remove items with low marginal utility\n        marginal_value = (value1_lst + value2_lst) / weight_lst\n        poor_items = np.argsort(marginal_value)[:min(5, len(weight_lst))]\n        for idx in poor_items:\n            if np.random.rand() < 0.5 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 5 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive by first clustering the objectives using k-means (with k=min(3, archive size)), then choosing the most dominant solution in the smallest cluster. It applies a hybrid local search that prioritizes either balanced improvements (high value correlation) or objective-specific gains (low correlation) via targeted item replacements, while dynamically perturbing solutions based on their centrality in the Pareto front to avoid local optima. Feasibility is maintained through adaptive capacity checks during all operations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Cluster-based selection (k-means on objectives)\n    from sklearn.cluster import KMeans\n    k = min(3, len(archive))\n    kmeans = KMeans(n_clusters=k, random_state=42).fit(objectives)\n    cluster_sizes = np.bincount(kmeans.labels_)\n    selected_cluster = np.argmin(cluster_sizes)\n    cluster_indices = np.where(kmeans.labels_ == selected_cluster)[0]\n\n    # Select solution with best dominance in its cluster\n    cluster_objectives = objectives[cluster_indices]\n    dominance_counts = np.zeros(len(cluster_indices))\n    for i in range(len(cluster_indices)):\n        for j in range(len(cluster_indices)):\n            if i != j:\n                if (cluster_objectives[i, 0] >= cluster_objectives[j, 0] and cluster_objectives[i, 1] > cluster_objectives[j, 1]) or \\\n                   (cluster_objectives[i, 0] > cluster_objectives[j, 0] and cluster_objectives[i, 1] >= cluster_objectives[j, 1]):\n                    dominance_counts[i] += 1\n    selected_idx = cluster_indices[np.argmax(dominance_counts)]\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate value correlation and centrality\n    value_correlation = np.corrcoef(value1_lst, value2_lst)[0, 1]\n    centroid = np.mean(objectives, axis=0)\n    distance_to_centroid = np.linalg.norm(objectives[selected_idx] - centroid)\n\n    # Targeted replacement based on value correlation and position\n    if value_correlation > 0.7:\n        # High correlation: prioritize balanced improvement\n        gain = (value1_lst + value2_lst) / weight_lst\n    else:\n        # Low correlation: prioritize objective with higher trade-off\n        trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n        if trade_off[selected_idx] > np.median(trade_off):\n            gain = value2_lst / weight_lst\n        else:\n            gain = value1_lst / weight_lst\n    sorted_indices = np.argsort(-gain)\n\n    # Perform replacements with feasibility check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on centrality\n    perturbation_prob = 0.4 if distance_to_centroid < np.median(np.linalg.norm(objectives - centroid, axis=1)) else 0.7\n    if np.random.rand() < perturbation_prob:\n        # Remove items with low utility for both objectives\n        utility = (value1_lst + value2_lst) / weight_lst\n        poor_utility_indices = np.argsort(utility)[:min(3, len(weight_lst))]\n        for idx in poor_utility_indices:\n            if np.random.rand() < 0.6 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid of crowding distance and objective trade-off analysis, then applies a novel local search that alternates between targeted item swaps (prioritizing high-value items with trade-off considerations) and probabilistic flips (removing low-value items with dynamic probability), while ensuring feasibility through constrained capacity checks. The selection prioritizes solutions with high crowding distance (indicating potential for improvement) and adjusts perturbation probabilities based on the solution's position in the Pareto front and its objective trade-offs.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine objective dominance and adaptive crowding\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate normalized crowding distances\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate objective trade-offs\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    avg_trade_off = np.mean(trade_off)\n\n    # Alternating objective improvement with trade-off consideration\n    if np.random.rand() < 0.5 or trade_off[selected_idx] < avg_trade_off:\n        # Improve first objective with trade-off consideration\n        gain = (value1_lst + 0.3 * value2_lst) / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective with trade-off consideration\n        gain = (value2_lst + 0.3 * value1_lst) / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Targeted item swaps with feasibility check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position and trade-off\n    perturbation_prob = 0.3 if trade_off[selected_idx] < avg_trade_off else 0.6\n    if np.random.rand() < perturbation_prob:\n        # Select items with poor value-to-weight ratio for potential removal\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        poor_ratio_indices = np.argsort(value_ratio)[:min(5, len(weight_lst))]\n        for idx in poor_ratio_indices:\n            if np.random.rand() < 0.5 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP:\n\n- **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n*(Word count: ~70)*\n\n### **Heuristic Function: `select_neighbor`**\n```python\nimport numpy as np\nfrom typing import List, Tuple\n\ndef select_neighbor(\n    archive: List[Tuple[np.ndarray, Tuple[float, float]]],\n    weights: np.ndarray,\n    capacity: float,\n    max_iter: int = 10\n) -> np.ndarray:\n    # Step 1: Select top 20% solutions by normalized objective sums\n    objectives = np.array([obj for _, obj in archive])\n    scores = np.sum(objectives * weights, axis=1)\n    top_indices = np.argsort(scores)[-max(1, len(archive) // 5):]\n    selected = np.random.choice(top_indices)\n\n    # Step 2: Local search with marginal gain + controlled randomness\n    current_sol, current_obj = archive[selected]\n    for _ in range(max_iter):\n        # Flip items with highest marginal gains in either objective\n        marginal_gains = np.zeros(len(current_sol))\n        for i in range(len(current_sol)):\n            new_sol = current_sol.copy()\n            new_sol[i] = 1 - new_sol[i]\n            if np.dot(new_sol, weights) <= capacity:\n                marginal_gains[i] = np.sum(objectives[selected] if current_sol[i] else objectives[selected])\n\n        # Targeted flips (top 20%)\n        flip_indices = np.argsort(marginal_gains)[-max(1, len(marginal_gains) // 5):]\n        for i in flip_indices:\n            new_sol = current_sol.copy()\n            new_sol[i] = 1 - new_sol[i]\n            if np.dot(new_sol, weights) <= capacity:\n                current_sol = new_sol\n\n        # Random flips (1-2) to avoid stagnation\n        random_flips = np.random.choice(len(current_sol), size=np.random.randint(1, 3), replace=False)\n        for i in random_flips:\n            new_sol = current_sol.copy()\n            new_sol[i] = 1 - new_sol[i]\n            if np.dot(new_sol, weights) <= capacity:\n                current_sol = new_sol\n\n    return current_sol\n```\n\n**Key Features**:\n1. **Diversity-aware selection**: Top 20% solutions by weighted objective sums.\n2. **Marginal gain flipping**: Targets items with highest gains in either objective.\n3. **Controlled randomness**: Adds 1-2 random flips per iteration to escape local optima.\n4. **Feasibility checks**: Ensures all generated neighbors are valid.\n\nThis heuristic balances exploitation (marginal gains) and exploration (random flips) while guaranteeing feasibility.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 123,
        "algorithm": "The algorithm selects the top 20% of solutions from the archive based on normalized objective sums, then performs a hybrid local search that alternates between flipping items with the highest combined marginal gains (prioritizing both objectives) and adding controlled random flips to escape local optima, ensuring feasibility by always checking the knapsack capacity constraint. The number of random flips is dynamically adjusted based on the solution's quality, balancing exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select top 20% solutions by normalized objective sums\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = np.max(objectives, axis=0)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0] / max_obj1 + objectives[:, 1] / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Step 3: Hybrid local search with targeted flips and controlled randomness\n    for _ in range(5):  # Number of iterations\n        # Targeted flips based on highest marginal gains\n        sorted_indices = np.argsort(-combined_gain)\n        for idx in sorted_indices[:min(3, len(sorted_indices))]:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        # Controlled random flips (1-2) to escape local optima\n        if np.random.rand() < 0.4:\n            random_flips = np.random.choice(len(base_solution), size=np.random.randint(1, 3), replace=False)\n            for idx in random_flips:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.5795222131417257,
            0.3543921411037445
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select top 20% solutions by normalized objective sums\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = np.max(objectives, axis=0)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0] / max_obj1 + objectives[:, 1] / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Step 3: Hybrid local search with targeted flips and controlled randomness\n    for _ in range(5):  # Number of iterations\n        # Targeted flips based on highest marginal gains\n        sorted_indices = np.argsort(-combined_gain)\n        for idx in sorted_indices[:min(3, len(sorted_indices))]:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        # Controlled random flips (1-2) to escape local optima\n        if np.random.rand() < 0.4:\n            random_flips = np.random.choice(len(base_solution), size=np.random.randint(1, 3), replace=False)\n            for idx in random_flips:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 4 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: - **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 124,
        "algorithm": "The algorithm selects top 20% of solutions from the archive based on normalized objective sums, then performs 5-10 iterations of targeted local search by flipping items with highest marginal gains in either objective while occasionally adding random flips to escape local optima, ensuring feasibility throughout. It prioritizes items with the highest value-to-weight ratios and iteratively refines solutions by comparing marginal gains across both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Perform 5-10 iterations of targeted local search\n    for _ in range(np.random.randint(5, 11)):\n        # Calculate marginal gains for both objectives\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n\n        # Identify items with highest marginal gains in either objective\n        high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n        # Flip items with highest marginal gains\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Add 1-2 random flips to escape local optima\n        random_flips = np.random.randint(1, 3)\n        for _ in range(random_flips):\n            candidate_idx = np.random.randint(len(weight_lst))\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n        # Iterative refinement: update base solution if better\n        if np.sum(value1_lst * new_solution) > np.sum(value1_lst * base_solution) or np.sum(value2_lst * new_solution) > np.sum(value2_lst * base_solution):\n            base_solution = new_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.3470830606433014,
            0.6947274208068848
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Perform 5-10 iterations of targeted local search\n    for _ in range(np.random.randint(5, 11)):\n        # Calculate marginal gains for both objectives\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n\n        # Identify items with highest marginal gains in either objective\n        high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n        # Flip items with highest marginal gains\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Add 1-2 random flips to escape local optima\n        random_flips = np.random.randint(1, 3)\n        for _ in range(random_flips):\n            candidate_idx = np.random.randint(len(weight_lst))\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n        # Iterative refinement: update base solution if better\n        if np.sum(value1_lst * new_solution) > np.sum(value1_lst * base_solution) or np.sum(value2_lst * new_solution) > np.sum(value2_lst * base_solution):\n            base_solution = new_solution.copy()\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid criterion that balances normalized objective values and diversity, then performs a targeted local search by flipping high-marginal-gain items (with 60% weight on value1 and 40% on value2) and occasionally perturbing low-contribution items with dynamic probability, while ensuring feasibility.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine normalized objectives with diversity consideration\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = []\n        for i, (sol, obj) in enumerate(archive):\n            # Calculate diversity score (distance to other solutions)\n            diversity = 0\n            for j, (other_sol, _) in enumerate(archive):\n                if i != j:\n                    diversity += np.sum(sol != other_sol)\n            weighted_score = 0.5 * (0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) + 0.5 * (diversity / len(archive))\n            normalized_scores.append(weighted_score)\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search with multi-objective gain calculation\n    marginal_gain1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n    combined_gain = 0.6 * marginal_gain1 + 0.4 * marginal_gain2\n\n    # Dynamic selection of items to flip based on solution quality\n    solution_quality = (archive[selected_idx][1][0] + archive[selected_idx][1][1]) / (max_obj1 + max_obj2 + 1e-6)\n    num_high_gain = max(1, int(5 * (1 - solution_quality)))  # More flips for lower-quality solutions\n    high_gain_indices = np.argsort(-combined_gain)[:min(num_high_gain, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Dynamic perturbation probability\n    perturbation_prob = 0.3 + 0.4 * (1 - solution_quality)\n    if np.random.rand() < perturbation_prob:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 125,
        "algorithm": "The algorithm combines adaptive solution selection (prioritizing both objective quality and structural diversity) with a hybrid local search that first flips high-gain items and then perturbs low-contribution items probabilistically, ensuring feasibility through iterative refinement. The selection process weights objectives (70%/30% priority) and diversity (40% weight), while the local search balances exploitation (structured flips) and exploration (dynamic perturbations).",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine normalized objectives with solution structure diversity\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = []\n        for i, (sol, obj) in enumerate(archive):\n            # Calculate structure diversity (Hamming distance to other solutions)\n            diversity = 0\n            for j, (other_sol, _) in enumerate(archive):\n                if i != j:\n                    diversity += np.sum(sol != other_sol)\n            # Weighted score combining objectives and diversity\n            obj_score = 0.7 * (obj[0]/max_obj1) + 0.3 * (obj[1]/max_obj2)\n            weighted_score = 0.6 * obj_score + 0.4 * (diversity / (len(archive) * len(weight_lst)))\n            normalized_scores.append(weighted_score)\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-6)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n\n    # Phase 1: Structured flip of high-gain items\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 2: Dynamic perturbation of low-contribution items\n    solution_quality = (archive[selected_idx][1][0] + archive[selected_idx][1][1]) / (max_obj1 + max_obj2 + 1e-6)\n    perturbation_prob = 0.2 + 0.3 * (1 - solution_quality)\n    low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n    for idx in low_gain_indices:\n        if np.random.rand() < perturbation_prob:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 3: Iterative refinement with multi-phase acceptance\n    for _ in range(3):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            # Calculate improvement in both objectives\n            old_obj = archive[selected_idx][1]\n            new_obj1 = np.sum(value1_lst * temp_solution)\n            new_obj2 = np.sum(value2_lst * temp_solution)\n            # Accept if at least one objective improves\n            if (new_obj1 > old_obj[0]) or (new_obj2 > old_obj[1]):\n                new_solution = temp_solution\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.844005306588288,
            3.0170426666736603
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine normalized objectives with solution structure diversity\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = []\n        for i, (sol, obj) in enumerate(archive):\n            # Calculate structure diversity (Hamming distance to other solutions)\n            diversity = 0\n            for j, (other_sol, _) in enumerate(archive):\n                if i != j:\n                    diversity += np.sum(sol != other_sol)\n            # Weighted score combining objectives and diversity\n            obj_score = 0.7 * (obj[0]/max_obj1) + 0.3 * (obj[1]/max_obj2)\n            weighted_score = 0.6 * obj_score + 0.4 * (diversity / (len(archive) * len(weight_lst)))\n            normalized_scores.append(weighted_score)\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-6)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n\n    # Phase 1: Structured flip of high-gain items\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 2: Dynamic perturbation of low-contribution items\n    solution_quality = (archive[selected_idx][1][0] + archive[selected_idx][1][1]) / (max_obj1 + max_obj2 + 1e-6)\n    perturbation_prob = 0.2 + 0.3 * (1 - solution_quality)\n    low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n    for idx in low_gain_indices:\n        if np.random.rand() < perturbation_prob:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 3: Iterative refinement with multi-phase acceptance\n    for _ in range(3):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            # Calculate improvement in both objectives\n            old_obj = archive[selected_idx][1]\n            new_obj1 = np.sum(value1_lst * temp_solution)\n            new_obj2 = np.sum(value2_lst * temp_solution)\n            # Accept if at least one objective improves\n            if (new_obj1 > old_obj[0]) or (new_obj2 > old_obj[1]):\n                new_solution = temp_solution\n                break\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects top 30% solutions from the archive based on a hybrid score combining normalized objectives (60% value1, 40% value2) and crowding distance, then performs a three-phase local search: first flipping high-marginal-gain items (weighted 50-50 for both objectives), followed by probabilistic flips of medium-marginal-gain items (40% chance), and finally flipping low-marginal-gain items (20% chance) to explore diverse neighborhoods while maintaining feasibility.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by hybrid score (objective + crowding)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_obj[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_obj[sorted_idx[-1], m] != normalized_obj[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_obj[sorted_idx[i+1], m] - normalized_obj[sorted_idx[i-1], m]) / (normalized_obj[sorted_idx[-1], m] - normalized_obj[sorted_idx[0], m])\n    hybrid_score = 0.6 * normalized_obj[:, 0] + 0.4 * normalized_obj[:, 1] + 0.5 * crowding / (np.max(crowding) + 1e-10)\n    top_indices = np.argsort(-hybrid_score)[:max(1, len(archive)//3)]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Flip top 8 high-marginal-gain items\n    combined_gain = 0.5 * (value1_lst / weight_lst) + 0.5 * (value2_lst / weight_lst)\n    high_gain_indices = np.argsort(-combined_gain)[:8]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Probabilistic flip of medium-marginal-gain items\n    medium_gain_indices = np.argsort(-combined_gain)[8:min(15, len(weight_lst))]\n    for idx in np.random.permutation(medium_gain_indices):\n        if np.random.rand() < 0.4:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 3: Probabilistic flip of low-marginal-gain items\n    low_gain_indices = np.argsort(combined_gain)[:min(10, len(weight_lst))]\n    for idx in np.random.permutation(low_gain_indices):\n        if np.random.rand() < 0.2:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid criterion that balances normalized objective values and diversity, then performs a targeted local search by flipping high-marginal-gain items (with 60% weight on value1 and 40% on value2) and occasionally perturbing low-contribution items with dynamic probability, while ensuring feasibility.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine normalized objectives with diversity consideration\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = []\n        for i, (sol, obj) in enumerate(archive):\n            # Calculate diversity score (distance to other solutions)\n            diversity = 0\n            for j, (other_sol, _) in enumerate(archive):\n                if i != j:\n                    diversity += np.sum(sol != other_sol)\n            weighted_score = 0.5 * (0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) + 0.5 * (diversity / len(archive))\n            normalized_scores.append(weighted_score)\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search with multi-objective gain calculation\n    marginal_gain1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n    combined_gain = 0.6 * marginal_gain1 + 0.4 * marginal_gain2\n\n    # Dynamic selection of items to flip based on solution quality\n    solution_quality = (archive[selected_idx][1][0] + archive[selected_idx][1][1]) / (max_obj1 + max_obj2 + 1e-6)\n    num_high_gain = max(1, int(5 * (1 - solution_quality)))  # More flips for lower-quality solutions\n    high_gain_indices = np.argsort(-combined_gain)[:min(num_high_gain, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Dynamic perturbation probability\n    perturbation_prob = 0.3 + 0.4 * (1 - solution_quality)\n    if np.random.rand() < perturbation_prob:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 126,
        "algorithm": "The algorithm selects promising solutions from the archive (top 20% by combined normalized objectives), then performs a multi-phase local search: first flipping items with highest marginal gains in either objective, followed by controlled random perturbations (1-2 flips) to maintain diversity while ensuring feasibility. The process repeats 5-10 times per solution to incrementally refine it, balancing exploitation of high-quality regions with exploration of neighboring solutions. The key design choices prioritize items with strong marginal gains in either objective while allowing occasional random perturbations to escape local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by combined normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    combined_score = np.sum(normalized_obj, axis=1)\n    top_indices = np.argsort(-combined_score)[:max(1, len(archive)//5)]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Multi-phase local search\n    for _ in range(np.random.randint(5, 11)):\n        # Phase 1: Flip items with highest marginal gains in either objective\n        marginal_gain1 = value1_lst / (weight_lst + 1e-6)\n        marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n\n        # Select items with top marginal gains in either objective\n        top_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n        for idx in top_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Phase 2: Controlled random perturbation (1-2 flips)\n        perturbation_indices = np.random.choice(range(len(weight_lst)), size=np.random.randint(1, 3), replace=False)\n        for idx in perturbation_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        # Update base solution for next iteration\n        base_solution = new_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.3712299601142125,
            0.9174838662147522
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by combined normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    combined_score = np.sum(normalized_obj, axis=1)\n    top_indices = np.argsort(-combined_score)[:max(1, len(archive)//5)]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Multi-phase local search\n    for _ in range(np.random.randint(5, 11)):\n        # Phase 1: Flip items with highest marginal gains in either objective\n        marginal_gain1 = value1_lst / (weight_lst + 1e-6)\n        marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n\n        # Select items with top marginal gains in either objective\n        top_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n        for idx in top_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Phase 2: Controlled random perturbation (1-2 flips)\n        perturbation_indices = np.random.choice(range(len(weight_lst)), size=np.random.randint(1, 3), replace=False)\n        for idx in perturbation_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        # Update base solution for next iteration\n        base_solution = new_solution.copy()\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the archive using a hybrid criterion that balances normalized objective values and diversity, then performs a targeted local search by flipping high-marginal-gain items (with 60% weight on value1 and 40% on value2) and occasionally perturbing low-contribution items with dynamic probability, while ensuring feasibility.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine normalized objectives with diversity consideration\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = []\n        for i, (sol, obj) in enumerate(archive):\n            # Calculate diversity score (distance to other solutions)\n            diversity = 0\n            for j, (other_sol, _) in enumerate(archive):\n                if i != j:\n                    diversity += np.sum(sol != other_sol)\n            weighted_score = 0.5 * (0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) + 0.5 * (diversity / len(archive))\n            normalized_scores.append(weighted_score)\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search with multi-objective gain calculation\n    marginal_gain1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n    combined_gain = 0.6 * marginal_gain1 + 0.4 * marginal_gain2\n\n    # Dynamic selection of items to flip based on solution quality\n    solution_quality = (archive[selected_idx][1][0] + archive[selected_idx][1][1]) / (max_obj1 + max_obj2 + 1e-6)\n    num_high_gain = max(1, int(5 * (1 - solution_quality)))  # More flips for lower-quality solutions\n    high_gain_indices = np.argsort(-combined_gain)[:min(num_high_gain, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Dynamic perturbation probability\n    perturbation_prob = 0.3 + 0.4 * (1 - solution_quality)\n    if np.random.rand() < perturbation_prob:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 127,
        "algorithm": "The algorithm selects a promising solution from the archive using a hybrid criterion that balances solution quality (normalized objectives) and diversity (Hamming distance), then performs a novel local search by adaptively flipping items based on their marginal gain, with dynamic flip counts and perturbation probabilities that depend on the solution's quality. It prioritizes higher-gain items and adjusts exploration/exploitation through weighted objectives and adaptive probabilities.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine normalized objectives with solution quality and diversity\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = []\n        for i, (sol, obj) in enumerate(archive):\n            # Calculate solution quality (normalized sum of objectives)\n            quality = (obj[0]/max_obj1 + obj[1]/max_obj2) / 2\n            # Calculate diversity (average hamming distance to other solutions)\n            diversity = np.mean([np.sum(sol != other_sol) for j, (other_sol, _) in enumerate(archive) if i != j])\n            # Weighted score combining quality and diversity\n            weighted_score = 0.6 * quality + 0.4 * diversity\n            normalized_scores.append(weighted_score)\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains with adaptive weights\n    solution_quality = (archive[selected_idx][1][0] + archive[selected_idx][1][1]) / (max_obj1 + max_obj2 + 1e-6)\n    obj1_weight = 0.7 - 0.2 * solution_quality  # More emphasis on obj1 for better solutions\n    obj2_weight = 1 - obj1_weight\n    marginal_gain1 = value1_lst / (weight_lst + 1e-6)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n    combined_gain = obj1_weight * marginal_gain1 + obj2_weight * marginal_gain2\n\n    # Dynamic selection of items to flip based on gain and solution quality\n    num_flips = max(1, int(3 * (1 - solution_quality)))  # More flips for lower-quality solutions\n    flip_indices = np.argsort(-combined_gain)[:min(num_flips, len(weight_lst))]\n\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive perturbation with solution quality and gain\n    perturbation_prob = 0.2 + 0.5 * (1 - solution_quality)\n    if np.random.rand() < perturbation_prob:\n        # Perturb low-gain items with higher probability for better solutions\n        low_gain_prob = 0.3 + 0.4 * solution_quality\n        for idx in range(len(weight_lst)):\n            if np.random.rand() < low_gain_prob:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.44151179338058694,
            0.4420907497406006
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine normalized objectives with solution quality and diversity\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = []\n        for i, (sol, obj) in enumerate(archive):\n            # Calculate solution quality (normalized sum of objectives)\n            quality = (obj[0]/max_obj1 + obj[1]/max_obj2) / 2\n            # Calculate diversity (average hamming distance to other solutions)\n            diversity = np.mean([np.sum(sol != other_sol) for j, (other_sol, _) in enumerate(archive) if i != j])\n            # Weighted score combining quality and diversity\n            weighted_score = 0.6 * quality + 0.4 * diversity\n            normalized_scores.append(weighted_score)\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains with adaptive weights\n    solution_quality = (archive[selected_idx][1][0] + archive[selected_idx][1][1]) / (max_obj1 + max_obj2 + 1e-6)\n    obj1_weight = 0.7 - 0.2 * solution_quality  # More emphasis on obj1 for better solutions\n    obj2_weight = 1 - obj1_weight\n    marginal_gain1 = value1_lst / (weight_lst + 1e-6)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n    combined_gain = obj1_weight * marginal_gain1 + obj2_weight * marginal_gain2\n\n    # Dynamic selection of items to flip based on gain and solution quality\n    num_flips = max(1, int(3 * (1 - solution_quality)))  # More flips for lower-quality solutions\n    flip_indices = np.argsort(-combined_gain)[:min(num_flips, len(weight_lst))]\n\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive perturbation with solution quality and gain\n    perturbation_prob = 0.2 + 0.5 * (1 - solution_quality)\n    if np.random.rand() < perturbation_prob:\n        # Perturb low-gain items with higher probability for better solutions\n        low_gain_prob = 0.3 + 0.4 * solution_quality\n        for idx in range(len(weight_lst)):\n            if np.random.rand() < low_gain_prob:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the archive using a hybrid criterion that balances normalized objective values and diversity, then performs a targeted local search by flipping high-marginal-gain items (with 60% weight on value1 and 40% on value2) and occasionally perturbing low-contribution items with dynamic probability, while ensuring feasibility.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine normalized objectives with diversity consideration\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = []\n        for i, (sol, obj) in enumerate(archive):\n            # Calculate diversity score (distance to other solutions)\n            diversity = 0\n            for j, (other_sol, _) in enumerate(archive):\n                if i != j:\n                    diversity += np.sum(sol != other_sol)\n            weighted_score = 0.5 * (0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) + 0.5 * (diversity / len(archive))\n            normalized_scores.append(weighted_score)\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search with multi-objective gain calculation\n    marginal_gain1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n    combined_gain = 0.6 * marginal_gain1 + 0.4 * marginal_gain2\n\n    # Dynamic selection of items to flip based on solution quality\n    solution_quality = (archive[selected_idx][1][0] + archive[selected_idx][1][1]) / (max_obj1 + max_obj2 + 1e-6)\n    num_high_gain = max(1, int(5 * (1 - solution_quality)))  # More flips for lower-quality solutions\n    high_gain_indices = np.argsort(-combined_gain)[:min(num_high_gain, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Dynamic perturbation probability\n    perturbation_prob = 0.3 + 0.4 * (1 - solution_quality)\n    if np.random.rand() < perturbation_prob:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 128,
        "algorithm": "The algorithm selects a promising solution from the archive using diversity-aware adaptive weights (prioritizing value1 over value2) and then applies a targeted local search by flipping high-marginal-gain items while ensuring feasibility, followed by a solution-quality-dependent perturbation to escape local optima. The marginal gains are adaptively weighted based on solution quality, and the perturbation probability increases with lower-quality solutions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Diversity-aware selection with adaptive objective weights\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = []\n        for i, (sol, obj) in enumerate(archive):\n            # Adaptive objective weights based on archive size\n            weight1 = 0.7 * (1 - 0.2 * (len(archive) / len(weight_lst)))\n            weight2 = 1 - weight1\n            diversity = 0\n            for j, (other_sol, _) in enumerate(archive):\n                if i != j:\n                    diversity += np.sum(sol != other_sol)\n            weighted_score = 0.6 * (weight1 * obj[0]/max_obj1 + weight2 * obj[1]/max_obj2) + 0.4 * (diversity / len(archive))\n            normalized_scores.append(weighted_score)\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive marginal gain calculation with solution quality\n    marginal_gain1 = value1_lst / (weight_lst + 1e-6)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n    solution_quality = (archive[selected_idx][1][0] + archive[selected_idx][1][1]) / (max_obj1 + max_obj2 + 1e-6)\n    weight1 = 0.7 * (1 - 0.3 * solution_quality)\n    weight2 = 1 - weight1\n    combined_gain = weight1 * marginal_gain1 + weight2 * marginal_gain2\n\n    # Targeted item selection based on adaptive gain and capacity\n    num_high_gain = max(1, int(4 * (1 - solution_quality)))\n    high_gain_indices = np.argsort(-combined_gain)[:min(num_high_gain, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Solution-quality-dependent perturbation\n    perturbation_prob = 0.2 + 0.5 * (1 - solution_quality)\n    if np.random.rand() < perturbation_prob:\n        low_gain_indices = np.argsort(combined_gain)[:min(2, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.888656421375257,
            2.963331937789917
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Diversity-aware selection with adaptive objective weights\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = []\n        for i, (sol, obj) in enumerate(archive):\n            # Adaptive objective weights based on archive size\n            weight1 = 0.7 * (1 - 0.2 * (len(archive) / len(weight_lst)))\n            weight2 = 1 - weight1\n            diversity = 0\n            for j, (other_sol, _) in enumerate(archive):\n                if i != j:\n                    diversity += np.sum(sol != other_sol)\n            weighted_score = 0.6 * (weight1 * obj[0]/max_obj1 + weight2 * obj[1]/max_obj2) + 0.4 * (diversity / len(archive))\n            normalized_scores.append(weighted_score)\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive marginal gain calculation with solution quality\n    marginal_gain1 = value1_lst / (weight_lst + 1e-6)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n    solution_quality = (archive[selected_idx][1][0] + archive[selected_idx][1][1]) / (max_obj1 + max_obj2 + 1e-6)\n    weight1 = 0.7 * (1 - 0.3 * solution_quality)\n    weight2 = 1 - weight1\n    combined_gain = weight1 * marginal_gain1 + weight2 * marginal_gain2\n\n    # Targeted item selection based on adaptive gain and capacity\n    num_high_gain = max(1, int(4 * (1 - solution_quality)))\n    high_gain_indices = np.argsort(-combined_gain)[:min(num_high_gain, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Solution-quality-dependent perturbation\n    perturbation_prob = 0.2 + 0.5 * (1 - solution_quality)\n    if np.random.rand() < perturbation_prob:\n        low_gain_indices = np.argsort(combined_gain)[:min(2, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 4 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid criterion that balances normalized objective values and diversity, then performs a targeted local search by flipping high-marginal-gain items (with 60% weight on value1 and 40% on value2) and occasionally perturbing low-contribution items with dynamic probability, while ensuring feasibility.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine normalized objectives with diversity consideration\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = []\n        for i, (sol, obj) in enumerate(archive):\n            # Calculate diversity score (distance to other solutions)\n            diversity = 0\n            for j, (other_sol, _) in enumerate(archive):\n                if i != j:\n                    diversity += np.sum(sol != other_sol)\n            weighted_score = 0.5 * (0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) + 0.5 * (diversity / len(archive))\n            normalized_scores.append(weighted_score)\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search with multi-objective gain calculation\n    marginal_gain1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n    combined_gain = 0.6 * marginal_gain1 + 0.4 * marginal_gain2\n\n    # Dynamic selection of items to flip based on solution quality\n    solution_quality = (archive[selected_idx][1][0] + archive[selected_idx][1][1]) / (max_obj1 + max_obj2 + 1e-6)\n    num_high_gain = max(1, int(5 * (1 - solution_quality)))  # More flips for lower-quality solutions\n    high_gain_indices = np.argsort(-combined_gain)[:min(num_high_gain, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Dynamic perturbation probability\n    perturbation_prob = 0.3 + 0.4 * (1 - solution_quality)\n    if np.random.rand() < perturbation_prob:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 129,
        "algorithm": "The algorithm selects promising solutions from the top 20% of the archive (based on normalized objective sums) and iteratively refines them by prioritizing items with high marginal gains in either objective, adding controlled random flips, and occasionally perturbing low-contribution items, ensuring feasibility at each step. It balances exploitation of high-value items with exploration through multiple iterations (5-10) of targeted and random flips. The solution is updated incrementally while maintaining feasibility, with low-contribution items being perturbed with 30% probability.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Iterative refinement: 5-10 iterations\n    for _ in range(np.random.randint(5, 11)):\n        # Targeted flips: highest marginal gains in either objective\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n        high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Add 1-2 random flips\n        n_random_flips = np.random.randint(1, 3)\n        for _ in range(n_random_flips):\n            candidate_idx = np.random.randint(len(weight_lst))\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n        # Controlled perturbation: flip low-marginal-contribution items\n        if np.random.rand() < 0.3:\n            low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n            for idx in low_gain_indices:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        base_solution = new_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.3290211024152907,
            0.5060948431491852
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Iterative refinement: 5-10 iterations\n    for _ in range(np.random.randint(5, 11)):\n        # Targeted flips: highest marginal gains in either objective\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n        high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Add 1-2 random flips\n        n_random_flips = np.random.randint(1, 3)\n        for _ in range(n_random_flips):\n            candidate_idx = np.random.randint(len(weight_lst))\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n        # Controlled perturbation: flip low-marginal-contribution items\n        if np.random.rand() < 0.3:\n            low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n            for idx in low_gain_indices:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        base_solution = new_solution.copy()\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 4 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: - **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 130,
        "algorithm": "The algorithm selects promising solutions from the top 20% of the archive (based on normalized objective sums), prioritizes flipping items with high marginal gains in either objective, and adds random feasible flips to balance exploitation and exploration. It then performs iterative refinement (5-10 times) to ensure feasibility, focusing on items with the highest value-to-weight ratios and random perturbations for diversity. The solution prioritizes high-value items while maintaining feasibility through careful weight checks during flips.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Flip items with highest marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips (ensuring feasibility)\n    num_random_flips = np.random.randint(1, 3)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement (5-10 times)\n    for _ in range(np.random.randint(5, 11)):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.7173434415271929,
            0.22864550352096558
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Flip items with highest marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips (ensuring feasibility)\n    num_random_flips = np.random.randint(1, 3)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement (5-10 times)\n    for _ in range(np.random.randint(5, 11)):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects from the top 20% of non-dominated solutions (weighted equally on normalized objectives) and performs a local search by flipping high-gain items (60% prioritizing value1, 40% prioritizing value2) while occasionally perturbing low-gain items (30% probability) to balance exploration and exploitation, always ensuring feasibility.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by equally weighted normalized objectives\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.5 * obj[0]/max_obj1 + 0.5 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Local search: flip items with highest combined gain (60% value1, 40% value2)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.6 * marginal_gain1 + 0.4 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-gain items with 30% probability\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm first selects promising solutions from the top 30% of the archive based on normalized trade-offs, then prioritizes those with high crowding distances for further improvement. It generates neighbors by flipping items with the highest combined marginal gains for both objectives, followed by a dynamic number of random flips (scaled inversely to crowding distance), and finally ensures feasibility through iterative removal of the least valuable items when capacity is exceeded. The solution prioritizes exploration in crowded regions while maintaining high-quality improvements through marginal gain-based flips.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by normalized trade-offs\n    objectives = np.array([obj for _, obj in archive])\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    top_indices = np.argsort(trade_off)[-max(1, len(archive) // 3):]\n\n    # Calculate crowding distances for selected solutions\n    selected_objectives = objectives[top_indices]\n    normalized_objectives = (selected_objectives - np.min(selected_objectives, axis=0)) / (np.max(selected_objectives, axis=0) - np.min(selected_objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(top_indices))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(top_indices)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = top_indices[np.argmax(crowding)]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain-based flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (inverse to crowding distance)\n    n_random_flips = max(1, int(10 * (1 / (crowding[np.argmax(crowding)] + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove least valuable item (min of value1 and value2)\n        remove_idx = removable_items[np.argmin(np.minimum(value1_lst[removable_items], value2_lst[removable_items]))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 131,
        "algorithm": "The algorithm selects promising solutions from the top 30% of the archive based on normalized trade-offs and crowding distance, then performs a hybrid local search combining marginal gain analysis with adaptive cluster-based perturbations. It prioritizes high-gain items while dynamically adjusting cluster perturbations based on solution crowding, ensuring feasibility through iterative refinement.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by normalized trade-offs\n    objectives = np.array([obj for _, obj in archive])\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    top_indices = np.argsort(trade_off)[-max(1, len(archive) // 3):]\n\n    # Calculate crowding distances for selected solutions\n    selected_objectives = objectives[top_indices]\n    normalized_objectives = (selected_objectives - np.min(selected_objectives, axis=0)) / (np.max(selected_objectives, axis=0) - np.min(selected_objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(top_indices))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(top_indices)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance\n    selected_idx = top_indices[np.argmax(crowding)]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains and identify clusters\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Cluster items with similar marginal gains\n    from sklearn.cluster import KMeans\n    n_clusters = min(5, len(weight_lst) // 3)\n    if n_clusters > 1:\n        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n        clusters = kmeans.fit_predict(combined_gain.reshape(-1, 1))\n    else:\n        clusters = np.zeros(len(weight_lst), dtype=int)\n\n    # Strategic flips: prioritize high-gain items\n    sorted_indices = np.argsort(combined_gain)[::-1]\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Adaptive cluster perturbations\n    n_perturbations = max(1, int(5 * (1 / (crowding[np.argmax(crowding)] + 1))))\n    for _ in range(n_perturbations):\n        cluster_idx = np.random.randint(n_clusters)\n        cluster_items = np.where(clusters == cluster_idx)[0]\n\n        # Flip entire cluster with 50% probability\n        if np.random.rand() < 0.5:\n            for idx in cluster_items:\n                if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove least valuable item (min of combined value)\n        remove_idx = removable_items[np.argmin(value1_lst[removable_items] + value2_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8145091609625066,
            2.973714143037796
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by normalized trade-offs\n    objectives = np.array([obj for _, obj in archive])\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    top_indices = np.argsort(trade_off)[-max(1, len(archive) // 3):]\n\n    # Calculate crowding distances for selected solutions\n    selected_objectives = objectives[top_indices]\n    normalized_objectives = (selected_objectives - np.min(selected_objectives, axis=0)) / (np.max(selected_objectives, axis=0) - np.min(selected_objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(top_indices))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(top_indices)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance\n    selected_idx = top_indices[np.argmax(crowding)]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains and identify clusters\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Cluster items with similar marginal gains\n    from sklearn.cluster import KMeans\n    n_clusters = min(5, len(weight_lst) // 3)\n    if n_clusters > 1:\n        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n        clusters = kmeans.fit_predict(combined_gain.reshape(-1, 1))\n    else:\n        clusters = np.zeros(len(weight_lst), dtype=int)\n\n    # Strategic flips: prioritize high-gain items\n    sorted_indices = np.argsort(combined_gain)[::-1]\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Adaptive cluster perturbations\n    n_perturbations = max(1, int(5 * (1 / (crowding[np.argmax(crowding)] + 1))))\n    for _ in range(n_perturbations):\n        cluster_idx = np.random.randint(n_clusters)\n        cluster_items = np.where(clusters == cluster_idx)[0]\n\n        # Flip entire cluster with 50% probability\n        if np.random.rand() < 0.5:\n            for idx in cluster_items:\n                if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove least valuable item (min of combined value)\n        remove_idx = removable_items[np.argmin(value1_lst[removable_items] + value2_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm first selects promising solutions from the top 30% of the archive based on normalized trade-offs, then prioritizes those with high crowding distances for further improvement. It generates neighbors by flipping items with the highest combined marginal gains for both objectives, followed by a dynamic number of random flips (scaled inversely to crowding distance), and finally ensures feasibility through iterative removal of the least valuable items when capacity is exceeded. The solution prioritizes exploration in crowded regions while maintaining high-quality improvements through marginal gain-based flips.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by normalized trade-offs\n    objectives = np.array([obj for _, obj in archive])\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    top_indices = np.argsort(trade_off)[-max(1, len(archive) // 3):]\n\n    # Calculate crowding distances for selected solutions\n    selected_objectives = objectives[top_indices]\n    normalized_objectives = (selected_objectives - np.min(selected_objectives, axis=0)) / (np.max(selected_objectives, axis=0) - np.min(selected_objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(top_indices))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(top_indices)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = top_indices[np.argmax(crowding)]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain-based flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (inverse to crowding distance)\n    n_random_flips = max(1, int(10 * (1 / (crowding[np.argmax(crowding)] + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove least valuable item (min of value1 and value2)\n        remove_idx = removable_items[np.argmin(np.minimum(value1_lst[removable_items], value2_lst[removable_items]))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 132,
        "algorithm": "The algorithm first clusters solutions in the archive based on their objective trade-offs, then selects a representative from the least explored cluster to generate neighbors. It prioritizes flipping items with high marginal gains in the objective with higher variance within the cluster, followed by controlled random flips proportional to the cluster's exploration potential, while ensuring feasibility through iterative removal of least valuable items. The method combines marginal gain optimization with diversity-aware exploration for balanced multi-objective improvement.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Extract solutions and objectives\n    solutions = np.array([s for s, _ in archive])\n    objectives = np.array([obj for _, obj in archive])\n\n    # Cluster solutions based on objective trade-offs\n    from sklearn.cluster import KMeans\n    n_clusters = min(5, len(archive) // 3)\n    if n_clusters < 2:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n        cluster_labels = kmeans.fit_predict(objectives)\n\n        # Calculate cluster exploration potential\n        cluster_potentials = []\n        for i in range(n_clusters):\n            cluster_solutions = solutions[cluster_labels == i]\n            if len(cluster_solutions) == 0:\n                cluster_potentials.append(0)\n                continue\n            # Calculate solution diversity within cluster\n            diversity = np.mean([np.sum(np.abs(s1 - s2)) for s1 in cluster_solutions for s2 in cluster_solutions])\n            # Calculate objective diversity within cluster\n            cluster_objectives = objectives[cluster_labels == i]\n            obj_diversity = np.mean([np.linalg.norm(obj1 - obj2) for obj1 in cluster_objectives for obj2 in cluster_objectives])\n            cluster_potentials.append(diversity * obj_diversity)\n\n        # Select least explored cluster\n        selected_cluster = np.argmin(cluster_potentials)\n        cluster_indices = np.where(cluster_labels == selected_cluster)[0]\n        selected_idx = np.random.choice(cluster_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Determine which objective to prioritize based on cluster variance\n    cluster_objectives = objectives[cluster_labels == selected_cluster]\n    obj1_var = np.var(cluster_objectives[:, 0])\n    obj2_var = np.var(cluster_objectives[:, 1])\n\n    # Flip items with highest marginal gains in the objective with higher variance\n    if obj1_var > obj2_var:\n        sorted_indices = np.argsort(marginal_gain1)[::-1]\n    else:\n        sorted_indices = np.argsort(marginal_gain2)[::-1]\n\n    max_flips = min(5, len(weight_lst))\n    for idx in sorted_indices[:max_flips]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add controlled random flips (scaled by cluster exploration potential)\n    n_random_flips = max(1, int(5 * (cluster_potentials[selected_cluster] / (np.sum(cluster_potentials) + 1e-10))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility through iterative refinement\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove least valuable item (min of both objectives)\n        remove_idx = removable_items[np.argmin(np.minimum(value1_lst[removable_items], value2_lst[removable_items]))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8824799309563233,
            4.934856802225113
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Extract solutions and objectives\n    solutions = np.array([s for s, _ in archive])\n    objectives = np.array([obj for _, obj in archive])\n\n    # Cluster solutions based on objective trade-offs\n    from sklearn.cluster import KMeans\n    n_clusters = min(5, len(archive) // 3)\n    if n_clusters < 2:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n        cluster_labels = kmeans.fit_predict(objectives)\n\n        # Calculate cluster exploration potential\n        cluster_potentials = []\n        for i in range(n_clusters):\n            cluster_solutions = solutions[cluster_labels == i]\n            if len(cluster_solutions) == 0:\n                cluster_potentials.append(0)\n                continue\n            # Calculate solution diversity within cluster\n            diversity = np.mean([np.sum(np.abs(s1 - s2)) for s1 in cluster_solutions for s2 in cluster_solutions])\n            # Calculate objective diversity within cluster\n            cluster_objectives = objectives[cluster_labels == i]\n            obj_diversity = np.mean([np.linalg.norm(obj1 - obj2) for obj1 in cluster_objectives for obj2 in cluster_objectives])\n            cluster_potentials.append(diversity * obj_diversity)\n\n        # Select least explored cluster\n        selected_cluster = np.argmin(cluster_potentials)\n        cluster_indices = np.where(cluster_labels == selected_cluster)[0]\n        selected_idx = np.random.choice(cluster_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Determine which objective to prioritize based on cluster variance\n    cluster_objectives = objectives[cluster_labels == selected_cluster]\n    obj1_var = np.var(cluster_objectives[:, 0])\n    obj2_var = np.var(cluster_objectives[:, 1])\n\n    # Flip items with highest marginal gains in the objective with higher variance\n    if obj1_var > obj2_var:\n        sorted_indices = np.argsort(marginal_gain1)[::-1]\n    else:\n        sorted_indices = np.argsort(marginal_gain2)[::-1]\n\n    max_flips = min(5, len(weight_lst))\n    for idx in sorted_indices[:max_flips]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add controlled random flips (scaled by cluster exploration potential)\n    n_random_flips = max(1, int(5 * (cluster_potentials[selected_cluster] / (np.sum(cluster_potentials) + 1e-10))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Ensure feasibility through iterative refinement\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove least valuable item (min of both objectives)\n        remove_idx = removable_items[np.argmin(np.minimum(value1_lst[removable_items], value2_lst[removable_items]))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm first selects promising solutions from the top 30% of the archive based on normalized trade-offs, then prioritizes those with high crowding distances for further improvement. It generates neighbors by flipping items with the highest combined marginal gains for both objectives, followed by a dynamic number of random flips (scaled inversely to crowding distance), and finally ensures feasibility through iterative removal of the least valuable items when capacity is exceeded. The solution prioritizes exploration in crowded regions while maintaining high-quality improvements through marginal gain-based flips.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by normalized trade-offs\n    objectives = np.array([obj for _, obj in archive])\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    top_indices = np.argsort(trade_off)[-max(1, len(archive) // 3):]\n\n    # Calculate crowding distances for selected solutions\n    selected_objectives = objectives[top_indices]\n    normalized_objectives = (selected_objectives - np.min(selected_objectives, axis=0)) / (np.max(selected_objectives, axis=0) - np.min(selected_objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(top_indices))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(top_indices)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = top_indices[np.argmax(crowding)]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain-based flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (inverse to crowding distance)\n    n_random_flips = max(1, int(10 * (1 / (crowding[np.argmax(crowding)] + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove least valuable item (min of value1 and value2)\n        remove_idx = removable_items[np.argmin(np.minimum(value1_lst[removable_items], value2_lst[removable_items]))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 133,
        "algorithm": "The algorithm selects the solution with the highest hypervolume contribution from the archive, then applies a hybrid local search combining marginal-gain-based flips with an objective-balanced mechanism that prioritizes items with high combined marginal gains and balanced trade-offs between objectives. It dynamically scales the number of random flips based on the solution's distance to the ideal point and ensures feasibility through a trade-off-aware removal process that eliminates items with the poorest trade-offs between objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    selected_idx = np.argmax(hypervolume)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Objective-balanced flipping mechanism\n    trade_off = value2_lst / (value1_lst + 1e-10)\n    combined_score = (marginal_gain1 + marginal_gain2) * (1 + 0.5 * np.abs(trade_off - np.mean(trade_off)))\n    sorted_indices = np.argsort(combined_score)[::-1]\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (scaled by distance to ideal point)\n    distance_to_ideal = np.linalg.norm(ideal_point - objectives[selected_idx])\n    n_random_flips = max(1, int(5 * (1 / (distance_to_ideal + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Trade-off-aware feasibility restoration\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with poorest trade-off\n        item_trade_off = value2_lst[removable_items] / (value1_lst[removable_items] + 1e-10)\n        avg_trade_off = np.mean(item_trade_off)\n        remove_idx = removable_items[np.argmax(np.abs(item_trade_off - avg_trade_off))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9386445648038064,
            0.23346582055091858
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    selected_idx = np.argmax(hypervolume)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Objective-balanced flipping mechanism\n    trade_off = value2_lst / (value1_lst + 1e-10)\n    combined_score = (marginal_gain1 + marginal_gain2) * (1 + 0.5 * np.abs(trade_off - np.mean(trade_off)))\n    sorted_indices = np.argsort(combined_score)[::-1]\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (scaled by distance to ideal point)\n    distance_to_ideal = np.linalg.norm(ideal_point - objectives[selected_idx])\n    n_random_flips = max(1, int(5 * (1 / (distance_to_ideal + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Trade-off-aware feasibility restoration\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with poorest trade-off\n        item_trade_off = value2_lst[removable_items] / (value1_lst[removable_items] + 1e-10)\n        avg_trade_off = np.mean(item_trade_off)\n        remove_idx = removable_items[np.argmax(np.abs(item_trade_off - avg_trade_off))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm first selects promising solutions from the top 30% of the archive based on normalized trade-offs, then prioritizes those with high crowding distances for further improvement. It generates neighbors by flipping items with the highest combined marginal gains for both objectives, followed by a dynamic number of random flips (scaled inversely to crowding distance), and finally ensures feasibility through iterative removal of the least valuable items when capacity is exceeded. The solution prioritizes exploration in crowded regions while maintaining high-quality improvements through marginal gain-based flips.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by normalized trade-offs\n    objectives = np.array([obj for _, obj in archive])\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    top_indices = np.argsort(trade_off)[-max(1, len(archive) // 3):]\n\n    # Calculate crowding distances for selected solutions\n    selected_objectives = objectives[top_indices]\n    normalized_objectives = (selected_objectives - np.min(selected_objectives, axis=0)) / (np.max(selected_objectives, axis=0) - np.min(selected_objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(top_indices))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(top_indices)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = top_indices[np.argmax(crowding)]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain-based flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (inverse to crowding distance)\n    n_random_flips = max(1, int(10 * (1 / (crowding[np.argmax(crowding)] + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove least valuable item (min of value1 and value2)\n        remove_idx = removable_items[np.argmin(np.minimum(value1_lst[removable_items], value2_lst[removable_items]))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 133,
        "algorithm": "The algorithm selects the solution with the highest hypervolume contribution from the archive, then applies a hybrid local search combining marginal-gain-based flips with an objective-balanced mechanism that prioritizes items with high combined marginal gains and balanced trade-offs between objectives. It dynamically scales the number of random flips based on the solution's distance to the ideal point and ensures feasibility through a trade-off-aware removal process that eliminates items with the poorest trade-offs between objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    selected_idx = np.argmax(hypervolume)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Objective-balanced flipping mechanism\n    trade_off = value2_lst / (value1_lst + 1e-10)\n    combined_score = (marginal_gain1 + marginal_gain2) * (1 + 0.5 * np.abs(trade_off - np.mean(trade_off)))\n    sorted_indices = np.argsort(combined_score)[::-1]\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (scaled by distance to ideal point)\n    distance_to_ideal = np.linalg.norm(ideal_point - objectives[selected_idx])\n    n_random_flips = max(1, int(5 * (1 / (distance_to_ideal + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Trade-off-aware feasibility restoration\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with poorest trade-off\n        item_trade_off = value2_lst[removable_items] / (value1_lst[removable_items] + 1e-10)\n        avg_trade_off = np.mean(item_trade_off)\n        remove_idx = removable_items[np.argmax(np.abs(item_trade_off - avg_trade_off))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9386445648038064,
            0.23346582055091858
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    selected_idx = np.argmax(hypervolume)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Objective-balanced flipping mechanism\n    trade_off = value2_lst / (value1_lst + 1e-10)\n    combined_score = (marginal_gain1 + marginal_gain2) * (1 + 0.5 * np.abs(trade_off - np.mean(trade_off)))\n    sorted_indices = np.argsort(combined_score)[::-1]\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (scaled by distance to ideal point)\n    distance_to_ideal = np.linalg.norm(ideal_point - objectives[selected_idx])\n    n_random_flips = max(1, int(5 * (1 / (distance_to_ideal + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Trade-off-aware feasibility restoration\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with poorest trade-off\n        item_trade_off = value2_lst[removable_items] / (value1_lst[removable_items] + 1e-10)\n        avg_trade_off = np.mean(item_trade_off)\n        remove_idx = removable_items[np.argmax(np.abs(item_trade_off - avg_trade_off))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm first selects promising solutions from the top 30% of the archive based on normalized trade-offs, then prioritizes those with high crowding distances for further improvement. It generates neighbors by flipping items with the highest combined marginal gains for both objectives, followed by a dynamic number of random flips (scaled inversely to crowding distance), and finally ensures feasibility through iterative removal of the least valuable items when capacity is exceeded. The solution prioritizes exploration in crowded regions while maintaining high-quality improvements through marginal gain-based flips.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by normalized trade-offs\n    objectives = np.array([obj for _, obj in archive])\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    top_indices = np.argsort(trade_off)[-max(1, len(archive) // 3):]\n\n    # Calculate crowding distances for selected solutions\n    selected_objectives = objectives[top_indices]\n    normalized_objectives = (selected_objectives - np.min(selected_objectives, axis=0)) / (np.max(selected_objectives, axis=0) - np.min(selected_objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(top_indices))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(top_indices)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = top_indices[np.argmax(crowding)]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain-based flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (inverse to crowding distance)\n    n_random_flips = max(1, int(10 * (1 / (crowding[np.argmax(crowding)] + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove least valuable item (min of value1 and value2)\n        remove_idx = removable_items[np.argmin(np.minimum(value1_lst[removable_items], value2_lst[removable_items]))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 134,
        "algorithm": "The algorithm selects underperforming solutions (bottom 25% by normalized trade-offs) with low crowding distances, then generates neighbors by prioritizing items with high marginal gains for one objective (70% value1, 30% value2) while occasionally making random flips weighted by combined item contributions. It ensures feasibility by iteratively removing the least valuable items (value2) when capacity is exceeded.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select bottom 25% solutions by normalized trade-offs\n    objectives = np.array([obj for _, obj in archive])\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    bottom_indices = np.argsort(trade_off)[:max(1, len(archive) // 4)]\n\n    # Calculate crowding distances for selected solutions\n    selected_objectives = objectives[bottom_indices]\n    normalized_objectives = (selected_objectives - np.min(selected_objectives, axis=0)) / (np.max(selected_objectives, axis=0) - np.min(selected_objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(bottom_indices))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(bottom_indices)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    # Select solution with lowest crowding distance (targeted for improvement)\n    selected_idx = bottom_indices[np.argmin(crowding)]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain-based flips for one objective while considering the other\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 * 0.7 + marginal_gain2 * 0.3  # Prioritize value1 more\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Fixed number of random flips weighted by item's contribution to both objectives\n    n_random_flips = 3\n    flip_weights = (marginal_gain1 + marginal_gain2) / (np.sum(marginal_gain1) + np.sum(marginal_gain2) + 1e-10)\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.choice(len(weight_lst), p=flip_weights)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove least valuable item in the other objective (value2)\n        remove_idx = removable_items[np.argmin(value2_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.7950553481785472,
            0.40051931142807007
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select bottom 25% solutions by normalized trade-offs\n    objectives = np.array([obj for _, obj in archive])\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    bottom_indices = np.argsort(trade_off)[:max(1, len(archive) // 4)]\n\n    # Calculate crowding distances for selected solutions\n    selected_objectives = objectives[bottom_indices]\n    normalized_objectives = (selected_objectives - np.min(selected_objectives, axis=0)) / (np.max(selected_objectives, axis=0) - np.min(selected_objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(bottom_indices))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(bottom_indices)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    # Select solution with lowest crowding distance (targeted for improvement)\n    selected_idx = bottom_indices[np.argmin(crowding)]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain-based flips for one objective while considering the other\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 * 0.7 + marginal_gain2 * 0.3  # Prioritize value1 more\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Fixed number of random flips weighted by item's contribution to both objectives\n    n_random_flips = 3\n    flip_weights = (marginal_gain1 + marginal_gain2) / (np.sum(marginal_gain1) + np.sum(marginal_gain2) + 1e-10)\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.choice(len(weight_lst), p=flip_weights)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove least valuable item in the other objective (value2)\n        remove_idx = removable_items[np.argmin(value2_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 4 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm first selects promising solutions from the top 30% of the archive based on normalized trade-offs, then prioritizes those with high crowding distances for further improvement. It generates neighbors by flipping items with the highest combined marginal gains for both objectives, followed by a dynamic number of random flips (scaled inversely to crowding distance), and finally ensures feasibility through iterative removal of the least valuable items when capacity is exceeded. The solution prioritizes exploration in crowded regions while maintaining high-quality improvements through marginal gain-based flips.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by normalized trade-offs\n    objectives = np.array([obj for _, obj in archive])\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    top_indices = np.argsort(trade_off)[-max(1, len(archive) // 3):]\n\n    # Calculate crowding distances for selected solutions\n    selected_objectives = objectives[top_indices]\n    normalized_objectives = (selected_objectives - np.min(selected_objectives, axis=0)) / (np.max(selected_objectives, axis=0) - np.min(selected_objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(top_indices))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(top_indices)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = top_indices[np.argmax(crowding)]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain-based flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (inverse to crowding distance)\n    n_random_flips = max(1, int(10 * (1 / (crowding[np.argmax(crowding)] + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove least valuable item (min of value1 and value2)\n        remove_idx = removable_items[np.argmin(np.minimum(value1_lst[removable_items], value2_lst[removable_items]))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive (based on normalized objective sums) and generates neighbors by flipping items with high marginal gains for both objectives, followed by 1-2 random feasible flips, while ensuring feasibility through iterative refinement by removing the lightest items when needed. It prioritizes items with combined high marginal gains for both objectives while maintaining diversity through random flips.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain-based flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add 1-2 random feasible flips\n    for _ in range(np.random.randint(1, 3)):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 135,
        "algorithm": "The algorithm first selects promising solutions from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items while ensuring feasibility, followed by random flips to maintain diversity and iterative refinement to guarantee capacity constraints. It prioritizes items with the highest combined marginal gains in either objective while balancing exploitation and exploration through controlled randomness and feasibility checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with highest marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips to maintain diversity\n    for _ in range(np.random.randint(1, 3)):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(np.minimum(value1_lst[removable_items], value2_lst[removable_items]))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.7965225635661823,
            0.21574169397354126
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with highest marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips to maintain diversity\n    for _ in range(np.random.randint(1, 3)):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(np.minimum(value1_lst[removable_items], value2_lst[removable_items]))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 4 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: - **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 136,
        "algorithm": "The algorithm selects top 20% of solutions from the archive based on normalized objective sums, then performs targeted flips of high-marginal-gain items while ensuring feasibility, followed by occasional random flips of low-marginal-gain items (50% probability) to escape local optima, and iterates 5-10 times per solution for refinement. It prioritizes items with higher marginal gains (max of value1/weight or value2/weight) in the targeted flips, while random flips focus on low-marginal-gain items to diversify the search. The selection process ensures the algorithm focuses on promising regions of the solution space while maintaining feasibility through strict capacity checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted flips of high-marginal-gain items\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Random flips of low-marginal-gain items (50% chance)\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(2, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement (5-10 iterations)\n    for _ in range(np.random.randint(5, 11)):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.7299061972253482,
            0.20875737071037292
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted flips of high-marginal-gain items\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Random flips of low-marginal-gain items (50% chance)\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(2, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement (5-10 iterations)\n    for _ in range(np.random.randint(5, 11)):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the top 20% of the archive (based on normalized objective sums) and applies a hybrid local search: first flipping high-marginal-gain items (prioritized by combined value-to-weight ratios) and then randomly flipping low-marginal-contribution items (with 30% probability), while ensuring feasibility through iterative removal of the lightest items if capacity is exceeded. The method balances exploitation (targeted flips) and exploration (random flips) while limiting iterations to 5-10 per solution.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    n_items = len(weight_lst)\n\n    # Targeted flipping of high-marginal-gain items\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    high_gain_indices = np.argsort(combined_gain)[::-1][:min(5, n_items)]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random flips of low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, n_items)]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 137,
        "algorithm": "The algorithm selects promising solutions from the top 20% of the archive based on combined objective scores, then performs a targeted local search by flipping high-marginal-gain items prioritizing the least dominated objective, followed by controlled random perturbations and adaptive feasibility repairs to ensure capacity constraints are met while maintaining solution diversity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by combined objective score\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        combined_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(combined_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains and dominance information\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Identify items that improve the least dominated objective\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    # Targeted flipping of high-marginal-gain items prioritizing least dominated objective\n    if least_dominated == 1:\n        target_gain = marginal_gain1\n    else:\n        target_gain = marginal_gain2\n\n    high_gain_indices = np.argsort(target_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation of low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined marginal gain\n        removal_candidates = included_items[np.argsort(combined_gain[included_items])]\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.8483212636259411,
            0.21432334184646606
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by combined objective score\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        combined_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(combined_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains and dominance information\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Identify items that improve the least dominated objective\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    # Targeted flipping of high-marginal-gain items prioritizing least dominated objective\n    if least_dominated == 1:\n        target_gain = marginal_gain1\n    else:\n        target_gain = marginal_gain2\n\n    high_gain_indices = np.argsort(target_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation of low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined marginal gain\n        removal_candidates = included_items[np.argsort(combined_gain[included_items])]\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects the solution with the highest hypervolume contribution from the archive, then applies a hybrid local search combining marginal-gain-based flips with an objective-balanced mechanism that prioritizes items with high combined marginal gains and balanced trade-offs between objectives. It dynamically scales the number of random flips based on the solution's distance to the ideal point and ensures feasibility through a trade-off-aware removal process that eliminates items with the poorest trade-offs between objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    selected_idx = np.argmax(hypervolume)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Objective-balanced flipping mechanism\n    trade_off = value2_lst / (value1_lst + 1e-10)\n    combined_score = (marginal_gain1 + marginal_gain2) * (1 + 0.5 * np.abs(trade_off - np.mean(trade_off)))\n    sorted_indices = np.argsort(combined_score)[::-1]\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (scaled by distance to ideal point)\n    distance_to_ideal = np.linalg.norm(ideal_point - objectives[selected_idx])\n    n_random_flips = max(1, int(5 * (1 / (distance_to_ideal + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Trade-off-aware feasibility restoration\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with poorest trade-off\n        item_trade_off = value2_lst[removable_items] / (value1_lst[removable_items] + 1e-10)\n        avg_trade_off = np.mean(item_trade_off)\n        remove_idx = removable_items[np.argmax(np.abs(item_trade_off - avg_trade_off))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the top 20% of the archive (based on normalized objective sums) and applies a hybrid local search: first flipping high-marginal-gain items (prioritized by combined value-to-weight ratios) and then randomly flipping low-marginal-contribution items (with 30% probability), while ensuring feasibility through iterative removal of the lightest items if capacity is exceeded. The method balances exploitation (targeted flips) and exploration (random flips) while limiting iterations to 5-10 per solution.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    n_items = len(weight_lst)\n\n    # Targeted flipping of high-marginal-gain items\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    high_gain_indices = np.argsort(combined_gain)[::-1][:min(5, n_items)]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random flips of low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, n_items)]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 138,
        "algorithm": "The algorithm selects promising solutions from the archive based on normalized objective sums, then applies a hybrid local search: first flipping items with high diversity-aware marginal gains, followed by adaptive random perturbations based on proximity to the ideal point, and finally ensuring feasibility through iterative removal of least-contributing items. The selection prioritizes solutions with balanced trade-offs between objectives, while the local search dynamically adjusts exploration intensity based on solution quality.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Diversity-aware flip mechanism\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    trade_off = value2_lst / (value1_lst + 1e-10)\n    diversity_score = (1 + 0.5 * np.abs(trade_off - np.mean(trade_off))) * combined_gain\n    flip_indices = np.argsort(diversity_score)[::-1][:min(5, len(weight_lst))]\n\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive perturbation phase\n    ideal_point = np.max(np.array([obj for _, obj in archive]), axis=0)\n    distance_to_ideal = np.linalg.norm(ideal_point - archive[selected_idx][1])\n    n_random_flips = max(1, int(3 * (1 / (distance_to_ideal + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility and diversity\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with least contribution to either objective\n        contribution = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(contribution)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.7928087461463924,
            0.2787232995033264
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Diversity-aware flip mechanism\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    trade_off = value2_lst / (value1_lst + 1e-10)\n    diversity_score = (1 + 0.5 * np.abs(trade_off - np.mean(trade_off))) * combined_gain\n    flip_indices = np.argsort(diversity_score)[::-1][:min(5, len(weight_lst))]\n\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive perturbation phase\n    ideal_point = np.max(np.array([obj for _, obj in archive]), axis=0)\n    distance_to_ideal = np.linalg.norm(ideal_point - archive[selected_idx][1])\n    n_random_flips = max(1, int(3 * (1 / (distance_to_ideal + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility and diversity\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with least contribution to either objective\n        contribution = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(contribution)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the top 20% of the archive (based on normalized objective sums) and applies a hybrid local search: first flipping high-marginal-gain items (prioritized by combined value-to-weight ratios) and then randomly flipping low-marginal-contribution items (with 30% probability), while ensuring feasibility through iterative removal of the lightest items if capacity is exceeded. The method balances exploitation (targeted flips) and exploration (random flips) while limiting iterations to 5-10 per solution.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    n_items = len(weight_lst)\n\n    # Targeted flipping of high-marginal-gain items\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    high_gain_indices = np.argsort(combined_gain)[::-1][:min(5, n_items)]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random flips of low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, n_items)]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 139,
        "algorithm": "This algorithm selects a high-potential solution from the archive based on normalized objective sums, then applies a hybrid local search: first flipping items with highest marginal gains for both objectives, followed by probabilistic adjacent swaps, with feasibility maintained through iterative removal of least impactful items. The method prioritizes solutions with balanced objective contributions and explores neighborhoods through both deterministic and stochastic moves.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest normalized objective sum\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    n_items = len(weight_lst)\n\n    # Calculate marginal contributions\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Flip items with highest marginal gain\n    for idx in np.argsort(combined_gain)[::-1][:min(5, n_items)]:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Probabilistic adjacent item swapping\n    if np.random.rand() < 0.4:\n        for i in range(n_items - 1):\n            if np.random.rand() < 0.2:\n                if base_solution[i] != base_solution[i+1]:\n                    temp_weight = current_weight - weight_lst[i] * base_solution[i] - weight_lst[i+1] * base_solution[i+1]\n                    temp_weight += weight_lst[i] * (1 - base_solution[i]) + weight_lst[i+1] * base_solution[i]\n                    if temp_weight <= capacity:\n                        new_solution[i], new_solution[i+1] = new_solution[i+1], new_solution[i]\n                        current_weight = temp_weight\n\n    # Ensure feasibility by removing least impactful items\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        impact = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        remove_idx = removable_items[np.argmin(impact[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.5714835896868091,
            0.27655842900276184
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest normalized objective sum\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    n_items = len(weight_lst)\n\n    # Calculate marginal contributions\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Flip items with highest marginal gain\n    for idx in np.argsort(combined_gain)[::-1][:min(5, n_items)]:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Probabilistic adjacent item swapping\n    if np.random.rand() < 0.4:\n        for i in range(n_items - 1):\n            if np.random.rand() < 0.2:\n                if base_solution[i] != base_solution[i+1]:\n                    temp_weight = current_weight - weight_lst[i] * base_solution[i] - weight_lst[i+1] * base_solution[i+1]\n                    temp_weight += weight_lst[i] * (1 - base_solution[i]) + weight_lst[i+1] * base_solution[i]\n                    if temp_weight <= capacity:\n                        new_solution[i], new_solution[i+1] = new_solution[i+1], new_solution[i]\n                        current_weight = temp_weight\n\n    # Ensure feasibility by removing least impactful items\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        impact = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        remove_idx = removable_items[np.argmin(impact[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the top 20% of the archive (based on normalized objective sums) and applies a hybrid local search: first flipping high-marginal-gain items (prioritized by combined value-to-weight ratios) and then randomly flipping low-marginal-contribution items (with 30% probability), while ensuring feasibility through iterative removal of the lightest items if capacity is exceeded. The method balances exploitation (targeted flips) and exploration (random flips) while limiting iterations to 5-10 per solution.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    n_items = len(weight_lst)\n\n    # Targeted flipping of high-marginal-gain items\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    high_gain_indices = np.argsort(combined_gain)[::-1][:min(5, n_items)]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random flips of low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, n_items)]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 140,
        "algorithm": "The algorithm selects from the bottom 30% of solutions in the archive (by normalized objective sums) to prioritize less-optimal solutions for improvement. It then applies a hybrid local search by targeting low-marginal-gain items for flips (prioritizing combined value-to-weight ratios) and occasionally randomly flipping high-marginal-contribution items (40% probability). Excess weight is resolved by iteratively removing the heaviest items, ensuring feasibility while maintaining a balance between targeted and exploratory search.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select from bottom 30% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        bottom_indices = np.argsort(normalized_scores)[:max(1, len(archive) // 3)]\n        selected_idx = np.random.choice(bottom_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    n_items = len(weight_lst)\n\n    # Targeted flipping of low-marginal-gain items\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    low_gain_indices = np.argsort(combined_gain)[:min(5, n_items)]\n\n    for idx in low_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random flips of high-marginal-contribution items\n    if np.random.rand() < 0.4:\n        high_gain_indices = np.argsort(combined_gain)[::-1][:min(3, n_items)]\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmax(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.7315500229788169,
            0.20937886834144592
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select from bottom 30% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        bottom_indices = np.argsort(normalized_scores)[:max(1, len(archive) // 3)]\n        selected_idx = np.random.choice(bottom_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    n_items = len(weight_lst)\n\n    # Targeted flipping of low-marginal-gain items\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    low_gain_indices = np.argsort(combined_gain)[:min(5, n_items)]\n\n    for idx in low_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random flips of high-marginal-contribution items\n    if np.random.rand() < 0.4:\n        high_gain_indices = np.argsort(combined_gain)[::-1][:min(3, n_items)]\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmax(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 4 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the top 20% of the archive (based on normalized objective sums) and applies a hybrid local search: first flipping high-marginal-gain items (prioritized by combined value-to-weight ratios) and then randomly flipping low-marginal-contribution items (with 30% probability), while ensuring feasibility through iterative removal of the lightest items if capacity is exceeded. The method balances exploitation (targeted flips) and exploration (random flips) while limiting iterations to 5-10 per solution.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    n_items = len(weight_lst)\n\n    # Targeted flipping of high-marginal-gain items\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    high_gain_indices = np.argsort(combined_gain)[::-1][:min(5, n_items)]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random flips of low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, n_items)]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive (based on normalized objective sums) and generates neighbors by flipping items with high marginal gains for both objectives, followed by 1-2 random feasible flips, while ensuring feasibility through iterative refinement by removing the lightest items when needed. It prioritizes items with combined high marginal gains for both objectives while maintaining diversity through random flips.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain-based flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add 1-2 random feasible flips\n    for _ in range(np.random.randint(1, 3)):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 141,
        "algorithm": "The algorithm selects promising solutions from the archive (top 20% by normalized objective sums) and generates neighbors by strategically flipping high-marginal-gain items (prioritizing combined value-to-weight ratios) while occasionally perturbing low-contribution items (30% chance) and ensuring feasibility through iterative weight adjustment by removing least impactful items. It balances exploitation (targeted flips) and exploration (random perturbations) while maintaining solution quality through controlled iterations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    n_items = len(weight_lst)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Targeted flips of high-marginal-gain items (3-5)\n    high_gain_indices = np.argsort(combined_gain)[::-1][:np.random.randint(3, min(6, n_items))]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation (30% chance)\n    if np.random.rand() < 0.3:\n        # Calculate marginal contribution for both objectives\n        marginal_contribution = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        low_contrib_indices = np.argsort(marginal_contribution)[:min(3, n_items)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement to ensure feasibility\n    for _ in range(5):\n        total_weight = np.sum(new_solution * weight_lst)\n        if total_weight <= capacity:\n            break\n        excess = total_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove items with smallest ratio of weight to marginal contribution\n        weights = weight_lst[removable_items]\n        contributions = (value1_lst[removable_items] + value2_lst[removable_items]) / (weights + 1e-10)\n        remove_idx = removable_items[np.argmin(contributions / weights)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.7070677448627247,
            0.8903672099113464
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    n_items = len(weight_lst)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Targeted flips of high-marginal-gain items (3-5)\n    high_gain_indices = np.argsort(combined_gain)[::-1][:np.random.randint(3, min(6, n_items))]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation (30% chance)\n    if np.random.rand() < 0.3:\n        # Calculate marginal contribution for both objectives\n        marginal_contribution = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        low_contrib_indices = np.argsort(marginal_contribution)[:min(3, n_items)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement to ensure feasibility\n    for _ in range(5):\n        total_weight = np.sum(new_solution * weight_lst)\n        if total_weight <= capacity:\n            break\n        excess = total_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove items with smallest ratio of weight to marginal contribution\n        weights = weight_lst[removable_items]\n        contributions = (value1_lst[removable_items] + value2_lst[removable_items]) / (weights + 1e-10)\n        remove_idx = removable_items[np.argmin(contributions / weights)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 4 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects the solution with the highest hypervolume contribution from the archive, then applies a hybrid local search combining marginal-gain-based flips with an objective-balanced mechanism that prioritizes items with high combined marginal gains and balanced trade-offs between objectives. It dynamically scales the number of random flips based on the solution's distance to the ideal point and ensures feasibility through a trade-off-aware removal process that eliminates items with the poorest trade-offs between objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    selected_idx = np.argmax(hypervolume)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Objective-balanced flipping mechanism\n    trade_off = value2_lst / (value1_lst + 1e-10)\n    combined_score = (marginal_gain1 + marginal_gain2) * (1 + 0.5 * np.abs(trade_off - np.mean(trade_off)))\n    sorted_indices = np.argsort(combined_score)[::-1]\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (scaled by distance to ideal point)\n    distance_to_ideal = np.linalg.norm(ideal_point - objectives[selected_idx])\n    n_random_flips = max(1, int(5 * (1 / (distance_to_ideal + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Trade-off-aware feasibility restoration\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with poorest trade-off\n        item_trade_off = value2_lst[removable_items] / (value1_lst[removable_items] + 1e-10)\n        avg_trade_off = np.mean(item_trade_off)\n        remove_idx = removable_items[np.argmax(np.abs(item_trade_off - avg_trade_off))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: - **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 142,
        "algorithm": "The algorithm selects promising solutions from the archive (top 20% by normalized objective sum), then applies a hybrid local search: first targeting high-marginal-gain items, followed by random flips and iterative refinement to ensure feasibility. The method prioritizes items with high value-to-weight ratios while maintaining solution feasibility through careful weight checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted flips: high marginal gain in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Random flips: 1-2 items\n    n_random_flips = np.random.randint(1, 3)\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement: 5-10 iterations\n    for _ in range(np.random.randint(5, 11)):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.8299841474000184,
            0.22207090258598328
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted flips: high marginal gain in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Random flips: 1-2 items\n    n_random_flips = np.random.randint(1, 3)\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement: 5-10 iterations\n    for _ in range(np.random.randint(5, 11)):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects the solution with the highest hypervolume contribution from the archive, then applies a hybrid local search combining marginal-gain-based flips with an objective-balanced mechanism that prioritizes items with high combined marginal gains and balanced trade-offs between objectives. It dynamically scales the number of random flips based on the solution's distance to the ideal point and ensures feasibility through a trade-off-aware removal process that eliminates items with the poorest trade-offs between objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    selected_idx = np.argmax(hypervolume)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Objective-balanced flipping mechanism\n    trade_off = value2_lst / (value1_lst + 1e-10)\n    combined_score = (marginal_gain1 + marginal_gain2) * (1 + 0.5 * np.abs(trade_off - np.mean(trade_off)))\n    sorted_indices = np.argsort(combined_score)[::-1]\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (scaled by distance to ideal point)\n    distance_to_ideal = np.linalg.norm(ideal_point - objectives[selected_idx])\n    n_random_flips = max(1, int(5 * (1 / (distance_to_ideal + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Trade-off-aware feasibility restoration\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with poorest trade-off\n        item_trade_off = value2_lst[removable_items] / (value1_lst[removable_items] + 1e-10)\n        avg_trade_off = np.mean(item_trade_off)\n        remove_idx = removable_items[np.argmax(np.abs(item_trade_off - avg_trade_off))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 143,
        "algorithm": "The algorithm selects a promising solution from the archive using a hybrid quality-diversity criterion, then applies a novel \"objective-balanced cluster flipping\" strategy that groups items by marginal gains and trade-offs, flipping entire clusters while maintaining feasibility through dynamic capacity adjustments and controlled random swaps between clusters. The selection prioritizes high-quality solutions while balancing exploration, and the local search emphasizes cluster-based operations with trade-off-aware adjustments to improve both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine quality and diversity\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = np.max(objectives, axis=0)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0]/max_obj1 + objectives[:, 1]/max_obj2)\n        diversity_scores = np.linalg.norm(objectives - np.mean(objectives, axis=0), axis=1)\n        combined_scores = 0.7 * normalized_scores + 0.3 * diversity_scores\n        selected_idx = np.argmax(combined_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains and trade-offs\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    trade_off = value2_lst / (value1_lst + 1e-10)\n\n    # Cluster items by marginal gains and trade-offs\n    cluster1 = np.where((marginal_gain1 > np.median(marginal_gain1)) & (trade_off < np.median(trade_off)))[0]\n    cluster2 = np.where((marginal_gain2 > np.median(marginal_gain2)) & (trade_off > np.median(trade_off)))[0]\n    cluster3 = np.where((marginal_gain1 <= np.median(marginal_gain1)) & (marginal_gain2 <= np.median(marginal_gain2)))[0]\n\n    # Objective-balanced cluster flipping\n    clusters = [cluster1, cluster2, cluster3]\n    for cluster in clusters:\n        if len(cluster) == 0:\n            continue\n        cluster_weight = np.sum(weight_lst[cluster])\n        cluster_value1 = np.sum(value1_lst[cluster])\n        cluster_value2 = np.sum(value2_lst[cluster])\n\n        # Flip entire cluster if beneficial\n        if np.all(base_solution[cluster] == 1):\n            if current_weight - cluster_weight <= capacity:\n                new_solution[cluster] = 0\n                current_weight -= cluster_weight\n        else:\n            if current_weight + cluster_weight <= capacity:\n                new_solution[cluster] = 1\n                current_weight += cluster_weight\n\n    # Controlled random swaps between clusters\n    n_swaps = min(3, len(cluster1), len(cluster2))\n    for _ in range(n_swaps):\n        if np.random.rand() < 0.5 and len(cluster1) > 0 and len(cluster2) > 0:\n            # Swap items between cluster1 and cluster2\n            idx1 = np.random.choice(cluster1)\n            idx2 = np.random.choice(cluster2)\n\n            if base_solution[idx1] == 1 and base_solution[idx2] == 0:\n                if current_weight - weight_lst[idx1] + weight_lst[idx2] <= capacity:\n                    new_solution[idx1], new_solution[idx2] = 0, 1\n                    current_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n\n    # Dynamic capacity adjustment for feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove items with poorest trade-offs\n        item_trade_off = trade_off[removable_items]\n        avg_trade_off = np.mean(item_trade_off)\n        remove_idx = removable_items[np.argmax(np.abs(item_trade_off - avg_trade_off))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.5554730505690734,
            4.493586927652359
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine quality and diversity\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = np.max(objectives, axis=0)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0]/max_obj1 + objectives[:, 1]/max_obj2)\n        diversity_scores = np.linalg.norm(objectives - np.mean(objectives, axis=0), axis=1)\n        combined_scores = 0.7 * normalized_scores + 0.3 * diversity_scores\n        selected_idx = np.argmax(combined_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains and trade-offs\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    trade_off = value2_lst / (value1_lst + 1e-10)\n\n    # Cluster items by marginal gains and trade-offs\n    cluster1 = np.where((marginal_gain1 > np.median(marginal_gain1)) & (trade_off < np.median(trade_off)))[0]\n    cluster2 = np.where((marginal_gain2 > np.median(marginal_gain2)) & (trade_off > np.median(trade_off)))[0]\n    cluster3 = np.where((marginal_gain1 <= np.median(marginal_gain1)) & (marginal_gain2 <= np.median(marginal_gain2)))[0]\n\n    # Objective-balanced cluster flipping\n    clusters = [cluster1, cluster2, cluster3]\n    for cluster in clusters:\n        if len(cluster) == 0:\n            continue\n        cluster_weight = np.sum(weight_lst[cluster])\n        cluster_value1 = np.sum(value1_lst[cluster])\n        cluster_value2 = np.sum(value2_lst[cluster])\n\n        # Flip entire cluster if beneficial\n        if np.all(base_solution[cluster] == 1):\n            if current_weight - cluster_weight <= capacity:\n                new_solution[cluster] = 0\n                current_weight -= cluster_weight\n        else:\n            if current_weight + cluster_weight <= capacity:\n                new_solution[cluster] = 1\n                current_weight += cluster_weight\n\n    # Controlled random swaps between clusters\n    n_swaps = min(3, len(cluster1), len(cluster2))\n    for _ in range(n_swaps):\n        if np.random.rand() < 0.5 and len(cluster1) > 0 and len(cluster2) > 0:\n            # Swap items between cluster1 and cluster2\n            idx1 = np.random.choice(cluster1)\n            idx2 = np.random.choice(cluster2)\n\n            if base_solution[idx1] == 1 and base_solution[idx2] == 0:\n                if current_weight - weight_lst[idx1] + weight_lst[idx2] <= capacity:\n                    new_solution[idx1], new_solution[idx2] = 0, 1\n                    current_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n\n    # Dynamic capacity adjustment for feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove items with poorest trade-offs\n        item_trade_off = trade_off[removable_items]\n        avg_trade_off = np.mean(item_trade_off)\n        remove_idx = removable_items[np.argmax(np.abs(item_trade_off - avg_trade_off))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive based on combined objective scores, then performs a targeted local search by flipping high-marginal-gain items prioritizing the least dominated objective, followed by controlled random perturbations and adaptive feasibility repairs to ensure capacity constraints are met while maintaining solution diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by combined objective score\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        combined_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(combined_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains and dominance information\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Identify items that improve the least dominated objective\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    # Targeted flipping of high-marginal-gain items prioritizing least dominated objective\n    if least_dominated == 1:\n        target_gain = marginal_gain1\n    else:\n        target_gain = marginal_gain2\n\n    high_gain_indices = np.argsort(target_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation of low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined marginal gain\n        removal_candidates = included_items[np.argsort(combined_gain[included_items])]\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects the solution with the highest hypervolume contribution from the archive, then applies a hybrid local search combining marginal-gain-based flips with an objective-balanced mechanism that prioritizes items with high combined marginal gains and balanced trade-offs between objectives. It dynamically scales the number of random flips based on the solution's distance to the ideal point and ensures feasibility through a trade-off-aware removal process that eliminates items with the poorest trade-offs between objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    selected_idx = np.argmax(hypervolume)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Objective-balanced flipping mechanism\n    trade_off = value2_lst / (value1_lst + 1e-10)\n    combined_score = (marginal_gain1 + marginal_gain2) * (1 + 0.5 * np.abs(trade_off - np.mean(trade_off)))\n    sorted_indices = np.argsort(combined_score)[::-1]\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (scaled by distance to ideal point)\n    distance_to_ideal = np.linalg.norm(ideal_point - objectives[selected_idx])\n    n_random_flips = max(1, int(5 * (1 / (distance_to_ideal + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Trade-off-aware feasibility restoration\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with poorest trade-off\n        item_trade_off = value2_lst[removable_items] / (value1_lst[removable_items] + 1e-10)\n        avg_trade_off = np.mean(item_trade_off)\n        remove_idx = removable_items[np.argmax(np.abs(item_trade_off - avg_trade_off))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 144,
        "algorithm": "The algorithm selects the non-dominated solution closest to the ideal point, then applies a hybrid local search that prioritizes adding high-marginal-gain items in either objective while balancing exploration through dynamic random flips, and ensures feasibility by removing low-marginal-gain items when capacity is exceeded. The number of random flips scales with the solution's distance to the ideal point, and marginal gains are computed as value-to-weight ratios for both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution closest to ideal point\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    distances = np.linalg.norm(objectives - ideal_point, axis=1)\n    selected_idx = np.argmin(distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Targeted flipping of high-marginal-gain items in either objective\n    sorted_indices1 = np.argsort(marginal_gain1)[::-1]\n    sorted_indices2 = np.argsort(marginal_gain2)[::-1]\n    for idx in sorted_indices1[:min(3, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n    for idx in sorted_indices2[:min(3, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic number of random flips (scaled by distance to ideal point)\n    distance_to_ideal = distances[selected_idx]\n    n_random_flips = max(1, int(3 * (1 / (distance_to_ideal + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Marginal-gain-aware feasibility restoration\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with lowest combined marginal gain\n        remove_idx = removable_items[np.argmin(combined_gain[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.5784107231629296,
            6.299902051687241
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution closest to ideal point\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    distances = np.linalg.norm(objectives - ideal_point, axis=1)\n    selected_idx = np.argmin(distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Targeted flipping of high-marginal-gain items in either objective\n    sorted_indices1 = np.argsort(marginal_gain1)[::-1]\n    sorted_indices2 = np.argsort(marginal_gain2)[::-1]\n    for idx in sorted_indices1[:min(3, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n    for idx in sorted_indices2[:min(3, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic number of random flips (scaled by distance to ideal point)\n    distance_to_ideal = distances[selected_idx]\n    n_random_flips = max(1, int(3 * (1 / (distance_to_ideal + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Marginal-gain-aware feasibility restoration\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with lowest combined marginal gain\n        remove_idx = removable_items[np.argmin(combined_gain[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects the solution with the highest hypervolume contribution from the archive, then applies a hybrid local search combining marginal-gain-based flips with an objective-balanced mechanism that prioritizes items with high combined marginal gains and balanced trade-offs between objectives. It dynamically scales the number of random flips based on the solution's distance to the ideal point and ensures feasibility through a trade-off-aware removal process that eliminates items with the poorest trade-offs between objectives.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    selected_idx = np.argmax(hypervolume)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Objective-balanced flipping mechanism\n    trade_off = value2_lst / (value1_lst + 1e-10)\n    combined_score = (marginal_gain1 + marginal_gain2) * (1 + 0.5 * np.abs(trade_off - np.mean(trade_off)))\n    sorted_indices = np.argsort(combined_score)[::-1]\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (scaled by distance to ideal point)\n    distance_to_ideal = np.linalg.norm(ideal_point - objectives[selected_idx])\n    n_random_flips = max(1, int(5 * (1 / (distance_to_ideal + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Trade-off-aware feasibility restoration\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with poorest trade-off\n        item_trade_off = value2_lst[removable_items] / (value1_lst[removable_items] + 1e-10)\n        avg_trade_off = np.mean(item_trade_off)\n        remove_idx = removable_items[np.argmax(np.abs(item_trade_off - avg_trade_off))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 145,
        "algorithm": "The algorithm selects the solution with the highest hypervolume contribution from the archive and generates a neighbor by first applying a targeted flip mechanism prioritizing items with high combined marginal gains and balanced trade-offs, then performing adaptive random flips scaled by the solution's quality and distance to the ideal point, and finally ensuring feasibility through a trade-off-aware removal process that eliminates items with the poorest trade-offs. The combined score (70% marginal gains, 30% trade-offs) guides flips, while random flips are dynamically adjusted based on solution quality and ideal distance.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    selected_idx = np.argmax(hypervolume)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate normalized marginal gains and trade-offs\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    trade_off = value2_lst / (value1_lst + 1e-10)\n\n    # Objective-balanced flipping mechanism with adaptive weighting\n    alpha = 0.7  # Weight for marginal gains\n    beta = 0.3   # Weight for trade-off balance\n    combined_score = alpha * (marginal_gain1 + marginal_gain2) + beta * (1 / (trade_off + 1e-10))\n    sorted_indices = np.argsort(combined_score)[::-1]\n\n    # Perform targeted flips based on combined score\n    for idx in sorted_indices[:min(7, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (scaled by distance to ideal point and current solution quality)\n    distance_to_ideal = np.linalg.norm(ideal_point - objectives[selected_idx])\n    current_quality = np.sum(objectives[selected_idx]) / np.sum(ideal_point)\n    n_random_flips = max(1, int(7 * (1 - current_quality) * (1 / (distance_to_ideal + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Trade-off-aware feasibility restoration with adaptive removal\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n\n        # Calculate removal impact score (trade-off deviation + weight contribution)\n        item_trade_off = value2_lst[removable_items] / (value1_lst[removable_items] + 1e-10)\n        avg_trade_off = np.mean(item_trade_off)\n        trade_off_dev = np.abs(item_trade_off - avg_trade_off)\n        weight_contrib = weight_lst[removable_items] / excess\n        removal_score = trade_off_dev + 0.5 * weight_contrib\n\n        remove_idx = removable_items[np.argmax(removal_score)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8880044358873276,
            0.23827174305915833
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    selected_idx = np.argmax(hypervolume)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate normalized marginal gains and trade-offs\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    trade_off = value2_lst / (value1_lst + 1e-10)\n\n    # Objective-balanced flipping mechanism with adaptive weighting\n    alpha = 0.7  # Weight for marginal gains\n    beta = 0.3   # Weight for trade-off balance\n    combined_score = alpha * (marginal_gain1 + marginal_gain2) + beta * (1 / (trade_off + 1e-10))\n    sorted_indices = np.argsort(combined_score)[::-1]\n\n    # Perform targeted flips based on combined score\n    for idx in sorted_indices[:min(7, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (scaled by distance to ideal point and current solution quality)\n    distance_to_ideal = np.linalg.norm(ideal_point - objectives[selected_idx])\n    current_quality = np.sum(objectives[selected_idx]) / np.sum(ideal_point)\n    n_random_flips = max(1, int(7 * (1 - current_quality) * (1 / (distance_to_ideal + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Trade-off-aware feasibility restoration with adaptive removal\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n\n        # Calculate removal impact score (trade-off deviation + weight contribution)\n        item_trade_off = value2_lst[removable_items] / (value1_lst[removable_items] + 1e-10)\n        avg_trade_off = np.mean(item_trade_off)\n        trade_off_dev = np.abs(item_trade_off - avg_trade_off)\n        weight_contrib = weight_lst[removable_items] / excess\n        removal_score = trade_off_dev + 0.5 * weight_contrib\n\n        remove_idx = removable_items[np.argmax(removal_score)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects the solution with the highest hypervolume contribution from the archive, then applies a hybrid local search combining marginal-gain-based flips with an objective-balanced mechanism that prioritizes items with high combined marginal gains and balanced trade-offs between objectives. It dynamically scales the number of random flips based on the solution's distance to the ideal point and ensures feasibility through a trade-off-aware removal process that eliminates items with the poorest trade-offs between objectives.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    selected_idx = np.argmax(hypervolume)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Objective-balanced flipping mechanism\n    trade_off = value2_lst / (value1_lst + 1e-10)\n    combined_score = (marginal_gain1 + marginal_gain2) * (1 + 0.5 * np.abs(trade_off - np.mean(trade_off)))\n    sorted_indices = np.argsort(combined_score)[::-1]\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (scaled by distance to ideal point)\n    distance_to_ideal = np.linalg.norm(ideal_point - objectives[selected_idx])\n    n_random_flips = max(1, int(5 * (1 / (distance_to_ideal + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Trade-off-aware feasibility restoration\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with poorest trade-off\n        item_trade_off = value2_lst[removable_items] / (value1_lst[removable_items] + 1e-10)\n        avg_trade_off = np.mean(item_trade_off)\n        remove_idx = removable_items[np.argmax(np.abs(item_trade_off - avg_trade_off))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 146,
        "algorithm": "The algorithm selects the most promising solution from the archive (based on normalized objective sums) and applies a two-phase local search: first flipping high-gain items deterministically, then performing dynamic random flips weighted by marginal gains, while ensuring feasibility through a weight-balanced removal process that prioritizes low-contribution items. The method balances exploration (random flips) and exploitation (high-gain flips) while dynamically adjusting flip intensity based on solution density.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest sum of normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = objectives / (np.max(objectives, axis=0) + 1e-10)\n    selected_idx = np.argmax(np.sum(normalized_objectives, axis=1))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate weighted marginal gains\n    weight_factor = 1 / (weight_lst + 1e-10)\n    marginal_gain1 = value1_lst * weight_factor\n    marginal_gain2 = value2_lst * weight_factor\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Phase 1: Deterministic flips of top 10% high-gain items\n    top_percent = max(1, int(0.1 * len(weight_lst)))\n    sorted_indices = np.argsort(combined_gain)[::-1]\n    for idx in sorted_indices[:top_percent]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Phase 2: Dynamic random flips weighted by marginal gains\n    gain_weights = combined_gain / (np.sum(combined_gain) + 1e-10)\n    n_random_flips = max(1, int(10 * np.exp(-np.sum(base_solution) / len(weight_lst))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.choice(len(weight_lst), p=gain_weights)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Weight-balanced feasibility restoration\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with least contribution to both objectives\n        total_contribution = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(total_contribution)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.6592794608609801,
            0.49498632550239563
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest sum of normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = objectives / (np.max(objectives, axis=0) + 1e-10)\n    selected_idx = np.argmax(np.sum(normalized_objectives, axis=1))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate weighted marginal gains\n    weight_factor = 1 / (weight_lst + 1e-10)\n    marginal_gain1 = value1_lst * weight_factor\n    marginal_gain2 = value2_lst * weight_factor\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Phase 1: Deterministic flips of top 10% high-gain items\n    top_percent = max(1, int(0.1 * len(weight_lst)))\n    sorted_indices = np.argsort(combined_gain)[::-1]\n    for idx in sorted_indices[:top_percent]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Phase 2: Dynamic random flips weighted by marginal gains\n    gain_weights = combined_gain / (np.sum(combined_gain) + 1e-10)\n    n_random_flips = max(1, int(10 * np.exp(-np.sum(base_solution) / len(weight_lst))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.choice(len(weight_lst), p=gain_weights)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Weight-balanced feasibility restoration\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with least contribution to both objectives\n        total_contribution = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(total_contribution)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 5 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects the solution with the highest hypervolume contribution from the archive, then applies a hybrid local search combining marginal-gain-based flips with an objective-balanced mechanism that prioritizes items with high combined marginal gains and balanced trade-offs between objectives. It dynamically scales the number of random flips based on the solution's distance to the ideal point and ensures feasibility through a trade-off-aware removal process that eliminates items with the poorest trade-offs between objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    selected_idx = np.argmax(hypervolume)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Objective-balanced flipping mechanism\n    trade_off = value2_lst / (value1_lst + 1e-10)\n    combined_score = (marginal_gain1 + marginal_gain2) * (1 + 0.5 * np.abs(trade_off - np.mean(trade_off)))\n    sorted_indices = np.argsort(combined_score)[::-1]\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (scaled by distance to ideal point)\n    distance_to_ideal = np.linalg.norm(ideal_point - objectives[selected_idx])\n    n_random_flips = max(1, int(5 * (1 / (distance_to_ideal + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Trade-off-aware feasibility restoration\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with poorest trade-off\n        item_trade_off = value2_lst[removable_items] / (value1_lst[removable_items] + 1e-10)\n        avg_trade_off = np.mean(item_trade_off)\n        remove_idx = removable_items[np.argmax(np.abs(item_trade_off - avg_trade_off))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm first selects promising solutions from the top 30% of the archive based on normalized trade-offs, then prioritizes those with high crowding distances for further improvement. It generates neighbors by flipping items with the highest combined marginal gains for both objectives, followed by a dynamic number of random flips (scaled inversely to crowding distance), and finally ensures feasibility through iterative removal of the least valuable items when capacity is exceeded. The solution prioritizes exploration in crowded regions while maintaining high-quality improvements through marginal gain-based flips.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by normalized trade-offs\n    objectives = np.array([obj for _, obj in archive])\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    top_indices = np.argsort(trade_off)[-max(1, len(archive) // 3):]\n\n    # Calculate crowding distances for selected solutions\n    selected_objectives = objectives[top_indices]\n    normalized_objectives = (selected_objectives - np.min(selected_objectives, axis=0)) / (np.max(selected_objectives, axis=0) - np.min(selected_objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(top_indices))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(top_indices)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = top_indices[np.argmax(crowding)]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain-based flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (inverse to crowding distance)\n    n_random_flips = max(1, int(10 * (1 / (crowding[np.argmax(crowding)] + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove least valuable item (min of value1 and value2)\n        remove_idx = removable_items[np.argmin(np.minimum(value1_lst[removable_items], value2_lst[removable_items]))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive (based on normalized objective sums) and generates neighbors by flipping items with high marginal gains for both objectives, followed by 1-2 random feasible flips, while ensuring feasibility through iterative refinement by removing the lightest items when needed. It prioritizes items with combined high marginal gains for both objectives while maintaining diversity through random flips.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain-based flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add 1-2 random feasible flips\n    for _ in range(np.random.randint(1, 3)):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection.\n- **Advice**: Select top 20% solutions by normalized objective sums, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.\n- **Explanation**: Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 147,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Targeted flips: prioritize items with highest combined marginal gains\n    sorted_indices = np.argsort(combined_gain)[::-1]\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Controlled random flips: 1-2 random feasible flips\n    for _ in range(np.random.randint(1, 3)):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with poorest trade-off between objectives\n        item_trade_off = value2_lst[removable_items] / (value1_lst[removable_items] + 1e-10)\n        avg_trade_off = np.mean(item_trade_off)\n        remove_idx = removable_items[np.argmax(np.abs(item_trade_off - avg_trade_off))]\n        new_solution[remove_idx] = 0\n\n    # Additional adaptive perturbation: occasionally flip low-marginal-contribution items\n    if np.random.rand() < 0.2:\n        low_contrib_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.6496648747818348,
            0.23382166028022766
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Targeted flips: prioritize items with highest combined marginal gains\n    sorted_indices = np.argsort(combined_gain)[::-1]\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Controlled random flips: 1-2 random feasible flips\n    for _ in range(np.random.randint(1, 3)):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with poorest trade-off between objectives\n        item_trade_off = value2_lst[removable_items] / (value1_lst[removable_items] + 1e-10)\n        avg_trade_off = np.mean(item_trade_off)\n        remove_idx = removable_items[np.argmax(np.abs(item_trade_off - avg_trade_off))]\n        new_solution[remove_idx] = 0\n\n    # Additional adaptive perturbation: occasionally flip low-marginal-contribution items\n    if np.random.rand() < 0.2:\n        low_contrib_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 5 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects the solution with the highest hypervolume contribution from the archive, then applies a hybrid local search combining marginal-gain-based flips with an objective-balanced mechanism that prioritizes items with high combined marginal gains and balanced trade-offs between objectives. It dynamically scales the number of random flips based on the solution's distance to the ideal point and ensures feasibility through a trade-off-aware removal process that eliminates items with the poorest trade-offs between objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    selected_idx = np.argmax(hypervolume)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Objective-balanced flipping mechanism\n    trade_off = value2_lst / (value1_lst + 1e-10)\n    combined_score = (marginal_gain1 + marginal_gain2) * (1 + 0.5 * np.abs(trade_off - np.mean(trade_off)))\n    sorted_indices = np.argsort(combined_score)[::-1]\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (scaled by distance to ideal point)\n    distance_to_ideal = np.linalg.norm(ideal_point - objectives[selected_idx])\n    n_random_flips = max(1, int(5 * (1 / (distance_to_ideal + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Trade-off-aware feasibility restoration\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with poorest trade-off\n        item_trade_off = value2_lst[removable_items] / (value1_lst[removable_items] + 1e-10)\n        avg_trade_off = np.mean(item_trade_off)\n        remove_idx = removable_items[np.argmax(np.abs(item_trade_off - avg_trade_off))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive based on combined objective scores, then performs a targeted local search by flipping high-marginal-gain items prioritizing the least dominated objective, followed by controlled random perturbations and adaptive feasibility repairs to ensure capacity constraints are met while maintaining solution diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by combined objective score\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        combined_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(combined_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains and dominance information\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Identify items that improve the least dominated objective\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    # Targeted flipping of high-marginal-gain items prioritizing least dominated objective\n    if least_dominated == 1:\n        target_gain = marginal_gain1\n    else:\n        target_gain = marginal_gain2\n\n    high_gain_indices = np.argsort(target_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation of low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined marginal gain\n        removal_candidates = included_items[np.argsort(combined_gain[included_items])]\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: ### **Refined Heuristic Design for BI-KP**\n- **Keywords**: **Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection, hypervolume contribution.**\n- **Advice**: **Select top 20% solutions by hypervolume contribution, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.**\n- **Avoid**: **Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.**\n- **Explanation**: **Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.**\n\n*(Word count: ~50)*\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 148,
        "algorithm": "The algorithm selects top 20% solutions by hypervolume contribution, prioritizes flipping items with highest marginal gains in either objective, and adds 1-2 random flips (ensuring feasibility) in 5-10 iterations per solution to balance exploration and exploitation while maintaining feasibility. It focuses on solutions with high hypervolume contribution and uses a combination of targeted and random moves to generate neighbors, always ensuring weight constraints are satisfied.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    top_indices = np.argsort(hypervolume)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Iterative refinement (5-10 times)\n    for _ in range(np.random.randint(5, 11)):\n        # Targeted flipping: highest marginal gains in either objective\n        combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n        sorted_indices = np.argsort(combined_gain)[::-1]\n\n        for idx in sorted_indices[:min(3, len(weight_lst))]:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n        # Random flipping (1-2 items)\n        n_random_flips = np.random.randint(1, 3)\n        for _ in range(n_random_flips):\n            candidate_idx = np.random.randint(len(weight_lst))\n            if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n            elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n        # Feasibility check\n        if np.sum(new_solution * weight_lst) > capacity:\n            excess = np.sum(new_solution * weight_lst) - capacity\n            removable_items = np.where(new_solution == 1)[0]\n            if len(removable_items) > 0:\n                remove_idx = removable_items[np.argmin(combined_gain[removable_items])]\n                new_solution[remove_idx] = 0\n                current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8055569030998189,
            0.505950540304184
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    top_indices = np.argsort(hypervolume)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Iterative refinement (5-10 times)\n    for _ in range(np.random.randint(5, 11)):\n        # Targeted flipping: highest marginal gains in either objective\n        combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n        sorted_indices = np.argsort(combined_gain)[::-1]\n\n        for idx in sorted_indices[:min(3, len(weight_lst))]:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n        # Random flipping (1-2 items)\n        n_random_flips = np.random.randint(1, 3)\n        for _ in range(n_random_flips):\n            candidate_idx = np.random.randint(len(weight_lst))\n            if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n            elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n        # Feasibility check\n        if np.sum(new_solution * weight_lst) > capacity:\n            excess = np.sum(new_solution * weight_lst) - capacity\n            removable_items = np.where(new_solution == 1)[0]\n            if len(removable_items) > 0:\n                remove_idx = removable_items[np.argmin(combined_gain[removable_items])]\n                new_solution[remove_idx] = 0\n                current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThis algorithm prioritizes high-performance solutions (top 20% by normalized objective sums) and enhances them through a diversity-aware local search that strategically flips items based on combined marginal gains and crowding distance, while maintaining feasibility through capacity checks. It further diversifies by replacing low-contribution items with high-potential alternatives, balancing exploration and exploitation to improve multi-objective trade-offs.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate crowding distance for diversity-aware selection\n    objectives = np.array([obj for _, obj in archive])\n    n_solutions = len(objectives)\n    crowding_dist = np.zeros(n_solutions)\n\n    for m in range(2):  # For each objective\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding_dist[sorted_idx[0]] = crowding_dist[sorted_idx[-1]] = np.inf  # Boundary solutions\n        for i in range(1, n_solutions - 1):\n            crowding_dist[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (max_obj1 if m == 0 else max_obj2)\n\n    # Prioritize flipping items based on multi-objective marginal gains and crowding distance\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = (marginal_gain1 + marginal_gain2) * (1 + crowding_dist[selected_idx] / (np.max(crowding_dist) + 1e-6))\n\n    # Flip top 3 high-gain items\n    high_gain_indices = np.argsort(-combined_gain)[:min(3, len(weight_lst))]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled diversification: replace low-contribution items with high-potential alternatives\n    if np.random.rand() < 0.4:\n        low_contrib_indices = np.argsort(combined_gain)[:min(2, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            # Try adding a high-potential item\n            candidate_idx = np.random.choice(np.where(base_solution == 0)[0])\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Refined Heuristic Design for BI-KP**\n- **Keywords**: **Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection, hypervolume contribution.**\n- **Advice**: **Select top 20% solutions by hypervolume contribution, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.**\n- **Avoid**: **Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.**\n- **Explanation**: **Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.**\n\n*(Word count: ~50)*\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 149,
        "algorithm": "The algorithm selects high-potential solutions from the archive based on hypervolume contribution, then iteratively flips items with highest marginal gains in either objective (alternating between objectives) while occasionally introducing random flips to escape local optima, all while ensuring feasibility through capacity checks. The process repeats 5-10 times per solution to balance exploitation of marginal gains and exploration of random flips.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate hypervolume contribution for each solution\n    objectives = np.array([obj for _, obj in archive])\n    ref_point = np.max(objectives, axis=0) * 1.1  # Slightly larger reference point\n    hypervolume = np.zeros(len(archive))\n\n    for i in range(len(archive)):\n        dominated = np.all((objectives >= objectives[i]) & (objectives != objectives[i]), axis=1)\n        if not np.any(dominated):\n            hypervolume[i] = np.prod(ref_point - objectives[i])\n        else:\n            dominated_points = objectives[dominated]\n            for j in range(len(dominated_points)):\n                hypervolume[i] += np.prod(np.maximum(ref_point - dominated_points[j], 0))\n\n    # Select top 20% solutions by hypervolume contribution\n    top_indices = np.argsort(hypervolume)[-max(1, len(archive)//5):]\n    selected_idx = np.random.choice(top_indices)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Perform 5-10 iterations of targeted flips\n    for _ in range(np.random.randint(5, 11)):\n        # Calculate marginal gains for both objectives\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n\n        # Flip items with highest marginal gains (alternating objectives)\n        if np.random.rand() < 0.5:\n            sorted_indices = np.argsort(-marginal_gain1)\n        else:\n            sorted_indices = np.argsort(-marginal_gain2)\n\n        # Try to flip top 2 items\n        for idx in sorted_indices[:2]:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Add 1-2 random flips to escape local optima\n        for _ in range(np.random.randint(1, 3)):\n            random_idx = np.random.randint(len(weight_lst))\n            if base_solution[random_idx] == 1:\n                if current_weight - weight_lst[random_idx] <= capacity:\n                    new_solution[random_idx] = 0\n                    current_weight -= weight_lst[random_idx]\n            else:\n                if current_weight + weight_lst[random_idx] <= capacity:\n                    new_solution[random_idx] = 1\n                    current_weight += weight_lst[random_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8015217290635367,
            2.211745798587799
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate hypervolume contribution for each solution\n    objectives = np.array([obj for _, obj in archive])\n    ref_point = np.max(objectives, axis=0) * 1.1  # Slightly larger reference point\n    hypervolume = np.zeros(len(archive))\n\n    for i in range(len(archive)):\n        dominated = np.all((objectives >= objectives[i]) & (objectives != objectives[i]), axis=1)\n        if not np.any(dominated):\n            hypervolume[i] = np.prod(ref_point - objectives[i])\n        else:\n            dominated_points = objectives[dominated]\n            for j in range(len(dominated_points)):\n                hypervolume[i] += np.prod(np.maximum(ref_point - dominated_points[j], 0))\n\n    # Select top 20% solutions by hypervolume contribution\n    top_indices = np.argsort(hypervolume)[-max(1, len(archive)//5):]\n    selected_idx = np.random.choice(top_indices)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Perform 5-10 iterations of targeted flips\n    for _ in range(np.random.randint(5, 11)):\n        # Calculate marginal gains for both objectives\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n\n        # Flip items with highest marginal gains (alternating objectives)\n        if np.random.rand() < 0.5:\n            sorted_indices = np.argsort(-marginal_gain1)\n        else:\n            sorted_indices = np.argsort(-marginal_gain2)\n\n        # Try to flip top 2 items\n        for idx in sorted_indices[:2]:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Add 1-2 random flips to escape local optima\n        for _ in range(np.random.randint(1, 3)):\n            random_idx = np.random.randint(len(weight_lst))\n            if base_solution[random_idx] == 1:\n                if current_weight - weight_lst[random_idx] <= capacity:\n                    new_solution[random_idx] = 0\n                    current_weight -= weight_lst[random_idx]\n            else:\n                if current_weight + weight_lst[random_idx] <= capacity:\n                    new_solution[random_idx] = 1\n                    current_weight += weight_lst[random_idx]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive based on combined objective scores, then performs a targeted local search by flipping high-marginal-gain items prioritizing the least dominated objective, followed by controlled random perturbations and adaptive feasibility repairs to ensure capacity constraints are met while maintaining solution diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by combined objective score\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        combined_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(combined_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains and dominance information\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Identify items that improve the least dominated objective\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    # Targeted flipping of high-marginal-gain items prioritizing least dominated objective\n    if least_dominated == 1:\n        target_gain = marginal_gain1\n    else:\n        target_gain = marginal_gain2\n\n    high_gain_indices = np.argsort(target_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation of low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined marginal gain\n        removal_candidates = included_items[np.argsort(combined_gain[included_items])]\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThis algorithm prioritizes high-performance solutions (top 20% by normalized objective sums) and enhances them through a diversity-aware local search that strategically flips items based on combined marginal gains and crowding distance, while maintaining feasibility through capacity checks. It further diversifies by replacing low-contribution items with high-potential alternatives, balancing exploration and exploitation to improve multi-objective trade-offs.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate crowding distance for diversity-aware selection\n    objectives = np.array([obj for _, obj in archive])\n    n_solutions = len(objectives)\n    crowding_dist = np.zeros(n_solutions)\n\n    for m in range(2):  # For each objective\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding_dist[sorted_idx[0]] = crowding_dist[sorted_idx[-1]] = np.inf  # Boundary solutions\n        for i in range(1, n_solutions - 1):\n            crowding_dist[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (max_obj1 if m == 0 else max_obj2)\n\n    # Prioritize flipping items based on multi-objective marginal gains and crowding distance\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = (marginal_gain1 + marginal_gain2) * (1 + crowding_dist[selected_idx] / (np.max(crowding_dist) + 1e-6))\n\n    # Flip top 3 high-gain items\n    high_gain_indices = np.argsort(-combined_gain)[:min(3, len(weight_lst))]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled diversification: replace low-contribution items with high-potential alternatives\n    if np.random.rand() < 0.4:\n        low_contrib_indices = np.argsort(combined_gain)[:min(2, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            # Try adding a high-potential item\n            candidate_idx = np.random.choice(np.where(base_solution == 0)[0])\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Refined Heuristic Design for BI-KP**\n- **Keywords**: **Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection, hypervolume contribution.**\n- **Advice**: **Select top 20% solutions by hypervolume contribution, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.**\n- **Avoid**: **Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.**\n- **Explanation**: **Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.**\n\n*(Word count: ~50)*\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 150,
        "algorithm": "The algorithm selects promising solutions from the archive based on hypervolume contribution, then performs a hybrid local search that prioritizes flipping items with high marginal gains in either objective (alternating between value1 and value2) while occasionally introducing random flips (1-2) to maintain diversity. It ensures feasibility by checking capacity constraints and iteratively refines the solution (5-10 iterations) to balance exploitation and exploration for high-quality neighbor generation. The selection is biased toward solutions with higher hypervolume contributions, and the local search alternates between objective-specific improvements and random perturbations to avoid local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate hypervolume contribution for each solution\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = np.max(objectives[:, 0]), np.max(objectives[:, 1])\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Normalize objectives\n        norm_obj1 = objectives[:, 0] / max_obj1\n        norm_obj2 = objectives[:, 1] / max_obj2\n        # Hypervolume contribution (approximated as product of normalized objectives)\n        hypervolume = norm_obj1 * norm_obj2\n        # Select top 20% solutions by hypervolume\n        top_indices = np.argsort(hypervolume)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Perform 5-10 iterations of local search\n    for _ in range(np.random.randint(5, 11)):\n        # Flip items with highest marginal gains in either objective\n        if np.random.rand() < 0.5:\n            target_gain = marginal_gain1\n        else:\n            target_gain = marginal_gain2\n\n        high_gain_indices = np.argsort(target_gain)[::-1][:min(3, len(weight_lst))]\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Perform 1-2 random flips to maintain diversity\n        for _ in range(np.random.randint(1, 3)):\n            idx = np.random.randint(len(weight_lst))\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3280011565178666,
            0.3998071551322937
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate hypervolume contribution for each solution\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = np.max(objectives[:, 0]), np.max(objectives[:, 1])\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Normalize objectives\n        norm_obj1 = objectives[:, 0] / max_obj1\n        norm_obj2 = objectives[:, 1] / max_obj2\n        # Hypervolume contribution (approximated as product of normalized objectives)\n        hypervolume = norm_obj1 * norm_obj2\n        # Select top 20% solutions by hypervolume\n        top_indices = np.argsort(hypervolume)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Perform 5-10 iterations of local search\n    for _ in range(np.random.randint(5, 11)):\n        # Flip items with highest marginal gains in either objective\n        if np.random.rand() < 0.5:\n            target_gain = marginal_gain1\n        else:\n            target_gain = marginal_gain2\n\n        high_gain_indices = np.argsort(target_gain)[::-1][:min(3, len(weight_lst))]\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Perform 1-2 random flips to maintain diversity\n        for _ in range(np.random.randint(1, 3)):\n            idx = np.random.randint(len(weight_lst))\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        This algorithm prioritizes high-performance solutions (top 20% by normalized objective sums) and enhances them through a diversity-aware local search that strategically flips items based on combined marginal gains and crowding distance, while maintaining feasibility through capacity checks. It further diversifies by replacing low-contribution items with high-potential alternatives, balancing exploration and exploitation to improve multi-objective trade-offs.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate crowding distance for diversity-aware selection\n    objectives = np.array([obj for _, obj in archive])\n    n_solutions = len(objectives)\n    crowding_dist = np.zeros(n_solutions)\n\n    for m in range(2):  # For each objective\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding_dist[sorted_idx[0]] = crowding_dist[sorted_idx[-1]] = np.inf  # Boundary solutions\n        for i in range(1, n_solutions - 1):\n            crowding_dist[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (max_obj1 if m == 0 else max_obj2)\n\n    # Prioritize flipping items based on multi-objective marginal gains and crowding distance\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = (marginal_gain1 + marginal_gain2) * (1 + crowding_dist[selected_idx] / (np.max(crowding_dist) + 1e-6))\n\n    # Flip top 3 high-gain items\n    high_gain_indices = np.argsort(-combined_gain)[:min(3, len(weight_lst))]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled diversification: replace low-contribution items with high-potential alternatives\n    if np.random.rand() < 0.4:\n        low_contrib_indices = np.argsort(combined_gain)[:min(2, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            # Try adding a high-potential item\n            candidate_idx = np.random.choice(np.where(base_solution == 0)[0])\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 151,
        "algorithm": "The algorithm combines Pareto dominance and hypervolume contribution for solution selection, then applies a two-phase local search: first refining solutions by prioritizing items with highest marginal gains for each objective, followed by a probabilistic diversification step that replaces low-value items with high-density alternatives while maintaining feasibility. The selection prioritizes non-dominated solutions with high crowding distance, and the local search alternates between objective-specific refinement and diversification to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate hypervolume contribution and diversity metric\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = np.max(objectives, axis=0)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Normalize objectives\n        norm_obj = objectives / np.array([max_obj1, max_obj2])\n        # Calculate dominance rank and crowding distance\n        dominance = np.zeros(len(archive))\n        crowding_dist = np.zeros(len(archive))\n        for i in range(len(archive)):\n            dominated_count = 0\n            for j in range(len(archive)):\n                if i != j and all(norm_obj[j] >= norm_obj[i]):\n                    dominated_count += 1\n            dominance[i] = dominated_count\n\n        # Combined selection metric: prioritize non-dominated solutions with high crowding distance\n        selection_metric = -dominance + crowding_dist\n        selected_idx = np.argmax(selection_metric)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Two-phase local search\n    # Phase 1: Objective-specific refinement\n    for obj_idx in [0, 1]:\n        marginal_gain = (value1_lst if obj_idx == 0 else value2_lst) / weight_lst\n        sorted_indices = np.argsort(-marginal_gain)\n\n        for idx in sorted_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Phase 2: Probabilistic diversification\n    if np.random.rand() < 0.5:\n        # Calculate value density for each item\n        value_density = (value1_lst + value2_lst) / weight_lst\n        sorted_density = np.argsort(-value_density)\n\n        # Replace low-value items with high-density alternatives\n        for i in range(len(sorted_density)):\n            idx = sorted_density[i]\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n                # Find a high-density item to add\n                for candidate_idx in sorted_density:\n                    if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n                        new_solution[candidate_idx] = 1\n                        current_weight += weight_lst[candidate_idx]\n                        break\n\n    return new_solution\n\n",
        "score": [
            -0.8615112405216327,
            1.5611952245235443
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate hypervolume contribution and diversity metric\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = np.max(objectives, axis=0)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Normalize objectives\n        norm_obj = objectives / np.array([max_obj1, max_obj2])\n        # Calculate dominance rank and crowding distance\n        dominance = np.zeros(len(archive))\n        crowding_dist = np.zeros(len(archive))\n        for i in range(len(archive)):\n            dominated_count = 0\n            for j in range(len(archive)):\n                if i != j and all(norm_obj[j] >= norm_obj[i]):\n                    dominated_count += 1\n            dominance[i] = dominated_count\n\n        # Combined selection metric: prioritize non-dominated solutions with high crowding distance\n        selection_metric = -dominance + crowding_dist\n        selected_idx = np.argmax(selection_metric)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Two-phase local search\n    # Phase 1: Objective-specific refinement\n    for obj_idx in [0, 1]:\n        marginal_gain = (value1_lst if obj_idx == 0 else value2_lst) / weight_lst\n        sorted_indices = np.argsort(-marginal_gain)\n\n        for idx in sorted_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Phase 2: Probabilistic diversification\n    if np.random.rand() < 0.5:\n        # Calculate value density for each item\n        value_density = (value1_lst + value2_lst) / weight_lst\n        sorted_density = np.argsort(-value_density)\n\n        # Replace low-value items with high-density alternatives\n        for i in range(len(sorted_density)):\n            idx = sorted_density[i]\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n                # Find a high-density item to add\n                for candidate_idx in sorted_density:\n                    if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n                        new_solution[candidate_idx] = 1\n                        current_weight += weight_lst[candidate_idx]\n                        break\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        This algorithm prioritizes high-performance solutions (top 20% by normalized objective sums) and enhances them through a diversity-aware local search that strategically flips items based on combined marginal gains and crowding distance, while maintaining feasibility through capacity checks. It further diversifies by replacing low-contribution items with high-potential alternatives, balancing exploration and exploitation to improve multi-objective trade-offs.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate crowding distance for diversity-aware selection\n    objectives = np.array([obj for _, obj in archive])\n    n_solutions = len(objectives)\n    crowding_dist = np.zeros(n_solutions)\n\n    for m in range(2):  # For each objective\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding_dist[sorted_idx[0]] = crowding_dist[sorted_idx[-1]] = np.inf  # Boundary solutions\n        for i in range(1, n_solutions - 1):\n            crowding_dist[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (max_obj1 if m == 0 else max_obj2)\n\n    # Prioritize flipping items based on multi-objective marginal gains and crowding distance\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = (marginal_gain1 + marginal_gain2) * (1 + crowding_dist[selected_idx] / (np.max(crowding_dist) + 1e-6))\n\n    # Flip top 3 high-gain items\n    high_gain_indices = np.argsort(-combined_gain)[:min(3, len(weight_lst))]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled diversification: replace low-contribution items with high-potential alternatives\n    if np.random.rand() < 0.4:\n        low_contrib_indices = np.argsort(combined_gain)[:min(2, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            # Try adding a high-potential item\n            candidate_idx = np.random.choice(np.where(base_solution == 0)[0])\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 152,
        "algorithm": "This algorithm selects promising solutions from the archive by prioritizing Pareto-dominated and diverse solutions (top 30%), then applies a hybrid local search that combines item flips based on marginal gains and strategic replacements of low-contribution items, ensuring feasibility through adaptive capacity checks. It balances exploitation (flipping high-margin items) and exploration (replacing low-contribution items) while maintaining diversity through crowding distance weighting. The method prioritizes items with higher combined marginal gains for both objectives, with diversity-aware selection to avoid local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by Pareto dominance and diversity\n    objectives = np.array([obj for _, obj in archive])\n    n_solutions = len(objectives)\n    crowding_dist = np.zeros(n_solutions)\n\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding_dist[sorted_idx[0]] = crowding_dist[sorted_idx[-1]] = np.inf\n        for i in range(1, n_solutions - 1):\n            crowding_dist[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (np.max(objectives[:, m]) + 1e-6)\n\n    combined_score = (objectives[:, 0] + objectives[:, 1]) * (1 + crowding_dist / (np.max(crowding_dist) + 1e-6))\n    top_indices = np.argsort(combined_score)[-max(1, len(archive) // 3):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains with diversity weighting\n    marginal_gain1 = value1_lst / (weight_lst + 1e-6)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n    combined_gain = (marginal_gain1 + marginal_gain2) * (1 + crowding_dist[selected_idx] / (np.max(crowding_dist) + 1e-6))\n\n    # Flip top 5 items with highest combined gain\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Strategic replacement of low-contribution items\n    if np.random.rand() < 0.5:\n        low_contrib_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            # Try adding a high-potential item with different criteria\n            candidate_pool = np.where((base_solution == 0) &\n                                     (weight_lst <= capacity - current_weight))[0]\n            if len(candidate_pool) > 0:\n                candidate_scores = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n                best_candidate = candidate_pool[np.argmax(candidate_scores[candidate_pool])]\n                if current_weight + weight_lst[best_candidate] <= capacity:\n                    new_solution[best_candidate] = 1\n                    current_weight += weight_lst[best_candidate]\n\n    return new_solution\n\n",
        "score": [
            -0.47447744122469543,
            1.8266284763813019
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by Pareto dominance and diversity\n    objectives = np.array([obj for _, obj in archive])\n    n_solutions = len(objectives)\n    crowding_dist = np.zeros(n_solutions)\n\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding_dist[sorted_idx[0]] = crowding_dist[sorted_idx[-1]] = np.inf\n        for i in range(1, n_solutions - 1):\n            crowding_dist[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (np.max(objectives[:, m]) + 1e-6)\n\n    combined_score = (objectives[:, 0] + objectives[:, 1]) * (1 + crowding_dist / (np.max(crowding_dist) + 1e-6))\n    top_indices = np.argsort(combined_score)[-max(1, len(archive) // 3):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains with diversity weighting\n    marginal_gain1 = value1_lst / (weight_lst + 1e-6)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n    combined_gain = (marginal_gain1 + marginal_gain2) * (1 + crowding_dist[selected_idx] / (np.max(crowding_dist) + 1e-6))\n\n    # Flip top 5 items with highest combined gain\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Strategic replacement of low-contribution items\n    if np.random.rand() < 0.5:\n        low_contrib_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            # Try adding a high-potential item with different criteria\n            candidate_pool = np.where((base_solution == 0) &\n                                     (weight_lst <= capacity - current_weight))[0]\n            if len(candidate_pool) > 0:\n                candidate_scores = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n                best_candidate = candidate_pool[np.argmax(candidate_scores[candidate_pool])]\n                if current_weight + weight_lst[best_candidate] <= capacity:\n                    new_solution[best_candidate] = 1\n                    current_weight += weight_lst[best_candidate]\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 3 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThis algorithm prioritizes high-performance solutions (top 20% by normalized objective sums) and enhances them through a diversity-aware local search that strategically flips items based on combined marginal gains and crowding distance, while maintaining feasibility through capacity checks. It further diversifies by replacing low-contribution items with high-potential alternatives, balancing exploration and exploitation to improve multi-objective trade-offs.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate crowding distance for diversity-aware selection\n    objectives = np.array([obj for _, obj in archive])\n    n_solutions = len(objectives)\n    crowding_dist = np.zeros(n_solutions)\n\n    for m in range(2):  # For each objective\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding_dist[sorted_idx[0]] = crowding_dist[sorted_idx[-1]] = np.inf  # Boundary solutions\n        for i in range(1, n_solutions - 1):\n            crowding_dist[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (max_obj1 if m == 0 else max_obj2)\n\n    # Prioritize flipping items based on multi-objective marginal gains and crowding distance\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = (marginal_gain1 + marginal_gain2) * (1 + crowding_dist[selected_idx] / (np.max(crowding_dist) + 1e-6))\n\n    # Flip top 3 high-gain items\n    high_gain_indices = np.argsort(-combined_gain)[:min(3, len(weight_lst))]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled diversification: replace low-contribution items with high-potential alternatives\n    if np.random.rand() < 0.4:\n        low_contrib_indices = np.argsort(combined_gain)[:min(2, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            # Try adding a high-potential item\n            candidate_idx = np.random.choice(np.where(base_solution == 0)[0])\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Refined Heuristic Design for BI-KP**\n- **Keywords**: **Multi-objective marginal gain, adaptive perturbation, feasibility-aware flipping, diversity-aware selection, hypervolume contribution.**\n- **Advice**: **Select top 20% solutions by hypervolume contribution, flip items with highest marginal gains in either objective, then add 1-2 random flips (ensuring feasibility), and iterate 5-10 times per solution.**\n- **Avoid**: **Overly aggressive flipping or pure randomness that disrupts progress; ignore feasibility checks after perturbations.**\n- **Explanation**: **Balances targeted exploitation (marginal gains) and controlled exploration (random flips) to ensure progress while preserving solution quality. Feasibility checks and iterative refinement yield high-quality neighbors efficiently.**\n\n*(Word count: ~50)*\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 153,
        "algorithm": "The algorithm selects promising solutions from the top 20% of the archive (based on normalized objective sums) and refines them through a hybrid local search combining targeted high-marginal-gain flips, controlled random flips, and adaptive perturbation of low-marginal-contribution items, ensuring feasibility at each step. It performs 5 iterations of refinement to balance exploration and exploitation, prioritizing items with higher combined marginal gains while occasionally perturbing low-contribution items for diversity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Iterative hybrid local search\n    for _ in range(5):  # Perform 5 iterations of refinement\n        # Targeted flipping: prioritize high-marginal-gain items in either objective\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n        combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n\n        high_gain_indices = np.argsort(-combined_gain)[:min(3, len(weight_lst))]\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Controlled random flips\n        if np.random.rand() < 0.3:  # 30% chance of random flip\n            candidate_idx = np.random.randint(len(weight_lst))\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n        # Adaptive perturbation: flip low-marginal-contribution items\n        if np.random.rand() < 0.2:  # 20% chance of perturbation\n            marginal_contribution = (value1_lst + value2_lst) / weight_lst\n            low_contrib_indices = np.argsort(marginal_contribution)[:min(2, len(weight_lst))]\n            for idx in low_contrib_indices:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Update base solution for next iteration\n        base_solution = new_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.36051908346635936,
            0.29693931341171265
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Iterative hybrid local search\n    for _ in range(5):  # Perform 5 iterations of refinement\n        # Targeted flipping: prioritize high-marginal-gain items in either objective\n        marginal_gain1 = value1_lst / weight_lst\n        marginal_gain2 = value2_lst / weight_lst\n        combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n\n        high_gain_indices = np.argsort(-combined_gain)[:min(3, len(weight_lst))]\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Controlled random flips\n        if np.random.rand() < 0.3:  # 30% chance of random flip\n            candidate_idx = np.random.randint(len(weight_lst))\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n        # Adaptive perturbation: flip low-marginal-contribution items\n        if np.random.rand() < 0.2:  # 20% chance of perturbation\n            marginal_contribution = (value1_lst + value2_lst) / weight_lst\n            low_contrib_indices = np.argsort(marginal_contribution)[:min(2, len(weight_lst))]\n            for idx in low_contrib_indices:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n        # Update base solution for next iteration\n        base_solution = new_solution.copy()\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 5 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects the solution with the highest hypervolume contribution from the archive, then applies a hybrid local search combining marginal-gain-based flips with an objective-balanced mechanism that prioritizes items with high combined marginal gains and balanced trade-offs between objectives. It dynamically scales the number of random flips based on the solution's distance to the ideal point and ensures feasibility through a trade-off-aware removal process that eliminates items with the poorest trade-offs between objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    selected_idx = np.argmax(hypervolume)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Objective-balanced flipping mechanism\n    trade_off = value2_lst / (value1_lst + 1e-10)\n    combined_score = (marginal_gain1 + marginal_gain2) * (1 + 0.5 * np.abs(trade_off - np.mean(trade_off)))\n    sorted_indices = np.argsort(combined_score)[::-1]\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (scaled by distance to ideal point)\n    distance_to_ideal = np.linalg.norm(ideal_point - objectives[selected_idx])\n    n_random_flips = max(1, int(5 * (1 / (distance_to_ideal + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Trade-off-aware feasibility restoration\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with poorest trade-off\n        item_trade_off = value2_lst[removable_items] / (value1_lst[removable_items] + 1e-10)\n        avg_trade_off = np.mean(item_trade_off)\n        remove_idx = removable_items[np.argmax(np.abs(item_trade_off - avg_trade_off))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive based on combined objective scores, then performs a targeted local search by flipping high-marginal-gain items prioritizing the least dominated objective, followed by controlled random perturbations and adaptive feasibility repairs to ensure capacity constraints are met while maintaining solution diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by combined objective score\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        combined_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(combined_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains and dominance information\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Identify items that improve the least dominated objective\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    # Targeted flipping of high-marginal-gain items prioritizing least dominated objective\n    if least_dominated == 1:\n        target_gain = marginal_gain1\n    else:\n        target_gain = marginal_gain2\n\n    high_gain_indices = np.argsort(target_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation of low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined marginal gain\n        removal_candidates = included_items[np.argsort(combined_gain[included_items])]\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s a refined heuristic design for the BI-KP, incorporating hypervolume-aware selection and a novel local search strategy:\n\n### **Refined Heuristic Design for BI-KP**\n- **Keywords**: **Hypervolume contribution, dominance-aware flipping, adaptive perturbation, feasibility-aware repair, multi-objective marginal gain.**\n- **Advice**:\n  1. **Select** top 20% solutions by hypervolume contribution.\n  2. **Flip** items with highest marginal gains in either objective, then add **1-2 random flips** (ensuring feasibility).\n  3. **Repair** infeasible neighbors by removing items with smallest marginal gain in the least critical objective.\n  4. **Iterate** 5-10 times per solution to refine the archive.\n- **Avoid**: **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Explanation**: **Balances exploitation (hypervolume-aware selection) and exploration (adaptive flips) while ensuring feasibility. Dominance-aware repairs prevent stagnation, and iterative refinement yields high-quality neighbors efficiently.**\n\n*(Word count: ~50)*\n\n**Why this works**:\n- **Hypervolume-aware selection** ensures diversity and trade-off awareness.\n- **Dominance-aware flipping** prioritizes items that improve either objective.\n- **Adaptive perturbation** (1-2 random flips) avoids premature convergence.\n- **Feasibility-aware repair** guarantees valid neighbors.\n\nThis heuristic avoids the pitfalls of ineffective self-reflection while leveraging multi-objective insights.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 154,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    top_indices = np.argsort(hypervolume)[-max(1, len(archive)//5):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Flip items with highest marginal gains in either objective\n    combined_gain = marginal_gain1 + marginal_gain2\n    high_gain_indices = np.argsort(combined_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips to escape local optima\n    n_random_flips = np.random.randint(1, 3)\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n\n    # Repair infeasible neighbors by removing items with smallest marginal gain in least critical objective\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Identify least critical objective\n        obj1_ratio = objectives[selected_idx][0] / (ideal_point[0] + 1e-10)\n        obj2_ratio = objectives[selected_idx][1] / (ideal_point[1] + 1e-10)\n        least_critical = 1 if obj1_ratio > obj2_ratio else 2\n\n        # Remove items with smallest marginal gain in least critical objective\n        if least_critical == 1:\n            removal_candidates = included_items[np.argsort(marginal_gain1[included_items])]\n        else:\n            removal_candidates = included_items[np.argsort(marginal_gain2[included_items])]\n\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.870503903035039,
            0.22981229424476624
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    top_indices = np.argsort(hypervolume)[-max(1, len(archive)//5):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Flip items with highest marginal gains in either objective\n    combined_gain = marginal_gain1 + marginal_gain2\n    high_gain_indices = np.argsort(combined_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips to escape local optima\n    n_random_flips = np.random.randint(1, 3)\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n\n    # Repair infeasible neighbors by removing items with smallest marginal gain in least critical objective\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Identify least critical objective\n        obj1_ratio = objectives[selected_idx][0] / (ideal_point[0] + 1e-10)\n        obj2_ratio = objectives[selected_idx][1] / (ideal_point[1] + 1e-10)\n        least_critical = 1 if obj1_ratio > obj2_ratio else 2\n\n        # Remove items with smallest marginal gain in least critical objective\n        if least_critical == 1:\n            removal_candidates = included_items[np.argsort(marginal_gain1[included_items])]\n        else:\n            removal_candidates = included_items[np.argsort(marginal_gain2[included_items])]\n\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive (based on normalized objective sums) and applies a targeted local search by prioritizing flips of high-marginal-gain items, followed by 1-2 random flips to escape local optima, while ensuring feasibility through iterative refinement. High-marginal-gain items (based on value-to-weight ratios) are given higher priority, and the algorithm balances exploitation (focused flips) with exploration (random flips) to improve solution quality.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips to escape local optima\n    num_random_flips = np.random.randint(1, 3)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s a refined heuristic design for the BI-KP, incorporating hypervolume-aware selection and a novel local search strategy:\n\n### **Refined Heuristic Design for BI-KP**\n- **Keywords**: **Hypervolume contribution, dominance-aware flipping, adaptive perturbation, feasibility-aware repair, multi-objective marginal gain.**\n- **Advice**:\n  1. **Select** top 20% solutions by hypervolume contribution.\n  2. **Flip** items with highest marginal gains in either objective, then add **1-2 random flips** (ensuring feasibility).\n  3. **Repair** infeasible neighbors by removing items with smallest marginal gain in the least critical objective.\n  4. **Iterate** 5-10 times per solution to refine the archive.\n- **Avoid**: **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Explanation**: **Balances exploitation (hypervolume-aware selection) and exploration (adaptive flips) while ensuring feasibility. Dominance-aware repairs prevent stagnation, and iterative refinement yields high-quality neighbors efficiently.**\n\n*(Word count: ~50)*\n\n**Why this works**:\n- **Hypervolume-aware selection** ensures diversity and trade-off awareness.\n- **Dominance-aware flipping** prioritizes items that improve either objective.\n- **Adaptive perturbation** (1-2 random flips) avoids premature convergence.\n- **Feasibility-aware repair** guarantees valid neighbors.\n\nThis heuristic avoids the pitfalls of ineffective self-reflection while leveraging multi-objective insights.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 155,
        "algorithm": "The algorithm selects promising solutions from the archive based on hypervolume contribution (prioritizing high product of normalized objectives), then applies a dominance-aware swapping strategy to exchange items between objectives based on marginal gains, followed by targeted flips of high-value items while ensuring feasibility through iterative weight adjustment and occasional random swaps to escape local optima. The selection focuses on top 20% solutions, prioritizes items with high marginal gains in either objective, and uses random swaps to maintain diversity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution (approximated as product of normalized objectives)\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dominance-aware swapping: exchange items between objectives based on marginal gains\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Check if swapping to the other objective improves marginal gain\n            if (marginal_gain1[i] < marginal_gain2[i] and current_weight - weight_lst[i] + weight_lst[i] <= capacity) or \\\n               (marginal_gain2[i] < marginal_gain1[i] and current_weight - weight_lst[i] + weight_lst[i] <= capacity):\n                new_solution[i] = 1 - new_solution[i]\n\n    # Targeted flipping: prioritize high-marginal-gain items in either objective\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Occasional random swap (20% chance) to escape local optima\n    if np.random.rand() < 0.2:\n        idx1, idx2 = np.random.choice(len(weight_lst), 2, replace=False)\n        if base_solution[idx1] == 1 and base_solution[idx2] == 0:\n            if current_weight - weight_lst[idx1] + weight_lst[idx2] <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Iterative refinement: ensure feasibility\n    for _ in range(5):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        # Remove items with smallest marginal gain in least critical objective\n        if np.random.rand() < 0.5:\n            least_critical_gain = np.minimum(marginal_gain1, marginal_gain2)\n        else:\n            least_critical_gain = np.maximum(marginal_gain1, marginal_gain2)\n        remove_idx = np.argmax(least_critical_gain * new_solution)\n        if new_solution[remove_idx] == 1:\n            new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8770790184265134,
            0.3437095284461975
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution (approximated as product of normalized objectives)\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dominance-aware swapping: exchange items between objectives based on marginal gains\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Check if swapping to the other objective improves marginal gain\n            if (marginal_gain1[i] < marginal_gain2[i] and current_weight - weight_lst[i] + weight_lst[i] <= capacity) or \\\n               (marginal_gain2[i] < marginal_gain1[i] and current_weight - weight_lst[i] + weight_lst[i] <= capacity):\n                new_solution[i] = 1 - new_solution[i]\n\n    # Targeted flipping: prioritize high-marginal-gain items in either objective\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Occasional random swap (20% chance) to escape local optima\n    if np.random.rand() < 0.2:\n        idx1, idx2 = np.random.choice(len(weight_lst), 2, replace=False)\n        if base_solution[idx1] == 1 and base_solution[idx2] == 0:\n            if current_weight - weight_lst[idx1] + weight_lst[idx2] <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Iterative refinement: ensure feasibility\n    for _ in range(5):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        # Remove items with smallest marginal gain in least critical objective\n        if np.random.rand() < 0.5:\n            least_critical_gain = np.minimum(marginal_gain1, marginal_gain2)\n        else:\n            least_critical_gain = np.maximum(marginal_gain1, marginal_gain2)\n        remove_idx = np.argmax(least_critical_gain * new_solution)\n        if new_solution[remove_idx] == 1:\n            new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive (by normalized objective sums), prioritizes flipping items with high marginal gains (either objective), and adds 1-2 random flips while maintaining feasibility. It then iteratively refines the solution 5-10 times to balance exploitation and exploration, ensuring the neighbor solution remains feasible. The approach combines targeted local search with randomness to improve solution quality across both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips (ensuring feasibility)\n    num_random_flips = np.random.randint(1, 3)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement: repeat 5-10 times\n    for _ in range(np.random.randint(5, 11)):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive (based on normalized objective sums) and applies a targeted local search by prioritizing flips of high-marginal-gain items, followed by 1-2 random flips to escape local optima, while ensuring feasibility through iterative refinement. High-marginal-gain items (based on value-to-weight ratios) are given higher priority, and the algorithm balances exploitation (focused flips) with exploration (random flips) to improve solution quality.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips to escape local optima\n    num_random_flips = np.random.randint(1, 3)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s a refined heuristic design for the BI-KP, incorporating hypervolume-aware selection and a novel local search strategy:\n\n### **Refined Heuristic Design for BI-KP**\n- **Keywords**: **Hypervolume contribution, dominance-aware flipping, adaptive perturbation, feasibility-aware repair, multi-objective marginal gain.**\n- **Advice**:\n  1. **Select** top 20% solutions by hypervolume contribution.\n  2. **Flip** items with highest marginal gains in either objective, then add **1-2 random flips** (ensuring feasibility).\n  3. **Repair** infeasible neighbors by removing items with smallest marginal gain in the least critical objective.\n  4. **Iterate** 5-10 times per solution to refine the archive.\n- **Avoid**: **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Explanation**: **Balances exploitation (hypervolume-aware selection) and exploration (adaptive flips) while ensuring feasibility. Dominance-aware repairs prevent stagnation, and iterative refinement yields high-quality neighbors efficiently.**\n\n*(Word count: ~50)*\n\n**Why this works**:\n- **Hypervolume-aware selection** ensures diversity and trade-off awareness.\n- **Dominance-aware flipping** prioritizes items that improve either objective.\n- **Adaptive perturbation** (1-2 random flips) avoids premature convergence.\n- **Feasibility-aware repair** guarantees valid neighbors.\n\nThis heuristic avoids the pitfalls of ineffective self-reflection while leveraging multi-objective insights.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 156,
        "algorithm": "The algorithm selects top 20% solutions from the archive based on hypervolume contribution, then applies a dominance-aware local search that prioritizes flipping high-marginal-gain items while ensuring feasibility, followed by adaptive flips targeting underrepresented items and hypervolume-aware repair to remove least critical items. The method balances exploitation (via marginal gains) and exploration (via random flips) while maintaining feasibility through iterative refinement.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    if objectives.size == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Compute hypervolume contribution (simplified)\n        max_obj1 = np.max(objectives[:, 0])\n        max_obj2 = np.max(objectives[:, 1])\n        if max_obj1 == 0 or max_obj2 == 0:\n            selected_idx = np.random.randint(len(archive))\n        else:\n            normalized_scores = (objectives[:, 0] / max_obj1) + (objectives[:, 1] / max_obj2)\n            top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n            selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dominance-aware flipping: prioritize items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive flips: target underrepresented items\n    num_random_flips = np.random.randint(1, 3)\n    for _ in range(num_random_flips):\n        # Prefer flipping items not in the current solution\n        candidate_indices = np.where(base_solution == 0)[0]\n        if len(candidate_indices) == 0:\n            candidate_indices = np.arange(len(weight_lst))\n        candidate_idx = np.random.choice(candidate_indices)\n        if current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n\n    # Hypervolume-aware repair: remove items with smallest marginal gain in least critical objective\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n        else:\n            # Identify least critical objective (simplified)\n            total_value1 = np.sum(value1_lst * temp_solution)\n            total_value2 = np.sum(value2_lst * temp_solution)\n            least_critical_obj = 1 if total_value1 / total_value2 > 1 else 2\n\n            # Remove items with smallest marginal gain in least critical objective\n            if least_critical_obj == 1:\n                candidate_indices = np.where(temp_solution == 1)[0]\n                if len(candidate_indices) > 0:\n                    marginal_gain = value1_lst[candidate_indices] / weight_lst[candidate_indices]\n                    remove_idx = candidate_indices[np.argmin(marginal_gain)]\n                    temp_solution[remove_idx] = 0\n            else:\n                candidate_indices = np.where(temp_solution == 1)[0]\n                if len(candidate_indices) > 0:\n                    marginal_gain = value2_lst[candidate_indices] / weight_lst[candidate_indices]\n                    remove_idx = candidate_indices[np.argmin(marginal_gain)]\n                    temp_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.7882628558891667,
            0.2511917054653168
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    if objectives.size == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Compute hypervolume contribution (simplified)\n        max_obj1 = np.max(objectives[:, 0])\n        max_obj2 = np.max(objectives[:, 1])\n        if max_obj1 == 0 or max_obj2 == 0:\n            selected_idx = np.random.randint(len(archive))\n        else:\n            normalized_scores = (objectives[:, 0] / max_obj1) + (objectives[:, 1] / max_obj2)\n            top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n            selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dominance-aware flipping: prioritize items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive flips: target underrepresented items\n    num_random_flips = np.random.randint(1, 3)\n    for _ in range(num_random_flips):\n        # Prefer flipping items not in the current solution\n        candidate_indices = np.where(base_solution == 0)[0]\n        if len(candidate_indices) == 0:\n            candidate_indices = np.arange(len(weight_lst))\n        candidate_idx = np.random.choice(candidate_indices)\n        if current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n\n    # Hypervolume-aware repair: remove items with smallest marginal gain in least critical objective\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n        else:\n            # Identify least critical objective (simplified)\n            total_value1 = np.sum(value1_lst * temp_solution)\n            total_value2 = np.sum(value2_lst * temp_solution)\n            least_critical_obj = 1 if total_value1 / total_value2 > 1 else 2\n\n            # Remove items with smallest marginal gain in least critical objective\n            if least_critical_obj == 1:\n                candidate_indices = np.where(temp_solution == 1)[0]\n                if len(candidate_indices) > 0:\n                    marginal_gain = value1_lst[candidate_indices] / weight_lst[candidate_indices]\n                    remove_idx = candidate_indices[np.argmin(marginal_gain)]\n                    temp_solution[remove_idx] = 0\n            else:\n                candidate_indices = np.where(temp_solution == 1)[0]\n                if len(candidate_indices) > 0:\n                    marginal_gain = value2_lst[candidate_indices] / weight_lst[candidate_indices]\n                    remove_idx = candidate_indices[np.argmin(marginal_gain)]\n                    temp_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects promising solutions from the top 20% of the archive (based on normalized objective sums) and applies a targeted local search by prioritizing flips of high-marginal-gain items, followed by 1-2 random flips to escape local optima, while ensuring feasibility through iterative refinement. High-marginal-gain items (based on value-to-weight ratios) are given higher priority, and the algorithm balances exploitation (focused flips) with exploration (random flips) to improve solution quality.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips to escape local optima\n    num_random_flips = np.random.randint(1, 3)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 157,
        "algorithm": "The algorithm selects promising solutions from the archive using a hybrid score combining normalized objectives and item diversity, then applies a multi-phase local search: prioritizing high-value items, performing targeted swaps between objectives, and using dynamic random flips to escape local optima while maintaining feasibility. The method emphasizes high-gain items first, then refines by swapping items between objectives, and finally applies adaptive flips to explore the solution space effectively.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate hybrid score: combination of normalized objectives and item diversity\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        diversity_scores = [np.sum(sol[0] != archive[0][0]) for sol in archive]\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2 + 0.5 * div/len(weight_lst))\n                           for (_, obj), div in zip(archive, diversity_scores)]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Prioritize high-value items in both objectives\n    combined_gain = (value1_lst + value2_lst) / weight_lst\n    high_gain_indices = np.argsort(-combined_gain)[:min(10, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Targeted swaps between objectives\n    for _ in range(3):\n        obj1_items = np.where((base_solution == 1) & (value1_lst > value2_lst))[0]\n        obj2_items = np.where((base_solution == 1) & (value2_lst > value1_lst))[0]\n\n        if len(obj1_items) > 0 and len(obj2_items) > 0:\n            swap_idx1 = np.random.choice(obj1_items)\n            swap_idx2 = np.random.choice(obj2_items)\n\n            if (current_weight - weight_lst[swap_idx1] + weight_lst[swap_idx2] <= capacity and\n                current_weight - weight_lst[swap_idx2] + weight_lst[swap_idx1] <= capacity):\n                # Perform the swap\n                new_solution[swap_idx1], new_solution[swap_idx2] = 0, 1\n                current_weight = current_weight - weight_lst[swap_idx1] + weight_lst[swap_idx2]\n\n    # Phase 3: Dynamic random flips with adaptive probability\n    flip_prob = 0.3 + 0.2 * (1 - current_weight/capacity)  # Higher probability when near capacity\n    for idx in range(len(weight_lst)):\n        if np.random.random() < flip_prob:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Iterative refinement\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.3768284389509498,
            0.6642734110355377
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate hybrid score: combination of normalized objectives and item diversity\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        diversity_scores = [np.sum(sol[0] != archive[0][0]) for sol in archive]\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2 + 0.5 * div/len(weight_lst))\n                           for (_, obj), div in zip(archive, diversity_scores)]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Prioritize high-value items in both objectives\n    combined_gain = (value1_lst + value2_lst) / weight_lst\n    high_gain_indices = np.argsort(-combined_gain)[:min(10, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Targeted swaps between objectives\n    for _ in range(3):\n        obj1_items = np.where((base_solution == 1) & (value1_lst > value2_lst))[0]\n        obj2_items = np.where((base_solution == 1) & (value2_lst > value1_lst))[0]\n\n        if len(obj1_items) > 0 and len(obj2_items) > 0:\n            swap_idx1 = np.random.choice(obj1_items)\n            swap_idx2 = np.random.choice(obj2_items)\n\n            if (current_weight - weight_lst[swap_idx1] + weight_lst[swap_idx2] <= capacity and\n                current_weight - weight_lst[swap_idx2] + weight_lst[swap_idx1] <= capacity):\n                # Perform the swap\n                new_solution[swap_idx1], new_solution[swap_idx2] = 0, 1\n                current_weight = current_weight - weight_lst[swap_idx1] + weight_lst[swap_idx2]\n\n    # Phase 3: Dynamic random flips with adaptive probability\n    flip_prob = 0.3 + 0.2 * (1 - current_weight/capacity)  # Higher probability when near capacity\n    for idx in range(len(weight_lst)):\n        if np.random.random() < flip_prob:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Iterative refinement\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects promising solutions from the top 20% of the archive (based on normalized objective sums) and applies a targeted local search by prioritizing flips of high-marginal-gain items, followed by 1-2 random flips to escape local optima, while ensuring feasibility through iterative refinement. High-marginal-gain items (based on value-to-weight ratios) are given higher priority, and the algorithm balances exploitation (focused flips) with exploration (random flips) to improve solution quality.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips to escape local optima\n    num_random_flips = np.random.randint(1, 3)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 158,
        "algorithm": "The algorithm selects promising solutions from the bottom 30% of the archive (based on normalized objective sums) and applies a targeted local search by prioritizing flips of low-marginal-gain items (based on value-to-weight ratios), followed by 2-3 random flips to escape local optima while ensuring feasibility through iterative refinement. The method balances exploitation (focused flips) with exploration (random flips) to improve solution quality.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select bottom 30% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        bottom_indices = np.argsort(normalized_scores)[:max(1, len(archive)//3)]\n        selected_idx = np.random.choice(bottom_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with low marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in low_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 2-3 random flips to escape local optima\n    num_random_flips = np.random.randint(2, 4)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.9063371563927572,
            0.20811793208122253
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select bottom 30% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        bottom_indices = np.argsort(normalized_scores)[:max(1, len(archive)//3)]\n        selected_idx = np.random.choice(bottom_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with low marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in low_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 2-3 random flips to escape local optima\n    num_random_flips = np.random.randint(2, 4)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 4 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive (based on normalized objective sums) and applies a targeted local search by prioritizing flips of high-marginal-gain items, followed by 1-2 random flips to escape local optima, while ensuring feasibility through iterative refinement. High-marginal-gain items (based on value-to-weight ratios) are given higher priority, and the algorithm balances exploitation (focused flips) with exploration (random flips) to improve solution quality.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips to escape local optima\n    num_random_flips = np.random.randint(1, 3)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive (based on normalized objective sums) and generates neighbors by flipping items with high marginal gains for both objectives, followed by 1-2 random feasible flips, while ensuring feasibility through iterative refinement by removing the lightest items when needed. It prioritizes items with combined high marginal gains for both objectives while maintaining diversity through random flips.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain-based flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add 1-2 random feasible flips\n    for _ in range(np.random.randint(1, 3)):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s a refined heuristic design for the BI-KP, incorporating hypervolume-aware selection and a novel local search strategy:\n\n### **Refined Heuristic Design for BI-KP**\n- **Keywords**: **Hypervolume contribution, dominance-aware flipping, adaptive perturbation, feasibility-aware repair, multi-objective marginal gain.**\n- **Advice**:\n  1. **Select** top 20% solutions by hypervolume contribution.\n  2. **Flip** items with highest marginal gains in either objective, then add **1-2 random flips** (ensuring feasibility).\n  3. **Repair** infeasible neighbors by removing items with smallest marginal gain in the least critical objective.\n  4. **Iterate** 5-10 times per solution to refine the archive.\n- **Avoid**: **Overly aggressive flipping** (e.g., flipping all items) or **pure randomness** that disrupts progress.\n- **Explanation**: **Balances exploitation (hypervolume-aware selection) and exploration (adaptive flips) while ensuring feasibility. Dominance-aware repairs prevent stagnation, and iterative refinement yields high-quality neighbors efficiently.**\n\n*(Word count: ~50)*\n\n**Why this works**:\n- **Hypervolume-aware selection** ensures diversity and trade-off awareness.\n- **Dominance-aware flipping** prioritizes items that improve either objective.\n- **Adaptive perturbation** (1-2 random flips) avoids premature convergence.\n- **Feasibility-aware repair** guarantees valid neighbors.\n\nThis heuristic avoids the pitfalls of ineffective self-reflection while leveraging multi-objective insights.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 159,
        "algorithm": "The algorithm selects promising solutions from the top 20% of the archive based on hypervolume contribution, then performs a targeted local search by flipping high-marginal-gain items while ensuring feasibility, followed by adaptive perturbation of low-contribution items to escape local optima. It balances exploitation (hypervolume-aware selection and high-gain flips) with exploration (adaptive perturbation and random flips) through iterative refinement and feasibility-aware repair. The selection prioritizes solutions with better hypervolume, while the local search intelligently modifies the solution by combining dominance-aware flipping, adaptive perturbation, and iterative refinement to improve both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    def hypervolume(sol):\n        obj1, obj2 = sol[1]\n        return obj1 * obj2\n\n    hypervolumes = [hypervolume(sol) for sol in archive]\n    top_indices = np.argsort(hypervolumes)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:min(3, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: repair infeasible solutions\n    for _ in range(5):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8094458658682218,
            0.1887216567993164
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    def hypervolume(sol):\n        obj1, obj2 = sol[1]\n        return obj1 * obj2\n\n    hypervolumes = [hypervolume(sol) for sol in archive]\n    top_indices = np.argsort(hypervolumes)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:min(3, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: repair infeasible solutions\n    for _ in range(5):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 5 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects the solution with the highest hypervolume contribution from the archive, then applies a hybrid local search combining marginal-gain-based flips with an objective-balanced mechanism that prioritizes items with high combined marginal gains and balanced trade-offs between objectives. It dynamically scales the number of random flips based on the solution's distance to the ideal point and ensures feasibility through a trade-off-aware removal process that eliminates items with the poorest trade-offs between objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    selected_idx = np.argmax(hypervolume)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Objective-balanced flipping mechanism\n    trade_off = value2_lst / (value1_lst + 1e-10)\n    combined_score = (marginal_gain1 + marginal_gain2) * (1 + 0.5 * np.abs(trade_off - np.mean(trade_off)))\n    sorted_indices = np.argsort(combined_score)[::-1]\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (scaled by distance to ideal point)\n    distance_to_ideal = np.linalg.norm(ideal_point - objectives[selected_idx])\n    n_random_flips = max(1, int(5 * (1 / (distance_to_ideal + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Trade-off-aware feasibility restoration\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with poorest trade-off\n        item_trade_off = value2_lst[removable_items] / (value1_lst[removable_items] + 1e-10)\n        avg_trade_off = np.mean(item_trade_off)\n        remove_idx = removable_items[np.argmax(np.abs(item_trade_off - avg_trade_off))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive based on combined objective scores, then performs a targeted local search by flipping high-marginal-gain items prioritizing the least dominated objective, followed by controlled random perturbations and adaptive feasibility repairs to ensure capacity constraints are met while maintaining solution diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by combined objective score\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        combined_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(combined_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains and dominance information\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Identify items that improve the least dominated objective\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    # Targeted flipping of high-marginal-gain items prioritizing least dominated objective\n    if least_dominated == 1:\n        target_gain = marginal_gain1\n    else:\n        target_gain = marginal_gain2\n\n    high_gain_indices = np.argsort(target_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation of low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined marginal gain\n        removal_candidates = included_items[np.argsort(combined_gain[included_items])]\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s a concise yet impactful heuristic design for the BI-KP:\n\n### **Refined Heuristic Design for BI-KP**\n- **Keywords**: **Hypervolume contribution, knee-point detection, trade-off-aware flipping, adaptive perturbation, feasibility-aware repair.**\n- **Advice**:\n  1. **Select** top 20% solutions by hypervolume contribution, prioritizing knee-points.\n  2. **Flip** items with highest marginal gains in either objective, then add **1-2 trade-off-aware flips** (ensuring feasibility).\n  3. **Repair** infeasible neighbors by removing items with smallest marginal gain in the least critical objective.\n  4. **Iterate** 5-10 times per solution to refine the archive.\n- **Avoid**: **Overly aggressive flipping** or **pure randomness**; ignore feasibility checks after perturbations.\n- **Explanation**: **Balances exploitation (knee-point selection) and exploration (trade-off-aware flips) while ensuring feasibility. Dominance-aware repairs prevent stagnation, and iterative refinement yields high-quality neighbors efficiently.**\n\n*(Word count: ~50)*\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 160,
        "algorithm": "The algorithm selects high-potential solutions from the archive (top 20% by hypervolume and knee-points) and applies a hybrid local search: it flips high-marginal-gain items in either objective, adds 1-2 trade-off-aware flips, and repairs infeasible solutions by removing items with smallest marginal gain in the least critical objective. The method prioritizes balanced trade-offs (knee-points) and intelligently repairs solutions to maintain feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    top_indices = np.argsort(hypervolume)[-max(1, len(archive) // 5):]\n\n    # Prioritize knee-points (solutions with balanced trade-offs)\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    avg_trade_off = np.mean(trade_off[top_indices])\n    knee_candidates = top_indices[np.argsort(np.abs(trade_off[top_indices] - avg_trade_off))[:min(3, len(top_indices))]]\n    selected_idx = np.random.choice(knee_candidates) if len(knee_candidates) > 0 else np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Flip high-marginal-gain items in either objective\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add 1-2 trade-off-aware flips\n    trade_off_aware_indices = np.argsort(np.abs(trade_off[selected_idx] - (value2_lst / (value1_lst + 1e-10))))[:2]\n    for idx in trade_off_aware_indices:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Repair infeasible neighbors\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n\n        # Remove items with smallest marginal gain in least critical objective\n        obj1_ratio = objectives[selected_idx, 0] / (ideal_point[0] + 1e-10)\n        obj2_ratio = objectives[selected_idx, 1] / (ideal_point[1] + 1e-10)\n        least_critical = 1 if obj1_ratio < obj2_ratio else 2\n\n        if least_critical == 1:\n            removal_candidates = included_items[np.argsort(marginal_gain1[included_items])]\n        else:\n            removal_candidates = included_items[np.argsort(marginal_gain2[included_items])]\n\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.8577015927987317,
            0.2595879137516022
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    top_indices = np.argsort(hypervolume)[-max(1, len(archive) // 5):]\n\n    # Prioritize knee-points (solutions with balanced trade-offs)\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    avg_trade_off = np.mean(trade_off[top_indices])\n    knee_candidates = top_indices[np.argsort(np.abs(trade_off[top_indices] - avg_trade_off))[:min(3, len(top_indices))]]\n    selected_idx = np.random.choice(knee_candidates) if len(knee_candidates) > 0 else np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Flip high-marginal-gain items in either objective\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add 1-2 trade-off-aware flips\n    trade_off_aware_indices = np.argsort(np.abs(trade_off[selected_idx] - (value2_lst / (value1_lst + 1e-10))))[:2]\n    for idx in trade_off_aware_indices:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Repair infeasible neighbors\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n\n        # Remove items with smallest marginal gain in least critical objective\n        obj1_ratio = objectives[selected_idx, 0] / (ideal_point[0] + 1e-10)\n        obj2_ratio = objectives[selected_idx, 1] / (ideal_point[1] + 1e-10)\n        least_critical = 1 if obj1_ratio < obj2_ratio else 2\n\n        if least_critical == 1:\n            removal_candidates = included_items[np.argsort(marginal_gain1[included_items])]\n        else:\n            removal_candidates = included_items[np.argsort(marginal_gain2[included_items])]\n\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects the solution with the highest hypervolume contribution from the archive, then applies a hybrid local search combining marginal-gain-based flips with an objective-balanced mechanism that prioritizes items with high combined marginal gains and balanced trade-offs between objectives. It dynamically scales the number of random flips based on the solution's distance to the ideal point and ensures feasibility through a trade-off-aware removal process that eliminates items with the poorest trade-offs between objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    selected_idx = np.argmax(hypervolume)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Objective-balanced flipping mechanism\n    trade_off = value2_lst / (value1_lst + 1e-10)\n    combined_score = (marginal_gain1 + marginal_gain2) * (1 + 0.5 * np.abs(trade_off - np.mean(trade_off)))\n    sorted_indices = np.argsort(combined_score)[::-1]\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (scaled by distance to ideal point)\n    distance_to_ideal = np.linalg.norm(ideal_point - objectives[selected_idx])\n    n_random_flips = max(1, int(5 * (1 / (distance_to_ideal + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Trade-off-aware feasibility restoration\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with poorest trade-off\n        item_trade_off = value2_lst[removable_items] / (value1_lst[removable_items] + 1e-10)\n        avg_trade_off = np.mean(item_trade_off)\n        remove_idx = removable_items[np.argmax(np.abs(item_trade_off - avg_trade_off))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects top-performing solutions from the archive (30% with highest weighted objective scores) and generates neighbors by prioritizing items with high combined normalized gains (70% value1, 30% value2, minus weight penalty), followed by 2-3 strategic flips that balance inclusion/exclusion based on value-weight ratios, with iterative feasibility checks to ensure weight constraints are met. It emphasizes value-driven selection while strategically adjusting the knapsack contents to maintain balance between objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        weighted_scores = 0.6 * (obj1_scores / max_obj1) + 0.4 * (obj2_scores / max_obj2)\n        top_indices = np.argsort(weighted_scores)[-max(1, len(archive) // 3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate normalized marginal gains\n    norm_value1 = value1_lst / np.max(value1_lst)\n    norm_value2 = value2_lst / np.max(value2_lst)\n    norm_weight = weight_lst / np.max(weight_lst)\n    combined_gain = 0.7 * norm_value1 + 0.3 * norm_value2 - 0.5 * norm_weight\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    # Prioritize high-gain flips\n    for idx in sorted_indices[:min(8, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add 2-3 strategic flips\n    for _ in range(np.random.randint(2, 4)):\n        # Balance between including light valuable items and excluding heavy ones\n        if np.random.random() < 0.7:\n            # Prefer including items with high value/weight ratio\n            candidates = np.where(base_solution == 0)[0]\n            if len(candidates) > 0:\n                candidate_idx = candidates[np.argmax(value1_lst[candidates] / (weight_lst[candidates] + 1e-10))]\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n        else:\n            # Prefer excluding heavy items\n            candidates = np.where(base_solution == 1)[0]\n            if len(candidates) > 0:\n                candidate_idx = candidates[np.argmax(weight_lst[candidates])]\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove items with lowest value/weight ratio\n        ratios = value1_lst[removable_items] / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(ratios)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s a concise yet impactful heuristic design for the BI-KP:\n\n### **Refined Heuristic Design for BI-KP**\n- **Keywords**: **Hypervolume contribution, knee-point detection, trade-off-aware flipping, adaptive perturbation, feasibility-aware repair.**\n- **Advice**:\n  1. **Select** top 20% solutions by hypervolume contribution, prioritizing knee-points.\n  2. **Flip** items with highest marginal gains in either objective, then add **1-2 trade-off-aware flips** (ensuring feasibility).\n  3. **Repair** infeasible neighbors by removing items with smallest marginal gain in the least critical objective.\n  4. **Iterate** 5-10 times per solution to refine the archive.\n- **Avoid**: **Overly aggressive flipping** or **pure randomness**; ignore feasibility checks after perturbations.\n- **Explanation**: **Balances exploitation (knee-point selection) and exploration (trade-off-aware flips) while ensuring feasibility. Dominance-aware repairs prevent stagnation, and iterative refinement yields high-quality neighbors efficiently.**\n\n*(Word count: ~50)*\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 161,
        "algorithm": "The algorithm selects a knee-point solution from the archive (balancing both objectives) and applies a two-phase flip strategy: first flipping high-marginal-gain items (Phase 1) and then strategically flipping trade-off-aware items (Phase 2), while dynamically adjusting flips based on solution quality. It uses trade-off-aware repair to maintain feasibility by removing items with the smallest marginal gain in the least critical objective. The method also includes adaptive perturbations to escape local optima, prioritizing items with high combined marginal gains and balanced trade-offs.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select knee-point solution (min distance to ideal point in normalized space)\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    normalized_obj = objectives / ideal_point\n    distances = np.linalg.norm(normalized_obj - 1, axis=1)\n    selected_idx = np.argmin(distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Phase 1: Flip high-marginal-gain items\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Phase 2: Flip trade-off-aware items\n    trade_off = value2_lst / (value1_lst + 1e-10)\n    balanced_score = (marginal_gain1 + marginal_gain2) * (1 - np.abs(trade_off - np.mean(trade_off)))\n    sorted_indices = np.argsort(balanced_score)[::-1]\n    for idx in sorted_indices[:min(3, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Adaptive perturbation (flip 1-2 random items if solution is not near ideal)\n    if np.sum(new_solution * weight_lst) < capacity * 0.9:\n        for _ in range(np.random.randint(1, 3)):\n            candidate_idx = np.random.randint(len(weight_lst))\n            if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n            elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Trade-off-aware repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest marginal gain in least critical objective\n        least_critical_obj = 0 if objectives[selected_idx][0] < objectives[selected_idx][1] else 1\n        if least_critical_obj == 0:\n            ratios = value1_lst[removable_items] / (weight_lst[removable_items] + 1e-10)\n        else:\n            ratios = value2_lst[removable_items] / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(ratios)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9136413684771605,
            0.27015262842178345
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select knee-point solution (min distance to ideal point in normalized space)\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    normalized_obj = objectives / ideal_point\n    distances = np.linalg.norm(normalized_obj - 1, axis=1)\n    selected_idx = np.argmin(distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Phase 1: Flip high-marginal-gain items\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Phase 2: Flip trade-off-aware items\n    trade_off = value2_lst / (value1_lst + 1e-10)\n    balanced_score = (marginal_gain1 + marginal_gain2) * (1 - np.abs(trade_off - np.mean(trade_off)))\n    sorted_indices = np.argsort(balanced_score)[::-1]\n    for idx in sorted_indices[:min(3, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Adaptive perturbation (flip 1-2 random items if solution is not near ideal)\n    if np.sum(new_solution * weight_lst) < capacity * 0.9:\n        for _ in range(np.random.randint(1, 3)):\n            candidate_idx = np.random.randint(len(weight_lst))\n            if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n            elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n\n    # Trade-off-aware repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest marginal gain in least critical objective\n        least_critical_obj = 0 if objectives[selected_idx][0] < objectives[selected_idx][1] else 1\n        if least_critical_obj == 0:\n            ratios = value1_lst[removable_items] / (weight_lst[removable_items] + 1e-10)\n        else:\n            ratios = value2_lst[removable_items] / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(ratios)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive based on combined objective scores, then performs a targeted local search by flipping high-marginal-gain items prioritizing the least dominated objective, followed by controlled random perturbations and adaptive feasibility repairs to ensure capacity constraints are met while maintaining solution diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by combined objective score\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        combined_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(combined_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains and dominance information\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Identify items that improve the least dominated objective\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    # Targeted flipping of high-marginal-gain items prioritizing least dominated objective\n    if least_dominated == 1:\n        target_gain = marginal_gain1\n    else:\n        target_gain = marginal_gain2\n\n    high_gain_indices = np.argsort(target_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation of low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined marginal gain\n        removal_candidates = included_items[np.argsort(combined_gain[included_items])]\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects top-performing solutions from the archive (30% with highest weighted objective scores) and generates neighbors by prioritizing items with high combined normalized gains (70% value1, 30% value2, minus weight penalty), followed by 2-3 strategic flips that balance inclusion/exclusion based on value-weight ratios, with iterative feasibility checks to ensure weight constraints are met. It emphasizes value-driven selection while strategically adjusting the knapsack contents to maintain balance between objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        weighted_scores = 0.6 * (obj1_scores / max_obj1) + 0.4 * (obj2_scores / max_obj2)\n        top_indices = np.argsort(weighted_scores)[-max(1, len(archive) // 3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate normalized marginal gains\n    norm_value1 = value1_lst / np.max(value1_lst)\n    norm_value2 = value2_lst / np.max(value2_lst)\n    norm_weight = weight_lst / np.max(weight_lst)\n    combined_gain = 0.7 * norm_value1 + 0.3 * norm_value2 - 0.5 * norm_weight\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    # Prioritize high-gain flips\n    for idx in sorted_indices[:min(8, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add 2-3 strategic flips\n    for _ in range(np.random.randint(2, 4)):\n        # Balance between including light valuable items and excluding heavy ones\n        if np.random.random() < 0.7:\n            # Prefer including items with high value/weight ratio\n            candidates = np.where(base_solution == 0)[0]\n            if len(candidates) > 0:\n                candidate_idx = candidates[np.argmax(value1_lst[candidates] / (weight_lst[candidates] + 1e-10))]\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n        else:\n            # Prefer excluding heavy items\n            candidates = np.where(base_solution == 1)[0]\n            if len(candidates) > 0:\n                candidate_idx = candidates[np.argmax(weight_lst[candidates])]\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove items with lowest value/weight ratio\n        ratios = value1_lst[removable_items] / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(ratios)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s a concise yet impactful heuristic design for the BI-KP:\n\n### **Refined Heuristic Design for BI-KP**\n- **Keywords**: **Hypervolume contribution, knee-point detection, trade-off-aware flipping, adaptive perturbation, feasibility-aware repair.**\n- **Advice**:\n  1. **Select** top 20% solutions by hypervolume contribution, prioritizing knee-points.\n  2. **Flip** items with highest marginal gains in either objective, then add **1-2 trade-off-aware flips** (ensuring feasibility).\n  3. **Repair** infeasible neighbors by removing items with smallest marginal gain in the least critical objective.\n  4. **Iterate** 5-10 times per solution to refine the archive.\n- **Avoid**: **Overly aggressive flipping** or **pure randomness**; ignore feasibility checks after perturbations.\n- **Explanation**: **Balances exploitation (knee-point selection) and exploration (trade-off-aware flips) while ensuring feasibility. Dominance-aware repairs prevent stagnation, and iterative refinement yields high-quality neighbors efficiently.**\n\n*(Word count: ~50)*\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 162,
        "algorithm": "The algorithm selects a high-potential solution from the archive (prioritizing those with maximum hypervolume contribution) and performs a two-phase local search: first flipping items with highest marginal gains in either objective while maintaining feasibility, followed by trade-off-aware flips that balance inclusion/exclusion based on value-weight ratios, with iterative feasibility checks to ensure the solution remains valid. The method emphasizes objective-specific gains in Phase 1 and value-to-weight trade-offs in Phase 2, while dynamically adjusting removals when capacity is exceeded.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with maximum hypervolume contribution\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Calculate hypervolume contribution (simplified)\n        hv_contributions = (obj1_scores / max_obj1) * (obj2_scores / max_obj2)\n        selected_idx = np.argmax(hv_contributions)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Phase 1: Flip items with highest marginal gains in either objective\n    for _ in range(2):\n        if np.random.rand() < 0.7:\n            target_gain = marginal_gain1\n        else:\n            target_gain = marginal_gain2\n\n        best_idx = np.argmax(target_gain * (1 - base_solution))\n        if base_solution[best_idx] == 0 and current_weight + weight_lst[best_idx] <= capacity:\n            new_solution[best_idx] = 1\n            current_weight += weight_lst[best_idx]\n\n    # Phase 2: Trade-off-aware flips (balance inclusion/exclusion)\n    for _ in range(2):\n        if np.random.rand() < 0.6:\n            # Prefer including light valuable items\n            candidates = np.where(base_solution == 0)[0]\n            if len(candidates) > 0:\n                candidate_idx = candidates[np.argmax(value1_lst[candidates] / (weight_lst[candidates] + 1e-10))]\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n        else:\n            # Prefer excluding heavy items\n            candidates = np.where(base_solution == 1)[0]\n            if len(candidates) > 0:\n                candidate_idx = candidates[np.argmax(weight_lst[candidates])]\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n\n    # Iterative feasibility check and repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n\n        # Remove items with smallest marginal gain in least critical objective\n        if np.sum(new_solution * value1_lst) < np.sum(new_solution * value2_lst):\n            ratios = marginal_gain1[removable_items]\n        else:\n            ratios = marginal_gain2[removable_items]\n\n        remove_idx = removable_items[np.argmin(ratios)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.34880851341976615,
            2.952974706888199
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with maximum hypervolume contribution\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Calculate hypervolume contribution (simplified)\n        hv_contributions = (obj1_scores / max_obj1) * (obj2_scores / max_obj2)\n        selected_idx = np.argmax(hv_contributions)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Phase 1: Flip items with highest marginal gains in either objective\n    for _ in range(2):\n        if np.random.rand() < 0.7:\n            target_gain = marginal_gain1\n        else:\n            target_gain = marginal_gain2\n\n        best_idx = np.argmax(target_gain * (1 - base_solution))\n        if base_solution[best_idx] == 0 and current_weight + weight_lst[best_idx] <= capacity:\n            new_solution[best_idx] = 1\n            current_weight += weight_lst[best_idx]\n\n    # Phase 2: Trade-off-aware flips (balance inclusion/exclusion)\n    for _ in range(2):\n        if np.random.rand() < 0.6:\n            # Prefer including light valuable items\n            candidates = np.where(base_solution == 0)[0]\n            if len(candidates) > 0:\n                candidate_idx = candidates[np.argmax(value1_lst[candidates] / (weight_lst[candidates] + 1e-10))]\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n        else:\n            # Prefer excluding heavy items\n            candidates = np.where(base_solution == 1)[0]\n            if len(candidates) > 0:\n                candidate_idx = candidates[np.argmax(weight_lst[candidates])]\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n\n    # Iterative feasibility check and repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n\n        # Remove items with smallest marginal gain in least critical objective\n        if np.sum(new_solution * value1_lst) < np.sum(new_solution * value2_lst):\n            ratios = marginal_gain1[removable_items]\n        else:\n            ratios = marginal_gain2[removable_items]\n\n        remove_idx = removable_items[np.argmin(ratios)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects top-performing solutions from the archive (30% with highest weighted objective scores) and generates neighbors by prioritizing items with high combined normalized gains (70% value1, 30% value2, minus weight penalty), followed by 2-3 strategic flips that balance inclusion/exclusion based on value-weight ratios, with iterative feasibility checks to ensure weight constraints are met. It emphasizes value-driven selection while strategically adjusting the knapsack contents to maintain balance between objectives.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        weighted_scores = 0.6 * (obj1_scores / max_obj1) + 0.4 * (obj2_scores / max_obj2)\n        top_indices = np.argsort(weighted_scores)[-max(1, len(archive) // 3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate normalized marginal gains\n    norm_value1 = value1_lst / np.max(value1_lst)\n    norm_value2 = value2_lst / np.max(value2_lst)\n    norm_weight = weight_lst / np.max(weight_lst)\n    combined_gain = 0.7 * norm_value1 + 0.3 * norm_value2 - 0.5 * norm_weight\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    # Prioritize high-gain flips\n    for idx in sorted_indices[:min(8, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add 2-3 strategic flips\n    for _ in range(np.random.randint(2, 4)):\n        # Balance between including light valuable items and excluding heavy ones\n        if np.random.random() < 0.7:\n            # Prefer including items with high value/weight ratio\n            candidates = np.where(base_solution == 0)[0]\n            if len(candidates) > 0:\n                candidate_idx = candidates[np.argmax(value1_lst[candidates] / (weight_lst[candidates] + 1e-10))]\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n        else:\n            # Prefer excluding heavy items\n            candidates = np.where(base_solution == 1)[0]\n            if len(candidates) > 0:\n                candidate_idx = candidates[np.argmax(weight_lst[candidates])]\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove items with lowest value/weight ratio\n        ratios = value1_lst[removable_items] / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(ratios)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 163,
        "algorithm": "The algorithm selects high-performing solutions (top 20% by hypervolume contribution) from the archive and generates neighbors by first flipping high-gain items (prioritizing 60% value1, 40% value2, and weight penalty), then applying a value-weighted random walk (with probabilities adjusted by normalized values), followed by iterative feasibility checks to remove low-value/weight items if capacity is exceeded.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Calculate hypervolume contribution (simplified)\n        normalized_scores = np.column_stack([obj1_scores/max_obj1, obj2_scores/max_obj2])\n        hv_contributions = np.zeros(len(archive))\n        for i in range(len(archive)):\n            dominated = np.all(normalized_scores >= normalized_scores[i], axis=1)\n            dominated = dominated & (normalized_scores != normalized_scores[i]).any(axis=1)\n            if np.any(dominated):\n                hv_contributions[i] = np.min(normalized_scores[dominated, 0] * normalized_scores[dominated, 1])\n            else:\n                hv_contributions[i] = normalized_scores[i, 0] * normalized_scores[i, 1]\n        top_indices = np.argsort(hv_contributions)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate normalized marginal gains\n    norm_value1 = value1_lst / np.max(value1_lst)\n    norm_value2 = value2_lst / np.max(value2_lst)\n    norm_weight = weight_lst / np.max(weight_lst)\n    combined_gain = 0.6 * norm_value1 + 0.4 * norm_value2 - 0.6 * norm_weight\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    # Prioritize high-gain flips\n    for idx in sorted_indices[:min(10, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Value-weighted random walk\n    prob_include = 0.5 + 0.5 * (0.6 * norm_value1 + 0.4 * norm_value2)\n    for idx in range(n_items):\n        if np.random.random() < prob_include[idx] and base_solution[idx] == 0:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n        elif np.random.random() < (1 - prob_include[idx]) and base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove items with lowest combined value/weight ratio\n        ratios = (0.6 * value1_lst[removable_items] + 0.4 * value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(ratios)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.36331671595400783,
            0.8798203766345978
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Calculate hypervolume contribution (simplified)\n        normalized_scores = np.column_stack([obj1_scores/max_obj1, obj2_scores/max_obj2])\n        hv_contributions = np.zeros(len(archive))\n        for i in range(len(archive)):\n            dominated = np.all(normalized_scores >= normalized_scores[i], axis=1)\n            dominated = dominated & (normalized_scores != normalized_scores[i]).any(axis=1)\n            if np.any(dominated):\n                hv_contributions[i] = np.min(normalized_scores[dominated, 0] * normalized_scores[dominated, 1])\n            else:\n                hv_contributions[i] = normalized_scores[i, 0] * normalized_scores[i, 1]\n        top_indices = np.argsort(hv_contributions)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate normalized marginal gains\n    norm_value1 = value1_lst / np.max(value1_lst)\n    norm_value2 = value2_lst / np.max(value2_lst)\n    norm_weight = weight_lst / np.max(weight_lst)\n    combined_gain = 0.6 * norm_value1 + 0.4 * norm_value2 - 0.6 * norm_weight\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    # Prioritize high-gain flips\n    for idx in sorted_indices[:min(10, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Value-weighted random walk\n    prob_include = 0.5 + 0.5 * (0.6 * norm_value1 + 0.4 * norm_value2)\n    for idx in range(n_items):\n        if np.random.random() < prob_include[idx] and base_solution[idx] == 0:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n        elif np.random.random() < (1 - prob_include[idx]) and base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove items with lowest combined value/weight ratio\n        ratios = (0.6 * value1_lst[removable_items] + 0.4 * value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(ratios)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects top-performing solutions from the archive (30% with highest weighted objective scores) and generates neighbors by prioritizing items with high combined normalized gains (70% value1, 30% value2, minus weight penalty), followed by 2-3 strategic flips that balance inclusion/exclusion based on value-weight ratios, with iterative feasibility checks to ensure weight constraints are met. It emphasizes value-driven selection while strategically adjusting the knapsack contents to maintain balance between objectives.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        weighted_scores = 0.6 * (obj1_scores / max_obj1) + 0.4 * (obj2_scores / max_obj2)\n        top_indices = np.argsort(weighted_scores)[-max(1, len(archive) // 3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate normalized marginal gains\n    norm_value1 = value1_lst / np.max(value1_lst)\n    norm_value2 = value2_lst / np.max(value2_lst)\n    norm_weight = weight_lst / np.max(weight_lst)\n    combined_gain = 0.7 * norm_value1 + 0.3 * norm_value2 - 0.5 * norm_weight\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    # Prioritize high-gain flips\n    for idx in sorted_indices[:min(8, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add 2-3 strategic flips\n    for _ in range(np.random.randint(2, 4)):\n        # Balance between including light valuable items and excluding heavy ones\n        if np.random.random() < 0.7:\n            # Prefer including items with high value/weight ratio\n            candidates = np.where(base_solution == 0)[0]\n            if len(candidates) > 0:\n                candidate_idx = candidates[np.argmax(value1_lst[candidates] / (weight_lst[candidates] + 1e-10))]\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n        else:\n            # Prefer excluding heavy items\n            candidates = np.where(base_solution == 1)[0]\n            if len(candidates) > 0:\n                candidate_idx = candidates[np.argmax(weight_lst[candidates])]\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove items with lowest value/weight ratio\n        ratios = value1_lst[removable_items] / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(ratios)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 164,
        "algorithm": "The algorithm selects promising solutions from the top 20% of the archive (based on a 50-50 weighted sum of normalized objectives), then generates neighbors by prioritizing high-value-to-weight-ratio items (60% weight on value1, 40% on value2) and performing 3-5 strategic flips (60% chance to add high-value items, 40% to remove low-value items), while ensuring feasibility through iterative weight checks and removal of least valuable items if capacity is exceeded.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by combined objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        combined_scores = 0.5 * (obj1_scores / max_obj1) + 0.5 * (obj2_scores / max_obj2)\n        top_indices = np.argsort(combined_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate normalized value-to-weight ratios\n    norm_value1 = value1_lst / np.max(value1_lst)\n    norm_value2 = value2_lst / np.max(value2_lst)\n    norm_weight = weight_lst / np.max(weight_lst)\n    value_weight_ratio = (0.6 * norm_value1 + 0.4 * norm_value2) / (norm_weight + 1e-10)\n    sorted_indices = np.argsort(value_weight_ratio)[::-1]\n\n    # Prioritize high-ratio flips\n    for idx in sorted_indices[:min(10, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add 3-5 strategic flips\n    for _ in range(np.random.randint(3, 6)):\n        # Balance between adding high-value items and removing low-value items\n        if np.random.random() < 0.6:\n            # Add high-value items\n            candidates = np.where(base_solution == 0)[0]\n            if len(candidates) > 0:\n                candidate_idx = candidates[np.argmax(value1_lst[candidates] / (weight_lst[candidates] + 1e-10))]\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n        else:\n            # Remove low-value items\n            candidates = np.where(base_solution == 1)[0]\n            if len(candidates) > 0:\n                candidate_idx = candidates[np.argmin(value1_lst[candidates] / (weight_lst[candidates] + 1e-10))]\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove items with lowest value/weight ratio\n        ratios = value1_lst[removable_items] / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(ratios)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.7949495664474622,
            0.32558634877204895
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by combined objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        combined_scores = 0.5 * (obj1_scores / max_obj1) + 0.5 * (obj2_scores / max_obj2)\n        top_indices = np.argsort(combined_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate normalized value-to-weight ratios\n    norm_value1 = value1_lst / np.max(value1_lst)\n    norm_value2 = value2_lst / np.max(value2_lst)\n    norm_weight = weight_lst / np.max(weight_lst)\n    value_weight_ratio = (0.6 * norm_value1 + 0.4 * norm_value2) / (norm_weight + 1e-10)\n    sorted_indices = np.argsort(value_weight_ratio)[::-1]\n\n    # Prioritize high-ratio flips\n    for idx in sorted_indices[:min(10, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add 3-5 strategic flips\n    for _ in range(np.random.randint(3, 6)):\n        # Balance between adding high-value items and removing low-value items\n        if np.random.random() < 0.6:\n            # Add high-value items\n            candidates = np.where(base_solution == 0)[0]\n            if len(candidates) > 0:\n                candidate_idx = candidates[np.argmax(value1_lst[candidates] / (weight_lst[candidates] + 1e-10))]\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n        else:\n            # Remove low-value items\n            candidates = np.where(base_solution == 1)[0]\n            if len(candidates) > 0:\n                candidate_idx = candidates[np.argmin(value1_lst[candidates] / (weight_lst[candidates] + 1e-10))]\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove items with lowest value/weight ratio\n        ratios = value1_lst[removable_items] / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(ratios)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 4 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects top-performing solutions from the archive (30% with highest weighted objective scores) and generates neighbors by prioritizing items with high combined normalized gains (70% value1, 30% value2, minus weight penalty), followed by 2-3 strategic flips that balance inclusion/exclusion based on value-weight ratios, with iterative feasibility checks to ensure weight constraints are met. It emphasizes value-driven selection while strategically adjusting the knapsack contents to maintain balance between objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        weighted_scores = 0.6 * (obj1_scores / max_obj1) + 0.4 * (obj2_scores / max_obj2)\n        top_indices = np.argsort(weighted_scores)[-max(1, len(archive) // 3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate normalized marginal gains\n    norm_value1 = value1_lst / np.max(value1_lst)\n    norm_value2 = value2_lst / np.max(value2_lst)\n    norm_weight = weight_lst / np.max(weight_lst)\n    combined_gain = 0.7 * norm_value1 + 0.3 * norm_value2 - 0.5 * norm_weight\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    # Prioritize high-gain flips\n    for idx in sorted_indices[:min(8, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add 2-3 strategic flips\n    for _ in range(np.random.randint(2, 4)):\n        # Balance between including light valuable items and excluding heavy ones\n        if np.random.random() < 0.7:\n            # Prefer including items with high value/weight ratio\n            candidates = np.where(base_solution == 0)[0]\n            if len(candidates) > 0:\n                candidate_idx = candidates[np.argmax(value1_lst[candidates] / (weight_lst[candidates] + 1e-10))]\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n        else:\n            # Prefer excluding heavy items\n            candidates = np.where(base_solution == 1)[0]\n            if len(candidates) > 0:\n                candidate_idx = candidates[np.argmax(weight_lst[candidates])]\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove items with lowest value/weight ratio\n        ratios = value1_lst[removable_items] / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(ratios)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive (based on normalized objective sums) and generates neighbors by flipping items with high marginal gains for both objectives, followed by 1-2 random feasible flips, while ensuring feasibility through iterative refinement by removing the lightest items when needed. It prioritizes items with combined high marginal gains for both objectives while maintaining diversity through random flips.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain-based flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add 1-2 random feasible flips\n    for _ in range(np.random.randint(1, 3)):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s a concise yet impactful heuristic design for the BI-KP:\n\n### **Refined Heuristic Design for BI-KP**\n- **Keywords**: **Hypervolume contribution, knee-point detection, trade-off-aware flipping, adaptive perturbation, feasibility-aware repair.**\n- **Advice**:\n  1. **Select** top 20% solutions by hypervolume contribution, prioritizing knee-points.\n  2. **Flip** items with highest marginal gains in either objective, then add **1-2 trade-off-aware flips** (ensuring feasibility).\n  3. **Repair** infeasible neighbors by removing items with smallest marginal gain in the least critical objective.\n  4. **Iterate** 5-10 times per solution to refine the archive.\n- **Avoid**: **Overly aggressive flipping** or **pure randomness**; ignore feasibility checks after perturbations.\n- **Explanation**: **Balances exploitation (knee-point selection) and exploration (trade-off-aware flips) while ensuring feasibility. Dominance-aware repairs prevent stagnation, and iterative refinement yields high-quality neighbors efficiently.**\n\n*(Word count: ~50)*\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 165,
        "algorithm": "The algorithm selects high-potential solutions from the archive (top 20% prioritizing knee-points) and applies a multi-stage local search: first flipping items with highest marginal gains, then performing trade-off-aware flips (favoring high-value/weight items and removing heavy ones), repairing infeasible solutions by removing least critical items, and finally adding random perturbations to escape local optima. The method balances exploitation (targeted flips) and exploration (random perturbations) while ensuring feasibility through iterative checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution (simplified as knee-point prioritization)\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Approximate knee-point selection (simplified)\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        sorted_indices = np.argsort(normalized_scores)\n        knee_idx = len(sorted_indices) // 2  # Approximate knee-point\n        top_indices = sorted_indices[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices) if knee_idx in top_indices else top_indices[0]\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted flips: highest marginal gains in either objective\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Trade-off-aware flips: include high value/weight items, exclude heavy ones\n    value_weight_ratio = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n    for _ in range(np.random.randint(1, 3)):\n        if np.random.random() < 0.7:\n            # Include high value/weight item\n            candidates = np.where(base_solution == 0)[0]\n            if len(candidates) > 0:\n                candidate_idx = candidates[np.argmax(value_weight_ratio[candidates])]\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n        else:\n            # Exclude heavy item\n            candidates = np.where(base_solution == 1)[0]\n            if len(candidates) > 0:\n                candidate_idx = candidates[np.argmax(weight_lst[candidates])]\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n\n    # Repair infeasible solutions\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove items with smallest marginal gain in least critical objective\n        least_critical_obj = obj1_scores[selected_idx] if max_obj1 > max_obj2 else obj2_scores[selected_idx]\n        if least_critical_obj == max_obj1:\n            ratios = value1_lst[removable_items] / (weight_lst[removable_items] + 1e-10)\n        else:\n            ratios = value2_lst[removable_items] / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(ratios)]\n        new_solution[remove_idx] = 0\n\n    # Random perturbations for exploration\n    if np.random.rand() < 0.3:\n        marginal_contribution = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        low_contrib_indices = np.argsort(marginal_contribution)[:min(3, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8885501894205173,
            0.2407403290271759
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution (simplified as knee-point prioritization)\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Approximate knee-point selection (simplified)\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        sorted_indices = np.argsort(normalized_scores)\n        knee_idx = len(sorted_indices) // 2  # Approximate knee-point\n        top_indices = sorted_indices[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices) if knee_idx in top_indices else top_indices[0]\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted flips: highest marginal gains in either objective\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Trade-off-aware flips: include high value/weight items, exclude heavy ones\n    value_weight_ratio = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n    for _ in range(np.random.randint(1, 3)):\n        if np.random.random() < 0.7:\n            # Include high value/weight item\n            candidates = np.where(base_solution == 0)[0]\n            if len(candidates) > 0:\n                candidate_idx = candidates[np.argmax(value_weight_ratio[candidates])]\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n        else:\n            # Exclude heavy item\n            candidates = np.where(base_solution == 1)[0]\n            if len(candidates) > 0:\n                candidate_idx = candidates[np.argmax(weight_lst[candidates])]\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n\n    # Repair infeasible solutions\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove items with smallest marginal gain in least critical objective\n        least_critical_obj = obj1_scores[selected_idx] if max_obj1 > max_obj2 else obj2_scores[selected_idx]\n        if least_critical_obj == max_obj1:\n            ratios = value1_lst[removable_items] / (weight_lst[removable_items] + 1e-10)\n        else:\n            ratios = value2_lst[removable_items] / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(ratios)]\n        new_solution[remove_idx] = 0\n\n    # Random perturbations for exploration\n    if np.random.rand() < 0.3:\n        marginal_contribution = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        low_contrib_indices = np.argsort(marginal_contribution)[:min(3, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 6 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects the solution with the highest hypervolume contribution from the archive, then applies a hybrid local search combining marginal-gain-based flips with an objective-balanced mechanism that prioritizes items with high combined marginal gains and balanced trade-offs between objectives. It dynamically scales the number of random flips based on the solution's distance to the ideal point and ensures feasibility through a trade-off-aware removal process that eliminates items with the poorest trade-offs between objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    selected_idx = np.argmax(hypervolume)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Objective-balanced flipping mechanism\n    trade_off = value2_lst / (value1_lst + 1e-10)\n    combined_score = (marginal_gain1 + marginal_gain2) * (1 + 0.5 * np.abs(trade_off - np.mean(trade_off)))\n    sorted_indices = np.argsort(combined_score)[::-1]\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (scaled by distance to ideal point)\n    distance_to_ideal = np.linalg.norm(ideal_point - objectives[selected_idx])\n    n_random_flips = max(1, int(5 * (1 / (distance_to_ideal + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Trade-off-aware feasibility restoration\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with poorest trade-off\n        item_trade_off = value2_lst[removable_items] / (value1_lst[removable_items] + 1e-10)\n        avg_trade_off = np.mean(item_trade_off)\n        remove_idx = removable_items[np.argmax(np.abs(item_trade_off - avg_trade_off))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from the bottom 30% of the archive (based on normalized objective sums) and applies a targeted local search by prioritizing flips of low-marginal-gain items (based on value-to-weight ratios), followed by 2-3 random flips to escape local optima while ensuring feasibility through iterative refinement. The method balances exploitation (focused flips) with exploration (random flips) to improve solution quality.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select bottom 30% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        bottom_indices = np.argsort(normalized_scores)[:max(1, len(archive)//3)]\n        selected_idx = np.random.choice(bottom_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with low marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in low_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 2-3 random flips to escape local optima\n    num_random_flips = np.random.randint(2, 4)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 6 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive based on hypervolume contribution, then performs a targeted local search by flipping high-marginal-gain items while ensuring feasibility, followed by adaptive perturbation of low-contribution items to escape local optima. It balances exploitation (hypervolume-aware selection and high-gain flips) with exploration (adaptive perturbation and random flips) through iterative refinement and feasibility-aware repair. The selection prioritizes solutions with better hypervolume, while the local search intelligently modifies the solution by combining dominance-aware flipping, adaptive perturbation, and iterative refinement to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    def hypervolume(sol):\n        obj1, obj2 = sol[1]\n        return obj1 * obj2\n\n    hypervolumes = [hypervolume(sol) for sol in archive]\n    top_indices = np.argsort(hypervolumes)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:min(3, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: repair infeasible solutions\n    for _ in range(5):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s the refined heuristic design for the BI-KP in your requested format:\n\n### **Refined Heuristic Design for BI-KP**\n- **Keywords**: **Hypervolume contribution, knee-point detection, trade-off-aware flipping, adaptive perturbation, feasibility-aware repair.**\n- **Advice**: Select top 20% solutions by hypervolume, prioritize knee-points; flip items with highest marginal gains in either objective, then add 1-2 trade-off-aware flips; repair infeasible neighbors by removing least critical items; iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness; ignore feasibility checks after perturbations.\n- **Explanation**: Balances exploitation (knee-point selection) and exploration (trade-off-aware flips) while ensuring feasibility. Dominance-aware repairs prevent stagnation, and iterative refinement yields high-quality neighbors efficiently.\n\n*(Word count: ~50)*\n\n**Why this works**:\n1. **Hypervolume + knee-point selection** ensures diversity and trade-off awareness.\n2. **Marginal gain + trade-off flips** prioritize items that improve either objective.\n3. **Adaptive perturbation** avoids premature convergence.\n4. **Feasibility-aware repair** guarantees valid neighbors.\n\nThis heuristic avoids pitfalls while leveraging multi-objective insights.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 166,
        "algorithm": "The algorithm starts by selecting the knee-point solution from the archive (using hypervolume and distance to the ideal point), then performs targeted flips of items with high marginal gains in either objective while maintaining feasibility, followed by 1-2 trade-off-aware flips to balance objectives, and finally repairs infeasible solutions by removing low-contribution items. The selection prioritizes knee-point solutions for exploration, while the flips focus on high-marginal-gain and trade-off items, ensuring feasibility through a repair mechanism.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select knee-point solution (hypervolume + knee-point detection)\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n\n    # Identify knee-point (solution with minimal distance to ideal point)\n    distances = np.linalg.norm(objectives - ideal_point, axis=1)\n    knee_idx = np.argmin(distances)\n    base_solution = archive[knee_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted flips: highest marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Trade-off-aware flips (1-2 items)\n    trade_off = value2_lst / (value1_lst + 1e-10)\n    sorted_trade_off = np.argsort(np.abs(trade_off - np.mean(trade_off)))[::-1]\n    n_trade_off_flips = np.random.randint(1, 3)\n\n    for idx in sorted_trade_off[:n_trade_off_flips]:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Feasibility repair (remove low-contribution items)\n    while np.sum(new_solution * weight_lst) > capacity:\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with lowest marginal contribution\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        remove_idx = removable_items[np.argmin(marginal_contribution[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8412873171618761,
            0.24623659253120422
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select knee-point solution (hypervolume + knee-point detection)\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n\n    # Identify knee-point (solution with minimal distance to ideal point)\n    distances = np.linalg.norm(objectives - ideal_point, axis=1)\n    knee_idx = np.argmin(distances)\n    base_solution = archive[knee_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted flips: highest marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Trade-off-aware flips (1-2 items)\n    trade_off = value2_lst / (value1_lst + 1e-10)\n    sorted_trade_off = np.argsort(np.abs(trade_off - np.mean(trade_off)))[::-1]\n    n_trade_off_flips = np.random.randint(1, 3)\n\n    for idx in sorted_trade_off[:n_trade_off_flips]:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Feasibility repair (remove low-contribution items)\n    while np.sum(new_solution * weight_lst) > capacity:\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with lowest marginal contribution\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        remove_idx = removable_items[np.argmin(marginal_contribution[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP in your requested format:\n\n### **Refined Heuristic Design for BI-KP**\n- **Keywords**: **Hypervolume contribution, knee-point detection, trade-off-aware flipping, adaptive perturbation, feasibility-aware repair.**\n- **Advice**: Select top 20% solutions by hypervolume, prioritize knee-points; flip items with highest marginal gains in either objective, then add 1-2 trade-off-aware flips; repair infeasible neighbors by removing least critical items; iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness; ignore feasibility checks after perturbations.\n- **Explanation**: Balances exploitation (knee-point selection) and exploration (trade-off-aware flips) while ensuring feasibility. Dominance-aware repairs prevent stagnation, and iterative refinement yields high-quality neighbors efficiently.\n\n*(Word count: ~50)*\n\n**Why this works**:\n1. **Hypervolume + knee-point selection** ensures diversity and trade-off awareness.\n2. **Marginal gain + trade-off flips** prioritize items that improve either objective.\n3. **Adaptive perturbation** avoids premature convergence.\n4. **Feasibility-aware repair** guarantees valid neighbors.\n\nThis heuristic avoids pitfalls while leveraging multi-objective insights.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 167,
        "algorithm": "The algorithm combines hypervolume-based selection of top 20% solutions with knee-point prioritization, then performs a three-phase local search: first flipping high-marginal-gain items, then strategically adding 1-2 trade-off-aware flips, and finally repairing infeasible solutions by removing least-critical items, while using adaptive perturbation to escape local optima. It prioritizes items with higher marginal gains for both objectives and strategically balances trade-offs between objectives, ensuring feasibility through iterative repair and dominance-aware neighbor generation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hypervolume-based selection of top 20% solutions\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = objectives.max(axis=0)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0] / max_obj1 + objectives[:, 1] / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Flip items with highest marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Add 1-2 trade-off-aware flips\n    trade_off_indices = np.argsort(np.abs(marginal_gain1 - marginal_gain2))[:min(2, len(weight_lst))]\n    for idx in trade_off_indices:\n        if np.random.rand() < 0.4:  # 40% chance to flip\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Phase 3: Repair infeasible solutions\n    if current_weight > capacity:\n        criticality = value1_lst + value2_lst  # Combined criticality\n        sorted_indices = np.argsort(criticality)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and current_weight > capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Adaptive perturbation\n    if np.random.rand() < 0.3:  # 30% chance to perturb\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if np.random.rand() < 0.5:  # 50% chance to flip each low-gain item\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7415888069524514,
            0.2225016951560974
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hypervolume-based selection of top 20% solutions\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = objectives.max(axis=0)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0] / max_obj1 + objectives[:, 1] / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Flip items with highest marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Add 1-2 trade-off-aware flips\n    trade_off_indices = np.argsort(np.abs(marginal_gain1 - marginal_gain2))[:min(2, len(weight_lst))]\n    for idx in trade_off_indices:\n        if np.random.rand() < 0.4:  # 40% chance to flip\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Phase 3: Repair infeasible solutions\n    if current_weight > capacity:\n        criticality = value1_lst + value2_lst  # Combined criticality\n        sorted_indices = np.argsort(criticality)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and current_weight > capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Adaptive perturbation\n    if np.random.rand() < 0.3:  # 30% chance to perturb\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if np.random.rand() < 0.5:  # 50% chance to flip each low-gain item\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects from the top 20% of non-dominated solutions (weighted equally on normalized objectives) and performs a local search by flipping high-gain items (60% prioritizing value1, 40% prioritizing value2) while occasionally perturbing low-gain items (30% probability) to balance exploration and exploitation, always ensuring feasibility.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by equally weighted normalized objectives\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.5 * obj[0]/max_obj1 + 0.5 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Local search: flip items with highest combined gain (60% value1, 40% value2)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.6 * marginal_gain1 + 0.4 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-gain items with 30% probability\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive based on hypervolume contribution, then performs a targeted local search by flipping high-marginal-gain items while ensuring feasibility, followed by adaptive perturbation of low-contribution items to escape local optima. It balances exploitation (hypervolume-aware selection and high-gain flips) with exploration (adaptive perturbation and random flips) through iterative refinement and feasibility-aware repair. The selection prioritizes solutions with better hypervolume, while the local search intelligently modifies the solution by combining dominance-aware flipping, adaptive perturbation, and iterative refinement to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    def hypervolume(sol):\n        obj1, obj2 = sol[1]\n        return obj1 * obj2\n\n    hypervolumes = [hypervolume(sol) for sol in archive]\n    top_indices = np.argsort(hypervolumes)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:min(3, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: repair infeasible solutions\n    for _ in range(5):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP in your requested format:\n\n### **Refined Heuristic Design for BI-KP**\n- **Keywords**: **Hypervolume contribution, knee-point detection, trade-off-aware flipping, adaptive perturbation, feasibility-aware repair.**\n- **Advice**: Select top 20% solutions by hypervolume, prioritize knee-points; flip items with highest marginal gains in either objective, then add 1-2 trade-off-aware flips; repair infeasible neighbors by removing least critical items; iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness; ignore feasibility checks after perturbations.\n- **Explanation**: Balances exploitation (knee-point selection) and exploration (trade-off-aware flips) while ensuring feasibility. Dominance-aware repairs prevent stagnation, and iterative refinement yields high-quality neighbors efficiently.\n\n*(Word count: ~50)*\n\n**Why this works**:\n1. **Hypervolume + knee-point selection** ensures diversity and trade-off awareness.\n2. **Marginal gain + trade-off flips** prioritize items that improve either objective.\n3. **Adaptive perturbation** avoids premature convergence.\n4. **Feasibility-aware repair** guarantees valid neighbors.\n\nThis heuristic avoids pitfalls while leveraging multi-objective insights.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 168,
        "algorithm": "The algorithm combines hypervolume-based selection with knee-point prioritization to identify promising solutions, then performs a two-phase local search: first flipping high-marginal-gain items while ensuring feasibility, followed by a trade-off-aware perturbation near the Pareto front with adaptive repair. It prioritizes knee-point solutions (with significant trade-offs) over top hypervolume solutions, and uses marginal gains and Pareto front proximity to guide neighborhood generation while maintaining feasibility through iterative repair.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select knee-point solutions if available, otherwise top 20% by hypervolume\n    def hypervolume(sol):\n        obj1, obj2 = sol[1]\n        return obj1 * obj2\n\n    hypervolumes = [hypervolume(sol) for sol in archive]\n    sorted_indices = np.argsort(hypervolumes)\n    top_indices = sorted_indices[-max(1, len(archive) // 5):]\n\n    # Identify knee points (solutions with largest angle between neighbors)\n    knee_indices = []\n    for i in range(1, len(sorted_indices)-1):\n        prev, curr, next = archive[sorted_indices[i-1]][1], archive[sorted_indices[i]][1], archive[sorted_indices[i+1]][1]\n        angle = np.arctan2(curr[1] - prev[1], curr[0] - prev[0]) - np.arctan2(next[1] - curr[1], next[0] - curr[0])\n        if angle > np.pi/4:  # Threshold for knee points\n            knee_indices.append(sorted_indices[i])\n\n    if knee_indices:\n        selected_idx = np.random.choice(knee_indices)\n    else:\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Flip items with highest marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Trade-off-aware perturbation near Pareto front\n    if np.random.rand() < 0.4:\n        # Select items near the Pareto front (high value1 but lower value2 or vice versa)\n        pareto_front = []\n        for i in range(len(archive)):\n            dominated = False\n            for j in range(len(archive)):\n                if i != j and archive[j][1][0] >= archive[i][1][0] and archive[j][1][1] >= archive[i][1][1]:\n                    dominated = True\n                    break\n            if not dominated:\n                pareto_front.append(i)\n\n        if pareto_front:\n            front_solutions = [archive[i][0] for i in pareto_front]\n            front_items = np.any(front_solutions, axis=0)\n            candidate_indices = np.where(front_items)[0]\n\n            if len(candidate_indices) > 0:\n                perturb_idx = np.random.choice(candidate_indices)\n                if base_solution[perturb_idx] == 1 and current_weight - weight_lst[perturb_idx] <= capacity:\n                    new_solution[perturb_idx] = 0\n                elif base_solution[perturb_idx] == 0 and current_weight + weight_lst[perturb_idx] <= capacity:\n                    new_solution[perturb_idx] = 1\n\n    # Feasibility repair\n    for _ in range(5):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.7963228836989574,
            2.417489230632782
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select knee-point solutions if available, otherwise top 20% by hypervolume\n    def hypervolume(sol):\n        obj1, obj2 = sol[1]\n        return obj1 * obj2\n\n    hypervolumes = [hypervolume(sol) for sol in archive]\n    sorted_indices = np.argsort(hypervolumes)\n    top_indices = sorted_indices[-max(1, len(archive) // 5):]\n\n    # Identify knee points (solutions with largest angle between neighbors)\n    knee_indices = []\n    for i in range(1, len(sorted_indices)-1):\n        prev, curr, next = archive[sorted_indices[i-1]][1], archive[sorted_indices[i]][1], archive[sorted_indices[i+1]][1]\n        angle = np.arctan2(curr[1] - prev[1], curr[0] - prev[0]) - np.arctan2(next[1] - curr[1], next[0] - curr[0])\n        if angle > np.pi/4:  # Threshold for knee points\n            knee_indices.append(sorted_indices[i])\n\n    if knee_indices:\n        selected_idx = np.random.choice(knee_indices)\n    else:\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Flip items with highest marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Trade-off-aware perturbation near Pareto front\n    if np.random.rand() < 0.4:\n        # Select items near the Pareto front (high value1 but lower value2 or vice versa)\n        pareto_front = []\n        for i in range(len(archive)):\n            dominated = False\n            for j in range(len(archive)):\n                if i != j and archive[j][1][0] >= archive[i][1][0] and archive[j][1][1] >= archive[i][1][1]:\n                    dominated = True\n                    break\n            if not dominated:\n                pareto_front.append(i)\n\n        if pareto_front:\n            front_solutions = [archive[i][0] for i in pareto_front]\n            front_items = np.any(front_solutions, axis=0)\n            candidate_indices = np.where(front_items)[0]\n\n            if len(candidate_indices) > 0:\n                perturb_idx = np.random.choice(candidate_indices)\n                if base_solution[perturb_idx] == 1 and current_weight - weight_lst[perturb_idx] <= capacity:\n                    new_solution[perturb_idx] = 0\n                elif base_solution[perturb_idx] == 0 and current_weight + weight_lst[perturb_idx] <= capacity:\n                    new_solution[perturb_idx] = 1\n\n    # Feasibility repair\n    for _ in range(5):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive based on combined objective scores, then performs a targeted local search by flipping high-marginal-gain items prioritizing the least dominated objective, followed by controlled random perturbations and adaptive feasibility repairs to ensure capacity constraints are met while maintaining solution diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by combined objective score\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        combined_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(combined_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains and dominance information\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Identify items that improve the least dominated objective\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    # Targeted flipping of high-marginal-gain items prioritizing least dominated objective\n    if least_dominated == 1:\n        target_gain = marginal_gain1\n    else:\n        target_gain = marginal_gain2\n\n    high_gain_indices = np.argsort(target_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation of low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined marginal gain\n        removal_candidates = included_items[np.argsort(combined_gain[included_items])]\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive based on hypervolume contribution, then performs a targeted local search by flipping high-marginal-gain items while ensuring feasibility, followed by adaptive perturbation of low-contribution items to escape local optima. It balances exploitation (hypervolume-aware selection and high-gain flips) with exploration (adaptive perturbation and random flips) through iterative refinement and feasibility-aware repair. The selection prioritizes solutions with better hypervolume, while the local search intelligently modifies the solution by combining dominance-aware flipping, adaptive perturbation, and iterative refinement to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    def hypervolume(sol):\n        obj1, obj2 = sol[1]\n        return obj1 * obj2\n\n    hypervolumes = [hypervolume(sol) for sol in archive]\n    top_indices = np.argsort(hypervolumes)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:min(3, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: repair infeasible solutions\n    for _ in range(5):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP in your requested format:\n\n### **Refined Heuristic Design for BI-KP**\n- **Keywords**: **Hypervolume contribution, knee-point detection, trade-off-aware flipping, adaptive perturbation, feasibility-aware repair.**\n- **Advice**: Select top 20% solutions by hypervolume, prioritize knee-points; flip items with highest marginal gains in either objective, then add 1-2 trade-off-aware flips; repair infeasible neighbors by removing least critical items; iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness; ignore feasibility checks after perturbations.\n- **Explanation**: Balances exploitation (knee-point selection) and exploration (trade-off-aware flips) while ensuring feasibility. Dominance-aware repairs prevent stagnation, and iterative refinement yields high-quality neighbors efficiently.\n\n*(Word count: ~50)*\n\n**Why this works**:\n1. **Hypervolume + knee-point selection** ensures diversity and trade-off awareness.\n2. **Marginal gain + trade-off flips** prioritize items that improve either objective.\n3. **Adaptive perturbation** avoids premature convergence.\n4. **Feasibility-aware repair** guarantees valid neighbors.\n\nThis heuristic avoids pitfalls while leveraging multi-objective insights.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 169,
        "algorithm": "The algorithm selects a knee-point solution from the Pareto front (balancing trade-offs between objectives) and applies a hybrid local search combining dominance-aware flipping (prioritizing items that improve the underrepresented objective) and diversity-aware perturbations (flipping items in underrepresented regions of the objective space), while ensuring feasibility through iterative removal of least critical items. The method intelligently balances exploration and exploitation by focusing on high-gain items and adaptive perturbations, with feasibility enforced by iterative weight adjustments.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select knee-point solution (balancing trade-offs)\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_obj1 = obj1_scores / max_obj1\n        normalized_obj2 = obj2_scores / max_obj2\n        distances = np.sqrt((1 - normalized_obj1)**2 + (1 - normalized_obj2)**2)\n        selected_idx = np.argmin(distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dominance-aware flipping (prioritize underrepresented objective)\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    if least_dominated == 1:\n        target_gain = value1_lst / (weight_lst + 1e-10)\n    else:\n        target_gain = value2_lst / (weight_lst + 1e-10)\n\n    high_gain_indices = np.argsort(target_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Diversity-aware perturbations (flip items in underrepresented regions)\n    if np.random.rand() < 0.3:\n        obj1_covered = np.sum(new_solution * value1_lst)\n        obj2_covered = np.sum(new_solution * value2_lst)\n        if obj1_covered < obj2_covered:\n            candidate_indices = np.where((value1_lst > value2_lst) & (new_solution == 0))[0]\n        else:\n            candidate_indices = np.where((value2_lst > value1_lst) & (new_solution == 0))[0]\n\n        if len(candidate_indices) > 0:\n            selected_idx = np.random.choice(candidate_indices)\n            if current_weight + weight_lst[selected_idx] <= capacity:\n                new_solution[selected_idx] = 1\n                current_weight += weight_lst[selected_idx]\n\n    # Iterative feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined marginal gain\n        combined_gain = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        remove_idx = included_items[np.argmin(combined_gain[included_items])]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9657298600122048,
            0.20827093720436096
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select knee-point solution (balancing trade-offs)\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_obj1 = obj1_scores / max_obj1\n        normalized_obj2 = obj2_scores / max_obj2\n        distances = np.sqrt((1 - normalized_obj1)**2 + (1 - normalized_obj2)**2)\n        selected_idx = np.argmin(distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dominance-aware flipping (prioritize underrepresented objective)\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    if least_dominated == 1:\n        target_gain = value1_lst / (weight_lst + 1e-10)\n    else:\n        target_gain = value2_lst / (weight_lst + 1e-10)\n\n    high_gain_indices = np.argsort(target_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Diversity-aware perturbations (flip items in underrepresented regions)\n    if np.random.rand() < 0.3:\n        obj1_covered = np.sum(new_solution * value1_lst)\n        obj2_covered = np.sum(new_solution * value2_lst)\n        if obj1_covered < obj2_covered:\n            candidate_indices = np.where((value1_lst > value2_lst) & (new_solution == 0))[0]\n        else:\n            candidate_indices = np.where((value2_lst > value1_lst) & (new_solution == 0))[0]\n\n        if len(candidate_indices) > 0:\n            selected_idx = np.random.choice(candidate_indices)\n            if current_weight + weight_lst[selected_idx] <= capacity:\n                new_solution[selected_idx] = 1\n                current_weight += weight_lst[selected_idx]\n\n    # Iterative feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined marginal gain\n        combined_gain = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        remove_idx = included_items[np.argmin(combined_gain[included_items])]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive based on combined objective scores, then performs a targeted local search by flipping high-marginal-gain items prioritizing the least dominated objective, followed by controlled random perturbations and adaptive feasibility repairs to ensure capacity constraints are met while maintaining solution diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by combined objective score\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        combined_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(combined_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains and dominance information\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Identify items that improve the least dominated objective\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    # Targeted flipping of high-marginal-gain items prioritizing least dominated objective\n    if least_dominated == 1:\n        target_gain = marginal_gain1\n    else:\n        target_gain = marginal_gain2\n\n    high_gain_indices = np.argsort(target_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation of low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined marginal gain\n        removal_candidates = included_items[np.argsort(combined_gain[included_items])]\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive based on hypervolume contribution, then performs a targeted local search by flipping high-marginal-gain items while ensuring feasibility, followed by adaptive perturbation of low-contribution items to escape local optima. It balances exploitation (hypervolume-aware selection and high-gain flips) with exploration (adaptive perturbation and random flips) through iterative refinement and feasibility-aware repair. The selection prioritizes solutions with better hypervolume, while the local search intelligently modifies the solution by combining dominance-aware flipping, adaptive perturbation, and iterative refinement to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    def hypervolume(sol):\n        obj1, obj2 = sol[1]\n        return obj1 * obj2\n\n    hypervolumes = [hypervolume(sol) for sol in archive]\n    top_indices = np.argsort(hypervolumes)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:min(3, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: repair infeasible solutions\n    for _ in range(5):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP in your requested format:\n\n### **Refined Heuristic Design for BI-KP**\n- **Keywords**: **Hypervolume contribution, knee-point detection, trade-off-aware flipping, adaptive perturbation, feasibility-aware repair.**\n- **Advice**: Select top 20% solutions by hypervolume, prioritize knee-points; flip items with highest marginal gains in either objective, then add 1-2 trade-off-aware flips; repair infeasible neighbors by removing least critical items; iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness; ignore feasibility checks after perturbations.\n- **Explanation**: Balances exploitation (knee-point selection) and exploration (trade-off-aware flips) while ensuring feasibility. Dominance-aware repairs prevent stagnation, and iterative refinement yields high-quality neighbors efficiently.\n\n*(Word count: ~50)*\n\n**Why this works**:\n1. **Hypervolume + knee-point selection** ensures diversity and trade-off awareness.\n2. **Marginal gain + trade-off flips** prioritize items that improve either objective.\n3. **Adaptive perturbation** avoids premature convergence.\n4. **Feasibility-aware repair** guarantees valid neighbors.\n\nThis heuristic avoids pitfalls while leveraging multi-objective insights.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 169,
        "algorithm": "The algorithm selects a knee-point solution from the Pareto front (balancing trade-offs between objectives) and applies a hybrid local search combining dominance-aware flipping (prioritizing items that improve the underrepresented objective) and diversity-aware perturbations (flipping items in underrepresented regions of the objective space), while ensuring feasibility through iterative removal of least critical items. The method intelligently balances exploration and exploitation by focusing on high-gain items and adaptive perturbations, with feasibility enforced by iterative weight adjustments.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select knee-point solution (balancing trade-offs)\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_obj1 = obj1_scores / max_obj1\n        normalized_obj2 = obj2_scores / max_obj2\n        distances = np.sqrt((1 - normalized_obj1)**2 + (1 - normalized_obj2)**2)\n        selected_idx = np.argmin(distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dominance-aware flipping (prioritize underrepresented objective)\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    if least_dominated == 1:\n        target_gain = value1_lst / (weight_lst + 1e-10)\n    else:\n        target_gain = value2_lst / (weight_lst + 1e-10)\n\n    high_gain_indices = np.argsort(target_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Diversity-aware perturbations (flip items in underrepresented regions)\n    if np.random.rand() < 0.3:\n        obj1_covered = np.sum(new_solution * value1_lst)\n        obj2_covered = np.sum(new_solution * value2_lst)\n        if obj1_covered < obj2_covered:\n            candidate_indices = np.where((value1_lst > value2_lst) & (new_solution == 0))[0]\n        else:\n            candidate_indices = np.where((value2_lst > value1_lst) & (new_solution == 0))[0]\n\n        if len(candidate_indices) > 0:\n            selected_idx = np.random.choice(candidate_indices)\n            if current_weight + weight_lst[selected_idx] <= capacity:\n                new_solution[selected_idx] = 1\n                current_weight += weight_lst[selected_idx]\n\n    # Iterative feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined marginal gain\n        combined_gain = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        remove_idx = included_items[np.argmin(combined_gain[included_items])]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9657298600122048,
            0.20827093720436096
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select knee-point solution (balancing trade-offs)\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_obj1 = obj1_scores / max_obj1\n        normalized_obj2 = obj2_scores / max_obj2\n        distances = np.sqrt((1 - normalized_obj1)**2 + (1 - normalized_obj2)**2)\n        selected_idx = np.argmin(distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dominance-aware flipping (prioritize underrepresented objective)\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    if least_dominated == 1:\n        target_gain = value1_lst / (weight_lst + 1e-10)\n    else:\n        target_gain = value2_lst / (weight_lst + 1e-10)\n\n    high_gain_indices = np.argsort(target_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Diversity-aware perturbations (flip items in underrepresented regions)\n    if np.random.rand() < 0.3:\n        obj1_covered = np.sum(new_solution * value1_lst)\n        obj2_covered = np.sum(new_solution * value2_lst)\n        if obj1_covered < obj2_covered:\n            candidate_indices = np.where((value1_lst > value2_lst) & (new_solution == 0))[0]\n        else:\n            candidate_indices = np.where((value2_lst > value1_lst) & (new_solution == 0))[0]\n\n        if len(candidate_indices) > 0:\n            selected_idx = np.random.choice(candidate_indices)\n            if current_weight + weight_lst[selected_idx] <= capacity:\n                new_solution[selected_idx] = 1\n                current_weight += weight_lst[selected_idx]\n\n    # Iterative feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined marginal gain\n        combined_gain = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        remove_idx = included_items[np.argmin(combined_gain[included_items])]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects promising solutions from the top 20% of the archive based on hypervolume contribution, then performs a targeted local search by flipping high-marginal-gain items while ensuring feasibility, followed by adaptive perturbation of low-contribution items to escape local optima. It balances exploitation (hypervolume-aware selection and high-gain flips) with exploration (adaptive perturbation and random flips) through iterative refinement and feasibility-aware repair. The selection prioritizes solutions with better hypervolume, while the local search intelligently modifies the solution by combining dominance-aware flipping, adaptive perturbation, and iterative refinement to improve both objectives.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    def hypervolume(sol):\n        obj1, obj2 = sol[1]\n        return obj1 * obj2\n\n    hypervolumes = [hypervolume(sol) for sol in archive]\n    top_indices = np.argsort(hypervolumes)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:min(3, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: repair infeasible solutions\n    for _ in range(5):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 170,
        "algorithm": "The algorithm selects high-potential solutions from the archive based on hypervolume and diversity, then performs a two-phase local search: first improving both objectives through correlated flips (prioritizing items with high combined value-weight ratio), followed by adaptive diversification (flipping low-contribution items with probability-based flips), while ensuring feasibility through capacity-aware repairs. The selection prioritizes solutions with high hypervolume and diversity, while the local search phase 1 focuses on correlated flips for positive correlation and minimal impact for negative correlation, and phase 2 introduces probabilistic diversification to escape local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solutions with high hypervolume and diversity\n    def hypervolume(sol):\n        obj1, obj2 = sol[1]\n        return obj1 * obj2\n\n    hypervolumes = [hypervolume(sol) for sol in archive]\n    diversity_scores = [np.sum(np.abs(sol[0] - archive[i][0])) for i, sol in enumerate(archive)]\n    combined_scores = [hv + 0.5 * div for hv, div in zip(hypervolumes, diversity_scores)]\n    top_indices = np.argsort(combined_scores)[-max(1, len(archive) // 4):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Correlated flips for both objectives\n    correlation = np.corrcoef(value1_lst, value2_lst)[0, 1]\n    if correlation > 0.3:\n        # Positive correlation: flip items that improve both objectives\n        combined_gain = (value1_lst + value2_lst) / weight_lst\n        high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n    else:\n        # Negative correlation: flip items that improve one objective while minimally affecting the other\n        for idx in range(len(weight_lst)):\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Phase 2: Adaptive diversification\n    if np.random.rand() < 0.4:\n        # Flip low-contribution items with probability based on their contribution\n        contribution = (value1_lst + value2_lst) / weight_lst\n        flip_prob = 1 / (1 + np.exp(-contribution))\n        for idx in range(len(weight_lst)):\n            if np.random.rand() < flip_prob[idx] * 0.2:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Feasibility repair\n    for _ in range(3):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.45848226559513894,
            0.6053535640239716
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solutions with high hypervolume and diversity\n    def hypervolume(sol):\n        obj1, obj2 = sol[1]\n        return obj1 * obj2\n\n    hypervolumes = [hypervolume(sol) for sol in archive]\n    diversity_scores = [np.sum(np.abs(sol[0] - archive[i][0])) for i, sol in enumerate(archive)]\n    combined_scores = [hv + 0.5 * div for hv, div in zip(hypervolumes, diversity_scores)]\n    top_indices = np.argsort(combined_scores)[-max(1, len(archive) // 4):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Correlated flips for both objectives\n    correlation = np.corrcoef(value1_lst, value2_lst)[0, 1]\n    if correlation > 0.3:\n        # Positive correlation: flip items that improve both objectives\n        combined_gain = (value1_lst + value2_lst) / weight_lst\n        high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n        for idx in high_gain_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n    else:\n        # Negative correlation: flip items that improve one objective while minimally affecting the other\n        for idx in range(len(weight_lst)):\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Phase 2: Adaptive diversification\n    if np.random.rand() < 0.4:\n        # Flip low-contribution items with probability based on their contribution\n        contribution = (value1_lst + value2_lst) / weight_lst\n        flip_prob = 1 / (1 + np.exp(-contribution))\n        for idx in range(len(weight_lst)):\n            if np.random.rand() < flip_prob[idx] * 0.2:\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Feasibility repair\n    for _ in range(3):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects promising solutions from the top 20% of the archive based on hypervolume contribution, then performs a targeted local search by flipping high-marginal-gain items while ensuring feasibility, followed by adaptive perturbation of low-contribution items to escape local optima. It balances exploitation (hypervolume-aware selection and high-gain flips) with exploration (adaptive perturbation and random flips) through iterative refinement and feasibility-aware repair. The selection prioritizes solutions with better hypervolume, while the local search intelligently modifies the solution by combining dominance-aware flipping, adaptive perturbation, and iterative refinement to improve both objectives.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    def hypervolume(sol):\n        obj1, obj2 = sol[1]\n        return obj1 * obj2\n\n    hypervolumes = [hypervolume(sol) for sol in archive]\n    top_indices = np.argsort(hypervolumes)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:min(3, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: repair infeasible solutions\n    for _ in range(5):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 171,
        "algorithm": "This heuristic selects high-performing solutions from the top 30% of the archive, prioritizes flipping high-marginal-gain items, probabilistically perturbs low-contribution items, and aggressively refines the solution by greedily removing least valuable items to ensure feasibility. The algorithm balances exploration (via probabilistic perturbations) with exploitation (via dominance-aware flips) while maintaining strict feasibility constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by combined objective score\n    def combined_score(sol):\n        obj1, obj2 = sol[1]\n        return obj1 + obj2\n\n    scores = [combined_score(sol) for sol in archive]\n    top_indices = np.argsort(scores)[-max(1, len(archive) // 3):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dominance-aware local search: flip items with high marginal gains\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(10, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Probabilistic perturbation: higher probability for low-contribution items\n    if np.random.rand() < 0.5:\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:min(5, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Aggressive iterative refinement: greedy removal of items\n    for _ in range(10):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin((value1_lst + value2_lst)[removable_items] / weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8244904566005473,
            0.20643413066864014
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by combined objective score\n    def combined_score(sol):\n        obj1, obj2 = sol[1]\n        return obj1 + obj2\n\n    scores = [combined_score(sol) for sol in archive]\n    top_indices = np.argsort(scores)[-max(1, len(archive) // 3):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dominance-aware local search: flip items with high marginal gains\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(10, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Probabilistic perturbation: higher probability for low-contribution items\n    if np.random.rand() < 0.5:\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:min(5, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Aggressive iterative refinement: greedy removal of items\n    for _ in range(10):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin((value1_lst + value2_lst)[removable_items] / weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 5 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive based on hypervolume contribution, then performs a targeted local search by flipping high-marginal-gain items while ensuring feasibility, followed by adaptive perturbation of low-contribution items to escape local optima. It balances exploitation (hypervolume-aware selection and high-gain flips) with exploration (adaptive perturbation and random flips) through iterative refinement and feasibility-aware repair. The selection prioritizes solutions with better hypervolume, while the local search intelligently modifies the solution by combining dominance-aware flipping, adaptive perturbation, and iterative refinement to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    def hypervolume(sol):\n        obj1, obj2 = sol[1]\n        return obj1 * obj2\n\n    hypervolumes = [hypervolume(sol) for sol in archive]\n    top_indices = np.argsort(hypervolumes)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:min(3, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: repair infeasible solutions\n    for _ in range(5):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive (based on normalized objective sums) and applies a targeted local search by prioritizing flips of high-marginal-gain items, followed by 1-2 random flips to escape local optima, while ensuring feasibility through iterative refinement. High-marginal-gain items (based on value-to-weight ratios) are given higher priority, and the algorithm balances exploitation (focused flips) with exploration (random flips) to improve solution quality.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips to escape local optima\n    num_random_flips = np.random.randint(1, 3)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive (based on normalized objective sums) and generates neighbors by flipping items with high marginal gains for both objectives, followed by 1-2 random feasible flips, while ensuring feasibility through iterative refinement by removing the lightest items when needed. It prioritizes items with combined high marginal gains for both objectives while maintaining diversity through random flips.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain-based flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add 1-2 random feasible flips\n    for _ in range(np.random.randint(1, 3)):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP in your requested format:\n\n### **Refined Heuristic Design for BI-KP**\n- **Keywords**: **Hypervolume contribution, knee-point detection, trade-off-aware flipping, adaptive perturbation, feasibility-aware repair.**\n- **Advice**: Select top 20% solutions by hypervolume, prioritize knee-points; flip items with highest marginal gains in either objective, then add 1-2 trade-off-aware flips; repair infeasible neighbors by removing least critical items; iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness; ignore feasibility checks after perturbations.\n- **Explanation**: Balances exploitation (knee-point selection) and exploration (trade-off-aware flips) while ensuring feasibility. Dominance-aware repairs prevent stagnation, and iterative refinement yields high-quality neighbors efficiently.\n\n*(Word count: ~50)*\n\n**Why this works**:\n1. **Hypervolume + knee-point selection** ensures diversity and trade-off awareness.\n2. **Marginal gain + trade-off flips** prioritize items that improve either objective.\n3. **Adaptive perturbation** avoids premature convergence.\n4. **Feasibility-aware repair** guarantees valid neighbors.\n\nThis heuristic avoids pitfalls while leveraging multi-objective insights.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 172,
        "algorithm": "The algorithm selects promising solutions from the archive (top 20% by hypervolume contribution) and performs a targeted local search by flipping items with high marginal gains in either objective, followed by trade-off-aware flips to balance both objectives, while ensuring feasibility through iterative refinement and occasional adaptive perturbations. It prioritizes items with the highest combined marginal gain for exploitation and occasionally perturbs low-contribution items for exploration, iterating 5-10 times per solution for refinement.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    def hypervolume(sol):\n        obj1, obj2 = sol[1]\n        return obj1 * obj2\n\n    hypervolumes = [hypervolume(sol) for sol in archive]\n    top_indices = np.argsort(hypervolumes)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Identify knee-points for trade-off awareness\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        knee_indices = np.arange(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        knee_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 10):]\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Trade-off-aware flips (1-2 flips balancing both objectives)\n    num_tradeoff_flips = np.random.randint(1, 3)\n    tradeoff_indices = np.argsort(-np.abs(marginal_gain1 - marginal_gain2))[:min(5, len(weight_lst))]\n    for idx in tradeoff_indices[:num_tradeoff_flips]:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive perturbation (30% chance)\n    if np.random.rand() < 0.3:\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:min(3, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement (5-10 times)\n    for _ in range(np.random.randint(5, 11)):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.7931904979822395,
            0.25972098112106323
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    def hypervolume(sol):\n        obj1, obj2 = sol[1]\n        return obj1 * obj2\n\n    hypervolumes = [hypervolume(sol) for sol in archive]\n    top_indices = np.argsort(hypervolumes)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Identify knee-points for trade-off awareness\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        knee_indices = np.arange(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        knee_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 10):]\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Trade-off-aware flips (1-2 flips balancing both objectives)\n    num_tradeoff_flips = np.random.randint(1, 3)\n    tradeoff_indices = np.argsort(-np.abs(marginal_gain1 - marginal_gain2))[:min(5, len(weight_lst))]\n    for idx in tradeoff_indices[:num_tradeoff_flips]:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive perturbation (30% chance)\n    if np.random.rand() < 0.3:\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:min(3, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement (5-10 times)\n    for _ in range(np.random.randint(5, 11)):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 6 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects the solution with the highest hypervolume contribution from the archive, then applies a hybrid local search combining marginal-gain-based flips with an objective-balanced mechanism that prioritizes items with high combined marginal gains and balanced trade-offs between objectives. It dynamically scales the number of random flips based on the solution's distance to the ideal point and ensures feasibility through a trade-off-aware removal process that eliminates items with the poorest trade-offs between objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    selected_idx = np.argmax(hypervolume)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Objective-balanced flipping mechanism\n    trade_off = value2_lst / (value1_lst + 1e-10)\n    combined_score = (marginal_gain1 + marginal_gain2) * (1 + 0.5 * np.abs(trade_off - np.mean(trade_off)))\n    sorted_indices = np.argsort(combined_score)[::-1]\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (scaled by distance to ideal point)\n    distance_to_ideal = np.linalg.norm(ideal_point - objectives[selected_idx])\n    n_random_flips = max(1, int(5 * (1 / (distance_to_ideal + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Trade-off-aware feasibility restoration\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with poorest trade-off\n        item_trade_off = value2_lst[removable_items] / (value1_lst[removable_items] + 1e-10)\n        avg_trade_off = np.mean(item_trade_off)\n        remove_idx = removable_items[np.argmax(np.abs(item_trade_off - avg_trade_off))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from the bottom 30% of the archive (based on normalized objective sums) and applies a targeted local search by prioritizing flips of low-marginal-gain items (based on value-to-weight ratios), followed by 2-3 random flips to escape local optima while ensuring feasibility through iterative refinement. The method balances exploitation (focused flips) with exploration (random flips) to improve solution quality.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select bottom 30% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        bottom_indices = np.argsort(normalized_scores)[:max(1, len(archive)//3)]\n        selected_idx = np.random.choice(bottom_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with low marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in low_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 2-3 random flips to escape local optima\n    num_random_flips = np.random.randint(2, 4)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 6 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive based on hypervolume contribution, then performs a targeted local search by flipping high-marginal-gain items while ensuring feasibility, followed by adaptive perturbation of low-contribution items to escape local optima. It balances exploitation (hypervolume-aware selection and high-gain flips) with exploration (adaptive perturbation and random flips) through iterative refinement and feasibility-aware repair. The selection prioritizes solutions with better hypervolume, while the local search intelligently modifies the solution by combining dominance-aware flipping, adaptive perturbation, and iterative refinement to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    def hypervolume(sol):\n        obj1, obj2 = sol[1]\n        return obj1 * obj2\n\n    hypervolumes = [hypervolume(sol) for sol in archive]\n    top_indices = np.argsort(hypervolumes)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:min(3, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: repair infeasible solutions\n    for _ in range(5):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s the ultra-refined heuristic design (under 100 words):\n\n- **Keywords**: **Hypervolume, knee-point selection, marginal gain flips, adaptive perturbation, feasibility repair**\n- **Advice**: Select top 20% solutions by hypervolume, prioritize knee-points; flip items with highest marginal gains in either objective, then add 1-2 random flips; repair infeasible neighbors by removing least critical items; iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness; ignore feasibility checks after perturbations.\n- **Explanation**: Balances exploitation (knee-point selection) and exploration (marginal gain flips) while ensuring feasibility. Dominance-aware repairs prevent stagnation, and iterative refinement yields high-quality neighbors efficiently.\n\n*(Word count: ~50)*\n\n**Why this works**:\n1. **Hypervolume + knee-point selection** ensures diversity and trade-off awareness.\n2. **Marginal gain + trade-off flips** prioritize items that improve either objective.\n3. **Adaptive perturbation** avoids premature convergence.\n4. **Feasibility-aware repair** guarantees valid neighbors.\n\nThis heuristic avoids pitfalls while leveraging multi-objective insights.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 173,
        "algorithm": "The algorithm selects knee-point solutions from the archive based on hypervolume contribution, then applies targeted flips of high-marginal-gain items in either objective, followed by 1-2 random flips to escape local optima, while ensuring feasibility through iterative repair by removing the least critical items. It prioritizes items with balanced gains in both objectives and uses marginal contributions to guide the repair process.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select knee-point solutions by hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    knee_indices = np.argsort(hypervolume)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(knee_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Targeted flips: prioritize items with high marginal gains in either objective\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Adaptive perturbation: 1-2 random flips\n    num_random_flips = np.random.randint(1, 3)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative repair: remove least critical items if infeasible\n    for _ in range(5):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with lowest marginal contribution to either objective\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        remove_idx = removable_items[np.argmin(marginal_contribution[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9295302772384724,
            0.2204917073249817
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select knee-point solutions by hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    knee_indices = np.argsort(hypervolume)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(knee_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Targeted flips: prioritize items with high marginal gains in either objective\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Adaptive perturbation: 1-2 random flips\n    num_random_flips = np.random.randint(1, 3)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative repair: remove least critical items if infeasible\n    for _ in range(5):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with lowest marginal contribution to either objective\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        remove_idx = removable_items[np.argmin(marginal_contribution[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive based on combined objective scores, then performs a targeted local search by flipping high-marginal-gain items prioritizing the least dominated objective, followed by controlled random perturbations and adaptive feasibility repairs to ensure capacity constraints are met while maintaining solution diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by combined objective score\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        combined_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(combined_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains and dominance information\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Identify items that improve the least dominated objective\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    # Targeted flipping of high-marginal-gain items prioritizing least dominated objective\n    if least_dominated == 1:\n        target_gain = marginal_gain1\n    else:\n        target_gain = marginal_gain2\n\n    high_gain_indices = np.argsort(target_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation of low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined marginal gain\n        removal_candidates = included_items[np.argsort(combined_gain[included_items])]\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm combines hypervolume-based selection of top 20% solutions with knee-point prioritization, then performs a three-phase local search: first flipping high-marginal-gain items, then strategically adding 1-2 trade-off-aware flips, and finally repairing infeasible solutions by removing least-critical items, while using adaptive perturbation to escape local optima. It prioritizes items with higher marginal gains for both objectives and strategically balances trade-offs between objectives, ensuring feasibility through iterative repair and dominance-aware neighbor generation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hypervolume-based selection of top 20% solutions\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = objectives.max(axis=0)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0] / max_obj1 + objectives[:, 1] / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Flip items with highest marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Add 1-2 trade-off-aware flips\n    trade_off_indices = np.argsort(np.abs(marginal_gain1 - marginal_gain2))[:min(2, len(weight_lst))]\n    for idx in trade_off_indices:\n        if np.random.rand() < 0.4:  # 40% chance to flip\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Phase 3: Repair infeasible solutions\n    if current_weight > capacity:\n        criticality = value1_lst + value2_lst  # Combined criticality\n        sorted_indices = np.argsort(criticality)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and current_weight > capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Adaptive perturbation\n    if np.random.rand() < 0.3:  # 30% chance to perturb\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if np.random.rand() < 0.5:  # 50% chance to flip each low-gain item\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the ultra-refined heuristic design (under 100 words):\n\n- **Keywords**: **Hypervolume, knee-point selection, marginal gain flips, adaptive perturbation, feasibility repair**\n- **Advice**: Select top 20% solutions by hypervolume, prioritize knee-points; flip items with highest marginal gains in either objective, then add 1-2 random flips; repair infeasible neighbors by removing least critical items; iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness; ignore feasibility checks after perturbations.\n- **Explanation**: Balances exploitation (knee-point selection) and exploration (marginal gain flips) while ensuring feasibility. Dominance-aware repairs prevent stagnation, and iterative refinement yields high-quality neighbors efficiently.\n\n*(Word count: ~50)*\n\n**Why this works**:\n1. **Hypervolume + knee-point selection** ensures diversity and trade-off awareness.\n2. **Marginal gain + trade-off flips** prioritize items that improve either objective.\n3. **Adaptive perturbation** avoids premature convergence.\n4. **Feasibility-aware repair** guarantees valid neighbors.\n\nThis heuristic avoids pitfalls while leveraging multi-objective insights.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 174,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = objectives.max(axis=0)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0] / max_obj1 + objectives[:, 1] / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate dominance-aware marginal gains\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Phase 1: Flip items with highest combined marginal gains\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Add diversity-aware flips\n    if np.random.rand() < 0.4:\n        diversity_indices = np.random.choice(len(weight_lst), min(2, len(weight_lst)), replace=False)\n        for idx in diversity_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Phase 3: Adaptive repair if infeasible\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined gain\n        removal_candidates = included_items[np.argsort(combined_gain[included_items])]\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    # Phase 4: Objective-aware fine-tuning\n    if np.random.rand() < 0.3:\n        obj1_ratio = objectives[selected_idx][0] / (max_obj1 + 1e-10)\n        obj2_ratio = objectives[selected_idx][1] / (max_obj2 + 1e-10)\n\n        if obj1_ratio < obj2_ratio:\n            # Improve objective 1\n            target_gain = marginal_gain1\n        else:\n            # Improve objective 2\n            target_gain = marginal_gain2\n\n        fine_tune_indices = np.argsort(-target_gain)[:min(3, len(weight_lst))]\n        for idx in fine_tune_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7891220097164751,
            0.23449105024337769
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = objectives.max(axis=0)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0] / max_obj1 + objectives[:, 1] / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate dominance-aware marginal gains\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Phase 1: Flip items with highest combined marginal gains\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Add diversity-aware flips\n    if np.random.rand() < 0.4:\n        diversity_indices = np.random.choice(len(weight_lst), min(2, len(weight_lst)), replace=False)\n        for idx in diversity_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Phase 3: Adaptive repair if infeasible\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined gain\n        removal_candidates = included_items[np.argsort(combined_gain[included_items])]\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    # Phase 4: Objective-aware fine-tuning\n    if np.random.rand() < 0.3:\n        obj1_ratio = objectives[selected_idx][0] / (max_obj1 + 1e-10)\n        obj2_ratio = objectives[selected_idx][1] / (max_obj2 + 1e-10)\n\n        if obj1_ratio < obj2_ratio:\n            # Improve objective 1\n            target_gain = marginal_gain1\n        else:\n            # Improve objective 2\n            target_gain = marginal_gain2\n\n        fine_tune_indices = np.argsort(-target_gain)[:min(3, len(weight_lst))]\n        for idx in fine_tune_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm combines hypervolume-based selection of top 20% solutions with knee-point prioritization, then performs a three-phase local search: first flipping high-marginal-gain items, then strategically adding 1-2 trade-off-aware flips, and finally repairing infeasible solutions by removing least-critical items, while using adaptive perturbation to escape local optima. It prioritizes items with higher marginal gains for both objectives and strategically balances trade-offs between objectives, ensuring feasibility through iterative repair and dominance-aware neighbor generation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hypervolume-based selection of top 20% solutions\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = objectives.max(axis=0)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0] / max_obj1 + objectives[:, 1] / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Flip items with highest marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Add 1-2 trade-off-aware flips\n    trade_off_indices = np.argsort(np.abs(marginal_gain1 - marginal_gain2))[:min(2, len(weight_lst))]\n    for idx in trade_off_indices:\n        if np.random.rand() < 0.4:  # 40% chance to flip\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Phase 3: Repair infeasible solutions\n    if current_weight > capacity:\n        criticality = value1_lst + value2_lst  # Combined criticality\n        sorted_indices = np.argsort(criticality)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and current_weight > capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Adaptive perturbation\n    if np.random.rand() < 0.3:  # 30% chance to perturb\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if np.random.rand() < 0.5:  # 50% chance to flip each low-gain item\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the ultra-refined heuristic design (under 100 words):\n\n- **Keywords**: **Hypervolume, knee-point selection, marginal gain flips, adaptive perturbation, feasibility repair**\n- **Advice**: Select top 20% solutions by hypervolume, prioritize knee-points; flip items with highest marginal gains in either objective, then add 1-2 random flips; repair infeasible neighbors by removing least critical items; iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness; ignore feasibility checks after perturbations.\n- **Explanation**: Balances exploitation (knee-point selection) and exploration (marginal gain flips) while ensuring feasibility. Dominance-aware repairs prevent stagnation, and iterative refinement yields high-quality neighbors efficiently.\n\n*(Word count: ~50)*\n\n**Why this works**:\n1. **Hypervolume + knee-point selection** ensures diversity and trade-off awareness.\n2. **Marginal gain + trade-off flips** prioritize items that improve either objective.\n3. **Adaptive perturbation** avoids premature convergence.\n4. **Feasibility-aware repair** guarantees valid neighbors.\n\nThis heuristic avoids pitfalls while leveraging multi-objective insights.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 175,
        "algorithm": "The algorithm combines hypervolume-based selection of top 20% solutions with a multi-phase local search: it first clusters items by marginal gains in both objectives, then flips items in the highest-gain cluster with probability proportional to their combined gain, followed by trade-off-aware swaps between clusters, and finally performs a feasibility repair by iteratively removing items with the lowest value-to-weight ratio until the solution is feasible. The approach prioritizes high-marginal-gain items while maintaining feasibility through dominance-aware clustering and repair.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hypervolume-based selection of top 20% solutions\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = objectives.max(axis=0)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0] / max_obj1 + objectives[:, 1] / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Cluster items by marginal gains\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    gains = np.column_stack((marginal_gain1, marginal_gain2))\n\n    # K-means clustering (k=3)\n    from sklearn.cluster import KMeans\n    kmeans = KMeans(n_clusters=3, random_state=42).fit(gains)\n    clusters = kmeans.labels_\n\n    # Phase 1: Flip items in the highest-gain cluster with probability proportional to gain\n    highest_cluster = np.argmax(np.mean(gains, axis=0))\n    cluster_indices = np.where(clusters == highest_cluster)[0]\n    for idx in cluster_indices:\n        if np.random.rand() < (gains[idx, 0] + gains[idx, 1]) / (2 * np.max(gains)):\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Phase 2: Trade-off-aware swap between clusters\n    if len(cluster_indices) > 0:\n        other_clusters = [c for c in range(3) if c != highest_cluster]\n        for c in other_clusters:\n            other_indices = np.where(clusters == c)[0]\n            if len(other_indices) > 0:\n                swap_idx = np.random.choice(other_indices)\n                if base_solution[swap_idx] == 1 and current_weight - weight_lst[swap_idx] <= capacity:\n                    new_solution[swap_idx] = 0\n                    current_weight -= weight_lst[swap_idx]\n                elif base_solution[swap_idx] == 0 and current_weight + weight_lst[swap_idx] <= capacity:\n                    new_solution[swap_idx] = 1\n                    current_weight += weight_lst[swap_idx]\n\n    # Phase 3: Feasibility repair\n    if current_weight > capacity:\n        value_to_weight_ratio = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = np.argsort(value_to_weight_ratio)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and current_weight > capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.5346783081456848,
            2.885302811861038
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hypervolume-based selection of top 20% solutions\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = objectives.max(axis=0)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0] / max_obj1 + objectives[:, 1] / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Cluster items by marginal gains\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    gains = np.column_stack((marginal_gain1, marginal_gain2))\n\n    # K-means clustering (k=3)\n    from sklearn.cluster import KMeans\n    kmeans = KMeans(n_clusters=3, random_state=42).fit(gains)\n    clusters = kmeans.labels_\n\n    # Phase 1: Flip items in the highest-gain cluster with probability proportional to gain\n    highest_cluster = np.argmax(np.mean(gains, axis=0))\n    cluster_indices = np.where(clusters == highest_cluster)[0]\n    for idx in cluster_indices:\n        if np.random.rand() < (gains[idx, 0] + gains[idx, 1]) / (2 * np.max(gains)):\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Phase 2: Trade-off-aware swap between clusters\n    if len(cluster_indices) > 0:\n        other_clusters = [c for c in range(3) if c != highest_cluster]\n        for c in other_clusters:\n            other_indices = np.where(clusters == c)[0]\n            if len(other_indices) > 0:\n                swap_idx = np.random.choice(other_indices)\n                if base_solution[swap_idx] == 1 and current_weight - weight_lst[swap_idx] <= capacity:\n                    new_solution[swap_idx] = 0\n                    current_weight -= weight_lst[swap_idx]\n                elif base_solution[swap_idx] == 0 and current_weight + weight_lst[swap_idx] <= capacity:\n                    new_solution[swap_idx] = 1\n                    current_weight += weight_lst[swap_idx]\n\n    # Phase 3: Feasibility repair\n    if current_weight > capacity:\n        value_to_weight_ratio = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = np.argsort(value_to_weight_ratio)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and current_weight > capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm combines hypervolume-based selection of top 20% solutions with knee-point prioritization, then performs a three-phase local search: first flipping high-marginal-gain items, then strategically adding 1-2 trade-off-aware flips, and finally repairing infeasible solutions by removing least-critical items, while using adaptive perturbation to escape local optima. It prioritizes items with higher marginal gains for both objectives and strategically balances trade-offs between objectives, ensuring feasibility through iterative repair and dominance-aware neighbor generation.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hypervolume-based selection of top 20% solutions\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = objectives.max(axis=0)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0] / max_obj1 + objectives[:, 1] / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Flip items with highest marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Add 1-2 trade-off-aware flips\n    trade_off_indices = np.argsort(np.abs(marginal_gain1 - marginal_gain2))[:min(2, len(weight_lst))]\n    for idx in trade_off_indices:\n        if np.random.rand() < 0.4:  # 40% chance to flip\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Phase 3: Repair infeasible solutions\n    if current_weight > capacity:\n        criticality = value1_lst + value2_lst  # Combined criticality\n        sorted_indices = np.argsort(criticality)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and current_weight > capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Adaptive perturbation\n    if np.random.rand() < 0.3:  # 30% chance to perturb\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if np.random.rand() < 0.5:  # 50% chance to flip each low-gain item\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 176,
        "algorithm": "The algorithm selects promising solutions from the archive based on hypervolume and knee-point characteristics, then performs a four-phase local search: (1) flips high-marginal-gain items, (2) applies objective-biased flips, (3) uses a trade-off-aware utility function, and (4) repairs infeasible solutions by removing low-criticality items while preserving high-utility ones. It prioritizes items with balanced value-weight ratios and adapts flipping strategies based on the solution's objective bias.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solutions with high hypervolume contribution and knee-point characteristics\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = objectives.max(axis=0)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Calculate knee-point score (distance to ideal point)\n        ideal_point = np.array([max_obj1, max_obj2])\n        distances = np.linalg.norm(objectives - ideal_point, axis=1)\n        knee_scores = distances / np.sum(distances)\n\n        # Hypervolume contribution (simplified)\n        sorted_indices = np.argsort(-objectives[:, 0] - objectives[:, 1])\n        hypervolume_scores = np.linspace(0, 1, len(archive))[sorted_indices]\n\n        # Combine scores\n        combined_scores = 0.6 * knee_scores + 0.4 * hypervolume_scores\n        top_indices = np.argsort(combined_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate current objective values\n    current_obj1 = np.sum(value1_lst * base_solution)\n    current_obj2 = np.sum(value2_lst * base_solution)\n\n    # Phase 1: Flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Apply objective-specific flips based on current solution's bias\n    obj1_bias = current_obj1 / (current_obj1 + current_obj2 + 1e-8)\n    obj2_bias = current_obj2 / (current_obj1 + current_obj2 + 1e-8)\n\n    if obj1_bias > 0.6:  # Strong bias toward obj1\n        # Prioritize items that improve obj1 more than obj2\n        obj_specific_gain = (value1_lst - 0.5 * value2_lst) / weight_lst\n    elif obj2_bias > 0.6:  # Strong bias toward obj2\n        # Prioritize items that improve obj2 more than obj1\n        obj_specific_gain = (value2_lst - 0.5 * value1_lst) / weight_lst\n    else:\n        # Balanced approach\n        obj_specific_gain = (value1_lst + value2_lst) / weight_lst\n\n    obj_specific_indices = np.argsort(-obj_specific_gain)[:min(3, len(weight_lst))]\n    for idx in obj_specific_indices:\n        if np.random.rand() < 0.5:  # 50% chance to flip\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Phase 3: Trade-off-aware flips using novel utility function\n    utility = (value1_lst + value2_lst) / (weight_lst + 1e-8)\n    trade_off_indices = np.argsort(np.abs(marginal_gain1 - marginal_gain2))[:min(2, len(weight_lst))]\n\n    for idx in trade_off_indices:\n        if np.random.rand() < 0.4:  # 40% chance to flip\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Phase 4: Repair infeasible solutions with criticality preservation\n    if current_weight > capacity:\n        # Calculate criticality: combine normalized values and weight efficiency\n        norm_value1 = value1_lst / (np.max(value1_lst) + 1e-8)\n        norm_value2 = value2_lst / (np.max(value2_lst) + 1e-8)\n        weight_efficiency = (value1_lst + value2_lst) / (weight_lst + 1e-8)\n\n        criticality = 0.5 * (norm_value1 + norm_value2) + 0.5 * weight_efficiency\n        sorted_indices = np.argsort(criticality)\n\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and current_weight > capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8109599634318524,
            0.3324871361255646
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solutions with high hypervolume contribution and knee-point characteristics\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = objectives.max(axis=0)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Calculate knee-point score (distance to ideal point)\n        ideal_point = np.array([max_obj1, max_obj2])\n        distances = np.linalg.norm(objectives - ideal_point, axis=1)\n        knee_scores = distances / np.sum(distances)\n\n        # Hypervolume contribution (simplified)\n        sorted_indices = np.argsort(-objectives[:, 0] - objectives[:, 1])\n        hypervolume_scores = np.linspace(0, 1, len(archive))[sorted_indices]\n\n        # Combine scores\n        combined_scores = 0.6 * knee_scores + 0.4 * hypervolume_scores\n        top_indices = np.argsort(combined_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate current objective values\n    current_obj1 = np.sum(value1_lst * base_solution)\n    current_obj2 = np.sum(value2_lst * base_solution)\n\n    # Phase 1: Flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Apply objective-specific flips based on current solution's bias\n    obj1_bias = current_obj1 / (current_obj1 + current_obj2 + 1e-8)\n    obj2_bias = current_obj2 / (current_obj1 + current_obj2 + 1e-8)\n\n    if obj1_bias > 0.6:  # Strong bias toward obj1\n        # Prioritize items that improve obj1 more than obj2\n        obj_specific_gain = (value1_lst - 0.5 * value2_lst) / weight_lst\n    elif obj2_bias > 0.6:  # Strong bias toward obj2\n        # Prioritize items that improve obj2 more than obj1\n        obj_specific_gain = (value2_lst - 0.5 * value1_lst) / weight_lst\n    else:\n        # Balanced approach\n        obj_specific_gain = (value1_lst + value2_lst) / weight_lst\n\n    obj_specific_indices = np.argsort(-obj_specific_gain)[:min(3, len(weight_lst))]\n    for idx in obj_specific_indices:\n        if np.random.rand() < 0.5:  # 50% chance to flip\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Phase 3: Trade-off-aware flips using novel utility function\n    utility = (value1_lst + value2_lst) / (weight_lst + 1e-8)\n    trade_off_indices = np.argsort(np.abs(marginal_gain1 - marginal_gain2))[:min(2, len(weight_lst))]\n\n    for idx in trade_off_indices:\n        if np.random.rand() < 0.4:  # 40% chance to flip\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Phase 4: Repair infeasible solutions with criticality preservation\n    if current_weight > capacity:\n        # Calculate criticality: combine normalized values and weight efficiency\n        norm_value1 = value1_lst / (np.max(value1_lst) + 1e-8)\n        norm_value2 = value2_lst / (np.max(value2_lst) + 1e-8)\n        weight_efficiency = (value1_lst + value2_lst) / (weight_lst + 1e-8)\n\n        criticality = 0.5 * (norm_value1 + norm_value2) + 0.5 * weight_efficiency\n        sorted_indices = np.argsort(criticality)\n\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and current_weight > capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm combines hypervolume-based selection of top 20% solutions with knee-point prioritization, then performs a three-phase local search: first flipping high-marginal-gain items, then strategically adding 1-2 trade-off-aware flips, and finally repairing infeasible solutions by removing least-critical items, while using adaptive perturbation to escape local optima. It prioritizes items with higher marginal gains for both objectives and strategically balances trade-offs between objectives, ensuring feasibility through iterative repair and dominance-aware neighbor generation.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hypervolume-based selection of top 20% solutions\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = objectives.max(axis=0)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0] / max_obj1 + objectives[:, 1] / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Flip items with highest marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Add 1-2 trade-off-aware flips\n    trade_off_indices = np.argsort(np.abs(marginal_gain1 - marginal_gain2))[:min(2, len(weight_lst))]\n    for idx in trade_off_indices:\n        if np.random.rand() < 0.4:  # 40% chance to flip\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Phase 3: Repair infeasible solutions\n    if current_weight > capacity:\n        criticality = value1_lst + value2_lst  # Combined criticality\n        sorted_indices = np.argsort(criticality)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and current_weight > capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Adaptive perturbation\n    if np.random.rand() < 0.3:  # 30% chance to perturb\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if np.random.rand() < 0.5:  # 50% chance to flip each low-gain item\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 177,
        "algorithm": "This heuristic algorithm prioritizes knee-point solutions (balancing both objectives) and employs a four-phase local search: first flipping items with balanced marginal gains, then dominance-aware flips, followed by hypervolume-optimized swaps, and finally repairing infeasible solutions by removing least valuable items, while incorporating randomized perturbations for exploration. The algorithm strategically balances exploitation (targeted flips) and exploration (random perturbations) to navigate the multi-objective solution space efficiently.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Knee-point prioritization\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = objectives.max(axis=0)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        knee_scores = (objectives[:, 0] / max_obj1) * (objectives[:, 1] / max_obj2)\n        selected_idx = np.argmax(knee_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Flip items with balanced marginal gains\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    balance_score = np.abs(marginal_gain1 - marginal_gain2)\n    balanced_indices = np.argsort(balance_score)[:min(4, len(weight_lst))]\n\n    for idx in balanced_indices:\n        if np.random.rand() < 0.6:  # 60% chance to flip\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Phase 2: Dominance-aware flips\n    dominance_score = (marginal_gain1 + marginal_gain2) / (np.abs(marginal_gain1 - marginal_gain2) + 1e-6)\n    dominance_indices = np.argsort(-dominance_score)[:min(3, len(weight_lst))]\n\n    for idx in dominance_indices:\n        if np.random.rand() < 0.5:  # 50% chance to flip\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Phase 3: Hypervolume-optimized swaps\n    hypervolume_score = (value1_lst * value2_lst) / (weight_lst + 1e-6)\n    hypervolume_indices = np.argsort(-hypervolume_score)[:min(2, len(weight_lst))]\n\n    for idx in hypervolume_indices:\n        if np.random.rand() < 0.4:  # 40% chance to flip\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Phase 4: Repair infeasible solutions\n    if current_weight > capacity:\n        repair_score = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        sorted_indices = np.argsort(repair_score)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and current_weight > capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Randomized perturbation\n    if np.random.rand() < 0.2:  # 20% chance to perturb\n        perturbation_indices = np.random.choice(len(weight_lst), size=min(3, len(weight_lst)), replace=False)\n        for idx in perturbation_indices:\n            if np.random.rand() < 0.3:  # 30% chance to flip each selected item\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3402048427414849,
            0.43769320845603943
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Knee-point prioritization\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = objectives.max(axis=0)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        knee_scores = (objectives[:, 0] / max_obj1) * (objectives[:, 1] / max_obj2)\n        selected_idx = np.argmax(knee_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Flip items with balanced marginal gains\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    balance_score = np.abs(marginal_gain1 - marginal_gain2)\n    balanced_indices = np.argsort(balance_score)[:min(4, len(weight_lst))]\n\n    for idx in balanced_indices:\n        if np.random.rand() < 0.6:  # 60% chance to flip\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Phase 2: Dominance-aware flips\n    dominance_score = (marginal_gain1 + marginal_gain2) / (np.abs(marginal_gain1 - marginal_gain2) + 1e-6)\n    dominance_indices = np.argsort(-dominance_score)[:min(3, len(weight_lst))]\n\n    for idx in dominance_indices:\n        if np.random.rand() < 0.5:  # 50% chance to flip\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Phase 3: Hypervolume-optimized swaps\n    hypervolume_score = (value1_lst * value2_lst) / (weight_lst + 1e-6)\n    hypervolume_indices = np.argsort(-hypervolume_score)[:min(2, len(weight_lst))]\n\n    for idx in hypervolume_indices:\n        if np.random.rand() < 0.4:  # 40% chance to flip\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Phase 4: Repair infeasible solutions\n    if current_weight > capacity:\n        repair_score = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        sorted_indices = np.argsort(repair_score)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and current_weight > capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Randomized perturbation\n    if np.random.rand() < 0.2:  # 20% chance to perturb\n        perturbation_indices = np.random.choice(len(weight_lst), size=min(3, len(weight_lst)), replace=False)\n        for idx in perturbation_indices:\n            if np.random.rand() < 0.3:  # 30% chance to flip each selected item\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 3 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm combines hypervolume-based selection of top 20% solutions with knee-point prioritization, then performs a three-phase local search: first flipping high-marginal-gain items, then strategically adding 1-2 trade-off-aware flips, and finally repairing infeasible solutions by removing least-critical items, while using adaptive perturbation to escape local optima. It prioritizes items with higher marginal gains for both objectives and strategically balances trade-offs between objectives, ensuring feasibility through iterative repair and dominance-aware neighbor generation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hypervolume-based selection of top 20% solutions\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = objectives.max(axis=0)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0] / max_obj1 + objectives[:, 1] / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Flip items with highest marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Add 1-2 trade-off-aware flips\n    trade_off_indices = np.argsort(np.abs(marginal_gain1 - marginal_gain2))[:min(2, len(weight_lst))]\n    for idx in trade_off_indices:\n        if np.random.rand() < 0.4:  # 40% chance to flip\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Phase 3: Repair infeasible solutions\n    if current_weight > capacity:\n        criticality = value1_lst + value2_lst  # Combined criticality\n        sorted_indices = np.argsort(criticality)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and current_weight > capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Adaptive perturbation\n    if np.random.rand() < 0.3:  # 30% chance to perturb\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if np.random.rand() < 0.5:  # 50% chance to flip each low-gain item\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the ultra-refined heuristic design (under 100 words):\n\n- **Keywords**: **Hypervolume, knee-point selection, marginal gain flips, adaptive perturbation, feasibility repair**\n- **Advice**: Select top 20% solutions by hypervolume, prioritize knee-points; flip items with highest marginal gains in either objective, then add 1-2 random flips; repair infeasible neighbors by removing least critical items; iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness; ignore feasibility checks after perturbations.\n- **Explanation**: Balances exploitation (knee-point selection) and exploration (marginal gain flips) while ensuring feasibility. Dominance-aware repairs prevent stagnation, and iterative refinement yields high-quality neighbors efficiently.\n\n*(Word count: ~50)*\n\n**Why this works**:\n1. **Hypervolume + knee-point selection** ensures diversity and trade-off awareness.\n2. **Marginal gain + trade-off flips** prioritize items that improve either objective.\n3. **Adaptive perturbation** avoids premature convergence.\n4. **Feasibility-aware repair** guarantees valid neighbors.\n\nThis heuristic avoids pitfalls while leveraging multi-objective insights.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 178,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hypervolume-based selection of top 20% solutions with knee-point prioritization\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = objectives.max(axis=0)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Calculate hypervolume contribution for each solution\n        sorted_indices = np.lexsort((-objectives[:, 1], -objectives[:, 0]))\n        sorted_objectives = objectives[sorted_indices]\n        hypervolume = np.zeros(len(archive))\n        for i in range(len(archive)):\n            if i == 0:\n                hypervolume[i] = sorted_objectives[i, 0] * sorted_objectives[i, 1]\n            else:\n                hypervolume[i] = (sorted_objectives[i, 0] - sorted_objectives[i-1, 0]) * sorted_objectives[i, 1]\n\n        # Combine hypervolume and knee-point selection\n        knee_points = np.zeros(len(archive))\n        for i in range(1, len(archive)-1):\n            knee_points[i] = np.linalg.norm(objectives[i] - objectives[i-1]) + np.linalg.norm(objectives[i] - objectives[i+1])\n\n        combined_scores = hypervolume + knee_points\n        top_indices = np.argsort(combined_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Flip items with highest marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(10, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Add 1-3 trade-off-aware flips with adaptive probability\n    trade_off_indices = np.argsort(np.abs(marginal_gain1 - marginal_gain2))[:min(3, len(weight_lst))]\n    for idx in trade_off_indices:\n        flip_prob = 0.5 * (1 - np.abs(marginal_gain1[idx] - marginal_gain2[idx]) / (marginal_gain1[idx] + marginal_gain2[idx] + 1e-6))\n        if np.random.rand() < flip_prob:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Phase 3: Repair infeasible solutions with dominance-aware removal\n    if current_weight > capacity:\n        criticality = value1_lst + value2_lst + (weight_lst * 0.1)  # Combined criticality with slight weight penalty\n        sorted_indices = np.argsort(criticality)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and current_weight > capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Phase 4: Adaptive perturbation with limited iterations\n    if np.random.rand() < 0.4:  # 40% chance to perturb\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n        for _ in range(2):  # Limit to 2 perturbations\n            idx = np.random.choice(low_gain_indices)\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7436227728606144,
            0.540527880191803
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hypervolume-based selection of top 20% solutions with knee-point prioritization\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = objectives.max(axis=0)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Calculate hypervolume contribution for each solution\n        sorted_indices = np.lexsort((-objectives[:, 1], -objectives[:, 0]))\n        sorted_objectives = objectives[sorted_indices]\n        hypervolume = np.zeros(len(archive))\n        for i in range(len(archive)):\n            if i == 0:\n                hypervolume[i] = sorted_objectives[i, 0] * sorted_objectives[i, 1]\n            else:\n                hypervolume[i] = (sorted_objectives[i, 0] - sorted_objectives[i-1, 0]) * sorted_objectives[i, 1]\n\n        # Combine hypervolume and knee-point selection\n        knee_points = np.zeros(len(archive))\n        for i in range(1, len(archive)-1):\n            knee_points[i] = np.linalg.norm(objectives[i] - objectives[i-1]) + np.linalg.norm(objectives[i] - objectives[i+1])\n\n        combined_scores = hypervolume + knee_points\n        top_indices = np.argsort(combined_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Flip items with highest marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(10, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Add 1-3 trade-off-aware flips with adaptive probability\n    trade_off_indices = np.argsort(np.abs(marginal_gain1 - marginal_gain2))[:min(3, len(weight_lst))]\n    for idx in trade_off_indices:\n        flip_prob = 0.5 * (1 - np.abs(marginal_gain1[idx] - marginal_gain2[idx]) / (marginal_gain1[idx] + marginal_gain2[idx] + 1e-6))\n        if np.random.rand() < flip_prob:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Phase 3: Repair infeasible solutions with dominance-aware removal\n    if current_weight > capacity:\n        criticality = value1_lst + value2_lst + (weight_lst * 0.1)  # Combined criticality with slight weight penalty\n        sorted_indices = np.argsort(criticality)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and current_weight > capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Phase 4: Adaptive perturbation with limited iterations\n    if np.random.rand() < 0.4:  # 40% chance to perturb\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n        for _ in range(2):  # Limit to 2 perturbations\n            idx = np.random.choice(low_gain_indices)\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 5 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from the bottom 30% of the archive (based on normalized objective sums) and applies a targeted local search by prioritizing flips of low-marginal-gain items (based on value-to-weight ratios), followed by 2-3 random flips to escape local optima while ensuring feasibility through iterative refinement. The method balances exploitation (focused flips) with exploration (random flips) to improve solution quality.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select bottom 30% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        bottom_indices = np.argsort(normalized_scores)[:max(1, len(archive)//3)]\n        selected_idx = np.random.choice(bottom_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with low marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in low_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 2-3 random flips to escape local optima\n    num_random_flips = np.random.randint(2, 4)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive based on hypervolume contribution, then performs a targeted local search by flipping high-marginal-gain items while ensuring feasibility, followed by adaptive perturbation of low-contribution items to escape local optima. It balances exploitation (hypervolume-aware selection and high-gain flips) with exploration (adaptive perturbation and random flips) through iterative refinement and feasibility-aware repair. The selection prioritizes solutions with better hypervolume, while the local search intelligently modifies the solution by combining dominance-aware flipping, adaptive perturbation, and iterative refinement to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    def hypervolume(sol):\n        obj1, obj2 = sol[1]\n        return obj1 * obj2\n\n    hypervolumes = [hypervolume(sol) for sol in archive]\n    top_indices = np.argsort(hypervolumes)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:min(3, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: repair infeasible solutions\n    for _ in range(5):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm selects a knee-point solution from the Pareto front (balancing trade-offs between objectives) and applies a hybrid local search combining dominance-aware flipping (prioritizing items that improve the underrepresented objective) and diversity-aware perturbations (flipping items in underrepresented regions of the objective space), while ensuring feasibility through iterative removal of least critical items. The method intelligently balances exploration and exploitation by focusing on high-gain items and adaptive perturbations, with feasibility enforced by iterative weight adjustments.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select knee-point solution (balancing trade-offs)\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_obj1 = obj1_scores / max_obj1\n        normalized_obj2 = obj2_scores / max_obj2\n        distances = np.sqrt((1 - normalized_obj1)**2 + (1 - normalized_obj2)**2)\n        selected_idx = np.argmin(distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dominance-aware flipping (prioritize underrepresented objective)\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    if least_dominated == 1:\n        target_gain = value1_lst / (weight_lst + 1e-10)\n    else:\n        target_gain = value2_lst / (weight_lst + 1e-10)\n\n    high_gain_indices = np.argsort(target_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Diversity-aware perturbations (flip items in underrepresented regions)\n    if np.random.rand() < 0.3:\n        obj1_covered = np.sum(new_solution * value1_lst)\n        obj2_covered = np.sum(new_solution * value2_lst)\n        if obj1_covered < obj2_covered:\n            candidate_indices = np.where((value1_lst > value2_lst) & (new_solution == 0))[0]\n        else:\n            candidate_indices = np.where((value2_lst > value1_lst) & (new_solution == 0))[0]\n\n        if len(candidate_indices) > 0:\n            selected_idx = np.random.choice(candidate_indices)\n            if current_weight + weight_lst[selected_idx] <= capacity:\n                new_solution[selected_idx] = 1\n                current_weight += weight_lst[selected_idx]\n\n    # Iterative feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined marginal gain\n        combined_gain = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        remove_idx = included_items[np.argmin(combined_gain[included_items])]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s the ultra-optimized heuristic design for BI-KP (under 100 words):\n\n- **Keywords**: **Hypervolume, knee-point selection, marginal gain flips, adaptive perturbation, feasibility repair**\n- **Advice**: Select top 20% solutions by hypervolume, prioritize knee-points; flip items with highest marginal gains in either objective, then add 1-2 random flips; repair infeasible neighbors by removing least critical items; iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness; ignore feasibility checks after perturbations.\n- **Explanation**: Balances exploitation (knee-point selection) and exploration (marginal gain flips) while ensuring feasibility. Dominance-aware repairs prevent stagnation, and iterative refinement yields high-quality neighbors efficiently.\n\n*(Word count: ~50)*\n\n**Why this wins**:\n1. **Hypervolume + knee-point selection** ensures diversity and trade-off awareness.\n2. **Marginal gain + trade-off flips** prioritize items that improve either objective.\n3. **Adaptive perturbation** avoids premature convergence.\n4. **Feasibility-aware repair** guarantees valid neighbors.\n\nThis heuristic avoids pitfalls while leveraging multi-objective insights.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 179,
        "algorithm": "The algorithm selects promising solutions from the archive by prioritizing high hypervolume and knee-point trade-off solutions, then applies a hybrid local search that flips high-marginal-gain items, adds random flips for exploration, and iteratively repairs infeasibility by removing least critical items. It balances exploitation (targeting high-gain items) and exploration (random flips) while ensuring feasibility through iterative repair. The knee-point selection and marginal-gain prioritization are key design choices to navigate the bi-objective trade-off efficiently.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume\n    def hypervolume(sol):\n        obj1, obj2 = sol[1]\n        return obj1 * obj2\n\n    hypervolumes = [hypervolume(sol) for sol in archive]\n    top_indices = np.argsort(hypervolumes)[-max(1, len(archive) // 5):]\n\n    # Among top 20%, select knee-point solution\n    obj1_scores = np.array([archive[i][1][0] for i in top_indices])\n    obj2_scores = np.array([archive[i][1][1] for i in top_indices])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.choice(top_indices)\n    else:\n        normalized_obj1 = obj1_scores / max_obj1\n        normalized_obj2 = obj2_scores / max_obj2\n        distances = np.sqrt((1 - normalized_obj1)**2 + (1 - normalized_obj2)**2)\n        knee_idx = np.argmin(distances)\n        selected_idx = top_indices[knee_idx]\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Flip items with highest marginal gains in either objective\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    max_gain = np.maximum(marginal_gain1, marginal_gain2)\n    high_gain_indices = np.argsort(-max_gain)[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips\n    num_random_flips = np.random.randint(1, 3)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Iterative feasibility repair (5-10 times)\n    for _ in range(np.random.randint(5, 11)):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined marginal gain\n        combined_gain = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        remove_idx = included_items[np.argmin(combined_gain[included_items])]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8070606034495903,
            0.26554957032203674
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume\n    def hypervolume(sol):\n        obj1, obj2 = sol[1]\n        return obj1 * obj2\n\n    hypervolumes = [hypervolume(sol) for sol in archive]\n    top_indices = np.argsort(hypervolumes)[-max(1, len(archive) // 5):]\n\n    # Among top 20%, select knee-point solution\n    obj1_scores = np.array([archive[i][1][0] for i in top_indices])\n    obj2_scores = np.array([archive[i][1][1] for i in top_indices])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.choice(top_indices)\n    else:\n        normalized_obj1 = obj1_scores / max_obj1\n        normalized_obj2 = obj2_scores / max_obj2\n        distances = np.sqrt((1 - normalized_obj1)**2 + (1 - normalized_obj2)**2)\n        knee_idx = np.argmin(distances)\n        selected_idx = top_indices[knee_idx]\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Flip items with highest marginal gains in either objective\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    max_gain = np.maximum(marginal_gain1, marginal_gain2)\n    high_gain_indices = np.argsort(-max_gain)[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips\n    num_random_flips = np.random.randint(1, 3)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Iterative feasibility repair (5-10 times)\n    for _ in range(np.random.randint(5, 11)):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined marginal gain\n        combined_gain = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        remove_idx = included_items[np.argmin(combined_gain[included_items])]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive based on hypervolume contribution, then performs a targeted local search by flipping high-marginal-gain items while ensuring feasibility, followed by adaptive perturbation of low-contribution items to escape local optima. It balances exploitation (hypervolume-aware selection and high-gain flips) with exploration (adaptive perturbation and random flips) through iterative refinement and feasibility-aware repair. The selection prioritizes solutions with better hypervolume, while the local search intelligently modifies the solution by combining dominance-aware flipping, adaptive perturbation, and iterative refinement to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    def hypervolume(sol):\n        obj1, obj2 = sol[1]\n        return obj1 * obj2\n\n    hypervolumes = [hypervolume(sol) for sol in archive]\n    top_indices = np.argsort(hypervolumes)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:min(3, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: repair infeasible solutions\n    for _ in range(5):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive based on combined objective scores, then performs a targeted local search by flipping high-marginal-gain items prioritizing the least dominated objective, followed by controlled random perturbations and adaptive feasibility repairs to ensure capacity constraints are met while maintaining solution diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by combined objective score\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        combined_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(combined_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains and dominance information\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Identify items that improve the least dominated objective\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    # Targeted flipping of high-marginal-gain items prioritizing least dominated objective\n    if least_dominated == 1:\n        target_gain = marginal_gain1\n    else:\n        target_gain = marginal_gain2\n\n    high_gain_indices = np.argsort(target_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation of low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined marginal gain\n        removal_candidates = included_items[np.argsort(combined_gain[included_items])]\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the ultra-optimized heuristic design for BI-KP (under 100 words):\n\n- **Keywords**: **Hypervolume, knee-point selection, marginal gain flips, adaptive perturbation, feasibility repair**\n- **Advice**: Select top 20% solutions by hypervolume, prioritize knee-points; flip items with highest marginal gains in either objective, then add 1-2 random flips; repair infeasible neighbors by removing least critical items; iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness; ignore feasibility checks after perturbations.\n- **Explanation**: Balances exploitation (knee-point selection) and exploration (marginal gain flips) while ensuring feasibility. Dominance-aware repairs prevent stagnation, and iterative refinement yields high-quality neighbors efficiently.\n\n*(Word count: ~50)*\n\n**Why this wins**:\n1. **Hypervolume + knee-point selection** ensures diversity and trade-off awareness.\n2. **Marginal gain + trade-off flips** prioritize items that improve either objective.\n3. **Adaptive perturbation** avoids premature convergence.\n4. **Feasibility-aware repair** guarantees valid neighbors.\n\nThis heuristic avoids pitfalls while leveraging multi-objective insights.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 180,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select knee-point solutions from the top 20% of the archive\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_obj1 = obj1_scores / max_obj1\n        normalized_obj2 = obj2_scores / max_obj2\n        knee_scores = np.abs(normalized_obj1 - normalized_obj2)\n        top_indices = np.argsort(knee_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains and combined gain\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Targeted flipping of high-marginal-gain items in either objective\n    high_gain_indices = np.argsort(combined_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips to explore neighborhood\n    if np.random.rand() < 0.5:\n        random_indices = np.random.choice(len(weight_lst), size=np.random.randint(1, 3), replace=False)\n        for idx in random_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative feasibility repair\n    for _ in range(5):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(combined_gain[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.7971475238109775,
            0.24494272470474243
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select knee-point solutions from the top 20% of the archive\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_obj1 = obj1_scores / max_obj1\n        normalized_obj2 = obj2_scores / max_obj2\n        knee_scores = np.abs(normalized_obj1 - normalized_obj2)\n        top_indices = np.argsort(knee_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains and combined gain\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Targeted flipping of high-marginal-gain items in either objective\n    high_gain_indices = np.argsort(combined_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips to explore neighborhood\n    if np.random.rand() < 0.5:\n        random_indices = np.random.choice(len(weight_lst), size=np.random.randint(1, 3), replace=False)\n        for idx in random_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative feasibility repair\n    for _ in range(5):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(combined_gain[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive based on hypervolume contribution, then performs a targeted local search by flipping high-marginal-gain items while ensuring feasibility, followed by adaptive perturbation of low-contribution items to escape local optima. It balances exploitation (hypervolume-aware selection and high-gain flips) with exploration (adaptive perturbation and random flips) through iterative refinement and feasibility-aware repair. The selection prioritizes solutions with better hypervolume, while the local search intelligently modifies the solution by combining dominance-aware flipping, adaptive perturbation, and iterative refinement to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    def hypervolume(sol):\n        obj1, obj2 = sol[1]\n        return obj1 * obj2\n\n    hypervolumes = [hypervolume(sol) for sol in archive]\n    top_indices = np.argsort(hypervolumes)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:min(3, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: repair infeasible solutions\n    for _ in range(5):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive based on combined objective scores, then performs a targeted local search by flipping high-marginal-gain items prioritizing the least dominated objective, followed by controlled random perturbations and adaptive feasibility repairs to ensure capacity constraints are met while maintaining solution diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by combined objective score\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        combined_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(combined_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains and dominance information\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Identify items that improve the least dominated objective\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    # Targeted flipping of high-marginal-gain items prioritizing least dominated objective\n    if least_dominated == 1:\n        target_gain = marginal_gain1\n    else:\n        target_gain = marginal_gain2\n\n    high_gain_indices = np.argsort(target_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation of low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined marginal gain\n        removal_candidates = included_items[np.argsort(combined_gain[included_items])]\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the ultra-optimized heuristic design for BI-KP (under 100 words):\n\n- **Keywords**: **Hypervolume, knee-point selection, marginal gain flips, adaptive perturbation, feasibility repair**\n- **Advice**: Select top 20% solutions by hypervolume, prioritize knee-points; flip items with highest marginal gains in either objective, then add 1-2 random flips; repair infeasible neighbors by removing least critical items; iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness; ignore feasibility checks after perturbations.\n- **Explanation**: Balances exploitation (knee-point selection) and exploration (marginal gain flips) while ensuring feasibility. Dominance-aware repairs prevent stagnation, and iterative refinement yields high-quality neighbors efficiently.\n\n*(Word count: ~50)*\n\n**Why this wins**:\n1. **Hypervolume + knee-point selection** ensures diversity and trade-off awareness.\n2. **Marginal gain + trade-off flips** prioritize items that improve either objective.\n3. **Adaptive perturbation** avoids premature convergence.\n4. **Feasibility-aware repair** guarantees valid neighbors.\n\nThis heuristic avoids pitfalls while leveraging multi-objective insights.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 181,
        "algorithm": "The algorithm combines knee-point selection with a two-phase local search: first, it flips high-marginal-gain items prioritizing the least dominated objective, then performs controlled swaps between high and low marginal contribution items, ensuring feasibility through a greedy repair mechanism that removes the least critical items when capacity is exceeded. The knee-point solution is selected by maximizing the product of normalized objective values, and the marginal gains are calculated to guide item flips and swaps, balancing exploitation and exploration while maintaining feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select knee-point solution (maximizing product of normalized objectives)\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_obj1 = obj1_scores / max_obj1\n        normalized_obj2 = obj2_scores / max_obj2\n        product_scores = normalized_obj1 * normalized_obj2\n        selected_idx = np.argmax(product_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains and identify least dominated objective\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    # Phase 1: Flip high-marginal-gain items prioritizing least dominated objective\n    if least_dominated == 1:\n        target_gain = marginal_gain1\n    else:\n        target_gain = marginal_gain2\n\n    high_gain_indices = np.argsort(target_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Controlled perturbation by swapping item pairs\n    if np.random.rand() < 0.4:\n        marginal_contribution = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        high_contrib_indices = np.argsort(marginal_contribution)[::-1][:min(3, len(weight_lst))]\n        low_contrib_indices = np.argsort(marginal_contribution)[:min(3, len(weight_lst))]\n\n        for high_idx in high_contrib_indices:\n            for low_idx in low_contrib_indices:\n                if base_solution[high_idx] == 1 and base_solution[low_idx] == 0:\n                    if current_weight - weight_lst[high_idx] + weight_lst[low_idx] <= capacity:\n                        new_solution[high_idx] = 0\n                        new_solution[low_idx] = 1\n                        current_weight = current_weight - weight_lst[high_idx] + weight_lst[low_idx]\n                        break\n\n    # Feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest marginal contribution\n        removal_candidates = included_items[np.argsort(marginal_contribution[included_items])]\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.8358460453736463,
            0.23842951655387878
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select knee-point solution (maximizing product of normalized objectives)\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_obj1 = obj1_scores / max_obj1\n        normalized_obj2 = obj2_scores / max_obj2\n        product_scores = normalized_obj1 * normalized_obj2\n        selected_idx = np.argmax(product_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains and identify least dominated objective\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    # Phase 1: Flip high-marginal-gain items prioritizing least dominated objective\n    if least_dominated == 1:\n        target_gain = marginal_gain1\n    else:\n        target_gain = marginal_gain2\n\n    high_gain_indices = np.argsort(target_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Controlled perturbation by swapping item pairs\n    if np.random.rand() < 0.4:\n        marginal_contribution = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        high_contrib_indices = np.argsort(marginal_contribution)[::-1][:min(3, len(weight_lst))]\n        low_contrib_indices = np.argsort(marginal_contribution)[:min(3, len(weight_lst))]\n\n        for high_idx in high_contrib_indices:\n            for low_idx in low_contrib_indices:\n                if base_solution[high_idx] == 1 and base_solution[low_idx] == 0:\n                    if current_weight - weight_lst[high_idx] + weight_lst[low_idx] <= capacity:\n                        new_solution[high_idx] = 0\n                        new_solution[low_idx] = 1\n                        current_weight = current_weight - weight_lst[high_idx] + weight_lst[low_idx]\n                        break\n\n    # Feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest marginal contribution\n        removal_candidates = included_items[np.argsort(marginal_contribution[included_items])]\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects promising solutions from the top 20% of the archive based on combined objective scores, then performs a targeted local search by flipping high-marginal-gain items prioritizing the least dominated objective, followed by controlled random perturbations and adaptive feasibility repairs to ensure capacity constraints are met while maintaining solution diversity.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by combined objective score\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        combined_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(combined_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains and dominance information\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Identify items that improve the least dominated objective\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    # Targeted flipping of high-marginal-gain items prioritizing least dominated objective\n    if least_dominated == 1:\n        target_gain = marginal_gain1\n    else:\n        target_gain = marginal_gain2\n\n    high_gain_indices = np.argsort(target_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation of low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined marginal gain\n        removal_candidates = included_items[np.argsort(combined_gain[included_items])]\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 182,
        "algorithm": "The algorithm selects promising solutions from the archive by balancing objective scores and diversity, then applies a hybrid local search that prioritizes high-value-density items while adaptively focusing on the least-dominated objective, with controlled perturbations to explore the solution space while ensuring feasibility through density-aware removal of excess items. It intelligently flips item selections based on their value-to-weight ratios and objective dominance, with additional random perturbations to escape local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solutions with high combined scores and good diversity\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Normalize and combine scores\n        norm_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        # Add diversity factor based on Hamming distance\n        diversity = np.array([np.sum(np.abs(archive[i][0] - archive[j][0])) for i in range(len(archive)) for j in range(len(archive)) if i != j])\n        diversity = diversity.reshape(len(archive), len(archive)-1)\n        diversity = np.mean(diversity, axis=1)\n        combined_scores = norm_scores + 0.3 * diversity\n        top_indices = np.argsort(combined_scores)[-max(1, len(archive) // 4):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate value-density metrics\n    density1 = value1_lst / (weight_lst + 1e-10)\n    density2 = value2_lst / (weight_lst + 1e-10)\n    combined_density = density1 + density2\n\n    # Determine objective dominance\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    # Adaptive prioritization based on objective dominance\n    if least_dominated == 1:\n        target_density = density1\n    else:\n        target_density = density2\n\n    # Hybrid local search: density-aware flipping with controlled perturbations\n    high_density_indices = np.argsort(target_density)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_density_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Value-density-aware perturbation\n    if np.random.rand() < 0.4:\n        # Select items with high density but low combined value\n        density_ratio = (density1 + density2) / (value1_lst + value2_lst + 1e-10)\n        perturbed_indices = np.argsort(density_ratio)[::-1][:min(3, len(weight_lst))]\n\n        for idx in perturbed_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Enhanced feasibility repair with density-aware removal\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined density\n        removal_candidates = included_items[np.argsort(combined_density[included_items])]\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.8871497508888513,
            2.705428183078766
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solutions with high combined scores and good diversity\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Normalize and combine scores\n        norm_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        # Add diversity factor based on Hamming distance\n        diversity = np.array([np.sum(np.abs(archive[i][0] - archive[j][0])) for i in range(len(archive)) for j in range(len(archive)) if i != j])\n        diversity = diversity.reshape(len(archive), len(archive)-1)\n        diversity = np.mean(diversity, axis=1)\n        combined_scores = norm_scores + 0.3 * diversity\n        top_indices = np.argsort(combined_scores)[-max(1, len(archive) // 4):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate value-density metrics\n    density1 = value1_lst / (weight_lst + 1e-10)\n    density2 = value2_lst / (weight_lst + 1e-10)\n    combined_density = density1 + density2\n\n    # Determine objective dominance\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    # Adaptive prioritization based on objective dominance\n    if least_dominated == 1:\n        target_density = density1\n    else:\n        target_density = density2\n\n    # Hybrid local search: density-aware flipping with controlled perturbations\n    high_density_indices = np.argsort(target_density)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_density_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Value-density-aware perturbation\n    if np.random.rand() < 0.4:\n        # Select items with high density but low combined value\n        density_ratio = (density1 + density2) / (value1_lst + value2_lst + 1e-10)\n        perturbed_indices = np.argsort(density_ratio)[::-1][:min(3, len(weight_lst))]\n\n        for idx in perturbed_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Enhanced feasibility repair with density-aware removal\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined density\n        removal_candidates = included_items[np.argsort(combined_density[included_items])]\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects promising solutions from the top 20% of the archive based on combined objective scores, then performs a targeted local search by flipping high-marginal-gain items prioritizing the least dominated objective, followed by controlled random perturbations and adaptive feasibility repairs to ensure capacity constraints are met while maintaining solution diversity.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by combined objective score\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        combined_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(combined_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains and dominance information\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Identify items that improve the least dominated objective\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    # Targeted flipping of high-marginal-gain items prioritizing least dominated objective\n    if least_dominated == 1:\n        target_gain = marginal_gain1\n    else:\n        target_gain = marginal_gain2\n\n    high_gain_indices = np.argsort(target_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation of low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined marginal gain\n        removal_candidates = included_items[np.argsort(combined_gain[included_items])]\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 183,
        "algorithm": "The algorithm selects solutions from the bottom 30% of the archive (by combined objective scores) to prioritize underperforming solutions for improvement. It then performs targeted local search by flipping high-marginal-gain items (70% probability) and controlled random perturbations of low-marginal-contribution items (40% probability), ensuring feasibility through adaptive repairs that remove low-value items when needed. The combined marginal gains of items guide both the selection and repair processes, balancing exploitation of high-value items with exploration through random perturbations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select bottom 30% solutions by combined objective score\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        combined_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        bottom_indices = np.argsort(combined_scores)[:max(1, len(archive) // 3)]\n        selected_idx = np.random.choice(bottom_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Targeted flipping of high-marginal-gain items with 70% probability\n    high_gain_indices = np.argsort(combined_gain)[::-1][:min(5, len(weight_lst))]\n    for idx in high_gain_indices:\n        if np.random.rand() < 0.7:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Controlled random perturbation of low-marginal-contribution items\n    if np.random.rand() < 0.4:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined marginal gain\n        removal_candidates = included_items[np.argsort(combined_gain[included_items])]\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.8346153441467599,
            0.2106742560863495
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select bottom 30% solutions by combined objective score\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        combined_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        bottom_indices = np.argsort(combined_scores)[:max(1, len(archive) // 3)]\n        selected_idx = np.random.choice(bottom_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Targeted flipping of high-marginal-gain items with 70% probability\n    high_gain_indices = np.argsort(combined_gain)[::-1][:min(5, len(weight_lst))]\n    for idx in high_gain_indices:\n        if np.random.rand() < 0.7:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Controlled random perturbation of low-marginal-contribution items\n    if np.random.rand() < 0.4:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined marginal gain\n        removal_candidates = included_items[np.argsort(combined_gain[included_items])]\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 5 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive based on combined objective scores, then performs a targeted local search by flipping high-marginal-gain items prioritizing the least dominated objective, followed by controlled random perturbations and adaptive feasibility repairs to ensure capacity constraints are met while maintaining solution diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by combined objective score\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        combined_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(combined_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains and dominance information\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Identify items that improve the least dominated objective\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    # Targeted flipping of high-marginal-gain items prioritizing least dominated objective\n    if least_dominated == 1:\n        target_gain = marginal_gain1\n    else:\n        target_gain = marginal_gain2\n\n    high_gain_indices = np.argsort(target_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation of low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined marginal gain\n        removal_candidates = included_items[np.argsort(combined_gain[included_items])]\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the top 20% of the archive (based on normalized objective sums) and applies a hybrid local search: first flipping high-marginal-gain items (prioritized by combined value-to-weight ratios) and then randomly flipping low-marginal-contribution items (with 30% probability), while ensuring feasibility through iterative removal of the lightest items if capacity is exceeded. The method balances exploitation (targeted flips) and exploration (random flips) while limiting iterations to 5-10 per solution.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    n_items = len(weight_lst)\n\n    # Targeted flipping of high-marginal-gain items\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    high_gain_indices = np.argsort(combined_gain)[::-1][:min(5, n_items)]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random flips of low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, n_items)]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive (based on normalized objective sums) and generates neighbors by flipping items with high marginal gains for both objectives, followed by 1-2 random feasible flips, while ensuring feasibility through iterative refinement by removing the lightest items when needed. It prioritizes items with combined high marginal gains for both objectives while maintaining diversity through random flips.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain-based flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add 1-2 random feasible flips\n    for _ in range(np.random.randint(1, 3)):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the ultra-optimized heuristic design for BI-KP (under 100 words):\n\n- **Keywords**: **Hypervolume, knee-point selection, marginal gain flips, adaptive perturbation, feasibility repair**\n- **Advice**: Select top 20% solutions by hypervolume, prioritize knee-points; flip items with highest marginal gains in either objective, then add 1-2 random flips; repair infeasible neighbors by removing least critical items; iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness; ignore feasibility checks after perturbations.\n- **Explanation**: Balances exploitation (knee-point selection) and exploration (marginal gain flips) while ensuring feasibility. Dominance-aware repairs prevent stagnation, and iterative refinement yields high-quality neighbors efficiently.\n\n*(Word count: ~50)*\n\n**Why this wins**:\n1. **Hypervolume + knee-point selection** ensures diversity and trade-off awareness.\n2. **Marginal gain + trade-off flips** prioritize items that improve either objective.\n3. **Adaptive perturbation** avoids premature convergence.\n4. **Feasibility-aware repair** guarantees valid neighbors.\n\nThis heuristic avoids pitfalls while leveraging multi-objective insights.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 184,
        "algorithm": "The algorithm selects promising solutions from the archive based on hypervolume contributions and knee-point analysis, then applies a hybrid local search that prioritizes flipping high-marginal-gain items in the least dominated objective while occasionally flipping low-marginal-gain items randomly, ensuring feasibility through iterative removal of least critical items. It balances exploitation and exploration by focusing on objective-specific gains while maintaining diversity through random perturbations. The method guarantees feasibility by dominance-aware repairs when needed.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hypervolume-based selection of top 20% solutions\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Calculate hypervolume contributions\n        sorted_indices = np.argsort(obj1_scores)\n        hypervolumes = np.zeros(len(archive))\n        ref_point = (max_obj1 * 1.1, max_obj2 * 1.1)\n        for i, idx in enumerate(sorted_indices):\n            current = archive[idx][1]\n            if i == 0:\n                hypervolumes[idx] = (ref_point[0] - current[0]) * (ref_point[1] - current[1])\n            else:\n                prev = archive[sorted_indices[i-1]][1]\n                hypervolumes[idx] = (current[0] - prev[0]) * (ref_point[1] - max(prev[1], current[1]))\n        top_indices = np.argsort(hypervolumes)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains and identify least dominated objective\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    # Targeted flipping of high-marginal-gain items prioritizing least dominated objective\n    if least_dominated == 1:\n        target_gain = marginal_gain1\n    else:\n        target_gain = marginal_gain2\n    high_gain_indices = np.argsort(target_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips of low-marginal-contribution items\n    combined_gain = marginal_gain1 + marginal_gain2\n    low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n    for _ in range(np.random.randint(1, 3)):\n        idx = np.random.choice(low_gain_indices)\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Feasibility repair by removing least critical items\n    while np.sum(new_solution * weight_lst) > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        # Remove items with lowest combined marginal gain\n        removal_candidates = included_items[np.argsort(combined_gain[included_items])]\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.828709074829948,
            0.2804678678512573
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hypervolume-based selection of top 20% solutions\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Calculate hypervolume contributions\n        sorted_indices = np.argsort(obj1_scores)\n        hypervolumes = np.zeros(len(archive))\n        ref_point = (max_obj1 * 1.1, max_obj2 * 1.1)\n        for i, idx in enumerate(sorted_indices):\n            current = archive[idx][1]\n            if i == 0:\n                hypervolumes[idx] = (ref_point[0] - current[0]) * (ref_point[1] - current[1])\n            else:\n                prev = archive[sorted_indices[i-1]][1]\n                hypervolumes[idx] = (current[0] - prev[0]) * (ref_point[1] - max(prev[1], current[1]))\n        top_indices = np.argsort(hypervolumes)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains and identify least dominated objective\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    # Targeted flipping of high-marginal-gain items prioritizing least dominated objective\n    if least_dominated == 1:\n        target_gain = marginal_gain1\n    else:\n        target_gain = marginal_gain2\n    high_gain_indices = np.argsort(target_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips of low-marginal-contribution items\n    combined_gain = marginal_gain1 + marginal_gain2\n    low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n    for _ in range(np.random.randint(1, 3)):\n        idx = np.random.choice(low_gain_indices)\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Feasibility repair by removing least critical items\n    while np.sum(new_solution * weight_lst) > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        # Remove items with lowest combined marginal gain\n        removal_candidates = included_items[np.argsort(combined_gain[included_items])]\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 5 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from the bottom 30% of the archive (based on normalized objective sums) and applies a targeted local search by prioritizing flips of low-marginal-gain items (based on value-to-weight ratios), followed by 2-3 random flips to escape local optima while ensuring feasibility through iterative refinement. The method balances exploitation (focused flips) with exploration (random flips) to improve solution quality.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select bottom 30% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        bottom_indices = np.argsort(normalized_scores)[:max(1, len(archive)//3)]\n        selected_idx = np.random.choice(bottom_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with low marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in low_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 2-3 random flips to escape local optima\n    num_random_flips = np.random.randint(2, 4)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive based on hypervolume contribution, then performs a targeted local search by flipping high-marginal-gain items while ensuring feasibility, followed by adaptive perturbation of low-contribution items to escape local optima. It balances exploitation (hypervolume-aware selection and high-gain flips) with exploration (adaptive perturbation and random flips) through iterative refinement and feasibility-aware repair. The selection prioritizes solutions with better hypervolume, while the local search intelligently modifies the solution by combining dominance-aware flipping, adaptive perturbation, and iterative refinement to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    def hypervolume(sol):\n        obj1, obj2 = sol[1]\n        return obj1 * obj2\n\n    hypervolumes = [hypervolume(sol) for sol in archive]\n    top_indices = np.argsort(hypervolumes)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:min(3, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: repair infeasible solutions\n    for _ in range(5):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm selects a knee-point solution from the Pareto front (balancing trade-offs between objectives) and applies a hybrid local search combining dominance-aware flipping (prioritizing items that improve the underrepresented objective) and diversity-aware perturbations (flipping items in underrepresented regions of the objective space), while ensuring feasibility through iterative removal of least critical items. The method intelligently balances exploration and exploitation by focusing on high-gain items and adaptive perturbations, with feasibility enforced by iterative weight adjustments.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select knee-point solution (balancing trade-offs)\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_obj1 = obj1_scores / max_obj1\n        normalized_obj2 = obj2_scores / max_obj2\n        distances = np.sqrt((1 - normalized_obj1)**2 + (1 - normalized_obj2)**2)\n        selected_idx = np.argmin(distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dominance-aware flipping (prioritize underrepresented objective)\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    if least_dominated == 1:\n        target_gain = value1_lst / (weight_lst + 1e-10)\n    else:\n        target_gain = value2_lst / (weight_lst + 1e-10)\n\n    high_gain_indices = np.argsort(target_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Diversity-aware perturbations (flip items in underrepresented regions)\n    if np.random.rand() < 0.3:\n        obj1_covered = np.sum(new_solution * value1_lst)\n        obj2_covered = np.sum(new_solution * value2_lst)\n        if obj1_covered < obj2_covered:\n            candidate_indices = np.where((value1_lst > value2_lst) & (new_solution == 0))[0]\n        else:\n            candidate_indices = np.where((value2_lst > value1_lst) & (new_solution == 0))[0]\n\n        if len(candidate_indices) > 0:\n            selected_idx = np.random.choice(candidate_indices)\n            if current_weight + weight_lst[selected_idx] <= capacity:\n                new_solution[selected_idx] = 1\n                current_weight += weight_lst[selected_idx]\n\n    # Iterative feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined marginal gain\n        combined_gain = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        remove_idx = included_items[np.argmin(combined_gain[included_items])]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s the ultra-optimized heuristic design for BI-KP (under 100 words):\n\n- **Keywords**: **Hypervolume, knee-point selection, marginal gain flips, adaptive perturbation, feasibility repair**\n- **Advice**: Select top 20% solutions by hypervolume, prioritize knee-points; flip items with highest marginal gains in either objective, then add 1-2 random flips; repair infeasible neighbors by removing least critical items; iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness; ignore feasibility checks after perturbations.\n- **Explanation**: Balances exploitation (knee-point selection) and exploration (marginal gain flips) while ensuring feasibility. Dominance-aware repairs prevent stagnation, and iterative refinement yields high-quality neighbors efficiently.\n\n*(Word count: ~50)*\n\n**Why this wins**:\n1. **Hypervolume + knee-point selection** ensures diversity and trade-off awareness.\n2. **Marginal gain + trade-off flips** prioritize items that improve either objective.\n3. **Adaptive perturbation** avoids premature convergence.\n4. **Feasibility-aware repair** guarantees valid neighbors.\n\nThis heuristic avoids pitfalls while leveraging multi-objective insights.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 185,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    def hypervolume(sol):\n        obj1, obj2 = sol[1]\n        return obj1 * obj2\n\n    hypervolumes = [hypervolume(sol) for sol in archive]\n    top_indices = np.argsort(hypervolumes)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive perturbation: flip 1-2 random items\n    num_random_flips = np.random.randint(1, 3)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Iterative feasibility repair\n    for _ in range(5):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin((value1_lst + value2_lst)[removable_items] / (weight_lst[removable_items] + 1e-10))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.6928655654075164,
            0.21595415472984314
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    def hypervolume(sol):\n        obj1, obj2 = sol[1]\n        return obj1 * obj2\n\n    hypervolumes = [hypervolume(sol) for sol in archive]\n    top_indices = np.argsort(hypervolumes)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive perturbation: flip 1-2 random items\n    num_random_flips = np.random.randint(1, 3)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Iterative feasibility repair\n    for _ in range(5):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin((value1_lst + value2_lst)[removable_items] / (weight_lst[removable_items] + 1e-10))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 7 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\nThe algorithm selects a random solution from the archive and performs a hybrid local search by swapping items with a focus on improving either objective while ensuring feasibility. It prioritizes swaps that increase at least one objective value and maintains the solution's weight within capacity. The method uses a value-to-weight ratio consideration to guide the swaps and limits the search to 10 attempts for efficiency.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: random swaps with value-to-weight ratio consideration\n    for _ in range(10):  # Number of attempts to find a feasible neighbor\n        # Select two random items\n        item1, item2 = np.random.choice(len(new_solution), size=2, replace=False)\n\n        # Calculate potential weight change\n        if new_solution[item1] == 1 and new_solution[item2] == 0:\n            delta_weight = weight_lst[item2] - weight_lst[item1]\n        elif new_solution[item1] == 0 and new_solution[item2] == 1:\n            delta_weight = weight_lst[item1] - weight_lst[item2]\n        else:\n            continue  # No change in weight\n\n        # Check feasibility\n        if current_weight + delta_weight <= capacity:\n            # Perform swap if it improves at least one objective\n            value1_delta = (value1_lst[item1] - value1_lst[item2]) if new_solution[item1] == 1 else (value1_lst[item2] - value1_lst[item1])\n            value2_delta = (value2_lst[item1] - value2_lst[item2]) if new_solution[item1] == 1 else (value2_lst[item2] - value2_lst[item1])\n\n            if value1_delta > 0 or value2_delta > 0:\n                new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n                current_weight += delta_weight\n                break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\nNo. 3 algorithm and the corresponding code are:\nThe algorithm selects a random solution from the archive and applies a hybrid local search strategy that prioritizes items with high marginal value (combined from both objectives) while ensuring feasibility, followed by random flips to explore diversity. It balances exploitation (targeting high-value items) with exploration (random perturbations) to generate improved neighbor solutions. The approach avoids standard local search methods like 2-opt by focusing on value-weighted flips and controlled randomness.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: Flip items based on marginal contribution and diversity\n    new_solution = base_solution.copy()\n\n    # Step 1: Identify items with high marginal contribution (value/weight ratio)\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Step 2: Flip items with high marginal contribution if feasible\n    for i in np.argsort(-combined_marginal):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Step 3: Randomly flip additional items to explore diversity\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    return new_solution\n\nNo. 4 algorithm and the corresponding code are:\nThe algorithm intelligently selects a non-dominated solution from the archive by prioritizing those with high marginal gains, then applies a hybrid local search combining probabilistic item flips and swaps to explore the solution space while ensuring feasibility. The selection is weighted probabilistically, favoring later entries in the archive, and the local search iteratively modifies the solution by flipping or swapping items, checking feasibility at each step. The key design ideas are prioritized selection and hybrid local search with feasibility checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution (prioritize those with high marginal gains)\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution, (base_value1, base_value2) = archive[selected_idx]\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Hybrid local search: probabilistic item flips and swaps\n    for _ in range(5):  # Number of local search iterations\n        # Probabilistic flip: flip a random item if feasible\n        flip_idx = np.random.randint(0, n_items)\n        if new_solution[flip_idx] == 1:\n            if np.sum(weight_lst[new_solution == 1] - weight_lst[flip_idx]) <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if np.sum(weight_lst[new_solution == 1] + weight_lst[flip_idx]) <= capacity:\n                new_solution[flip_idx] = 1\n\n        # Item swap: swap two random items if feasible\n        swap_idx1, swap_idx2 = np.random.choice(n_items, 2, replace=False)\n        if new_solution[swap_idx1] != new_solution[swap_idx2]:\n            if new_solution[swap_idx1] == 1:\n                if np.sum(weight_lst[new_solution == 1] - weight_lst[swap_idx1] + weight_lst[swap_idx2]) <= capacity:\n                    new_solution[swap_idx1] = 0\n                    new_solution[swap_idx2] = 1\n            else:\n                if np.sum(weight_lst[new_solution == 1] - weight_lst[swap_idx2] + weight_lst[swap_idx1]) <= capacity:\n                    new_solution[swap_idx1] = 1\n                    new_solution[swap_idx2] = 0\n\n    return new_solution\n\nNo. 5 algorithm and the corresponding code are:\nThe algorithm selects a random solution from the archive, applies a hybrid local search by flipping a small random subset of items (with feasibility checks), and then performs a greedy improvement step to add items that improve at least one objective. The design prioritizes diversity and local optimization while ensuring feasibility, using a combination of randomness and greedy selection to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    import random\n    import numpy as np\n\n    # Select a promising solution from the archive (here, we select a random one for diversity)\n    selected_solution, _ = random.choice(archive)\n    new_solution = selected_solution.copy()\n\n    # Apply a hybrid local search: flip a random subset of items and then perform a greedy improvement\n    num_items = len(new_solution)\n    flip_indices = random.sample(range(num_items), min(3, num_items))  # Flip up to 3 random items\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            # Only flip to 1 if it doesn't exceed capacity\n            current_weight = np.sum(new_solution * weight_lst)\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Greedy improvement: try to add items that improve at least one objective\n    for idx in range(num_items):\n        if new_solution[idx] == 0:\n            current_weight = np.sum(new_solution * weight_lst)\n            if current_weight + weight_lst[idx] <= capacity:\n                # Simulate adding the item\n                temp_solution = new_solution.copy()\n                temp_solution[idx] = 1\n                temp_value1 = np.sum(temp_solution * value1_lst)\n                temp_value2 = np.sum(temp_solution * value2_lst)\n                current_value1 = np.sum(new_solution * value1_lst)\n                current_value2 = np.sum(new_solution * value2_lst)\n\n                # Accept if at least one objective improves\n                if (temp_value1 > current_value1) or (temp_value2 > current_value2):\n                    new_solution[idx] = 1\n\n    return new_solution\n\nNo. 6 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive by weighting choices based on normalized objective values, then applies a hybrid local search that clusters items by value-to-weight ratios and correlation with the current solution's objectives, performing targeted flips and swaps within clusters while occasionally perturbing the solution to escape local optima. The selection prioritizes high-performing solutions, and the local search intelligently explores the neighborhood by focusing on cluster-specific improvements, ensuring feasibility and diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive (weighted by normalized objectives)\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.random.choice(len(archive), p=np.array(normalized_scores)/sum(normalized_scores))\n\n    base_solution, (base_obj1, base_obj2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Cluster items based on value-to-weight ratios and correlation with objectives\n    value_ratio1 = value1_lst / (weight_lst + 1e-10)\n    value_ratio2 = value2_lst / (weight_lst + 1e-10)\n    correlation = (value_ratio1 * base_obj1 + value_ratio2 * base_obj2) / (np.sqrt(value_ratio1**2 + value_ratio2**2) + 1e-10)\n\n    # Sort items by correlation and value ratios\n    sorted_indices = np.argsort(-correlation)\n    clusters = [sorted_indices[i:i+5] for i in range(0, len(sorted_indices), 5)]  # Create clusters of 5 items\n\n    # Hybrid local search: cluster-based flips and swaps\n    for cluster in clusters:\n        # Probabilistic flip within cluster\n        if np.random.rand() < 0.5:\n            flip_idx = np.random.choice(cluster)\n            if base_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n        # Probabilistic swap within cluster\n        if np.random.rand() < 0.3 and len(cluster) > 1:\n            swap_idx1, swap_idx2 = np.random.choice(cluster, 2, replace=False)\n            if new_solution[swap_idx1] != new_solution[swap_idx2]:\n                if new_solution[swap_idx1] == 1:\n                    if current_weight - weight_lst[swap_idx1] + weight_lst[swap_idx2] <= capacity:\n                        new_solution[swap_idx1] = 0\n                        new_solution[swap_idx2] = 1\n                else:\n                    if current_weight - weight_lst[swap_idx2] + weight_lst[swap_idx1] <= capacity:\n                        new_solution[swap_idx1] = 1\n                        new_solution[swap_idx2] = 0\n\n    # Occasional perturbation to escape local optima\n    if np.random.rand() < 0.2:\n        perturb_idx = np.random.randint(len(new_solution))\n        if new_solution[perturb_idx] == 1:\n            if current_weight - weight_lst[perturb_idx] <= capacity:\n                new_solution[perturb_idx] = 0\n        else:\n            if current_weight + weight_lst[perturb_idx] <= capacity:\n                new_solution[perturb_idx] = 1\n\n    return new_solution\n\nNo. 7 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive by weighting choices based on normalized objective values, then applies a hybrid local search that clusters items by value-to-weight ratios and correlation with the current solution's objectives, performing targeted flips and swaps within clusters while occasionally perturbing the solution to escape local optima. The selection prioritizes high-performing solutions, and the local search intelligently explores the neighborhood by focusing on cluster-specific improvements, ensuring feasibility and diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive (weighted by normalized objectives)\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.random.choice(len(archive), p=np.array(normalized_scores)/sum(normalized_scores))\n\n    base_solution, (base_obj1, base_obj2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Cluster items based on value-to-weight ratios and correlation with objectives\n    value_ratio1 = value1_lst / (weight_lst + 1e-10)\n    value_ratio2 = value2_lst / (weight_lst + 1e-10)\n    correlation = (value_ratio1 * base_obj1 + value_ratio2 * base_obj2) / (np.sqrt(value_ratio1**2 + value_ratio2**2) + 1e-10)\n\n    # Sort items by correlation and value ratios\n    sorted_indices = np.argsort(-correlation)\n    clusters = [sorted_indices[i:i+5] for i in range(0, len(sorted_indices), 5)]  # Create clusters of 5 items\n\n    # Hybrid local search: cluster-based flips and swaps\n    for cluster in clusters:\n        # Probabilistic flip within cluster\n        if np.random.rand() < 0.5:\n            flip_idx = np.random.choice(cluster)\n            if base_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n        # Probabilistic swap within cluster\n        if np.random.rand() < 0.3 and len(cluster) > 1:\n            swap_idx1, swap_idx2 = np.random.choice(cluster, 2, replace=False)\n            if new_solution[swap_idx1] != new_solution[swap_idx2]:\n                if new_solution[swap_idx1] == 1:\n                    if current_weight - weight_lst[swap_idx1] + weight_lst[swap_idx2] <= capacity:\n                        new_solution[swap_idx1] = 0\n                        new_solution[swap_idx2] = 1\n                else:\n                    if current_weight - weight_lst[swap_idx2] + weight_lst[swap_idx1] <= capacity:\n                        new_solution[swap_idx1] = 1\n                        new_solution[swap_idx2] = 0\n\n    # Occasional perturbation to escape local optima\n    if np.random.rand() < 0.2:\n        perturb_idx = np.random.randint(len(new_solution))\n        if new_solution[perturb_idx] == 1:\n            if current_weight - weight_lst[perturb_idx] <= capacity:\n                new_solution[perturb_idx] = 0\n        else:\n            if current_weight + weight_lst[perturb_idx] <= capacity:\n                new_solution[perturb_idx] = 1\n\n    return new_solution\n\n\n\nAnalyze the logic of all the given code snippets carefully. Then identify the two code snippets whose logic is most different from each other\nand create a new algorithm that totally different in logic and form from both of them.\n1. First, describe your new algorithm and main steps in one long, detail sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 186,
        "algorithm": "The algorithm selects a solution from the archive by identifying the most underrepresented objective (value1 or value2) and prioritizes flipping items with high marginal contribution to that objective while ensuring feasibility. It then perturbs low-contribution items to balance both objectives, with a 20% random chance per item. The selection is based on objective imbalance, and the local search intelligently modifies the solution by prioritizing high-marginal-gain flips and targeted perturbations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Identify the most underrepresented objective in the archive\n    obj1_sum = sum(obj[0] for _, obj in archive)\n    obj2_sum = sum(obj[1] for _, obj in archive)\n    if obj1_sum < obj2_sum:\n        target_objective = 1  # Focus on improving value1\n    else:\n        target_objective = 2  # Focus on improving value2\n\n    # Select the solution with the highest value in the underrepresented objective\n    if target_objective == 1:\n        selected_idx = np.argmax([obj[0] for _, obj in archive])\n    else:\n        selected_idx = np.argmax([obj[1] for _, obj in archive])\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal contributions for the target objective\n    if target_objective == 1:\n        marginal_contribution = value1_lst / (weight_lst + 1e-10)\n    else:\n        marginal_contribution = value2_lst / (weight_lst + 1e-10)\n\n    # Flip items with high marginal contribution for the target objective\n    for i in np.argsort(-marginal_contribution):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1 and (current_weight - weight_lst[i]) >= 0:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Perturb items with low marginal contribution to balance objectives\n    combined_marginal = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n    low_contrib_indices = np.argsort(combined_marginal)[:max(1, len(combined_marginal) // 4)]\n    for i in low_contrib_indices:\n        if np.random.rand() < 0.2:  # 20% chance to perturb each low-contribution item\n            if base_solution[i] == 1 and (current_weight - weight_lst[i]) >= 0:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n            elif base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.8117253732035081,
            0.45941802859306335
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Identify the most underrepresented objective in the archive\n    obj1_sum = sum(obj[0] for _, obj in archive)\n    obj2_sum = sum(obj[1] for _, obj in archive)\n    if obj1_sum < obj2_sum:\n        target_objective = 1  # Focus on improving value1\n    else:\n        target_objective = 2  # Focus on improving value2\n\n    # Select the solution with the highest value in the underrepresented objective\n    if target_objective == 1:\n        selected_idx = np.argmax([obj[0] for _, obj in archive])\n    else:\n        selected_idx = np.argmax([obj[1] for _, obj in archive])\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal contributions for the target objective\n    if target_objective == 1:\n        marginal_contribution = value1_lst / (weight_lst + 1e-10)\n    else:\n        marginal_contribution = value2_lst / (weight_lst + 1e-10)\n\n    # Flip items with high marginal contribution for the target objective\n    for i in np.argsort(-marginal_contribution):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1 and (current_weight - weight_lst[i]) >= 0:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Perturb items with low marginal contribution to balance objectives\n    combined_marginal = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n    low_contrib_indices = np.argsort(combined_marginal)[:max(1, len(combined_marginal) // 4)]\n    for i in low_contrib_indices:\n        if np.random.rand() < 0.2:  # 20% chance to perturb each low-contribution item\n            if base_solution[i] == 1 and (current_weight - weight_lst[i]) >= 0:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n            elif base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    return new_solution\n\n",
        "operation": "e1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects knee-point solutions from the archive based on hypervolume contribution, then applies targeted flips of high-marginal-gain items in either objective, followed by 1-2 random flips to escape local optima, while ensuring feasibility through iterative repair by removing the least critical items. It prioritizes items with balanced gains in both objectives and uses marginal contributions to guide the repair process.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select knee-point solutions by hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    knee_indices = np.argsort(hypervolume)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(knee_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Targeted flips: prioritize items with high marginal gains in either objective\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Adaptive perturbation: 1-2 random flips\n    num_random_flips = np.random.randint(1, 3)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative repair: remove least critical items if infeasible\n    for _ in range(5):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with lowest marginal contribution to either objective\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        remove_idx = removable_items[np.argmin(marginal_contribution[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive using a dynamic weighted sum of objectives (prioritizing value1 at 70% and value2 at 30%), then applies a hybrid local search combining greedy flips for top marginal-gain items and probabilistic swaps, while maintaining feasibility through a multi-criteria removal strategy that balances value-weight ratios and weight penalties. The search adapts exploration/exploitation based on current solution utilization, favoring marginal gains in underutilized knapsacks and probabilistic swaps in overutilized ones.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions using dynamic weighted objective sum\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Dynamic weighting based on solution quality diversity\n        quality_diversity = np.std(obj1_scores) + np.std(obj2_scores)\n        weight1 = 0.7 - 0.1 * (quality_diversity / (max_obj1 + max_obj2 + 1e-10))\n        weight2 = 1 - weight1\n        normalized_scores = (weight1 * obj1_scores / max_obj1) + (weight2 * obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n    current_utilization = current_weight / capacity\n\n    # Hybrid local search with marginal gain and probabilistic swaps\n    # Calculate utilization-aware marginal gains\n    utilization_factor = 1 - (current_utilization ** 2)\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = (utilization_factor * marginal_gain1) + ((1 - utilization_factor) * marginal_gain2)\n\n    # Greedy flips for top 5 items\n    sorted_indices = np.argsort(combined_gain)[::-1]\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Probabilistic swaps based on marginal gains\n    swap_prob = 0.3 * (1 - current_utilization)\n    for idx in range(n_items):\n        if np.random.random() < swap_prob:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Multi-criteria feasibility maintenance\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n\n        if len(removable_items) == 0:\n            break\n\n        # Remove items with lowest value-weight ratio or highest weight\n        value_weight_ratio = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        weight_penalty = weight_lst[removable_items] / capacity\n        removal_score = value_weight_ratio - 2 * weight_penalty\n        remove_idx = removable_items[np.argmin(removal_score)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the ultra-optimized heuristic design for BI-KP (under 100 words):\n\n- **Keywords**: **Hypervolume, knee-point selection, marginal gain flips, adaptive perturbation, feasibility repair**\n- **Advice**: Select top 20% solutions by hypervolume, prioritize knee-points; flip items with highest marginal gains in either objective, then add 1-2 random flips; repair infeasible neighbors by removing least critical items; iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness; ignore feasibility checks after perturbations.\n- **Explanation**: Balances exploitation (knee-point selection) and exploration (marginal gain flips) while ensuring feasibility. Dominance-aware repairs prevent stagnation, and iterative refinement yields high-quality neighbors efficiently.\n\n*(Word count: ~50)*\n\n**Why this wins**:\n1. **Hypervolume + knee-point selection** ensures diversity and trade-off awareness.\n2. **Marginal gain + trade-off flips** prioritize items that improve either objective.\n3. **Adaptive perturbation** avoids premature convergence.\n4. **Feasibility-aware repair** guarantees valid neighbors.\n\nThis heuristic avoids pitfalls while leveraging multi-objective insights.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 187,
        "algorithm": "The algorithm combines knee-point selection with hypervolume contribution to identify promising solutions, then applies a two-phase local search: first flipping items with highest marginal gains in either objective while maintaining feasibility, followed by targeted perturbations that swap items between objectives based on relative marginal contributions, with dynamic repair to ensure feasibility. It prioritizes items with maximum combined marginal gain in the first phase and those with significantly higher relative gains in the second, while dynamically removing least valuable items to restore feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select knee-point solutions by hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    knee_indices = np.argsort(hypervolume)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(knee_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Phase 1: Flip items with highest marginal gains in either objective\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n    sorted_indices = np.argsort(-combined_gain)\n\n    for idx in sorted_indices:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Phase 2: Targeted perturbation - swap items between objectives\n    # Calculate relative marginal gains\n    relative_gain1 = marginal_gain1 / (marginal_gain2 + 1e-10)\n    relative_gain2 = marginal_gain2 / (marginal_gain1 + 1e-10)\n\n    # Identify items to swap: those where one objective's marginal gain is significantly higher\n    swap_candidates = np.where((relative_gain1 > 1.5) | (relative_gain2 > 1.5))[0]\n\n    if len(swap_candidates) > 0:\n        swap_idx = np.random.choice(swap_candidates)\n        # Determine which objective's item is better to swap\n        if relative_gain1[swap_idx] > 1.5:\n            # Swap to maximize objective 1\n            if base_solution[swap_idx] == 1 and current_weight - weight_lst[swap_idx] + weight_lst[swap_idx] <= capacity:\n                # No weight change, just swap\n                new_solution[swap_idx] = 1 - new_solution[swap_idx]\n        elif relative_gain2[swap_idx] > 1.5:\n            # Swap to maximize objective 2\n            if base_solution[swap_idx] == 1 and current_weight - weight_lst[swap_idx] + weight_lst[swap_idx] <= capacity:\n                # No weight change, just swap\n                new_solution[swap_idx] = 1 - new_solution[swap_idx]\n\n    # Dynamic repair: remove items with least combined marginal gain if infeasible\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n\n        if len(removable_items) == 0:\n            break\n\n        # Calculate combined marginal gain for removable items\n        combined_marginal = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(combined_marginal)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8438408066608891,
            0.5108509063720703
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select knee-point solutions by hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    knee_indices = np.argsort(hypervolume)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(knee_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Phase 1: Flip items with highest marginal gains in either objective\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n    sorted_indices = np.argsort(-combined_gain)\n\n    for idx in sorted_indices:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Phase 2: Targeted perturbation - swap items between objectives\n    # Calculate relative marginal gains\n    relative_gain1 = marginal_gain1 / (marginal_gain2 + 1e-10)\n    relative_gain2 = marginal_gain2 / (marginal_gain1 + 1e-10)\n\n    # Identify items to swap: those where one objective's marginal gain is significantly higher\n    swap_candidates = np.where((relative_gain1 > 1.5) | (relative_gain2 > 1.5))[0]\n\n    if len(swap_candidates) > 0:\n        swap_idx = np.random.choice(swap_candidates)\n        # Determine which objective's item is better to swap\n        if relative_gain1[swap_idx] > 1.5:\n            # Swap to maximize objective 1\n            if base_solution[swap_idx] == 1 and current_weight - weight_lst[swap_idx] + weight_lst[swap_idx] <= capacity:\n                # No weight change, just swap\n                new_solution[swap_idx] = 1 - new_solution[swap_idx]\n        elif relative_gain2[swap_idx] > 1.5:\n            # Swap to maximize objective 2\n            if base_solution[swap_idx] == 1 and current_weight - weight_lst[swap_idx] + weight_lst[swap_idx] <= capacity:\n                # No weight change, just swap\n                new_solution[swap_idx] = 1 - new_solution[swap_idx]\n\n    # Dynamic repair: remove items with least combined marginal gain if infeasible\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n\n        if len(removable_items) == 0:\n            break\n\n        # Calculate combined marginal gain for removable items\n        combined_marginal = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(combined_marginal)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects promising solutions from the top 20% of the archive based on combined objective scores, then performs a targeted local search by flipping high-marginal-gain items prioritizing the least dominated objective, followed by controlled random perturbations and adaptive feasibility repairs to ensure capacity constraints are met while maintaining solution diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by combined objective score\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        combined_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(combined_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains and dominance information\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Identify items that improve the least dominated objective\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    # Targeted flipping of high-marginal-gain items prioritizing least dominated objective\n    if least_dominated == 1:\n        target_gain = marginal_gain1\n    else:\n        target_gain = marginal_gain2\n\n    high_gain_indices = np.argsort(target_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation of low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined marginal gain\n        removal_candidates = included_items[np.argsort(combined_gain[included_items])]\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects top 20% solutions from the archive using a dynamic weighted sum of objectives (prioritizing value1 at 70% and value2 at 30%), then applies a hybrid local search combining greedy flips for top marginal-gain items and probabilistic swaps, while maintaining feasibility through a multi-criteria removal strategy that balances value-weight ratios and weight penalties. The search adapts exploration/exploitation based on current solution utilization, favoring marginal gains in underutilized knapsacks and probabilistic swaps in overutilized ones.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions using dynamic weighted objective sum\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Dynamic weighting based on solution quality diversity\n        quality_diversity = np.std(obj1_scores) + np.std(obj2_scores)\n        weight1 = 0.7 - 0.1 * (quality_diversity / (max_obj1 + max_obj2 + 1e-10))\n        weight2 = 1 - weight1\n        normalized_scores = (weight1 * obj1_scores / max_obj1) + (weight2 * obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n    current_utilization = current_weight / capacity\n\n    # Hybrid local search with marginal gain and probabilistic swaps\n    # Calculate utilization-aware marginal gains\n    utilization_factor = 1 - (current_utilization ** 2)\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = (utilization_factor * marginal_gain1) + ((1 - utilization_factor) * marginal_gain2)\n\n    # Greedy flips for top 5 items\n    sorted_indices = np.argsort(combined_gain)[::-1]\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Probabilistic swaps based on marginal gains\n    swap_prob = 0.3 * (1 - current_utilization)\n    for idx in range(n_items):\n        if np.random.random() < swap_prob:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Multi-criteria feasibility maintenance\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n\n        if len(removable_items) == 0:\n            break\n\n        # Remove items with lowest value-weight ratio or highest weight\n        value_weight_ratio = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        weight_penalty = weight_lst[removable_items] / capacity\n        removal_score = value_weight_ratio - 2 * weight_penalty\n        remove_idx = removable_items[np.argmin(removal_score)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the ultra-optimized heuristic design for BI-KP (under 100 words):\n\n- **Keywords**: **Hypervolume, knee-point selection, marginal gain flips, adaptive perturbation, feasibility repair**\n- **Advice**: Select top 20% solutions by hypervolume, prioritize knee-points; flip items with highest marginal gains in either objective, then add 1-2 random flips; repair infeasible neighbors by removing least critical items; iterate 5-10 times per solution.\n- **Avoid**: Overly aggressive flipping or pure randomness; ignore feasibility checks after perturbations.\n- **Explanation**: Balances exploitation (knee-point selection) and exploration (marginal gain flips) while ensuring feasibility. Dominance-aware repairs prevent stagnation, and iterative refinement yields high-quality neighbors efficiently.\n\n*(Word count: ~50)*\n\n**Why this wins**:\n1. **Hypervolume + knee-point selection** ensures diversity and trade-off awareness.\n2. **Marginal gain + trade-off flips** prioritize items that improve either objective.\n3. **Adaptive perturbation** avoids premature convergence.\n4. **Feasibility-aware repair** guarantees valid neighbors.\n\nThis heuristic avoids pitfalls while leveraging multi-objective insights.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 188,
        "algorithm": "The algorithm selects promising solutions from the archive by prioritizing those with high hypervolume contribution (top 20%) and identifies knee points to guide local search. It then flips items with high marginal gains in either objective, applies controlled random perturbations to low-contribution items, and ensures feasibility through dominance-aware repairs by removing items with the least impact on the least dominated objective. The approach balances exploitation of high-quality regions with exploration of marginal gains while maintaining feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Calculate hypervolume contribution (approximated by product of normalized objectives)\n        hypervolume = (obj1_scores / max_obj1) * (obj2_scores / max_obj2)\n        top_indices = np.argsort(hypervolume)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Identify knee-point (solution closest to ideal point in objective space)\n    ideal_point = (max_obj1, max_obj2)\n    distances = np.sqrt(((obj1_scores - ideal_point[0]) / (ideal_point[0] + 1e-10))**2 +\n                        ((obj2_scores - ideal_point[1]) / (ideal_point[1] + 1e-10))**2)\n    knee_idx = np.argmin(distances)\n    knee_solution = archive[knee_idx][0]\n\n    # Calculate marginal gains and identify items to flip\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Prioritize flipping items that improve either objective\n    for idx in np.argsort(marginal_gain1 + marginal_gain2)[::-1][:min(3, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Controlled random perturbation of low-contribution items\n    if np.random.rand() < 0.3:\n        low_contrib_indices = np.where(base_solution != knee_solution)[0]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Dominance-aware feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Remove items with least impact on least dominated objective\n        obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n        obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n        least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n        if least_dominated == 1:\n            removal_candidates = included_items[np.argsort(marginal_gain1[included_items])]\n        else:\n            removal_candidates = included_items[np.argsort(marginal_gain2[included_items])]\n\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.8733098348753503,
            0.25799328088760376
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Calculate hypervolume contribution (approximated by product of normalized objectives)\n        hypervolume = (obj1_scores / max_obj1) * (obj2_scores / max_obj2)\n        top_indices = np.argsort(hypervolume)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Identify knee-point (solution closest to ideal point in objective space)\n    ideal_point = (max_obj1, max_obj2)\n    distances = np.sqrt(((obj1_scores - ideal_point[0]) / (ideal_point[0] + 1e-10))**2 +\n                        ((obj2_scores - ideal_point[1]) / (ideal_point[1] + 1e-10))**2)\n    knee_idx = np.argmin(distances)\n    knee_solution = archive[knee_idx][0]\n\n    # Calculate marginal gains and identify items to flip\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Prioritize flipping items that improve either objective\n    for idx in np.argsort(marginal_gain1 + marginal_gain2)[::-1][:min(3, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Controlled random perturbation of low-contribution items\n    if np.random.rand() < 0.3:\n        low_contrib_indices = np.where(base_solution != knee_solution)[0]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Dominance-aware feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Remove items with least impact on least dominated objective\n        obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n        obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n        least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n        if least_dominated == 1:\n            removal_candidates = included_items[np.argsort(marginal_gain1[included_items])]\n        else:\n            removal_candidates = included_items[np.argsort(marginal_gain2[included_items])]\n\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects top 20% solutions from the archive using a dynamic weighted sum of objectives (prioritizing value1 at 70% and value2 at 30%), then applies a hybrid local search combining greedy flips for top marginal-gain items and probabilistic swaps, while maintaining feasibility through a multi-criteria removal strategy that balances value-weight ratios and weight penalties. The search adapts exploration/exploitation based on current solution utilization, favoring marginal gains in underutilized knapsacks and probabilistic swaps in overutilized ones.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions using dynamic weighted objective sum\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Dynamic weighting based on solution quality diversity\n        quality_diversity = np.std(obj1_scores) + np.std(obj2_scores)\n        weight1 = 0.7 - 0.1 * (quality_diversity / (max_obj1 + max_obj2 + 1e-10))\n        weight2 = 1 - weight1\n        normalized_scores = (weight1 * obj1_scores / max_obj1) + (weight2 * obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n    current_utilization = current_weight / capacity\n\n    # Hybrid local search with marginal gain and probabilistic swaps\n    # Calculate utilization-aware marginal gains\n    utilization_factor = 1 - (current_utilization ** 2)\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = (utilization_factor * marginal_gain1) + ((1 - utilization_factor) * marginal_gain2)\n\n    # Greedy flips for top 5 items\n    sorted_indices = np.argsort(combined_gain)[::-1]\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Probabilistic swaps based on marginal gains\n    swap_prob = 0.3 * (1 - current_utilization)\n    for idx in range(n_items):\n        if np.random.random() < swap_prob:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Multi-criteria feasibility maintenance\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n\n        if len(removable_items) == 0:\n            break\n\n        # Remove items with lowest value-weight ratio or highest weight\n        value_weight_ratio = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        weight_penalty = weight_lst[removable_items] / capacity\n        removal_score = value_weight_ratio - 2 * weight_penalty\n        remove_idx = removable_items[np.argmin(removal_score)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 189,
        "algorithm": "This algorithm selects promising solutions from the archive using an adaptive weighting scheme that prioritizes objectives based on their balance in the archive, then applies a hybrid local search combining value-weighted flips, probabilistic swaps, and a dynamic removal strategy to generate neighbors while maintaining feasibility through utilization-aware penalties. The method emphasizes high-value items, balances exploration with exploitation via probabilistic swaps, and ensures feasibility by removing low-value items with high utilization penalties when necessary.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions using adaptive objective weighting\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Adaptive weighting based on objective balance in archive\n        archive_balance = np.mean(obj1_scores) / (np.mean(obj1_scores) + np.mean(obj2_scores) + 1e-10)\n        weight1 = 0.6 - 0.2 * archive_balance\n        weight2 = 1 - weight1\n        normalized_scores = (weight1 * obj1_scores / max_obj1) + (weight2 * obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n    current_utilization = current_weight / capacity\n\n    # Calculate adaptive marginal gains\n    obj1_ratio = value1_lst / (weight_lst + 1e-10)\n    obj2_ratio = value2_lst / (weight_lst + 1e-10)\n    combined_ratio = (obj1_ratio + obj2_ratio) / 2\n\n    # Value-weighted flips for top 10 items\n    sorted_indices = np.argsort(combined_ratio)[::-1]\n    for idx in sorted_indices[:min(10, n_items)]:\n        flip_value = (value1_lst[idx] + value2_lst[idx]) * (1 - current_utilization)\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            if flip_value > 0:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            if flip_value > 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Probabilistic swaps with dynamic probability\n    swap_prob = 0.4 * (1 - current_utilization) + 0.1 * (current_utilization > 0.8)\n    for idx in range(n_items):\n        if np.random.random() < swap_prob:\n            swap_value = (value1_lst[idx] + value2_lst[idx]) * (1 - current_utilization)\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                if swap_value > 0:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                if swap_value > 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n\n    # Dynamic removal strategy\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n\n        if len(removable_items) == 0:\n            break\n\n        # Remove items with lowest combined value-weight ratio and highest utilization penalty\n        value_ratio = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        utilization_penalty = weight_lst[removable_items] / (capacity * (1 - current_utilization + 1e-10))\n        removal_score = value_ratio - 1.5 * utilization_penalty\n        remove_idx = removable_items[np.argmin(removal_score)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.35194557279384237,
            0.526778906583786
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions using adaptive objective weighting\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Adaptive weighting based on objective balance in archive\n        archive_balance = np.mean(obj1_scores) / (np.mean(obj1_scores) + np.mean(obj2_scores) + 1e-10)\n        weight1 = 0.6 - 0.2 * archive_balance\n        weight2 = 1 - weight1\n        normalized_scores = (weight1 * obj1_scores / max_obj1) + (weight2 * obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n    current_utilization = current_weight / capacity\n\n    # Calculate adaptive marginal gains\n    obj1_ratio = value1_lst / (weight_lst + 1e-10)\n    obj2_ratio = value2_lst / (weight_lst + 1e-10)\n    combined_ratio = (obj1_ratio + obj2_ratio) / 2\n\n    # Value-weighted flips for top 10 items\n    sorted_indices = np.argsort(combined_ratio)[::-1]\n    for idx in sorted_indices[:min(10, n_items)]:\n        flip_value = (value1_lst[idx] + value2_lst[idx]) * (1 - current_utilization)\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            if flip_value > 0:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            if flip_value > 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Probabilistic swaps with dynamic probability\n    swap_prob = 0.4 * (1 - current_utilization) + 0.1 * (current_utilization > 0.8)\n    for idx in range(n_items):\n        if np.random.random() < swap_prob:\n            swap_value = (value1_lst[idx] + value2_lst[idx]) * (1 - current_utilization)\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                if swap_value > 0:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                if swap_value > 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n\n    # Dynamic removal strategy\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n\n        if len(removable_items) == 0:\n            break\n\n        # Remove items with lowest combined value-weight ratio and highest utilization penalty\n        value_ratio = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        utilization_penalty = weight_lst[removable_items] / (capacity * (1 - current_utilization + 1e-10))\n        removal_score = value_ratio - 1.5 * utilization_penalty\n        remove_idx = removable_items[np.argmin(removal_score)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "m1"
    }
]