[
    {
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7633290724762323,
            0.17913395166397095
        ]
    },
    {
        "algorithm": "The algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.8399822123976359,
            0.2032187581062317
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9223724891724746,
            0.21610364317893982
        ]
    },
    {
        "algorithm": "The algorithm selects the solution with the highest hypervolume contribution from the archive, then applies a hybrid local search combining marginal-gain-based flips with an objective-balanced mechanism that prioritizes items with high combined marginal gains and balanced trade-offs between objectives. It dynamically scales the number of random flips based on the solution's distance to the ideal point and ensures feasibility through a trade-off-aware removal process that eliminates items with the poorest trade-offs between objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    selected_idx = np.argmax(hypervolume)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Objective-balanced flipping mechanism\n    trade_off = value2_lst / (value1_lst + 1e-10)\n    combined_score = (marginal_gain1 + marginal_gain2) * (1 + 0.5 * np.abs(trade_off - np.mean(trade_off)))\n    sorted_indices = np.argsort(combined_score)[::-1]\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (scaled by distance to ideal point)\n    distance_to_ideal = np.linalg.norm(ideal_point - objectives[selected_idx])\n    n_random_flips = max(1, int(5 * (1 / (distance_to_ideal + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Trade-off-aware feasibility restoration\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with poorest trade-off\n        item_trade_off = value2_lst[removable_items] / (value1_lst[removable_items] + 1e-10)\n        avg_trade_off = np.mean(item_trade_off)\n        remove_idx = removable_items[np.argmax(np.abs(item_trade_off - avg_trade_off))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9386445648038064,
            0.23346582055091858
        ]
    },
    {
        "algorithm": "The algorithm selects promising solutions from the bottom 30% of the archive (based on normalized objective sums) and applies a targeted local search by prioritizing flips of low-marginal-gain items (based on value-to-weight ratios), followed by 2-3 random flips to escape local optima while ensuring feasibility through iterative refinement. The method balances exploitation (focused flips) with exploration (random flips) to improve solution quality.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select bottom 30% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        bottom_indices = np.argsort(normalized_scores)[:max(1, len(archive)//3)]\n        selected_idx = np.random.choice(bottom_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with low marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in low_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 2-3 random flips to escape local optima\n    num_random_flips = np.random.randint(2, 4)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.9063371563927572,
            0.20811793208122253
        ]
    },
    {
        "algorithm": "The algorithm selects promising solutions from the top 20% of the archive based on hypervolume contribution, then performs a targeted local search by flipping high-marginal-gain items while ensuring feasibility, followed by adaptive perturbation of low-contribution items to escape local optima. It balances exploitation (hypervolume-aware selection and high-gain flips) with exploration (adaptive perturbation and random flips) through iterative refinement and feasibility-aware repair. The selection prioritizes solutions with better hypervolume, while the local search intelligently modifies the solution by combining dominance-aware flipping, adaptive perturbation, and iterative refinement to improve both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    def hypervolume(sol):\n        obj1, obj2 = sol[1]\n        return obj1 * obj2\n\n    hypervolumes = [hypervolume(sol) for sol in archive]\n    top_indices = np.argsort(hypervolumes)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:min(3, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: repair infeasible solutions\n    for _ in range(5):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8094458658682218,
            0.1887216567993164
        ]
    },
    {
        "algorithm": "The algorithm selects from the top 20% of non-dominated solutions (weighted equally on normalized objectives) and performs a local search by flipping high-gain items (60% prioritizing value1, 40% prioritizing value2) while occasionally perturbing low-gain items (30% probability) to balance exploration and exploitation, always ensuring feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by equally weighted normalized objectives\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.5 * obj[0]/max_obj1 + 0.5 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Local search: flip items with highest combined gain (60% value1, 40% value2)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.6 * marginal_gain1 + 0.4 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-gain items with 30% probability\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7786288219507125,
            0.20604312419891357
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9295394386064582,
            0.5756343901157379
        ]
    },
    {
        "algorithm": "The algorithm selects the solution with the highest hypervolume contribution from the archive and generates a neighbor by first applying a targeted flip mechanism prioritizing items with high combined marginal gains and balanced trade-offs, then performing adaptive random flips scaled by the solution's quality and distance to the ideal point, and finally ensuring feasibility through a trade-off-aware removal process that eliminates items with the poorest trade-offs. The combined score (70% marginal gains, 30% trade-offs) guides flips, while random flips are dynamically adjusted based on solution quality and ideal distance.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    selected_idx = np.argmax(hypervolume)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate normalized marginal gains and trade-offs\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    trade_off = value2_lst / (value1_lst + 1e-10)\n\n    # Objective-balanced flipping mechanism with adaptive weighting\n    alpha = 0.7  # Weight for marginal gains\n    beta = 0.3   # Weight for trade-off balance\n    combined_score = alpha * (marginal_gain1 + marginal_gain2) + beta * (1 / (trade_off + 1e-10))\n    sorted_indices = np.argsort(combined_score)[::-1]\n\n    # Perform targeted flips based on combined score\n    for idx in sorted_indices[:min(7, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (scaled by distance to ideal point and current solution quality)\n    distance_to_ideal = np.linalg.norm(ideal_point - objectives[selected_idx])\n    current_quality = np.sum(objectives[selected_idx]) / np.sum(ideal_point)\n    n_random_flips = max(1, int(7 * (1 - current_quality) * (1 / (distance_to_ideal + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Trade-off-aware feasibility restoration with adaptive removal\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n\n        # Calculate removal impact score (trade-off deviation + weight contribution)\n        item_trade_off = value2_lst[removable_items] / (value1_lst[removable_items] + 1e-10)\n        avg_trade_off = np.mean(item_trade_off)\n        trade_off_dev = np.abs(item_trade_off - avg_trade_off)\n        weight_contrib = weight_lst[removable_items] / excess\n        removal_score = trade_off_dev + 0.5 * weight_contrib\n\n        remove_idx = removable_items[np.argmax(removal_score)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8880044358873276,
            0.23827174305915833
        ]
    },
    {
        "algorithm": "The algorithm selects promising solutions from the top 20% of the archive based on combined objective scores, then performs a targeted local search by flipping high-marginal-gain items prioritizing the least dominated objective, followed by controlled random perturbations and adaptive feasibility repairs to ensure capacity constraints are met while maintaining solution diversity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by combined objective score\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        combined_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(combined_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains and dominance information\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Identify items that improve the least dominated objective\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    # Targeted flipping of high-marginal-gain items prioritizing least dominated objective\n    if least_dominated == 1:\n        target_gain = marginal_gain1\n    else:\n        target_gain = marginal_gain2\n\n    high_gain_indices = np.argsort(target_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation of low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined marginal gain\n        removal_candidates = included_items[np.argsort(combined_gain[included_items])]\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.8483212636259411,
            0.21432334184646606
        ]
    }
]