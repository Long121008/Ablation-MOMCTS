[
    {
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7633290724762323,
            0.17913395166397095
        ]
    },
    {
        "algorithm": "The algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.8399822123976359,
            0.2032187581062317
        ]
    },
    {
        "algorithm": "The algorithm selects promising solutions from the bottom 30% of the archive (based on normalized objective sums) and applies a targeted local search by prioritizing flips of low-marginal-gain items (based on value-to-weight ratios), followed by 2-3 random flips to escape local optima while ensuring feasibility through iterative refinement. The method balances exploitation (focused flips) with exploration (random flips) to improve solution quality.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select bottom 30% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        bottom_indices = np.argsort(normalized_scores)[:max(1, len(archive)//3)]\n        selected_idx = np.random.choice(bottom_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with low marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in low_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 2-3 random flips to escape local optima\n    num_random_flips = np.random.randint(2, 4)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.9063371563927572,
            0.20811793208122253
        ]
    },
    {
        "algorithm": "The algorithm selects promising solutions from the top 20% of the archive based on hypervolume contribution, then performs a targeted local search by flipping high-marginal-gain items while ensuring feasibility, followed by adaptive perturbation of low-contribution items to escape local optima. It balances exploitation (hypervolume-aware selection and high-gain flips) with exploration (adaptive perturbation and random flips) through iterative refinement and feasibility-aware repair. The selection prioritizes solutions with better hypervolume, while the local search intelligently modifies the solution by combining dominance-aware flipping, adaptive perturbation, and iterative refinement to improve both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by hypervolume contribution\n    def hypervolume(sol):\n        obj1, obj2 = sol[1]\n        return obj1 * obj2\n\n    hypervolumes = [hypervolume(sol) for sol in archive]\n    top_indices = np.argsort(hypervolumes)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:min(3, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: repair infeasible solutions\n    for _ in range(5):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8094458658682218,
            0.1887216567993164
        ]
    },
    {
        "algorithm": "The algorithm selects a knee-point solution from the Pareto front (balancing trade-offs between objectives) and applies a hybrid local search combining dominance-aware flipping (prioritizing items that improve the underrepresented objective) and diversity-aware perturbations (flipping items in underrepresented regions of the objective space), while ensuring feasibility through iterative removal of least critical items. The method intelligently balances exploration and exploitation by focusing on high-gain items and adaptive perturbations, with feasibility enforced by iterative weight adjustments.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select knee-point solution (balancing trade-offs)\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_obj1 = obj1_scores / max_obj1\n        normalized_obj2 = obj2_scores / max_obj2\n        distances = np.sqrt((1 - normalized_obj1)**2 + (1 - normalized_obj2)**2)\n        selected_idx = np.argmin(distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dominance-aware flipping (prioritize underrepresented objective)\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    if least_dominated == 1:\n        target_gain = value1_lst / (weight_lst + 1e-10)\n    else:\n        target_gain = value2_lst / (weight_lst + 1e-10)\n\n    high_gain_indices = np.argsort(target_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Diversity-aware perturbations (flip items in underrepresented regions)\n    if np.random.rand() < 0.3:\n        obj1_covered = np.sum(new_solution * value1_lst)\n        obj2_covered = np.sum(new_solution * value2_lst)\n        if obj1_covered < obj2_covered:\n            candidate_indices = np.where((value1_lst > value2_lst) & (new_solution == 0))[0]\n        else:\n            candidate_indices = np.where((value2_lst > value1_lst) & (new_solution == 0))[0]\n\n        if len(candidate_indices) > 0:\n            selected_idx = np.random.choice(candidate_indices)\n            if current_weight + weight_lst[selected_idx] <= capacity:\n                new_solution[selected_idx] = 1\n                current_weight += weight_lst[selected_idx]\n\n    # Iterative feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined marginal gain\n        combined_gain = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        remove_idx = included_items[np.argmin(combined_gain[included_items])]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9657298600122048,
            0.20827093720436096
        ]
    },
    {
        "algorithm": "The algorithm selects from the top 20% of non-dominated solutions (weighted equally on normalized objectives) and performs a local search by flipping high-gain items (60% prioritizing value1, 40% prioritizing value2) while occasionally perturbing low-gain items (30% probability) to balance exploration and exploitation, always ensuring feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by equally weighted normalized objectives\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.5 * obj[0]/max_obj1 + 0.5 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Local search: flip items with highest combined gain (60% value1, 40% value2)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.6 * marginal_gain1 + 0.4 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-gain items with 30% probability\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7786288219507125,
            0.20604312419891357
        ]
    },
    {
        "algorithm": "The algorithm selects the solution with the highest hypervolume contribution from the archive, then applies a hybrid local search combining marginal-gain-based flips with an objective-balanced mechanism that prioritizes items with high combined marginal gains and balanced trade-offs between objectives. It dynamically scales the number of random flips based on the solution's distance to the ideal point and ensures feasibility through a trade-off-aware removal process that eliminates items with the poorest trade-offs between objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    selected_idx = np.argmax(hypervolume)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Objective-balanced flipping mechanism\n    trade_off = value2_lst / (value1_lst + 1e-10)\n    combined_score = (marginal_gain1 + marginal_gain2) * (1 + 0.5 * np.abs(trade_off - np.mean(trade_off)))\n    sorted_indices = np.argsort(combined_score)[::-1]\n\n    for idx in sorted_indices[:min(5, len(weight_lst))]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips (scaled by distance to ideal point)\n    distance_to_ideal = np.linalg.norm(ideal_point - objectives[selected_idx])\n    n_random_flips = max(1, int(5 * (1 / (distance_to_ideal + 1))))\n    for _ in range(n_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Trade-off-aware feasibility restoration\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with poorest trade-off\n        item_trade_off = value2_lst[removable_items] / (value1_lst[removable_items] + 1e-10)\n        avg_trade_off = np.mean(item_trade_off)\n        remove_idx = removable_items[np.argmax(np.abs(item_trade_off - avg_trade_off))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9386445648038064,
            0.23346582055091858
        ]
    },
    {
        "algorithm": "The algorithm selects knee-point solutions from the archive based on hypervolume contribution, then applies targeted flips of high-marginal-gain items in either objective, followed by 1-2 random flips to escape local optima, while ensuring feasibility through iterative repair by removing the least critical items. It prioritizes items with balanced gains in both objectives and uses marginal contributions to guide the repair process.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select knee-point solutions by hypervolume contribution\n    objectives = np.array([obj for _, obj in archive])\n    ideal_point = np.max(objectives, axis=0)\n    hypervolume = np.prod(ideal_point - objectives, axis=1)\n    knee_indices = np.argsort(hypervolume)[-max(1, len(archive) // 5):]\n    selected_idx = np.random.choice(knee_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Targeted flips: prioritize items with high marginal gains in either objective\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Adaptive perturbation: 1-2 random flips\n    num_random_flips = np.random.randint(1, 3)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative repair: remove least critical items if infeasible\n    for _ in range(5):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with lowest marginal contribution to either objective\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        remove_idx = removable_items[np.argmin(marginal_contribution[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9295302772384724,
            0.2204917073249817
        ]
    },
    {
        "algorithm": "The algorithm selects promising solutions from the top 20% of the archive based on combined objective scores, then performs a targeted local search by flipping high-marginal-gain items prioritizing the least dominated objective, followed by controlled random perturbations and adaptive feasibility repairs to ensure capacity constraints are met while maintaining solution diversity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by combined objective score\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        combined_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(combined_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains and dominance information\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Identify items that improve the least dominated objective\n    obj1_ratio = obj1_scores[selected_idx] / (max_obj1 + 1e-10)\n    obj2_ratio = obj2_scores[selected_idx] / (max_obj2 + 1e-10)\n    least_dominated = 1 if obj1_ratio < obj2_ratio else 2\n\n    # Targeted flipping of high-marginal-gain items prioritizing least dominated objective\n    if least_dominated == 1:\n        target_gain = marginal_gain1\n    else:\n        target_gain = marginal_gain2\n\n    high_gain_indices = np.argsort(target_gain)[::-1][:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation of low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive feasibility repair\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(included_items) == 0:\n            break\n\n        # Remove items with lowest combined marginal gain\n        removal_candidates = included_items[np.argsort(combined_gain[included_items])]\n        for idx in removal_candidates:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.8483212636259411,
            0.21432334184646606
        ]
    },
    {
        "algorithm": "This heuristic selects high-performing solutions from the top 30% of the archive, prioritizes flipping high-marginal-gain items, probabilistically perturbs low-contribution items, and aggressively refines the solution by greedily removing least valuable items to ensure feasibility. The algorithm balances exploration (via probabilistic perturbations) with exploitation (via dominance-aware flips) while maintaining strict feasibility constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by combined objective score\n    def combined_score(sol):\n        obj1, obj2 = sol[1]\n        return obj1 + obj2\n\n    scores = [combined_score(sol) for sol in archive]\n    top_indices = np.argsort(scores)[-max(1, len(archive) // 3):]\n    selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dominance-aware local search: flip items with high marginal gains\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(10, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Probabilistic perturbation: higher probability for low-contribution items\n    if np.random.rand() < 0.5:\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:min(5, len(weight_lst))]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Aggressive iterative refinement: greedy removal of items\n    for _ in range(10):\n        temp_weight = np.sum(weight_lst * new_solution)\n        if temp_weight <= capacity:\n            break\n        excess = temp_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin((value1_lst + value2_lst)[removable_items] / weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8244904566005473,
            0.20643413066864014
        ]
    }
]