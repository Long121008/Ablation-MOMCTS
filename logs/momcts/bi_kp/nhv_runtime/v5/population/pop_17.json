[
    {
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7633290724762323,
            0.17913395166397095
        ]
    },
    {
        "algorithm": "The algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.8399822123976359,
            0.2032187581062317
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9295394386064582,
            0.5756343901157379
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9223724891724746,
            0.21610364317893982
        ]
    },
    {
        "algorithm": "The algorithm selects a balanced solution from the archive (prioritizing solutions with similar objective values) and applies a hybrid local search combining value-weighted bit-flipping (focusing on high-value-weight items), probabilistic objective-space perturbations (randomly flipping items based on individual objective ratios), and adaptive capacity-aware swaps (swapping critical items while respecting capacity). It ensures feasibility by dynamically checking weight constraints during each operation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced objectives\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    balance_scores = np.abs(obj1_scores - obj2_scores)\n    selected_idx = np.argmin(balance_scores) if np.random.rand() < 0.7 else np.argmax(balance_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Value-weighted bit-flipping\n    combined_value = value1_lst + value2_lst\n    value_weight_ratio = combined_value / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(value_weight_ratio)[::-1]\n\n    for idx in sorted_indices[:min(7, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Objective-space perturbation\n    if np.random.rand() < 0.5:\n        obj1_ratio = value1_lst / (weight_lst + 1e-6)\n        obj2_ratio = value2_lst / (weight_lst + 1e-6)\n        obj1_indices = np.argsort(obj1_ratio)[::-1]\n        obj2_indices = np.argsort(obj2_ratio)[::-1]\n\n        for idx in obj1_indices[:min(3, n_items)]:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        for idx in obj2_indices[:min(3, n_items)]:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive capacity-aware swaps\n    if np.random.rand() < 0.4:\n        item_criticality = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        sorted_critical = np.argsort(item_criticality)[::-1]\n\n        for i in range(min(5, n_items)):\n            for j in range(i+1, min(i+5, n_items)):\n                if base_solution[sorted_critical[i]] == 1 and base_solution[sorted_critical[j]] == 0:\n                    weight_diff = weight_lst[sorted_critical[j]] - weight_lst[sorted_critical[i]]\n                    if current_weight + weight_diff <= capacity:\n                        new_solution[sorted_critical[i]] = 0\n                        new_solution[sorted_critical[j]] = 1\n                        current_weight += weight_diff\n                        break\n\n    return new_solution\n\n",
        "score": [
            -0.796088654335021,
            0.20981630682945251
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with potential for improvement (items that can be added without exceeding capacity), then applies a hybrid approach combining value-weighted greedy selection (prioritizing items with highest combined marginal value) and adaptive random perturbations (flipping items probabilistically, with flip probability adjusted based on archive diversity). Finally, it ensures feasibility through greedy backtracking by removing low-marginal-value items if the weight exceeds capacity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    import random\n    import numpy as np\n\n    # Select a solution with potential for improvement by considering both value and archive diversity\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(sol * weight_lst)\n        remaining_capacity = capacity - current_weight\n        potential_items = np.where((sol == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(potential_items) > 0:\n            candidates.append(sol)\n\n    if not candidates:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        selected_solution = random.choice(candidates).copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Step 1: Value-weighted greedy selection\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    for i in np.argsort(-combined_marginal):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    # Step 2: Adaptive random perturbation based on solution quality\n    num_items = len(new_solution)\n    flip_prob = 0.3  # Base flip probability\n    if len(archive) > 1:\n        # Adjust flip probability based on archive diversity\n        archive_weights = np.array([sol[0] for sol, _ in archive])\n        diversity = np.mean(np.std(archive_weights, axis=0))\n        flip_prob = min(0.5, flip_prob + 0.2 * diversity)\n\n    flip_indices = [i for i in range(num_items) if random.random() < flip_prob]\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    # Step 3: Greedy backtracking to maintain feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess_weight = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest marginal value contribution\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        remove_idx = removable_items[np.argmin(marginal_contrib[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8698856534598612,
            0.7990563213825226
        ]
    },
    {
        "algorithm": "The algorithm selects a high-performing solution from the archive by prioritizing those with normalized objective values, then applies a hybrid local search combining adaptive bit-flipping (prioritizing high value-to-weight ratio items), probabilistic value-based perturbations (removing low-value, high-weight items), and dynamic weight adjustments (temporarily scaling weights for exploration), ensuring feasibility by strict capacity checks at each step. The approach balances exploitation (value optimization) and exploration (perturbations) while maintaining solution feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with high normalized objective values\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive bit-flipping based on value-to-weight ratio\n    value_ratio = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(value_ratio)[::-1]  # Highest ratio first\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Value-based perturbation: flip items with low value but high weight\n    if np.random.rand() < 0.4:\n        low_value_high_weight = (value1_lst < np.median(value1_lst)) & (value2_lst < np.median(value2_lst)) & (weight_lst > np.median(weight_lst))\n        perturb_indices = np.where(low_value_high_weight)[0]\n        for idx in perturb_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Dynamic weight adjustment: scale weights temporarily for perturbation\n    if np.random.rand() < 0.3:\n        temp_weights = weight_lst * (1 + 0.1 * np.random.randn(n_items))\n        for idx in np.random.choice(n_items, size=min(3, n_items), replace=False):\n            if base_solution[idx] == 0 and current_weight + temp_weights[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += temp_weights[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8304688143210642,
            0.25333505868911743
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with high marginal value potential and weight diversity, then applies a hybrid approach combining marginal value-based addition, adaptive probabilistic swaps, and weighted removal to generate a feasible neighbor solution. It balances exploration and exploitation by adjusting swap probabilities based on archive diversity and ensures feasibility through targeted item removal when capacity is exceeded. The critical design choices include prioritizing items with high combined marginal value, favoring weight-diverse items, and dynamically adjusting exploration intensity based on solution quality.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    import random\n    import numpy as np\n\n    # Select the solution with the highest potential for improvement\n    best_candidate = None\n    max_potential = -1\n    for sol, _ in archive:\n        current_weight = np.sum(sol * weight_lst)\n        remaining_capacity = capacity - current_weight\n        potential_items = np.where((sol == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(potential_items) > 0:\n            # Calculate potential based on combined marginal value and weight diversity\n            marginal_value1 = value1_lst[potential_items] / (weight_lst[potential_items] + 1e-10)\n            marginal_value2 = value2_lst[potential_items] / (weight_lst[potential_items] + 1e-10)\n            combined_marginal = marginal_value1 + marginal_value2\n            weight_diversity = np.std(weight_lst[potential_items])\n            potential = np.sum(combined_marginal) * (1 + weight_diversity)\n            if potential > max_potential:\n                max_potential = potential\n                best_candidate = sol\n\n    if best_candidate is None:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        selected_solution = best_candidate.copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Step 1: Marginal value-based selection with weight diversity consideration\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n    weight_diversity = np.std(weight_lst)\n\n    for i in np.argsort(-combined_marginal):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            # Add item with higher probability if it's part of diverse weight range\n            add_prob = 0.7 if (weight_lst[i] > np.percentile(weight_lst, 30) and weight_lst[i] < np.percentile(weight_lst, 70)) else 0.4\n            if random.random() < add_prob:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Step 2: Adaptive probabilistic swaps based on solution quality and diversity\n    num_items = len(new_solution)\n    swap_prob = 0.2  # Base swap probability\n    if len(archive) > 1:\n        # Adjust swap probability based on archive diversity and solution quality\n        archive_weights = np.array([sol[0] for sol, _ in archive])\n        diversity = np.mean(np.std(archive_weights, axis=0))\n        swap_prob = min(0.4, swap_prob + 0.15 * diversity)\n\n    for i in range(num_items):\n        if random.random() < swap_prob:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n            elif new_solution[i] == 1:\n                new_solution[i] = 0\n\n    # Step 3: Weighted removal to maintain feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest weighted marginal value contribution\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        weights = weight_lst[removable_items]\n        weighted_contrib = marginal_contrib[removable_items] * weights\n        remove_idx = removable_items[np.argmin(weighted_contrib)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8803102034567545,
            0.8085598945617676
        ]
    },
    {
        "algorithm": "The algorithm selects promising solutions from the top 20% of the archive (based on normalized objective sums) and generates neighbors by flipping items with high marginal gains for both objectives, followed by 1-2 random feasible flips, while ensuring feasibility through iterative refinement by removing the lightest items when needed. It prioritizes items with combined high marginal gains for both objectives while maintaining diversity through random flips.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Marginal gain-based flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Add 1-2 random feasible flips\n    for _ in range(np.random.randint(1, 3)):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.7986965115457588,
            0.24817776679992676
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive based on a diversity-aware normalized score, then applies a three-phase local search: first flipping items with high marginal gains for both objectives, followed by targeted perturbations of low value-to-weight ratio items, and finally dynamic weight scaling for exploration, all while maintaining feasibility. The selection prioritizes solutions with high normalized scores but also considers their potential for improvement through adaptive perturbations, with the first phase focusing on objective-maximizing flips, the second on low-value items, and the third on dynamic weight adjustments.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with high diversity-aware normalized score\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Normalized score with diversity consideration\n        normalized_scores = []\n        for sol, obj in archive:\n            normalized_score = (obj[0]/max_obj1 + obj[1]/max_obj2) * (1 + 0.1 * (np.sum(sol) / len(sol)))\n            normalized_scores.append(normalized_score)\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    n_items = len(weight_lst)\n\n    # Phase 1: Marginal gain flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    for gain in [marginal_gain1, marginal_gain2]:\n        top_indices = np.argsort(gain)[-5:]  # Top 5 items per objective\n        for idx in top_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Targeted perturbations (low value-to-weight ratio)\n    value_ratio = (value1_lst + value2_lst) / weight_lst\n    low_ratio_indices = np.where(value_ratio < np.median(value_ratio))[0]\n    if np.random.rand() < 0.3 and len(low_ratio_indices) > 0:\n        perturb_indices = np.random.choice(low_ratio_indices, size=min(3, len(low_ratio_indices)), replace=False)\n        for idx in perturb_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Phase 3: Dynamic weight scaling for exploration\n    if np.random.rand() < 0.2:\n        temp_weights = weight_lst * (1 + 0.1 * np.random.randn(n_items))\n        for idx in np.random.choice(n_items, size=min(2, n_items), replace=False):\n            if base_solution[idx] == 0 and current_weight + temp_weights[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += temp_weights[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8161294309538617,
            0.382090300321579
        ]
    }
]