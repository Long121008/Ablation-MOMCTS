[
    {
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with potential for improvement (items that can be added without exceeding capacity), then applies a hybrid approach combining value-weighted greedy selection (prioritizing items with highest combined marginal value) and adaptive random perturbations (flipping items probabilistically, with flip probability adjusted based on archive diversity). Finally, it ensures feasibility through greedy backtracking by removing low-marginal-value items if the weight exceeds capacity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    import random\n    import numpy as np\n\n    # Select a solution with potential for improvement by considering both value and archive diversity\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(sol * weight_lst)\n        remaining_capacity = capacity - current_weight\n        potential_items = np.where((sol == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(potential_items) > 0:\n            candidates.append(sol)\n\n    if not candidates:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        selected_solution = random.choice(candidates).copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Step 1: Value-weighted greedy selection\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    for i in np.argsort(-combined_marginal):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    # Step 2: Adaptive random perturbation based on solution quality\n    num_items = len(new_solution)\n    flip_prob = 0.3  # Base flip probability\n    if len(archive) > 1:\n        # Adjust flip probability based on archive diversity\n        archive_weights = np.array([sol[0] for sol, _ in archive])\n        diversity = np.mean(np.std(archive_weights, axis=0))\n        flip_prob = min(0.5, flip_prob + 0.2 * diversity)\n\n    flip_indices = [i for i in range(num_items) if random.random() < flip_prob]\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    # Step 3: Greedy backtracking to maintain feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess_weight = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest marginal value contribution\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        remove_idx = removable_items[np.argmin(marginal_contrib[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8698856534598612,
            0.7990563213825226
        ]
    },
    {
        "algorithm": "The algorithm selects a high-performing solution from the archive by prioritizing those with normalized objective values, then applies a hybrid local search combining adaptive bit-flipping (prioritizing high value-to-weight ratio items), probabilistic value-based perturbations (removing low-value, high-weight items), and dynamic weight adjustments (temporarily scaling weights for exploration), ensuring feasibility by strict capacity checks at each step. The approach balances exploitation (value optimization) and exploration (perturbations) while maintaining solution feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with high normalized objective values\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive bit-flipping based on value-to-weight ratio\n    value_ratio = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(value_ratio)[::-1]  # Highest ratio first\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Value-based perturbation: flip items with low value but high weight\n    if np.random.rand() < 0.4:\n        low_value_high_weight = (value1_lst < np.median(value1_lst)) & (value2_lst < np.median(value2_lst)) & (weight_lst > np.median(weight_lst))\n        perturb_indices = np.where(low_value_high_weight)[0]\n        for idx in perturb_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Dynamic weight adjustment: scale weights temporarily for perturbation\n    if np.random.rand() < 0.3:\n        temp_weights = weight_lst * (1 + 0.1 * np.random.randn(n_items))\n        for idx in np.random.choice(n_items, size=min(3, n_items), replace=False):\n            if base_solution[idx] == 0 and current_weight + temp_weights[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += temp_weights[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8304688143210642,
            0.25333505868911743
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7633290724762323,
            0.17913395166397095
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with high marginal value potential and weight diversity, then applies a hybrid approach combining marginal value-based addition, adaptive probabilistic swaps, and weighted removal to generate a feasible neighbor solution. It balances exploration and exploitation by adjusting swap probabilities based on archive diversity and ensures feasibility through targeted item removal when capacity is exceeded. The critical design choices include prioritizing items with high combined marginal value, favoring weight-diverse items, and dynamically adjusting exploration intensity based on solution quality.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    import random\n    import numpy as np\n\n    # Select the solution with the highest potential for improvement\n    best_candidate = None\n    max_potential = -1\n    for sol, _ in archive:\n        current_weight = np.sum(sol * weight_lst)\n        remaining_capacity = capacity - current_weight\n        potential_items = np.where((sol == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(potential_items) > 0:\n            # Calculate potential based on combined marginal value and weight diversity\n            marginal_value1 = value1_lst[potential_items] / (weight_lst[potential_items] + 1e-10)\n            marginal_value2 = value2_lst[potential_items] / (weight_lst[potential_items] + 1e-10)\n            combined_marginal = marginal_value1 + marginal_value2\n            weight_diversity = np.std(weight_lst[potential_items])\n            potential = np.sum(combined_marginal) * (1 + weight_diversity)\n            if potential > max_potential:\n                max_potential = potential\n                best_candidate = sol\n\n    if best_candidate is None:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        selected_solution = best_candidate.copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Step 1: Marginal value-based selection with weight diversity consideration\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n    weight_diversity = np.std(weight_lst)\n\n    for i in np.argsort(-combined_marginal):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            # Add item with higher probability if it's part of diverse weight range\n            add_prob = 0.7 if (weight_lst[i] > np.percentile(weight_lst, 30) and weight_lst[i] < np.percentile(weight_lst, 70)) else 0.4\n            if random.random() < add_prob:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Step 2: Adaptive probabilistic swaps based on solution quality and diversity\n    num_items = len(new_solution)\n    swap_prob = 0.2  # Base swap probability\n    if len(archive) > 1:\n        # Adjust swap probability based on archive diversity and solution quality\n        archive_weights = np.array([sol[0] for sol, _ in archive])\n        diversity = np.mean(np.std(archive_weights, axis=0))\n        swap_prob = min(0.4, swap_prob + 0.15 * diversity)\n\n    for i in range(num_items):\n        if random.random() < swap_prob:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n            elif new_solution[i] == 1:\n                new_solution[i] = 0\n\n    # Step 3: Weighted removal to maintain feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest weighted marginal value contribution\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        weights = weight_lst[removable_items]\n        weighted_contrib = marginal_contrib[removable_items] * weights\n        remove_idx = removable_items[np.argmin(weighted_contrib)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8803102034567545,
            0.8085598945617676
        ]
    },
    {
        "algorithm": "The algorithm selects a balanced solution from the archive (prioritizing solutions with similar objective values) and applies a hybrid local search combining value-weighted bit-flipping (focusing on high-value-weight items), probabilistic objective-space perturbations (randomly flipping items based on individual objective ratios), and adaptive capacity-aware swaps (swapping critical items while respecting capacity). It ensures feasibility by dynamically checking weight constraints during each operation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced objectives\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    balance_scores = np.abs(obj1_scores - obj2_scores)\n    selected_idx = np.argmin(balance_scores) if np.random.rand() < 0.7 else np.argmax(balance_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Value-weighted bit-flipping\n    combined_value = value1_lst + value2_lst\n    value_weight_ratio = combined_value / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(value_weight_ratio)[::-1]\n\n    for idx in sorted_indices[:min(7, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Objective-space perturbation\n    if np.random.rand() < 0.5:\n        obj1_ratio = value1_lst / (weight_lst + 1e-6)\n        obj2_ratio = value2_lst / (weight_lst + 1e-6)\n        obj1_indices = np.argsort(obj1_ratio)[::-1]\n        obj2_indices = np.argsort(obj2_ratio)[::-1]\n\n        for idx in obj1_indices[:min(3, n_items)]:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        for idx in obj2_indices[:min(3, n_items)]:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Adaptive capacity-aware swaps\n    if np.random.rand() < 0.4:\n        item_criticality = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        sorted_critical = np.argsort(item_criticality)[::-1]\n\n        for i in range(min(5, n_items)):\n            for j in range(i+1, min(i+5, n_items)):\n                if base_solution[sorted_critical[i]] == 1 and base_solution[sorted_critical[j]] == 0:\n                    weight_diff = weight_lst[sorted_critical[j]] - weight_lst[sorted_critical[i]]\n                    if current_weight + weight_diff <= capacity:\n                        new_solution[sorted_critical[i]] = 0\n                        new_solution[sorted_critical[j]] = 1\n                        current_weight += weight_diff\n                        break\n\n    return new_solution\n\n",
        "score": [
            -0.796088654335021,
            0.20981630682945251
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive based on a diversity-aware normalized score, then applies a three-phase local search: first flipping items with high marginal gains for both objectives, followed by targeted perturbations of low value-to-weight ratio items, and finally dynamic weight scaling for exploration, all while maintaining feasibility. The selection prioritizes solutions with high normalized scores but also considers their potential for improvement through adaptive perturbations, with the first phase focusing on objective-maximizing flips, the second on low-value items, and the third on dynamic weight adjustments.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with high diversity-aware normalized score\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Normalized score with diversity consideration\n        normalized_scores = []\n        for sol, obj in archive:\n            normalized_score = (obj[0]/max_obj1 + obj[1]/max_obj2) * (1 + 0.1 * (np.sum(sol) / len(sol)))\n            normalized_scores.append(normalized_score)\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    n_items = len(weight_lst)\n\n    # Phase 1: Marginal gain flips for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    for gain in [marginal_gain1, marginal_gain2]:\n        top_indices = np.argsort(gain)[-5:]  # Top 5 items per objective\n        for idx in top_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Targeted perturbations (low value-to-weight ratio)\n    value_ratio = (value1_lst + value2_lst) / weight_lst\n    low_ratio_indices = np.where(value_ratio < np.median(value_ratio))[0]\n    if np.random.rand() < 0.3 and len(low_ratio_indices) > 0:\n        perturb_indices = np.random.choice(low_ratio_indices, size=min(3, len(low_ratio_indices)), replace=False)\n        for idx in perturb_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Phase 3: Dynamic weight scaling for exploration\n    if np.random.rand() < 0.2:\n        temp_weights = weight_lst * (1 + 0.1 * np.random.randn(n_items))\n        for idx in np.random.choice(n_items, size=min(2, n_items), replace=False):\n            if base_solution[idx] == 0 and current_weight + temp_weights[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += temp_weights[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8161294309538617,
            0.382090300321579
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using a normalized combined objective score, then applies a hybrid local search that flips items with high marginal gains for each objective while maintaining feasibility. It also includes a probabilistic random perturbation step to escape local optima. The selection prioritizes solutions with better normalized scores, while the local search focuses on objective-specific item flips and adaptive random changes.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest normalized combined objective value\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: objective-specific marginal gain flips\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Flip items with highest marginal gain for each objective\n    for gain, obj in [(marginal_gain1, 1), (marginal_gain2, 2)]:\n        top_indices = np.argsort(gain)[-3:]  # Top 3 items per objective\n        for idx in top_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Adaptive random perturbation (20% probability)\n    if np.random.rand() < 0.2:\n        perturb_indices = np.random.choice(len(weight_lst), size=2, replace=False)\n        for idx in perturb_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7439505675889477,
            0.21176332235336304
        ]
    },
    {
        "algorithm": "The algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7809195178124401,
            1.0582151114940643
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive by normalizing objective sums, then applies a hybrid local search combining targeted flips of high value-to-weight ratio items, adaptive perturbations of low-marginal-contribution items, and dynamic weight adjustments for exploration, while ensuring feasibility at each step. It prioritizes items with the highest combined value-to-weight ratios and occasionally perturbs low-contribution items to escape local optima. The method balances exploitation and exploration through weighted randomness and iterative refinement.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted flips: high value-to-weight ratio items\n    value_ratio = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(value_ratio)[::-1]\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Adaptive perturbation: flip low marginal contribution items\n    if np.random.rand() < 0.4:\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 5)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Dynamic weight adjustment for exploration\n    if np.random.rand() < 0.3:\n        temp_weights = weight_lst * (1 + 0.1 * np.random.randn(n_items))\n        for idx in np.random.choice(n_items, size=min(3, n_items), replace=False):\n            if base_solution[idx] == 0 and current_weight + temp_weights[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += temp_weights[idx]\n\n    # Iterative refinement: additional random flips\n    for _ in range(min(2, n_items)):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.498320809846788,
            0.22736230492591858
        ]
    },
    {
        "algorithm": "The algorithm selects top-performing solutions (top 20%) from the archive based on normalized objective sums, then applies a targeted local search prioritizing items with high marginal gains in either objective, followed by 1-2 random flips to maintain diversity while ensuring feasibility. It first evaluates items by their marginal gains (value-to-weight ratio) for both objectives, flipping the most promising ones, and then introduces randomness to escape local optima. The solution always remains feasible by checking weight constraints before each flip.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.choice(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for each objective\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Flip items with highest marginal gains in either objective\n    for i in np.argsort(-np.maximum(marginal_gain1, marginal_gain2)):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1 and (current_weight - weight_lst[i]) <= capacity:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Add 1-2 random flips to maintain diversity\n    flip_indices = np.random.choice(len(new_solution), size=np.random.randint(1, 3), replace=False)\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1 and (current_weight - weight_lst[i]) <= capacity:\n            new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.7693802282111715,
            0.48120638728141785
        ]
    }
]