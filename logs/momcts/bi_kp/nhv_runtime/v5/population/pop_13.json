[
    {
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with potential for improvement (items that can be added without exceeding capacity), then applies a hybrid approach combining value-weighted greedy selection (prioritizing items with highest combined marginal value) and adaptive random perturbations (flipping items probabilistically, with flip probability adjusted based on archive diversity). Finally, it ensures feasibility through greedy backtracking by removing low-marginal-value items if the weight exceeds capacity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    import random\n    import numpy as np\n\n    # Select a solution with potential for improvement by considering both value and archive diversity\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(sol * weight_lst)\n        remaining_capacity = capacity - current_weight\n        potential_items = np.where((sol == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(potential_items) > 0:\n            candidates.append(sol)\n\n    if not candidates:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        selected_solution = random.choice(candidates).copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Step 1: Value-weighted greedy selection\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    for i in np.argsort(-combined_marginal):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    # Step 2: Adaptive random perturbation based on solution quality\n    num_items = len(new_solution)\n    flip_prob = 0.3  # Base flip probability\n    if len(archive) > 1:\n        # Adjust flip probability based on archive diversity\n        archive_weights = np.array([sol[0] for sol, _ in archive])\n        diversity = np.mean(np.std(archive_weights, axis=0))\n        flip_prob = min(0.5, flip_prob + 0.2 * diversity)\n\n    flip_indices = [i for i in range(num_items) if random.random() < flip_prob]\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    # Step 3: Greedy backtracking to maintain feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess_weight = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        # Remove item with smallest marginal value contribution\n        marginal_contrib = (new_solution * value1_lst + new_solution * value2_lst) / (weight_lst + 1e-10)\n        remove_idx = removable_items[np.argmin(marginal_contrib[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8698856534598612,
            0.7990563213825226
        ]
    },
    {
        "algorithm": "The algorithm selects a high-performing solution from the archive by prioritizing those with normalized objective values, then applies a hybrid local search combining adaptive bit-flipping (prioritizing high value-to-weight ratio items), probabilistic value-based perturbations (removing low-value, high-weight items), and dynamic weight adjustments (temporarily scaling weights for exploration), ensuring feasibility by strict capacity checks at each step. The approach balances exploitation (value optimization) and exploration (perturbations) while maintaining solution feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with high normalized objective values\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive bit-flipping based on value-to-weight ratio\n    value_ratio = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(value_ratio)[::-1]  # Highest ratio first\n\n    for idx in sorted_indices[:min(5, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Value-based perturbation: flip items with low value but high weight\n    if np.random.rand() < 0.4:\n        low_value_high_weight = (value1_lst < np.median(value1_lst)) & (value2_lst < np.median(value2_lst)) & (weight_lst > np.median(weight_lst))\n        perturb_indices = np.where(low_value_high_weight)[0]\n        for idx in perturb_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Dynamic weight adjustment: scale weights temporarily for perturbation\n    if np.random.rand() < 0.3:\n        temp_weights = weight_lst * (1 + 0.1 * np.random.randn(n_items))\n        for idx in np.random.choice(n_items, size=min(3, n_items), replace=False):\n            if base_solution[idx] == 0 and current_weight + temp_weights[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += temp_weights[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8304688143210642,
            0.25333505868911743
        ]
    },
    {
        "algorithm": "The algorithm selects a random solution from the archive and performs a hybrid local search by swapping items with a focus on improving either objective while ensuring feasibility. It prioritizes swaps that increase at least one objective value and maintains the solution's weight within capacity. The method uses a value-to-weight ratio consideration to guide the swaps and limits the search to 10 attempts for efficiency.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: random swaps with value-to-weight ratio consideration\n    for _ in range(10):  # Number of attempts to find a feasible neighbor\n        # Select two random items\n        item1, item2 = np.random.choice(len(new_solution), size=2, replace=False)\n\n        # Calculate potential weight change\n        if new_solution[item1] == 1 and new_solution[item2] == 0:\n            delta_weight = weight_lst[item2] - weight_lst[item1]\n        elif new_solution[item1] == 0 and new_solution[item2] == 1:\n            delta_weight = weight_lst[item1] - weight_lst[item2]\n        else:\n            continue  # No change in weight\n\n        # Check feasibility\n        if current_weight + delta_weight <= capacity:\n            # Perform swap if it improves at least one objective\n            value1_delta = (value1_lst[item1] - value1_lst[item2]) if new_solution[item1] == 1 else (value1_lst[item2] - value1_lst[item1])\n            value2_delta = (value2_lst[item1] - value2_lst[item2]) if new_solution[item1] == 1 else (value2_lst[item2] - value2_lst[item1])\n\n            if value1_delta > 0 or value2_delta > 0:\n                new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n                current_weight += delta_weight\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.49864606700041164,
            0.321457177400589
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with the highest normalized sum of objective values, then applies a hybrid local search that combines random bit-flipping and adaptive perturbation to explore the neighborhood while ensuring feasibility. It balances exploration and exploitation by limiting bit-flips and occasionally perturbing low-marginal-contribution items to escape local optima. The selection criterion favors solutions with better combined performance, while the local search intelligently modifies the solution to improve both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives to balance both criteria\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: bit-flipping with adaptive perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    for _ in range(min(3, n_items)):  # Limit flips to avoid excessive computation\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Step 2: Adaptive perturbation - flip items with low marginal contribution\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n        for idx in low_contrib_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3202108423479148,
            0.2685256004333496
        ]
    },
    {
        "algorithm": "The algorithm selects a random solution from the archive and applies a hybrid local search strategy that prioritizes items with high marginal value (combined from both objectives) while ensuring feasibility, followed by random flips to explore diversity. It balances exploitation (targeting high-value items) with exploration (random perturbations) to generate improved neighbor solutions. The approach avoids standard local search methods like 2-opt by focusing on value-weighted flips and controlled randomness.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: Flip items based on marginal contribution and diversity\n    new_solution = base_solution.copy()\n\n    # Step 1: Identify items with high marginal contribution (value/weight ratio)\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Step 2: Flip items with high marginal contribution if feasible\n    for i in np.argsort(-combined_marginal):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Step 3: Randomly flip additional items to explore diversity\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1:\n            new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.6371576377229591,
            0.4495231509208679
        ]
    },
    {
        "algorithm": "The algorithm selects top-performing solutions (top 20%) from the archive based on normalized objective sums, then applies a targeted local search prioritizing items with high marginal gains in either objective, followed by 1-2 random flips to maintain diversity while ensuring feasibility. It first evaluates items by their marginal gains (value-to-weight ratio) for both objectives, flipping the most promising ones, and then introduces randomness to escape local optima. The solution always remains feasible by checking weight constraints before each flip.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.choice(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate marginal gains for each objective\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n\n    # Flip items with highest marginal gains in either objective\n    for i in np.argsort(-np.maximum(marginal_gain1, marginal_gain2)):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1 and (current_weight - weight_lst[i]) <= capacity:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Add 1-2 random flips to maintain diversity\n    flip_indices = np.random.choice(len(new_solution), size=np.random.randint(1, 3), replace=False)\n    for i in flip_indices:\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif new_solution[i] == 1 and (current_weight - weight_lst[i]) <= capacity:\n            new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.7693802282111715,
            0.48120638728141785
        ]
    },
    {
        "algorithm": "The algorithm first selects a promising solution from the top 20% of the archive based on normalized objective sums, then performs a targeted local search by flipping high-marginal-gain items (prioritizing those with the largest value-to-weight ratios) while maintaining feasibility, followed by a controlled random perturbation of low-marginal-contribution items to escape local optima. The approach balances exploitation of high-value items and exploration of low-contribution items through strict capacity checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7809195178124401,
            1.0582151114940643
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive based on normalized objective product scores, then applies a hybrid local search that first prioritizes high-marginal-contribution items for targeted bit-flips and occasionally perturbs low-contribution items with stochastic probability to escape local optima while maintaining feasibility. It balances exploitation (high-contribution items) with exploration (low-contribution perturbations) to improve both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Normalize objectives using product to favor balanced solutions\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: targeted bit-flipping with stochastic perturbation\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 1: Targeted bit-flip - prioritize high-marginal-contribution items\n    marginal_contribution = (value1_lst + value2_lst) / weight_lst\n    high_contrib_indices = np.argsort(marginal_contribution)[-max(1, n_items // 3):]\n    for idx in high_contrib_indices:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 2: Stochastic perturbation - flip low-contribution items with probability\n    low_contrib_indices = np.argsort(marginal_contribution)[:max(1, n_items // 4)]\n    for idx in low_contrib_indices:\n        if np.random.rand() < 0.2:  # 20% chance per low-contribution item\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.49723235786746045,
            0.3195430338382721
        ]
    },
    {
        "algorithm": "The algorithm intelligently selects a non-dominated solution from the archive by prioritizing those with high marginal gains, then applies a hybrid local search combining probabilistic item flips and swaps to explore the solution space while ensuring feasibility. The selection is weighted probabilistically, favoring later entries in the archive, and the local search iteratively modifies the solution by flipping or swapping items, checking feasibility at each step. The key design ideas are prioritized selection and hybrid local search with feasibility checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution (prioritize those with high marginal gains)\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution, (base_value1, base_value2) = archive[selected_idx]\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Hybrid local search: probabilistic item flips and swaps\n    for _ in range(5):  # Number of local search iterations\n        # Probabilistic flip: flip a random item if feasible\n        flip_idx = np.random.randint(0, n_items)\n        if new_solution[flip_idx] == 1:\n            if np.sum(weight_lst[new_solution == 1] - weight_lst[flip_idx]) <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if np.sum(weight_lst[new_solution == 1] + weight_lst[flip_idx]) <= capacity:\n                new_solution[flip_idx] = 1\n\n        # Item swap: swap two random items if feasible\n        swap_idx1, swap_idx2 = np.random.choice(n_items, 2, replace=False)\n        if new_solution[swap_idx1] != new_solution[swap_idx2]:\n            if new_solution[swap_idx1] == 1:\n                if np.sum(weight_lst[new_solution == 1] - weight_lst[swap_idx1] + weight_lst[swap_idx2]) <= capacity:\n                    new_solution[swap_idx1] = 0\n                    new_solution[swap_idx2] = 1\n            else:\n                if np.sum(weight_lst[new_solution == 1] - weight_lst[swap_idx2] + weight_lst[swap_idx1]) <= capacity:\n                    new_solution[swap_idx1] = 1\n                    new_solution[swap_idx2] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.3688356342738096,
            0.4918815791606903
        ]
    },
    {
        "algorithm": "The algorithm selects top 20% solutions from the archive based on normalized objective scores, prioritizes less-dominant objectives for flipping items, and performs random flips on low-contribution items to escape local optima while ensuring feasibility. It uses crowding distance to balance diversity and exploitation, and validates feasibility through weighted random removal of excess items. The two-phase approach first improves marginal contributions and then introduces randomness for better exploration.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n\n        # Select solution with probability inversely proportional to crowding distance\n        crowding_distances = []\n        for idx in top_indices:\n            sol = archive[idx][0]\n            distances = [np.sum(np.abs(sol - other_sol)) for other_sol, _ in archive if other_sol is not sol]\n            crowding_distances.append(np.mean(distances) if distances else 1)\n        inv_distances = [1/(d+1e-10) for d in crowding_distances]\n        selected_local_idx = np.random.choice(len(top_indices), p=np.array(inv_distances)/np.sum(inv_distances))\n        selected_idx = top_indices[selected_local_idx]\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Flip items with highest marginal contribution to less dominant objective\n    obj1, obj2 = archive[selected_idx][1]\n    less_dominant = 1 if obj1 > obj2 else 2\n    marginal_values = value1_lst if less_dominant == 1 else value2_lst\n    marginal_contribution = marginal_values / (weight_lst + 1e-10)\n\n    for i in np.argsort(-marginal_contribution):\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Phase 2: Random flips on low marginal contribution items (1-2 flips)\n    low_contrib_mask = (value1_lst + value2_lst) / (weight_lst + 1e-10) < np.percentile((value1_lst + value2_lst)/(weight_lst + 1e-10), 30)\n    low_contrib_indices = np.where(low_contrib_mask)[0]\n    np.random.shuffle(low_contrib_indices)\n    for i in low_contrib_indices[:np.random.randint(1, 3)]:\n        if base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n        elif base_solution[i] == 1:\n            new_solution[i] = 0\n\n    # Validate feasibility\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess = np.sum(weight_lst * new_solution) - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        if len(excess_items) == 0:\n            break\n        remove_idx = np.random.choice(excess_items)\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.6433115363420745,
            1.4424501955509186
        ]
    }
]