[
    {
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with the highest normalized objective product (balancing both objectives), then applies a hybrid local search that combines targeted bit-flipping of items with the highest combined marginal gain ratio (value1/weight + value2/weight) and occasional random bit-flipping (30% chance) to escape local optima while ensuring feasibility by dynamically adjusting flips based on capacity constraints. The number of flips is limited to a small fraction of items to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive using normalized objective product\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 * obj[1]/max_obj2) for _, obj in archive]\n        selected_idx = np.argmax(normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: targeted bit-flipping + random bit-flipping\n    n_items = len(weight_lst)\n    max_flips = min(5, n_items)  # Dynamic flip limit based on problem size\n\n    # Step 1: Targeted bit-flipping (highest marginal gain ratio)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_indices = np.argsort(combined_gain)[-max_flips:]\n\n    for idx in top_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Random bit-flipping (30% chance)\n    if np.random.rand() < 0.3:\n        remaining_flips = max_flips // 2\n        for _ in range(remaining_flips):\n            candidate_idx = np.random.randint(n_items)\n            if base_solution[candidate_idx] == 1:\n                if current_weight - weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 0\n                    current_weight -= weight_lst[candidate_idx]\n            else:\n                if current_weight + weight_lst[candidate_idx] <= capacity:\n                    new_solution[candidate_idx] = 1\n                    current_weight += weight_lst[candidate_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7633290724762323,
            0.17913395166397095
        ]
    },
    {
        "algorithm": "The algorithm selects top 20% solutions from the archive based on normalized objective sums, then performs a targeted local search by prioritizing high-marginal-gain items (flipping them while maintaining feasibility), followed by controlled random perturbations of low-marginal-contribution items (with a 30% probability). It ensures feasibility through iterative refinement and rejection of infeasible neighbors, focusing on high-quality solutions while avoiding standard local search methods. The structure emphasizes diversity-aware selection and feasibility-aware flipping, balancing exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(np.minimum(marginal_gain1, marginal_gain2))[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.8399822123976359,
            0.2032187581062317
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using a hybrid crowding-distance-based approach, then applies a novel local search that alternates between greedy improvement of one objective and targeted exploration of the other, while maintaining feasibility through adaptive capacity checks and dynamic perturbations that adjust based on the solution's position in the Pareto front. It prioritizes high-value items first but also includes probabilistic flips of low-value items to escape local optima, with perturbation probabilities varying based on the solution's crowding distance.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and objective dominance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Alternating objective improvement\n    if np.random.rand() < 0.5:\n        # Improve first objective\n        gain = value1_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective\n        gain = value2_lst / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Greedy flips with adaptive capacity check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity * 1.05:  # Slightly relaxed capacity\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity * 1.05:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.5\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n\n    if np.random.rand() < perturbation_prob:\n        # Flip low-value items with higher probability\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        low_value_indices = np.argsort(value_ratio)[:min(3, len(weight_lst))]\n        for idx in low_value_indices:\n            if np.random.rand() < 0.4:  # Higher probability for low-value items\n                if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9295394386064582,
            0.5756343901157379
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the top 30% of the archive (weighted by normalized objectives, prioritizing value1) and performs a targeted local search by flipping high-marginal-gain items (considering both objectives) while occasionally perturbing low-contribution items with a 50% probability to escape local optima, all while maintaining feasibility. The combined gain is weighted 70% toward value1 and 30% toward value2, with the top 7 high-gain items and up to 5 low-gain items being considered for flipping.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.6 * obj[0]/max_obj1 + 0.4 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains considering both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.7 * marginal_gain1 + 0.3 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(7, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-marginal-contribution items with higher probability\n    if np.random.rand() < 0.5:\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9223724891724746,
            0.21610364317893982
        ]
    },
    {
        "algorithm": "The algorithm selects from the top 20% of non-dominated solutions (weighted equally on normalized objectives) and performs a local search by flipping high-gain items (60% prioritizing value1, 40% prioritizing value2) while occasionally perturbing low-gain items (30% probability) to balance exploration and exploitation, always ensuring feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by equally weighted normalized objectives\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(0.5 * obj[0]/max_obj1 + 0.5 * obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Local search: flip items with highest combined gain (60% value1, 40% value2)\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = 0.6 * marginal_gain1 + 0.4 * marginal_gain2\n    high_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random perturbation: flip low-gain items with 30% probability\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, len(weight_lst))]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7786288219507125,
            0.20604312419891357
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using a hybrid of crowding distance and objective trade-off analysis, then applies a novel local search that alternates between targeted item swaps (prioritizing high-value items with trade-off considerations) and probabilistic flips (removing low-value items with dynamic probability), while ensuring feasibility through constrained capacity checks. The selection prioritizes solutions with high crowding distance (indicating potential for improvement) and adjusts perturbation probabilities based on the solution's position in the Pareto front and its objective trade-offs.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine objective dominance and adaptive crowding\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate normalized crowding distances\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(normalized_objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if normalized_objectives[sorted_idx[-1], m] != normalized_objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (normalized_objectives[sorted_idx[i+1], m] - normalized_objectives[sorted_idx[i-1], m]) / (normalized_objectives[sorted_idx[-1], m] - normalized_objectives[sorted_idx[0], m])\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate objective trade-offs\n    trade_off = objectives[:, 1] / (objectives[:, 0] + 1e-10)\n    avg_trade_off = np.mean(trade_off)\n\n    # Alternating objective improvement with trade-off consideration\n    if np.random.rand() < 0.5 or trade_off[selected_idx] < avg_trade_off:\n        # Improve first objective with trade-off consideration\n        gain = (value1_lst + 0.3 * value2_lst) / weight_lst\n        sorted_indices = np.argsort(-gain)\n    else:\n        # Improve second objective with trade-off consideration\n        gain = (value2_lst + 0.3 * value1_lst) / weight_lst\n        sorted_indices = np.argsort(-gain)\n\n    # Targeted item swaps with feasibility check\n    for idx in sorted_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic perturbation based on solution's Pareto position and trade-off\n    perturbation_prob = 0.3 if trade_off[selected_idx] < avg_trade_off else 0.6\n    if np.random.rand() < perturbation_prob:\n        # Select items with poor value-to-weight ratio for potential removal\n        value_ratio = np.minimum(value1_lst, value2_lst) / weight_lst\n        poor_ratio_indices = np.argsort(value_ratio)[:min(5, len(weight_lst))]\n        for idx in poor_ratio_indices:\n            if np.random.rand() < 0.5 and base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9265764495419105,
            0.6385702192783356
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solutions with high crowding distance and high normalized objective sums\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distances\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = np.inf\n        crowding[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if objectives[sorted_idx[-1], m] != objectives[sorted_idx[0], m]:\n                crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m])\n\n    # Calculate normalized objective sums\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        normalized_scores = np.ones(len(archive))\n    else:\n        normalized_scores = (objectives[:, 0]/max_obj1 + objectives[:, 1]/max_obj2)\n\n    # Combine crowding and normalized scores\n    combined_scores = crowding * normalized_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate multi-objective marginal gains\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = np.maximum(marginal_gain1, marginal_gain2)\n\n    # Select top items with highest combined marginal gains\n    top_gain_indices = np.argsort(-combined_gain)[:min(5, len(weight_lst))]\n\n    # Greedy flips for top gain items\n    for idx in top_gain_indices:\n        if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Adaptive perturbation based on solution's position\n    if crowding[selected_idx] > np.median(crowding):\n        # More aggressive perturbation for non-crowded solutions\n        perturbation_prob = 0.4\n        num_perturbations = 2\n    else:\n        # More conservative perturbation for crowded solutions\n        perturbation_prob = 0.2\n        num_perturbations = 1\n\n    if np.random.rand() < perturbation_prob:\n        # Select items with low combined marginal gains for perturbation\n        low_gain_indices = np.argsort(combined_gain)[:min(5, len(weight_lst))]\n        selected_perturbations = np.random.choice(low_gain_indices, min(num_perturbations, len(low_gain_indices)), replace=False)\n\n        for idx in selected_perturbations:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Final feasibility check and refinement\n    for _ in range(3):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n        else:\n            # Remove heaviest items to make feasible\n            excess = temp_weight - capacity\n            while excess > 0 and np.any(temp_solution):\n                heaviest_idx = np.argmax(weight_lst * temp_solution)\n                if temp_solution[heaviest_idx] == 1:\n                    temp_solution[heaviest_idx] = 0\n                    excess -= weight_lst[heaviest_idx]\n            new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -0.8757989809123614,
            0.4065599739551544
        ]
    },
    {
        "algorithm": "The algorithm selects top 30% solutions from the archive based on a weighted sum of normalized objectives (60% weight for value1, 40% for value2), then generates neighbors by flipping items with highest marginal gains (adjusted by current weight utilization) followed by dynamic random flips, ensuring feasibility through adaptive item removal based on marginal gain ratios. It prioritizes high-value items early while maintaining diversity through weighted selection and utilization-aware flipping.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 30% solutions by weighted normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (0.6 * obj1_scores / max_obj1) + (0.4 * obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 3):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n    current_utilization = current_weight / capacity\n\n    # Calculate marginal gains with weight sensitivity\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = (1 - current_utilization) * marginal_gain1 + current_utilization * marginal_gain2\n    sorted_indices = np.argsort(combined_gain)[::-1]\n\n    # Flip items with highest combined gains\n    for idx in sorted_indices[:min(7, n_items)]:\n        if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic number of random flips based on current utilization\n    num_flips = max(1, int(3 * (1 - current_utilization)))\n    for _ in range(num_flips):\n        candidate_idx = np.random.randint(n_items)\n        if base_solution[candidate_idx] == 0 and current_weight + weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 1\n            current_weight += weight_lst[candidate_idx]\n        elif base_solution[candidate_idx] == 1 and current_weight - weight_lst[candidate_idx] <= capacity:\n            new_solution[candidate_idx] = 0\n            current_weight -= weight_lst[candidate_idx]\n\n    # Adaptive feasibility maintenance\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n\n        if len(removable_items) == 0:\n            break\n\n        # Remove item with lowest marginal gain ratio\n        removal_criteria = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-10)\n        remove_idx = removable_items[np.argmin(removal_criteria)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8552214925232527,
            0.2515418827533722
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the top 20% of the archive (based on normalized objective sums) and applies a hybrid local search: first flipping high-marginal-gain items (prioritized by combined value-to-weight ratios) and then randomly flipping low-marginal-contribution items (with 30% probability), while ensuring feasibility through iterative removal of the lightest items if capacity is exceeded. The method balances exploitation (targeted flips) and exploration (random flips) while limiting iterations to 5-10 per solution.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sums\n    obj1_scores = np.array([obj[0] for _, obj in archive])\n    obj2_scores = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1_scores), np.max(obj2_scores)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = (obj1_scores / max_obj1) + (obj2_scores / max_obj2)\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive) // 5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    n_items = len(weight_lst)\n\n    # Targeted flipping of high-marginal-gain items\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n    high_gain_indices = np.argsort(combined_gain)[::-1][:min(5, n_items)]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Controlled random flips of low-marginal-contribution items\n    if np.random.rand() < 0.3:\n        low_gain_indices = np.argsort(combined_gain)[:min(3, n_items)]\n        for idx in low_gain_indices:\n            if base_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            elif base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Iterative refinement to ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) == 0:\n            break\n        remove_idx = removable_items[np.argmin(weight_lst[removable_items])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.826961791986931,
            0.2329617738723755
        ]
    },
    {
        "algorithm": "The algorithm selects promising solutions from the top 20% of the archive (based on normalized objective sums) and applies a targeted local search by prioritizing flips of high-marginal-gain items, followed by 1-2 random flips to escape local optima, while ensuring feasibility through iterative refinement. High-marginal-gain items (based on value-to-weight ratios) are given higher priority, and the algorithm balances exploitation (focused flips) with exploration (random flips) to improve solution quality.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select top 20% solutions by normalized objective sum\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_scores = [(obj[0]/max_obj1 + obj[1]/max_obj2) for _, obj in archive]\n        top_indices = np.argsort(normalized_scores)[-max(1, len(archive)//5):]\n        selected_idx = np.random.choice(top_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Targeted local search: flip items with high marginal gains in either objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    high_gain_indices = np.argsort(-np.maximum(marginal_gain1, marginal_gain2))[:min(5, len(weight_lst))]\n\n    for idx in high_gain_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Add 1-2 random flips to escape local optima\n    num_random_flips = np.random.randint(1, 3)\n    for _ in range(num_random_flips):\n        candidate_idx = np.random.randint(len(weight_lst))\n        if base_solution[candidate_idx] == 1:\n            if current_weight - weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight -= weight_lst[candidate_idx]\n        else:\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n    # Iterative refinement: reject infeasible neighbors and repeat\n    for _ in range(5):\n        temp_solution = new_solution.copy()\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.7943566467977887,
            0.2194809913635254
        ]
    }
]