[
    {
        "algorithm": "The algorithm combines intelligent solution selection with a three-phase local search: first exploring high-value items probabilistically, then performing targeted swaps to improve both objectives, and finally rebalancing by removing low-value items to maintain feasibility. It prioritizes items with high value ratios while dynamically adjusting the solution to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high value ratio potential\n    archive.sort(key=lambda x: (x[1][0] / (x[1][1] + 1e-6), sum(x[1])), reverse=True)\n    base_solution = archive[0][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n\n    # Calculate value ratios for each item\n    value_ratios = (value1_lst + 1e-6) / (value2_lst + 1e-6)\n    sorted_indices = np.argsort(value_ratios)\n\n    # Phase 1: Probabilistic item additions (exploration)\n    remaining_capacity = capacity - current_weight\n    candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n    if len(candidates) > 0:\n        # Select items with high value ratios first\n        for idx in sorted_indices[::-1]:\n            if idx in candidates and np.random.rand() < 0.7:  # 70% chance to add\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n                candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n                if len(candidates) == 0:\n                    break\n\n    # Phase 2: Targeted swaps based on objective improvements\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    for i in included_items:\n        for j in excluded_items:\n            if weight_lst[j] <= capacity - current_weight + weight_lst[i]:\n                # Check if swap improves both objectives\n                if (value1_lst[j] > value1_lst[i] and value2_lst[j] > value2_lst[i]) or \\\n                   (value1_lst[j] > value1_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity) or \\\n                   (value2_lst[j] > value2_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n                    new_solution[i], new_solution[j] = 0, 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    break\n\n    # Phase 3: Weight-sensitive rebalancing\n    while current_weight > capacity:\n        # Remove items with lowest value ratio first\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        worst_item = included_items[np.argmin(value_ratios[included_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "score": [
            -0.9382821717578097,
            0.46551522612571716
        ]
    },
    {
        "algorithm": "The algorithm randomly selects a solution from the archive and generates a neighbor by flipping up to 5 high-impact items (top 30% by marginal contribution to either objective), prioritizing those that improve both objectives while ensuring feasibility. It balances exploration (random selection) and exploitation (targeted flips) to balance the bi-objective trade-off. The critical design idea is the selection of high-impact items based on marginal contributions, ensuring the neighbor remains feasible while potentially improving both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst[base_solution == 1])\n\n    marginal_impact1 = value1_lst - value1_lst[base_solution == 1].sum()\n    marginal_impact2 = value2_lst - value2_lst[base_solution == 1].sum()\n\n    num_items = len(weight_lst)\n    top_items1 = np.argsort(marginal_impact1)[-max(1, num_items // 3):]\n    top_items2 = np.argsort(marginal_impact2)[-max(1, num_items // 3):]\n    top_items = np.union1d(top_items1, top_items2)\n\n    if len(top_items) > 0:\n        num_to_flip = min(5, len(top_items))\n        flip_indices = np.random.choice(top_items, size=num_to_flip, replace=False)\n\n        for idx in flip_indices:\n            if new_solution[idx] == 1:\n                if total_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    total_weight -= weight_lst[idx]\n            else:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    total_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.45860529653600796,
            0.24088504910469055
        ]
    },
    {
        "algorithm": "The algorithm selects a high-potential solution from the archive, prioritizes items with high marginal impact (combining both objectives) for addition, then performs adaptive swaps to improve both objectives while ensuring feasibility, and finally rebalances the solution by removing low-impact items if the weight exceeds capacity. It balances exploration (via marginal impact) and exploitation (via adaptive swaps) while maintaining feasibility through weight-sensitive rebalancing.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    archive.sort(key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate combined marginal impact for each item\n    marginal_impact = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(marginal_impact)[::-1]  # Descending order\n\n    # Phase 1: Dynamic item selection based on marginal impact\n    remaining_capacity = capacity - current_weight\n    candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n\n    if len(candidates) > 0:\n        # Select top items with highest marginal impact\n        for idx in sorted_indices:\n            if idx in candidates and np.random.rand() < 0.6:  # 60% chance to add\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n                candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n                if len(candidates) == 0:\n                    break\n\n    # Phase 2: Adaptive flipping based on current solution's characteristics\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    # Calculate potential improvements for each swap\n    for i in included_items:\n        for j in excluded_items:\n            if weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                # Check if swap improves both objectives\n                if (value1_lst[j] > value1_lst[i] and value2_lst[j] > value2_lst[i]) or \\\n                   (value1_lst[j] > value1_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity) or \\\n                   (value2_lst[j] > value2_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n                    new_solution[i], new_solution[j] = 0, 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    remaining_capacity = capacity - current_weight\n                    break\n\n    # Phase 3: Weight-sensitive rebalancing with dynamic threshold\n    while current_weight > capacity:\n        # Remove items with lowest marginal impact first\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        worst_item = included_items[np.argmin(marginal_impact[included_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "score": [
            -0.9093676276444078,
            0.6341427564620972
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive (top 30% by combined objective value) and applies a hybrid local search combining probabilistic additions of high-impact items, targeted swaps between included and excluded items, and adaptive removals of low-impact items to ensure feasibility while balancing exploration and exploitation. It prioritizes items with high marginal impact (top percentile) in both objectives and dynamically adjusts the solution to maintain capacity constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential (top 30% by combined objective value)\n    archive.sort(key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    base_solution = archive[min(len(archive) // 3, len(archive) - 1)][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n\n    # Calculate adaptive marginal impact (percentile-based)\n    included = base_solution == 1\n    marginal_impact1 = value1_lst - value1_lst[included].sum()\n    marginal_impact2 = value2_lst - value2_lst[included].sum()\n    top_percentile = min(30, len(weight_lst) // 5)  # Dynamic threshold\n\n    top_items1 = np.argsort(marginal_impact1)[-top_percentile:]\n    top_items2 = np.argsort(marginal_impact2)[-top_percentile:]\n    top_items = np.union1d(top_items1, top_items2)\n\n    # Hybrid local search: Phase 1 - Probabilistic additions\n    remaining_capacity = capacity - current_weight\n    candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0) & np.isin(np.arange(len(weight_lst)), top_items))[0]\n    if len(candidates) > 0:\n        for idx in np.random.permutation(candidates):\n            if np.random.rand() < 0.5:  # 50% chance to add\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n                if remaining_capacity <= 0:\n                    break\n\n    # Phase 2 - Targeted swaps\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    for i in included_items:\n        if i not in top_items:\n            continue\n        for j in excluded_items:\n            if j not in top_items:\n                continue\n            if (weight_lst[j] <= remaining_capacity + weight_lst[i] and\n                (value1_lst[j] > value1_lst[i] or value2_lst[j] > value2_lst[i])):\n                new_solution[i], new_solution[j] = 0, 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                break\n\n    # Phase 3 - Adaptive removals\n    while current_weight > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        # Remove items with lowest combined marginal impact\n        marginal_combined = value1_lst[included_items] + value2_lst[included_items]\n        worst_item = included_items[np.argmin(marginal_combined)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "score": [
            -0.9131241836479801,
            3.4764381051063538
        ]
    },
    {
        "algorithm": "The algorithm selects a random solution from the archive and generates a neighbor by flipping a subset of high-impact items (top 20% by marginal contribution to both objectives) while ensuring feasibility. It prioritizes items that improve both objectives and flips up to 3 of them randomly, adjusting weights accordingly. The heuristic balances exploration (random selection) and exploitation (targeted flips) to balance the bi-objective trade-off.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a neighbor using a hybrid local search: flip a subset of items with high marginal impact\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate marginal impact of each item (difference in objective values if flipped)\n    marginal_impact1 = value1_lst - value1_lst[base_solution == 1].sum()\n    marginal_impact2 = value2_lst - value2_lst[base_solution == 1].sum()\n\n    # Identify items with high marginal impact (top 20%)\n    num_items = len(weight_lst)\n    top_items1 = np.argsort(marginal_impact1)[-max(1, num_items // 5):]\n    top_items2 = np.argsort(marginal_impact2)[-max(1, num_items // 5):]\n    top_items = np.union1d(top_items1, top_items2)\n\n    # Randomly select a subset of top items to flip\n    if len(top_items) > 0:\n        num_to_flip = min(3, len(top_items))  # Flip up to 3 items\n        flip_indices = np.random.choice(top_items, size=num_to_flip, replace=False)\n\n        # Flip selected items and ensure feasibility\n        for idx in flip_indices:\n            if new_solution[idx] == 1:\n                if total_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    total_weight -= weight_lst[idx]\n            else:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    total_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3908341285465272,
            0.2811393439769745
        ]
    },
    {
        "algorithm": "The algorithm selects the highest-potential solution from the archive, then applies a three-phase local search: first removing items probabilistically to free capacity, next inserting high-value items based on normalized combined objective scores, and finally performing limited swaps to balance objectives while ensuring feasibility. The method prioritizes items with better combined normalized values and maintains feasibility through strict weight checks at each step.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential (highest sum of objectives)\n    archive.sort(key=lambda x: sum(x[1]), reverse=True)\n    base_solution = archive[0][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Phase 1: Probabilistic item removal to create capacity\n    for i in np.where(new_solution == 1)[0]:\n        if np.random.rand() < 0.3:  # 30% chance to remove\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Phase 2: Value-driven insertion of high-potential items\n    available_items = np.where(new_solution == 0)[0]\n    if len(available_items) > 0:\n        # Calculate marginal improvement for each item\n        marginal_value1 = value1_lst[available_items]\n        marginal_value2 = value2_lst[available_items]\n        marginal_weights = weight_lst[available_items]\n\n        # Normalize and combine marginal improvements\n        norm_value1 = (marginal_value1 - np.min(marginal_value1)) / (np.max(marginal_value1) - np.min(marginal_value1) + 1e-8)\n        norm_value2 = (marginal_value2 - np.min(marginal_value2)) / (np.max(marginal_value2) - np.min(marginal_value2) + 1e-8)\n        combined_score = norm_value1 + norm_value2\n\n        # Select top 30% items by combined score\n        top_indices = np.argsort(combined_score)[-max(1, len(combined_score)//3):]\n        for idx in top_indices:\n            item = available_items[idx]\n            if current_weight + marginal_weights[idx] <= capacity:\n                new_solution[item] = 1\n                current_weight += marginal_weights[idx]\n\n    # Phase 3: Balanced adjustment considering both objectives\n    for _ in range(5):  # Limited iterations\n        items_in = np.where(new_solution == 1)[0]\n        items_out = np.where(new_solution == 0)[0]\n\n        if len(items_in) > 0 and len(items_out) > 0:\n            # Select items to swap\n            i = np.random.choice(items_in)\n            j = np.random.choice(items_out)\n\n            # Calculate potential improvement\n            delta_weight = weight_lst[j] - weight_lst[i]\n            if current_weight + delta_weight <= capacity:\n                new_value1 = sum(value1_lst * new_solution) - value1_lst[i] + value1_lst[j]\n                new_value2 = sum(value2_lst * new_solution) - value2_lst[i] + value2_lst[j]\n\n                # Accept if at least one objective improves\n                if new_value1 > sum(value1_lst * new_solution) or new_value2 > sum(value2_lst * new_solution):\n                    new_solution[i], new_solution[j] = 0, 1\n                    current_weight += delta_weight\n\n    return new_solution\n\n",
        "score": [
            -0.40184509587363354,
            0.9591511785984039
        ]
    },
    {
        "algorithm": "The algorithm selects a solution with the lowest dominance count (most diverse) from the archive and applies a hybrid local search combining probabilistic swaps and value-weighted replacements to generate a neighbor solution while ensuring feasibility. It prioritizes items with higher combined value-to-weight ratios and performs targeted swaps or replacements to improve both objectives, with a final feasibility check to remove excess items if necessary.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate dominance counts and select a solution with high diversity\n    dominance_counts = []\n    for i, (sol, _) in enumerate(archive):\n        count = sum(1 for (_, obj) in archive if obj[0] > archive[i][1][0] and obj[1] > archive[i][1][1])\n        dominance_counts.append(count)\n\n    # Select solution with lowest dominance count (most diverse)\n    selected_idx = np.argmin(dominance_counts)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Probabilistic swaps based on value-weight ratio\n    for i in range(n_items):\n        if np.random.random() < 0.3:  # 30% chance for swap attempt\n            j = np.random.randint(n_items)\n            if i != j and new_solution[i] != new_solution[j]:\n                delta_weight = (weight_lst[j] - weight_lst[i]) if new_solution[i] == 1 else (weight_lst[i] - weight_lst[j])\n                if current_weight + delta_weight <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                    current_weight += delta_weight\n\n    # Value-weighted replacements\n    for i in range(n_items):\n        if new_solution[i] == 1 and np.random.random() < 0.5:  # 50% chance to consider replacement\n            # Calculate value-to-weight ratios\n            ratios = (value1_lst + value2_lst) / weight_lst\n            candidates = np.where((weight_lst <= capacity - current_weight + weight_lst[i]) &\n                               (new_solution == 0) &\n                               (ratios > ratios[i]))[0]\n            if len(candidates) > 0:\n                j = candidates[np.argmax(ratios[candidates])]  # Select best candidate\n                new_solution[i], new_solution[j] = 0, 1\n                current_weight += weight_lst[j] - weight_lst[i]\n\n    # Final feasibility check\n    while np.sum(weight_lst[new_solution == 1]) > capacity:\n        excess_items = np.where(new_solution == 1)[0]\n        if len(excess_items) == 0:\n            break\n        # Remove item with lowest value-to-weight ratio\n        ratios = (value1_lst[excess_items] + value2_lst[excess_items]) / weight_lst[excess_items]\n        i = excess_items[np.argmin(ratios)]\n        new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.44655856702936997,
            1.5639890134334564
        ]
    },
    {
        "algorithm": "The algorithm intelligently selects a solution from the archive, prioritizes items with high combined marginal gain for both objectives, performs targeted flips and replacements to improve Pareto-dominance, and ensures feasibility through dynamic weight checks. It balances exploration (via random selection and candidate ranking) with exploitation (via marginal gain analysis and Pareto-dominance checks), while strictly maintaining capacity constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Intelligently select a solution with high marginal impact\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Step 1: Dynamic marginal impact analysis\n    included = new_solution == 1\n    excluded = new_solution == 0\n\n    # Calculate marginal gains for excluded items (potential additions)\n    marginal_gain1 = value1_lst[excluded] / weight_lst[excluded]\n    marginal_gain2 = value2_lst[excluded] / weight_lst[excluded]\n\n    # Rank items by combined marginal gain (Pareto-dominance approximation)\n    combined_gain = marginal_gain1 + marginal_gain2\n    top_candidates = np.argsort(combined_gain)[-min(5, len(combined_gain)):]\n\n    # Step 2: Adaptive local search - targeted flips and replacements\n    for i in top_candidates:\n        if current_weight + weight_lst[i] <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    # Step 3: Dynamic Pareto-dominance check for included items\n    for i in np.where(included)[0]:\n        # Find items that would improve both objectives when swapped\n        candidates = np.where((weight_lst <= capacity - current_weight + weight_lst[i]) &\n                            (excluded) &\n                            ((value1_lst > value1_lst[i]) | (value2_lst > value2_lst[i])))[0]\n\n        if len(candidates) > 0:\n            j = np.random.choice(candidates)\n            new_solution[i], new_solution[j] = 0, 1\n            current_weight += weight_lst[j] - weight_lst[i]\n\n    # Ensure feasibility (final check)\n    while np.sum(weight_lst[new_solution == 1]) > capacity:\n        excess_items = np.where(new_solution == 1)[0]\n        if len(excess_items) == 0:\n            break\n        i = np.random.choice(excess_items)\n        new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.7989523428841754,
            1.974008470773697
        ]
    },
    {
        "algorithm": "The algorithm combines marginal impact analysis with adaptive local search by first selecting promising solutions near the Pareto frontier (top 30% by dominance), then applying a hybrid operator that probabilistically swaps items based on their marginal contribution to both objectives while ensuring feasibility, and finally performs targeted replacements of low-impact items with high-impact candidates, prioritizing solutions with higher combined marginal impact in both objectives. The algorithm maintains feasibility through continuous weight checks and dynamic adjustments, ensuring the generated neighbor solution remains valid.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Identify solutions near the Pareto frontier (top 30% by dominance)\n    dominance_scores = []\n    for i, (sol, obj) in enumerate(archive):\n        dominated = sum(1 for (_, other_obj) in archive if other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1]))\n        dominance_scores.append(dominated)\n    threshold = np.percentile(dominance_scores, 30)\n    candidate_indices = [i for i, score in enumerate(dominance_scores) if score <= threshold]\n\n    if not candidate_indices:\n        selected_idx = np.random.randint(0, len(archive))\n    else:\n        selected_idx = np.random.choice(candidate_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate marginal contributions for both objectives\n    marginal1 = np.where(base_solution == 1, -value1_lst, value1_lst)\n    marginal2 = np.where(base_solution == 1, -value2_lst, value2_lst)\n\n    # Probabilistic swaps based on combined marginal impact\n    for i in range(len(weight_lst)):\n        if np.random.random() < 0.4:  # 40% chance for swap attempt\n            j = np.random.randint(len(weight_lst))\n            if i != j:\n                delta_weight = (weight_lst[j] - weight_lst[i]) if new_solution[i] == 1 else (weight_lst[i] - weight_lst[j])\n                if current_weight + delta_weight <= capacity:\n                    # Accept swap if it improves at least one objective\n                    if (marginal1[i] + marginal1[j] > 0) or (marginal2[i] + marginal2[j] > 0):\n                        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                        current_weight += delta_weight\n\n    # Targeted replacements of low-impact items with high-impact candidates\n    for i in np.where(new_solution == 1)[0]:\n        if np.random.random() < 0.3:  # 30% chance to consider replacement\n            # Find items not in solution with high marginal impact\n            candidates = np.where((new_solution == 0) &\n                                ((marginal1 > marginal1[i]) | (marginal2 > marginal2[i])) &\n                                (weight_lst <= capacity - current_weight + weight_lst[i]))[0]\n            if len(candidates) > 0:\n                # Select candidate with highest combined marginal impact\n                combined_marginal = marginal1[candidates] + marginal2[candidates]\n                j = candidates[np.argmax(combined_marginal)]\n                new_solution[i], new_solution[j] = 0, 1\n                current_weight += weight_lst[j] - weight_lst[i]\n\n    # Final feasibility check and adjustment\n    while np.sum(weight_lst[new_solution == 1]) > capacity:\n        excess_items = np.where(new_solution == 1)[0]\n        if len(excess_items) == 0:\n            break\n        # Remove item with lowest combined marginal impact\n        combined_marginal = marginal1[excess_items] + marginal2[excess_items]\n        i = excess_items[np.argmin(combined_marginal)]\n        new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.5841007254867978,
            1.7514790296554565
        ]
    },
    {
        "algorithm": "The heuristic function selects a solution from the archive with high potential for improvement (prioritizing less-explored solutions) and applies a hybrid local search combining random swaps (exploration) with targeted item replacements (exploitation) to generate neighbors while ensuring feasibility. It intelligently selects items to swap based on their potential to improve both objectives, prioritizing higher-value items while maintaining capacity constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Intelligent selection: choose a solution with high potential for improvement\n    # We select a solution that is not too crowded in the archive (less likely to be explored)\n    # and has a high potential for improvement (high value but not fully packed)\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Hybrid local search: combine random swaps with targeted item replacements\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Step 1: Random swaps (exploration)\n    for _ in range(min(3, n_items // 2)):\n        i, j = np.random.choice(n_items, size=2, replace=False)\n        if new_solution[i] != new_solution[j]:\n            temp_weight = current_weight - weight_lst[i] + weight_lst[j] if new_solution[i] == 1 else current_weight + weight_lst[i] - weight_lst[j]\n            if temp_weight <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                current_weight = temp_weight\n\n    # Step 2: Targeted item replacements (exploitation)\n    # Identify items that could improve both objectives when swapped\n    for i in range(n_items):\n        if new_solution[i] == 1:\n            # Try to replace with an item not in the solution\n            candidates = np.where((weight_lst <= capacity - current_weight + weight_lst[i]) &\n                                (new_solution == 0) &\n                                ((value1_lst > value1_lst[i]) | (value2_lst > value2_lst[i])))[0]\n            if len(candidates) > 0:\n                j = np.random.choice(candidates)\n                new_solution[i], new_solution[j] = 0, 1\n                current_weight += weight_lst[j] - weight_lst[i]\n\n    # Ensure feasibility (in case of any numerical precision issues)\n    while np.sum(weight_lst[new_solution == 1]) > capacity:\n        # Randomly remove items until feasible\n        excess_items = np.where(new_solution == 1)[0]\n        if len(excess_items) == 0:\n            break\n        i = np.random.choice(excess_items)\n        new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.6520115066392751,
            3.8804451525211334
        ]
    }
]