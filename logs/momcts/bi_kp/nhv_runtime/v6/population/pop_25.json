[
    {
        "algorithm": "The algorithm combines intelligent solution selection with a three-phase local search: first exploring high-value items probabilistically, then performing targeted swaps to improve both objectives, and finally rebalancing by removing low-value items to maintain feasibility. It prioritizes items with high value ratios while dynamically adjusting the solution to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high value ratio potential\n    archive.sort(key=lambda x: (x[1][0] / (x[1][1] + 1e-6), sum(x[1])), reverse=True)\n    base_solution = archive[0][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n\n    # Calculate value ratios for each item\n    value_ratios = (value1_lst + 1e-6) / (value2_lst + 1e-6)\n    sorted_indices = np.argsort(value_ratios)\n\n    # Phase 1: Probabilistic item additions (exploration)\n    remaining_capacity = capacity - current_weight\n    candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n    if len(candidates) > 0:\n        # Select items with high value ratios first\n        for idx in sorted_indices[::-1]:\n            if idx in candidates and np.random.rand() < 0.7:  # 70% chance to add\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n                candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n                if len(candidates) == 0:\n                    break\n\n    # Phase 2: Targeted swaps based on objective improvements\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    for i in included_items:\n        for j in excluded_items:\n            if weight_lst[j] <= capacity - current_weight + weight_lst[i]:\n                # Check if swap improves both objectives\n                if (value1_lst[j] > value1_lst[i] and value2_lst[j] > value2_lst[i]) or \\\n                   (value1_lst[j] > value1_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity) or \\\n                   (value2_lst[j] > value2_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n                    new_solution[i], new_solution[j] = 0, 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    break\n\n    # Phase 3: Weight-sensitive rebalancing\n    while current_weight > capacity:\n        # Remove items with lowest value ratio first\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        worst_item = included_items[np.argmin(value_ratios[included_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "score": [
            -0.9382821717578097,
            0.46551522612571716
        ]
    },
    {
        "algorithm": "The algorithm randomly selects a solution from the archive and generates a neighbor by flipping up to 5 high-impact items (top 30% by marginal contribution to either objective), prioritizing those that improve both objectives while ensuring feasibility. It balances exploration (random selection) and exploitation (targeted flips) to balance the bi-objective trade-off. The critical design idea is the selection of high-impact items based on marginal contributions, ensuring the neighbor remains feasible while potentially improving both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst[base_solution == 1])\n\n    marginal_impact1 = value1_lst - value1_lst[base_solution == 1].sum()\n    marginal_impact2 = value2_lst - value2_lst[base_solution == 1].sum()\n\n    num_items = len(weight_lst)\n    top_items1 = np.argsort(marginal_impact1)[-max(1, num_items // 3):]\n    top_items2 = np.argsort(marginal_impact2)[-max(1, num_items // 3):]\n    top_items = np.union1d(top_items1, top_items2)\n\n    if len(top_items) > 0:\n        num_to_flip = min(5, len(top_items))\n        flip_indices = np.random.choice(top_items, size=num_to_flip, replace=False)\n\n        for idx in flip_indices:\n            if new_solution[idx] == 1:\n                if total_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    total_weight -= weight_lst[idx]\n            else:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    total_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.45860529653600796,
            0.24088504910469055
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using a hybrid criterion combining objective values and diversity, then generates a neighbor through three phases: (1) probabilistically adding high-impact items with adaptive thresholds, (2) capacity-aware swaps between items with complementary marginal improvements, and (3) dynamic rebalancing by removing low-utility items with a novel utility-based criterion that balances marginal impact and objective trade-offs. The algorithm prioritizes items with high combined marginal impact for objectives 1 and 2, while ensuring feasibility through capacity-aware operations and rebalancing.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine objective values and diversity\n    archive_with_diversity = []\n    for sol, obj in archive:\n        diversity = np.sum(np.abs(sol - archive[0][0]))  # Simple diversity measure\n        score = (obj[0] + obj[1]) * (1 + diversity/len(sol))\n        archive_with_diversity.append((sol, obj, score))\n\n    archive_with_diversity.sort(key=lambda x: x[2], reverse=True)\n    selected = archive_with_diversity[0][0].copy()\n    new_solution = selected.copy()\n    current_weight = np.sum(weight_lst[selected == 1])\n\n    # Calculate normalized marginal impacts\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = (marginal1 + marginal2) / 2\n\n    # Phase 1: Probabilistic addition with adaptive thresholds\n    remaining_capacity = capacity - current_weight\n    candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n\n    if len(candidates) > 0:\n        # Adaptive threshold based on current solution quality\n        threshold = np.percentile(combined_marginal, 100 - (current_weight/capacity)*30)\n        strong_candidates = candidates[combined_marginal[candidates] >= threshold]\n\n        if len(strong_candidates) > 0:\n            # Add with probability based on marginal impact\n            for idx in strong_candidates:\n                prob = min(0.9, combined_marginal[idx] / np.max(combined_marginal))\n                if np.random.rand() < prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n\n    # Phase 2: Capacity-aware swaps with complementary improvements\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    for i in included:\n        for j in excluded:\n            if weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                # Check for complementary improvements\n                if (marginal1[j] > marginal1[i] and marginal2[j] < marginal2[i]) or \\\n                   (marginal1[j] < marginal1[i] and marginal2[j] > marginal2[i]):\n                    new_solution[i], new_solution[j] = 0, 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    remaining_capacity = capacity - current_weight\n                    break\n\n    # Phase 3: Dynamic rebalancing with utility-based removal\n    while current_weight > capacity:\n        included = np.where(new_solution == 1)[0]\n        if len(included) == 0:\n            break\n\n        # Calculate utility scores for removal\n        utility_scores = []\n        for idx in included:\n            # Utility considers both marginal impact and objective trade-offs\n            utility = (combined_marginal[idx] *\n                      (1 - (value1_lst[idx]/(np.sum(value1_lst[included]) + 1e-6)) *\n                      (value2_lst[idx]/(np.sum(value2_lst[included]) + 1e-6))))\n            utility_scores.append((idx, utility))\n\n        utility_scores.sort(key=lambda x: x[1])\n        worst_idx = utility_scores[0][0]\n        new_solution[worst_idx] = 0\n        current_weight -= weight_lst[worst_idx]\n\n    return new_solution\n\n",
        "score": [
            -1.011331337201361,
            1.7290266454219818
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the most crowded region in the objective space to focus on well-represented trade-offs, then applies a hybrid local search combining multi-objective greedy insertion (prioritizing items with high combined marginal value) with deterministic removal of low-impact items (based on a fixed threshold). It ensures feasibility by strictly enforcing weight constraints during both insertion and removal operations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution from most crowded region in objective space\n    objectives = np.array([obj for _, obj in archive])\n    if len(objectives) > 1:\n        # Calculate crowding distance for each solution\n        crowding = np.zeros(len(objectives))\n        for i in range(2):  # For both objectives\n            sorted_idx = np.argsort(objectives[:, i])\n            crowding[sorted_idx[0]] = np.inf\n            crowding[sorted_idx[-1]] = np.inf\n            for j in range(1, len(objectives)-1):\n                if objectives[sorted_idx[-1], i] != objectives[sorted_idx[0], i]:\n                    crowding[sorted_idx[j]] += (objectives[sorted_idx[j+1], i] - objectives[sorted_idx[j-1], i]) / \\\n                                              (objectives[sorted_idx[-1], i] - objectives[sorted_idx[0], i])\n        # Select solution with highest crowding distance\n        selected_idx = np.argmax(crowding)\n    else:\n        selected_idx = 0\n\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n\n    # Multi-objective greedy insertion\n    available_items = np.where(base_solution == 0)[0]\n    if len(available_items) > 0:\n        # Calculate normalized marginal contributions\n        marginal1 = value1_lst[available_items] / (weight_lst[available_items] + 1e-6)\n        marginal2 = value2_lst[available_items] / (weight_lst[available_items] + 1e-6)\n        combined_marginal = (marginal1 + marginal2) / 2\n\n        # Sort by combined marginal value\n        sorted_items = available_items[np.argsort(combined_marginal)[::-1]]\n\n        # Try to add top items\n        for item in sorted_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n                break  # Add only one item per iteration\n\n    # Deterministic removal of low-impact items\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate impact score (product of normalized values)\n        impact_scores = (value1_lst[included_items] / (np.max(value1_lst) + 1e-6)) * \\\n                       (value2_lst[included_items] / (np.max(value2_lst) + 1e-6))\n        # Remove items with impact below threshold\n        threshold = 0.2  # Fixed threshold for removal\n        for i, item in enumerate(included_items):\n            if impact_scores[i] < threshold:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.8585810284176447,
            0.4377875030040741
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the Pareto frontier using weighted crowding distance, then applies a hybrid local search that first performs adaptive item replacement (prioritizing high marginal value ratios) and then, with a dynamic threshold, attempts Pareto-aware swaps to explore trade-offs while maintaining feasibility. The threshold adjusts based on archive size, and the method ensures solutions remain feasible by checking weight constraints during swaps.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    objectives = np.array([obj for _, obj in archive])\n    if len(objectives) > 1:\n        # Calculate weighted crowding distance to select frontier solutions\n        crowding = np.zeros(len(objectives))\n        for i in range(2):\n            sorted_idx = np.argsort(objectives[:, i])\n            crowding[sorted_idx[0]] = np.inf\n            crowding[sorted_idx[-1]] = np.inf\n            for j in range(1, len(objectives)-1):\n                if objectives[sorted_idx[-1], i] != objectives[sorted_idx[0], i]:\n                    crowding[sorted_idx[j]] += (objectives[sorted_idx[j+1], i] - objectives[sorted_idx[j-1], i]) / \\\n                                              (objectives[sorted_idx[-1], i] - objectives[sorted_idx[0], i])\n        # Weight crowding by solution's position relative to frontier\n        frontier_idx = np.argmax(np.sum(crowding))\n        selected_idx = frontier_idx\n    else:\n        selected_idx = 0\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Adaptive item replacement (prioritize high marginal value ratios)\n    included_items = np.where(base_solution == 1)[0]\n    excluded_items = np.where(base_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate marginal value ratios for included items\n        marginal1_in = value1_lst[included_items] / (weight_lst[included_items] + 1e-6)\n        marginal2_in = value2_lst[included_items] / (weight_lst[included_items] + 1e-6)\n        combined_in = (marginal1_in + marginal2_in) / 2\n\n        # Calculate marginal value ratios for excluded items\n        marginal1_out = value1_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        marginal2_out = value2_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        combined_out = (marginal1_out + marginal2_out) / 2\n\n        # Find best item to remove (lowest combined marginal)\n        remove_idx = np.argmin(combined_in)\n        item_to_remove = included_items[remove_idx]\n\n        # Find best item to add (highest combined marginal)\n        add_idx = np.argmax(combined_out)\n        item_to_add = excluded_items[add_idx]\n\n        # Perform swap if feasible\n        if (current_weight - weight_lst[item_to_remove] + weight_lst[item_to_add]) <= capacity:\n            new_solution[item_to_remove] = 0\n            new_solution[item_to_add] = 1\n\n    # Dynamic threshold for Pareto-aware swaps\n    threshold = 0.3 if len(archive) > 5 else 0.5  # Adjust threshold based on archive size\n    if np.random.random() < threshold:\n        # Try a random swap to explore trade-offs\n        included_items = np.where(new_solution == 1)[0]\n        excluded_items = np.where(new_solution == 0)[0]\n        if len(included_items) > 0 and len(excluded_items) > 0:\n            item_to_remove = np.random.choice(included_items)\n            item_to_add = np.random.choice(excluded_items)\n            if (current_weight - weight_lst[item_to_remove] + weight_lst[item_to_add]) <= capacity:\n                new_solution[item_to_remove] = 0\n                new_solution[item_to_add] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.7804210783472116,
            0.3466379642486572
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive using a diversity-aware mechanism that prioritizes solutions in underrepresented quadrants of the objective space, then applies a hybrid local search that dynamically adds high-marginal-value items and removes low-contribution items based on a weighted combination of the two objectives. The weighted marginal value calculation (with \u03b1=0.7 favoring the first objective) guides item additions, while dynamic removal thresholds (30th percentile of normalized contributions) ensure feasible solutions. The approach balances exploration (quadrant-based selection) and exploitation (marginal value prioritization).",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Novel diversity-aware selection\n    objectives = np.array([obj for _, obj in archive])\n    if len(objectives) > 1:\n        # Partition objective space into quadrants\n        median1 = np.median(objectives[:, 0])\n        median2 = np.median(objectives[:, 1])\n        quadrant_counts = np.zeros(4)\n        for obj in objectives:\n            if obj[0] > median1 and obj[1] > median2:\n                quadrant_counts[0] += 1\n            elif obj[0] <= median1 and obj[1] > median2:\n                quadrant_counts[1] += 1\n            elif obj[0] <= median1 and obj[1] <= median2:\n                quadrant_counts[2] += 1\n            else:\n                quadrant_counts[3] += 1\n\n        # Select from least populated quadrant\n        selected_quadrant = np.argmin(quadrant_counts)\n        candidate_indices = []\n        for i, obj in enumerate(objectives):\n            if (selected_quadrant == 0 and obj[0] > median1 and obj[1] > median2) or \\\n               (selected_quadrant == 1 and obj[0] <= median1 and obj[1] > median2) or \\\n               (selected_quadrant == 2 and obj[0] <= median1 and obj[1] <= median2) or \\\n               (selected_quadrant == 3 and obj[0] > median1 and obj[1] <= median2):\n                candidate_indices.append(i)\n\n        if candidate_indices:\n            # Calculate crowding distance within selected quadrant\n            quadrant_obj = objectives[candidate_indices]\n            crowding = np.zeros(len(quadrant_obj))\n            for i in range(2):\n                sorted_idx = np.argsort(quadrant_obj[:, i])\n                crowding[sorted_idx[0]] = np.inf\n                crowding[sorted_idx[-1]] = np.inf\n                for j in range(1, len(quadrant_obj)-1):\n                    if quadrant_obj[sorted_idx[-1], i] != quadrant_obj[sorted_idx[0], i]:\n                        crowding[sorted_idx[j]] += (quadrant_obj[sorted_idx[j+1], i] - quadrant_obj[sorted_idx[j-1], i]) / \\\n                                                  (quadrant_obj[sorted_idx[-1], i] - quadrant_obj[sorted_idx[0], i])\n            selected_idx = candidate_indices[np.argmax(crowding)]\n        else:\n            selected_idx = np.random.randint(len(archive))\n    else:\n        selected_idx = 0\n\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n\n    # Hybrid local search with dynamic threshold\n    available_items = np.where(base_solution == 0)[0]\n    if len(available_items) > 0:\n        # Weighted marginal value calculation\n        alpha = 0.7  # Weight for first objective\n        marginal = (alpha * value1_lst[available_items] + (1-alpha) * value2_lst[available_items]) / (weight_lst[available_items] + 1e-6)\n        sorted_items = available_items[np.argsort(marginal)[::-1]]\n\n        # Try to add top items\n        for item in sorted_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n                break\n\n    # Dynamic removal based on combined objective contribution\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate normalized combined contribution\n        total_value1 = np.sum(value1_lst[included_items])\n        total_value2 = np.sum(value2_lst[included_items])\n        contribution = (value1_lst[included_items] / total_value1 + value2_lst[included_items] / total_value2) / 2\n        dynamic_threshold = np.percentile(contribution, 30)  # Remove bottom 30%\n\n        for i, item in enumerate(included_items):\n            if contribution[i] < dynamic_threshold:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.9642388599604512,
            0.5729503333568573
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (top 20% by combined objective)\n    archive.sort(key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    selected_idx = min(int(0.2 * len(archive)), len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate weighted marginal impact for each objective and combined\n    marginal_impact1 = value1_lst / (weight_lst + 1e-6)\n    marginal_impact2 = value2_lst / (weight_lst + 1e-6)\n    combined_impact = (marginal_impact1 + marginal_impact2) / 2\n\n    # Phase 1: Dynamic high-impact additions (top 25% marginal impact for each objective)\n    top_impact_items1 = np.argsort(marginal_impact1)[::-1][:max(1, len(marginal_impact1) // 4)]\n    top_impact_items2 = np.argsort(marginal_impact2)[::-1][:max(1, len(marginal_impact2) // 4)]\n    top_impact_items = np.union1d(top_impact_items1, top_impact_items2)\n\n    remaining_capacity = capacity - current_weight\n    for idx in top_impact_items:\n        if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n            remaining_capacity -= weight_lst[idx]\n\n    # Phase 2: Adaptive swaps between high-impact items\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    for i in included_items:\n        for j in excluded_items:\n            if weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                # Check if swap improves both objectives or at least one with high probability\n                if ((marginal_impact1[j] > marginal_impact1[i] and marginal_impact2[j] > marginal_impact2[i]) or\n                    (marginal_impact1[j] > marginal_impact1[i] and np.random.rand() < 0.7) or\n                    (marginal_impact2[j] > marginal_impact2[i] and np.random.rand() < 0.7)):\n                    new_solution[i], new_solution[j] = 0, 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    remaining_capacity = capacity - current_weight\n                    break\n\n    # Phase 3: Capacity-preserving replacements with dynamic thresholds\n    while current_weight > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        # Remove items with lowest combined marginal impact\n        worst_item = included_items[np.argmin(combined_impact[included_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    # Phase 4: Probabilistic flips of high-impact items (up to 2 items)\n    high_impact_items = np.argsort(combined_impact)[::-1][:max(1, len(combined_impact) // 5)]\n    if len(high_impact_items) > 0:\n        num_to_flip = min(2, len(high_impact_items))\n        flip_indices = np.random.choice(high_impact_items, size=num_to_flip, replace=False)\n        for idx in flip_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.952293818245308,
            1.7788688838481903
        ]
    },
    {
        "algorithm": "The algorithm selects a random solution from the archive and generates a neighbor by flipping a dynamic subset of high-impact items (top 25% by marginal contribution to either objective), using a hybrid local search that includes add, swap, and replace operations, prioritizing items that improve both objectives while ensuring feasibility. It dynamically adjusts the number of flips (1-5) and includes occasional swaps to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst[base_solution == 1])\n\n    marginal_impact1 = value1_lst - value1_lst[base_solution == 1].sum()\n    marginal_impact2 = value2_lst - value2_lst[base_solution == 1].sum()\n\n    num_items = len(weight_lst)\n    top_items1 = np.argsort(marginal_impact1)[-max(1, num_items // 4):]\n    top_items2 = np.argsort(marginal_impact2)[-max(1, num_items // 4):]\n    top_items = np.union1d(top_items1, top_items2)\n\n    if len(top_items) > 0:\n        num_to_flip = min(5, max(1, len(top_items) // 2))\n        flip_indices = np.random.choice(top_items, size=num_to_flip, replace=False)\n\n        for idx in flip_indices:\n            if new_solution[idx] == 1:\n                if total_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    total_weight -= weight_lst[idx]\n            else:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    total_weight += weight_lst[idx]\n\n        if np.random.rand() < 0.3:\n            swap_indices = np.random.choice(top_items, size=min(2, len(top_items)), replace=False)\n            for idx in swap_indices:\n                if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    total_weight -= weight_lst[idx]\n                elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    total_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.40979307830754713,
            0.24711576104164124
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    archive.sort(key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate adaptive marginal impacts\n    marginal_impact1 = value1_lst * (1 - base_solution)\n    marginal_impact2 = value2_lst * (1 - base_solution)\n\n    # Dynamic thresholds (75th percentile)\n    threshold1 = np.percentile(marginal_impact1, 75)\n    threshold2 = np.percentile(marginal_impact2, 75)\n\n    # Phase 1: Hybrid add/swap operations\n    remaining_capacity = capacity - current_weight\n    candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n\n    if len(candidates) > 0:\n        # Add items with high marginal impact\n        high_impact1 = candidates[marginal_impact1[candidates] > threshold1]\n        high_impact2 = candidates[marginal_impact2[candidates] > threshold2]\n\n        for idx in np.concatenate([high_impact1, high_impact2]):\n            if np.random.rand() < 0.6:  # 60% chance to add\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n\n    # Phase 2: Targeted swaps with feasibility check\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    for i in included_items:\n        for j in excluded_items:\n            if (weight_lst[j] <= capacity - current_weight + weight_lst[i] and\n                (marginal_impact1[j] > marginal_impact1[i] or marginal_impact2[j] > marginal_impact2[i])):\n                new_solution[i], new_solution[j] = 0, 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                break\n\n    # Phase 3: Weight-sensitive removal\n    while current_weight > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        removal_candidates = included_items[np.argsort(marginal_impact1[included_items] + marginal_impact2[included_items])]\n        worst_item = removal_candidates[0]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "score": [
            -0.9322289850854732,
            0.6346070170402527
        ]
    },
    {
        "algorithm": "This algorithm selects a solution from the least crowded region in the objective space to explore underrepresented trade-offs, then applies a hybrid local search combining multi-objective greedy removal (prioritizing items with low combined marginal value) with probabilistic insertion of high-impact items (based on adaptive thresholds). The method ensures feasibility by checking weight constraints during both removal and insertion phases, and uses crowding distance to guide exploration toward less crowded regions of the Pareto front.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution from least crowded region in objective space\n    objectives = np.array([obj for _, obj in archive])\n    if len(objectives) > 1:\n        # Calculate crowding distance for each solution\n        crowding = np.zeros(len(objectives))\n        for i in range(2):  # For both objectives\n            sorted_idx = np.argsort(objectives[:, i])\n            crowding[sorted_idx[0]] = np.inf\n            crowding[sorted_idx[-1]] = np.inf\n            for j in range(1, len(objectives)-1):\n                if objectives[sorted_idx[-1], i] != objectives[sorted_idx[0], i]:\n                    crowding[sorted_idx[j]] += (objectives[sorted_idx[j+1], i] - objectives[sorted_idx[j-1], i]) / \\\n                                              (objectives[sorted_idx[-1], i] - objectives[sorted_idx[0], i])\n        # Select solution with lowest crowding distance\n        selected_idx = np.argmin(crowding)\n    else:\n        selected_idx = 0\n\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n\n    # Multi-objective greedy removal\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate normalized marginal contributions\n        marginal1 = value1_lst[included_items] / (weight_lst[included_items] + 1e-6)\n        marginal2 = value2_lst[included_items] / (weight_lst[included_items] + 1e-6)\n        combined_marginal = (marginal1 + marginal2) / 2\n\n        # Sort by combined marginal value (ascending)\n        sorted_items = included_items[np.argsort(combined_marginal)]\n\n        # Remove items with lowest combined marginal value\n        for item in sorted_items:\n            new_solution[item] = 0\n            current_weight -= weight_lst[item]\n            # Check if solution is still feasible\n            if current_weight <= capacity:\n                break  # Remove only one item per iteration\n\n    # Probabilistic insertion of high-impact items\n    available_items = np.where(new_solution == 0)[0]\n    if len(available_items) > 0:\n        # Calculate adaptive thresholds based on current solution's objectives\n        current_value1 = np.sum(value1_lst[new_solution == 1])\n        current_value2 = np.sum(value2_lst[new_solution == 1])\n        threshold1 = current_value1 * 0.8  # 80% of current value1\n        threshold2 = current_value2 * 0.8  # 80% of current value2\n\n        # Filter items that meet both thresholds\n        eligible_items = [item for item in available_items\n                         if value1_lst[item] >= threshold1 and\n                         value2_lst[item] >= threshold2 and\n                         current_weight + weight_lst[item] <= capacity]\n\n        if eligible_items:\n            # Randomly select one item to add\n            selected_item = np.random.choice(eligible_items)\n            new_solution[selected_item] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.7792387438254766,
            0.40261930227279663
        ]
    }
]