[
    {
        "algorithm": "The algorithm combines intelligent solution selection with a three-phase local search: first exploring high-value items probabilistically, then performing targeted swaps to improve both objectives, and finally rebalancing by removing low-value items to maintain feasibility. It prioritizes items with high value ratios while dynamically adjusting the solution to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high value ratio potential\n    archive.sort(key=lambda x: (x[1][0] / (x[1][1] + 1e-6), sum(x[1])), reverse=True)\n    base_solution = archive[0][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n\n    # Calculate value ratios for each item\n    value_ratios = (value1_lst + 1e-6) / (value2_lst + 1e-6)\n    sorted_indices = np.argsort(value_ratios)\n\n    # Phase 1: Probabilistic item additions (exploration)\n    remaining_capacity = capacity - current_weight\n    candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n    if len(candidates) > 0:\n        # Select items with high value ratios first\n        for idx in sorted_indices[::-1]:\n            if idx in candidates and np.random.rand() < 0.7:  # 70% chance to add\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n                candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n                if len(candidates) == 0:\n                    break\n\n    # Phase 2: Targeted swaps based on objective improvements\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    for i in included_items:\n        for j in excluded_items:\n            if weight_lst[j] <= capacity - current_weight + weight_lst[i]:\n                # Check if swap improves both objectives\n                if (value1_lst[j] > value1_lst[i] and value2_lst[j] > value2_lst[i]) or \\\n                   (value1_lst[j] > value1_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity) or \\\n                   (value2_lst[j] > value2_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n                    new_solution[i], new_solution[j] = 0, 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    break\n\n    # Phase 3: Weight-sensitive rebalancing\n    while current_weight > capacity:\n        # Remove items with lowest value ratio first\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        worst_item = included_items[np.argmin(value_ratios[included_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "score": [
            -0.9382821717578097,
            0.46551522612571716
        ]
    },
    {
        "algorithm": "The algorithm randomly selects a solution from the archive and generates a neighbor by flipping up to 5 high-impact items (top 30% by marginal contribution to either objective), prioritizing those that improve both objectives while ensuring feasibility. It balances exploration (random selection) and exploitation (targeted flips) to balance the bi-objective trade-off. The critical design idea is the selection of high-impact items based on marginal contributions, ensuring the neighbor remains feasible while potentially improving both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst[base_solution == 1])\n\n    marginal_impact1 = value1_lst - value1_lst[base_solution == 1].sum()\n    marginal_impact2 = value2_lst - value2_lst[base_solution == 1].sum()\n\n    num_items = len(weight_lst)\n    top_items1 = np.argsort(marginal_impact1)[-max(1, num_items // 3):]\n    top_items2 = np.argsort(marginal_impact2)[-max(1, num_items // 3):]\n    top_items = np.union1d(top_items1, top_items2)\n\n    if len(top_items) > 0:\n        num_to_flip = min(5, len(top_items))\n        flip_indices = np.random.choice(top_items, size=num_to_flip, replace=False)\n\n        for idx in flip_indices:\n            if new_solution[idx] == 1:\n                if total_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    total_weight -= weight_lst[idx]\n            else:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    total_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.45860529653600796,
            0.24088504910469055
        ]
    },
    {
        "algorithm": "The algorithm selects a high-potential solution from the archive, prioritizes items with high marginal impact (combining both objectives) for addition, then performs adaptive swaps to improve both objectives while ensuring feasibility, and finally rebalances the solution by removing low-impact items if the weight exceeds capacity. It balances exploration (via marginal impact) and exploitation (via adaptive swaps) while maintaining feasibility through weight-sensitive rebalancing.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    archive.sort(key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate combined marginal impact for each item\n    marginal_impact = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(marginal_impact)[::-1]  # Descending order\n\n    # Phase 1: Dynamic item selection based on marginal impact\n    remaining_capacity = capacity - current_weight\n    candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n\n    if len(candidates) > 0:\n        # Select top items with highest marginal impact\n        for idx in sorted_indices:\n            if idx in candidates and np.random.rand() < 0.6:  # 60% chance to add\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n                candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n                if len(candidates) == 0:\n                    break\n\n    # Phase 2: Adaptive flipping based on current solution's characteristics\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    # Calculate potential improvements for each swap\n    for i in included_items:\n        for j in excluded_items:\n            if weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                # Check if swap improves both objectives\n                if (value1_lst[j] > value1_lst[i] and value2_lst[j] > value2_lst[i]) or \\\n                   (value1_lst[j] > value1_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity) or \\\n                   (value2_lst[j] > value2_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n                    new_solution[i], new_solution[j] = 0, 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    remaining_capacity = capacity - current_weight\n                    break\n\n    # Phase 3: Weight-sensitive rebalancing with dynamic threshold\n    while current_weight > capacity:\n        # Remove items with lowest marginal impact first\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        worst_item = included_items[np.argmin(marginal_impact[included_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "score": [
            -0.9093676276444078,
            0.6341427564620972
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive (top 30% by combined objective value) and applies a hybrid local search combining probabilistic additions of high-impact items, targeted swaps between included and excluded items, and adaptive removals of low-impact items to ensure feasibility while balancing exploration and exploitation. It prioritizes items with high marginal impact (top percentile) in both objectives and dynamically adjusts the solution to maintain capacity constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential (top 30% by combined objective value)\n    archive.sort(key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    base_solution = archive[min(len(archive) // 3, len(archive) - 1)][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n\n    # Calculate adaptive marginal impact (percentile-based)\n    included = base_solution == 1\n    marginal_impact1 = value1_lst - value1_lst[included].sum()\n    marginal_impact2 = value2_lst - value2_lst[included].sum()\n    top_percentile = min(30, len(weight_lst) // 5)  # Dynamic threshold\n\n    top_items1 = np.argsort(marginal_impact1)[-top_percentile:]\n    top_items2 = np.argsort(marginal_impact2)[-top_percentile:]\n    top_items = np.union1d(top_items1, top_items2)\n\n    # Hybrid local search: Phase 1 - Probabilistic additions\n    remaining_capacity = capacity - current_weight\n    candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0) & np.isin(np.arange(len(weight_lst)), top_items))[0]\n    if len(candidates) > 0:\n        for idx in np.random.permutation(candidates):\n            if np.random.rand() < 0.5:  # 50% chance to add\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n                if remaining_capacity <= 0:\n                    break\n\n    # Phase 2 - Targeted swaps\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    for i in included_items:\n        if i not in top_items:\n            continue\n        for j in excluded_items:\n            if j not in top_items:\n                continue\n            if (weight_lst[j] <= remaining_capacity + weight_lst[i] and\n                (value1_lst[j] > value1_lst[i] or value2_lst[j] > value2_lst[i])):\n                new_solution[i], new_solution[j] = 0, 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                break\n\n    # Phase 3 - Adaptive removals\n    while current_weight > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        # Remove items with lowest combined marginal impact\n        marginal_combined = value1_lst[included_items] + value2_lst[included_items]\n        worst_item = included_items[np.argmin(marginal_combined)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "score": [
            -0.9131241836479801,
            3.4764381051063538
        ]
    },
    {
        "algorithm": "The algorithm first selects a solution from the archive with high potential for improvement, then applies a hybrid local search that combines probabilistic item additions (prioritizing high-value items), targeted swaps (ensuring multi-objective improvements), and adaptive rebalancing (removing low-value items to maintain feasibility). The exploration intensity is dynamically adjusted based on the solution's current weight, and the search prioritizes items with favorable value ratios while ensuring both objectives are improved.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n\n    # Calculate dynamic value ratios and prioritize items\n    value_ratios = (value1_lst + 1e-6) / (value2_lst + 1e-6)\n    sorted_indices = np.argsort(value_ratios)\n\n    # Phase 1: Probabilistic item additions with dynamic intensity\n    remaining_capacity = capacity - current_weight\n    candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n    if len(candidates) > 0:\n        # Adjust exploration intensity based on solution quality\n        exploration_prob = min(0.9, 0.5 + (current_weight / capacity) * 0.4)\n        for idx in sorted_indices[::-1]:\n            if idx in candidates and np.random.rand() < exploration_prob:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n                candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n                if len(candidates) == 0:\n                    break\n\n    # Phase 2: Targeted swaps with multi-objective improvement\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    for i in included_items:\n        for j in excluded_items:\n            if weight_lst[j] <= capacity - current_weight + weight_lst[i]:\n                # Check for multi-objective improvement\n                if (value1_lst[j] > value1_lst[i] and value2_lst[j] > value2_lst[i]) or \\\n                   (value1_lst[j] > value1_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity) or \\\n                   (value2_lst[j] > value2_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n                    new_solution[i], new_solution[j] = 0, 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    break\n\n    # Phase 3: Adaptive rebalancing with dynamic removal criteria\n    while current_weight > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        # Remove items with lowest value ratio or least contribution to objectives\n        removal_criteria = value_ratios[included_items] * (1 - (value1_lst[included_items] + value2_lst[included_items]) / (np.sum(value1_lst) + np.sum(value2_lst)))\n        worst_item = included_items[np.argmin(removal_criteria)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "score": [
            -0.8370011111640884,
            0.5209901034832001
        ]
    },
    {
        "algorithm": "The algorithm selects a random solution from the archive and generates a neighbor by flipping a subset of high-impact items (top 20% by marginal contribution to both objectives) while ensuring feasibility. It prioritizes items that improve both objectives and flips up to 3 of them randomly, adjusting weights accordingly. The heuristic balances exploration (random selection) and exploitation (targeted flips) to balance the bi-objective trade-off.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a neighbor using a hybrid local search: flip a subset of items with high marginal impact\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate marginal impact of each item (difference in objective values if flipped)\n    marginal_impact1 = value1_lst - value1_lst[base_solution == 1].sum()\n    marginal_impact2 = value2_lst - value2_lst[base_solution == 1].sum()\n\n    # Identify items with high marginal impact (top 20%)\n    num_items = len(weight_lst)\n    top_items1 = np.argsort(marginal_impact1)[-max(1, num_items // 5):]\n    top_items2 = np.argsort(marginal_impact2)[-max(1, num_items // 5):]\n    top_items = np.union1d(top_items1, top_items2)\n\n    # Randomly select a subset of top items to flip\n    if len(top_items) > 0:\n        num_to_flip = min(3, len(top_items))  # Flip up to 3 items\n        flip_indices = np.random.choice(top_items, size=num_to_flip, replace=False)\n\n        # Flip selected items and ensure feasibility\n        for idx in flip_indices:\n            if new_solution[idx] == 1:\n                if total_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    total_weight -= weight_lst[idx]\n            else:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    total_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3908341285465272,
            0.2811393439769745
        ]
    },
    {
        "algorithm": "The algorithm combines adaptive marginal impact analysis with a hybrid local search strategy that prioritizes high-impact items by first removing low-performing items below a 75th percentile ratio threshold, then strategically inserting top 30% high-margin items from excluded options, and finally performing probabilistic item replacements to rebalance the solution while maintaining feasibility through continuous weight tracking and dynamic adjustments. The method balances exploration (via random selection and insertion) with exploitation (targeted removal and replacement) while ensuring capacity constraints are respected through final feasibility checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest combined objective value\n    archive.sort(key=lambda x: sum(x[1]), reverse=True)\n    base_solution = archive[0][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Calculate dynamic thresholds for marginal impact\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0:\n        # Calculate value ratios for included items\n        included_ratios = (value1_lst[included_items] + 1e-6) / (value2_lst[included_items] + 1e-6)\n        ratio_threshold = np.percentile(included_ratios, 75)  # Top 25% ratio threshold\n\n        # Phase 1: Remove low-impact items below threshold\n        for i in included_items:\n            if (value1_lst[i] + 1e-6) / (value2_lst[i] + 1e-6) < ratio_threshold:\n                if np.random.rand() < 0.4:  # 40% chance to remove\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Phase 2: Insert high-impact items from excluded\n    if len(excluded_items) > 0:\n        # Calculate marginal improvements for excluded items\n        marginal_weights = weight_lst[excluded_items]\n        marginal_value1 = value1_lst[excluded_items]\n        marginal_value2 = value2_lst[excluded_items]\n\n        # Normalize and combine marginal improvements\n        norm_value1 = (marginal_value1 - np.min(marginal_value1)) / (np.max(marginal_value1) - np.min(marginal_value1) + 1e-8)\n        norm_value2 = (marginal_value2 - np.min(marginal_value2)) / (np.max(marginal_value2) - np.min(marginal_value2) + 1e-8)\n        combined_score = norm_value1 + norm_value2\n\n        # Select top 30% items by combined score\n        top_indices = np.argsort(combined_score)[-max(1, len(combined_score)//3):]\n        for idx in top_indices:\n            item = excluded_items[idx]\n            if current_weight + marginal_weights[idx] <= capacity:\n                if np.random.rand() < 0.6:  # 60% chance to insert\n                    new_solution[item] = 1\n                    current_weight += marginal_weights[idx]\n\n    # Phase 3: Probabilistic replacement for rebalancing\n    if current_weight < capacity:\n        # Find items to potentially replace\n        included_items = np.where(new_solution == 1)[0]\n        excluded_items = np.where(new_solution == 0)[0]\n\n        if len(included_items) > 0 and len(excluded_items) > 0:\n            # Calculate replacement potential\n            for i in included_items:\n                for j in excluded_items:\n                    if weight_lst[j] <= capacity - current_weight + weight_lst[i]:\n                        # Calculate potential improvement\n                        delta_value1 = value1_lst[j] - value1_lst[i]\n                        delta_value2 = value2_lst[j] - value2_lst[i]\n\n                        # Accept if both objectives improve or one improves significantly\n                        if (delta_value1 > 0 and delta_value2 > 0) or \\\n                           (delta_value1 > 0 and delta_value2 >= -0.1 * value2_lst[i]) or \\\n                           (delta_value2 > 0 and delta_value1 >= -0.1 * value1_lst[i]):\n                            if np.random.rand() < 0.5:  # 50% chance to replace\n                                new_solution[i], new_solution[j] = 0, 1\n                                current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                                break\n\n    # Final feasibility check\n    if np.sum(weight_lst * new_solution) > capacity:\n        # Remove items with lowest value ratio until feasible\n        while np.sum(weight_lst * new_solution) > capacity:\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break\n            value_ratios = (value1_lst[included_items] + 1e-6) / (value2_lst[included_items] + 1e-6)\n            worst_item = included_items[np.argmin(value_ratios)]\n            new_solution[worst_item] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8781872264842637,
            3.1987808644771576
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive based on marginal potential scores (prioritizing items with high value-weight ratios for both objectives), then applies a three-phase hybrid local search: probabilistic additions of high-marginal items, targeted swaps improving both objectives, and dynamic rebalancing by removing low-performing items below a 30th-percentile threshold to ensure feasibility. The method intelligently balances exploration and exploitation by dynamically adjusting thresholds and hybridizing operations to maintain solution quality across objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest marginal potential\n    marginal_scores = []\n    for sol, obj in archive:\n        included = sol == 1\n        excluded = sol == 0\n        obj1, obj2 = obj\n\n        # Calculate marginal impact for included items\n        included_marginal = (value1_lst[included] / weight_lst[included], value2_lst[included] / weight_lst[included])\n        # Calculate potential marginal impact for excluded items\n        excluded_marginal = (value1_lst[excluded] / weight_lst[excluded], value2_lst[excluded] / weight_lst[excluded])\n\n        # Score based on both objectives' potential improvement\n        score = np.mean(included_marginal[0]) + np.mean(included_marginal[1]) + 0.5 * np.mean(excluded_marginal[0]) + 0.5 * np.mean(excluded_marginal[1])\n        marginal_scores.append(score)\n\n    selected_idx = np.argmax(marginal_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Phase 1: Probabilistic additions based on normalized marginal impact\n    remaining_capacity = capacity - current_weight\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate normalized marginal impact scores\n        marginal_impact = (value1_lst[excluded_items] / weight_lst[excluded_items] + value2_lst[excluded_items] / weight_lst[excluded_items]) / 2\n        marginal_impact /= np.max(marginal_impact) if np.max(marginal_impact) > 0 else 1\n\n        # Add items with probability proportional to their normalized marginal impact\n        for i in excluded_items:\n            if weight_lst[i] <= remaining_capacity and np.random.rand() < marginal_impact[i] * 0.8:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n                remaining_capacity -= weight_lst[i]\n\n    # Phase 2: Targeted swaps improving both objectives\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    for i in included_items:\n        for j in excluded_items:\n            if weight_lst[j] <= capacity - current_weight + weight_lst[i]:\n                # Calculate objective improvements\n                obj1_improve = value1_lst[j] > value1_lst[i]\n                obj2_improve = value2_lst[j] > value2_lst[i]\n\n                # Accept swap if it improves both objectives or maintains feasibility\n                if (obj1_improve and obj2_improve) or (obj1_improve and current_weight - weight_lst[i] + weight_lst[j] <= capacity) or (obj2_improve and current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n                    new_solution[i], new_solution[j] = 0, 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    break\n\n    # Phase 3: Dynamic rebalancing with percentile-based thresholds\n    while current_weight > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n\n        # Calculate value-weight ratios and find 30th percentile threshold\n        ratios = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n        threshold = np.percentile(ratios, 30) if len(ratios) > 1 else np.min(ratios)\n\n        # Remove items below threshold\n        candidates = included_items[ratios <= threshold]\n        if len(candidates) > 0:\n            worst_item = candidates[np.argmin(ratios[ratios <= threshold])]\n            new_solution[worst_item] = 0\n            current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "score": [
            -0.8309101407237802,
            1.9195991456508636
        ]
    },
    {
        "algorithm": "The algorithm employs a multi-phase approach that first selects the most promising solution from the archive (prioritizing those with higher combined normalized utility scores), then adaptively adds high-utility items while respecting capacity constraints, followed by objective-aware swaps that prioritize items improving both objectives, and finally ensures feasibility through a weighted removal strategy that balances both objectives and weight. The dynamic selection probabilities and dominance-checking mechanism are key to its effectiveness.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Adaptive solution selection and initialization\n    archive.sort(key=lambda x: (x[1][0] + x[1][1]) / (sum(weight_lst[x[0] == 1]) + 1e-6), reverse=True)\n    base_solution = archive[0][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n\n    # Calculate normalized utility scores\n    norm_value1 = (value1_lst - np.min(value1_lst)) / (np.max(value1_lst) - np.min(value1_lst) + 1e-6)\n    norm_value2 = (value2_lst - np.min(value2_lst)) / (np.max(value2_lst) - np.min(value2_lst) + 1e-6)\n    utility_scores = (norm_value1 + norm_value2) / (weight_lst + 1e-6)\n\n    # Phase 2: Dynamic item addition with adaptive probabilities\n    remaining_capacity = capacity - current_weight\n    candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n\n    if len(candidates) > 0:\n        probs = utility_scores[candidates]\n        probs = probs / np.sum(probs)\n        selected = np.random.choice(candidates, size=min(3, len(candidates)), p=probs, replace=False)\n\n        for idx in selected:\n            if np.random.rand() < 0.8:  # 80% chance to add\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n\n    # Phase 3: Objective-aware swaps with dominance checking\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    for i in included:\n        for j in excluded:\n            if weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                # Novel dominance check\n                delta1 = value1_lst[j] - value1_lst[i]\n                delta2 = value2_lst[j] - value2_lst[i]\n                if (delta1 > 0 and delta2 > 0) or \\\n                   (delta1 > 0 and (current_weight - weight_lst[i] + weight_lst[j] <= capacity)) or \\\n                   (delta2 > 0 and (current_weight - weight_lst[i] + weight_lst[j] <= capacity)):\n                    new_solution[i], new_solution[j] = 0, 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    remaining_capacity = capacity - current_weight\n                    break\n\n    # Phase 4: Capacity-aware pruning with weighted removal\n    while current_weight > capacity:\n        included = np.where(new_solution == 1)[0]\n        if len(included) == 0:\n            break\n\n        # Calculate removal weights based on both objectives and weight\n        removal_weights = (value1_lst[included] + value2_lst[included]) / (weight_lst[included] + 1e-6)\n        worst_item = included[np.argmin(removal_weights)]\n\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "score": [
            -0.7899513916588247,
            0.9302513301372528
        ]
    },
    {
        "algorithm": "The algorithm selects a high-potential solution from the archive, then performs a three-phase local search: 1) probabilistically adds high-dominance items, 2) swaps items to improve dominance while maintaining feasibility, and 3) removes low-dominance items to ensure capacity constraints are satisfied. Dominance is prioritized over individual objective values, with items evaluated by their combined value-to-weight ratio, and swaps are only performed if they improve the product of the two objective values.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high dominance potential\n    archive.sort(key=lambda x: (x[1][0] * x[1][1], sum(x[1])), reverse=True)\n    base_solution = archive[0][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n\n    # Calculate dominance scores for each item\n    dominance_scores = (value1_lst * value2_lst) / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(dominance_scores)\n\n    # Phase 1: Probabilistic dominance-based additions\n    remaining_capacity = capacity - current_weight\n    candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n    if len(candidates) > 0:\n        for idx in sorted_indices[::-1]:\n            if idx in candidates and np.random.rand() < 0.6:  # 60% chance to add\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n                candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n                if len(candidates) == 0:\n                    break\n\n    # Phase 2: Dominance-aware swaps\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    for i in included_items:\n        for j in excluded_items:\n            if weight_lst[j] <= capacity - current_weight + weight_lst[i]:\n                # Check if swap improves dominance\n                if (value1_lst[j] * value2_lst[j] > value1_lst[i] * value2_lst[i]) and \\\n                   (current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n                    new_solution[i], new_solution[j] = 0, 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    break\n\n    # Phase 3: Capacity-aware removal\n    while current_weight > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        # Remove items with lowest dominance score first\n        worst_item = included_items[np.argmin(dominance_scores[included_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "score": [
            -0.8100387846760317,
            1.3364790380001068
        ]
    }
]