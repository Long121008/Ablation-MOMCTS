[
    {
        "algorithm": "The algorithm combines intelligent solution selection with a three-phase local search: first exploring high-value items probabilistically, then performing targeted swaps to improve both objectives, and finally rebalancing by removing low-value items to maintain feasibility. It prioritizes items with high value ratios while dynamically adjusting the solution to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high value ratio potential\n    archive.sort(key=lambda x: (x[1][0] / (x[1][1] + 1e-6), sum(x[1])), reverse=True)\n    base_solution = archive[0][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n\n    # Calculate value ratios for each item\n    value_ratios = (value1_lst + 1e-6) / (value2_lst + 1e-6)\n    sorted_indices = np.argsort(value_ratios)\n\n    # Phase 1: Probabilistic item additions (exploration)\n    remaining_capacity = capacity - current_weight\n    candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n    if len(candidates) > 0:\n        # Select items with high value ratios first\n        for idx in sorted_indices[::-1]:\n            if idx in candidates and np.random.rand() < 0.7:  # 70% chance to add\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n                candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n                if len(candidates) == 0:\n                    break\n\n    # Phase 2: Targeted swaps based on objective improvements\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    for i in included_items:\n        for j in excluded_items:\n            if weight_lst[j] <= capacity - current_weight + weight_lst[i]:\n                # Check if swap improves both objectives\n                if (value1_lst[j] > value1_lst[i] and value2_lst[j] > value2_lst[i]) or \\\n                   (value1_lst[j] > value1_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity) or \\\n                   (value2_lst[j] > value2_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n                    new_solution[i], new_solution[j] = 0, 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    break\n\n    # Phase 3: Weight-sensitive rebalancing\n    while current_weight > capacity:\n        # Remove items with lowest value ratio first\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        worst_item = included_items[np.argmin(value_ratios[included_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "score": [
            -0.9382821717578097,
            0.46551522612571716
        ]
    },
    {
        "algorithm": "The algorithm randomly selects a solution from the archive and generates a neighbor by flipping up to 5 high-impact items (top 30% by marginal contribution to either objective), prioritizing those that improve both objectives while ensuring feasibility. It balances exploration (random selection) and exploitation (targeted flips) to balance the bi-objective trade-off. The critical design idea is the selection of high-impact items based on marginal contributions, ensuring the neighbor remains feasible while potentially improving both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst[base_solution == 1])\n\n    marginal_impact1 = value1_lst - value1_lst[base_solution == 1].sum()\n    marginal_impact2 = value2_lst - value2_lst[base_solution == 1].sum()\n\n    num_items = len(weight_lst)\n    top_items1 = np.argsort(marginal_impact1)[-max(1, num_items // 3):]\n    top_items2 = np.argsort(marginal_impact2)[-max(1, num_items // 3):]\n    top_items = np.union1d(top_items1, top_items2)\n\n    if len(top_items) > 0:\n        num_to_flip = min(5, len(top_items))\n        flip_indices = np.random.choice(top_items, size=num_to_flip, replace=False)\n\n        for idx in flip_indices:\n            if new_solution[idx] == 1:\n                if total_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    total_weight -= weight_lst[idx]\n            else:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    total_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.45860529653600796,
            0.24088504910469055
        ]
    },
    {
        "algorithm": "The algorithm selects a high-potential solution from the archive, prioritizes items with high marginal impact (combining both objectives) for addition, then performs adaptive swaps to improve both objectives while ensuring feasibility, and finally rebalances the solution by removing low-impact items if the weight exceeds capacity. It balances exploration (via marginal impact) and exploitation (via adaptive swaps) while maintaining feasibility through weight-sensitive rebalancing.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    archive.sort(key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate combined marginal impact for each item\n    marginal_impact = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(marginal_impact)[::-1]  # Descending order\n\n    # Phase 1: Dynamic item selection based on marginal impact\n    remaining_capacity = capacity - current_weight\n    candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n\n    if len(candidates) > 0:\n        # Select top items with highest marginal impact\n        for idx in sorted_indices:\n            if idx in candidates and np.random.rand() < 0.6:  # 60% chance to add\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n                candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n                if len(candidates) == 0:\n                    break\n\n    # Phase 2: Adaptive flipping based on current solution's characteristics\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    # Calculate potential improvements for each swap\n    for i in included_items:\n        for j in excluded_items:\n            if weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                # Check if swap improves both objectives\n                if (value1_lst[j] > value1_lst[i] and value2_lst[j] > value2_lst[i]) or \\\n                   (value1_lst[j] > value1_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity) or \\\n                   (value2_lst[j] > value2_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n                    new_solution[i], new_solution[j] = 0, 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    remaining_capacity = capacity - current_weight\n                    break\n\n    # Phase 3: Weight-sensitive rebalancing with dynamic threshold\n    while current_weight > capacity:\n        # Remove items with lowest marginal impact first\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        worst_item = included_items[np.argmin(marginal_impact[included_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "score": [
            -0.9093676276444078,
            0.6341427564620972
        ]
    },
    {
        "algorithm": "The algorithm first selects a solution from the archive with high potential for improvement, then applies a hybrid local search that combines probabilistic item additions (prioritizing high-value items), targeted swaps (ensuring multi-objective improvements), and adaptive rebalancing (removing low-value items to maintain feasibility). The exploration intensity is dynamically adjusted based on the solution's current weight, and the search prioritizes items with favorable value ratios while ensuring both objectives are improved.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n\n    # Calculate dynamic value ratios and prioritize items\n    value_ratios = (value1_lst + 1e-6) / (value2_lst + 1e-6)\n    sorted_indices = np.argsort(value_ratios)\n\n    # Phase 1: Probabilistic item additions with dynamic intensity\n    remaining_capacity = capacity - current_weight\n    candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n    if len(candidates) > 0:\n        # Adjust exploration intensity based on solution quality\n        exploration_prob = min(0.9, 0.5 + (current_weight / capacity) * 0.4)\n        for idx in sorted_indices[::-1]:\n            if idx in candidates and np.random.rand() < exploration_prob:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n                candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n                if len(candidates) == 0:\n                    break\n\n    # Phase 2: Targeted swaps with multi-objective improvement\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    for i in included_items:\n        for j in excluded_items:\n            if weight_lst[j] <= capacity - current_weight + weight_lst[i]:\n                # Check for multi-objective improvement\n                if (value1_lst[j] > value1_lst[i] and value2_lst[j] > value2_lst[i]) or \\\n                   (value1_lst[j] > value1_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity) or \\\n                   (value2_lst[j] > value2_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n                    new_solution[i], new_solution[j] = 0, 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    break\n\n    # Phase 3: Adaptive rebalancing with dynamic removal criteria\n    while current_weight > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        # Remove items with lowest value ratio or least contribution to objectives\n        removal_criteria = value_ratios[included_items] * (1 - (value1_lst[included_items] + value2_lst[included_items]) / (np.sum(value1_lst) + np.sum(value2_lst)))\n        worst_item = included_items[np.argmin(removal_criteria)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "score": [
            -0.8370011111640884,
            0.5209901034832001
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive (top 20% by combined marginal impact), then generates a neighbor through a three-phase process: 1) adding high-impact items (70% chance for top 20% marginal items), 2) targeted swaps where excluded items dominate included ones in at least one objective while respecting capacity, and 3) dynamic rebalancing by removing low-marginal items if capacity is exceeded. The method prioritizes high-marginal items and ensures feasibility through capacity-aware operations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (top 20% by combined marginal impact)\n    archive.sort(key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    selected_idx = min(len(archive) // 5, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate combined marginal impact for each item\n    marginal_impact = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(marginal_impact)[::-1]  # Descending order\n\n    # Phase 1: Add high-impact items not in the solution\n    remaining_capacity = capacity - current_weight\n    candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n\n    if len(candidates) > 0:\n        # Select top 20% of high-impact items to add\n        num_to_add = max(1, len(sorted_indices) // 5)\n        for idx in sorted_indices[:num_to_add]:\n            if idx in candidates and np.random.rand() < 0.7:  # 70% chance to add\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n                candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n                if len(candidates) == 0:\n                    break\n\n    # Phase 2: Targeted swaps of high-impact items\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    # Calculate potential improvements for each swap\n    for i in included_items:\n        for j in excluded_items:\n            if weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                # Check if swap improves both objectives or at least one\n                if (value1_lst[j] > value1_lst[i] and value2_lst[j] > value2_lst[i]) or \\\n                   (value1_lst[j] > value1_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity) or \\\n                   (value2_lst[j] > value2_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n                    new_solution[i], new_solution[j] = 0, 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    remaining_capacity = capacity - current_weight\n                    break\n\n    # Phase 3: Dynamic rebalancing with percentile-based thresholds\n    while current_weight > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        # Remove items with lowest 20% marginal impact\n        remove_threshold = np.percentile(marginal_impact[included_items], 20)\n        worst_items = included_items[marginal_impact[included_items] <= remove_threshold]\n        if len(worst_items) > 0:\n            worst_item = worst_items[0]\n            new_solution[worst_item] = 0\n            current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "score": [
            -0.8172125621391388,
            0.5021446347236633
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    archive.sort(key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate adaptive marginal impacts\n    marginal_impact1 = value1_lst * (1 - base_solution)\n    marginal_impact2 = value2_lst * (1 - base_solution)\n\n    # Dynamic thresholds (75th percentile)\n    threshold1 = np.percentile(marginal_impact1, 75)\n    threshold2 = np.percentile(marginal_impact2, 75)\n\n    # Phase 1: Hybrid add/swap operations\n    remaining_capacity = capacity - current_weight\n    candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n\n    if len(candidates) > 0:\n        # Add items with high marginal impact\n        high_impact1 = candidates[marginal_impact1[candidates] > threshold1]\n        high_impact2 = candidates[marginal_impact2[candidates] > threshold2]\n\n        for idx in np.concatenate([high_impact1, high_impact2]):\n            if np.random.rand() < 0.6:  # 60% chance to add\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n\n    # Phase 2: Targeted swaps with feasibility check\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    for i in included_items:\n        for j in excluded_items:\n            if (weight_lst[j] <= capacity - current_weight + weight_lst[i] and\n                (marginal_impact1[j] > marginal_impact1[i] or marginal_impact2[j] > marginal_impact2[i])):\n                new_solution[i], new_solution[j] = 0, 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                break\n\n    # Phase 3: Weight-sensitive removal\n    while current_weight > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        removal_candidates = included_items[np.argsort(marginal_impact1[included_items] + marginal_impact2[included_items])]\n        worst_item = removal_candidates[0]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "score": [
            -0.9322289850854732,
            0.6346070170402527
        ]
    },
    {
        "algorithm": "The algorithm selects a random solution from the archive and generates a neighbor by flipping a dynamic subset of high-impact items (top 25% by marginal contribution to either objective), using a hybrid local search that includes add, swap, and replace operations, prioritizing items that improve both objectives while ensuring feasibility. It dynamically adjusts the number of flips (1-5) and includes occasional swaps to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst[base_solution == 1])\n\n    marginal_impact1 = value1_lst - value1_lst[base_solution == 1].sum()\n    marginal_impact2 = value2_lst - value2_lst[base_solution == 1].sum()\n\n    num_items = len(weight_lst)\n    top_items1 = np.argsort(marginal_impact1)[-max(1, num_items // 4):]\n    top_items2 = np.argsort(marginal_impact2)[-max(1, num_items // 4):]\n    top_items = np.union1d(top_items1, top_items2)\n\n    if len(top_items) > 0:\n        num_to_flip = min(5, max(1, len(top_items) // 2))\n        flip_indices = np.random.choice(top_items, size=num_to_flip, replace=False)\n\n        for idx in flip_indices:\n            if new_solution[idx] == 1:\n                if total_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    total_weight -= weight_lst[idx]\n            else:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    total_weight += weight_lst[idx]\n\n        if np.random.rand() < 0.3:\n            swap_indices = np.random.choice(top_items, size=min(2, len(top_items)), replace=False)\n            for idx in swap_indices:\n                if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    total_weight -= weight_lst[idx]\n                elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    total_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.40979307830754713,
            0.24711576104164124
        ]
    },
    {
        "algorithm": "This algorithm selects a promising solution from an archive based on weight utilization and objective dominance, then applies a three-phase hybrid local search: Phase 1 adds high-impact items using dynamic marginal thresholds, Phase 2 performs targeted swaps between high-impact items from both objectives, and Phase 3 adaptively removes low-contribution items when capacity is exceeded, using percentile-based criteria to balance both objectives while ensuring feasibility. The selection prioritizes solutions with higher weight utilization and better objective product scores, while the local search dynamically adjusts thresholds to explore the solution space more effectively.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution based on weight utilization and objective dominance\n    utilization = [np.sum(weight_lst[s[0] == 1]) / capacity for s in archive]\n    dominance = [s[1][0] * s[1][1] for s in archive]\n    scores = [u * d for u, d in zip(utilization, dominance)]\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Phase 1: Dynamic marginal impact thresholding\n    marginal1 = value1_lst - np.sum(value1_lst[base_solution == 1])\n    marginal2 = value2_lst - np.sum(value2_lst[base_solution == 1])\n\n    # Calculate dynamic thresholds based on percentiles\n    p1_threshold = np.percentile(marginal1, 70)\n    p2_threshold = np.percentile(marginal2, 70)\n\n    # Identify candidate items\n    candidates1 = np.where((marginal1 > p1_threshold) & (new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n    candidates2 = np.where((marginal2 > p2_threshold) & (new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n    candidates = np.union1d(candidates1, candidates2)\n\n    # Add high-impact items\n    for idx in candidates:\n        if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 2: Targeted swaps between objectives\n    included1 = np.where((new_solution == 1) & (marginal1 > p1_threshold))[0]\n    included2 = np.where((new_solution == 1) & (marginal2 > p2_threshold))[0]\n\n    for i in included1:\n        for j in included2:\n            if weight_lst[j] <= capacity - current_weight + weight_lst[i]:\n                if (marginal1[j] > marginal1[i] and marginal2[j] > marginal2[i]) or \\\n                   (marginal1[j] > marginal1[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity) or \\\n                   (marginal2[j] > marginal2[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n                    new_solution[i], new_solution[j] = 0, 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    break\n\n    # Phase 3: Adaptive replacement with percentile-based criteria\n    while current_weight > capacity:\n        included = np.where(new_solution == 1)[0]\n        if len(included) == 0:\n            break\n\n        # Calculate replacement criteria based on marginal impact percentiles\n        p1 = np.percentile(marginal1[included], 30)\n        p2 = np.percentile(marginal2[included], 30)\n        criteria = (marginal1[included] <= p1) | (marginal2[included] <= p2)\n\n        if np.any(criteria):\n            worst_items = included[criteria]\n            remove_idx = worst_items[np.argmin(weight_lst[worst_items])]\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n        else:\n            # Remove least valuable item if no candidates meet criteria\n            remove_idx = included[np.argmin(marginal1[included] + marginal2[included])]\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9203671744323288,
            0.809229165315628
        ]
    },
    {
        "algorithm": "The algorithm selects a random solution from the archive and generates a neighbor by flipping a subset of high-impact items (top 20% by marginal contribution to both objectives) while ensuring feasibility. It prioritizes items that improve both objectives and flips up to 3 of them randomly, adjusting weights accordingly. The heuristic balances exploration (random selection) and exploitation (targeted flips) to balance the bi-objective trade-off.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a neighbor using a hybrid local search: flip a subset of items with high marginal impact\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate marginal impact of each item (difference in objective values if flipped)\n    marginal_impact1 = value1_lst - value1_lst[base_solution == 1].sum()\n    marginal_impact2 = value2_lst - value2_lst[base_solution == 1].sum()\n\n    # Identify items with high marginal impact (top 20%)\n    num_items = len(weight_lst)\n    top_items1 = np.argsort(marginal_impact1)[-max(1, num_items // 5):]\n    top_items2 = np.argsort(marginal_impact2)[-max(1, num_items // 5):]\n    top_items = np.union1d(top_items1, top_items2)\n\n    # Randomly select a subset of top items to flip\n    if len(top_items) > 0:\n        num_to_flip = min(3, len(top_items))  # Flip up to 3 items\n        flip_indices = np.random.choice(top_items, size=num_to_flip, replace=False)\n\n        # Flip selected items and ensure feasibility\n        for idx in flip_indices:\n            if new_solution[idx] == 1:\n                if total_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    total_weight -= weight_lst[idx]\n            else:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    total_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3908341285465272,
            0.2811393439769745
        ]
    },
    {
        "algorithm": "The algorithm combines adaptive marginal impact analysis with a three-phase local search strategy: it first selects high-impact items using dynamic percentile thresholds, probabilistically flips them to explore the solution space while maintaining feasibility, then performs greedy replacements of low-impact items with high-impact alternatives, and finally ensures feasibility through targeted removals. The approach prioritizes items with high combined marginal impact in both objectives while dynamically adjusting the solution to balance the bi-objective trade-off and capacity constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential (top 20% by combined objective value)\n    archive.sort(key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    base_solution = archive[min(len(archive) // 5, len(archive) - 1)][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate adaptive marginal impact (percentile-based)\n    marginal_impact1 = value1_lst - value1_lst[base_solution == 1].sum()\n    marginal_impact2 = value2_lst - value2_lst[base_solution == 1].sum()\n    top_percentile = min(25, len(weight_lst) // 4)  # Dynamic threshold\n\n    top_items1 = np.argsort(marginal_impact1)[-top_percentile:]\n    top_items2 = np.argsort(marginal_impact2)[-top_percentile:]\n    top_items = np.union1d(top_items1, top_items2)\n\n    # Phase 1: Probabilistic flips of high-impact items\n    for idx in top_items:\n        if np.random.rand() < 0.3:  # 30% chance to flip\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Phase 2: Greedy replacement of low-impact items\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Find items with lowest combined marginal impact\n        marginal_combined = value1_lst[included_items] + value2_lst[included_items]\n        worst_items = included_items[np.argsort(marginal_combined)[:min(3, len(included_items))]]\n\n        for worst in worst_items:\n            # Find best replacement item (highest marginal impact, not already included)\n            candidates = np.where((weight_lst <= current_weight - weight_lst[worst] + capacity) &\n                                (new_solution == 0) &\n                                np.isin(np.arange(len(weight_lst)), top_items))[0]\n            if len(candidates) > 0:\n                best_candidate = candidates[np.argmax(value1_lst[candidates] + value2_lst[candidates])]\n                new_solution[worst] = 0\n                new_solution[best_candidate] = 1\n                current_weight = current_weight - weight_lst[worst] + weight_lst[best_candidate]\n\n    # Phase 3: Final feasibility check and adjustments\n    while current_weight > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        # Remove items with lowest combined marginal impact\n        marginal_combined = value1_lst[included_items] + value2_lst[included_items]\n        worst_item = included_items[np.argmin(marginal_combined)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "score": [
            -0.4449410662760863,
            0.5290350914001465
        ]
    }
]