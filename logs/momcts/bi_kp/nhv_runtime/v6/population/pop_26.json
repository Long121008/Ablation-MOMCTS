[
    {
        "algorithm": "The algorithm combines intelligent solution selection with a three-phase local search: first exploring high-value items probabilistically, then performing targeted swaps to improve both objectives, and finally rebalancing by removing low-value items to maintain feasibility. It prioritizes items with high value ratios while dynamically adjusting the solution to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high value ratio potential\n    archive.sort(key=lambda x: (x[1][0] / (x[1][1] + 1e-6), sum(x[1])), reverse=True)\n    base_solution = archive[0][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n\n    # Calculate value ratios for each item\n    value_ratios = (value1_lst + 1e-6) / (value2_lst + 1e-6)\n    sorted_indices = np.argsort(value_ratios)\n\n    # Phase 1: Probabilistic item additions (exploration)\n    remaining_capacity = capacity - current_weight\n    candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n    if len(candidates) > 0:\n        # Select items with high value ratios first\n        for idx in sorted_indices[::-1]:\n            if idx in candidates and np.random.rand() < 0.7:  # 70% chance to add\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n                candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n                if len(candidates) == 0:\n                    break\n\n    # Phase 2: Targeted swaps based on objective improvements\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    for i in included_items:\n        for j in excluded_items:\n            if weight_lst[j] <= capacity - current_weight + weight_lst[i]:\n                # Check if swap improves both objectives\n                if (value1_lst[j] > value1_lst[i] and value2_lst[j] > value2_lst[i]) or \\\n                   (value1_lst[j] > value1_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity) or \\\n                   (value2_lst[j] > value2_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n                    new_solution[i], new_solution[j] = 0, 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    break\n\n    # Phase 3: Weight-sensitive rebalancing\n    while current_weight > capacity:\n        # Remove items with lowest value ratio first\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        worst_item = included_items[np.argmin(value_ratios[included_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "score": [
            -0.9382821717578097,
            0.46551522612571716
        ]
    },
    {
        "algorithm": "The algorithm randomly selects a solution from the archive and generates a neighbor by flipping up to 5 high-impact items (top 30% by marginal contribution to either objective), prioritizing those that improve both objectives while ensuring feasibility. It balances exploration (random selection) and exploitation (targeted flips) to balance the bi-objective trade-off. The critical design idea is the selection of high-impact items based on marginal contributions, ensuring the neighbor remains feasible while potentially improving both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst[base_solution == 1])\n\n    marginal_impact1 = value1_lst - value1_lst[base_solution == 1].sum()\n    marginal_impact2 = value2_lst - value2_lst[base_solution == 1].sum()\n\n    num_items = len(weight_lst)\n    top_items1 = np.argsort(marginal_impact1)[-max(1, num_items // 3):]\n    top_items2 = np.argsort(marginal_impact2)[-max(1, num_items // 3):]\n    top_items = np.union1d(top_items1, top_items2)\n\n    if len(top_items) > 0:\n        num_to_flip = min(5, len(top_items))\n        flip_indices = np.random.choice(top_items, size=num_to_flip, replace=False)\n\n        for idx in flip_indices:\n            if new_solution[idx] == 1:\n                if total_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    total_weight -= weight_lst[idx]\n            else:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    total_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.45860529653600796,
            0.24088504910469055
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using a hybrid criterion combining objective values and diversity, then generates a neighbor through three phases: (1) probabilistically adding high-impact items with adaptive thresholds, (2) capacity-aware swaps between items with complementary marginal improvements, and (3) dynamic rebalancing by removing low-utility items with a novel utility-based criterion that balances marginal impact and objective trade-offs. The algorithm prioritizes items with high combined marginal impact for objectives 1 and 2, while ensuring feasibility through capacity-aware operations and rebalancing.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine objective values and diversity\n    archive_with_diversity = []\n    for sol, obj in archive:\n        diversity = np.sum(np.abs(sol - archive[0][0]))  # Simple diversity measure\n        score = (obj[0] + obj[1]) * (1 + diversity/len(sol))\n        archive_with_diversity.append((sol, obj, score))\n\n    archive_with_diversity.sort(key=lambda x: x[2], reverse=True)\n    selected = archive_with_diversity[0][0].copy()\n    new_solution = selected.copy()\n    current_weight = np.sum(weight_lst[selected == 1])\n\n    # Calculate normalized marginal impacts\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = (marginal1 + marginal2) / 2\n\n    # Phase 1: Probabilistic addition with adaptive thresholds\n    remaining_capacity = capacity - current_weight\n    candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n\n    if len(candidates) > 0:\n        # Adaptive threshold based on current solution quality\n        threshold = np.percentile(combined_marginal, 100 - (current_weight/capacity)*30)\n        strong_candidates = candidates[combined_marginal[candidates] >= threshold]\n\n        if len(strong_candidates) > 0:\n            # Add with probability based on marginal impact\n            for idx in strong_candidates:\n                prob = min(0.9, combined_marginal[idx] / np.max(combined_marginal))\n                if np.random.rand() < prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n\n    # Phase 2: Capacity-aware swaps with complementary improvements\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    for i in included:\n        for j in excluded:\n            if weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                # Check for complementary improvements\n                if (marginal1[j] > marginal1[i] and marginal2[j] < marginal2[i]) or \\\n                   (marginal1[j] < marginal1[i] and marginal2[j] > marginal2[i]):\n                    new_solution[i], new_solution[j] = 0, 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    remaining_capacity = capacity - current_weight\n                    break\n\n    # Phase 3: Dynamic rebalancing with utility-based removal\n    while current_weight > capacity:\n        included = np.where(new_solution == 1)[0]\n        if len(included) == 0:\n            break\n\n        # Calculate utility scores for removal\n        utility_scores = []\n        for idx in included:\n            # Utility considers both marginal impact and objective trade-offs\n            utility = (combined_marginal[idx] *\n                      (1 - (value1_lst[idx]/(np.sum(value1_lst[included]) + 1e-6)) *\n                      (value2_lst[idx]/(np.sum(value2_lst[included]) + 1e-6))))\n            utility_scores.append((idx, utility))\n\n        utility_scores.sort(key=lambda x: x[1])\n        worst_idx = utility_scores[0][0]\n        new_solution[worst_idx] = 0\n        current_weight -= weight_lst[worst_idx]\n\n    return new_solution\n\n",
        "score": [
            -1.011331337201361,
            1.7290266454219818
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the most crowded region in the objective space to focus on well-represented trade-offs, then applies a hybrid local search combining multi-objective greedy insertion (prioritizing items with high combined marginal value) with deterministic removal of low-impact items (based on a fixed threshold). It ensures feasibility by strictly enforcing weight constraints during both insertion and removal operations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution from most crowded region in objective space\n    objectives = np.array([obj for _, obj in archive])\n    if len(objectives) > 1:\n        # Calculate crowding distance for each solution\n        crowding = np.zeros(len(objectives))\n        for i in range(2):  # For both objectives\n            sorted_idx = np.argsort(objectives[:, i])\n            crowding[sorted_idx[0]] = np.inf\n            crowding[sorted_idx[-1]] = np.inf\n            for j in range(1, len(objectives)-1):\n                if objectives[sorted_idx[-1], i] != objectives[sorted_idx[0], i]:\n                    crowding[sorted_idx[j]] += (objectives[sorted_idx[j+1], i] - objectives[sorted_idx[j-1], i]) / \\\n                                              (objectives[sorted_idx[-1], i] - objectives[sorted_idx[0], i])\n        # Select solution with highest crowding distance\n        selected_idx = np.argmax(crowding)\n    else:\n        selected_idx = 0\n\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n\n    # Multi-objective greedy insertion\n    available_items = np.where(base_solution == 0)[0]\n    if len(available_items) > 0:\n        # Calculate normalized marginal contributions\n        marginal1 = value1_lst[available_items] / (weight_lst[available_items] + 1e-6)\n        marginal2 = value2_lst[available_items] / (weight_lst[available_items] + 1e-6)\n        combined_marginal = (marginal1 + marginal2) / 2\n\n        # Sort by combined marginal value\n        sorted_items = available_items[np.argsort(combined_marginal)[::-1]]\n\n        # Try to add top items\n        for item in sorted_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n                break  # Add only one item per iteration\n\n    # Deterministic removal of low-impact items\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate impact score (product of normalized values)\n        impact_scores = (value1_lst[included_items] / (np.max(value1_lst) + 1e-6)) * \\\n                       (value2_lst[included_items] / (np.max(value2_lst) + 1e-6))\n        # Remove items with impact below threshold\n        threshold = 0.2  # Fixed threshold for removal\n        for i, item in enumerate(included_items):\n            if impact_scores[i] < threshold:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.8585810284176447,
            0.4377875030040741
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the Pareto frontier using weighted crowding distance, then applies a hybrid local search that first performs adaptive item replacement (prioritizing high marginal value ratios) and then, with a dynamic threshold, attempts Pareto-aware swaps to explore trade-offs while maintaining feasibility. The threshold adjusts based on archive size, and the method ensures solutions remain feasible by checking weight constraints during swaps.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    objectives = np.array([obj for _, obj in archive])\n    if len(objectives) > 1:\n        # Calculate weighted crowding distance to select frontier solutions\n        crowding = np.zeros(len(objectives))\n        for i in range(2):\n            sorted_idx = np.argsort(objectives[:, i])\n            crowding[sorted_idx[0]] = np.inf\n            crowding[sorted_idx[-1]] = np.inf\n            for j in range(1, len(objectives)-1):\n                if objectives[sorted_idx[-1], i] != objectives[sorted_idx[0], i]:\n                    crowding[sorted_idx[j]] += (objectives[sorted_idx[j+1], i] - objectives[sorted_idx[j-1], i]) / \\\n                                              (objectives[sorted_idx[-1], i] - objectives[sorted_idx[0], i])\n        # Weight crowding by solution's position relative to frontier\n        frontier_idx = np.argmax(np.sum(crowding))\n        selected_idx = frontier_idx\n    else:\n        selected_idx = 0\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Adaptive item replacement (prioritize high marginal value ratios)\n    included_items = np.where(base_solution == 1)[0]\n    excluded_items = np.where(base_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate marginal value ratios for included items\n        marginal1_in = value1_lst[included_items] / (weight_lst[included_items] + 1e-6)\n        marginal2_in = value2_lst[included_items] / (weight_lst[included_items] + 1e-6)\n        combined_in = (marginal1_in + marginal2_in) / 2\n\n        # Calculate marginal value ratios for excluded items\n        marginal1_out = value1_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        marginal2_out = value2_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        combined_out = (marginal1_out + marginal2_out) / 2\n\n        # Find best item to remove (lowest combined marginal)\n        remove_idx = np.argmin(combined_in)\n        item_to_remove = included_items[remove_idx]\n\n        # Find best item to add (highest combined marginal)\n        add_idx = np.argmax(combined_out)\n        item_to_add = excluded_items[add_idx]\n\n        # Perform swap if feasible\n        if (current_weight - weight_lst[item_to_remove] + weight_lst[item_to_add]) <= capacity:\n            new_solution[item_to_remove] = 0\n            new_solution[item_to_add] = 1\n\n    # Dynamic threshold for Pareto-aware swaps\n    threshold = 0.3 if len(archive) > 5 else 0.5  # Adjust threshold based on archive size\n    if np.random.random() < threshold:\n        # Try a random swap to explore trade-offs\n        included_items = np.where(new_solution == 1)[0]\n        excluded_items = np.where(new_solution == 0)[0]\n        if len(included_items) > 0 and len(excluded_items) > 0:\n            item_to_remove = np.random.choice(included_items)\n            item_to_add = np.random.choice(excluded_items)\n            if (current_weight - weight_lst[item_to_remove] + weight_lst[item_to_add]) <= capacity:\n                new_solution[item_to_remove] = 0\n                new_solution[item_to_add] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.7804210783472116,
            0.3466379642486572
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive using a diversity-aware mechanism that prioritizes solutions in underrepresented quadrants of the objective space, then applies a hybrid local search that dynamically adds high-marginal-value items and removes low-contribution items based on a weighted combination of the two objectives. The weighted marginal value calculation (with \u03b1=0.7 favoring the first objective) guides item additions, while dynamic removal thresholds (30th percentile of normalized contributions) ensure feasible solutions. The approach balances exploration (quadrant-based selection) and exploitation (marginal value prioritization).",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Novel diversity-aware selection\n    objectives = np.array([obj for _, obj in archive])\n    if len(objectives) > 1:\n        # Partition objective space into quadrants\n        median1 = np.median(objectives[:, 0])\n        median2 = np.median(objectives[:, 1])\n        quadrant_counts = np.zeros(4)\n        for obj in objectives:\n            if obj[0] > median1 and obj[1] > median2:\n                quadrant_counts[0] += 1\n            elif obj[0] <= median1 and obj[1] > median2:\n                quadrant_counts[1] += 1\n            elif obj[0] <= median1 and obj[1] <= median2:\n                quadrant_counts[2] += 1\n            else:\n                quadrant_counts[3] += 1\n\n        # Select from least populated quadrant\n        selected_quadrant = np.argmin(quadrant_counts)\n        candidate_indices = []\n        for i, obj in enumerate(objectives):\n            if (selected_quadrant == 0 and obj[0] > median1 and obj[1] > median2) or \\\n               (selected_quadrant == 1 and obj[0] <= median1 and obj[1] > median2) or \\\n               (selected_quadrant == 2 and obj[0] <= median1 and obj[1] <= median2) or \\\n               (selected_quadrant == 3 and obj[0] > median1 and obj[1] <= median2):\n                candidate_indices.append(i)\n\n        if candidate_indices:\n            # Calculate crowding distance within selected quadrant\n            quadrant_obj = objectives[candidate_indices]\n            crowding = np.zeros(len(quadrant_obj))\n            for i in range(2):\n                sorted_idx = np.argsort(quadrant_obj[:, i])\n                crowding[sorted_idx[0]] = np.inf\n                crowding[sorted_idx[-1]] = np.inf\n                for j in range(1, len(quadrant_obj)-1):\n                    if quadrant_obj[sorted_idx[-1], i] != quadrant_obj[sorted_idx[0], i]:\n                        crowding[sorted_idx[j]] += (quadrant_obj[sorted_idx[j+1], i] - quadrant_obj[sorted_idx[j-1], i]) / \\\n                                                  (quadrant_obj[sorted_idx[-1], i] - quadrant_obj[sorted_idx[0], i])\n            selected_idx = candidate_indices[np.argmax(crowding)]\n        else:\n            selected_idx = np.random.randint(len(archive))\n    else:\n        selected_idx = 0\n\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n\n    # Hybrid local search with dynamic threshold\n    available_items = np.where(base_solution == 0)[0]\n    if len(available_items) > 0:\n        # Weighted marginal value calculation\n        alpha = 0.7  # Weight for first objective\n        marginal = (alpha * value1_lst[available_items] + (1-alpha) * value2_lst[available_items]) / (weight_lst[available_items] + 1e-6)\n        sorted_items = available_items[np.argsort(marginal)[::-1]]\n\n        # Try to add top items\n        for item in sorted_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n                break\n\n    # Dynamic removal based on combined objective contribution\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate normalized combined contribution\n        total_value1 = np.sum(value1_lst[included_items])\n        total_value2 = np.sum(value2_lst[included_items])\n        contribution = (value1_lst[included_items] / total_value1 + value2_lst[included_items] / total_value2) / 2\n        dynamic_threshold = np.percentile(contribution, 30)  # Remove bottom 30%\n\n        for i, item in enumerate(included_items):\n            if contribution[i] < dynamic_threshold:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.9642388599604512,
            0.5729503333568573
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Step 1: Select a solution with high potential for improvement\n    objectives = np.array([obj for _, obj in archive])\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-6)\n    potential_scores = normalized[:, 0] * normalized[:, 1]  # Geometric mean for balanced potential\n    selected_idx = np.argmax(potential_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Step 3: Adaptive threshold-based item selection\n    included = np.where(base_solution == 1)[0]\n    excluded = np.where(base_solution == 0)[0]\n\n    # Calculate dynamic thresholds (median of included items)\n    if len(included) > 0:\n        med_value1 = np.median(value1_lst[included])\n        med_value2 = np.median(value2_lst[included])\n        med_weight = np.median(weight_lst[included])\n    else:\n        med_value1, med_value2, med_weight = 0, 0, 0\n\n    # Step 4: Hybrid operation - prioritize items that improve both objectives\n    new_solution = base_solution.copy()\n    improved = False\n\n    # First pass: Try to add items that improve both objectives\n    for item in excluded:\n        if (current_weight + weight_lst[item] <= capacity and\n            value1_lst[item] > med_value1 and\n            value2_lst[item] > med_value2):\n            new_solution[item] = 1\n            current_weight += weight_lst[item]\n            improved = True\n            break\n\n    # Second pass: If no improvement, try to remove items that are below median in both objectives\n    if not improved and len(included) > 0:\n        for item in included:\n            if (value1_lst[item] < med_value1 and\n                value2_lst[item] < med_value2):\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n                improved = True\n                break\n\n    # Third pass: If still no improvement, perform a random swap\n    if not improved and len(included) > 0 and len(excluded) > 0:\n        item_out = np.random.choice(included)\n        item_in = np.random.choice(excluded)\n        if (current_weight - weight_lst[item_out] + weight_lst[item_in] <= capacity):\n            new_solution[item_out] = 0\n            new_solution[item_in] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.8377091640717841,
            0.37413325905799866
        ]
    },
    {
        "algorithm": "The algorithm selects the most balanced solution from the archive (based on harmonic mean of normalized objectives) and applies a hybrid local search that aggressively removes low-value items (below 80% of the median ratio) and adds high-value items (above 120% of the median ratio) while ensuring feasibility through probabilistic selection and value-aware removal. It prioritizes items with combined value-to-weight ratios from both objectives, dynamically adjusting thresholds based on included items.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution with highest harmonic mean of normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-6)\n    harmonic_scores = 2 / (1/normalized_obj[:, 0] + 1/normalized_obj[:, 1])\n    selected_idx = np.argmax(harmonic_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n\n    # Calculate value-to-weight ratios for both objectives\n    ratio1 = value1_lst / weight_lst\n    ratio2 = value2_lst / weight_lst\n    combined_ratio = ratio1 + ratio2\n\n    # Dynamic threshold selection (median of included items' ratios)\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0:\n        included_ratios = combined_ratio[included_items]\n        threshold_ratio = np.median(included_ratios)\n    else:\n        threshold_ratio = np.median(combined_ratio)\n\n    # Hybrid operation: remove items below threshold and add high-ratio items\n    for item in included_items:\n        if combined_ratio[item] < threshold_ratio * 0.8:  # More aggressive removal\n            if np.random.rand() < 0.6:  # Higher removal probability\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n\n    # Add items with high ratios if they fit\n    for item in excluded_items:\n        if combined_ratio[item] > threshold_ratio * 1.2:  # Higher addition threshold\n            if current_weight + weight_lst[item] <= capacity:\n                if np.random.rand() < 0.8:  # Higher addition probability\n                    new_solution[item] = 1\n                    current_weight += weight_lst[item]\n\n    # Final capacity check with value-aware removal\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Remove items with lowest value-to-weight ratio first\n        over_items = np.where(new_solution == 1)[0]\n        sorted_items = sorted(over_items, key=lambda x: combined_ratio[x])\n        for item in sorted_items:\n            if current_weight <= capacity:\n                break\n            new_solution[item] = 0\n            current_weight -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.5004141164786036,
            0.34565797448158264
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive using a diversity-aware mechanism that prioritizes underrepresented quadrants in the objective space, then applies a hybrid local search that dynamically adds high-marginal-value items (weighted by an adaptive balance between objectives) and removes low-contribution items (based on normalized combined utility), while adjusting thresholds to balance exploration and exploitation. The method ensures feasibility by only adding items that fit within the remaining capacity and removing items below a dynamically calculated contribution threshold.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Diversity-aware selection based on objective quadrants\n    objectives = np.array([obj for _, obj in archive])\n    if len(objectives) > 1:\n        # Partition objective space into quadrants\n        median1 = np.median(objectives[:, 0])\n        median2 = np.median(objectives[:, 1])\n        quadrant_counts = np.zeros(4)\n        for obj in objectives:\n            if obj[0] > median1 and obj[1] > median2:\n                quadrant_counts[0] += 1\n            elif obj[0] <= median1 and obj[1] > median2:\n                quadrant_counts[1] += 1\n            elif obj[0] <= median1 and obj[1] <= median2:\n                quadrant_counts[2] += 1\n            else:\n                quadrant_counts[3] += 1\n\n        # Select from least populated quadrant\n        selected_quadrant = np.argmin(quadrant_counts)\n        candidate_indices = []\n        for i, obj in enumerate(objectives):\n            if (selected_quadrant == 0 and obj[0] > median1 and obj[1] > median2) or \\\n               (selected_quadrant == 1 and obj[0] <= median1 and obj[1] > median2) or \\\n               (selected_quadrant == 2 and obj[0] <= median1 and obj[1] <= median2) or \\\n               (selected_quadrant == 3 and obj[0] > median1 and obj[1] <= median2):\n                candidate_indices.append(i)\n\n        if candidate_indices:\n            # Calculate crowding distance within selected quadrant\n            quadrant_obj = objectives[candidate_indices]\n            crowding = np.zeros(len(quadrant_obj))\n            for i in range(2):\n                sorted_idx = np.argsort(quadrant_obj[:, i])\n                crowding[sorted_idx[0]] = np.inf\n                crowding[sorted_idx[-1]] = np.inf\n                for j in range(1, len(quadrant_obj)-1):\n                    if quadrant_obj[sorted_idx[-1], i] != quadrant_obj[sorted_idx[0], i]:\n                        crowding[sorted_idx[j]] += (quadrant_obj[sorted_idx[j+1], i] - quadrant_obj[sorted_idx[j-1], i]) / \\\n                                                  (quadrant_obj[sorted_idx[-1], i] - quadrant_obj[sorted_idx[0], i])\n            selected_idx = candidate_indices[np.argmax(crowding)]\n        else:\n            selected_idx = np.random.randint(len(archive))\n    else:\n        selected_idx = 0\n\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n\n    # Hybrid local search with adaptive thresholds\n    available_items = np.where(base_solution == 0)[0]\n    if len(available_items) > 0:\n        # Calculate weighted marginal value with adaptive weights\n        alpha = 0.6 + 0.2 * (current_weight / capacity)  # Dynamically adjust weight for first objective\n        marginal = (alpha * value1_lst[available_items] + (1-alpha) * value2_lst[available_items]) / (weight_lst[available_items] + 1e-6)\n        sorted_items = available_items[np.argsort(marginal)[::-1]]\n\n        # Try to add top items with adaptive probability\n        for item in sorted_items:\n            if current_weight + weight_lst[item] <= capacity:\n                prob = min(0.9, marginal[item] / np.max(marginal))\n                if np.random.rand() < prob:\n                    new_solution[item] = 1\n                    current_weight += weight_lst[item]\n\n    # Dynamic removal based on adaptive contribution thresholds\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate normalized combined contribution with adaptive weights\n        total_value1 = np.sum(value1_lst[included_items])\n        total_value2 = np.sum(value2_lst[included_items])\n        beta = 0.5 + 0.3 * (current_weight / capacity)  # Dynamically adjust weight for first objective\n        contribution = (beta * value1_lst[included_items] / total_value1 + (1-beta) * value2_lst[included_items] / total_value2) / 2\n        adaptive_threshold = np.percentile(contribution, 25)  # Remove bottom 25%\n\n        for i, item in enumerate(included_items):\n            if contribution[i] < adaptive_threshold:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.9390331106772647,
            0.5691756010055542
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (top 20% by combined objective)\n    archive.sort(key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    selected_idx = min(int(0.2 * len(archive)), len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate weighted marginal impact for each objective and combined\n    marginal_impact1 = value1_lst / (weight_lst + 1e-6)\n    marginal_impact2 = value2_lst / (weight_lst + 1e-6)\n    combined_impact = (marginal_impact1 + marginal_impact2) / 2\n\n    # Phase 1: Dynamic high-impact additions (top 25% marginal impact for each objective)\n    top_impact_items1 = np.argsort(marginal_impact1)[::-1][:max(1, len(marginal_impact1) // 4)]\n    top_impact_items2 = np.argsort(marginal_impact2)[::-1][:max(1, len(marginal_impact2) // 4)]\n    top_impact_items = np.union1d(top_impact_items1, top_impact_items2)\n\n    remaining_capacity = capacity - current_weight\n    for idx in top_impact_items:\n        if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n            remaining_capacity -= weight_lst[idx]\n\n    # Phase 2: Adaptive swaps between high-impact items\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    for i in included_items:\n        for j in excluded_items:\n            if weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                # Check if swap improves both objectives or at least one with high probability\n                if ((marginal_impact1[j] > marginal_impact1[i] and marginal_impact2[j] > marginal_impact2[i]) or\n                    (marginal_impact1[j] > marginal_impact1[i] and np.random.rand() < 0.7) or\n                    (marginal_impact2[j] > marginal_impact2[i] and np.random.rand() < 0.7)):\n                    new_solution[i], new_solution[j] = 0, 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    remaining_capacity = capacity - current_weight\n                    break\n\n    # Phase 3: Capacity-preserving replacements with dynamic thresholds\n    while current_weight > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        # Remove items with lowest combined marginal impact\n        worst_item = included_items[np.argmin(combined_impact[included_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    # Phase 4: Probabilistic flips of high-impact items (up to 2 items)\n    high_impact_items = np.argsort(combined_impact)[::-1][:max(1, len(combined_impact) // 5)]\n    if len(high_impact_items) > 0:\n        num_to_flip = min(2, len(high_impact_items))\n        flip_indices = np.random.choice(high_impact_items, size=num_to_flip, replace=False)\n        for idx in flip_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.952293818245308,
            1.7788688838481903
        ]
    }
]