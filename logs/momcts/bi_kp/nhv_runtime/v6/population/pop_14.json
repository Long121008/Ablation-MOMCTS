[
    {
        "algorithm": "The algorithm combines intelligent solution selection with a three-phase local search: first exploring high-value items probabilistically, then performing targeted swaps to improve both objectives, and finally rebalancing by removing low-value items to maintain feasibility. It prioritizes items with high value ratios while dynamically adjusting the solution to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high value ratio potential\n    archive.sort(key=lambda x: (x[1][0] / (x[1][1] + 1e-6), sum(x[1])), reverse=True)\n    base_solution = archive[0][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n\n    # Calculate value ratios for each item\n    value_ratios = (value1_lst + 1e-6) / (value2_lst + 1e-6)\n    sorted_indices = np.argsort(value_ratios)\n\n    # Phase 1: Probabilistic item additions (exploration)\n    remaining_capacity = capacity - current_weight\n    candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n    if len(candidates) > 0:\n        # Select items with high value ratios first\n        for idx in sorted_indices[::-1]:\n            if idx in candidates and np.random.rand() < 0.7:  # 70% chance to add\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n                candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n                if len(candidates) == 0:\n                    break\n\n    # Phase 2: Targeted swaps based on objective improvements\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    for i in included_items:\n        for j in excluded_items:\n            if weight_lst[j] <= capacity - current_weight + weight_lst[i]:\n                # Check if swap improves both objectives\n                if (value1_lst[j] > value1_lst[i] and value2_lst[j] > value2_lst[i]) or \\\n                   (value1_lst[j] > value1_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity) or \\\n                   (value2_lst[j] > value2_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n                    new_solution[i], new_solution[j] = 0, 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    break\n\n    # Phase 3: Weight-sensitive rebalancing\n    while current_weight > capacity:\n        # Remove items with lowest value ratio first\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        worst_item = included_items[np.argmin(value_ratios[included_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "score": [
            -0.9382821717578097,
            0.46551522612571716
        ]
    },
    {
        "algorithm": "The algorithm randomly selects a solution from the archive and generates a neighbor by flipping up to 5 high-impact items (top 30% by marginal contribution to either objective), prioritizing those that improve both objectives while ensuring feasibility. It balances exploration (random selection) and exploitation (targeted flips) to balance the bi-objective trade-off. The critical design idea is the selection of high-impact items based on marginal contributions, ensuring the neighbor remains feasible while potentially improving both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst[base_solution == 1])\n\n    marginal_impact1 = value1_lst - value1_lst[base_solution == 1].sum()\n    marginal_impact2 = value2_lst - value2_lst[base_solution == 1].sum()\n\n    num_items = len(weight_lst)\n    top_items1 = np.argsort(marginal_impact1)[-max(1, num_items // 3):]\n    top_items2 = np.argsort(marginal_impact2)[-max(1, num_items // 3):]\n    top_items = np.union1d(top_items1, top_items2)\n\n    if len(top_items) > 0:\n        num_to_flip = min(5, len(top_items))\n        flip_indices = np.random.choice(top_items, size=num_to_flip, replace=False)\n\n        for idx in flip_indices:\n            if new_solution[idx] == 1:\n                if total_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    total_weight -= weight_lst[idx]\n            else:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    total_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.45860529653600796,
            0.24088504910469055
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using a hybrid criterion combining objective values and diversity, then generates a neighbor through three phases: (1) probabilistically adding high-impact items with adaptive thresholds, (2) capacity-aware swaps between items with complementary marginal improvements, and (3) dynamic rebalancing by removing low-utility items with a novel utility-based criterion that balances marginal impact and objective trade-offs. The algorithm prioritizes items with high combined marginal impact for objectives 1 and 2, while ensuring feasibility through capacity-aware operations and rebalancing.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine objective values and diversity\n    archive_with_diversity = []\n    for sol, obj in archive:\n        diversity = np.sum(np.abs(sol - archive[0][0]))  # Simple diversity measure\n        score = (obj[0] + obj[1]) * (1 + diversity/len(sol))\n        archive_with_diversity.append((sol, obj, score))\n\n    archive_with_diversity.sort(key=lambda x: x[2], reverse=True)\n    selected = archive_with_diversity[0][0].copy()\n    new_solution = selected.copy()\n    current_weight = np.sum(weight_lst[selected == 1])\n\n    # Calculate normalized marginal impacts\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = (marginal1 + marginal2) / 2\n\n    # Phase 1: Probabilistic addition with adaptive thresholds\n    remaining_capacity = capacity - current_weight\n    candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n\n    if len(candidates) > 0:\n        # Adaptive threshold based on current solution quality\n        threshold = np.percentile(combined_marginal, 100 - (current_weight/capacity)*30)\n        strong_candidates = candidates[combined_marginal[candidates] >= threshold]\n\n        if len(strong_candidates) > 0:\n            # Add with probability based on marginal impact\n            for idx in strong_candidates:\n                prob = min(0.9, combined_marginal[idx] / np.max(combined_marginal))\n                if np.random.rand() < prob:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n\n    # Phase 2: Capacity-aware swaps with complementary improvements\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    for i in included:\n        for j in excluded:\n            if weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                # Check for complementary improvements\n                if (marginal1[j] > marginal1[i] and marginal2[j] < marginal2[i]) or \\\n                   (marginal1[j] < marginal1[i] and marginal2[j] > marginal2[i]):\n                    new_solution[i], new_solution[j] = 0, 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    remaining_capacity = capacity - current_weight\n                    break\n\n    # Phase 3: Dynamic rebalancing with utility-based removal\n    while current_weight > capacity:\n        included = np.where(new_solution == 1)[0]\n        if len(included) == 0:\n            break\n\n        # Calculate utility scores for removal\n        utility_scores = []\n        for idx in included:\n            # Utility considers both marginal impact and objective trade-offs\n            utility = (combined_marginal[idx] *\n                      (1 - (value1_lst[idx]/(np.sum(value1_lst[included]) + 1e-6)) *\n                      (value2_lst[idx]/(np.sum(value2_lst[included]) + 1e-6))))\n            utility_scores.append((idx, utility))\n\n        utility_scores.sort(key=lambda x: x[1])\n        worst_idx = utility_scores[0][0]\n        new_solution[worst_idx] = 0\n        current_weight -= weight_lst[worst_idx]\n\n    return new_solution\n\n",
        "score": [
            -1.011331337201361,
            1.7290266454219818
        ]
    },
    {
        "algorithm": "The algorithm selects a high-potential solution from the archive, prioritizes items with high marginal impact (combining both objectives) for addition, then performs adaptive swaps to improve both objectives while ensuring feasibility, and finally rebalances the solution by removing low-impact items if the weight exceeds capacity. It balances exploration (via marginal impact) and exploitation (via adaptive swaps) while maintaining feasibility through weight-sensitive rebalancing.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    archive.sort(key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate combined marginal impact for each item\n    marginal_impact = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(marginal_impact)[::-1]  # Descending order\n\n    # Phase 1: Dynamic item selection based on marginal impact\n    remaining_capacity = capacity - current_weight\n    candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n\n    if len(candidates) > 0:\n        # Select top items with highest marginal impact\n        for idx in sorted_indices:\n            if idx in candidates and np.random.rand() < 0.6:  # 60% chance to add\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n                candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n                if len(candidates) == 0:\n                    break\n\n    # Phase 2: Adaptive flipping based on current solution's characteristics\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    # Calculate potential improvements for each swap\n    for i in included_items:\n        for j in excluded_items:\n            if weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                # Check if swap improves both objectives\n                if (value1_lst[j] > value1_lst[i] and value2_lst[j] > value2_lst[i]) or \\\n                   (value1_lst[j] > value1_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity) or \\\n                   (value2_lst[j] > value2_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n                    new_solution[i], new_solution[j] = 0, 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    remaining_capacity = capacity - current_weight\n                    break\n\n    # Phase 3: Weight-sensitive rebalancing with dynamic threshold\n    while current_weight > capacity:\n        # Remove items with lowest marginal impact first\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        worst_item = included_items[np.argmin(marginal_impact[included_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "score": [
            -0.9093676276444078,
            0.6341427564620972
        ]
    },
    {
        "algorithm": "The algorithm first selects a solution from the archive with high potential for improvement, then applies a hybrid local search that combines probabilistic item additions (prioritizing high-value items), targeted swaps (ensuring multi-objective improvements), and adaptive rebalancing (removing low-value items to maintain feasibility). The exploration intensity is dynamically adjusted based on the solution's current weight, and the search prioritizes items with favorable value ratios while ensuring both objectives are improved.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n\n    # Calculate dynamic value ratios and prioritize items\n    value_ratios = (value1_lst + 1e-6) / (value2_lst + 1e-6)\n    sorted_indices = np.argsort(value_ratios)\n\n    # Phase 1: Probabilistic item additions with dynamic intensity\n    remaining_capacity = capacity - current_weight\n    candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n    if len(candidates) > 0:\n        # Adjust exploration intensity based on solution quality\n        exploration_prob = min(0.9, 0.5 + (current_weight / capacity) * 0.4)\n        for idx in sorted_indices[::-1]:\n            if idx in candidates and np.random.rand() < exploration_prob:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n                candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n                if len(candidates) == 0:\n                    break\n\n    # Phase 2: Targeted swaps with multi-objective improvement\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    for i in included_items:\n        for j in excluded_items:\n            if weight_lst[j] <= capacity - current_weight + weight_lst[i]:\n                # Check for multi-objective improvement\n                if (value1_lst[j] > value1_lst[i] and value2_lst[j] > value2_lst[i]) or \\\n                   (value1_lst[j] > value1_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity) or \\\n                   (value2_lst[j] > value2_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n                    new_solution[i], new_solution[j] = 0, 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    break\n\n    # Phase 3: Adaptive rebalancing with dynamic removal criteria\n    while current_weight > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        # Remove items with lowest value ratio or least contribution to objectives\n        removal_criteria = value_ratios[included_items] * (1 - (value1_lst[included_items] + value2_lst[included_items]) / (np.sum(value1_lst) + np.sum(value2_lst)))\n        worst_item = included_items[np.argmin(removal_criteria)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "score": [
            -0.8370011111640884,
            0.5209901034832001
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive (top 20% by combined marginal impact), then generates a neighbor through a three-phase process: 1) adding high-impact items (70% chance for top 20% marginal items), 2) targeted swaps where excluded items dominate included ones in at least one objective while respecting capacity, and 3) dynamic rebalancing by removing low-marginal items if capacity is exceeded. The method prioritizes high-marginal items and ensures feasibility through capacity-aware operations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (top 20% by combined marginal impact)\n    archive.sort(key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    selected_idx = min(len(archive) // 5, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate combined marginal impact for each item\n    marginal_impact = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(marginal_impact)[::-1]  # Descending order\n\n    # Phase 1: Add high-impact items not in the solution\n    remaining_capacity = capacity - current_weight\n    candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n\n    if len(candidates) > 0:\n        # Select top 20% of high-impact items to add\n        num_to_add = max(1, len(sorted_indices) // 5)\n        for idx in sorted_indices[:num_to_add]:\n            if idx in candidates and np.random.rand() < 0.7:  # 70% chance to add\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n                candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n                if len(candidates) == 0:\n                    break\n\n    # Phase 2: Targeted swaps of high-impact items\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    # Calculate potential improvements for each swap\n    for i in included_items:\n        for j in excluded_items:\n            if weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                # Check if swap improves both objectives or at least one\n                if (value1_lst[j] > value1_lst[i] and value2_lst[j] > value2_lst[i]) or \\\n                   (value1_lst[j] > value1_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity) or \\\n                   (value2_lst[j] > value2_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n                    new_solution[i], new_solution[j] = 0, 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    remaining_capacity = capacity - current_weight\n                    break\n\n    # Phase 3: Dynamic rebalancing with percentile-based thresholds\n    while current_weight > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        # Remove items with lowest 20% marginal impact\n        remove_threshold = np.percentile(marginal_impact[included_items], 20)\n        worst_items = included_items[marginal_impact[included_items] <= remove_threshold]\n        if len(worst_items) > 0:\n            worst_item = worst_items[0]\n            new_solution[worst_item] = 0\n            current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "score": [
            -0.8172125621391388,
            0.5021446347236633
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    archive.sort(key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate adaptive marginal impacts\n    marginal_impact1 = value1_lst * (1 - base_solution)\n    marginal_impact2 = value2_lst * (1 - base_solution)\n\n    # Dynamic thresholds (75th percentile)\n    threshold1 = np.percentile(marginal_impact1, 75)\n    threshold2 = np.percentile(marginal_impact2, 75)\n\n    # Phase 1: Hybrid add/swap operations\n    remaining_capacity = capacity - current_weight\n    candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n\n    if len(candidates) > 0:\n        # Add items with high marginal impact\n        high_impact1 = candidates[marginal_impact1[candidates] > threshold1]\n        high_impact2 = candidates[marginal_impact2[candidates] > threshold2]\n\n        for idx in np.concatenate([high_impact1, high_impact2]):\n            if np.random.rand() < 0.6:  # 60% chance to add\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n\n    # Phase 2: Targeted swaps with feasibility check\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    for i in included_items:\n        for j in excluded_items:\n            if (weight_lst[j] <= capacity - current_weight + weight_lst[i] and\n                (marginal_impact1[j] > marginal_impact1[i] or marginal_impact2[j] > marginal_impact2[i])):\n                new_solution[i], new_solution[j] = 0, 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                break\n\n    # Phase 3: Weight-sensitive removal\n    while current_weight > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        removal_candidates = included_items[np.argsort(marginal_impact1[included_items] + marginal_impact2[included_items])]\n        worst_item = removal_candidates[0]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "score": [
            -0.9322289850854732,
            0.6346070170402527
        ]
    },
    {
        "algorithm": "The algorithm implements a multi-phase adaptive local search for the BI-KP, prioritizing high-impact items (based on combined marginal impact) through three phases: adding top 15% of high-impact excluded items, performing targeted swaps between included and excluded items that improve at least one objective while respecting capacity, and dynamically removing low-impact included items when capacity is exceeded. It intelligently selects solutions from the top 15% of the archive for improvement, using adaptive thresholds and dynamic probabilities to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (top 15% by combined marginal impact)\n    archive.sort(key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    selected_idx = min(len(archive) // 7, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate adaptive marginal impact for each item\n    marginal_impact1 = value1_lst / (weight_lst + 1e-6)\n    marginal_impact2 = value2_lst / (weight_lst + 1e-6)\n    combined_impact = marginal_impact1 + marginal_impact2\n    sorted_indices = np.argsort(combined_impact)[::-1]\n\n    # Phase 1: Add high-impact items not in the solution with dynamic probability\n    remaining_capacity = capacity - current_weight\n    candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n\n    if len(candidates) > 0:\n        # Select top 15% of high-impact items to add with dynamic probability\n        num_to_add = max(1, len(sorted_indices) // 7)\n        for idx in sorted_indices[:num_to_add]:\n            if idx in candidates and np.random.rand() < 0.6:  # 60% chance to add\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n                candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n                if len(candidates) == 0:\n                    break\n\n    # Phase 2: Targeted swaps of high-impact items with adaptive thresholds\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    # Calculate potential improvements for each swap\n    for i in included_items:\n        for j in excluded_items:\n            if weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                # Check if swap improves at least one objective and respects capacity\n                if (value1_lst[j] > value1_lst[i] or value2_lst[j] > value2_lst[i]) and \\\n                   (current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n                    new_solution[i], new_solution[j] = 0, 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    remaining_capacity = capacity - current_weight\n                    break\n\n    # Phase 3: Dynamic rebalancing with adaptive percentile-based thresholds\n    while current_weight > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        # Remove items with lowest 15% marginal impact\n        remove_threshold = np.percentile(combined_impact[included_items], 15)\n        worst_items = included_items[combined_impact[included_items] <= remove_threshold]\n        if len(worst_items) > 0:\n            worst_item = worst_items[0]\n            new_solution[worst_item] = 0\n            current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "score": [
            -0.8683496923227703,
            0.5731351971626282
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive (top 20% by combined marginal impact) and generates a neighbor through four phases: 1) adding high-impact items (top 20%) with 70% probability, 2) performing capacity-aware swaps of high-impact items, 3) dynamically removing low-marginal items if capacity is exceeded, and 4) optionally flipping high-impact items for diversity. It prioritizes marginal impact, ensures feasibility, and balances exploitation/exploration through probabilistic selection. The algorithm is structured to iteratively refine solutions while maintaining diversity and feasibility constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (top 20% by combined marginal impact)\n    archive.sort(key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    selected_idx = min(len(archive) // 5, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate combined marginal impact for each item\n    marginal_impact = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(marginal_impact)[::-1]  # Descending order\n\n    # Phase 1: Add high-impact items not in the solution\n    remaining_capacity = capacity - current_weight\n    candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n\n    if len(candidates) > 0:\n        # Select top 20% of high-impact items to add\n        num_to_add = max(1, len(sorted_indices) // 5)\n        for idx in sorted_indices[:num_to_add]:\n            if idx in candidates and np.random.rand() < 0.7:  # 70% chance to add\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n                candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n                if len(candidates) == 0:\n                    break\n\n    # Phase 2: Targeted swaps of high-impact items\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    # Calculate potential improvements for each swap\n    for i in included_items:\n        for j in excluded_items:\n            if weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                # Check if swap improves both objectives or at least one\n                if (value1_lst[j] > value1_lst[i] and value2_lst[j] > value2_lst[i]) or \\\n                   (value1_lst[j] > value1_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity) or \\\n                   (value2_lst[j] > value2_lst[i] and current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n                    new_solution[i], new_solution[j] = 0, 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    remaining_capacity = capacity - current_weight\n                    break\n\n    # Phase 3: Dynamic rebalancing with percentile-based thresholds\n    while current_weight > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        # Remove items with lowest 20% marginal impact\n        remove_threshold = np.percentile(marginal_impact[included_items], 20)\n        worst_items = included_items[marginal_impact[included_items] <= remove_threshold]\n        if len(worst_items) > 0:\n            worst_item = worst_items[0]\n            new_solution[worst_item] = 0\n            current_weight -= weight_lst[worst_item]\n\n    # Phase 4: Optional random flip of high-impact items for diversity\n    if np.random.rand() < 0.3:  # 30% chance to perform this phase\n        top_impact_items = sorted_indices[:max(1, len(sorted_indices) // 5)]\n        if len(top_impact_items) > 0:\n            num_to_flip = min(2, len(top_impact_items))  # Flip up to 2 items\n            flip_indices = np.random.choice(top_impact_items, size=num_to_flip, replace=False)\n            for idx in flip_indices:\n                if new_solution[idx] == 1:\n                    if current_weight - weight_lst[idx] <= capacity:\n                        new_solution[idx] = 0\n                        current_weight -= weight_lst[idx]\n                else:\n                    if current_weight + weight_lst[idx] <= capacity:\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7497767617170195,
            0.49938327074050903
        ]
    },
    {
        "algorithm": "The algorithm selects a random solution from the archive and generates a neighbor by flipping a dynamic subset of high-impact items (top 25% by marginal contribution to either objective), using a hybrid local search that includes add, swap, and replace operations, prioritizing items that improve both objectives while ensuring feasibility. It dynamically adjusts the number of flips (1-5) and includes occasional swaps to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst[base_solution == 1])\n\n    marginal_impact1 = value1_lst - value1_lst[base_solution == 1].sum()\n    marginal_impact2 = value2_lst - value2_lst[base_solution == 1].sum()\n\n    num_items = len(weight_lst)\n    top_items1 = np.argsort(marginal_impact1)[-max(1, num_items // 4):]\n    top_items2 = np.argsort(marginal_impact2)[-max(1, num_items // 4):]\n    top_items = np.union1d(top_items1, top_items2)\n\n    if len(top_items) > 0:\n        num_to_flip = min(5, max(1, len(top_items) // 2))\n        flip_indices = np.random.choice(top_items, size=num_to_flip, replace=False)\n\n        for idx in flip_indices:\n            if new_solution[idx] == 1:\n                if total_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    total_weight -= weight_lst[idx]\n            else:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    total_weight += weight_lst[idx]\n\n        if np.random.rand() < 0.3:\n            swap_indices = np.random.choice(top_items, size=min(2, len(top_items)), replace=False)\n            for idx in swap_indices:\n                if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    total_weight -= weight_lst[idx]\n                elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    total_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.40979307830754713,
            0.24711576104164124
        ]
    }
]