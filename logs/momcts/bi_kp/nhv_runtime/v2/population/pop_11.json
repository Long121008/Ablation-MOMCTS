[
    {
        "algorithm": "The algorithm selects a random solution from the archive, identifies critical items based on combined value-to-weight ratios, and applies a hybrid local search by toggling these items while ensuring feasibility. It also randomly flips non-critical items to escape local optima. The method prioritizes high-value items while maintaining solution feasibility through weight checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.choice(len(archive))\n    selected_solution, _ = archive[selected_idx]\n    current_solution = selected_solution.copy()\n\n    # Step 2: Identify critical items (those with high value-to-weight ratios)\n    value_to_weight1 = value1_lst / weight_lst\n    value_to_weight2 = value2_lst / weight_lst\n    combined_value_to_weight = value_to_weight1 + value_to_weight2\n    critical_items = np.argsort(combined_value_to_weight)[-min(5, len(weight_lst)):]  # Top 5 items\n\n    # Step 3: Apply a hybrid local search strategy\n    # Flip critical items (if not already in the solution) or remove low-value items\n    new_solution = current_solution.copy()\n    for item in critical_items:\n        if current_solution[item] == 0:\n            # Try adding the item if it fits\n            if (np.sum(weight_lst * new_solution) + weight_lst[item]) <= capacity:\n                new_solution[item] = 1\n        else:\n            # Try removing the item\n            new_solution[item] = 0\n            if np.sum(weight_lst * new_solution) <= capacity:\n                pass  # Keep the change\n            else:\n                new_solution[item] = 1  # Revert if infeasible\n\n    # Step 4: Randomly flip a small number of non-critical items to escape local optima\n    non_critical_items = np.setdiff1d(np.arange(len(weight_lst)), critical_items)\n    if len(non_critical_items) > 0:\n        flip_indices = np.random.choice(non_critical_items, size=min(2, len(non_critical_items)), replace=False)\n        for idx in flip_indices:\n            new_solution[idx] = 1 - new_solution[idx]\n            # Ensure feasibility\n            if np.sum(weight_lst * new_solution) > capacity:\n                new_solution[idx] = 1 - new_solution[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8266459948173828,
            0.3179592788219452
        ]
    },
    {
        "algorithm": "The algorithm selects the most promising solution from the archive (prioritizing high combined normalized objective value), applies a random swap mutation, and then performs a weighted greedy local search to add/remove items, favoring objective 1 (60%) over objective 2 (40%) while ensuring feasibility. The weighted approach balances improvements across objectives, and the random shuffling ensures exploration. The structure combines mutation and greedy search to efficiently explore the neighborhood of the selected solution.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    max_score = -1\n    selected_idx = 0\n    for i, (sol, (v1, v2)) in enumerate(archive):\n        score = (v1 + v2) / (np.sum(weight_lst * sol) + 1e-6)  # Normalized by weight\n        if score > max_score:\n            max_score = score\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Step 1: Randomly swap two items (swap mutation)\n    if n_items >= 2:\n        swap_indices = np.random.choice(n_items, 2, replace=False)\n        new_solution[swap_indices[0]], new_solution[swap_indices[1]] = new_solution[swap_indices[1]], new_solution[swap_indices[0]]\n\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 2: Greedy addition based on weighted objective improvement\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n\n    for item in remaining_items:\n        if current_weight + weight_lst[item] <= capacity:\n            # Calculate weighted objective improvement\n            weight_improvement = 0.6 * value1_lst[item] + 0.4 * value2_lst[item]\n            new_solution[item] = 1\n            current_weight += weight_lst[item]\n\n    # Step 3: Greedy removal based on weighted objective improvement\n    included_items = np.where(new_solution == 1)[0]\n    np.random.shuffle(included_items)\n\n    for item in included_items:\n        # Calculate weighted objective loss\n        weight_loss = 0.6 * value1_lst[item] + 0.4 * value2_lst[item]\n        new_solution[item] = 0\n        current_weight -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.9780105623667606,
            0.5062039494514465
        ]
    },
    {
        "algorithm": "The algorithm selects a younger solution from the archive, prioritizes critical high-value items for flipping with age-based probability, and performs guided probabilistic swaps to improve objective values while maintaining feasibility through incremental weight checks and a repair mechanism that removes low-value items first. It dynamically adjusts perturbation intensity based on solution age and combines value-to-weight ratios for intelligent item selection.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Age-based selection: prioritize younger solutions (lower index)\n    selected_idx = min(len(archive) // 4, len(archive) - 1)  # Select from younger 25% or last if fewer than 4\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate combined value-to-weight ratios\n    combined_ratios = (value1_lst + value2_lst) / weight_lst\n    critical_items = np.argsort(combined_ratios)[-max(1, len(weight_lst) // 20):]  # Top 5% items\n\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Dynamic perturbation: flip critical items with probability inversely proportional to age\n    flip_prob = 1.0 / (selected_idx + 1)  # Younger solutions have higher flip probability\n    for item in critical_items:\n        if np.random.rand() < flip_prob:\n            if new_solution[item] == 0:\n                if current_weight + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                    current_weight += weight_lst[item]\n            else:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n\n    # Guided probabilistic swap: higher probability for high-value items\n    swap_prob = 0.3 / (selected_idx + 1)  # Younger solutions have higher swap probability\n    if np.random.rand() < swap_prob and len(np.where(new_solution == 1)[0]) > 0:\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Select swap-out item (lowest value-to-weight in current solution)\n            swap_out = in_items[np.argmin(combined_ratios[in_items])]\n            # Select swap-in item (highest value-to-weight not in solution)\n            swap_in = out_items[np.argmax(combined_ratios[out_items])]\n\n            potential_weight = current_weight - weight_lst[swap_out] + weight_lst[swap_in]\n            if potential_weight <= capacity:\n                new_solution[swap_out] = 0\n                new_solution[swap_in] = 1\n\n    # Ensure feasibility: remove low-value items if needed\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess_items = np.where(new_solution == 1)[0]\n        excess_ratios = combined_ratios[excess_items]\n        while current_weight > capacity and len(excess_items) > 0:\n            remove_idx = excess_items[np.argmin(excess_ratios)]\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n            excess_items = np.where(new_solution == 1)[0]\n            excess_ratios = combined_ratios[excess_items]\n\n    return new_solution\n\n",
        "score": [
            -0.8087162914292674,
            0.16034522652626038
        ]
    },
    {
        "algorithm": "The algorithm prioritizes solutions with high variance in objective values, applies a random bit-flip mutation, and performs a dynamic weighted greedy search that alternates between objectives based on their current dominance, ensuring feasibility through adaptive weight adjustments. The selection of solutions is biased toward those with significant differences between the two objectives, while the local search dynamically adjusts weights to balance improvements in either objective, with occasional removals to maintain diversity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    max_variance = -1\n    selected_idx = 0\n    for i, (sol, (v1, v2)) in enumerate(archive):\n        variance = abs(v1 - v2)\n        if variance > max_variance:\n            max_variance = variance\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Step 1: Random bit-flip mutation\n    flip_index = np.random.randint(n_items)\n    new_solution[flip_index] = 1 - new_solution[flip_index]\n\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 2: Dynamic weighted greedy search\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n\n    # Determine objective weights dynamically\n    total_v1 = np.sum(value1_lst * new_solution)\n    total_v2 = np.sum(value2_lst * new_solution)\n    w1 = 0.7 if total_v1 < total_v2 else 0.3\n    w2 = 1 - w1\n\n    for item in remaining_items:\n        if current_weight + weight_lst[item] <= capacity:\n            improvement = w1 * value1_lst[item] + w2 * value2_lst[item]\n            new_solution[item] = 1\n            current_weight += weight_lst[item]\n\n    # Step 3: Dynamic weighted greedy removal\n    included_items = np.where(new_solution == 1)[0]\n    np.random.shuffle(included_items)\n\n    for item in included_items:\n        loss = w1 * value1_lst[item] + w2 * value2_lst[item]\n        if np.random.rand() < 0.3:  # 30% chance to remove to maintain diversity\n            new_solution[item] = 0\n            current_weight -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.8841680503524515,
            0.35383936762809753
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive based on a weighted ratio of total values to weight, then applies a probabilistic item flipping mechanism that prioritizes high-value items differently depending on their current inclusion status. It follows with a multi-phase greedy search that alternates between prioritizing each objective and balancing them, while ensuring feasibility by randomly removing excess items. The flipping probabilities are adaptive, favoring inclusion of items with higher values in their respective objectives, and the greedy phases systematically explore item additions and removals to improve both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    max_ratio = -1\n    selected_idx = 0\n    for i, (sol, (v1, v2)) in enumerate(archive):\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight == 0:\n            ratio = (v1 + v2) / 1e-6\n        else:\n            ratio = (v1 + v2) / total_weight\n        if ratio > max_ratio:\n            max_ratio = ratio\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Step 2: Probabilistic item flipping with adaptive weights\n    flip_probs = np.zeros(n_items)\n    for i in range(n_items):\n        if new_solution[i] == 1:\n            flip_probs[i] = 0.7 * (value1_lst[i] / (np.sum(value1_lst) + 1e-6)) + 0.3 * (value2_lst[i] / (np.sum(value2_lst) + 1e-6))\n        else:\n            flip_probs[i] = 0.3 * (value1_lst[i] / (np.sum(value1_lst) + 1e-6)) + 0.7 * (value2_lst[i] / (np.sum(value2_lst) + 1e-6))\n\n    flip_mask = np.random.rand(n_items) < flip_probs\n    new_solution = np.where(flip_mask, 1 - new_solution, new_solution)\n\n    # Ensure feasibility after flipping\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(excess_items)\n        for item in excess_items:\n            if excess <= 0:\n                break\n            if new_solution[item] == 1:\n                new_solution[item] = 0\n                excess -= weight_lst[item]\n\n    # Step 3: Multi-phase greedy search\n    phases = [\n        (0.8, 0.2),  # Phase 1: Prioritize objective 1\n        (0.5, 0.5),  # Phase 2: Balance both objectives\n        (0.2, 0.8)   # Phase 3: Prioritize objective 2\n    ]\n\n    for w1, w2 in phases:\n        # Addition phase\n        remaining_items = np.where(new_solution == 0)[0]\n        np.random.shuffle(remaining_items)\n        for item in remaining_items:\n            if current_weight + weight_lst[item] <= capacity:\n                improvement = w1 * value1_lst[item] + w2 * value2_lst[item]\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n        # Removal phase\n        included_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(included_items)\n        for item in included_items:\n            removal_cost = w1 * value1_lst[item] + w2 * value2_lst[item]\n            new_solution[item] = 0\n            current_weight -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.9340506264272932,
            3.4212915301322937
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using an age-weighted score (prioritizing younger solutions) and applies a hybrid perturbation: flipping critical items (top 5% value-to-weight) and swapping high-value items, while ensuring feasibility through incremental repairs. It then performs a weighted greedy local search (favoring objective 1 over objective 2) to add/remove items, dynamically adjusting probabilities and prioritizing high-value items. The solution is repaired if it exceeds capacity by removing the least valuable items.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    scores = []\n    for i, (sol, (v1, v2)) in enumerate(archive):\n        # Age-weighted score: younger solutions get higher priority\n        age_weight = 1.0 / (i + 1)\n        normalized_score = (v1 + v2) / (np.sum(weight_lst * sol) + 1e-6)\n        scores.append(age_weight * normalized_score)\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid perturbation\n    n_items = len(base_solution)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 1: Flip critical items (top 5% value-to-weight)\n    value_to_weight = (0.6 * value1_lst + 0.4 * value2_lst) / (weight_lst + 1e-6)\n    critical_items = np.argsort(value_to_weight)[-max(1, n_items // 20):]\n\n    for item in critical_items:\n        if np.random.rand() < 0.3:  # Dynamic probability (adjust based on improvement trends)\n            new_solution[item] = 1 - new_solution[item]\n\n    # Step 2: Guided random swap of high-value items\n    high_value_items = np.argsort(0.6 * value1_lst + 0.4 * value2_lst)[-max(2, n_items // 10):]\n    if len(high_value_items) >= 2:\n        swap_indices = np.random.choice(high_value_items, 2, replace=False)\n        new_solution[swap_indices[0]], new_solution[swap_indices[1]] = new_solution[swap_indices[1]], new_solution[swap_indices[0]]\n\n    # Ensure feasibility incrementally\n    if np.sum(weight_lst * new_solution) > capacity:\n        # Remove least valuable items until feasible\n        included_items = np.where(new_solution == 1)[0]\n        value_ratio = (0.6 * value1_lst + 0.4 * value2_lst) / (weight_lst + 1e-6)\n        sorted_items = np.argsort(value_ratio[included_items])\n        for item in included_items[sorted_items]:\n            new_solution[item] = 0\n            if np.sum(weight_lst * new_solution) <= capacity:\n                break\n\n    # Weighted greedy local search (add/remove)\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n\n    for item in remaining_items:\n        if current_weight + weight_lst[item] <= capacity:\n            # Weighted improvement\n            weight_improvement = 0.6 * value1_lst[item] + 0.4 * value2_lst[item]\n            new_solution[item] = 1\n            current_weight += weight_lst[item]\n\n    included_items = np.where(new_solution == 1)[0]\n    np.random.shuffle(included_items)\n\n    for item in included_items:\n        # Weighted loss\n        weight_loss = 0.6 * value1_lst[item] + 0.4 * value2_lst[item]\n        new_solution[item] = 0\n        current_weight -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.8998382734890571,
            0.6170006692409515
        ]
    },
    {
        "algorithm": "The algorithm selects promising solutions from the archive using an age-weighted diversity metric (prioritizing younger, more diverse solutions) and applies a hybrid local search combining critical item flips and guided random swaps, with dynamic perturbation intensity based on search progress. It ensures feasibility through incremental checks and lightweight repair, focusing on high-value items while maintaining balance between exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive selection: prioritize solutions with high diversity and younger age\n    current_time = len(archive)\n    selected_idx = 0\n    max_score = -1\n    for i, (sol, obj) in enumerate(archive):\n        diversity = abs(obj[0] - obj[1])\n        age = current_time - i\n        score = (diversity + 1) / (age + 1)\n        if score > max_score:\n            max_score = score\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Dynamic perturbation intensity\n    perturbation_intensity = min(0.3 + (len(archive) / 1000), 1.0)\n\n    # Critical items (top 5% by combined value-to-weight)\n    combined_ratio = (value1_lst + value2_lst) / weight_lst\n    critical_items = np.argsort(-combined_ratio)[:max(1, int(len(weight_lst) * 0.05))]\n\n    # Hybrid perturbation\n    for _ in range(2):\n        # Critical item flips\n        if np.random.rand() < perturbation_intensity:\n            for item in critical_items:\n                if np.random.rand() < 0.5:\n                    temp_solution = new_solution.copy()\n                    temp_solution[item] = 1 - temp_solution[item]\n                    if np.sum(temp_solution * weight_lst) <= capacity:\n                        new_solution = temp_solution\n\n        # Guided random swaps (higher-value items)\n        if np.random.rand() < 0.5 * perturbation_intensity:\n            high_value_items = np.argsort(-(value1_lst + value2_lst))[:max(2, int(len(weight_lst) * 0.2))]\n            i, j = np.random.choice(high_value_items, size=2, replace=False)\n            temp_solution = new_solution.copy()\n            temp_solution[i], temp_solution[j] = temp_solution[j], temp_solution[i]\n            if np.sum(temp_solution * weight_lst) <= capacity:\n                new_solution = temp_solution\n\n    # Lightweight repair\n    if np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(removable_items)\n        for item in removable_items:\n            if excess <= 0:\n                break\n            temp_solution = new_solution.copy()\n            temp_solution[item] = 0\n            excess -= weight_lst[item]\n            if excess >= 0:\n                new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -0.6901818589045985,
            0.24805396795272827
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using adaptive normalization (prioritizing solutions with high unexplored potential) and applies a hybrid local search combining critical-item flips (top 10% value-to-weight) with guided random swaps (biased toward high-value items), while ensuring feasibility through incremental weight checks and repair mechanisms. The method prioritizes items with the highest combined value-to-weight ratios, flips their inclusion status, and performs targeted swaps to improve both objectives while maintaining capacity constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive selection: prioritize solutions with unexplored neighborhoods\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    diversity_scores = np.std(objectives, axis=0)  # Higher diversity suggests unexplored regions\n    weighted_scores = normalized_obj * diversity_scores\n    selected_idx = np.argmax(weighted_scores.sum(axis=1))\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate combined value-to-weight ratios\n    combined_ratios = (value1_lst + value2_lst) / weight_lst\n    critical_items = np.argsort(combined_ratios)[-max(1, len(weight_lst) // 10):]  # Top 10% items\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid perturbation\n    # 1. Flip critical items (add if not present, remove if present)\n    for item in critical_items:\n        if new_solution[item] == 0:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n        else:\n            new_solution[item] = 0\n            current_weight -= weight_lst[item]\n\n    # 2. Guided random swaps (bias toward high-value items)\n    non_critical_items = np.setdiff1d(np.arange(len(weight_lst)), critical_items)\n    if len(non_critical_items) > 0:\n        # Select a candidate to swap out (lowest value-to-weight ratio in current solution)\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) > 0:\n            in_ratios = combined_ratios[in_items]\n            swap_out = in_items[np.argmin(in_ratios)]\n\n            # Select a candidate to swap in (highest value-to-weight ratio not in solution)\n            out_items = np.where(new_solution == 0)[0]\n            if len(out_items) > 0:\n                out_ratios = combined_ratios[out_items]\n                swap_in = out_items[np.argmax(out_ratios)]\n\n                # Check if swap is feasible\n                potential_weight = current_weight - weight_lst[swap_out] + weight_lst[swap_in]\n                if potential_weight <= capacity:\n                    new_solution[swap_out] = 0\n                    new_solution[swap_in] = 1\n\n    # Ensure feasibility (repair if needed)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess_items = np.where(new_solution == 1)[0]\n        excess_ratios = combined_ratios[excess_items]\n        # Remove items with lowest value-to-weight ratio until feasible\n        while current_weight > capacity and len(excess_items) > 0:\n            remove_idx = excess_items[np.argmin(excess_ratios)]\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n            excess_items = np.where(new_solution == 1)[0]\n            excess_ratios = combined_ratios[excess_items]\n\n    return new_solution\n\n",
        "score": [
            -0.7557951720924632,
            0.38932788372039795
        ]
    },
    {
        "algorithm": "The algorithm combines adaptive solution selection (prioritizing diverse and younger solutions) with a hybrid perturbation strategy that dynamically adjusts critical item flips and guided random swaps, while ensuring feasibility through lightweight repair. It balances exploration and exploitation by increasing perturbation intensity with search progress, focusing on high-value items while maintaining knapsack capacity constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive selection: prioritize solutions with high diversity and younger age\n    current_time = len(archive)  # Simulate age by archive position\n    selected_idx = 0\n    max_score = -1\n    for i, (sol, obj) in enumerate(archive):\n        diversity = abs(obj[0] - obj[1])\n        age = current_time - i\n        score = (diversity + 1) / (age + 1)  # Prefer diverse and younger solutions\n        if score > max_score:\n            max_score = score\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Dynamic perturbation intensity based on search progress\n    perturbation_intensity = min(0.3 + (len(archive) / 1000), 1.0)  # Increase with archive size\n\n    # Hybrid perturbation: critical flips + guided random swaps\n    n_items = len(weight_lst)\n    critical_items = np.argsort(-(value1_lst + value2_lst))[:max(2, int(n_items * 0.1))]  # Top 10% most valuable items\n\n    for _ in range(2):  # Perform 2 perturbation iterations\n        # Critical flips with higher probability\n        if np.random.rand() < perturbation_intensity:\n            for item in critical_items:\n                if np.random.rand() < 0.5:  # 50% chance to flip each critical item\n                    temp_solution = new_solution.copy()\n                    temp_solution[item] = 1 - temp_solution[item]\n                    if np.sum(temp_solution * weight_lst) <= capacity:\n                        new_solution = temp_solution\n\n        # Guided random swaps\n        if np.random.rand() < 0.5 * perturbation_intensity:\n            i, j = np.random.choice(n_items, size=2, replace=False)\n            temp_solution = new_solution.copy()\n            temp_solution[i], temp_solution[j] = temp_solution[j], temp_solution[i]\n            if np.sum(temp_solution * weight_lst) <= capacity:\n                new_solution = temp_solution\n\n    # Lightweight repair if solution is infeasible\n    if np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(removable_items)\n        for item in removable_items:\n            if excess <= 0:\n                break\n            temp_solution = new_solution.copy()\n            temp_solution[item] = 0\n            excess -= weight_lst[item]\n            if excess >= 0:\n                new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -0.663515986230289,
            0.30924123525619507
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive based on novelty and diversity scores, then generates a neighbor by performing a value-weighted random walk where items are flipped with probabilities proportional to their combined value-to-weight ratios, dynamically adjusting the intensity of this walk. It further refines the solution by guidedly removing low-contribution items and flipping high-value items, while ensuring feasibility through incremental weight checks and a lightweight repair mechanism that prioritizes removing items with the smallest marginal contribution. The algorithm prioritizes items with higher combined value-to-weight ratios and adjusts search intensity based on progress, balancing exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive selection: prioritize solutions with high novelty and diversity\n    objectives = np.array([obj for _, obj in archive])\n    novelty_scores = np.max(np.abs(objectives[:, None, :] - objectives[None, :, :]), axis=1).mean(axis=1)\n    selected_idx = np.argmax(novelty_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    n_items = len(weight_lst)\n\n    # Calculate combined value-to-weight ratios\n    combined_ratios = (value1_lst + value2_lst) / weight_lst\n\n    # Value-weighted random walk with dynamic intensity\n    intensity = max(0.1, 0.5 * (1 - selected_idx / len(archive)))  # Decreases as search progresses\n    for i in range(n_items):\n        if np.random.rand() < intensity * combined_ratios[i] / np.sum(combined_ratios):\n            if new_solution[i] == 0:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n            else:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n\n    # Guided removal of low-contribution items\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        marginal_contributions = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n        sorted_items = included_items[np.argsort(marginal_contributions)]\n        for item in sorted_items[:max(1, len(sorted_items) // 10)]:  # Remove bottom 10%\n            new_solution[item] = 0\n            current_weight -= weight_lst[item]\n\n    # Lightweight repair if needed\n    if current_weight > capacity:\n        excess_items = np.where(new_solution == 1)[0]\n        excess_ratios = combined_ratios[excess_items]\n        while current_weight > capacity and len(excess_items) > 0:\n            remove_idx = excess_items[np.argmin(excess_ratios)]\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n            excess_items = np.where(new_solution == 1)[0]\n            excess_ratios = combined_ratios[excess_items]\n\n    return new_solution\n\n",
        "score": [
            -0.8841827446269912,
            1.5795058608055115
        ]
    }
]