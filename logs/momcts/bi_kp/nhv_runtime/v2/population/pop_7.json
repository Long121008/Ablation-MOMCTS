[
    {
        "algorithm": "This algorithm intelligently selects a promising solution from the archive by normalizing and summing its objectives, then generates a neighbor solution through a hybrid approach combining random item flips (with a 30% probability) and strategic swaps (prioritizing high-value-to-weight items). It ensures feasibility by checking weights and removing excess items if needed, always maintaining the knapsack capacity constraint. The method balances exploration (random flips) with exploitation (value-based swaps) for effective local search.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (here, we choose the one with the highest sum of normalized objectives)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    scores = normalized_obj.sum(axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Create a neighbor solution using a hybrid approach\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Step 1: Randomly flip a subset of items (with bias towards improving both objectives)\n    flip_mask = np.zeros(n_items, dtype=bool)\n    for i in range(n_items):\n        if random.random() < 0.3:  # 30% chance to consider flipping\n            if base_solution[i] == 0:\n                potential_weight = np.sum(weight_lst[new_solution == 1]) + weight_lst[i]\n                if potential_weight <= capacity:\n                    flip_mask[i] = True\n            else:\n                flip_mask[i] = True\n\n    # Step 2: Apply the flips\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Step 3: If no flips applied, try a different approach (swap two items)\n    if not np.any(flip_mask):\n        # Find two items to swap (one in, one out)\n        in_items = np.where(base_solution == 1)[0]\n        out_items = np.where(base_solution == 0)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Select items with high value-to-weight ratio for potential swap\n            in_ratios = (value1_lst[in_items] + value2_lst[in_items]) / weight_lst[in_items]\n            out_ratios = (value1_lst[out_items] + value2_lst[out_items]) / weight_lst[out_items]\n\n            best_in = in_items[np.argmin(in_ratios)]  # Item to remove (lowest ratio)\n            best_out = out_items[np.argmax(out_ratios)]  # Item to add (highest ratio)\n\n            # Check if swap is feasible\n            current_weight = np.sum(weight_lst[base_solution == 1])\n            potential_weight = current_weight - weight_lst[best_in] + weight_lst[best_out]\n\n            if potential_weight <= capacity:\n                new_solution[best_in] = 0\n                new_solution[best_out] = 1\n\n    # Ensure solution is feasible (in case of any errors)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Remove items randomly until feasible\n        while current_weight > capacity:\n            excess_items = np.where(new_solution == 1)[0]\n            if len(excess_items) == 0:\n                break\n            remove_idx = random.choice(excess_items)\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8777357135529364,
            0.6920754313468933
        ]
    },
    {
        "algorithm": "The algorithm selects a random solution from the archive, identifies critical items based on combined value-to-weight ratios, and applies a hybrid local search by toggling these items while ensuring feasibility. It also randomly flips non-critical items to escape local optima. The method prioritizes high-value items while maintaining solution feasibility through weight checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.choice(len(archive))\n    selected_solution, _ = archive[selected_idx]\n    current_solution = selected_solution.copy()\n\n    # Step 2: Identify critical items (those with high value-to-weight ratios)\n    value_to_weight1 = value1_lst / weight_lst\n    value_to_weight2 = value2_lst / weight_lst\n    combined_value_to_weight = value_to_weight1 + value_to_weight2\n    critical_items = np.argsort(combined_value_to_weight)[-min(5, len(weight_lst)):]  # Top 5 items\n\n    # Step 3: Apply a hybrid local search strategy\n    # Flip critical items (if not already in the solution) or remove low-value items\n    new_solution = current_solution.copy()\n    for item in critical_items:\n        if current_solution[item] == 0:\n            # Try adding the item if it fits\n            if (np.sum(weight_lst * new_solution) + weight_lst[item]) <= capacity:\n                new_solution[item] = 1\n        else:\n            # Try removing the item\n            new_solution[item] = 0\n            if np.sum(weight_lst * new_solution) <= capacity:\n                pass  # Keep the change\n            else:\n                new_solution[item] = 1  # Revert if infeasible\n\n    # Step 4: Randomly flip a small number of non-critical items to escape local optima\n    non_critical_items = np.setdiff1d(np.arange(len(weight_lst)), critical_items)\n    if len(non_critical_items) > 0:\n        flip_indices = np.random.choice(non_critical_items, size=min(2, len(non_critical_items)), replace=False)\n        for idx in flip_indices:\n            new_solution[idx] = 1 - new_solution[idx]\n            # Ensure feasibility\n            if np.sum(weight_lst * new_solution) > capacity:\n                new_solution[idx] = 1 - new_solution[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8266459948173828,
            0.3179592788219452
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high objective diversity and moderate density\n    selected_idx = 0\n    max_diversity = -1\n    for i, (sol, obj) in enumerate(archive):\n        diversity = abs(obj[0] - obj[1])\n        density = np.sum(sol)\n        score = diversity / (density + 1e-6)  # Avoid division by zero\n        if score > max_diversity:\n            max_diversity = score\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Identify critical items based on combined value-to-weight ratios\n    value_to_weight1 = value1_lst / weight_lst\n    value_to_weight2 = value2_lst / weight_lst\n    combined_value_to_weight = value_to_weight1 + value_to_weight2\n    critical_items = np.argsort(combined_value_to_weight)[-min(3, len(weight_lst)):]  # Top 3 items\n\n    # Hybrid local search: flip critical items and guided random swaps\n    for _ in range(3):  # Perform 3 iterations\n        # Flip critical items\n        for item in critical_items:\n            temp_solution = new_solution.copy()\n            temp_solution[item] = 1 - temp_solution[item]\n            total_weight = np.sum(temp_solution * weight_lst)\n            if total_weight <= capacity:\n                new_solution = temp_solution.copy()\n\n        # Guided random swap: prioritize high-value items\n        if len(critical_items) > 1:\n            i, j = np.random.choice(critical_items, size=2, replace=False)\n            temp_solution = new_solution.copy()\n            temp_solution[i], temp_solution[j] = temp_solution[j], temp_solution[i]\n            total_weight = np.sum(temp_solution * weight_lst)\n            if total_weight <= capacity:\n                new_solution = temp_solution.copy()\n\n        # Random flip of non-critical items with probability 0.2\n        non_critical_items = np.setdiff1d(np.arange(len(weight_lst)), critical_items)\n        if len(non_critical_items) > 0 and np.random.rand() < 0.2:\n            idx = np.random.choice(non_critical_items)\n            temp_solution = new_solution.copy()\n            temp_solution[idx] = 1 - temp_solution[idx]\n            total_weight = np.sum(temp_solution * weight_lst)\n            if total_weight <= capacity:\n                new_solution = temp_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.8648274670870268,
            0.7946086823940277
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using adaptive normalization (prioritizing solutions with high unexplored potential) and applies a hybrid local search combining critical-item flips (top 10% value-to-weight) with guided random swaps (biased toward high-value items), while ensuring feasibility through incremental weight checks and repair mechanisms. The method prioritizes items with the highest combined value-to-weight ratios, flips their inclusion status, and performs targeted swaps to improve both objectives while maintaining capacity constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive selection: prioritize solutions with unexplored neighborhoods\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    diversity_scores = np.std(objectives, axis=0)  # Higher diversity suggests unexplored regions\n    weighted_scores = normalized_obj * diversity_scores\n    selected_idx = np.argmax(weighted_scores.sum(axis=1))\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate combined value-to-weight ratios\n    combined_ratios = (value1_lst + value2_lst) / weight_lst\n    critical_items = np.argsort(combined_ratios)[-max(1, len(weight_lst) // 10):]  # Top 10% items\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid perturbation\n    # 1. Flip critical items (add if not present, remove if present)\n    for item in critical_items:\n        if new_solution[item] == 0:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n        else:\n            new_solution[item] = 0\n            current_weight -= weight_lst[item]\n\n    # 2. Guided random swaps (bias toward high-value items)\n    non_critical_items = np.setdiff1d(np.arange(len(weight_lst)), critical_items)\n    if len(non_critical_items) > 0:\n        # Select a candidate to swap out (lowest value-to-weight ratio in current solution)\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) > 0:\n            in_ratios = combined_ratios[in_items]\n            swap_out = in_items[np.argmin(in_ratios)]\n\n            # Select a candidate to swap in (highest value-to-weight ratio not in solution)\n            out_items = np.where(new_solution == 0)[0]\n            if len(out_items) > 0:\n                out_ratios = combined_ratios[out_items]\n                swap_in = out_items[np.argmax(out_ratios)]\n\n                # Check if swap is feasible\n                potential_weight = current_weight - weight_lst[swap_out] + weight_lst[swap_in]\n                if potential_weight <= capacity:\n                    new_solution[swap_out] = 0\n                    new_solution[swap_in] = 1\n\n    # Ensure feasibility (repair if needed)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess_items = np.where(new_solution == 1)[0]\n        excess_ratios = combined_ratios[excess_items]\n        # Remove items with lowest value-to-weight ratio until feasible\n        while current_weight > capacity and len(excess_items) > 0:\n            remove_idx = excess_items[np.argmin(excess_ratios)]\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n            excess_items = np.where(new_solution == 1)[0]\n            excess_ratios = combined_ratios[excess_items]\n\n    return new_solution\n\n",
        "score": [
            -0.7557951720924632,
            0.38932788372039795
        ]
    },
    {
        "algorithm": "The algorithm implements a hybrid adaptive local search that prioritizes younger, more diverse solutions from the archive, flips critical high-value items first, then applies guided random perturbations with dynamic intensity, and finally ensures feasibility through lightweight repair. It balances exploration (via diversity and randomness) and exploitation (via critical item flips) while dynamically adjusting perturbation strength based on solution age. The selection scores combine age and diversity to guide the search toward promising regions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive solution selection: prioritize younger solutions with higher diversity\n    ages = np.array([i for i in range(len(archive))])  # Assume newer solutions have higher indices\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    diversity_scores = normalized_obj.std(axis=1)  # Higher diversity is better\n    selection_scores = (ages / len(archive)) + diversity_scores  # Balance age and diversity\n    selected_idx = np.argmax(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid perturbation strategy\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 1: Critical item flips (high value-to-weight ratio)\n    combined_value_to_weight = (value1_lst + value2_lst) / weight_lst\n    critical_items = np.argsort(combined_value_to_weight)[-min(5, n_items):]  # Top 5 items\n\n    for item in critical_items:\n        if base_solution[item] == 0:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n        else:\n            new_solution[item] = 0\n            current_weight -= weight_lst[item]\n\n    # Step 2: Guided random swaps (dynamic intensity)\n    perturbation_intensity = 0.3 + (0.7 * (selected_idx / len(archive)))  # Higher for older solutions\n    for i in range(n_items):\n        if random.random() < perturbation_intensity:\n            if new_solution[i] == 0:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n            else:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n\n    # Step 3: Lightweight repair (remove excess items if needed)\n    if current_weight > capacity:\n        excess_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(excess_items)\n        for item in excess_items:\n            if current_weight <= capacity:\n                break\n            new_solution[item] = 0\n            current_weight -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.48432951236982885,
            0.3804723024368286
        ]
    },
    {
        "algorithm": "The algorithm selects a random solution from the archive, applies a flip mutation to a random item, and then attempts to iteratively add or remove items to improve both objectives while ensuring feasibility. It prioritizes flipping a single item first, followed by greedy additions and removals of items that don't worsen either objective. The heuristic balances exploration (random selection and flipping) with exploitation (greedy improvements) to generate diverse, high-quality neighbors.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: Flip a randomly selected item and attempt to add/remove items to improve both objectives\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Step 1: Randomly flip one item (basic local search)\n    flip_idx = np.random.choice(n_items)\n    new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # Ensure feasibility\n    if np.sum(weight_lst * new_solution) > capacity:\n        # If flipping violates capacity, undo the flip\n        new_solution[flip_idx] = base_solution[flip_idx]\n\n    # Step 2: Attempt to add items not in the solution to improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n\n    for item in remaining_items:\n        if current_weight + weight_lst[item] <= capacity:\n            # Temporarily add the item\n            temp_solution = new_solution.copy()\n            temp_solution[item] = 1\n            temp_weight = np.sum(weight_lst * temp_solution)\n\n            # Check if adding improves both objectives (approximate)\n            if temp_weight <= capacity:\n                # If no objective worsens, keep the change\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    # Step 3: Attempt to remove items to improve both objectives\n    included_items = np.where(new_solution == 1)[0]\n    np.random.shuffle(included_items)\n\n    for item in included_items:\n        temp_solution = new_solution.copy()\n        temp_solution[item] = 0\n        temp_weight = np.sum(weight_lst * temp_solution)\n\n        # Check if removing improves both objectives (approximate)\n        if temp_weight <= capacity:\n            # If no objective worsens, keep the change\n            new_solution = temp_solution\n            current_weight = temp_weight\n\n    return new_solution\n\n",
        "score": [
            -0.8479368153123263,
            0.807338297367096
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive prioritizing those with high objective diversity (absolute difference between the two objectives) and low density (fewer items), then applies a hybrid local search combining random item swaps and flips with a probability of 0.3, ensuring feasibility by always checking the weight constraint. The selection emphasizes solutions with balanced objectives and simplicity, while the local search explores neighbors intelligently to escape local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high objective diversity and low density\n    selected_idx = 0\n    max_diversity = -1\n    for i, (sol, obj) in enumerate(archive):\n        diversity = abs(obj[0] - obj[1])  # Measure of objective diversity\n        density = np.sum(sol)  # Number of items in the solution\n        score = diversity / (density + 1)  # Prefer solutions with high diversity and low density\n        if score > max_diversity:\n            max_diversity = score\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: swap items and flip with probability\n    n_items = len(weight_lst)\n    for _ in range(2):  # Perform 2 iterations of local search\n        # Randomly select two distinct items\n        i, j = np.random.choice(n_items, size=2, replace=False)\n\n        # Try swapping items i and j\n        temp_solution = new_solution.copy()\n        temp_solution[i], temp_solution[j] = temp_solution[j], temp_solution[i]\n        total_weight = np.sum(temp_solution * weight_lst)\n\n        if total_weight <= capacity:\n            new_solution = temp_solution.copy()\n\n        # Try flipping item i with probability 0.3\n        if np.random.rand() < 0.3:\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1 - temp_solution[i]\n            total_weight = np.sum(temp_solution * weight_lst)\n\n            if total_weight <= capacity:\n                new_solution = temp_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.7024644525497394,
            0.6926618814468384
        ]
    },
    {
        "algorithm": "The algorithm combines adaptive solution selection (prioritizing novel solutions) with a hybrid perturbation strategy that flips critical items (high value-to-weight ratio) with higher probability, performs guided swaps between low-contribution and high-value items, and occasionally flips low-contribution items to escape local optima, all while ensuring feasibility through incremental weight checks and repair mechanisms. It dynamically balances exploration and exploitation by adjusting perturbation intensity based on item contributions and solution diversity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive selection: prioritize solutions with high novelty (diversity in objectives)\n    objectives = np.array([obj for _, obj in archive])\n    novelty_scores = np.max(np.abs(objectives[:, None, :] - objectives[None, :, :]), axis=1).mean(axis=1)\n    selected_idx = np.argmax(novelty_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate combined value-to-weight ratios and identify critical items\n    combined_ratios = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(combined_ratios)[::-1]\n    critical_items = sorted_indices[:max(1, len(weight_lst) // 20)]  # Top 5% items\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid perturbation\n    # 1. Flip critical items with adaptive probability based on their contribution\n    for item in critical_items:\n        if np.random.rand() < 0.7:  # Higher probability for critical items\n            if new_solution[item] == 0:\n                if current_weight + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                    current_weight += weight_lst[item]\n            else:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n\n    # 2. Guided random swaps with novelty-aware selection\n    non_critical_items = np.setdiff1d(np.arange(len(weight_lst)), critical_items)\n    if len(non_critical_items) > 0:\n        # Select a candidate to swap out (lowest marginal contribution)\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) > 0:\n            marginal_contributions = (value1_lst[in_items] + value2_lst[in_items]) / weight_lst[in_items]\n            swap_out = in_items[np.argmin(marginal_contributions)]\n\n            # Select a candidate to swap in (highest value-to-weight ratio not in solution)\n            out_items = np.where(new_solution == 0)[0]\n            if len(out_items) > 0:\n                out_ratios = combined_ratios[out_items]\n                swap_in = out_items[np.argmax(out_ratios)]\n\n                # Check if swap is feasible\n                potential_weight = current_weight - weight_lst[swap_out] + weight_lst[swap_in]\n                if potential_weight <= capacity:\n                    new_solution[swap_out] = 0\n                    new_solution[swap_in] = 1\n                    current_weight = potential_weight\n\n    # 3. Novelty-aware random flips to escape local optima\n    if np.random.rand() < 0.3:  # 30% chance to perform novelty flips\n        low_contribution_items = sorted_indices[-len(sorted_indices)//2:]  # Bottom 50% items\n        for item in low_contribution_items:\n            if np.random.rand() < 0.2:  # 20% chance to flip each low-contribution item\n                if new_solution[item] == 0:\n                    if current_weight + weight_lst[item] <= capacity:\n                        new_solution[item] = 1\n                        current_weight += weight_lst[item]\n                else:\n                    new_solution[item] = 0\n                    current_weight -= weight_lst[item]\n\n    # Ensure feasibility (repair if needed)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess_items = np.where(new_solution == 1)[0]\n        excess_ratios = combined_ratios[excess_items]\n        # Remove items with lowest value-to-weight ratio until feasible\n        while current_weight > capacity and len(excess_items) > 0:\n            remove_idx = excess_items[np.argmin(excess_ratios)]\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n            excess_items = np.where(new_solution == 1)[0]\n            excess_ratios = combined_ratios[excess_items]\n\n    return new_solution\n\n",
        "score": [
            -0.4607933612068813,
            0.39616963267326355
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive (based on normalized objective scores) and generates a neighbor by first flipping high-impact \"critical\" items (top 5 by combined value-to-weight ratio) with a 70% chance, then probabilistically flipping remaining items with a decaying probability (starting at 50%) to balance exploration and exploitation, while always ensuring feasibility by removing excess items if needed.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of normalized objectives)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    scores = normalized_obj.sum(axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Phase 1: Identify critical items (high impact on both objectives)\n    value_ratios = (value1_lst + value2_lst) / weight_lst\n    critical_items = np.argsort(value_ratios)[-min(5, n_items):]  # Top 5 items by combined ratio\n\n    # Phase 2: Guided flip of critical items\n    for item in critical_items:\n        if np.random.rand() < 0.7:  # 70% chance to consider flipping\n            if new_solution[item] == 0:\n                if current_weight + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                    current_weight += weight_lst[item]\n            else:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n\n    # Phase 3: Probabilistic exploration (decaying probability)\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n    exploration_prob = 0.5  # Initial probability\n\n    for item in remaining_items:\n        if np.random.rand() < exploration_prob:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n                exploration_prob *= 0.9  # Decay probability\n\n    # Ensure feasibility\n    while current_weight > capacity:\n        excess_items = np.where(new_solution == 1)[0]\n        if len(excess_items) == 0:\n            break\n        remove_idx = np.random.choice(excess_items)\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.4640978474732475,
            0.964194118976593
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive by weighting objectives randomly, then applies a hybrid local search that prioritizes flipping high-marginal-value items (top 3 by combined value/weight ratio) with 60% probability while ensuring feasibility, followed by random perturbations to other items to escape local optima. The selection balances exploration (weighted objectives) and exploitation (high-marginal items), ensuring feasible neighbors through capacity checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) == 1:\n        selected_solution = archive[0][0].copy()\n    else:\n        objectives = np.array([obj for _, obj in archive])\n        weights = np.random.uniform(0.3, 0.7, size=2)  # Random weights for objectives\n        weighted_scores = np.dot(objectives, weights)\n        selected_idx = np.argmax(weighted_scores)\n        selected_solution = archive[selected_idx][0].copy()\n\n    current_solution = selected_solution.copy()\n    new_solution = current_solution.copy()\n\n    # Calculate marginal contributions for each item\n    marginal1 = value1_lst / weight_lst\n    marginal2 = value2_lst / weight_lst\n    combined_marginal = (marginal1 + marginal2) / 2\n\n    # Identify items with high marginal contributions\n    high_marginal_items = np.argsort(combined_marginal)[-min(3, len(weight_lst)):]  # Top 3 items\n\n    # Flip high marginal items with probability based on their marginal value\n    for item in high_marginal_items:\n        if np.random.rand() < 0.6:  # Higher probability to flip high marginal items\n            if current_solution[item] == 0:\n                if (np.sum(weight_lst * new_solution) + weight_lst[item]) <= capacity:\n                    new_solution[item] = 1\n            else:\n                new_solution[item] = 0\n                if np.sum(weight_lst * new_solution) > capacity:\n                    new_solution[item] = 1\n\n    # Randomly flip a small number of items not in high marginal set\n    non_high_marginal_items = np.setdiff1d(np.arange(len(weight_lst)), high_marginal_items)\n    if len(non_high_marginal_items) > 0:\n        flip_indices = np.random.choice(non_high_marginal_items, size=min(1, len(non_high_marginal_items)), replace=False)\n        for idx in flip_indices:\n            new_solution[idx] = 1 - new_solution[idx]\n            if np.sum(weight_lst * new_solution) > capacity:\n                new_solution[idx] = 1 - new_solution[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3566614660723011,
            0.4891371428966522
        ]
    }
]