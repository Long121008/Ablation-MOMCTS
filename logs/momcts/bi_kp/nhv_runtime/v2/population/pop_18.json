[
    {
        "algorithm": "The algorithm intelligently selects a solution from the archive by prioritizing high-objective-value solutions with low crowding distance, then applies a hybrid local search combining random item swaps and adaptive perturbations to explore neighbors while ensuring feasibility. It prioritizes solutions with better combined objective values and diversity (crowding distance) to guide selection, and uses a mix of item swaps and random flips to generate neighbors, with feasibility checks at each step.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high objective values and low crowding distance\n    objectives = np.array([obj for (sol, obj) in archive])\n    if len(archive) > 1:\n        # Compute crowding distance\n        sorted_indices = np.argsort(objectives[:, 0])\n        crowding = np.zeros(len(archive))\n        crowding[sorted_indices[0]] = crowding[sorted_indices[-1]] = float('inf')\n        for i in range(1, len(archive) - 1):\n            crowding[sorted_indices[i]] = objectives[sorted_indices[i+1], 0] - objectives[sorted_indices[i-1], 0]\n        # Normalize and combine with objective values\n        scores = objectives[:, 0] + objectives[:, 1] + crowding\n    else:\n        scores = np.array([1.0])\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search: item swapping and adaptive perturbation\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Swap items between included and excluded with feasibility check\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Select a random item to remove\n        remove_idx = np.random.choice(included)\n        # Select a random item to add\n        add_idx = np.random.choice(excluded)\n\n        # Check feasibility\n        if (current_weight - weight_lst[remove_idx] + weight_lst[add_idx]) <= capacity:\n            new_solution[remove_idx] = 0\n            new_solution[add_idx] = 1\n\n    # Adaptive perturbation: randomly flip a small number of items\n    num_flips = max(1, int(0.1 * len(weight_lst)))\n    flip_indices = np.random.choice(len(weight_lst), num_flips, replace=False)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            if (current_weight - weight_lst[idx]) <= capacity:\n                new_solution[idx] = 0\n        else:\n            if (current_weight + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.7589912329452198,
            0.27401870489120483
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with higher combined objective values and lower weights, then applies a hybrid local search that intelligently swaps items between objectives to balance improvements in both value dimensions while ensuring feasibility. It first tries beneficial swaps between included and excluded items, then adds new items if possible, and finally removes the least valuable item if no improvements are found. The selection criterion balances both objectives and weight, while the local search prioritizes simultaneous improvements in both value dimensions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution (higher objectives, lower weight)\n    selected_idx = np.argmax([obj[0] + obj[1] - 0.1 * np.sum(weight_lst * sol) for sol, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: balance improvements in both objectives\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = archive[selected_idx][1][0]\n    current_value2 = archive[selected_idx][1][1]\n\n    # Identify items to potentially swap or reallocate\n    zero_indices = np.where(base_solution == 0)[0]\n    one_indices = np.where(base_solution == 1)[0]\n\n    # Try to improve both objectives by swapping items\n    for i in one_indices:\n        for j in zero_indices:\n            if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                delta_value1 = value1_lst[j] - value1_lst[i]\n                delta_value2 = value2_lst[j] - value2_lst[i]\n                if (delta_value1 > 0 and delta_value2 > 0) or (delta_value1 * delta_value2 > 0):\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n                    return new_solution\n\n    # If no beneficial swap, try to add a new item if possible\n    for j in zero_indices:\n        if current_weight + weight_lst[j] <= capacity:\n            new_solution[j] = 1\n            return new_solution\n\n    # If no improvement, try to remove the least valuable item\n    if len(one_indices) > 0:\n        least_value_idx = one_indices[np.argmin(value1_lst[one_indices] + value2_lst[one_indices])]\n        new_solution[least_value_idx] = 0\n        return new_solution\n\n    return new_solution\n\n",
        "score": [
            -0.4437320828583445,
            0.2243274748325348
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive by balancing high objective values and diversity (crowding distance), then generates a neighbor solution through a value-weighted perturbation strategy that flips items probabilistically based on their combined marginal contributions, while maintaining feasibility through adaptive capacity checks. It further refines the solution with a multi-objective guided swap operation that intelligently exchanges items between included and excluded sets to improve both objectives. The approach prioritizes items with higher value-to-weight ratios and ensures the neighbor solution remains feasible by carefully adjusting the knapsack capacity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high objective values and moderate crowding distance\n    objectives = np.array([obj for (sol, obj) in archive])\n    if len(archive) > 1:\n        # Compute crowding distance\n        sorted_indices = np.argsort(objectives[:, 0])\n        crowding = np.zeros(len(archive))\n        crowding[sorted_indices[0]] = crowding[sorted_indices[-1]] = float('inf')\n        for i in range(1, len(archive) - 1):\n            crowding[sorted_indices[i]] = objectives[sorted_indices[i+1], 0] - objectives[sorted_indices[i-1], 0]\n        # Normalize crowding and combine with objective values\n        normalized_crowding = (crowding - np.min(crowding)) / (np.max(crowding) - np.min(crowding) + 1e-10)\n        scores = objectives[:, 0] + objectives[:, 1] - normalized_crowding\n    else:\n        scores = np.array([1.0])\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Value-weighted perturbation strategy\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Calculate marginal contributions (value-to-weight ratios)\n    marginal1 = value1_lst / (weight_lst + 1e-10)\n    marginal2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal1 + marginal2\n\n    # Select items to flip based on marginal contribution and current inclusion\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    # Probabilistic flip based on marginal contribution\n    flip_prob = np.zeros(len(weight_lst))\n    flip_prob[included] = 1 - np.exp(-combined_marginal[included])\n    flip_prob[excluded] = np.exp(-combined_marginal[excluded])\n    flip_indices = np.where(np.random.rand(len(weight_lst)) < flip_prob)[0]\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            if (current_weight - weight_lst[idx]) <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if (current_weight + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Multi-objective guided swap\n    if len(included) > 0 and len(excluded) > 0:\n        # Sort included items by combined marginal contribution (descending)\n        included_sorted = included[np.argsort(-combined_marginal[included])]\n        # Sort excluded items by combined marginal contribution (ascending)\n        excluded_sorted = excluded[np.argsort(combined_marginal[excluded])]\n\n        for i in range(min(2, len(included_sorted), len(excluded_sorted))):\n            remove_idx = included_sorted[i]\n            add_idx = excluded_sorted[i]\n\n            if (current_weight - weight_lst[remove_idx] + weight_lst[add_idx]) <= capacity:\n                new_solution[remove_idx] = 0\n                new_solution[add_idx] = 1\n                current_weight = current_weight - weight_lst[remove_idx] + weight_lst[add_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9310224274226554,
            0.39585617184638977
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive based on a combination of objective values and crowding distance, then applies a three-phase local search: first reallocating items by removing low-value/high-weight items and adding high-value/low-weight items, followed by targeted flipping of high-value items, and finally adding items with the highest marginal gain while ensuring feasibility. The selection prioritizes solutions with balanced objectives and diversity, while the local search strategically improves solutions by focusing on value ratios, weight impacts, and marginal gains.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high combined objective values and low crowding distance\n    objectives = np.array([obj for (sol, obj) in archive])\n    if len(archive) > 1:\n        # Compute crowding distance\n        sorted_indices = np.argsort(objectives[:, 0])\n        crowding = np.zeros(len(archive))\n        crowding[sorted_indices[0]] = crowding[sorted_indices[-1]] = float('inf')\n        for i in range(1, len(archive) - 1):\n            crowding[sorted_indices[i]] = objectives[sorted_indices[i+1], 0] - objectives[sorted_indices[i-1], 0]\n        # Normalize and combine with objective values\n        scores = (objectives[:, 0] + objectives[:, 1]) * (1 + 1 / (1 + crowding))\n    else:\n        scores = np.array([1.0])\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Phase 1: Intelligent reallocation based on value ratios and weight impacts\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value ratios and weight impacts\n        value_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        included_ratios = value_ratios[included]\n        excluded_ratios = value_ratios[excluded]\n\n        # Find best candidate to remove and add\n        remove_candidate = included[np.argmin(included_ratios)]\n        add_candidate = excluded[np.argmax(excluded_ratios)]\n\n        if (current_weight - weight_lst[remove_candidate] + weight_lst[add_candidate]) <= capacity:\n            new_solution[remove_candidate] = 0\n            new_solution[add_candidate] = 1\n            current_weight = current_weight - weight_lst[remove_candidate] + weight_lst[add_candidate]\n\n    # Phase 2: Targeted perturbation in high-value regions\n    if len(included) > 0:\n        # Identify high-value regions\n        included_values = value1_lst[included] + value2_lst[included]\n        high_value_indices = included[np.argsort(included_values)[-max(1, len(included)//5):]]\n\n        # Flip some items in these regions\n        for idx in high_value_indices:\n            if np.random.rand() < 0.3:  # 30% chance to flip\n                if new_solution[idx] == 1 and (current_weight - weight_lst[idx]) <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n\n    # Phase 3: Feasibility-preserving mutation with marginal gain\n    if len(excluded) > 0:\n        # Calculate marginal gains\n        remaining_capacity = capacity - current_weight\n        feasible_excluded = excluded[weight_lst[excluded] <= remaining_capacity]\n        if len(feasible_excluded) > 0:\n            marginal_gains = (value1_lst[feasible_excluded] + value2_lst[feasible_excluded]) / weight_lst[feasible_excluded]\n            best_add = feasible_excluded[np.argmax(marginal_gains)]\n\n            if np.random.rand() < 0.5:  # 50% chance to add best marginal gain item\n                new_solution[best_add] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.5649989391927909,
            0.2467847466468811
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive based on high marginal contributions (value-to-weight ratios) and low crowding distance, then applies a hybrid local search combining probabilistic flips and Pareto-guided swaps to generate feasible neighbors that balance both objectives. It prioritizes items with high combined marginal values for flips and performs targeted swaps between included and excluded items that improve both objectives simultaneously. The method ensures feasibility by checking weight constraints at each operation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution with high marginal contributions and low crowding distance\n    objectives = np.array([obj for (sol, obj) in archive])\n    if len(archive) > 1:\n        # Compute crowding distance\n        sorted_indices = np.argsort(objectives[:, 0])\n        crowding = np.zeros(len(archive))\n        crowding[sorted_indices[0]] = crowding[sorted_indices[-1]] = float('inf')\n        for i in range(1, len(archive) - 1):\n            crowding[sorted_indices[i]] = objectives[sorted_indices[i+1], 0] - objectives[sorted_indices[i-1], 0]\n        normalized_crowding = (crowding - np.min(crowding)) / (np.max(crowding) - np.min(crowding) + 1e-10)\n        scores = objectives[:, 0] + objectives[:, 1] - normalized_crowding\n    else:\n        scores = np.array([1.0])\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Calculate marginal contributions (value-to-weight ratios)\n    marginal1 = value1_lst / (weight_lst + 1e-10)\n    marginal2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal1 + marginal2\n\n    # Probabilistic flip based on marginal contributions\n    flip_prob = np.zeros(len(weight_lst))\n    flip_prob[new_solution == 1] = 1 - np.exp(-combined_marginal[new_solution == 1])\n    flip_prob[new_solution == 0] = np.exp(-combined_marginal[new_solution == 0])\n    flip_indices = np.where(np.random.rand(len(weight_lst)) < flip_prob)[0]\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            if (current_weight - weight_lst[idx]) <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if (current_weight + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Pareto-guided swap: prioritize items that improve both objectives\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Sort included items by descending marginal contribution\n        included_sorted = included[np.argsort(-combined_marginal[included])]\n        # Sort excluded items by ascending marginal contribution\n        excluded_sorted = excluded[np.argsort(combined_marginal[excluded])]\n\n        for i in range(min(2, len(included_sorted), len(excluded_sorted))):\n            remove_idx = included_sorted[i]\n            add_idx = excluded_sorted[i]\n\n            if (current_weight - weight_lst[remove_idx] + weight_lst[add_idx]) <= capacity:\n                delta_value1 = value1_lst[add_idx] - value1_lst[remove_idx]\n                delta_value2 = value2_lst[add_idx] - value2_lst[remove_idx]\n\n                if (delta_value1 > 0 and delta_value2 > 0) or (delta_value1 * delta_value2 > 0):\n                    new_solution[remove_idx] = 0\n                    new_solution[add_idx] = 1\n                    current_weight = current_weight - weight_lst[remove_idx] + weight_lst[add_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9724996908482954,
            0.4105971157550812
        ]
    },
    {
        "algorithm": "The algorithm selects a high-quality solution from the archive by prioritizing both objective values and crowding distance, then generates a neighbor through a three-phase process: probabilistic flips weighted by marginal contributions, Pareto-guided swaps between included and excluded items, and adaptive perturbations to escape local optima while maintaining feasibility. The method balances exploration (via marginal contributions and random flips) with exploitation (via Pareto-guided swaps) to efficiently navigate the solution space.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high objective values and low crowding distance\n    objectives = np.array([obj for (sol, obj) in archive])\n    if len(archive) > 1:\n        # Compute crowding distance\n        sorted_indices = np.argsort(objectives[:, 0])\n        crowding = np.zeros(len(archive))\n        crowding[sorted_indices[0]] = crowding[sorted_indices[-1]] = float('inf')\n        for i in range(1, len(archive) - 1):\n            crowding[sorted_indices[i]] = objectives[sorted_indices[i+1], 0] - objectives[sorted_indices[i-1], 0]\n        # Normalize and combine with objective values\n        scores = objectives[:, 0] + objectives[:, 1] + crowding\n    else:\n        scores = np.array([1.0])\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-10)\n    marginal2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal1 + marginal2\n\n    # Phase 1: Probabilistic flip with marginal weighting\n    flip_prob = np.zeros(len(weight_lst))\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    flip_prob[included] = 1 - np.exp(-combined_marginal[included])\n    flip_prob[excluded] = np.exp(-combined_marginal[excluded]) * (weight_lst[excluded] <= remaining_capacity)\n\n    flip_mask = np.random.rand(len(weight_lst)) < flip_prob\n    for idx in np.where(flip_mask)[0]:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n            remaining_capacity += weight_lst[idx]\n        else:\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    # Phase 2: Pareto-guided swap\n    if len(included) > 0 and len(excluded) > 0:\n        # Sort included by descending marginal, excluded by ascending marginal\n        included_sorted = included[np.argsort(-combined_marginal[included])]\n        excluded_sorted = excluded[np.argsort(combined_marginal[excluded])]\n\n        for i in range(min(3, len(included_sorted), len(excluded_sorted))):\n            remove_idx = included_sorted[i]\n            add_idx = excluded_sorted[i]\n\n            if (weight_lst[add_idx] - weight_lst[remove_idx]) <= remaining_capacity:\n                new_solution[remove_idx] = 0\n                new_solution[add_idx] = 1\n                remaining_capacity += weight_lst[remove_idx] - weight_lst[add_idx]\n\n    # Phase 3: Adaptive perturbation\n    num_flips = max(1, int(0.05 * len(weight_lst)))\n    flip_indices = np.random.choice(len(weight_lst), num_flips, replace=False)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 0\n                remaining_capacity += weight_lst[idx]\n        else:\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9089812321900332,
            0.3354184925556183
        ]
    },
    {
        "algorithm": "The heuristic selects a random solution from the archive and applies a hybrid local search combining random item swaps (to explore the solution space) and greedy marginal-value selection (to exploit high-value items), ensuring feasibility by checking weights at each step. The algorithm prioritizes items with combined high value-to-weight ratios while maintaining the knapsack capacity constraint.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: random swaps with greedy selection\n    for _ in range(10):  # Number of iterations\n        # Randomly select two items to swap\n        item1, item2 = random.sample(range(len(weight_lst)), 2)\n\n        # Calculate new weights if we swap the items\n        new_weight = current_weight - weight_lst[item1] * new_solution[item1] + weight_lst[item1] * (1 - new_solution[item1])\n        new_weight = new_weight - weight_lst[item2] * new_solution[item2] + weight_lst[item2] * (1 - new_solution[item2])\n\n        if new_weight <= capacity:\n            # Accept the swap if feasible\n            new_solution[item1] = 1 - new_solution[item1]\n            new_solution[item2] = 1 - new_solution[item2]\n            current_weight = new_weight\n\n    # Additional greedy improvement: add items with highest marginal value\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        marginal_values = (value1_lst + value2_lst) / weight_lst\n        feasible_items = (weight_lst <= remaining_capacity) & (new_solution == 0)\n        if np.any(feasible_items):\n            best_item = np.argmax(marginal_values * feasible_items)\n            if marginal_values[best_item] > 0:\n                new_solution[best_item] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.38488836615279653,
            0.23517856001853943
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with high dominance (fewer dominators), better crowding distance, and balanced objective values, then generates a neighbor through a hybrid local search combining probabilistic item flips (weighted by marginal contributions) and Pareto-guided swaps, ensuring feasibility by checking capacity constraints at each step. The selection emphasizes solutions with fewer dominators and better diversity, while the neighbor generation prioritizes high-value-to-weight items and balanced contributions to both objectives, using adaptive swaps to refine the solution.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high objective dominance, diversity, and balanced values\n    objectives = np.array([obj for (sol, obj) in archive])\n    if len(archive) > 1:\n        # Compute dominance\n        dominance = np.zeros(len(archive))\n        for i in range(len(archive)):\n            dominated = 0\n            for j in range(len(archive)):\n                if i != j and objectives[j, 0] >= objectives[i, 0] and objectives[j, 1] >= objectives[i, 1]:\n                    if objectives[j, 0] > objectives[i, 0] or objectives[j, 1] > objectives[i, 1]:\n                        dominated += 1\n            dominance[i] = 1 / (dominated + 1)\n\n        # Compute crowding distance\n        sorted_indices = np.argsort(objectives[:, 0])\n        crowding = np.zeros(len(archive))\n        crowding[sorted_indices[0]] = crowding[sorted_indices[-1]] = float('inf')\n        for i in range(1, len(archive) - 1):\n            crowding[sorted_indices[i]] = objectives[sorted_indices[i+1], 0] - objectives[sorted_indices[i-1], 0]\n\n        # Combine dominance, crowding, and balanced objectives\n        balanced_scores = (objectives[:, 0] + objectives[:, 1]) / (np.abs(objectives[:, 0] - objectives[:, 1]) + 1e-10)\n        scores = dominance * (1 + crowding) * balanced_scores\n    else:\n        scores = np.array([1.0])\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search: probabilistic flips + Pareto-guided swaps\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Calculate marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-10)\n    marginal2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal1 + marginal2\n\n    # Probabilistic flip based on marginal contributions\n    flip_prob = np.zeros(len(weight_lst))\n    flip_prob[new_solution == 1] = 1 - np.exp(-combined_marginal[new_solution == 1])\n    flip_prob[new_solution == 0] = np.exp(-combined_marginal[new_solution == 0]) * 0.5\n    flip_indices = np.where(np.random.rand(len(weight_lst)) < flip_prob)[0]\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            if (current_weight - weight_lst[idx]) <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if (current_weight + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Pareto-guided swaps\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Sort included by descending marginal contribution\n        included_sorted = included[np.argsort(-combined_marginal[included])]\n        # Sort excluded by ascending marginal contribution\n        excluded_sorted = excluded[np.argsort(combined_marginal[excluded])]\n\n        swap_count = min(2, len(included_sorted), len(excluded_sorted))\n        for i in range(swap_count):\n            remove_idx = included_sorted[i]\n            add_idx = excluded_sorted[i]\n\n            if (current_weight - weight_lst[remove_idx] + weight_lst[add_idx]) <= capacity:\n                new_solution[remove_idx] = 0\n                new_solution[add_idx] = 1\n                current_weight = current_weight - weight_lst[remove_idx] + weight_lst[add_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9655623769220382,
            0.8025371432304382
        ]
    },
    {
        "algorithm": "This algorithm selects a promising solution from the archive by combining objective product scores with diversity metrics, then generates neighbors through a two-phase process: first flipping items probabilistically based on value ratios and feasibility, followed by impact-based swaps prioritizing high-value items while maintaining capacity constraints. The method intelligently balances exploration (via probabilistic flips) and exploitation (via strategic swaps) to improve both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Calculate hybrid metrics\n    value_ratio = (value1_lst + 1e-10) / (value2_lst + 1e-10)\n    diversity_score = np.zeros(len(archive))\n    for i, (sol, _) in enumerate(archive):\n        diversity_score[i] = np.sum(np.abs(sol - np.mean(archive[i][0])))\n\n    # Select solution with highest hybrid score (objective product + diversity)\n    scores = np.array([(obj[0] * obj[1]) * diversity_score[i] for i, (_, obj) in enumerate(archive)])\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    # Phase 1: Adaptive flip with value-ratio weighting\n    flip_prob = np.zeros(len(weight_lst))\n    if len(included) > 0:\n        flip_prob[included] = np.exp(-value_ratio[included]) * (weight_lst[included] / (value1_lst[included] + value2_lst[included] + 1e-10))\n    flip_prob[excluded] = (1 - np.exp(-value_ratio[excluded])) * (weight_lst[excluded] <= remaining_capacity)\n\n    flip_mask = np.random.rand(len(weight_lst)) < flip_prob\n    for idx in np.where(flip_mask)[0]:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n            remaining_capacity += weight_lst[idx]\n        else:\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    # Phase 2: Impact-based swap\n    if len(included) > 0 and len(excluded) > 0:\n        impact_scores = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        included_sorted = included[np.argsort(-impact_scores[included])]\n        excluded_sorted = excluded[np.argsort(impact_scores[excluded])]\n\n        for i in range(min(2, len(included_sorted), len(excluded_sorted))):\n            remove_idx = included_sorted[i]\n            add_idx = excluded_sorted[i]\n            delta_weight = weight_lst[add_idx] - weight_lst[remove_idx]\n\n            if delta_weight <= remaining_capacity:\n                new_solution[remove_idx] = 0\n                new_solution[add_idx] = 1\n                remaining_capacity -= delta_weight\n\n    return new_solution\n\n",
        "score": [
            -0.9100108026150004,
            0.657597154378891
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution with high combined marginal contributions and low crowding distance\n    objectives = np.array([obj for (sol, obj) in archive])\n    if len(archive) > 1:\n        sorted_indices = np.argsort(objectives[:, 0])\n        crowding = np.zeros(len(archive))\n        crowding[sorted_indices[0]] = crowding[sorted_indices[-1]] = float('inf')\n        for i in range(1, len(archive) - 1):\n            crowding[sorted_indices[i]] = objectives[sorted_indices[i+1], 0] - objectives[sorted_indices[i-1], 0]\n        normalized_crowding = (crowding - np.min(crowding)) / (np.max(crowding) - np.min(crowding) + 1e-10)\n        marginal1 = value1_lst / (weight_lst + 1e-10)\n        marginal2 = value2_lst / (weight_lst + 1e-10)\n        combined_marginal = marginal1 + marginal2\n        scores = objectives[:, 0] + objectives[:, 1] - normalized_crowding + np.sum(combined_marginal[archive[0][0] == 1])\n    else:\n        scores = np.array([1.0])\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: marginal-guided flips and Pareto-aware swaps\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    # Marginal-guided flip\n    flip_prob = np.zeros(len(weight_lst))\n    flip_prob[included] = 1 - np.exp(-combined_marginal[included])\n    flip_prob[excluded] = np.exp(-combined_marginal[excluded]) * (weight_lst[excluded] <= capacity - current_weight)\n    flip_mask = np.random.rand(len(weight_lst)) < flip_prob\n    for idx in np.where(flip_mask)[0]:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        else:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Pareto-aware swap\n    if len(included) > 0 and len(excluded) > 0:\n        included_sorted = included[np.argsort(-combined_marginal[included])]\n        excluded_sorted = excluded[np.argsort(combined_marginal[excluded])]\n        for i in range(min(3, len(included_sorted), len(excluded_sorted))):\n            remove_idx = included_sorted[i]\n            add_idx = excluded_sorted[i]\n            if (current_weight - weight_lst[remove_idx] + weight_lst[add_idx]) <= capacity:\n                delta_value1 = value1_lst[add_idx] - value1_lst[remove_idx]\n                delta_value2 = value2_lst[add_idx] - value2_lst[remove_idx]\n                if (delta_value1 > 0 and delta_value2 > 0) or (delta_value1 * delta_value2 > 0):\n                    new_solution[remove_idx] = 0\n                    new_solution[add_idx] = 1\n                    current_weight = current_weight - weight_lst[remove_idx] + weight_lst[add_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9042168689257356,
            0.34769105911254883
        ]
    }
]