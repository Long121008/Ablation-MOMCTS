[
    {
        "algorithm": "The algorithm intelligently selects a solution from the archive by prioritizing high-objective-value solutions with low crowding distance, then applies a hybrid local search combining random item swaps and adaptive perturbations to explore neighbors while ensuring feasibility. It prioritizes solutions with better combined objective values and diversity (crowding distance) to guide selection, and uses a mix of item swaps and random flips to generate neighbors, with feasibility checks at each step.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high objective values and low crowding distance\n    objectives = np.array([obj for (sol, obj) in archive])\n    if len(archive) > 1:\n        # Compute crowding distance\n        sorted_indices = np.argsort(objectives[:, 0])\n        crowding = np.zeros(len(archive))\n        crowding[sorted_indices[0]] = crowding[sorted_indices[-1]] = float('inf')\n        for i in range(1, len(archive) - 1):\n            crowding[sorted_indices[i]] = objectives[sorted_indices[i+1], 0] - objectives[sorted_indices[i-1], 0]\n        # Normalize and combine with objective values\n        scores = objectives[:, 0] + objectives[:, 1] + crowding\n    else:\n        scores = np.array([1.0])\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search: item swapping and adaptive perturbation\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Swap items between included and excluded with feasibility check\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Select a random item to remove\n        remove_idx = np.random.choice(included)\n        # Select a random item to add\n        add_idx = np.random.choice(excluded)\n\n        # Check feasibility\n        if (current_weight - weight_lst[remove_idx] + weight_lst[add_idx]) <= capacity:\n            new_solution[remove_idx] = 0\n            new_solution[add_idx] = 1\n\n    # Adaptive perturbation: randomly flip a small number of items\n    num_flips = max(1, int(0.1 * len(weight_lst)))\n    flip_indices = np.random.choice(len(weight_lst), num_flips, replace=False)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            if (current_weight - weight_lst[idx]) <= capacity:\n                new_solution[idx] = 0\n        else:\n            if (current_weight + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.7589912329452198,
            0.27401870489120483
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with higher combined objective values and lower weights, then applies a hybrid local search that intelligently swaps items between objectives to balance improvements in both value dimensions while ensuring feasibility. It first tries beneficial swaps between included and excluded items, then adds new items if possible, and finally removes the least valuable item if no improvements are found. The selection criterion balances both objectives and weight, while the local search prioritizes simultaneous improvements in both value dimensions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution (higher objectives, lower weight)\n    selected_idx = np.argmax([obj[0] + obj[1] - 0.1 * np.sum(weight_lst * sol) for sol, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: balance improvements in both objectives\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = archive[selected_idx][1][0]\n    current_value2 = archive[selected_idx][1][1]\n\n    # Identify items to potentially swap or reallocate\n    zero_indices = np.where(base_solution == 0)[0]\n    one_indices = np.where(base_solution == 1)[0]\n\n    # Try to improve both objectives by swapping items\n    for i in one_indices:\n        for j in zero_indices:\n            if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                delta_value1 = value1_lst[j] - value1_lst[i]\n                delta_value2 = value2_lst[j] - value2_lst[i]\n                if (delta_value1 > 0 and delta_value2 > 0) or (delta_value1 * delta_value2 > 0):\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n                    return new_solution\n\n    # If no beneficial swap, try to add a new item if possible\n    for j in zero_indices:\n        if current_weight + weight_lst[j] <= capacity:\n            new_solution[j] = 1\n            return new_solution\n\n    # If no improvement, try to remove the least valuable item\n    if len(one_indices) > 0:\n        least_value_idx = one_indices[np.argmin(value1_lst[one_indices] + value2_lst[one_indices])]\n        new_solution[least_value_idx] = 0\n        return new_solution\n\n    return new_solution\n\n",
        "score": [
            -0.4437320828583445,
            0.2243274748325348
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive based on a combination of objective values and crowding distance, then applies a three-phase local search: first reallocating items by removing low-value/high-weight items and adding high-value/low-weight items, followed by targeted flipping of high-value items, and finally adding items with the highest marginal gain while ensuring feasibility. The selection prioritizes solutions with balanced objectives and diversity, while the local search strategically improves solutions by focusing on value ratios, weight impacts, and marginal gains.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high combined objective values and low crowding distance\n    objectives = np.array([obj for (sol, obj) in archive])\n    if len(archive) > 1:\n        # Compute crowding distance\n        sorted_indices = np.argsort(objectives[:, 0])\n        crowding = np.zeros(len(archive))\n        crowding[sorted_indices[0]] = crowding[sorted_indices[-1]] = float('inf')\n        for i in range(1, len(archive) - 1):\n            crowding[sorted_indices[i]] = objectives[sorted_indices[i+1], 0] - objectives[sorted_indices[i-1], 0]\n        # Normalize and combine with objective values\n        scores = (objectives[:, 0] + objectives[:, 1]) * (1 + 1 / (1 + crowding))\n    else:\n        scores = np.array([1.0])\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Phase 1: Intelligent reallocation based on value ratios and weight impacts\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value ratios and weight impacts\n        value_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        included_ratios = value_ratios[included]\n        excluded_ratios = value_ratios[excluded]\n\n        # Find best candidate to remove and add\n        remove_candidate = included[np.argmin(included_ratios)]\n        add_candidate = excluded[np.argmax(excluded_ratios)]\n\n        if (current_weight - weight_lst[remove_candidate] + weight_lst[add_candidate]) <= capacity:\n            new_solution[remove_candidate] = 0\n            new_solution[add_candidate] = 1\n            current_weight = current_weight - weight_lst[remove_candidate] + weight_lst[add_candidate]\n\n    # Phase 2: Targeted perturbation in high-value regions\n    if len(included) > 0:\n        # Identify high-value regions\n        included_values = value1_lst[included] + value2_lst[included]\n        high_value_indices = included[np.argsort(included_values)[-max(1, len(included)//5):]]\n\n        # Flip some items in these regions\n        for idx in high_value_indices:\n            if np.random.rand() < 0.3:  # 30% chance to flip\n                if new_solution[idx] == 1 and (current_weight - weight_lst[idx]) <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n\n    # Phase 3: Feasibility-preserving mutation with marginal gain\n    if len(excluded) > 0:\n        # Calculate marginal gains\n        remaining_capacity = capacity - current_weight\n        feasible_excluded = excluded[weight_lst[excluded] <= remaining_capacity]\n        if len(feasible_excluded) > 0:\n            marginal_gains = (value1_lst[feasible_excluded] + value2_lst[feasible_excluded]) / weight_lst[feasible_excluded]\n            best_add = feasible_excluded[np.argmax(marginal_gains)]\n\n            if np.random.rand() < 0.5:  # 50% chance to add best marginal gain item\n                new_solution[best_add] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.5649989391927909,
            0.2467847466468811
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive based on high marginal contributions (value-to-weight ratios) and low crowding distance, then applies a hybrid local search combining probabilistic flips and Pareto-guided swaps to generate feasible neighbors that balance both objectives. It prioritizes items with high combined marginal values for flips and performs targeted swaps between included and excluded items that improve both objectives simultaneously. The method ensures feasibility by checking weight constraints at each operation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution with high marginal contributions and low crowding distance\n    objectives = np.array([obj for (sol, obj) in archive])\n    if len(archive) > 1:\n        # Compute crowding distance\n        sorted_indices = np.argsort(objectives[:, 0])\n        crowding = np.zeros(len(archive))\n        crowding[sorted_indices[0]] = crowding[sorted_indices[-1]] = float('inf')\n        for i in range(1, len(archive) - 1):\n            crowding[sorted_indices[i]] = objectives[sorted_indices[i+1], 0] - objectives[sorted_indices[i-1], 0]\n        normalized_crowding = (crowding - np.min(crowding)) / (np.max(crowding) - np.min(crowding) + 1e-10)\n        scores = objectives[:, 0] + objectives[:, 1] - normalized_crowding\n    else:\n        scores = np.array([1.0])\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Calculate marginal contributions (value-to-weight ratios)\n    marginal1 = value1_lst / (weight_lst + 1e-10)\n    marginal2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal1 + marginal2\n\n    # Probabilistic flip based on marginal contributions\n    flip_prob = np.zeros(len(weight_lst))\n    flip_prob[new_solution == 1] = 1 - np.exp(-combined_marginal[new_solution == 1])\n    flip_prob[new_solution == 0] = np.exp(-combined_marginal[new_solution == 0])\n    flip_indices = np.where(np.random.rand(len(weight_lst)) < flip_prob)[0]\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            if (current_weight - weight_lst[idx]) <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if (current_weight + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Pareto-guided swap: prioritize items that improve both objectives\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Sort included items by descending marginal contribution\n        included_sorted = included[np.argsort(-combined_marginal[included])]\n        # Sort excluded items by ascending marginal contribution\n        excluded_sorted = excluded[np.argsort(combined_marginal[excluded])]\n\n        for i in range(min(2, len(included_sorted), len(excluded_sorted))):\n            remove_idx = included_sorted[i]\n            add_idx = excluded_sorted[i]\n\n            if (current_weight - weight_lst[remove_idx] + weight_lst[add_idx]) <= capacity:\n                delta_value1 = value1_lst[add_idx] - value1_lst[remove_idx]\n                delta_value2 = value2_lst[add_idx] - value2_lst[remove_idx]\n\n                if (delta_value1 > 0 and delta_value2 > 0) or (delta_value1 * delta_value2 > 0):\n                    new_solution[remove_idx] = 0\n                    new_solution[add_idx] = 1\n                    current_weight = current_weight - weight_lst[remove_idx] + weight_lst[add_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9724996908482954,
            0.4105971157550812
        ]
    },
    {
        "algorithm": "The algorithm selects a high-quality solution from the archive by prioritizing both objective values and crowding distance, then generates a neighbor through a three-phase process: probabilistic flips weighted by marginal contributions, Pareto-guided swaps between included and excluded items, and adaptive perturbations to escape local optima while maintaining feasibility. The method balances exploration (via marginal contributions and random flips) with exploitation (via Pareto-guided swaps) to efficiently navigate the solution space.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high objective values and low crowding distance\n    objectives = np.array([obj for (sol, obj) in archive])\n    if len(archive) > 1:\n        # Compute crowding distance\n        sorted_indices = np.argsort(objectives[:, 0])\n        crowding = np.zeros(len(archive))\n        crowding[sorted_indices[0]] = crowding[sorted_indices[-1]] = float('inf')\n        for i in range(1, len(archive) - 1):\n            crowding[sorted_indices[i]] = objectives[sorted_indices[i+1], 0] - objectives[sorted_indices[i-1], 0]\n        # Normalize and combine with objective values\n        scores = objectives[:, 0] + objectives[:, 1] + crowding\n    else:\n        scores = np.array([1.0])\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-10)\n    marginal2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal1 + marginal2\n\n    # Phase 1: Probabilistic flip with marginal weighting\n    flip_prob = np.zeros(len(weight_lst))\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    flip_prob[included] = 1 - np.exp(-combined_marginal[included])\n    flip_prob[excluded] = np.exp(-combined_marginal[excluded]) * (weight_lst[excluded] <= remaining_capacity)\n\n    flip_mask = np.random.rand(len(weight_lst)) < flip_prob\n    for idx in np.where(flip_mask)[0]:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n            remaining_capacity += weight_lst[idx]\n        else:\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    # Phase 2: Pareto-guided swap\n    if len(included) > 0 and len(excluded) > 0:\n        # Sort included by descending marginal, excluded by ascending marginal\n        included_sorted = included[np.argsort(-combined_marginal[included])]\n        excluded_sorted = excluded[np.argsort(combined_marginal[excluded])]\n\n        for i in range(min(3, len(included_sorted), len(excluded_sorted))):\n            remove_idx = included_sorted[i]\n            add_idx = excluded_sorted[i]\n\n            if (weight_lst[add_idx] - weight_lst[remove_idx]) <= remaining_capacity:\n                new_solution[remove_idx] = 0\n                new_solution[add_idx] = 1\n                remaining_capacity += weight_lst[remove_idx] - weight_lst[add_idx]\n\n    # Phase 3: Adaptive perturbation\n    num_flips = max(1, int(0.05 * len(weight_lst)))\n    flip_indices = np.random.choice(len(weight_lst), num_flips, replace=False)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 0\n                remaining_capacity += weight_lst[idx]\n        else:\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9089812321900332,
            0.3354184925556183
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using a scoring mechanism that combines objective values and crowding distance, then applies a hybrid local search combining probabilistic flips (weighted by marginal contributions), Pareto-guided swaps, and adaptive perturbations to generate a feasible neighbor solution. It prioritizes items with high combined marginal value while ensuring weight constraints are maintained through feasibility checks. The selection process favors solutions with high combined objectives and low crowding distance, while the local search dynamically balances exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution with high combined objectives and low crowding distance\n    objectives = np.array([obj for (sol, obj) in archive])\n    if len(archive) > 1:\n        sorted_indices = np.argsort(objectives[:, 0])\n        crowding = np.zeros(len(archive))\n        crowding[sorted_indices[0]] = crowding[sorted_indices[-1]] = float('inf')\n        for i in range(1, len(archive) - 1):\n            crowding[sorted_indices[i]] = objectives[sorted_indices[i+1], 0] - objectives[sorted_indices[i-1], 0]\n        normalized_crowding = (crowding - np.min(crowding)) / (np.max(crowding) - np.min(crowding) + 1e-10)\n        scores = objectives[:, 0] + objectives[:, 1] - normalized_crowding\n    else:\n        scores = np.array([1.0])\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Calculate marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-10)\n    marginal2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal1 + marginal2\n\n    # Hybrid local search: probabilistic flips + Pareto-guided swaps\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    # Phase 1: Probabilistic flip weighted by marginal contributions\n    flip_prob = np.zeros(len(weight_lst))\n    flip_prob[included] = 1 - np.exp(-combined_marginal[included])\n    flip_prob[excluded] = np.exp(-combined_marginal[excluded]) * (weight_lst[excluded] <= (capacity - current_weight))\n    flip_mask = np.random.rand(len(weight_lst)) < flip_prob\n\n    for idx in np.where(flip_mask)[0]:\n        if new_solution[idx] == 1:\n            if (current_weight - weight_lst[idx]) <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if (current_weight + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Pareto-guided swap\n    if len(included) > 0 and len(excluded) > 0:\n        included_sorted = included[np.argsort(-combined_marginal[included])]\n        excluded_sorted = excluded[np.argsort(combined_marginal[excluded])]\n\n        for i in range(min(3, len(included_sorted), len(excluded_sorted))):\n            remove_idx = included_sorted[i]\n            add_idx = excluded_sorted[i]\n\n            if (current_weight - weight_lst[remove_idx] + weight_lst[add_idx]) <= capacity:\n                delta_value1 = value1_lst[add_idx] - value1_lst[remove_idx]\n                delta_value2 = value2_lst[add_idx] - value2_lst[remove_idx]\n\n                if (delta_value1 > 0 and delta_value2 > 0) or (delta_value1 * delta_value2 > 0):\n                    new_solution[remove_idx] = 0\n                    new_solution[add_idx] = 1\n                    current_weight = current_weight - weight_lst[remove_idx] + weight_lst[add_idx]\n\n    # Phase 3: Adaptive perturbation (small random flips)\n    num_flips = max(1, int(0.05 * len(weight_lst)))\n    flip_indices = np.random.choice(len(weight_lst), num_flips, replace=False)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            if (current_weight - weight_lst[idx]) <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if (current_weight + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9383569247378656,
            0.3933005630970001
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Calculate objective diversity and dominance\n    objectives = np.array([obj for (sol, obj) in archive])\n    dominance = np.zeros(len(archive))\n    for i in range(len(archive)):\n        dominated = 0\n        for j in range(len(archive)):\n            if i != j and objectives[j, 0] >= objectives[i, 0] and objectives[j, 1] >= objectives[i, 1]:\n                if objectives[j, 0] > objectives[i, 0] or objectives[j, 1] > objectives[i, 1]:\n                    dominated += 1\n        dominance[i] = 1 / (dominated + 1)\n\n    # Select solution with high dominance and balanced objectives\n    balanced_scores = (objectives[:, 0] + objectives[:, 1]) / (np.abs(objectives[:, 0] - objectives[:, 1]) + 1e-10)\n    scores = dominance * balanced_scores\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    # Phase 1: Probabilistic flip based on marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-10)\n    marginal2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal1 + marginal2\n\n    flip_prob = np.zeros(len(weight_lst))\n    flip_prob[new_solution == 1] = 1 - np.exp(-combined_marginal[new_solution == 1])\n    flip_prob[new_solution == 0] = np.exp(-combined_marginal[new_solution == 0]) * 0.5\n\n    flip_indices = np.where(np.random.rand(len(weight_lst)) < flip_prob)[0]\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            if (current_weight - weight_lst[idx]) <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if (current_weight + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Objective-specific swaps\n    if len(included) > 0 and len(excluded) > 0:\n        # Sort included by descending marginal contribution to the other objective\n        if np.random.rand() < 0.5:\n            # Prioritize value1\n            included_sorted = included[np.argsort(-marginal1[included])]\n            excluded_sorted = excluded[np.argsort(marginal1[excluded])]\n        else:\n            # Prioritize value2\n            included_sorted = included[np.argsort(-marginal2[included])]\n            excluded_sorted = excluded[np.argsort(marginal2[excluded])]\n\n        swap_count = min(2, len(included_sorted), len(excluded_sorted))\n        for i in range(swap_count):\n            remove_idx = included_sorted[i]\n            add_idx = excluded_sorted[i]\n            delta_weight = weight_lst[add_idx] - weight_lst[remove_idx]\n\n            if delta_weight <= remaining_capacity:\n                new_solution[remove_idx] = 0\n                new_solution[add_idx] = 1\n                remaining_capacity -= delta_weight\n\n    return new_solution\n\n",
        "score": [
            -0.9680587690752314,
            0.7631611526012421
        ]
    },
    {
        "algorithm": "The heuristic selects a random solution from the archive and applies a hybrid local search combining random item swaps (to explore the solution space) and greedy marginal-value selection (to exploit high-value items), ensuring feasibility by checking weights at each step. The algorithm prioritizes items with combined high value-to-weight ratios while maintaining the knapsack capacity constraint.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: random swaps with greedy selection\n    for _ in range(10):  # Number of iterations\n        # Randomly select two items to swap\n        item1, item2 = random.sample(range(len(weight_lst)), 2)\n\n        # Calculate new weights if we swap the items\n        new_weight = current_weight - weight_lst[item1] * new_solution[item1] + weight_lst[item1] * (1 - new_solution[item1])\n        new_weight = new_weight - weight_lst[item2] * new_solution[item2] + weight_lst[item2] * (1 - new_solution[item2])\n\n        if new_weight <= capacity:\n            # Accept the swap if feasible\n            new_solution[item1] = 1 - new_solution[item1]\n            new_solution[item2] = 1 - new_solution[item2]\n            current_weight = new_weight\n\n    # Additional greedy improvement: add items with highest marginal value\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        marginal_values = (value1_lst + value2_lst) / weight_lst\n        feasible_items = (weight_lst <= remaining_capacity) & (new_solution == 0)\n        if np.any(feasible_items):\n            best_item = np.argmax(marginal_values * feasible_items)\n            if marginal_values[best_item] > 0:\n                new_solution[best_item] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.38488836615279653,
            0.23517856001853943
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high combined objective values and low crowding distance\n    objectives = np.array([obj for (sol, obj) in archive])\n    if len(archive) > 1:\n        # Compute crowding distance\n        sorted_indices = np.argsort(objectives[:, 0])\n        crowding = np.zeros(len(archive))\n        crowding[sorted_indices[0]] = crowding[sorted_indices[-1]] = float('inf')\n        for i in range(1, len(archive) - 1):\n            crowding[sorted_indices[i]] = objectives[sorted_indices[i+1], 0] - objectives[sorted_indices[i-1], 0]\n        # Normalize and combine with objective values\n        scores = (objectives[:, 0] + objectives[:, 1]) * (1 + 1 / (1 + crowding))\n    else:\n        scores = np.array([1.0])\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Phase 1: Adaptive value-weighted perturbation\n    value_weights = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0:\n        # Remove low-value items with probability inversely proportional to their value\n        remove_probs = 1 / (1 + value_weights[included])\n        remove_probs = remove_probs / np.sum(remove_probs)\n        remove_candidate = np.random.choice(included, p=remove_probs)\n\n        if (current_weight - weight_lst[remove_candidate]) <= capacity:\n            new_solution[remove_candidate] = 0\n            current_weight -= weight_lst[remove_candidate]\n\n    # Phase 2: Marginal gain insertion with diversity consideration\n    remaining_capacity = capacity - current_weight\n    feasible_excluded = excluded[weight_lst[excluded] <= remaining_capacity]\n\n    if len(feasible_excluded) > 0:\n        # Calculate marginal gains considering both objectives\n        marginal_gains = (value1_lst[feasible_excluded] + value2_lst[feasible_excluded]) / weight_lst[feasible_excluded]\n\n        # Add items with highest marginal gains, but with probability inversely proportional to their weight\n        add_probs = marginal_gains / np.sum(marginal_gains)\n        add_candidate = np.random.choice(feasible_excluded, p=add_probs)\n\n        if np.random.rand() < 0.7:  # Higher probability to add high-marginal items\n            new_solution[add_candidate] = 1\n\n    # Phase 3: Objective-balanced flip\n    flip_candidates = np.where(new_solution == 1)[0]\n    if len(flip_candidates) > 0:\n        # Calculate objective balance for each item\n        obj_balance = np.abs((value1_lst[flip_candidates] / (np.sum(value1_lst) + 1e-6)) -\n                           (value2_lst[flip_candidates] / (np.sum(value2_lst) + 1e-6)))\n\n        # Flip items that are most imbalanced in objectives\n        flip_candidate = flip_candidates[np.argmax(obj_balance)]\n        if (current_weight - weight_lst[flip_candidate]) <= capacity:\n            new_solution[flip_candidate] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.6344350186746086,
            0.3452870547771454
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive by balancing high objective values and diversity (crowding distance), then generates a neighbor solution through a value-weighted perturbation strategy that flips items probabilistically based on their combined marginal contributions, while maintaining feasibility through adaptive capacity checks. It further refines the solution with a multi-objective guided swap operation that intelligently exchanges items between included and excluded sets to improve both objectives. The approach prioritizes items with higher value-to-weight ratios and ensures the neighbor solution remains feasible by carefully adjusting the knapsack capacity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high objective values and moderate crowding distance\n    objectives = np.array([obj for (sol, obj) in archive])\n    if len(archive) > 1:\n        # Compute crowding distance\n        sorted_indices = np.argsort(objectives[:, 0])\n        crowding = np.zeros(len(archive))\n        crowding[sorted_indices[0]] = crowding[sorted_indices[-1]] = float('inf')\n        for i in range(1, len(archive) - 1):\n            crowding[sorted_indices[i]] = objectives[sorted_indices[i+1], 0] - objectives[sorted_indices[i-1], 0]\n        # Normalize crowding and combine with objective values\n        normalized_crowding = (crowding - np.min(crowding)) / (np.max(crowding) - np.min(crowding) + 1e-10)\n        scores = objectives[:, 0] + objectives[:, 1] - normalized_crowding\n    else:\n        scores = np.array([1.0])\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Value-weighted perturbation strategy\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Calculate marginal contributions (value-to-weight ratios)\n    marginal1 = value1_lst / (weight_lst + 1e-10)\n    marginal2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal1 + marginal2\n\n    # Select items to flip based on marginal contribution and current inclusion\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    # Probabilistic flip based on marginal contribution\n    flip_prob = np.zeros(len(weight_lst))\n    flip_prob[included] = 1 - np.exp(-combined_marginal[included])\n    flip_prob[excluded] = np.exp(-combined_marginal[excluded])\n    flip_indices = np.where(np.random.rand(len(weight_lst)) < flip_prob)[0]\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            if (current_weight - weight_lst[idx]) <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if (current_weight + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Multi-objective guided swap\n    if len(included) > 0 and len(excluded) > 0:\n        # Sort included items by combined marginal contribution (descending)\n        included_sorted = included[np.argsort(-combined_marginal[included])]\n        # Sort excluded items by combined marginal contribution (ascending)\n        excluded_sorted = excluded[np.argsort(combined_marginal[excluded])]\n\n        for i in range(min(2, len(included_sorted), len(excluded_sorted))):\n            remove_idx = included_sorted[i]\n            add_idx = excluded_sorted[i]\n\n            if (current_weight - weight_lst[remove_idx] + weight_lst[add_idx]) <= capacity:\n                new_solution[remove_idx] = 0\n                new_solution[add_idx] = 1\n                current_weight = current_weight - weight_lst[remove_idx] + weight_lst[add_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9310224274226554,
            0.39585617184638977
        ]
    }
]