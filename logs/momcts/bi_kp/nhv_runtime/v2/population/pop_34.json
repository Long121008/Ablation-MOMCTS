[
    {
        "algorithm": "The algorithm intelligently selects a solution from the archive by prioritizing high-objective-value solutions with low crowding distance, then applies a hybrid local search combining random item swaps and adaptive perturbations to explore neighbors while ensuring feasibility. It prioritizes solutions with better combined objective values and diversity (crowding distance) to guide selection, and uses a mix of item swaps and random flips to generate neighbors, with feasibility checks at each step.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high objective values and low crowding distance\n    objectives = np.array([obj for (sol, obj) in archive])\n    if len(archive) > 1:\n        # Compute crowding distance\n        sorted_indices = np.argsort(objectives[:, 0])\n        crowding = np.zeros(len(archive))\n        crowding[sorted_indices[0]] = crowding[sorted_indices[-1]] = float('inf')\n        for i in range(1, len(archive) - 1):\n            crowding[sorted_indices[i]] = objectives[sorted_indices[i+1], 0] - objectives[sorted_indices[i-1], 0]\n        # Normalize and combine with objective values\n        scores = objectives[:, 0] + objectives[:, 1] + crowding\n    else:\n        scores = np.array([1.0])\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search: item swapping and adaptive perturbation\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Swap items between included and excluded with feasibility check\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Select a random item to remove\n        remove_idx = np.random.choice(included)\n        # Select a random item to add\n        add_idx = np.random.choice(excluded)\n\n        # Check feasibility\n        if (current_weight - weight_lst[remove_idx] + weight_lst[add_idx]) <= capacity:\n            new_solution[remove_idx] = 0\n            new_solution[add_idx] = 1\n\n    # Adaptive perturbation: randomly flip a small number of items\n    num_flips = max(1, int(0.1 * len(weight_lst)))\n    flip_indices = np.random.choice(len(weight_lst), num_flips, replace=False)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            if (current_weight - weight_lst[idx]) <= capacity:\n                new_solution[idx] = 0\n        else:\n            if (current_weight + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.7589912329452198,
            0.27401870489120483
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with higher combined objective values and lower weights, then applies a hybrid local search that intelligently swaps items between objectives to balance improvements in both value dimensions while ensuring feasibility. It first tries beneficial swaps between included and excluded items, then adds new items if possible, and finally removes the least valuable item if no improvements are found. The selection criterion balances both objectives and weight, while the local search prioritizes simultaneous improvements in both value dimensions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution (higher objectives, lower weight)\n    selected_idx = np.argmax([obj[0] + obj[1] - 0.1 * np.sum(weight_lst * sol) for sol, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: balance improvements in both objectives\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = archive[selected_idx][1][0]\n    current_value2 = archive[selected_idx][1][1]\n\n    # Identify items to potentially swap or reallocate\n    zero_indices = np.where(base_solution == 0)[0]\n    one_indices = np.where(base_solution == 1)[0]\n\n    # Try to improve both objectives by swapping items\n    for i in one_indices:\n        for j in zero_indices:\n            if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                delta_value1 = value1_lst[j] - value1_lst[i]\n                delta_value2 = value2_lst[j] - value2_lst[i]\n                if (delta_value1 > 0 and delta_value2 > 0) or (delta_value1 * delta_value2 > 0):\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n                    return new_solution\n\n    # If no beneficial swap, try to add a new item if possible\n    for j in zero_indices:\n        if current_weight + weight_lst[j] <= capacity:\n            new_solution[j] = 1\n            return new_solution\n\n    # If no improvement, try to remove the least valuable item\n    if len(one_indices) > 0:\n        least_value_idx = one_indices[np.argmin(value1_lst[one_indices] + value2_lst[one_indices])]\n        new_solution[least_value_idx] = 0\n        return new_solution\n\n    return new_solution\n\n",
        "score": [
            -0.4437320828583445,
            0.2243274748325348
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive based on a combination of objective values and crowding distance, then applies a three-phase local search: first reallocating items by removing low-value/high-weight items and adding high-value/low-weight items, followed by targeted flipping of high-value items, and finally adding items with the highest marginal gain while ensuring feasibility. The selection prioritizes solutions with balanced objectives and diversity, while the local search strategically improves solutions by focusing on value ratios, weight impacts, and marginal gains.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high combined objective values and low crowding distance\n    objectives = np.array([obj for (sol, obj) in archive])\n    if len(archive) > 1:\n        # Compute crowding distance\n        sorted_indices = np.argsort(objectives[:, 0])\n        crowding = np.zeros(len(archive))\n        crowding[sorted_indices[0]] = crowding[sorted_indices[-1]] = float('inf')\n        for i in range(1, len(archive) - 1):\n            crowding[sorted_indices[i]] = objectives[sorted_indices[i+1], 0] - objectives[sorted_indices[i-1], 0]\n        # Normalize and combine with objective values\n        scores = (objectives[:, 0] + objectives[:, 1]) * (1 + 1 / (1 + crowding))\n    else:\n        scores = np.array([1.0])\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Phase 1: Intelligent reallocation based on value ratios and weight impacts\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Calculate value ratios and weight impacts\n        value_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        included_ratios = value_ratios[included]\n        excluded_ratios = value_ratios[excluded]\n\n        # Find best candidate to remove and add\n        remove_candidate = included[np.argmin(included_ratios)]\n        add_candidate = excluded[np.argmax(excluded_ratios)]\n\n        if (current_weight - weight_lst[remove_candidate] + weight_lst[add_candidate]) <= capacity:\n            new_solution[remove_candidate] = 0\n            new_solution[add_candidate] = 1\n            current_weight = current_weight - weight_lst[remove_candidate] + weight_lst[add_candidate]\n\n    # Phase 2: Targeted perturbation in high-value regions\n    if len(included) > 0:\n        # Identify high-value regions\n        included_values = value1_lst[included] + value2_lst[included]\n        high_value_indices = included[np.argsort(included_values)[-max(1, len(included)//5):]]\n\n        # Flip some items in these regions\n        for idx in high_value_indices:\n            if np.random.rand() < 0.3:  # 30% chance to flip\n                if new_solution[idx] == 1 and (current_weight - weight_lst[idx]) <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n\n    # Phase 3: Feasibility-preserving mutation with marginal gain\n    if len(excluded) > 0:\n        # Calculate marginal gains\n        remaining_capacity = capacity - current_weight\n        feasible_excluded = excluded[weight_lst[excluded] <= remaining_capacity]\n        if len(feasible_excluded) > 0:\n            marginal_gains = (value1_lst[feasible_excluded] + value2_lst[feasible_excluded]) / weight_lst[feasible_excluded]\n            best_add = feasible_excluded[np.argmax(marginal_gains)]\n\n            if np.random.rand() < 0.5:  # 50% chance to add best marginal gain item\n                new_solution[best_add] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.5649989391927909,
            0.2467847466468811
        ]
    },
    {
        "algorithm": "The algorithm selects a high-quality solution from the archive by prioritizing both objective values and crowding distance, then generates a neighbor through a three-phase process: probabilistic flips weighted by marginal contributions, Pareto-guided swaps between included and excluded items, and adaptive perturbations to escape local optima while maintaining feasibility. The method balances exploration (via marginal contributions and random flips) with exploitation (via Pareto-guided swaps) to efficiently navigate the solution space.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high objective values and low crowding distance\n    objectives = np.array([obj for (sol, obj) in archive])\n    if len(archive) > 1:\n        # Compute crowding distance\n        sorted_indices = np.argsort(objectives[:, 0])\n        crowding = np.zeros(len(archive))\n        crowding[sorted_indices[0]] = crowding[sorted_indices[-1]] = float('inf')\n        for i in range(1, len(archive) - 1):\n            crowding[sorted_indices[i]] = objectives[sorted_indices[i+1], 0] - objectives[sorted_indices[i-1], 0]\n        # Normalize and combine with objective values\n        scores = objectives[:, 0] + objectives[:, 1] + crowding\n    else:\n        scores = np.array([1.0])\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-10)\n    marginal2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal1 + marginal2\n\n    # Phase 1: Probabilistic flip with marginal weighting\n    flip_prob = np.zeros(len(weight_lst))\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    flip_prob[included] = 1 - np.exp(-combined_marginal[included])\n    flip_prob[excluded] = np.exp(-combined_marginal[excluded]) * (weight_lst[excluded] <= remaining_capacity)\n\n    flip_mask = np.random.rand(len(weight_lst)) < flip_prob\n    for idx in np.where(flip_mask)[0]:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n            remaining_capacity += weight_lst[idx]\n        else:\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    # Phase 2: Pareto-guided swap\n    if len(included) > 0 and len(excluded) > 0:\n        # Sort included by descending marginal, excluded by ascending marginal\n        included_sorted = included[np.argsort(-combined_marginal[included])]\n        excluded_sorted = excluded[np.argsort(combined_marginal[excluded])]\n\n        for i in range(min(3, len(included_sorted), len(excluded_sorted))):\n            remove_idx = included_sorted[i]\n            add_idx = excluded_sorted[i]\n\n            if (weight_lst[add_idx] - weight_lst[remove_idx]) <= remaining_capacity:\n                new_solution[remove_idx] = 0\n                new_solution[add_idx] = 1\n                remaining_capacity += weight_lst[remove_idx] - weight_lst[add_idx]\n\n    # Phase 3: Adaptive perturbation\n    num_flips = max(1, int(0.05 * len(weight_lst)))\n    flip_indices = np.random.choice(len(weight_lst), num_flips, replace=False)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 0\n                remaining_capacity += weight_lst[idx]\n        else:\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9089812321900332,
            0.3354184925556183
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution with high combined objectives and low crowding distance\n    objectives = np.array([obj for (sol, obj) in archive])\n    if len(archive) > 1:\n        sorted_indices = np.argsort(objectives[:, 0])\n        crowding = np.zeros(len(archive))\n        crowding[sorted_indices[0]] = crowding[sorted_indices[-1]] = float('inf')\n        for i in range(1, len(archive) - 1):\n            crowding[sorted_indices[i]] = objectives[sorted_indices[i+1], 0] - objectives[sorted_indices[i-1], 0]\n        normalized_crowding = (crowding - np.min(crowding)) / (np.max(crowding) - np.min(crowding) + 1e-10)\n        scores = objectives[:, 0] + objectives[:, 1] - normalized_crowding\n    else:\n        scores = np.array([1.0])\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Calculate marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-10)\n    marginal2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal1 + marginal2\n\n    # Novel local search: Dynamic Value-Weight Ratio Guided Perturbation\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    # Phase 1: Dynamic Value-Weight Ratio Guided Perturbation\n    perturbation_prob = np.zeros(len(weight_lst))\n    perturbation_prob[included] = 1 - np.tanh(combined_marginal[included] * 0.1)\n    perturbation_prob[excluded] = np.tanh(combined_marginal[excluded] * 0.1) * (weight_lst[excluded] <= (capacity - current_weight))\n\n    for idx in np.where(np.random.rand(len(weight_lst)) < perturbation_prob)[0]:\n        if new_solution[idx] == 1:\n            if (current_weight - weight_lst[idx]) <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if (current_weight + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Adaptive Objective-Specific Swaps\n    if len(included) > 0 and len(excluded) > 0:\n        # Sort included items by combined marginal contribution (descending)\n        included_sorted = included[np.argsort(-combined_marginal[included])]\n        # Sort excluded items by combined marginal contribution (ascending)\n        excluded_sorted = excluded[np.argsort(combined_marginal[excluded])]\n\n        for i in range(min(2, len(included_sorted), len(excluded_sorted))):\n            remove_idx = included_sorted[i]\n            add_idx = excluded_sorted[i]\n\n            if (current_weight - weight_lst[remove_idx] + weight_lst[add_idx]) <= capacity:\n                # Adaptive objective-specific swap\n                if np.random.rand() < 0.5:  # Focus on value1\n                    if value1_lst[add_idx] > value1_lst[remove_idx]:\n                        new_solution[remove_idx] = 0\n                        new_solution[add_idx] = 1\n                        current_weight = current_weight - weight_lst[remove_idx] + weight_lst[add_idx]\n                else:  # Focus on value2\n                    if value2_lst[add_idx] > value2_lst[remove_idx]:\n                        new_solution[remove_idx] = 0\n                        new_solution[add_idx] = 1\n                        current_weight = current_weight - weight_lst[remove_idx] + weight_lst[add_idx]\n\n    # Phase 3: Lightweight Feasibility Repair\n    while np.sum(weight_lst[new_solution == 1]) > capacity:\n        excess = np.sum(weight_lst[new_solution == 1]) - capacity\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) == 0:\n            break\n        remove_idx = candidates[np.argmin(weight_lst[candidates] / (value1_lst[candidates] + value2_lst[candidates] + 1e-10))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9563318975643356,
            0.34690505266189575
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution with high combined objectives and low crowding distance\n    objectives = np.array([obj for (sol, obj) in archive])\n    if len(archive) > 1:\n        # Compute crowding distance\n        sorted_indices = np.argsort(objectives[:, 0])\n        crowding = np.zeros(len(archive))\n        crowding[sorted_indices[0]] = crowding[sorted_indices[-1]] = float('inf')\n        for i in range(1, len(archive) - 1):\n            crowding[sorted_indices[i]] = objectives[sorted_indices[i+1], 0] - objectives[sorted_indices[i-1], 0]\n        normalized_crowding = (crowding - np.min(crowding)) / (np.max(crowding) - np.min(crowding) + 1e-10)\n        scores = objectives[:, 0] + objectives[:, 1] - normalized_crowding\n    else:\n        scores = np.array([1.0])\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-10)\n    marginal2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal1 + marginal2\n\n    # Novel Adaptive Multi-Objective Perturbation with Dynamic Thresholds\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    # Phase 1: Dynamic Value-Weight Ratio Guided Perturbation\n    perturbation_prob = np.zeros(len(weight_lst))\n    perturbation_prob[included] = 1 - np.tanh(combined_marginal[included] * 0.1)\n    perturbation_prob[excluded] = np.tanh(combined_marginal[excluded] * 0.1) * (weight_lst[excluded] <= (capacity - np.sum(weight_lst[new_solution == 1])))\n\n    for idx in np.where(np.random.rand(len(weight_lst)) < perturbation_prob)[0]:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            if np.sum(weight_lst[new_solution == 1]) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 2: Objective-Specific Swaps with Adaptive Threshold\n    if len(included) > 0 and len(excluded) > 0:\n        # Sort included items by combined marginal contribution (descending)\n        included_sorted = included[np.argsort(-combined_marginal[included])]\n        # Sort excluded items by combined marginal contribution (ascending)\n        excluded_sorted = excluded[np.argsort(combined_marginal[excluded])]\n\n        # Adaptive threshold for swaps based on solution quality\n        swap_threshold = 0.3 if (objectives[selected_idx][0] + objectives[selected_idx][1]) > np.mean(objectives.sum(axis=1)) else 0.5\n\n        for i in range(min(3, len(included_sorted), len(excluded_sorted))):\n            remove_idx = included_sorted[i]\n            add_idx = excluded_sorted[i]\n\n            if np.sum(weight_lst[new_solution == 1]) - weight_lst[remove_idx] + weight_lst[add_idx] <= capacity:\n                # Objective-specific swap with adaptive threshold\n                if np.random.rand() < swap_threshold:  # Focus on value1\n                    if value1_lst[add_idx] > value1_lst[remove_idx]:\n                        new_solution[remove_idx] = 0\n                        new_solution[add_idx] = 1\n                else:  # Focus on value2\n                    if value2_lst[add_idx] > value2_lst[remove_idx]:\n                        new_solution[remove_idx] = 0\n                        new_solution[add_idx] = 1\n\n    # Phase 3: Lightweight Feasibility Repair\n    while np.sum(weight_lst[new_solution == 1]) > capacity:\n        excess = np.sum(weight_lst[new_solution == 1]) - capacity\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) == 0:\n            break\n        remove_idx = candidates[np.argmin(weight_lst[candidates] / (value1_lst[candidates] + value2_lst[candidates] + 1e-10))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9789034311187153,
            0.3725893795490265
        ]
    },
    {
        "algorithm": "The heuristic selects a random solution from the archive and applies a hybrid local search combining random item swaps (to explore the solution space) and greedy marginal-value selection (to exploit high-value items), ensuring feasibility by checking weights at each step. The algorithm prioritizes items with combined high value-to-weight ratios while maintaining the knapsack capacity constraint.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: random swaps with greedy selection\n    for _ in range(10):  # Number of iterations\n        # Randomly select two items to swap\n        item1, item2 = random.sample(range(len(weight_lst)), 2)\n\n        # Calculate new weights if we swap the items\n        new_weight = current_weight - weight_lst[item1] * new_solution[item1] + weight_lst[item1] * (1 - new_solution[item1])\n        new_weight = new_weight - weight_lst[item2] * new_solution[item2] + weight_lst[item2] * (1 - new_solution[item2])\n\n        if new_weight <= capacity:\n            # Accept the swap if feasible\n            new_solution[item1] = 1 - new_solution[item1]\n            new_solution[item2] = 1 - new_solution[item2]\n            current_weight = new_weight\n\n    # Additional greedy improvement: add items with highest marginal value\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        marginal_values = (value1_lst + value2_lst) / weight_lst\n        feasible_items = (weight_lst <= remaining_capacity) & (new_solution == 0)\n        if np.any(feasible_items):\n            best_item = np.argmax(marginal_values * feasible_items)\n            if marginal_values[best_item] > 0:\n                new_solution[best_item] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.38488836615279653,
            0.23517856001853943
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive based on high marginal contributions (value-to-weight ratios) and low crowding distance, then applies a hybrid local search combining probabilistic flips and Pareto-guided swaps to generate feasible neighbors that balance both objectives. It prioritizes items with high combined marginal values for flips and performs targeted swaps between included and excluded items that improve both objectives simultaneously. The method ensures feasibility by checking weight constraints at each operation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution with high marginal contributions and low crowding distance\n    objectives = np.array([obj for (sol, obj) in archive])\n    if len(archive) > 1:\n        # Compute crowding distance\n        sorted_indices = np.argsort(objectives[:, 0])\n        crowding = np.zeros(len(archive))\n        crowding[sorted_indices[0]] = crowding[sorted_indices[-1]] = float('inf')\n        for i in range(1, len(archive) - 1):\n            crowding[sorted_indices[i]] = objectives[sorted_indices[i+1], 0] - objectives[sorted_indices[i-1], 0]\n        normalized_crowding = (crowding - np.min(crowding)) / (np.max(crowding) - np.min(crowding) + 1e-10)\n        scores = objectives[:, 0] + objectives[:, 1] - normalized_crowding\n    else:\n        scores = np.array([1.0])\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Calculate marginal contributions (value-to-weight ratios)\n    marginal1 = value1_lst / (weight_lst + 1e-10)\n    marginal2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal1 + marginal2\n\n    # Probabilistic flip based on marginal contributions\n    flip_prob = np.zeros(len(weight_lst))\n    flip_prob[new_solution == 1] = 1 - np.exp(-combined_marginal[new_solution == 1])\n    flip_prob[new_solution == 0] = np.exp(-combined_marginal[new_solution == 0])\n    flip_indices = np.where(np.random.rand(len(weight_lst)) < flip_prob)[0]\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            if (current_weight - weight_lst[idx]) <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if (current_weight + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Pareto-guided swap: prioritize items that improve both objectives\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Sort included items by descending marginal contribution\n        included_sorted = included[np.argsort(-combined_marginal[included])]\n        # Sort excluded items by ascending marginal contribution\n        excluded_sorted = excluded[np.argsort(combined_marginal[excluded])]\n\n        for i in range(min(2, len(included_sorted), len(excluded_sorted))):\n            remove_idx = included_sorted[i]\n            add_idx = excluded_sorted[i]\n\n            if (current_weight - weight_lst[remove_idx] + weight_lst[add_idx]) <= capacity:\n                delta_value1 = value1_lst[add_idx] - value1_lst[remove_idx]\n                delta_value2 = value2_lst[add_idx] - value2_lst[remove_idx]\n\n                if (delta_value1 > 0 and delta_value2 > 0) or (delta_value1 * delta_value2 > 0):\n                    new_solution[remove_idx] = 0\n                    new_solution[add_idx] = 1\n                    current_weight = current_weight - weight_lst[remove_idx] + weight_lst[add_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9724996908482954,
            0.4105971157550812
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution with highest combined objective values and lowest weight\n    selected_idx = np.argmax([obj[0] + obj[1] - 0.1 * np.sum(weight_lst * sol) for sol, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = archive[selected_idx][1][0]\n    current_value2 = archive[selected_idx][1][1]\n\n    # Identify items to potentially swap or reallocate\n    zero_indices = np.where(base_solution == 0)[0]\n    one_indices = np.where(base_solution == 1)[0]\n\n    # Try to improve both objectives by swapping items\n    for i in one_indices:\n        for j in zero_indices:\n            if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                delta_value1 = value1_lst[j] - value1_lst[i]\n                delta_value2 = value2_lst[j] - value2_lst[i]\n                if (delta_value1 > 0 and delta_value2 > 0) or (delta_value1 * delta_value2 > 0):\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n                    return new_solution\n\n    # If no beneficial swap, try to add a new item if possible\n    for j in zero_indices:\n        if current_weight + weight_lst[j] <= capacity:\n            new_solution[j] = 1\n            return new_solution\n\n    # If no improvement, try to remove the least valuable item\n    if len(one_indices) > 0:\n        least_value_idx = one_indices[np.argmin(value1_lst[one_indices] + value2_lst[one_indices])]\n        new_solution[least_value_idx] = 0\n        return new_solution\n\n    return new_solution\n\n",
        "score": [
            -0.6244680989927601,
            0.2740948498249054
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution with high combined objectives and low crowding distance\n    objectives = np.array([obj for (sol, obj) in archive])\n    if len(archive) > 1:\n        sorted_indices = np.argsort(objectives[:, 0])\n        crowding = np.zeros(len(archive))\n        crowding[sorted_indices[0]] = crowding[sorted_indices[-1]] = float('inf')\n        for i in range(1, len(archive) - 1):\n            crowding[sorted_indices[i]] = objectives[sorted_indices[i+1], 0] - objectives[sorted_indices[i-1], 0]\n        scores = objectives[:, 0] + objectives[:, 1] - crowding\n    else:\n        scores = np.array([1.0])\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Calculate marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-10)\n    marginal2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal1 + marginal2\n\n    # Phase 1: Dynamic Value-Weight Ratio Guided Perturbation\n    perturbation_prob = np.zeros(len(weight_lst))\n    perturbation_prob[new_solution == 1] = 1 - np.tanh(combined_marginal[new_solution == 1] * 0.1)\n    perturbation_prob[new_solution == 0] = np.tanh(combined_marginal[new_solution == 0] * 0.1) * (weight_lst[new_solution == 0] <= (capacity - current_weight))\n\n    for idx in np.where(np.random.rand(len(weight_lst)) < perturbation_prob)[0]:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Adaptive Objective-Specific Swaps\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        # Sort included items by combined marginal contribution (descending)\n        included_sorted = included[np.argsort(-combined_marginal[included])]\n        # Sort excluded items by combined marginal contribution (ascending)\n        excluded_sorted = excluded[np.argsort(combined_marginal[excluded])]\n\n        for i in range(min(3, len(included_sorted), len(excluded_sorted))):\n            remove_idx = included_sorted[i]\n            add_idx = excluded_sorted[i]\n\n            if current_weight - weight_lst[remove_idx] + weight_lst[add_idx] <= capacity:\n                if np.random.rand() < 0.5:  # Focus on value1\n                    if value1_lst[add_idx] > value1_lst[remove_idx]:\n                        new_solution[remove_idx] = 0\n                        new_solution[add_idx] = 1\n                        current_weight = current_weight - weight_lst[remove_idx] + weight_lst[add_idx]\n                else:  # Focus on value2\n                    if value2_lst[add_idx] > value2_lst[remove_idx]:\n                        new_solution[remove_idx] = 0\n                        new_solution[add_idx] = 1\n                        current_weight = current_weight - weight_lst[remove_idx] + weight_lst[add_idx]\n\n    # Phase 3: Lightweight Feasibility Repair\n    while np.sum(weight_lst[new_solution == 1]) > capacity:\n        excess = np.sum(weight_lst[new_solution == 1]) - capacity\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) == 0:\n            break\n        remove_idx = candidates[np.argmin(weight_lst[candidates] / (value1_lst[candidates] + value2_lst[candidates] + 1e-10))]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.7823628310212614,
            0.340983510017395
        ]
    }
]