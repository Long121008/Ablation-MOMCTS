[
    {
        "algorithm": "The algorithm selects a random solution from the archive, identifies critical items based on combined value-to-weight ratios, and applies a hybrid local search by toggling these items while ensuring feasibility. It also randomly flips non-critical items to escape local optima. The method prioritizes high-value items while maintaining solution feasibility through weight checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_idx = np.random.choice(len(archive))\n    selected_solution, _ = archive[selected_idx]\n    current_solution = selected_solution.copy()\n\n    # Step 2: Identify critical items (those with high value-to-weight ratios)\n    value_to_weight1 = value1_lst / weight_lst\n    value_to_weight2 = value2_lst / weight_lst\n    combined_value_to_weight = value_to_weight1 + value_to_weight2\n    critical_items = np.argsort(combined_value_to_weight)[-min(5, len(weight_lst)):]  # Top 5 items\n\n    # Step 3: Apply a hybrid local search strategy\n    # Flip critical items (if not already in the solution) or remove low-value items\n    new_solution = current_solution.copy()\n    for item in critical_items:\n        if current_solution[item] == 0:\n            # Try adding the item if it fits\n            if (np.sum(weight_lst * new_solution) + weight_lst[item]) <= capacity:\n                new_solution[item] = 1\n        else:\n            # Try removing the item\n            new_solution[item] = 0\n            if np.sum(weight_lst * new_solution) <= capacity:\n                pass  # Keep the change\n            else:\n                new_solution[item] = 1  # Revert if infeasible\n\n    # Step 4: Randomly flip a small number of non-critical items to escape local optima\n    non_critical_items = np.setdiff1d(np.arange(len(weight_lst)), critical_items)\n    if len(non_critical_items) > 0:\n        flip_indices = np.random.choice(non_critical_items, size=min(2, len(non_critical_items)), replace=False)\n        for idx in flip_indices:\n            new_solution[idx] = 1 - new_solution[idx]\n            # Ensure feasibility\n            if np.sum(weight_lst * new_solution) > capacity:\n                new_solution[idx] = 1 - new_solution[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8266459948173828,
            0.3179592788219452
        ]
    },
    {
        "algorithm": "The algorithm combines adaptive solution selection (prioritizing diverse and younger solutions) with a hybrid perturbation strategy that dynamically adjusts critical item flips and guided random swaps, while ensuring feasibility through lightweight repair. It balances exploration and exploitation by increasing perturbation intensity with search progress, focusing on high-value items while maintaining knapsack capacity constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive selection: prioritize solutions with high diversity and younger age\n    current_time = len(archive)  # Simulate age by archive position\n    selected_idx = 0\n    max_score = -1\n    for i, (sol, obj) in enumerate(archive):\n        diversity = abs(obj[0] - obj[1])\n        age = current_time - i\n        score = (diversity + 1) / (age + 1)  # Prefer diverse and younger solutions\n        if score > max_score:\n            max_score = score\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Dynamic perturbation intensity based on search progress\n    perturbation_intensity = min(0.3 + (len(archive) / 1000), 1.0)  # Increase with archive size\n\n    # Hybrid perturbation: critical flips + guided random swaps\n    n_items = len(weight_lst)\n    critical_items = np.argsort(-(value1_lst + value2_lst))[:max(2, int(n_items * 0.1))]  # Top 10% most valuable items\n\n    for _ in range(2):  # Perform 2 perturbation iterations\n        # Critical flips with higher probability\n        if np.random.rand() < perturbation_intensity:\n            for item in critical_items:\n                if np.random.rand() < 0.5:  # 50% chance to flip each critical item\n                    temp_solution = new_solution.copy()\n                    temp_solution[item] = 1 - temp_solution[item]\n                    if np.sum(temp_solution * weight_lst) <= capacity:\n                        new_solution = temp_solution\n\n        # Guided random swaps\n        if np.random.rand() < 0.5 * perturbation_intensity:\n            i, j = np.random.choice(n_items, size=2, replace=False)\n            temp_solution = new_solution.copy()\n            temp_solution[i], temp_solution[j] = temp_solution[j], temp_solution[i]\n            if np.sum(temp_solution * weight_lst) <= capacity:\n                new_solution = temp_solution\n\n    # Lightweight repair if solution is infeasible\n    if np.sum(new_solution * weight_lst) > capacity:\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(removable_items)\n        for item in removable_items:\n            if excess <= 0:\n                break\n            temp_solution = new_solution.copy()\n            temp_solution[item] = 0\n            excess -= weight_lst[item]\n            if excess >= 0:\n                new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -0.663515986230289,
            0.30924123525619507
        ]
    },
    {
        "algorithm": "The algorithm selects the most promising solution from the archive (prioritizing high combined normalized objective value), applies a random swap mutation, and then performs a weighted greedy local search to add/remove items, favoring objective 1 (60%) over objective 2 (40%) while ensuring feasibility. The weighted approach balances improvements across objectives, and the random shuffling ensures exploration. The structure combines mutation and greedy search to efficiently explore the neighborhood of the selected solution.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    max_score = -1\n    selected_idx = 0\n    for i, (sol, (v1, v2)) in enumerate(archive):\n        score = (v1 + v2) / (np.sum(weight_lst * sol) + 1e-6)  # Normalized by weight\n        if score > max_score:\n            max_score = score\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Step 1: Randomly swap two items (swap mutation)\n    if n_items >= 2:\n        swap_indices = np.random.choice(n_items, 2, replace=False)\n        new_solution[swap_indices[0]], new_solution[swap_indices[1]] = new_solution[swap_indices[1]], new_solution[swap_indices[0]]\n\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 2: Greedy addition based on weighted objective improvement\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n\n    for item in remaining_items:\n        if current_weight + weight_lst[item] <= capacity:\n            # Calculate weighted objective improvement\n            weight_improvement = 0.6 * value1_lst[item] + 0.4 * value2_lst[item]\n            new_solution[item] = 1\n            current_weight += weight_lst[item]\n\n    # Step 3: Greedy removal based on weighted objective improvement\n    included_items = np.where(new_solution == 1)[0]\n    np.random.shuffle(included_items)\n\n    for item in included_items:\n        # Calculate weighted objective loss\n        weight_loss = 0.6 * value1_lst[item] + 0.4 * value2_lst[item]\n        new_solution[item] = 0\n        current_weight -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.9780105623667606,
            0.5062039494514465
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using adaptive normalization (prioritizing solutions with high unexplored potential) and applies a hybrid local search combining critical-item flips (top 10% value-to-weight) with guided random swaps (biased toward high-value items), while ensuring feasibility through incremental weight checks and repair mechanisms. The method prioritizes items with the highest combined value-to-weight ratios, flips their inclusion status, and performs targeted swaps to improve both objectives while maintaining capacity constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive selection: prioritize solutions with unexplored neighborhoods\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    diversity_scores = np.std(objectives, axis=0)  # Higher diversity suggests unexplored regions\n    weighted_scores = normalized_obj * diversity_scores\n    selected_idx = np.argmax(weighted_scores.sum(axis=1))\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate combined value-to-weight ratios\n    combined_ratios = (value1_lst + value2_lst) / weight_lst\n    critical_items = np.argsort(combined_ratios)[-max(1, len(weight_lst) // 10):]  # Top 10% items\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid perturbation\n    # 1. Flip critical items (add if not present, remove if present)\n    for item in critical_items:\n        if new_solution[item] == 0:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n        else:\n            new_solution[item] = 0\n            current_weight -= weight_lst[item]\n\n    # 2. Guided random swaps (bias toward high-value items)\n    non_critical_items = np.setdiff1d(np.arange(len(weight_lst)), critical_items)\n    if len(non_critical_items) > 0:\n        # Select a candidate to swap out (lowest value-to-weight ratio in current solution)\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) > 0:\n            in_ratios = combined_ratios[in_items]\n            swap_out = in_items[np.argmin(in_ratios)]\n\n            # Select a candidate to swap in (highest value-to-weight ratio not in solution)\n            out_items = np.where(new_solution == 0)[0]\n            if len(out_items) > 0:\n                out_ratios = combined_ratios[out_items]\n                swap_in = out_items[np.argmax(out_ratios)]\n\n                # Check if swap is feasible\n                potential_weight = current_weight - weight_lst[swap_out] + weight_lst[swap_in]\n                if potential_weight <= capacity:\n                    new_solution[swap_out] = 0\n                    new_solution[swap_in] = 1\n\n    # Ensure feasibility (repair if needed)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess_items = np.where(new_solution == 1)[0]\n        excess_ratios = combined_ratios[excess_items]\n        # Remove items with lowest value-to-weight ratio until feasible\n        while current_weight > capacity and len(excess_items) > 0:\n            remove_idx = excess_items[np.argmin(excess_ratios)]\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n            excess_items = np.where(new_solution == 1)[0]\n            excess_ratios = combined_ratios[excess_items]\n\n    return new_solution\n\n",
        "score": [
            -0.7557951720924632,
            0.38932788372039795
        ]
    },
    {
        "algorithm": "The algorithm employs an adaptive hybrid local search that prioritizes solutions with high crowding distance and younger age, then applies dynamic perturbations\u2014focusing on critical items (top 5% value-to-weight ratio) with targeted flips and guided swaps among high-value items\u2014while ensuring feasibility through incremental checks and repair. Perturbation intensity scales with archive size, balancing exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Adaptive selection using crowding distance and age\n    crowding_distances = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        if i == 0 or i == len(archive)-1:\n            crowding_distances[i] = float('inf')\n        else:\n            left_obj = archive[i-1][1]\n            right_obj = archive[i+1][1]\n            crowding_distances[i] = abs(obj[0] - left_obj[0]) + abs(obj[1] - left_obj[1]) + abs(obj[0] - right_obj[0]) + abs(obj[1] - right_obj[1])\n\n    ages = np.arange(len(archive))[::-1]  # Newer solutions have lower age\n    selection_scores = crowding_distances + (1 / (ages + 1))  # Prefer diverse and younger solutions\n    selected_idx = np.argmax(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Dynamic perturbation intensity based on search progress\n    perturbation_intensity = min(0.2 + (len(archive) / 2000), 0.8)  # Increase with archive size\n\n    # Step 3: Identify critical items (top 5% value-to-weight ratio)\n    combined_value_to_weight = (value1_lst + value2_lst) / weight_lst\n    critical_items = np.argsort(-combined_value_to_weight)[:max(1, int(len(weight_lst) * 0.05))]\n\n    # Step 4: Hybrid perturbation\n    for _ in range(3):  # Perform 3 perturbation iterations\n        # Critical flips with higher probability\n        if np.random.rand() < perturbation_intensity:\n            for item in critical_items:\n                if np.random.rand() < 0.6:  # 60% chance to flip each critical item\n                    temp_solution = new_solution.copy()\n                    temp_solution[item] = 1 - temp_solution[item]\n                    if np.sum(temp_solution * weight_lst) <= capacity:\n                        new_solution = temp_solution\n\n        # Guided random swaps (only between high-value items)\n        if np.random.rand() < 0.4 * perturbation_intensity:\n            high_value_items = np.argsort(-(value1_lst + value2_lst))[:max(2, int(len(weight_lst) * 0.2))]\n            if len(high_value_items) >= 2:\n                i, j = np.random.choice(high_value_items, size=2, replace=False)\n                temp_solution = new_solution.copy()\n                temp_solution[i], temp_solution[j] = temp_solution[j], temp_solution[i]\n                if np.sum(temp_solution * weight_lst) <= capacity:\n                    new_solution = temp_solution\n\n    # Step 5: Incremental feasibility check and repair\n    current_weight = np.sum(new_solution * weight_lst)\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(removable_items)\n        for item in removable_items:\n            if excess <= 0:\n                break\n            if new_solution[item] == 1:\n                new_solution[item] = 0\n                excess -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.6678273418997038,
            0.35101014375686646
        ]
    },
    {
        "algorithm": "This algorithm intelligently selects a promising solution from the archive by normalizing and summing its objectives, then generates a neighbor solution through a hybrid approach combining random item flips (with a 30% probability) and strategic swaps (prioritizing high-value-to-weight items). It ensures feasibility by checking weights and removing excess items if needed, always maintaining the knapsack capacity constraint. The method balances exploration (random flips) with exploitation (value-based swaps) for effective local search.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (here, we choose the one with the highest sum of normalized objectives)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    scores = normalized_obj.sum(axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Create a neighbor solution using a hybrid approach\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Step 1: Randomly flip a subset of items (with bias towards improving both objectives)\n    flip_mask = np.zeros(n_items, dtype=bool)\n    for i in range(n_items):\n        if random.random() < 0.3:  # 30% chance to consider flipping\n            if base_solution[i] == 0:\n                potential_weight = np.sum(weight_lst[new_solution == 1]) + weight_lst[i]\n                if potential_weight <= capacity:\n                    flip_mask[i] = True\n            else:\n                flip_mask[i] = True\n\n    # Step 2: Apply the flips\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Step 3: If no flips applied, try a different approach (swap two items)\n    if not np.any(flip_mask):\n        # Find two items to swap (one in, one out)\n        in_items = np.where(base_solution == 1)[0]\n        out_items = np.where(base_solution == 0)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Select items with high value-to-weight ratio for potential swap\n            in_ratios = (value1_lst[in_items] + value2_lst[in_items]) / weight_lst[in_items]\n            out_ratios = (value1_lst[out_items] + value2_lst[out_items]) / weight_lst[out_items]\n\n            best_in = in_items[np.argmin(in_ratios)]  # Item to remove (lowest ratio)\n            best_out = out_items[np.argmax(out_ratios)]  # Item to add (highest ratio)\n\n            # Check if swap is feasible\n            current_weight = np.sum(weight_lst[base_solution == 1])\n            potential_weight = current_weight - weight_lst[best_in] + weight_lst[best_out]\n\n            if potential_weight <= capacity:\n                new_solution[best_in] = 0\n                new_solution[best_out] = 1\n\n    # Ensure solution is feasible (in case of any errors)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Remove items randomly until feasible\n        while current_weight > capacity:\n            excess_items = np.where(new_solution == 1)[0]\n            if len(excess_items) == 0:\n                break\n            remove_idx = random.choice(excess_items)\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8777357135529364,
            0.6920754313468933
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive based on novelty and diversity scores, then generates a neighbor by performing a value-weighted random walk where items are flipped with probabilities proportional to their combined value-to-weight ratios, dynamically adjusting the intensity of this walk. It further refines the solution by guidedly removing low-contribution items and flipping high-value items, while ensuring feasibility through incremental weight checks and a lightweight repair mechanism that prioritizes removing items with the smallest marginal contribution. The algorithm prioritizes items with higher combined value-to-weight ratios and adjusts search intensity based on progress, balancing exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive selection: prioritize solutions with high novelty and diversity\n    objectives = np.array([obj for _, obj in archive])\n    novelty_scores = np.max(np.abs(objectives[:, None, :] - objectives[None, :, :]), axis=1).mean(axis=1)\n    selected_idx = np.argmax(novelty_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    n_items = len(weight_lst)\n\n    # Calculate combined value-to-weight ratios\n    combined_ratios = (value1_lst + value2_lst) / weight_lst\n\n    # Value-weighted random walk with dynamic intensity\n    intensity = max(0.1, 0.5 * (1 - selected_idx / len(archive)))  # Decreases as search progresses\n    for i in range(n_items):\n        if np.random.rand() < intensity * combined_ratios[i] / np.sum(combined_ratios):\n            if new_solution[i] == 0:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n            else:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n\n    # Guided removal of low-contribution items\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        marginal_contributions = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n        sorted_items = included_items[np.argsort(marginal_contributions)]\n        for item in sorted_items[:max(1, len(sorted_items) // 10)]:  # Remove bottom 10%\n            new_solution[item] = 0\n            current_weight -= weight_lst[item]\n\n    # Lightweight repair if needed\n    if current_weight > capacity:\n        excess_items = np.where(new_solution == 1)[0]\n        excess_ratios = combined_ratios[excess_items]\n        while current_weight > capacity and len(excess_items) > 0:\n            remove_idx = excess_items[np.argmin(excess_ratios)]\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n            excess_items = np.where(new_solution == 1)[0]\n            excess_ratios = combined_ratios[excess_items]\n\n    return new_solution\n\n",
        "score": [
            -0.8841827446269912,
            1.5795058608055115
        ]
    },
    {
        "algorithm": "The algorithm implements a hybrid adaptive local search that prioritizes younger, more diverse solutions from the archive, flips critical high-value items first, then applies guided random perturbations with dynamic intensity, and finally ensures feasibility through lightweight repair. It balances exploration (via diversity and randomness) and exploitation (via critical item flips) while dynamically adjusting perturbation strength based on solution age. The selection scores combine age and diversity to guide the search toward promising regions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive solution selection: prioritize younger solutions with higher diversity\n    ages = np.array([i for i in range(len(archive))])  # Assume newer solutions have higher indices\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    diversity_scores = normalized_obj.std(axis=1)  # Higher diversity is better\n    selection_scores = (ages / len(archive)) + diversity_scores  # Balance age and diversity\n    selected_idx = np.argmax(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid perturbation strategy\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 1: Critical item flips (high value-to-weight ratio)\n    combined_value_to_weight = (value1_lst + value2_lst) / weight_lst\n    critical_items = np.argsort(combined_value_to_weight)[-min(5, n_items):]  # Top 5 items\n\n    for item in critical_items:\n        if base_solution[item] == 0:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n        else:\n            new_solution[item] = 0\n            current_weight -= weight_lst[item]\n\n    # Step 2: Guided random swaps (dynamic intensity)\n    perturbation_intensity = 0.3 + (0.7 * (selected_idx / len(archive)))  # Higher for older solutions\n    for i in range(n_items):\n        if random.random() < perturbation_intensity:\n            if new_solution[i] == 0:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n            else:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n\n    # Step 3: Lightweight repair (remove excess items if needed)\n    if current_weight > capacity:\n        excess_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(excess_items)\n        for item in excess_items:\n            if current_weight <= capacity:\n                break\n            new_solution[item] = 0\n            current_weight -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.48432951236982885,
            0.3804723024368286
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high objective diversity and moderate density\n    selected_idx = 0\n    max_diversity = -1\n    for i, (sol, obj) in enumerate(archive):\n        diversity = abs(obj[0] - obj[1])\n        density = np.sum(sol)\n        score = diversity / (density + 1e-6)  # Avoid division by zero\n        if score > max_diversity:\n            max_diversity = score\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Identify critical items based on combined value-to-weight ratios\n    value_to_weight1 = value1_lst / weight_lst\n    value_to_weight2 = value2_lst / weight_lst\n    combined_value_to_weight = value_to_weight1 + value_to_weight2\n    critical_items = np.argsort(combined_value_to_weight)[-min(3, len(weight_lst)):]  # Top 3 items\n\n    # Hybrid local search: flip critical items and guided random swaps\n    for _ in range(3):  # Perform 3 iterations\n        # Flip critical items\n        for item in critical_items:\n            temp_solution = new_solution.copy()\n            temp_solution[item] = 1 - temp_solution[item]\n            total_weight = np.sum(temp_solution * weight_lst)\n            if total_weight <= capacity:\n                new_solution = temp_solution.copy()\n\n        # Guided random swap: prioritize high-value items\n        if len(critical_items) > 1:\n            i, j = np.random.choice(critical_items, size=2, replace=False)\n            temp_solution = new_solution.copy()\n            temp_solution[i], temp_solution[j] = temp_solution[j], temp_solution[i]\n            total_weight = np.sum(temp_solution * weight_lst)\n            if total_weight <= capacity:\n                new_solution = temp_solution.copy()\n\n        # Random flip of non-critical items with probability 0.2\n        non_critical_items = np.setdiff1d(np.arange(len(weight_lst)), critical_items)\n        if len(non_critical_items) > 0 and np.random.rand() < 0.2:\n            idx = np.random.choice(non_critical_items)\n            temp_solution = new_solution.copy()\n            temp_solution[idx] = 1 - temp_solution[idx]\n            total_weight = np.sum(temp_solution * weight_lst)\n            if total_weight <= capacity:\n                new_solution = temp_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.8648274670870268,
            0.7946086823940277
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive prioritizing those with high objective diversity (absolute difference between the two objectives) and low density (fewer items), then applies a hybrid local search combining random item swaps and flips with a probability of 0.3, ensuring feasibility by always checking the weight constraint. The selection emphasizes solutions with balanced objectives and simplicity, while the local search explores neighbors intelligently to escape local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high objective diversity and low density\n    selected_idx = 0\n    max_diversity = -1\n    for i, (sol, obj) in enumerate(archive):\n        diversity = abs(obj[0] - obj[1])  # Measure of objective diversity\n        density = np.sum(sol)  # Number of items in the solution\n        score = diversity / (density + 1)  # Prefer solutions with high diversity and low density\n        if score > max_diversity:\n            max_diversity = score\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: swap items and flip with probability\n    n_items = len(weight_lst)\n    for _ in range(2):  # Perform 2 iterations of local search\n        # Randomly select two distinct items\n        i, j = np.random.choice(n_items, size=2, replace=False)\n\n        # Try swapping items i and j\n        temp_solution = new_solution.copy()\n        temp_solution[i], temp_solution[j] = temp_solution[j], temp_solution[i]\n        total_weight = np.sum(temp_solution * weight_lst)\n\n        if total_weight <= capacity:\n            new_solution = temp_solution.copy()\n\n        # Try flipping item i with probability 0.3\n        if np.random.rand() < 0.3:\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1 - temp_solution[i]\n            total_weight = np.sum(temp_solution * weight_lst)\n\n            if total_weight <= capacity:\n                new_solution = temp_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.7024644525497394,
            0.6926618814468384
        ]
    }
]