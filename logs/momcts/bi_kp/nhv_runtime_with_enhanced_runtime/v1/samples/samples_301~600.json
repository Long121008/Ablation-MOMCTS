[
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm prioritizes solutions with high combined objective values and crowding distance, applying a hybrid local search that adaptively flips items with probabilities based on objective balance and novelty scores, while ensuring feasibility through a multi-criteria removal strategy that balances value1 and value2 with different weightings. It dynamically adjusts flip probabilities and selection criteria, favoring value1 in novelty calculations and value2 in quality evaluations, and enforces feasibility by removing items with the lowest combined novelty and quality metrics.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Novelty-driven selection with different weightings\n    obj1 = np.array([obj[0] for _, obj in archive])\n    obj2 = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1), np.max(obj2)\n\n    # Calculate novelty score with different balancing\n    novelty_score = (obj1 / (max_obj1 + 1e-10))**0.8 * (obj2 / (max_obj2 + 1e-10))**0.8 * (1 - np.abs(obj1 - obj2) / (max_obj1 + max_obj2 + 1e-10))\n\n    # Calculate crowding distance with different metric\n    sorted_indices = np.argsort(obj1)\n    crowding = np.zeros(len(archive))\n    crowding[sorted_indices[0]] = crowding[sorted_indices[-1]] = float('inf')\n    for i in range(1, len(archive)-1):\n        crowding[sorted_indices[i]] = abs(obj1[sorted_indices[i+1]] - obj1[sorted_indices[i-1]]) / (max_obj1 + 1e-10)\n\n    # Combine novelty and crowding with different weights\n    selection_score = 0.7 * novelty_score + 0.3 * crowding\n    selected_idx = np.argmax(selection_score)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Adaptive local search with different parameters\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    if len(in_items) > 0 and len(out_items) > 0:\n        # Objective balance factor with different calculation\n        obj_balance = (obj1[selected_idx] + 0.4 * obj2[selected_idx]) / (max_obj1 + max_obj2 + 1e-10)\n\n        # Dynamic flip probabilities with different formula\n        flip_prob = 0.3 + 0.4 * obj_balance + 0.3 * (1 - novelty_score[selected_idx])\n\n        # Novelty-aware flip\n        for i in in_items:\n            if random.random() < flip_prob:\n                new_weight = current_weight - weight_lst[i]\n                if new_weight >= 0:\n                    new_solution[i] = 0\n\n        # Targeted swap with different selection criteria\n        if len(out_items) > 0:\n            # Calculate novelty-aware marginal gains with different weights\n            novelty_gain = (value1_lst[out_items] * 0.8 + value2_lst[out_items] * 0.2) / (weight_lst[out_items] + 1e-10)\n            quality_gain = (value1_lst[out_items] * 0.2 + value2_lst[out_items] * 0.8) / (weight_lst[out_items] + 1e-10)\n\n            # Combined metric for swap selection with different weights\n            combined_gain = 0.6 * novelty_gain + 0.4 * quality_gain\n            swap_in = out_items[np.argmax(combined_gain)]\n\n            # Calculate marginal gains for removal with different metric\n            if len(in_items) > 0:\n                marginal_gain = (value1_lst[in_items] * 0.3 + value2_lst[in_items] * 0.7) / weight_lst[in_items]\n                swap_out = in_items[np.argmin(marginal_gain)]\n\n                if (current_weight - weight_lst[swap_out] + weight_lst[swap_in]) <= capacity:\n                    new_solution[swap_out] = 0\n                    new_solution[swap_in] = 1\n\n    # Multi-criteria feasibility enforcement with different weights\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        # Remove items with lowest combined novelty and quality with different weights\n        combined_metric = (value1_lst[included_items] * 0.7 + value2_lst[included_items] * 0.3) / (weight_lst[included_items] + 1e-10)\n        novelty_metric = (value1_lst[included_items] * 0.3 + value2_lst[included_items] * 0.7) / (weight_lst[included_items] + 1e-10)\n        removal_metric = 0.7 * combined_metric + 0.3 * novelty_metric\n\n        sorted_indices = included_items[np.argsort(removal_metric)]\n\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            excess -= weight_lst[i]\n            new_solution[i] = 0\n\n    return new_solution\n\n\n        \n        Your **sole objective** is to reduce the runtime of the algorithm as much as possible.\n        Ignore any performance metrics other than runtime.\n        \n        Please create a new algorithm that is a modified, faster version of the provided one.\n        Focus on optimizations such as reducing algorithmic complexity, improving loops,\n        using efficient data structures, removing redundant computations, and simplifying logic.\n        \n        1. First, identify parts of the code that most likely cause high runtime and suggest optimizations.\n        2. Next, describe your new optimized algorithm and its main steps in one detailed sentence. The description must be inside boxed {}.\n        3. Finally, implement the optimized algorithm in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        \n        Check syntax and code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 301,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Precompute objectives and max values\n    obj1 = np.array([obj[0] for _, obj in archive])\n    obj2 = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1), np.max(obj2)\n\n    # Simplified novelty and crowding calculation\n    novelty_score = (obj1 / (max_obj1 + 1e-10)) * (obj2 / (max_obj2 + 1e-10))\n    sorted_obj1 = np.argsort(obj1)\n    crowding = np.zeros(len(archive))\n    crowding[sorted_obj1[0]] = crowding[sorted_obj1[-1]] = float('inf')\n    for i in range(1, len(archive)-1):\n        crowding[sorted_obj1[i]] = abs(obj1[sorted_obj1[i+1]] - obj1[sorted_obj1[i-1]]) / (max_obj1 + 1e-10)\n\n    # Combined selection score (simplified)\n    selection_score = novelty_score + 0.3 * crowding\n    selected_idx = np.argmax(selection_score)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Simplified local search\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    if len(in_items) > 0 and len(out_items) > 0:\n        # Simplified flip probability\n        flip_prob = 0.3\n\n        # Fast flip operation\n        for i in in_items:\n            if random.random() < flip_prob and (current_weight - weight_lst[i]) >= 0:\n                new_solution[i] = 0\n\n        # Fast swap operation\n        if len(out_items) > 0:\n            # Precompute gains\n            gains = (value1_lst[out_items] + value2_lst[out_items]) / (weight_lst[out_items] + 1e-10)\n            swap_in = out_items[np.argmax(gains)]\n\n            if len(in_items) > 0:\n                # Precompute removal gains\n                removal_gains = (value1_lst[in_items] + value2_lst[in_items]) / weight_lst[in_items]\n                swap_out = in_items[np.argmin(removal_gains)]\n\n                if (current_weight - weight_lst[swap_out] + weight_lst[swap_in]) <= capacity:\n                    new_solution[swap_out] = 0\n                    new_solution[swap_in] = 1\n\n    # Fast feasibility check\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        # Fast removal metric\n        removal_metric = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-10)\n        sorted_indices = included_items[np.argsort(removal_metric)]\n\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            excess -= weight_lst[i]\n            new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8996023673761626,
            0.4475407898426056
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Precompute objectives and max values\n    obj1 = np.array([obj[0] for _, obj in archive])\n    obj2 = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1), np.max(obj2)\n\n    # Simplified novelty and crowding calculation\n    novelty_score = (obj1 / (max_obj1 + 1e-10)) * (obj2 / (max_obj2 + 1e-10))\n    sorted_obj1 = np.argsort(obj1)\n    crowding = np.zeros(len(archive))\n    crowding[sorted_obj1[0]] = crowding[sorted_obj1[-1]] = float('inf')\n    for i in range(1, len(archive)-1):\n        crowding[sorted_obj1[i]] = abs(obj1[sorted_obj1[i+1]] - obj1[sorted_obj1[i-1]]) / (max_obj1 + 1e-10)\n\n    # Combined selection score (simplified)\n    selection_score = novelty_score + 0.3 * crowding\n    selected_idx = np.argmax(selection_score)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Simplified local search\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    if len(in_items) > 0 and len(out_items) > 0:\n        # Simplified flip probability\n        flip_prob = 0.3\n\n        # Fast flip operation\n        for i in in_items:\n            if random.random() < flip_prob and (current_weight - weight_lst[i]) >= 0:\n                new_solution[i] = 0\n\n        # Fast swap operation\n        if len(out_items) > 0:\n            # Precompute gains\n            gains = (value1_lst[out_items] + value2_lst[out_items]) / (weight_lst[out_items] + 1e-10)\n            swap_in = out_items[np.argmax(gains)]\n\n            if len(in_items) > 0:\n                # Precompute removal gains\n                removal_gains = (value1_lst[in_items] + value2_lst[in_items]) / weight_lst[in_items]\n                swap_out = in_items[np.argmin(removal_gains)]\n\n                if (current_weight - weight_lst[swap_out] + weight_lst[swap_in]) <= capacity:\n                    new_solution[swap_out] = 0\n                    new_solution[swap_in] = 1\n\n    # Fast feasibility check\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        # Fast removal metric\n        removal_metric = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-10)\n        sorted_indices = included_items[np.argsort(removal_metric)]\n\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            excess -= weight_lst[i]\n            new_solution[i] = 0\n\n    return new_solution\n\n",
        "operation": "r1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm combines a diversity-aware selection strategy with a hybrid local search that dynamically balances marginal contribution flips (70% probability) and value-aware swaps (30% probability), prioritizing solutions with high combined objective ratios while ensuring feasibility through greedy excess removal. It intelligently samples from the archive using a combined objective ratio to guide exploration, dynamically adjusting between exploration and exploitation based on archive size, and always maintains feasibility through strict capacity checks and greedy removal steps.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Calculate combined objective ratios for selection\n    obj1 = np.array([obj[0] for _, obj in archive])\n    obj2 = np.array([obj[1] for _, obj in archive])\n    combined_ratios = (obj1 + obj2) / (np.sum(weight_lst) + 1e-8)\n\n    # Select solution with highest combined ratio\n    selected_idx = np.argmax(combined_ratios)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Dynamic exploration/exploitation trade-off\n    exploration_prob = 0.5 + 0.5 * (1 - len(archive) / 100)\n\n    if random.random() < exploration_prob:\n        # Marginal contribution flips (70% probability)\n        for i in range(len(weight_lst)):\n            if random.random() < 0.7:\n                if new_solution[i] == 1:\n                    # Remove if negative marginal contribution\n                    marginal1 = -value1_lst[i]\n                    marginal2 = -value2_lst[i]\n                    if marginal1 < 0 or marginal2 < 0:\n                        new_weight = current_weight - weight_lst[i]\n                        if new_weight >= 0:\n                            new_solution[i] = 0\n                            current_weight = new_weight\n                else:\n                    # Add if positive marginal contribution\n                    marginal1 = value1_lst[i]\n                    marginal2 = value2_lst[i]\n                    if marginal1 > 0 and marginal2 > 0:\n                        new_weight = current_weight + weight_lst[i]\n                        if new_weight <= capacity:\n                            new_solution[i] = 1\n                            current_weight = new_weight\n    else:\n        # Value-aware swaps (30% probability)\n        not_in_solution = np.where(new_solution == 0)[0]\n        if len(not_in_solution) > 0:\n            # Calculate value ratios\n            ratios1 = value1_lst[not_in_solution] / weight_lst[not_in_solution]\n            ratios2 = value2_lst[not_in_solution] / weight_lst[not_in_solution]\n            combined_ratios = ratios1 + ratios2\n\n            # Select top 30% candidates\n            top_candidates = not_in_solution[np.argsort(combined_ratios)[-max(1, len(combined_ratios)//3):]]\n            if len(top_candidates) > 0:\n                swap_in = random.choice(top_candidates)\n\n                # Find worst item to remove\n                in_solution = np.where(new_solution == 1)[0]\n                if len(in_solution) > 0:\n                    ratios1_in = value1_lst[in_solution] / weight_lst[in_solution]\n                    ratios2_in = value2_lst[in_solution] / weight_lst[in_solution]\n                    combined_ratios_in = ratios1_in + ratios2_in\n                    swap_out = in_solution[np.argmin(combined_ratios_in)]\n\n                    # Perform swap if feasible\n                    if (current_weight - weight_lst[swap_out] + weight_lst[swap_in]) <= capacity:\n                        new_solution[swap_out] = 0\n                        new_solution[swap_in] = 1\n                        current_weight = current_weight - weight_lst[swap_out] + weight_lst[swap_in]\n\n    # Greedy excess removal if still over capacity\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        ratios = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n        sorted_indices = included_items[np.argsort(ratios)]\n        excess = total_weight - capacity\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            excess -= weight_lst[i]\n            new_solution[i] = 0\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a solution from the archive based on its trade-off between objectives (prioritizing extreme ratios), then applies a hybrid local search that probabilistically removes items (with higher probability for solutions with better value ratios) and inserts items using a utility metric that balances both objectives while considering weight efficiency, all while ensuring feasibility through adaptive removal of heaviest items if necessary. The utility metric dynamically adjusts based on the selected solution's objective trade-off, favoring items that complement the current solution's weaknesses.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    obj1 = np.array([obj[0] for _, obj in archive])\n    obj2 = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1), np.max(obj2)\n    norm_obj1 = obj1 / (max_obj1 + 1e-10)\n    norm_obj2 = obj2 / (max_obj2 + 1e-10)\n\n    tradeoff_scores = np.abs(norm_obj1 - norm_obj2)\n    selected_idx = np.argmax(tradeoff_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    obj_ratio = norm_obj1[selected_idx] / (norm_obj2[selected_idx] + 1e-10)\n    removal_prob = 0.3 + 0.5 * (1 - np.exp(-obj_ratio))\n\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        for i in in_items:\n            if random.random() < removal_prob:\n                new_weight = current_weight - weight_lst[i]\n                if new_weight >= 0:\n                    new_solution[i] = 0\n                    current_weight = new_weight\n\n    out_items = np.where(new_solution == 0)[0]\n    if len(out_items) > 0:\n        utility_metric = (value1_lst[out_items] * (1 - norm_obj1[selected_idx]) + value2_lst[out_items] * (1 - norm_obj2[selected_idx])) / (weight_lst[out_items] + 1e-10)\n        utility_metric += 0.2 * np.random.rand(len(out_items))\n        best_insert = out_items[np.argmax(utility_metric)]\n\n        if (current_weight + weight_lst[best_insert]) <= capacity:\n            new_solution[best_insert] = 1\n            current_weight += weight_lst[best_insert]\n\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        sorted_indices = included_items[np.argsort(-weight_lst[included_items])]\n\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            excess -= weight_lst[i]\n            new_solution[i] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design in your requested format:\n\n- **Keywords**: Hypervolume-guided selection, correlation-aware local search, adaptive marginal thresholds, probabilistic swaps, feasibility enforcement.\n- **Advice**: Prioritize solutions with high hypervolume and objective correlations; dynamically adjust flip/swap probabilities based on marginal gains; enforce feasibility via greedy excess removal; sample solutions with high diversity.\n- **Avoid**: Static local search (e.g., 2-opt), uniform selection, infeasible weight overflow, randomness without objective guidance.\n- **Explanation**: The heuristic balances exploration (hypervolume-guided selection) and exploitation (correlation-aware flips), ensures feasibility, and avoids local optima via adaptive thresholds and intelligent sampling. This ensures high-quality, feasible neighbors while avoiding pitfalls of ineffectiveness.\n\n**Step-by-step reasoning**:\n1. **Selection**: Use hypervolume to prioritize solutions with high diversity and marginal value potential.\n2. **Local Search**: Alternate between correlation-aware swaps (70%) and marginal-gain flips (30%) to balance exploration/exploitation.\n3. **Feasibility**: Enforce feasibility via greedy excess removal when weight overflows.\n4. **Dynamic Adjustment**: Adjust flip/swap probabilities based on objective correlations to avoid overfitting.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 302,
        "algorithm": "The algorithm combines hypervolume-guided solution selection with a dynamic local search that alternates between correlation-aware item swaps (prioritizing uncorrelated objectives) and marginal-gain flips (focusing on high-value-to-weight items), while maintaining feasibility through adaptive weight balancing and greedy excess removal. It intelligently selects solutions based on their hypervolume contribution and adjusts flip/swap probabilities based on objective correlations, ensuring high-quality neighbors while avoiding infeasible solutions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Calculate hypervolume contributions for selection\n    obj1 = np.array([obj[0] for _, obj in archive])\n    obj2 = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1), np.max(obj2)\n    norm_obj1 = obj1 / (max_obj1 + 1e-10)\n    norm_obj2 = obj2 / (max_obj2 + 1e-10)\n\n    # Compute hypervolume contribution (simplified)\n    hypervolume = norm_obj1 * norm_obj2\n    selected_idx = np.argmax(hypervolume)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate objective correlations\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        in_values1 = value1_lst[in_items]\n        in_values2 = value2_lst[in_items]\n        corr = np.corrcoef(in_values1, in_values2)[0, 1] if len(in_items) > 1 else 0.0\n\n    # Dynamic flip/swap probability based on correlation\n    flip_prob = 0.7 if corr < 0.5 else 0.3  # More flips if objectives are uncorrelated\n\n    # Correlation-aware swaps (70% probability)\n    if random.random() < flip_prob:\n        out_items = np.where(new_solution == 0)[0]\n        if len(out_items) > 0:\n            # Calculate correlation-based utility\n            utility_metric = (value1_lst[out_items] * (1 - corr) + value2_lst[out_items] * (1 - corr)) / (weight_lst[out_items] + 1e-10)\n            best_insert = out_items[np.argmax(utility_metric)]\n\n            if (current_weight + weight_lst[best_insert]) <= capacity:\n                new_solution[best_insert] = 1\n                current_weight += weight_lst[best_insert]\n\n                # Remove worst item if solution is full\n                if current_weight > 0.9 * capacity:\n                    in_items = np.where(new_solution == 1)[0]\n                    if len(in_items) > 0:\n                        ratios = (value1_lst[in_items] + value2_lst[in_items]) / weight_lst[in_items]\n                        worst_item = in_items[np.argmin(ratios)]\n                        new_solution[worst_item] = 0\n                        current_weight -= weight_lst[worst_item]\n\n    # Marginal-gain flips (30% probability)\n    else:\n        for i in range(len(weight_lst)):\n            if random.random() < 0.5:  # Random flip with 50% probability\n                if new_solution[i] == 1:\n                    marginal1 = -value1_lst[i]\n                    marginal2 = -value2_lst[i]\n                    if marginal1 < 0 or marginal2 < 0:\n                        new_weight = current_weight - weight_lst[i]\n                        if new_weight >= 0:\n                            new_solution[i] = 0\n                            current_weight = new_weight\n                else:\n                    marginal1 = value1_lst[i]\n                    marginal2 = value2_lst[i]\n                    if marginal1 > 0 and marginal2 > 0:\n                        new_weight = current_weight + weight_lst[i]\n                        if new_weight <= capacity:\n                            new_solution[i] = 1\n                            current_weight = new_weight\n\n    # Greedy excess removal if still over capacity\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        ratios = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n        sorted_indices = included_items[np.argsort(ratios)]\n        excess = total_weight - capacity\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            excess -= weight_lst[i]\n            new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.48933555985198485,
            9.902268290519714
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Calculate hypervolume contributions for selection\n    obj1 = np.array([obj[0] for _, obj in archive])\n    obj2 = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1), np.max(obj2)\n    norm_obj1 = obj1 / (max_obj1 + 1e-10)\n    norm_obj2 = obj2 / (max_obj2 + 1e-10)\n\n    # Compute hypervolume contribution (simplified)\n    hypervolume = norm_obj1 * norm_obj2\n    selected_idx = np.argmax(hypervolume)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate objective correlations\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        in_values1 = value1_lst[in_items]\n        in_values2 = value2_lst[in_items]\n        corr = np.corrcoef(in_values1, in_values2)[0, 1] if len(in_items) > 1 else 0.0\n\n    # Dynamic flip/swap probability based on correlation\n    flip_prob = 0.7 if corr < 0.5 else 0.3  # More flips if objectives are uncorrelated\n\n    # Correlation-aware swaps (70% probability)\n    if random.random() < flip_prob:\n        out_items = np.where(new_solution == 0)[0]\n        if len(out_items) > 0:\n            # Calculate correlation-based utility\n            utility_metric = (value1_lst[out_items] * (1 - corr) + value2_lst[out_items] * (1 - corr)) / (weight_lst[out_items] + 1e-10)\n            best_insert = out_items[np.argmax(utility_metric)]\n\n            if (current_weight + weight_lst[best_insert]) <= capacity:\n                new_solution[best_insert] = 1\n                current_weight += weight_lst[best_insert]\n\n                # Remove worst item if solution is full\n                if current_weight > 0.9 * capacity:\n                    in_items = np.where(new_solution == 1)[0]\n                    if len(in_items) > 0:\n                        ratios = (value1_lst[in_items] + value2_lst[in_items]) / weight_lst[in_items]\n                        worst_item = in_items[np.argmin(ratios)]\n                        new_solution[worst_item] = 0\n                        current_weight -= weight_lst[worst_item]\n\n    # Marginal-gain flips (30% probability)\n    else:\n        for i in range(len(weight_lst)):\n            if random.random() < 0.5:  # Random flip with 50% probability\n                if new_solution[i] == 1:\n                    marginal1 = -value1_lst[i]\n                    marginal2 = -value2_lst[i]\n                    if marginal1 < 0 or marginal2 < 0:\n                        new_weight = current_weight - weight_lst[i]\n                        if new_weight >= 0:\n                            new_solution[i] = 0\n                            current_weight = new_weight\n                else:\n                    marginal1 = value1_lst[i]\n                    marginal2 = value2_lst[i]\n                    if marginal1 > 0 and marginal2 > 0:\n                        new_weight = current_weight + weight_lst[i]\n                        if new_weight <= capacity:\n                            new_solution[i] = 1\n                            current_weight = new_weight\n\n    # Greedy excess removal if still over capacity\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        ratios = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n        sorted_indices = included_items[np.argsort(ratios)]\n        excess = total_weight - capacity\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            excess -= weight_lst[i]\n            new_solution[i] = 0\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a solution from the archive based on its trade-off between objectives (prioritizing extreme ratios), then applies a hybrid local search that probabilistically removes items (with higher probability for solutions with better value ratios) and inserts items using a utility metric that balances both objectives while considering weight efficiency, all while ensuring feasibility through adaptive removal of heaviest items if necessary. The utility metric dynamically adjusts based on the selected solution's objective trade-off, favoring items that complement the current solution's weaknesses.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    obj1 = np.array([obj[0] for _, obj in archive])\n    obj2 = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1), np.max(obj2)\n    norm_obj1 = obj1 / (max_obj1 + 1e-10)\n    norm_obj2 = obj2 / (max_obj2 + 1e-10)\n\n    tradeoff_scores = np.abs(norm_obj1 - norm_obj2)\n    selected_idx = np.argmax(tradeoff_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    obj_ratio = norm_obj1[selected_idx] / (norm_obj2[selected_idx] + 1e-10)\n    removal_prob = 0.3 + 0.5 * (1 - np.exp(-obj_ratio))\n\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        for i in in_items:\n            if random.random() < removal_prob:\n                new_weight = current_weight - weight_lst[i]\n                if new_weight >= 0:\n                    new_solution[i] = 0\n                    current_weight = new_weight\n\n    out_items = np.where(new_solution == 0)[0]\n    if len(out_items) > 0:\n        utility_metric = (value1_lst[out_items] * (1 - norm_obj1[selected_idx]) + value2_lst[out_items] * (1 - norm_obj2[selected_idx])) / (weight_lst[out_items] + 1e-10)\n        utility_metric += 0.2 * np.random.rand(len(out_items))\n        best_insert = out_items[np.argmax(utility_metric)]\n\n        if (current_weight + weight_lst[best_insert]) <= capacity:\n            new_solution[best_insert] = 1\n            current_weight += weight_lst[best_insert]\n\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        sorted_indices = included_items[np.argsort(-weight_lst[included_items])]\n\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            excess -= weight_lst[i]\n            new_solution[i] = 0\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 303,
        "algorithm": "The algorithm selects a promising solution from the archive based on a dominance score that balances both objectives, then applies a hybrid local search: it probabilistically removes items from the solution (weighted by their contribution to the less dominant objective) and adds high-value items (considering both objectives) while ensuring feasibility through a weight-adjusted dominance metric and excess removal. The selection prioritizes solutions with balanced objective values, while the local search focuses on improving the weaker objective through intelligent item swaps.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    obj1 = np.array([obj[0] for _, obj in archive])\n    obj2 = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1), np.max(obj2)\n    norm_obj1 = obj1 / (max_obj1 + 1e-10)\n    norm_obj2 = obj2 / (max_obj2 + 1e-10)\n\n    dominance_scores = (1 - norm_obj1) * norm_obj2 + norm_obj1 * (1 - norm_obj2)\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    obj_ratio = norm_obj1[selected_idx] / (norm_obj2[selected_idx] + 1e-10)\n    swap_prob = 0.4 + 0.4 * np.tanh(obj_ratio - 1)\n\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        for i in in_items:\n            if random.random() < swap_prob:\n                new_weight = current_weight - weight_lst[i]\n                if new_weight >= 0:\n                    new_solution[i] = 0\n                    current_weight = new_weight\n\n    out_items = np.where(new_solution == 0)[0]\n    if len(out_items) > 0:\n        dominance_metric = (value1_lst[out_items] * (1 - norm_obj1[selected_idx]) + value2_lst[out_items] * (1 - norm_obj2[selected_idx])) / (weight_lst[out_items] + 1e-10)\n        dominance_metric += 0.1 * np.random.rand(len(out_items))\n        best_candidate = out_items[np.argmax(dominance_metric)]\n\n        if (current_weight + weight_lst[best_candidate]) <= capacity:\n            new_solution[best_candidate] = 1\n            current_weight += weight_lst[best_candidate]\n\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        sorted_indices = included_items[np.argsort(-(value1_lst[included_items] / weight_lst[included_items] + value2_lst[included_items] / weight_lst[included_items]))]\n\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            excess -= weight_lst[i]\n            new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8221264735197218,
            1.0884661078453064
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    obj1 = np.array([obj[0] for _, obj in archive])\n    obj2 = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1), np.max(obj2)\n    norm_obj1 = obj1 / (max_obj1 + 1e-10)\n    norm_obj2 = obj2 / (max_obj2 + 1e-10)\n\n    dominance_scores = (1 - norm_obj1) * norm_obj2 + norm_obj1 * (1 - norm_obj2)\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    obj_ratio = norm_obj1[selected_idx] / (norm_obj2[selected_idx] + 1e-10)\n    swap_prob = 0.4 + 0.4 * np.tanh(obj_ratio - 1)\n\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        for i in in_items:\n            if random.random() < swap_prob:\n                new_weight = current_weight - weight_lst[i]\n                if new_weight >= 0:\n                    new_solution[i] = 0\n                    current_weight = new_weight\n\n    out_items = np.where(new_solution == 0)[0]\n    if len(out_items) > 0:\n        dominance_metric = (value1_lst[out_items] * (1 - norm_obj1[selected_idx]) + value2_lst[out_items] * (1 - norm_obj2[selected_idx])) / (weight_lst[out_items] + 1e-10)\n        dominance_metric += 0.1 * np.random.rand(len(out_items))\n        best_candidate = out_items[np.argmax(dominance_metric)]\n\n        if (current_weight + weight_lst[best_candidate]) <= capacity:\n            new_solution[best_candidate] = 1\n            current_weight += weight_lst[best_candidate]\n\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        sorted_indices = included_items[np.argsort(-(value1_lst[included_items] / weight_lst[included_items] + value2_lst[included_items] / weight_lst[included_items]))]\n\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            excess -= weight_lst[i]\n            new_solution[i] = 0\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a solution from the archive based on its trade-off between objectives (prioritizing extreme ratios), then applies a hybrid local search that probabilistically removes items (with higher probability for solutions with better value ratios) and inserts items using a utility metric that balances both objectives while considering weight efficiency, all while ensuring feasibility through adaptive removal of heaviest items if necessary. The utility metric dynamically adjusts based on the selected solution's objective trade-off, favoring items that complement the current solution's weaknesses.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    obj1 = np.array([obj[0] for _, obj in archive])\n    obj2 = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1), np.max(obj2)\n    norm_obj1 = obj1 / (max_obj1 + 1e-10)\n    norm_obj2 = obj2 / (max_obj2 + 1e-10)\n\n    tradeoff_scores = np.abs(norm_obj1 - norm_obj2)\n    selected_idx = np.argmax(tradeoff_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    obj_ratio = norm_obj1[selected_idx] / (norm_obj2[selected_idx] + 1e-10)\n    removal_prob = 0.3 + 0.5 * (1 - np.exp(-obj_ratio))\n\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        for i in in_items:\n            if random.random() < removal_prob:\n                new_weight = current_weight - weight_lst[i]\n                if new_weight >= 0:\n                    new_solution[i] = 0\n                    current_weight = new_weight\n\n    out_items = np.where(new_solution == 0)[0]\n    if len(out_items) > 0:\n        utility_metric = (value1_lst[out_items] * (1 - norm_obj1[selected_idx]) + value2_lst[out_items] * (1 - norm_obj2[selected_idx])) / (weight_lst[out_items] + 1e-10)\n        utility_metric += 0.2 * np.random.rand(len(out_items))\n        best_insert = out_items[np.argmax(utility_metric)]\n\n        if (current_weight + weight_lst[best_insert]) <= capacity:\n            new_solution[best_insert] = 1\n            current_weight += weight_lst[best_insert]\n\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        sorted_indices = included_items[np.argsort(-weight_lst[included_items])]\n\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            excess -= weight_lst[i]\n            new_solution[i] = 0\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 304,
        "algorithm": "This algorithm selects a solution from the archive based on diversity scores (prioritizing solutions in less explored regions of the objective space), then applies a hybrid local search: adaptive item swapping (considering both value and weight trade-offs) followed by probabilistic removal of redundant items (prioritizing heavier items). The method ensures feasibility by dynamically adjusting the solution if the capacity is exceeded. The key design choices are diversity-aware selection, weight-aware utility scoring, and probabilistic redundancy removal.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    obj1 = np.array([obj[0] for _, obj in archive])\n    obj2 = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1), np.max(obj2)\n    norm_obj1 = obj1 / (max_obj1 + 1e-10)\n    norm_obj2 = obj2 / (max_obj2 + 1e-10)\n\n    diversity_scores = np.sqrt((norm_obj1 - np.mean(norm_obj1))**2 + (norm_obj2 - np.mean(norm_obj2))**2)\n    selected_idx = np.argmax(diversity_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    if len(in_items) > 0 and len(out_items) > 0:\n        swap_utility = (value1_lst[out_items] * norm_obj1[selected_idx] + value2_lst[out_items] * norm_obj2[selected_idx]) / (weight_lst[out_items] + 1e-10)\n        swap_utility -= 0.1 * np.abs(weight_lst[out_items] - np.mean(weight_lst[in_items]))\n        best_swap = out_items[np.argmax(swap_utility)]\n\n        if (current_weight - weight_lst[in_items[0]] + weight_lst[best_swap]) <= capacity:\n            new_solution[in_items[0]] = 0\n            new_solution[best_swap] = 1\n\n    removal_threshold = 0.7 * np.mean(weight_lst[in_items]) if len(in_items) > 0 else 0\n    for i in in_items:\n        if weight_lst[i] > removal_threshold and random.random() < 0.4:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight >= 0:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        sorted_indices = included_items[np.argsort(weight_lst[included_items])]\n\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            excess -= weight_lst[i]\n            new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8937211450614844,
            1.2873046696186066
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    obj1 = np.array([obj[0] for _, obj in archive])\n    obj2 = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1), np.max(obj2)\n    norm_obj1 = obj1 / (max_obj1 + 1e-10)\n    norm_obj2 = obj2 / (max_obj2 + 1e-10)\n\n    diversity_scores = np.sqrt((norm_obj1 - np.mean(norm_obj1))**2 + (norm_obj2 - np.mean(norm_obj2))**2)\n    selected_idx = np.argmax(diversity_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    if len(in_items) > 0 and len(out_items) > 0:\n        swap_utility = (value1_lst[out_items] * norm_obj1[selected_idx] + value2_lst[out_items] * norm_obj2[selected_idx]) / (weight_lst[out_items] + 1e-10)\n        swap_utility -= 0.1 * np.abs(weight_lst[out_items] - np.mean(weight_lst[in_items]))\n        best_swap = out_items[np.argmax(swap_utility)]\n\n        if (current_weight - weight_lst[in_items[0]] + weight_lst[best_swap]) <= capacity:\n            new_solution[in_items[0]] = 0\n            new_solution[best_swap] = 1\n\n    removal_threshold = 0.7 * np.mean(weight_lst[in_items]) if len(in_items) > 0 else 0\n    for i in in_items:\n        if weight_lst[i] > removal_threshold and random.random() < 0.4:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight >= 0:\n                new_solution[i] = 0\n                current_weight = new_weight\n\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        sorted_indices = included_items[np.argsort(weight_lst[included_items])]\n\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            excess -= weight_lst[i]\n            new_solution[i] = 0\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 3 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThis algorithm employs a diversity-aware selection mechanism that prioritizes solutions with high variance in marginal value-to-weight ratios, followed by a hybrid local search that alternates between targeted inclusion of high-value items and strategic swaps of low-value items with high-weight alternatives, while dynamically balancing exploration and exploitation based on solution quality and ensuring feasibility through a greedy removal process prioritizing high weight-to-value ratios.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Diversity-aware selection: prioritize solutions with high marginal contribution variance\n    diversity_scores = []\n    for sol, _ in archive:\n        included = np.where(sol == 1)[0]\n        if len(included) == 0:\n            diversity_scores.append(0)\n            continue\n\n        # Calculate marginal contributions for included items\n        marginal_contribs1 = value1_lst[included] / weight_lst[included]\n        marginal_contribs2 = value2_lst[included] / weight_lst[included]\n        combined_contribs = marginal_contribs1 + marginal_contribs2\n\n        # Diversity score is the variance of marginal contributions\n        diversity = np.var(combined_contribs)\n        diversity_scores.append(diversity)\n\n    # Select solution with highest diversity score\n    selected_idx = np.argmax(diversity_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate solution quality score (combined value-to-weight ratio)\n    included = np.where(base_solution == 1)[0]\n    if len(included) > 0:\n        total_value1 = np.sum(value1_lst[included])\n        total_value2 = np.sum(value2_lst[included])\n        total_weight = np.sum(weight_lst[included])\n        quality_score = (total_value1 + total_value2) / (total_weight + 1e-8)\n    else:\n        quality_score = 0\n\n    # Dynamic exploration/exploitation trade-off (inverse of original)\n    exploitation_prob = 0.3 + 0.7 * (quality_score / (np.max([obj[0] + obj[1] for _, obj in archive]) + 1e-8))\n\n    # Hybrid local search with different strategy\n    if np.random.rand() < exploitation_prob:\n        # Targeted inclusion of high-value items with low weight\n        not_included = np.where(base_solution == 0)[0]\n        if len(not_included) > 0:\n            # Calculate value-to-weight ratio for not-included items\n            vw_ratios = (value1_lst[not_included] + value2_lst[not_included]) / (weight_lst[not_included] + 1e-8)\n\n            # Select top 20% items with highest value-to-weight ratio\n            top_candidates = not_included[np.argsort(vw_ratios)[-max(1, len(not_included)//5):]]\n\n            for item in top_candidates:\n                if np.random.rand() < 0.6:  # 60% chance to include each top candidate\n                    if (np.sum(weight_lst[new_solution == 1]) + weight_lst[item]) <= capacity:\n                        new_solution[item] = 1\n    else:\n        # Probabilistic swap of low-value items with high-weight items\n        included = np.where(base_solution == 1)[0]\n        not_included = np.where(base_solution == 0)[0]\n\n        if len(included) > 0 and len(not_included) > 0:\n            # Find low-value items to potentially remove\n            removal_ratios = (value1_lst[included] + value2_lst[included]) / (weight_lst[included] + 1e-8)\n            low_value_items = included[np.argsort(removal_ratios)[:max(1, len(included)//4)]]\n\n            # Find high-weight items to potentially add\n            high_weight_items = not_included[np.argsort(weight_lst[not_included])[-max(1, len(not_included)//4):]]\n\n            for remove_item in low_value_items:\n                for add_item in high_weight_items:\n                    if (np.sum(weight_lst[new_solution == 1]) - weight_lst[remove_item] + weight_lst[add_item]) <= capacity:\n                        new_solution[remove_item] = 0\n                        new_solution[add_item] = 1\n                        break\n\n    # Feasibility enforcement (different priority calculation)\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        # Calculate removal priorities (highest weight-to-value ratio)\n        removal_priorities = (weight_lst[included_items] + 1e-8) / (value1_lst[included_items] + value2_lst[included_items] + 1e-8)\n        sorted_indices = included_items[np.argsort(removal_priorities)[::-1]]  # Descending order\n\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            excess -= weight_lst[i]\n            new_solution[i] = 0\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm combines Pareto filtering with objective-space partitioning to select a diverse, high-potential solution from the archive, then applies a hybrid local search featuring adaptive flipping (based on negative objective gradients) and correlation-aware swapping (probabilistically guided by objective correlation) to generate neighbors while maintaining feasibility through probabilistic capacity adjustment. It prioritizes items with high value-to-weight ratios during removal when capacity is exceeded.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Diversity-aware selection with Pareto filtering\n    pareto_front = []\n    for sol, obj in archive:\n        dominated = False\n        for i, (_, other_obj) in enumerate(pareto_front):\n            if other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append((sol, obj))\n\n    if not pareto_front:\n        pareto_front = archive\n\n    # Objective-space partitioning\n    obj1 = np.array([obj[0] for _, obj in pareto_front])\n    obj2 = np.array([obj[1] for _, obj in pareto_front])\n    max_obj1, max_obj2 = np.max(obj1), np.max(obj2)\n    min_obj1, min_obj2 = np.min(obj1), np.min(obj2)\n\n    # Select solution from under-represented region\n    density = np.zeros(len(pareto_front))\n    for i in range(len(pareto_front)):\n        dist1 = (obj1[i] - min_obj1) / (max_obj1 - min_obj1 + 1e-10)\n        dist2 = (obj2[i] - min_obj2) / (max_obj2 - min_obj2 + 1e-10)\n        density[i] = dist1 + dist2\n\n    selected_idx = np.argmin(density)\n    base_solution = pareto_front[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Adaptive flipping based on objective gradients\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    if len(in_items) > 0:\n        # Calculate objective gradients\n        obj1_grad = (value1_lst[in_items] - np.mean(value1_lst[in_items])) / (np.std(value1_lst[in_items]) + 1e-10)\n        obj2_grad = (value2_lst[in_items] - np.mean(value2_lst[in_items])) / (np.std(value2_lst[in_items]) + 1e-10)\n\n        # Flip items with high negative gradients\n        flip_mask = (obj1_grad < -0.5) | (obj2_grad < -0.5)\n        for i in in_items[flip_mask]:\n            if current_weight - weight_lst[i] >= 0:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n\n    # Correlation-aware swapping\n    if len(out_items) > 0 and len(in_items) > 0:\n        # Calculate correlation between objectives\n        obj_corr = np.corrcoef(value1_lst[in_items], value2_lst[in_items])[0, 1]\n        swap_prob = 0.5 * (1 + obj_corr)\n\n        if random.random() < swap_prob:\n            # Select item to remove based on combined value\n            combined_value = value1_lst[in_items] + value2_lst[in_items]\n            remove_idx = in_items[np.argmin(combined_value)]\n\n            # Select item to add based on marginal gain\n            marginal_gain = (value1_lst[out_items] + value2_lst[out_items]) / weight_lst[out_items]\n            add_idx = out_items[np.argmax(marginal_gain)]\n\n            if (current_weight - weight_lst[remove_idx] + weight_lst[add_idx]) <= capacity:\n                new_solution[remove_idx] = 0\n                new_solution[add_idx] = 1\n\n    # Probabilistic capacity adjustment\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        # Calculate removal probabilities based on value-to-weight ratio\n        value_ratio = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n        removal_probs = value_ratio / np.sum(value_ratio)\n\n        while excess > 0 and len(included_items) > 0:\n            removal_idx = np.random.choice(included_items, p=removal_probs)\n            excess -= weight_lst[removal_idx]\n            new_solution[removal_idx] = 0\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) > 0:\n                value_ratio = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n                removal_probs = value_ratio / np.sum(value_ratio)\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive based on its trade-off between objectives (prioritizing extreme ratios), then applies a hybrid local search that probabilistically removes items (with higher probability for solutions with better value ratios) and inserts items using a utility metric that balances both objectives while considering weight efficiency, all while ensuring feasibility through adaptive removal of heaviest items if necessary. The utility metric dynamically adjusts based on the selected solution's objective trade-off, favoring items that complement the current solution's weaknesses.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    obj1 = np.array([obj[0] for _, obj in archive])\n    obj2 = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1), np.max(obj2)\n    norm_obj1 = obj1 / (max_obj1 + 1e-10)\n    norm_obj2 = obj2 / (max_obj2 + 1e-10)\n\n    tradeoff_scores = np.abs(norm_obj1 - norm_obj2)\n    selected_idx = np.argmax(tradeoff_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    obj_ratio = norm_obj1[selected_idx] / (norm_obj2[selected_idx] + 1e-10)\n    removal_prob = 0.3 + 0.5 * (1 - np.exp(-obj_ratio))\n\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        for i in in_items:\n            if random.random() < removal_prob:\n                new_weight = current_weight - weight_lst[i]\n                if new_weight >= 0:\n                    new_solution[i] = 0\n                    current_weight = new_weight\n\n    out_items = np.where(new_solution == 0)[0]\n    if len(out_items) > 0:\n        utility_metric = (value1_lst[out_items] * (1 - norm_obj1[selected_idx]) + value2_lst[out_items] * (1 - norm_obj2[selected_idx])) / (weight_lst[out_items] + 1e-10)\n        utility_metric += 0.2 * np.random.rand(len(out_items))\n        best_insert = out_items[np.argmax(utility_metric)]\n\n        if (current_weight + weight_lst[best_insert]) <= capacity:\n            new_solution[best_insert] = 1\n            current_weight += weight_lst[best_insert]\n\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        sorted_indices = included_items[np.argsort(-weight_lst[included_items])]\n\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            excess -= weight_lst[i]\n            new_solution[i] = 0\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: - **Keywords**: Hypervolume-guided selection, correlation-aware local search, adaptive marginal thresholds, probabilistic swaps, feasibility enforcement.\n- **Advice**: Prioritize solutions with high hypervolume and objective correlations; dynamically adjust flip/swap probabilities based on marginal gains; enforce feasibility via greedy excess removal; sample solutions with high diversity.\n- **Avoid**: Static local search (e.g., 2-opt), uniform selection, infeasible weight overflow, randomness without objective guidance.\n- **Explanation**: The heuristic balances exploration (hypervolume-guided selection) and exploitation (correlation-aware flips), ensures feasibility, and avoids local optima via adaptive thresholds and intelligent sampling. This ensures high-quality, feasible neighbors while avoiding pitfalls of ineffectiveness.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 305,
        "algorithm": "The algorithm selects a solution from the archive prioritizing those with high hypervolume contribution and objective correlation, then applies a hybrid local search that adaptively removes low-value items and probabilistically swaps items based on dynamic marginal thresholds, while enforcing feasibility through greedy excess removal and prioritizing items with high combined value-to-weight ratios. The method emphasizes objective-aware selection and adaptive neighborhood exploration while maintaining feasibility constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Hypervolume-guided selection\n    obj1 = np.array([obj[0] for _, obj in archive])\n    obj2 = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1), np.max(obj2)\n\n    # Calculate hypervolume contribution for each solution\n    hv_contribs = []\n    for i in range(len(archive)):\n        contrib = (max_obj1 - obj1[i]) * (max_obj2 - obj2[i])\n        hv_contribs.append(contrib)\n\n    # Calculate objective correlations\n    obj_corr = np.corrcoef(obj1, obj2)[0, 1]\n\n    # Combine scores (prioritize high hypervolume and high correlation)\n    combined_scores = np.array(hv_contribs) * (1 + obj_corr)\n\n    # Select solution with highest combined score\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate current marginal thresholds\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        marginal1 = value1_lst[in_items] / weight_lst[in_items]\n        marginal2 = value2_lst[in_items] / weight_lst[in_items]\n        avg_marginal1, avg_marginal2 = np.mean(marginal1), np.mean(marginal2)\n\n        # Flip items with negative marginal gains\n        for i in in_items:\n            if (value1_lst[i] / weight_lst[i] < avg_marginal1 and random.random() < 0.7) or \\\n               (value2_lst[i] / weight_lst[i] < avg_marginal2 and random.random() < 0.7):\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Probabilistic swapping based on dynamic thresholds\n    out_items = np.where(new_solution == 0)[0]\n    if len(out_items) > 0 and len(in_items) > 0:\n        # Calculate dynamic thresholds\n        threshold1 = np.percentile(value1_lst[out_items] / weight_lst[out_items], 70)\n        threshold2 = np.percentile(value2_lst[out_items] / weight_lst[out_items], 70)\n\n        # Find candidate items to swap\n        candidates = []\n        for i in out_items:\n            if (value1_lst[i] / weight_lst[i] > threshold1) or (value2_lst[i] / weight_lst[i] > threshold2):\n                candidates.append(i)\n\n        if candidates:\n            # Select random candidate to add\n            add_item = random.choice(candidates)\n\n            # Select item to remove based on combined value-to-weight ratio\n            removal_ratios = (value1_lst[in_items] + value2_lst[in_items]) / weight_lst[in_items]\n            remove_item = in_items[np.argmin(removal_ratios)]\n\n            if (current_weight - weight_lst[remove_item] + weight_lst[add_item]) <= capacity:\n                new_solution[remove_item] = 0\n                new_solution[add_item] = 1\n\n    # Feasibility enforcement\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        # Remove items with highest weight-to-value ratio\n        removal_priorities = weight_lst[included_items] / (value1_lst[included_items] + value2_lst[included_items] + 1e-10)\n        sorted_indices = included_items[np.argsort(removal_priorities)[::-1]]\n\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            excess -= weight_lst[i]\n            new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9352180457182996,
            4.793694704771042
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Hypervolume-guided selection\n    obj1 = np.array([obj[0] for _, obj in archive])\n    obj2 = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1), np.max(obj2)\n\n    # Calculate hypervolume contribution for each solution\n    hv_contribs = []\n    for i in range(len(archive)):\n        contrib = (max_obj1 - obj1[i]) * (max_obj2 - obj2[i])\n        hv_contribs.append(contrib)\n\n    # Calculate objective correlations\n    obj_corr = np.corrcoef(obj1, obj2)[0, 1]\n\n    # Combine scores (prioritize high hypervolume and high correlation)\n    combined_scores = np.array(hv_contribs) * (1 + obj_corr)\n\n    # Select solution with highest combined score\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate current marginal thresholds\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        marginal1 = value1_lst[in_items] / weight_lst[in_items]\n        marginal2 = value2_lst[in_items] / weight_lst[in_items]\n        avg_marginal1, avg_marginal2 = np.mean(marginal1), np.mean(marginal2)\n\n        # Flip items with negative marginal gains\n        for i in in_items:\n            if (value1_lst[i] / weight_lst[i] < avg_marginal1 and random.random() < 0.7) or \\\n               (value2_lst[i] / weight_lst[i] < avg_marginal2 and random.random() < 0.7):\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Probabilistic swapping based on dynamic thresholds\n    out_items = np.where(new_solution == 0)[0]\n    if len(out_items) > 0 and len(in_items) > 0:\n        # Calculate dynamic thresholds\n        threshold1 = np.percentile(value1_lst[out_items] / weight_lst[out_items], 70)\n        threshold2 = np.percentile(value2_lst[out_items] / weight_lst[out_items], 70)\n\n        # Find candidate items to swap\n        candidates = []\n        for i in out_items:\n            if (value1_lst[i] / weight_lst[i] > threshold1) or (value2_lst[i] / weight_lst[i] > threshold2):\n                candidates.append(i)\n\n        if candidates:\n            # Select random candidate to add\n            add_item = random.choice(candidates)\n\n            # Select item to remove based on combined value-to-weight ratio\n            removal_ratios = (value1_lst[in_items] + value2_lst[in_items]) / weight_lst[in_items]\n            remove_item = in_items[np.argmin(removal_ratios)]\n\n            if (current_weight - weight_lst[remove_item] + weight_lst[add_item]) <= capacity:\n                new_solution[remove_item] = 0\n                new_solution[add_item] = 1\n\n    # Feasibility enforcement\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        # Remove items with highest weight-to-value ratio\n        removal_priorities = weight_lst[included_items] / (value1_lst[included_items] + value2_lst[included_items] + 1e-10)\n        sorted_indices = included_items[np.argsort(removal_priorities)[::-1]]\n\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            excess -= weight_lst[i]\n            new_solution[i] = 0\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a solution from the archive based on its trade-off between objectives (prioritizing extreme ratios), then applies a hybrid local search that probabilistically removes items (with higher probability for solutions with better value ratios) and inserts items using a utility metric that balances both objectives while considering weight efficiency, all while ensuring feasibility through adaptive removal of heaviest items if necessary. The utility metric dynamically adjusts based on the selected solution's objective trade-off, favoring items that complement the current solution's weaknesses.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    obj1 = np.array([obj[0] for _, obj in archive])\n    obj2 = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1), np.max(obj2)\n    norm_obj1 = obj1 / (max_obj1 + 1e-10)\n    norm_obj2 = obj2 / (max_obj2 + 1e-10)\n\n    tradeoff_scores = np.abs(norm_obj1 - norm_obj2)\n    selected_idx = np.argmax(tradeoff_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    obj_ratio = norm_obj1[selected_idx] / (norm_obj2[selected_idx] + 1e-10)\n    removal_prob = 0.3 + 0.5 * (1 - np.exp(-obj_ratio))\n\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        for i in in_items:\n            if random.random() < removal_prob:\n                new_weight = current_weight - weight_lst[i]\n                if new_weight >= 0:\n                    new_solution[i] = 0\n                    current_weight = new_weight\n\n    out_items = np.where(new_solution == 0)[0]\n    if len(out_items) > 0:\n        utility_metric = (value1_lst[out_items] * (1 - norm_obj1[selected_idx]) + value2_lst[out_items] * (1 - norm_obj2[selected_idx])) / (weight_lst[out_items] + 1e-10)\n        utility_metric += 0.2 * np.random.rand(len(out_items))\n        best_insert = out_items[np.argmax(utility_metric)]\n\n        if (current_weight + weight_lst[best_insert]) <= capacity:\n            new_solution[best_insert] = 1\n            current_weight += weight_lst[best_insert]\n\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        sorted_indices = included_items[np.argsort(-weight_lst[included_items])]\n\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            excess -= weight_lst[i]\n            new_solution[i] = 0\n\n    return new_solution\n\n\n        \n        Your **sole objective** is to reduce the runtime of the algorithm as much as possible.\n        Ignore any performance metrics other than runtime.\n        \n        Please create a new algorithm that is a modified, faster version of the provided one.\n        Focus on optimizations such as reducing algorithmic complexity, improving loops,\n        using efficient data structures, removing redundant computations, and simplifying logic.\n        \n        1. First, identify parts of the code that most likely cause high runtime and suggest optimizations.\n        2. Next, describe your new optimized algorithm and its main steps in one detailed sentence. The description must be inside boxed {}.\n        3. Finally, implement the optimized algorithm in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        \n        Check syntax and code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 306,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Precompute normalized objectives and tradeoff scores\n    obj1 = np.array([obj[0] for _, obj in archive])\n    obj2 = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1), np.max(obj2)\n    norm_obj1 = obj1 / (max_obj1 + 1e-10)\n    norm_obj2 = obj2 / (max_obj2 + 1e-10)\n    tradeoff_scores = np.abs(norm_obj1 - norm_obj2)\n\n    # Select solution with highest tradeoff score\n    selected_idx = np.argmax(tradeoff_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight using vectorized operation\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Precompute removal probability and utility weights\n    obj_ratio = norm_obj1[selected_idx] / (norm_obj2[selected_idx] + 1e-10)\n    removal_prob = 0.3 + 0.5 * (1 - np.exp(-obj_ratio))\n    utility_weight1 = 1 - norm_obj1[selected_idx]\n    utility_weight2 = 1 - norm_obj2[selected_idx]\n\n    # Vectorized removal of items\n    in_mask = new_solution == 1\n    if np.any(in_mask):\n        remove_mask = np.random.random(np.sum(in_mask)) < removal_prob\n        in_indices = np.where(in_mask)[0]\n        to_remove = in_indices[remove_mask]\n        new_solution[to_remove] = 0\n        current_weight -= np.sum(weight_lst[to_remove])\n\n    # Vectorized insertion of best item\n    out_mask = new_solution == 0\n    if np.any(out_mask):\n        out_indices = np.where(out_mask)[0]\n        utility = (value1_lst[out_indices] * utility_weight1 +\n                  value2_lst[out_indices] * utility_weight2) / (weight_lst[out_indices] + 1e-10)\n        utility += 0.2 * np.random.random(len(out_indices))\n        best_insert = out_indices[np.argmax(utility)]\n\n        if (current_weight + weight_lst[best_insert]) <= capacity:\n            new_solution[best_insert] = 1\n            current_weight += weight_lst[best_insert]\n\n    # Vectorized excess weight removal\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        included_indices = np.where(new_solution == 1)[0]\n        sorted_indices = included_indices[np.argsort(-weight_lst[included_indices])]\n\n        cumulative_weights = np.cumsum(weight_lst[sorted_indices])\n        remove_count = np.searchsorted(cumulative_weights, excess, side='right')\n        new_solution[sorted_indices[:remove_count]] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8725841098063656,
            1.071774184703827
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Precompute normalized objectives and tradeoff scores\n    obj1 = np.array([obj[0] for _, obj in archive])\n    obj2 = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1), np.max(obj2)\n    norm_obj1 = obj1 / (max_obj1 + 1e-10)\n    norm_obj2 = obj2 / (max_obj2 + 1e-10)\n    tradeoff_scores = np.abs(norm_obj1 - norm_obj2)\n\n    # Select solution with highest tradeoff score\n    selected_idx = np.argmax(tradeoff_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight using vectorized operation\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Precompute removal probability and utility weights\n    obj_ratio = norm_obj1[selected_idx] / (norm_obj2[selected_idx] + 1e-10)\n    removal_prob = 0.3 + 0.5 * (1 - np.exp(-obj_ratio))\n    utility_weight1 = 1 - norm_obj1[selected_idx]\n    utility_weight2 = 1 - norm_obj2[selected_idx]\n\n    # Vectorized removal of items\n    in_mask = new_solution == 1\n    if np.any(in_mask):\n        remove_mask = np.random.random(np.sum(in_mask)) < removal_prob\n        in_indices = np.where(in_mask)[0]\n        to_remove = in_indices[remove_mask]\n        new_solution[to_remove] = 0\n        current_weight -= np.sum(weight_lst[to_remove])\n\n    # Vectorized insertion of best item\n    out_mask = new_solution == 0\n    if np.any(out_mask):\n        out_indices = np.where(out_mask)[0]\n        utility = (value1_lst[out_indices] * utility_weight1 +\n                  value2_lst[out_indices] * utility_weight2) / (weight_lst[out_indices] + 1e-10)\n        utility += 0.2 * np.random.random(len(out_indices))\n        best_insert = out_indices[np.argmax(utility)]\n\n        if (current_weight + weight_lst[best_insert]) <= capacity:\n            new_solution[best_insert] = 1\n            current_weight += weight_lst[best_insert]\n\n    # Vectorized excess weight removal\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        included_indices = np.where(new_solution == 1)[0]\n        sorted_indices = included_indices[np.argsort(-weight_lst[included_indices])]\n\n        cumulative_weights = np.cumsum(weight_lst[sorted_indices])\n        remove_count = np.searchsorted(cumulative_weights, excess, side='right')\n        new_solution[sorted_indices[:remove_count]] = 0\n\n    return new_solution\n\n",
        "operation": "r1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a solution from the archive based on its trade-off between objectives (prioritizing extreme ratios), then applies a hybrid local search that probabilistically removes items (with higher probability for solutions with better value ratios) and inserts items using a utility metric that balances both objectives while considering weight efficiency, all while ensuring feasibility through adaptive removal of heaviest items if necessary. The utility metric dynamically adjusts based on the selected solution's objective trade-off, favoring items that complement the current solution's weaknesses.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    obj1 = np.array([obj[0] for _, obj in archive])\n    obj2 = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1), np.max(obj2)\n    norm_obj1 = obj1 / (max_obj1 + 1e-10)\n    norm_obj2 = obj2 / (max_obj2 + 1e-10)\n\n    tradeoff_scores = np.abs(norm_obj1 - norm_obj2)\n    selected_idx = np.argmax(tradeoff_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    obj_ratio = norm_obj1[selected_idx] / (norm_obj2[selected_idx] + 1e-10)\n    removal_prob = 0.3 + 0.5 * (1 - np.exp(-obj_ratio))\n\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        for i in in_items:\n            if random.random() < removal_prob:\n                new_weight = current_weight - weight_lst[i]\n                if new_weight >= 0:\n                    new_solution[i] = 0\n                    current_weight = new_weight\n\n    out_items = np.where(new_solution == 0)[0]\n    if len(out_items) > 0:\n        utility_metric = (value1_lst[out_items] * (1 - norm_obj1[selected_idx]) + value2_lst[out_items] * (1 - norm_obj2[selected_idx])) / (weight_lst[out_items] + 1e-10)\n        utility_metric += 0.2 * np.random.rand(len(out_items))\n        best_insert = out_items[np.argmax(utility_metric)]\n\n        if (current_weight + weight_lst[best_insert]) <= capacity:\n            new_solution[best_insert] = 1\n            current_weight += weight_lst[best_insert]\n\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        sorted_indices = included_items[np.argsort(-weight_lst[included_items])]\n\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            excess -= weight_lst[i]\n            new_solution[i] = 0\n\n    return new_solution\n\n\n        \n        Your **sole objective** is to reduce the runtime of the algorithm as much as possible.\n        Ignore any performance metrics other than runtime.\n        \n        Please create a new algorithm that is a modified, faster version of the provided one.\n        Focus on optimizations such as reducing algorithmic complexity, improving loops,\n        using efficient data structures, removing redundant computations, and simplifying logic.\n        \n        1. First, identify parts of the code that most likely cause high runtime and suggest optimizations.\n        2. Next, describe your new optimized algorithm and its main steps in one detailed sentence. The description must be inside boxed {}.\n        3. Finally, implement the optimized algorithm in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        \n        Check syntax and code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 307,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Precompute all objectives and normalize\n    obj1 = np.array([obj[0] for _, obj in archive])\n    obj2 = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1), np.max(obj2)\n    norm_obj1 = obj1 / (max_obj1 + 1e-10)\n    norm_obj2 = obj2 / (max_obj2 + 1e-10)\n\n    # Select solution with most extreme tradeoff\n    tradeoff_scores = np.abs(norm_obj1 - norm_obj2)\n    selected_idx = np.argmax(tradeoff_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Precompute removal probabilities and item indices\n    obj_ratio = norm_obj1[selected_idx] / (norm_obj2[selected_idx] + 1e-10)\n    removal_prob = 0.3 + 0.5 * (1 - np.exp(-obj_ratio))\n    in_items = np.where(new_solution == 1)[0]\n\n    # Vectorized removal\n    if len(in_items) > 0:\n        remove_mask = (np.random.random(len(in_items)) < removal_prob)\n        remove_items = in_items[remove_mask]\n        if len(remove_items) > 0:\n            new_solution[remove_items] = 0\n            current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Precompute utility metric for insertion\n    out_items = np.where(new_solution == 0)[0]\n    if len(out_items) > 0:\n        utility_metric = (value1_lst[out_items] * (1 - norm_obj1[selected_idx]) +\n                         value2_lst[out_items] * (1 - norm_obj2[selected_idx])) / (weight_lst[out_items] + 1e-10)\n        utility_metric += 0.2 * np.random.random(len(out_items))\n        best_insert = out_items[np.argmax(utility_metric)]\n\n        if (current_weight + weight_lst[best_insert]) <= capacity:\n            new_solution[best_insert] = 1\n\n    # Final feasibility check\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        sorted_indices = included_items[np.argsort(-weight_lst[included_items])]\n\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            excess -= weight_lst[i]\n            new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8406180176352505,
            0.9648355841636658
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Precompute all objectives and normalize\n    obj1 = np.array([obj[0] for _, obj in archive])\n    obj2 = np.array([obj[1] for _, obj in archive])\n    max_obj1, max_obj2 = np.max(obj1), np.max(obj2)\n    norm_obj1 = obj1 / (max_obj1 + 1e-10)\n    norm_obj2 = obj2 / (max_obj2 + 1e-10)\n\n    # Select solution with most extreme tradeoff\n    tradeoff_scores = np.abs(norm_obj1 - norm_obj2)\n    selected_idx = np.argmax(tradeoff_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Precompute removal probabilities and item indices\n    obj_ratio = norm_obj1[selected_idx] / (norm_obj2[selected_idx] + 1e-10)\n    removal_prob = 0.3 + 0.5 * (1 - np.exp(-obj_ratio))\n    in_items = np.where(new_solution == 1)[0]\n\n    # Vectorized removal\n    if len(in_items) > 0:\n        remove_mask = (np.random.random(len(in_items)) < removal_prob)\n        remove_items = in_items[remove_mask]\n        if len(remove_items) > 0:\n            new_solution[remove_items] = 0\n            current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Precompute utility metric for insertion\n    out_items = np.where(new_solution == 0)[0]\n    if len(out_items) > 0:\n        utility_metric = (value1_lst[out_items] * (1 - norm_obj1[selected_idx]) +\n                         value2_lst[out_items] * (1 - norm_obj2[selected_idx])) / (weight_lst[out_items] + 1e-10)\n        utility_metric += 0.2 * np.random.random(len(out_items))\n        best_insert = out_items[np.argmax(utility_metric)]\n\n        if (current_weight + weight_lst[best_insert]) <= capacity:\n            new_solution[best_insert] = 1\n\n    # Final feasibility check\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        sorted_indices = included_items[np.argsort(-weight_lst[included_items])]\n\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            excess -= weight_lst[i]\n            new_solution[i] = 0\n\n    return new_solution\n\n",
        "operation": "r1"
    }
]