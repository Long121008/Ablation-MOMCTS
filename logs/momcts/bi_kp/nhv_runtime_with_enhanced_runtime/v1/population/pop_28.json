[
    {
        "algorithm": "The algorithm selects the most promising solution from the archive (based on the product of its two objective values) and applies a hybrid local search strategy: it first tries a random item swap (if feasible) and then probabilistically flips items with low marginal contribution, ensuring feasibility by removing excess items if needed. The approach balances exploration (via random swaps and flips) and exploitation (focusing on high-potential solutions) while strictly enforcing capacity constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select the solution with the highest potential (product of objectives)\n    potentials = [obj[0] * obj[1] for _, obj in archive]\n    selected_idx = np.argmax(potentials)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Generate a neighbor solution using hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Strategy 1: Randomly swap two items (if feasible)\n    if n_items >= 2:\n        swap_indices = np.random.choice(n_items, 2, replace=False)\n        if new_solution[swap_indices[0]] != new_solution[swap_indices[1]]:\n            # Check feasibility\n            if new_solution[swap_indices[0]] == 1:\n                new_weight = current_weight - weight_lst[swap_indices[0]] + weight_lst[swap_indices[1]]\n            else:\n                new_weight = current_weight + weight_lst[swap_indices[0]] - weight_lst[swap_indices[1]]\n            if new_weight <= capacity:\n                new_solution[swap_indices[0]], new_solution[swap_indices[1]] = new_solution[swap_indices[1]], new_solution[swap_indices[0]]\n\n    # Strategy 2: Probabilistic flip of items with low marginal contribution\n    for i in range(n_items):\n        if np.random.rand() < 0.2:  # 20% chance to flip\n            if new_solution[i] == 1:\n                new_weight = current_weight - weight_lst[i]\n                if new_weight >= 0:  # Ensure non-negative weight (though capacity check is more important)\n                    new_solution[i] = 0\n            else:\n                new_weight = current_weight + weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i] = 1\n\n    # Ensure feasibility (in case of multiple changes)\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items until feasible\n        excess = total_weight - capacity\n        while excess > 0:\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break\n            remove_idx = np.random.choice(included_items)\n            excess -= weight_lst[remove_idx]\n            new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8969946250886272,
            2.1612739861011505
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using a weighted sum of normalized objectives (70% value1, 30% value2), then applies a hybrid local search combining probabilistic swaps, marginal contribution-based flips, and a greedy removal step to ensure feasibility. It dynamically balances exploration/exploitation based on archive size, with higher probabilities for marginal improvements and feasibility checks. The method prioritizes solutions with better combined objective scores while intelligently modifying them to improve both objectives while respecting capacity constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Normalize objectives and compute combined scores\n    obj1 = np.array([obj[0] for _, obj in archive])\n    obj2 = np.array([obj[1] for _, obj in archive])\n    norm_obj1 = (obj1 - np.min(obj1)) / (np.max(obj1) - np.min(obj1) + 1e-8)\n    norm_obj2 = (obj2 - np.min(obj2)) / (np.max(obj2) - np.min(obj2) + 1e-8)\n    combined_scores = 0.7 * norm_obj1 + 0.3 * norm_obj2  # Weighted sum\n\n    # Select solution with highest combined score\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Dynamic exploration/exploitation trade-off\n    exploration_prob = 0.5 + 0.5 * (1 - len(archive) / 100)  # Higher exploration for small archives\n\n    # Strategy 1: Probabilistic item swap with feasibility check\n    if np.random.rand() < exploration_prob and n_items >= 2:\n        swap_indices = np.random.choice(n_items, 2, replace=False)\n        if new_solution[swap_indices[0]] != new_solution[swap_indices[1]]:\n            # Check feasibility\n            delta = (weight_lst[swap_indices[1]] - weight_lst[swap_indices[0]]) if new_solution[swap_indices[0]] == 1 else (weight_lst[swap_indices[0]] - weight_lst[swap_indices[1]])\n            if current_weight + delta <= capacity:\n                new_solution[swap_indices[0]], new_solution[swap_indices[1]] = new_solution[swap_indices[1]], new_solution[swap_indices[0]]\n\n    # Strategy 2: Marginal contribution-based flips\n    for i in range(n_items):\n        if np.random.rand() < 0.3:  # Higher probability than original\n            if new_solution[i] == 1:\n                # Check if removing improves both objectives\n                marginal1 = -value1_lst[i]\n                marginal2 = -value2_lst[i]\n                if marginal1 < 0 or marginal2 < 0:  # Negative marginal\n                    new_weight = current_weight - weight_lst[i]\n                    if new_weight >= 0:\n                        new_solution[i] = 0\n            else:\n                # Check if adding improves both objectives\n                marginal1 = value1_lst[i]\n                marginal2 = value2_lst[i]\n                if marginal1 > 0 and marginal2 > 0:  # Positive marginal\n                    new_weight = current_weight + weight_lst[i]\n                    if new_weight <= capacity:\n                        new_solution[i] = 1\n\n    # Strategy 3: Greedy removal for feasibility\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Sort items by weight/value ratio and remove until feasible\n        included_items = np.where(new_solution == 1)[0]\n        ratios = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n        sorted_indices = included_items[np.argsort(ratios)]\n        excess = total_weight - capacity\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            excess -= weight_lst[i]\n            new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9450039798002199,
            2.6820522248744965
        ]
    },
    {
        "algorithm": "The algorithm implements a diversity-aware selection strategy that prioritizes solutions with high potential for improvement, followed by a hybrid local search combining random flips (60% chance) for items already in the solution and a value-aware swap (40% chance) that intelligently selects high-value items to add while removing low-value items to maintain feasibility. The value-aware swap specifically targets items with top 40% combined value-to-weight ratios, ensuring both objectives are balanced.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (diversity-aware)\n    selected_idx = random.choices(range(len(archive)), weights=[1/(1 + i) for i in range(len(archive))])[0]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random flip with value-aware swap\n    if random.random() < 0.6:  # 60% chance for random flip\n        # Randomly flip items that could improve either objective\n        candidates = np.where(base_solution == 1)[0]\n        if len(candidates) > 0:\n            flip_idx = random.choice(candidates)\n            new_solution[flip_idx] = 0\n    else:  # 40% chance for value-aware swap\n        # Find items not in solution with high value ratios\n        not_in_solution = np.where(base_solution == 0)[0]\n        if len(not_in_solution) > 0:\n            # Calculate value ratios (value1/weight and value2/weight)\n            ratios1 = value1_lst[not_in_solution] / weight_lst[not_in_solution]\n            ratios2 = value2_lst[not_in_solution] / weight_lst[not_in_solution]\n            combined_ratios = ratios1 + ratios2\n\n            # Select top 40% candidates by combined ratio\n            top_candidates = not_in_solution[np.argsort(combined_ratios)[-max(1, len(combined_ratios)//2):]]\n            if len(top_candidates) > 0:\n                swap_in = random.choice(top_candidates)\n\n                # Find items in solution with low value ratios to swap out\n                in_solution = np.where(base_solution == 1)[0]\n                if len(in_solution) > 0:\n                    ratios1_in = value1_lst[in_solution] / weight_lst[in_solution]\n                    ratios2_in = value2_lst[in_solution] / weight_lst[in_solution]\n                    combined_ratios_in = ratios1_in + ratios2_in\n                    swap_out = in_solution[np.argmin(combined_ratios_in)]\n\n                    # Perform swap if feasible\n                    if (np.sum(weight_lst[new_solution == 1]) - weight_lst[swap_out] + weight_lst[swap_in]) <= capacity:\n                        new_solution[swap_out] = 0\n                        new_solution[swap_in] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.5493558789167777,
            1.034000277519226
        ]
    },
    {
        "algorithm": "This algorithm implements a crowding-distance-aware selection strategy that prioritizes solutions near the Pareto front boundaries, followed by a hybrid local search combining probabilistic swaps (70% chance) that favor high-margin items and a value-aware removal (30% chance) that intelligently eliminates low-impact items while maintaining feasibility. The selection process uses crowding distance to identify crowded regions of the Pareto front, while the local search alternates between swapping high-margin items and removing low-value items to explore the solution space effectively.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution near Pareto front boundaries using crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    if len(objectives) == 1:\n        selected_idx = 0\n    else:\n        # Calculate crowding distance for each objective\n        crowding_dist = np.zeros(len(objectives))\n        for i in range(2):\n            sorted_idx = np.argsort(objectives[:, i])\n            crowding_dist[sorted_idx[0]] = np.inf\n            crowding_dist[sorted_idx[-1]] = np.inf\n            for j in range(1, len(objectives)-1):\n                crowding_dist[sorted_idx[j]] += (objectives[sorted_idx[j+1], i] - objectives[sorted_idx[j-1], i]) / (objectives[sorted_idx[-1], i] - objectives[sorted_idx[0], i])\n\n        # Select solution with lowest crowding distance (most crowded)\n        selected_idx = np.argmin(crowding_dist)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: probabilistic swap with value-aware removal\n    if random.random() < 0.7:  # 70% chance for probabilistic swap\n        # Calculate value margins for both objectives\n        in_items = np.where(base_solution == 1)[0]\n        not_in_items = np.where(base_solution == 0)[0]\n\n        if len(in_items) > 0 and len(not_in_items) > 0:\n            # Calculate marginal gains for not-in items\n            marginal_gain1 = value1_lst[not_in_items] / weight_lst[not_in_items]\n            marginal_gain2 = value2_lst[not_in_items] / weight_lst[not_in_items]\n            combined_gains = marginal_gain1 + marginal_gain2\n\n            # Select item with highest combined gain\n            swap_in = not_in_items[np.argmax(combined_gains)]\n\n            # Calculate marginal losses for in items\n            marginal_loss1 = value1_lst[in_items] / weight_lst[in_items]\n            marginal_loss2 = value2_lst[in_items] / weight_lst[in_items]\n            combined_losses = marginal_loss1 + marginal_loss2\n\n            # Select item with lowest combined loss\n            swap_out = in_items[np.argmin(combined_losses)]\n\n            # Perform swap if feasible\n            if (np.sum(weight_lst[new_solution == 1]) - weight_lst[swap_out] + weight_lst[swap_in]) <= capacity:\n                new_solution[swap_out] = 0\n                new_solution[swap_in] = 1\n    else:  # 30% chance for value-aware removal\n        # Remove items with lowest combined value-to-weight ratio\n        in_items = np.where(base_solution == 1)[0]\n        if len(in_items) > 1:  # Need at least one item to remain\n            ratios1 = value1_lst[in_items] / weight_lst[in_items]\n            ratios2 = value2_lst[in_items] / weight_lst[in_items]\n            combined_ratios = ratios1 + ratios2\n            remove_idx = in_items[np.argmin(combined_ratios)]\n            new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9585816545487339,
            3.386291205883026
        ]
    },
    {
        "algorithm": "The algorithm combines a diversity-aware selection strategy with a hybrid local search that dynamically balances marginal contribution flips (70% probability) and value-aware swaps (30% probability), prioritizing solutions with high combined objective ratios while ensuring feasibility through greedy excess removal. It intelligently samples from the archive using a combined objective ratio to guide exploration, dynamically adjusting between exploration and exploitation based on archive size, and always maintains feasibility through strict capacity checks and greedy removal steps.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Calculate combined objective ratios for selection\n    obj1 = np.array([obj[0] for _, obj in archive])\n    obj2 = np.array([obj[1] for _, obj in archive])\n    combined_ratios = (obj1 + obj2) / (np.sum(weight_lst) + 1e-8)\n\n    # Select solution with highest combined ratio\n    selected_idx = np.argmax(combined_ratios)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Dynamic exploration/exploitation trade-off\n    exploration_prob = 0.5 + 0.5 * (1 - len(archive) / 100)\n\n    if random.random() < exploration_prob:\n        # Marginal contribution flips (70% probability)\n        for i in range(len(weight_lst)):\n            if random.random() < 0.7:\n                if new_solution[i] == 1:\n                    # Remove if negative marginal contribution\n                    marginal1 = -value1_lst[i]\n                    marginal2 = -value2_lst[i]\n                    if marginal1 < 0 or marginal2 < 0:\n                        new_weight = current_weight - weight_lst[i]\n                        if new_weight >= 0:\n                            new_solution[i] = 0\n                            current_weight = new_weight\n                else:\n                    # Add if positive marginal contribution\n                    marginal1 = value1_lst[i]\n                    marginal2 = value2_lst[i]\n                    if marginal1 > 0 and marginal2 > 0:\n                        new_weight = current_weight + weight_lst[i]\n                        if new_weight <= capacity:\n                            new_solution[i] = 1\n                            current_weight = new_weight\n    else:\n        # Value-aware swaps (30% probability)\n        not_in_solution = np.where(new_solution == 0)[0]\n        if len(not_in_solution) > 0:\n            # Calculate value ratios\n            ratios1 = value1_lst[not_in_solution] / weight_lst[not_in_solution]\n            ratios2 = value2_lst[not_in_solution] / weight_lst[not_in_solution]\n            combined_ratios = ratios1 + ratios2\n\n            # Select top 30% candidates\n            top_candidates = not_in_solution[np.argsort(combined_ratios)[-max(1, len(combined_ratios)//3):]]\n            if len(top_candidates) > 0:\n                swap_in = random.choice(top_candidates)\n\n                # Find worst item to remove\n                in_solution = np.where(new_solution == 1)[0]\n                if len(in_solution) > 0:\n                    ratios1_in = value1_lst[in_solution] / weight_lst[in_solution]\n                    ratios2_in = value2_lst[in_solution] / weight_lst[in_solution]\n                    combined_ratios_in = ratios1_in + ratios2_in\n                    swap_out = in_solution[np.argmin(combined_ratios_in)]\n\n                    # Perform swap if feasible\n                    if (current_weight - weight_lst[swap_out] + weight_lst[swap_in]) <= capacity:\n                        new_solution[swap_out] = 0\n                        new_solution[swap_in] = 1\n                        current_weight = current_weight - weight_lst[swap_out] + weight_lst[swap_in]\n\n    # Greedy excess removal if still over capacity\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        ratios = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n        sorted_indices = included_items[np.argsort(ratios)]\n        excess = total_weight - capacity\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            excess -= weight_lst[i]\n            new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.39200351044471826,
            0.8863400220870972
        ]
    },
    {
        "algorithm": "This algorithm employs a hybrid local search strategy that combines adaptive value-based selection with dynamic capacity-aware flips, prioritizing high-value items while intelligently adjusting solutions through marginal contribution analysis and probabilistic swaps to maintain feasibility and maximize multi-objective quality. It selects solutions probabilistically based on diversity, then performs either value-driven insertions (70% chance) or capacity-aware replacements (30% chance), followed by dynamic probabilistic flips based on value density, and finally ensures feasibility through a final repair step. The algorithm prioritizes items with high combined objective ratios and value densities, balancing exploration and exploitation through randomness and marginal contribution analysis.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution with diversity-aware probabilistic choice\n    ranks = [i for i in range(len(archive))]\n    selected_idx = random.choices(range(len(archive)), weights=[1/(1 + r) for r in ranks])[0]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state and value metrics\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    combined_values = value1_lst + value2_lst\n    value_ratios = combined_values / weight_lst\n\n    # Adaptive hybrid search phase\n    if random.random() < 0.7:  # 70% chance for value-driven insertion\n        # Select top 50% value items not in solution\n        not_in_solution = np.where(base_solution == 0)[0]\n        if len(not_in_solution) > 0:\n            top_candidates = not_in_solution[np.argsort(value_ratios[not_in_solution])[-max(1, len(not_in_solution)//2):]]\n            if len(top_candidates) > 0:\n                # Select item with highest marginal contribution\n                marginal_contributions = np.zeros_like(top_candidates, dtype=float)\n                for i, idx in enumerate(top_candidates):\n                    if current_weight + weight_lst[idx] <= capacity:\n                        marginal_contributions[i] = combined_values[idx] / weight_lst[idx]\n                if np.any(marginal_contributions > 0):\n                    best_insert = top_candidates[np.argmax(marginal_contributions)]\n                    new_solution[best_insert] = 1\n    else:  # 30% chance for capacity-aware replacement\n        in_solution = np.where(base_solution == 1)[0]\n        if len(in_solution) > 0:\n            # Identify low-value items (bottom 40%)\n            low_value_items = in_solution[np.argsort(value_ratios[in_solution])[:max(1, len(in_solution)//2)]]\n            if len(low_value_items) > 0:\n                replace_out = random.choice(low_value_items)\n                not_in_solution = np.where(base_solution == 0)[0]\n                if len(not_in_solution) > 0:\n                    # Select high-value items (top 40%) with capacity check\n                    high_value_items = not_in_solution[np.argsort(value_ratios[not_in_solution])[-max(1, len(not_in_solution)//2):]]\n                    feasible_items = [i for i in high_value_items if (current_weight - weight_lst[replace_out] + weight_lst[i]) <= capacity]\n                    if feasible_items:\n                        replace_in = random.choice(feasible_items)\n                        new_solution[replace_out] = 0\n                        new_solution[replace_in] = 1\n\n    # Dynamic probabilistic flips based on value density\n    value_density = combined_values / (weight_lst + 1e-6)  # Avoid division by zero\n    mean_density = np.mean(value_density[new_solution == 1]) if np.sum(new_solution) > 0 else 0\n\n    for i in range(len(weight_lst)):\n        if random.random() < 0.3:  # 30% chance for each item\n            if new_solution[i] == 1:\n                # Remove if below average density\n                if value_density[i] < mean_density * 0.8:\n                    new_solution[i] = 0\n            else:\n                # Add if above average density and feasible\n                if value_density[i] > mean_density * 1.2:\n                    if (current_weight + weight_lst[i]) <= capacity:\n                        new_solution[i] = 1\n\n    # Final feasibility check and repair\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        while excess > 0 and np.sum(new_solution) > 0:\n            # Remove items with lowest value density\n            included_items = np.where(new_solution == 1)[0]\n            remove_idx = included_items[np.argmin(value_density[included_items])]\n            excess -= weight_lst[remove_idx]\n            new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8625314874516408,
            2.559768259525299
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (diversity-aware)\n    selected_idx = random.choices(range(len(archive)), weights=[1/(1 + i) for i in range(len(archive))])[0]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and combined value ratios\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    combined_ratios = (value1_lst + value2_lst) / weight_lst\n\n    # Hybrid local search: probabilistic greedy insertion (70%) and value-aware replacement (30%)\n    if random.random() < 0.7:\n        # Probabilistic greedy insertion: add high-value items not in solution\n        not_in_solution = np.where(base_solution == 0)[0]\n        if len(not_in_solution) > 0:\n            # Select top 30% items by combined ratio\n            top_candidates = not_in_solution[np.argsort(combined_ratios[not_in_solution])[-max(1, len(not_in_solution)//3):]]\n            if len(top_candidates) > 0:\n                insert_idx = random.choice(top_candidates)\n                if current_weight + weight_lst[insert_idx] <= capacity:\n                    new_solution[insert_idx] = 1\n    else:\n        # Value-aware replacement: swap low-value items with high-value items\n        in_solution = np.where(base_solution == 1)[0]\n        if len(in_solution) > 0:\n            # Find low-value items (bottom 40%)\n            low_value_items = in_solution[np.argsort(combined_ratios[in_solution])[:max(1, len(in_solution)//2)]]\n            if len(low_value_items) > 0:\n                replace_out = random.choice(low_value_items)\n                not_in_solution = np.where(base_solution == 0)[0]\n                if len(not_in_solution) > 0:\n                    # Find high-value items (top 40%)\n                    high_value_items = not_in_solution[np.argsort(combined_ratios[not_in_solution])[-max(1, len(not_in_solution)//2):]]\n                    if len(high_value_items) > 0:\n                        replace_in = random.choice(high_value_items)\n                        if (current_weight - weight_lst[replace_out] + weight_lst[replace_in]) <= capacity:\n                            new_solution[replace_out] = 0\n                            new_solution[replace_in] = 1\n\n    # Dynamic marginal contribution flip (25% chance for each item)\n    for i in range(len(weight_lst)):\n        if random.random() < 0.25:\n            if new_solution[i] == 1:\n                # Calculate marginal contribution\n                marginal = (value1_lst[i] + value2_lst[i]) / weight_lst[i]\n                threshold = np.mean(combined_ratios[new_solution == 1]) if np.sum(new_solution) > 0 else 0\n                if marginal < threshold:\n                    new_solution[i] = 0\n            else:\n                if (current_weight + weight_lst[i]) <= capacity:\n                    new_solution[i] = 1\n\n    # Ensure feasibility by removing low-value items if weight exceeds capacity\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        while excess > 0 and np.sum(new_solution) > 0:\n            included_items = np.where(new_solution == 1)[0]\n            remove_idx = included_items[np.argmin((value1_lst + value2_lst)[included_items] / weight_lst[included_items])]\n            excess -= weight_lst[remove_idx]\n            new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8963669385263168,
            3.0419974625110626
        ]
    },
    {
        "algorithm": "The heuristic algorithm prioritizes solutions with high potential for improvement through a diversity-aware selection strategy, then applies a hybrid local search combining random flips (70% chance) for items already in the solution and a value-aware swap (30% chance) that intelligently selects high-value items to add while removing low-value items to maintain feasibility. The value-aware swap specifically targets items with top 30% combined value-to-weight ratios, ensuring both objectives are balanced.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (diversity-aware)\n    selected_idx = random.choices(range(len(archive)), weights=[1/(1 + i) for i in range(len(archive))])[0]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random flip with value-aware swap\n    if random.random() < 0.7:  # 70% chance for random flip\n        # Randomly flip items that could improve either objective\n        candidates = np.where(base_solution == 1)[0]\n        if len(candidates) > 0:\n            flip_idx = random.choice(candidates)\n            new_solution[flip_idx] = 0\n    else:  # 30% chance for value-aware swap\n        # Find items not in solution with high value ratios\n        not_in_solution = np.where(base_solution == 0)[0]\n        if len(not_in_solution) > 0:\n            # Calculate value ratios (value1/weight and value2/weight)\n            ratios1 = value1_lst[not_in_solution] / weight_lst[not_in_solution]\n            ratios2 = value2_lst[not_in_solution] / weight_lst[not_in_solution]\n            combined_ratios = ratios1 + ratios2\n\n            # Select top 30% candidates by combined ratio\n            top_candidates = not_in_solution[np.argsort(combined_ratios)[-max(1, len(combined_ratios)//3):]]\n            if len(top_candidates) > 0:\n                swap_in = random.choice(top_candidates)\n\n                # Find items in solution with low value ratios to swap out\n                in_solution = np.where(base_solution == 1)[0]\n                if len(in_solution) > 0:\n                    ratios1_in = value1_lst[in_solution] / weight_lst[in_solution]\n                    ratios2_in = value2_lst[in_solution] / weight_lst[in_solution]\n                    combined_ratios_in = ratios1_in + ratios2_in\n                    swap_out = in_solution[np.argmin(combined_ratios_in)]\n\n                    # Perform swap if feasible\n                    if (np.sum(weight_lst[new_solution == 1]) - weight_lst[swap_out] + weight_lst[swap_in]) <= capacity:\n                        new_solution[swap_out] = 0\n                        new_solution[swap_in] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.4075866881488455,
            1.4317869246006012
        ]
    },
    {
        "algorithm": "This algorithm employs a hypervolume-based selection to prioritize non-dominated solutions, followed by a three-phase local search: value-balanced flips for initial improvement, objective-specific swaps for targeted optimization, and diversity-preserving perturbations to explore the solution space. It ensures feasibility through adaptive capacity checks and marginal contribution filtering, with selection probabilities favoring items with higher value-to-weight ratios.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Hypervolume-based selection\n    obj_values = np.array([obj for _, obj in archive])\n    reference_point = np.max(obj_values, axis=0)\n    hypervolumes = []\n    for i in range(len(archive)):\n        dominated = False\n        for j in range(len(archive)):\n            if i != j and (obj_values[j][0] >= obj_values[i][0] and obj_values[j][1] >= obj_values[i][1]) and (obj_values[j][0] > obj_values[i][0] or obj_values[j][1] > obj_values[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            hv = (reference_point[0] - obj_values[i][0]) * (reference_point[1] - obj_values[i][1])\n            hypervolumes.append((i, hv))\n\n    if hypervolumes:\n        selected_idx = max(hypervolumes, key=lambda x: x[1])[0]\n    else:\n        selected_idx = random.randint(0, len(archive)-1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Phase 1: Value-balanced flips\n    value_balance = value1_lst / (value2_lst + 1e-8)\n    sorted_indices = np.argsort(value_balance)\n    for i in sorted_indices:\n        if random.random() < 0.6:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                if current_weight + weight_lst[i] <= capacity and (value_balance[i] > 1.2 or random.random() < 0.3):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Phase 2: Objective-specific swaps\n    if random.random() < 0.5:\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Select best candidate to add\n            add_candidates = out_items\n            add_scores = (value1_lst[add_candidates] + value2_lst[add_candidates]) / weight_lst[add_candidates]\n            best_add = add_candidates[np.argmax(add_scores)]\n\n            # Select worst candidate to remove\n            remove_scores = (value1_lst[in_items] + value2_lst[in_items]) / weight_lst[in_items]\n            worst_remove = in_items[np.argmin(remove_scores)]\n\n            # Perform swap if feasible\n            if (current_weight - weight_lst[worst_remove] + weight_lst[best_add]) <= capacity:\n                new_solution[worst_remove] = 0\n                new_solution[best_add] = 1\n                current_weight = current_weight - weight_lst[worst_remove] + weight_lst[best_add]\n\n    # Phase 3: Diversity-preserving perturbation\n    if random.random() < 0.3:\n        diversity_factor = 0.2 + 0.8 * (1 - len(archive)/100)\n        for i in range(len(weight_lst)):\n            if random.random() < diversity_factor:\n                if new_solution[i] == 1:\n                    if current_weight - weight_lst[i] >= 0:\n                        new_solution[i] = 0\n                        current_weight -= weight_lst[i]\n                else:\n                    if current_weight + weight_lst[i] <= capacity:\n                        new_solution[i] = 1\n                        current_weight += weight_lst[i]\n\n    # Final feasibility check\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        ratios = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n        sorted_indices = included_items[np.argsort(ratios)]\n        excess = total_weight - capacity\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            excess -= weight_lst[i]\n            new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.5146849944902991,
            2.0465817749500275
        ]
    },
    {
        "algorithm": "The algorithm selects promising solutions from an archive based on combined objective ratios and marginal contributions, then applies a hybrid local search that either flips high-marginal-contribution items (70% chance) or performs objective-specific swaps (30% chance), while ensuring feasibility through adaptive excess removal prioritized by objective dominance. It intelligently balances exploration (via selection scores) and exploitation (via marginal contribution flips and objective swaps) to navigate the multi-objective solution space efficiently.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Dynamic solution selection based on combined objective ratios and marginal contributions\n    obj1 = np.array([obj[0] for _, obj in archive])\n    obj2 = np.array([obj[1] for _, obj in archive])\n    combined_ratios = (obj1 + obj2) / (np.sum(weight_lst[archive[0][0] == 1]) + 1e-8)\n\n    # Calculate marginal contributions for each solution\n    marginal_contribs = []\n    for sol, _ in archive:\n        included = np.where(sol == 1)[0]\n        excluded = np.where(sol == 0)[0]\n        if len(included) == 0 or len(excluded) == 0:\n            marginal_contribs.append(0)\n            continue\n\n        # Calculate average marginal contribution for included items\n        included_contribs = (value1_lst[included] + value2_lst[included]) / weight_lst[included]\n        avg_included = np.mean(included_contribs)\n\n        # Calculate average marginal contribution for excluded items\n        excluded_contribs = (value1_lst[excluded] + value2_lst[excluded]) / weight_lst[excluded]\n        avg_excluded = np.mean(excluded_contribs)\n\n        marginal_contribs.append(avg_included - avg_excluded)\n\n    # Combine selection scores (combined ratios - marginal contributions)\n    selection_scores = combined_ratios - np.array(marginal_contribs)\n    selected_idx = np.argmax(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search with adjusted probabilities\n    if random.random() < 0.7:  # 70% chance for marginal contribution flip\n        included = np.where(base_solution == 1)[0]\n        if len(included) > 0:\n            # Calculate marginal contributions for included items\n            marginal_contribs = (value1_lst[included] + value2_lst[included]) / weight_lst[included]\n            best_item = included[np.argmax(marginal_contribs)]\n            new_solution[best_item] = 0\n    else:  # 30% chance for objective-specific swap\n        not_in_solution = np.where(base_solution == 0)[0]\n        if len(not_in_solution) > 0:\n            # Select top 20% items by objective-specific value-to-weight ratio\n            obj1_ratios = value1_lst / weight_lst\n            obj2_ratios = value2_lst / weight_lst\n            top_candidates = not_in_solution[np.argsort(obj1_ratios[not_in_solution] + obj2_ratios[not_in_solution])[-max(1, len(not_in_solution)//5):]]\n\n            if len(top_candidates) > 0:\n                swap_in = random.choice(top_candidates)\n                included = np.where(base_solution == 1)[0]\n\n                if len(included) > 0:\n                    # Find items with worst objective-specific marginal contribution\n                    obj1_marginals = value1_lst[included] / weight_lst[included]\n                    obj2_marginals = value2_lst[included] / weight_lst[included]\n                    swap_out = included[np.argmin(obj1_marginals + obj2_marginals)]\n\n                    if (np.sum(weight_lst[new_solution == 1]) - weight_lst[swap_out] + weight_lst[swap_in]) <= capacity:\n                        new_solution[swap_out] = 0\n                        new_solution[swap_in] = 1\n\n    # Adaptive feasibility enforcement\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n\n        # Calculate adaptive removal priorities based on objective dominance\n        obj_dominance = (obj1[selected_idx] > obj2[selected_idx]) * 0.7 + 0.5\n        removal_priorities = (obj_dominance * value1_lst[included_items] + (1 - obj_dominance) * value2_lst[included_items]) / weight_lst[included_items]\n        sorted_indices = included_items[np.argsort(removal_priorities)]\n\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            excess -= weight_lst[i]\n            new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.7674161615392132,
            8.26865491271019
        ]
    }
]