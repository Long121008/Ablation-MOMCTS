[
    {
        "algorithm": "The algorithm selects the most promising solution from the archive (based on the product of its two objective values) and applies a hybrid local search strategy: it first tries a random item swap (if feasible) and then probabilistically flips items with low marginal contribution, ensuring feasibility by removing excess items if needed. The approach balances exploration (via random swaps and flips) and exploitation (focusing on high-potential solutions) while strictly enforcing capacity constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select the solution with the highest potential (product of objectives)\n    potentials = [obj[0] * obj[1] for _, obj in archive]\n    selected_idx = np.argmax(potentials)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Generate a neighbor solution using hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Strategy 1: Randomly swap two items (if feasible)\n    if n_items >= 2:\n        swap_indices = np.random.choice(n_items, 2, replace=False)\n        if new_solution[swap_indices[0]] != new_solution[swap_indices[1]]:\n            # Check feasibility\n            if new_solution[swap_indices[0]] == 1:\n                new_weight = current_weight - weight_lst[swap_indices[0]] + weight_lst[swap_indices[1]]\n            else:\n                new_weight = current_weight + weight_lst[swap_indices[0]] - weight_lst[swap_indices[1]]\n            if new_weight <= capacity:\n                new_solution[swap_indices[0]], new_solution[swap_indices[1]] = new_solution[swap_indices[1]], new_solution[swap_indices[0]]\n\n    # Strategy 2: Probabilistic flip of items with low marginal contribution\n    for i in range(n_items):\n        if np.random.rand() < 0.2:  # 20% chance to flip\n            if new_solution[i] == 1:\n                new_weight = current_weight - weight_lst[i]\n                if new_weight >= 0:  # Ensure non-negative weight (though capacity check is more important)\n                    new_solution[i] = 0\n            else:\n                new_weight = current_weight + weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i] = 1\n\n    # Ensure feasibility (in case of multiple changes)\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items until feasible\n        excess = total_weight - capacity\n        while excess > 0:\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break\n            remove_idx = np.random.choice(included_items)\n            excess -= weight_lst[remove_idx]\n            new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8969946250886272,
            2.1612739861011505
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using a weighted sum of normalized objectives (70% value1, 30% value2), then applies a hybrid local search combining probabilistic swaps, marginal contribution-based flips, and a greedy removal step to ensure feasibility. It dynamically balances exploration/exploitation based on archive size, with higher probabilities for marginal improvements and feasibility checks. The method prioritizes solutions with better combined objective scores while intelligently modifying them to improve both objectives while respecting capacity constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Normalize objectives and compute combined scores\n    obj1 = np.array([obj[0] for _, obj in archive])\n    obj2 = np.array([obj[1] for _, obj in archive])\n    norm_obj1 = (obj1 - np.min(obj1)) / (np.max(obj1) - np.min(obj1) + 1e-8)\n    norm_obj2 = (obj2 - np.min(obj2)) / (np.max(obj2) - np.min(obj2) + 1e-8)\n    combined_scores = 0.7 * norm_obj1 + 0.3 * norm_obj2  # Weighted sum\n\n    # Select solution with highest combined score\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Dynamic exploration/exploitation trade-off\n    exploration_prob = 0.5 + 0.5 * (1 - len(archive) / 100)  # Higher exploration for small archives\n\n    # Strategy 1: Probabilistic item swap with feasibility check\n    if np.random.rand() < exploration_prob and n_items >= 2:\n        swap_indices = np.random.choice(n_items, 2, replace=False)\n        if new_solution[swap_indices[0]] != new_solution[swap_indices[1]]:\n            # Check feasibility\n            delta = (weight_lst[swap_indices[1]] - weight_lst[swap_indices[0]]) if new_solution[swap_indices[0]] == 1 else (weight_lst[swap_indices[0]] - weight_lst[swap_indices[1]])\n            if current_weight + delta <= capacity:\n                new_solution[swap_indices[0]], new_solution[swap_indices[1]] = new_solution[swap_indices[1]], new_solution[swap_indices[0]]\n\n    # Strategy 2: Marginal contribution-based flips\n    for i in range(n_items):\n        if np.random.rand() < 0.3:  # Higher probability than original\n            if new_solution[i] == 1:\n                # Check if removing improves both objectives\n                marginal1 = -value1_lst[i]\n                marginal2 = -value2_lst[i]\n                if marginal1 < 0 or marginal2 < 0:  # Negative marginal\n                    new_weight = current_weight - weight_lst[i]\n                    if new_weight >= 0:\n                        new_solution[i] = 0\n            else:\n                # Check if adding improves both objectives\n                marginal1 = value1_lst[i]\n                marginal2 = value2_lst[i]\n                if marginal1 > 0 and marginal2 > 0:  # Positive marginal\n                    new_weight = current_weight + weight_lst[i]\n                    if new_weight <= capacity:\n                        new_solution[i] = 1\n\n    # Strategy 3: Greedy removal for feasibility\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Sort items by weight/value ratio and remove until feasible\n        included_items = np.where(new_solution == 1)[0]\n        ratios = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n        sorted_indices = included_items[np.argsort(ratios)]\n        excess = total_weight - capacity\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            excess -= weight_lst[i]\n            new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9450039798002199,
            2.6820522248744965
        ]
    },
    {
        "algorithm": "The algorithm implements a diversity-aware selection strategy that prioritizes solutions with high potential for improvement, followed by a hybrid local search combining random flips (60% chance) for items already in the solution and a value-aware swap (40% chance) that intelligently selects high-value items to add while removing low-value items to maintain feasibility. The value-aware swap specifically targets items with top 40% combined value-to-weight ratios, ensuring both objectives are balanced.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (diversity-aware)\n    selected_idx = random.choices(range(len(archive)), weights=[1/(1 + i) for i in range(len(archive))])[0]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random flip with value-aware swap\n    if random.random() < 0.6:  # 60% chance for random flip\n        # Randomly flip items that could improve either objective\n        candidates = np.where(base_solution == 1)[0]\n        if len(candidates) > 0:\n            flip_idx = random.choice(candidates)\n            new_solution[flip_idx] = 0\n    else:  # 40% chance for value-aware swap\n        # Find items not in solution with high value ratios\n        not_in_solution = np.where(base_solution == 0)[0]\n        if len(not_in_solution) > 0:\n            # Calculate value ratios (value1/weight and value2/weight)\n            ratios1 = value1_lst[not_in_solution] / weight_lst[not_in_solution]\n            ratios2 = value2_lst[not_in_solution] / weight_lst[not_in_solution]\n            combined_ratios = ratios1 + ratios2\n\n            # Select top 40% candidates by combined ratio\n            top_candidates = not_in_solution[np.argsort(combined_ratios)[-max(1, len(combined_ratios)//2):]]\n            if len(top_candidates) > 0:\n                swap_in = random.choice(top_candidates)\n\n                # Find items in solution with low value ratios to swap out\n                in_solution = np.where(base_solution == 1)[0]\n                if len(in_solution) > 0:\n                    ratios1_in = value1_lst[in_solution] / weight_lst[in_solution]\n                    ratios2_in = value2_lst[in_solution] / weight_lst[in_solution]\n                    combined_ratios_in = ratios1_in + ratios2_in\n                    swap_out = in_solution[np.argmin(combined_ratios_in)]\n\n                    # Perform swap if feasible\n                    if (np.sum(weight_lst[new_solution == 1]) - weight_lst[swap_out] + weight_lst[swap_in]) <= capacity:\n                        new_solution[swap_out] = 0\n                        new_solution[swap_in] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.5493558789167777,
            1.034000277519226
        ]
    },
    {
        "algorithm": "This algorithm implements a crowding-distance-aware selection strategy that prioritizes solutions near the Pareto front boundaries, followed by a hybrid local search combining probabilistic swaps (70% chance) that favor high-margin items and a value-aware removal (30% chance) that intelligently eliminates low-impact items while maintaining feasibility. The selection process uses crowding distance to identify crowded regions of the Pareto front, while the local search alternates between swapping high-margin items and removing low-value items to explore the solution space effectively.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution near Pareto front boundaries using crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    if len(objectives) == 1:\n        selected_idx = 0\n    else:\n        # Calculate crowding distance for each objective\n        crowding_dist = np.zeros(len(objectives))\n        for i in range(2):\n            sorted_idx = np.argsort(objectives[:, i])\n            crowding_dist[sorted_idx[0]] = np.inf\n            crowding_dist[sorted_idx[-1]] = np.inf\n            for j in range(1, len(objectives)-1):\n                crowding_dist[sorted_idx[j]] += (objectives[sorted_idx[j+1], i] - objectives[sorted_idx[j-1], i]) / (objectives[sorted_idx[-1], i] - objectives[sorted_idx[0], i])\n\n        # Select solution with lowest crowding distance (most crowded)\n        selected_idx = np.argmin(crowding_dist)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: probabilistic swap with value-aware removal\n    if random.random() < 0.7:  # 70% chance for probabilistic swap\n        # Calculate value margins for both objectives\n        in_items = np.where(base_solution == 1)[0]\n        not_in_items = np.where(base_solution == 0)[0]\n\n        if len(in_items) > 0 and len(not_in_items) > 0:\n            # Calculate marginal gains for not-in items\n            marginal_gain1 = value1_lst[not_in_items] / weight_lst[not_in_items]\n            marginal_gain2 = value2_lst[not_in_items] / weight_lst[not_in_items]\n            combined_gains = marginal_gain1 + marginal_gain2\n\n            # Select item with highest combined gain\n            swap_in = not_in_items[np.argmax(combined_gains)]\n\n            # Calculate marginal losses for in items\n            marginal_loss1 = value1_lst[in_items] / weight_lst[in_items]\n            marginal_loss2 = value2_lst[in_items] / weight_lst[in_items]\n            combined_losses = marginal_loss1 + marginal_loss2\n\n            # Select item with lowest combined loss\n            swap_out = in_items[np.argmin(combined_losses)]\n\n            # Perform swap if feasible\n            if (np.sum(weight_lst[new_solution == 1]) - weight_lst[swap_out] + weight_lst[swap_in]) <= capacity:\n                new_solution[swap_out] = 0\n                new_solution[swap_in] = 1\n    else:  # 30% chance for value-aware removal\n        # Remove items with lowest combined value-to-weight ratio\n        in_items = np.where(base_solution == 1)[0]\n        if len(in_items) > 1:  # Need at least one item to remain\n            ratios1 = value1_lst[in_items] / weight_lst[in_items]\n            ratios2 = value2_lst[in_items] / weight_lst[in_items]\n            combined_ratios = ratios1 + ratios2\n            remove_idx = in_items[np.argmin(combined_ratios)]\n            new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9585816545487339,
            3.386291205883026
        ]
    },
    {
        "algorithm": "This algorithm employs a hybrid local search strategy that combines adaptive value-based selection with dynamic capacity-aware flips, prioritizing high-value items while intelligently adjusting solutions through marginal contribution analysis and probabilistic swaps to maintain feasibility and maximize multi-objective quality. It selects solutions probabilistically based on diversity, then performs either value-driven insertions (70% chance) or capacity-aware replacements (30% chance), followed by dynamic probabilistic flips based on value density, and finally ensures feasibility through a final repair step. The algorithm prioritizes items with high combined objective ratios and value densities, balancing exploration and exploitation through randomness and marginal contribution analysis.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution with diversity-aware probabilistic choice\n    ranks = [i for i in range(len(archive))]\n    selected_idx = random.choices(range(len(archive)), weights=[1/(1 + r) for r in ranks])[0]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state and value metrics\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    combined_values = value1_lst + value2_lst\n    value_ratios = combined_values / weight_lst\n\n    # Adaptive hybrid search phase\n    if random.random() < 0.7:  # 70% chance for value-driven insertion\n        # Select top 50% value items not in solution\n        not_in_solution = np.where(base_solution == 0)[0]\n        if len(not_in_solution) > 0:\n            top_candidates = not_in_solution[np.argsort(value_ratios[not_in_solution])[-max(1, len(not_in_solution)//2):]]\n            if len(top_candidates) > 0:\n                # Select item with highest marginal contribution\n                marginal_contributions = np.zeros_like(top_candidates, dtype=float)\n                for i, idx in enumerate(top_candidates):\n                    if current_weight + weight_lst[idx] <= capacity:\n                        marginal_contributions[i] = combined_values[idx] / weight_lst[idx]\n                if np.any(marginal_contributions > 0):\n                    best_insert = top_candidates[np.argmax(marginal_contributions)]\n                    new_solution[best_insert] = 1\n    else:  # 30% chance for capacity-aware replacement\n        in_solution = np.where(base_solution == 1)[0]\n        if len(in_solution) > 0:\n            # Identify low-value items (bottom 40%)\n            low_value_items = in_solution[np.argsort(value_ratios[in_solution])[:max(1, len(in_solution)//2)]]\n            if len(low_value_items) > 0:\n                replace_out = random.choice(low_value_items)\n                not_in_solution = np.where(base_solution == 0)[0]\n                if len(not_in_solution) > 0:\n                    # Select high-value items (top 40%) with capacity check\n                    high_value_items = not_in_solution[np.argsort(value_ratios[not_in_solution])[-max(1, len(not_in_solution)//2):]]\n                    feasible_items = [i for i in high_value_items if (current_weight - weight_lst[replace_out] + weight_lst[i]) <= capacity]\n                    if feasible_items:\n                        replace_in = random.choice(feasible_items)\n                        new_solution[replace_out] = 0\n                        new_solution[replace_in] = 1\n\n    # Dynamic probabilistic flips based on value density\n    value_density = combined_values / (weight_lst + 1e-6)  # Avoid division by zero\n    mean_density = np.mean(value_density[new_solution == 1]) if np.sum(new_solution) > 0 else 0\n\n    for i in range(len(weight_lst)):\n        if random.random() < 0.3:  # 30% chance for each item\n            if new_solution[i] == 1:\n                # Remove if below average density\n                if value_density[i] < mean_density * 0.8:\n                    new_solution[i] = 0\n            else:\n                # Add if above average density and feasible\n                if value_density[i] > mean_density * 1.2:\n                    if (current_weight + weight_lst[i]) <= capacity:\n                        new_solution[i] = 1\n\n    # Final feasibility check and repair\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        while excess > 0 and np.sum(new_solution) > 0:\n            # Remove items with lowest value density\n            included_items = np.where(new_solution == 1)[0]\n            remove_idx = included_items[np.argmin(value_density[included_items])]\n            excess -= weight_lst[remove_idx]\n            new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8625314874516408,
            2.559768259525299
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (diversity-aware)\n    selected_idx = random.choices(range(len(archive)), weights=[1/(1 + i) for i in range(len(archive))])[0]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and combined value ratios\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    combined_ratios = (value1_lst + value2_lst) / weight_lst\n\n    # Hybrid local search: probabilistic greedy insertion (70%) and value-aware replacement (30%)\n    if random.random() < 0.7:\n        # Probabilistic greedy insertion: add high-value items not in solution\n        not_in_solution = np.where(base_solution == 0)[0]\n        if len(not_in_solution) > 0:\n            # Select top 30% items by combined ratio\n            top_candidates = not_in_solution[np.argsort(combined_ratios[not_in_solution])[-max(1, len(not_in_solution)//3):]]\n            if len(top_candidates) > 0:\n                insert_idx = random.choice(top_candidates)\n                if current_weight + weight_lst[insert_idx] <= capacity:\n                    new_solution[insert_idx] = 1\n    else:\n        # Value-aware replacement: swap low-value items with high-value items\n        in_solution = np.where(base_solution == 1)[0]\n        if len(in_solution) > 0:\n            # Find low-value items (bottom 40%)\n            low_value_items = in_solution[np.argsort(combined_ratios[in_solution])[:max(1, len(in_solution)//2)]]\n            if len(low_value_items) > 0:\n                replace_out = random.choice(low_value_items)\n                not_in_solution = np.where(base_solution == 0)[0]\n                if len(not_in_solution) > 0:\n                    # Find high-value items (top 40%)\n                    high_value_items = not_in_solution[np.argsort(combined_ratios[not_in_solution])[-max(1, len(not_in_solution)//2):]]\n                    if len(high_value_items) > 0:\n                        replace_in = random.choice(high_value_items)\n                        if (current_weight - weight_lst[replace_out] + weight_lst[replace_in]) <= capacity:\n                            new_solution[replace_out] = 0\n                            new_solution[replace_in] = 1\n\n    # Dynamic marginal contribution flip (25% chance for each item)\n    for i in range(len(weight_lst)):\n        if random.random() < 0.25:\n            if new_solution[i] == 1:\n                # Calculate marginal contribution\n                marginal = (value1_lst[i] + value2_lst[i]) / weight_lst[i]\n                threshold = np.mean(combined_ratios[new_solution == 1]) if np.sum(new_solution) > 0 else 0\n                if marginal < threshold:\n                    new_solution[i] = 0\n            else:\n                if (current_weight + weight_lst[i]) <= capacity:\n                    new_solution[i] = 1\n\n    # Ensure feasibility by removing low-value items if weight exceeds capacity\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        while excess > 0 and np.sum(new_solution) > 0:\n            included_items = np.where(new_solution == 1)[0]\n            remove_idx = included_items[np.argmin((value1_lst + value2_lst)[included_items] / weight_lst[included_items])]\n            excess -= weight_lst[remove_idx]\n            new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8963669385263168,
            3.0419974625110626
        ]
    },
    {
        "algorithm": "The heuristic algorithm prioritizes solutions with high potential for improvement through a diversity-aware selection strategy, then applies a hybrid local search combining random flips (70% chance) for items already in the solution and a value-aware swap (30% chance) that intelligently selects high-value items to add while removing low-value items to maintain feasibility. The value-aware swap specifically targets items with top 30% combined value-to-weight ratios, ensuring both objectives are balanced.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (diversity-aware)\n    selected_idx = random.choices(range(len(archive)), weights=[1/(1 + i) for i in range(len(archive))])[0]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random flip with value-aware swap\n    if random.random() < 0.7:  # 70% chance for random flip\n        # Randomly flip items that could improve either objective\n        candidates = np.where(base_solution == 1)[0]\n        if len(candidates) > 0:\n            flip_idx = random.choice(candidates)\n            new_solution[flip_idx] = 0\n    else:  # 30% chance for value-aware swap\n        # Find items not in solution with high value ratios\n        not_in_solution = np.where(base_solution == 0)[0]\n        if len(not_in_solution) > 0:\n            # Calculate value ratios (value1/weight and value2/weight)\n            ratios1 = value1_lst[not_in_solution] / weight_lst[not_in_solution]\n            ratios2 = value2_lst[not_in_solution] / weight_lst[not_in_solution]\n            combined_ratios = ratios1 + ratios2\n\n            # Select top 30% candidates by combined ratio\n            top_candidates = not_in_solution[np.argsort(combined_ratios)[-max(1, len(combined_ratios)//3):]]\n            if len(top_candidates) > 0:\n                swap_in = random.choice(top_candidates)\n\n                # Find items in solution with low value ratios to swap out\n                in_solution = np.where(base_solution == 1)[0]\n                if len(in_solution) > 0:\n                    ratios1_in = value1_lst[in_solution] / weight_lst[in_solution]\n                    ratios2_in = value2_lst[in_solution] / weight_lst[in_solution]\n                    combined_ratios_in = ratios1_in + ratios2_in\n                    swap_out = in_solution[np.argmin(combined_ratios_in)]\n\n                    # Perform swap if feasible\n                    if (np.sum(weight_lst[new_solution == 1]) - weight_lst[swap_out] + weight_lst[swap_in]) <= capacity:\n                        new_solution[swap_out] = 0\n                        new_solution[swap_in] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.4075866881488455,
            1.4317869246006012
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using a weighted combination of normalized objectives (60% value1, 40% value2) and applies a hybrid local search strategy: 70% marginal contribution flips (probabilistically flipping items based on their impact) and 30% value-aware swaps (targeting high-value items for insertion while removing low-value items), always ensuring feasibility through greedy excess removal. The solution prioritizes items with higher combined value-to-weight ratios while maintaining capacity constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Normalize objectives and compute weighted scores\n    obj1 = np.array([obj[0] for _, obj in archive])\n    obj2 = np.array([obj[1] for _, obj in archive])\n    norm_obj1 = (obj1 - np.min(obj1)) / (np.max(obj1) - np.min(obj1) + 1e-8)\n    norm_obj2 = (obj2 - np.min(obj2)) / (np.max(obj2) - np.min(obj2) + 1e-8)\n    weighted_scores = 0.6 * norm_obj1 + 0.4 * norm_obj2\n\n    # Select solution with highest weighted score\n    selected_idx = np.argmax(weighted_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    n_items = len(weight_lst)\n\n    # Hybrid local search: 70% marginal flips, 30% value-aware swaps\n    if np.random.rand() < 0.7:  # Marginal contribution flips\n        for i in range(n_items):\n            if np.random.rand() < 0.3:  # 30% chance per item\n                if new_solution[i] == 1:\n                    # Check if removing improves both objectives\n                    marginal1 = -value1_lst[i]\n                    marginal2 = -value2_lst[i]\n                    if marginal1 < 0 or marginal2 < 0:\n                        new_weight = current_weight - weight_lst[i]\n                        if new_weight >= 0:\n                            new_solution[i] = 0\n                else:\n                    # Check if adding improves both objectives\n                    marginal1 = value1_lst[i]\n                    marginal2 = value2_lst[i]\n                    if marginal1 > 0 and marginal2 > 0:\n                        new_weight = current_weight + weight_lst[i]\n                        if new_weight <= capacity:\n                            new_solution[i] = 1\n    else:  # Value-aware swap (top 30% value items)\n        # Find items not in solution with high value ratios\n        not_in_solution = np.where(base_solution == 0)[0]\n        if len(not_in_solution) > 0:\n            combined_ratios = (value1_lst + value2_lst) / weight_lst\n            top_candidates = not_in_solution[np.argsort(combined_ratios[not_in_solution])[-max(1, len(not_in_solution)//3):]]\n\n            if len(top_candidates) > 0:\n                swap_in = np.random.choice(top_candidates)\n\n                # Find worst items in solution to swap out\n                in_solution = np.where(base_solution == 1)[0]\n                if len(in_solution) > 0:\n                    combined_ratios_in = (value1_lst + value2_lst)[in_solution] / weight_lst[in_solution]\n                    swap_out = in_solution[np.argmin(combined_ratios_in)]\n\n                    # Perform swap if feasible\n                    if (current_weight - weight_lst[swap_out] + weight_lst[swap_in]) <= capacity:\n                        new_solution[swap_out] = 0\n                        new_solution[swap_in] = 1\n\n    # Ensure feasibility (greedy excess removal)\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        # Sort by value-to-weight ratio and remove until feasible\n        ratios = (value1_lst + value2_lst)[included_items] / weight_lst[included_items]\n        sorted_indices = included_items[np.argsort(ratios)]\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            excess -= weight_lst[i]\n            new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.47378695677848687,
            2.1038510501384735
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using a weighted objective score (60% value1, 40% value2), then applies a hybrid local search combining probabilistic swaps (60% chance) and marginal contribution-based flips (40% chance), while ensuring feasibility through a greedy removal step. It dynamically balances exploration/exploitation based on archive size, prioritizing high-value items while intelligently modifying solutions to improve both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Weighted objective selection (60% value1, 40% value2)\n    obj1 = np.array([obj[0] for _, obj in archive])\n    obj2 = np.array([obj[1] for _, obj in archive])\n    norm_obj1 = (obj1 - np.min(obj1)) / (np.max(obj1) - np.min(obj1) + 1e-8)\n    norm_obj2 = (obj2 - np.min(obj2)) / (np.max(obj2) - np.min(obj2) + 1e-8)\n    combined_scores = 0.6 * norm_obj1 + 0.4 * norm_obj2\n\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Dynamic exploration/exploitation trade-off\n    exploration_prob = 0.5 + 0.5 * (1 - len(archive) / 100)\n\n    # Strategy 1: Probabilistic swap with feasibility check (60% chance)\n    if np.random.rand() < 0.6 * exploration_prob and n_items >= 2:\n        swap_indices = np.random.choice(n_items, 2, replace=False)\n        if new_solution[swap_indices[0]] != new_solution[swap_indices[1]]:\n            delta = (weight_lst[swap_indices[1]] - weight_lst[swap_indices[0]]) if new_solution[swap_indices[0]] == 1 else (weight_lst[swap_indices[0]] - weight_lst[swap_indices[1]])\n            if current_weight + delta <= capacity:\n                new_solution[swap_indices[0]], new_solution[swap_indices[1]] = new_solution[swap_indices[1]], new_solution[swap_indices[0]]\n\n    # Strategy 2: Marginal contribution-based flips (40% chance)\n    for i in range(n_items):\n        if np.random.rand() < 0.4:\n            if new_solution[i] == 1:\n                marginal1 = -value1_lst[i]\n                marginal2 = -value2_lst[i]\n                if marginal1 < 0 or marginal2 < 0:\n                    new_weight = current_weight - weight_lst[i]\n                    if new_weight >= 0:\n                        new_solution[i] = 0\n            else:\n                marginal1 = value1_lst[i]\n                marginal2 = value2_lst[i]\n                if marginal1 > 0 and marginal2 > 0:\n                    new_weight = current_weight + weight_lst[i]\n                    if new_weight <= capacity:\n                        new_solution[i] = 1\n\n    # Strategy 3: Greedy removal for feasibility\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        ratios = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n        sorted_indices = included_items[np.argsort(ratios)]\n        excess = total_weight - capacity\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            excess -= weight_lst[i]\n            new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.894846266927728,
            5.222519427537918
        ]
    },
    {
        "algorithm": "The heuristic algorithm selects a promising solution from the archive based on normalized objective values, then applies a hybrid local search combining item swaps and random flips, ensuring feasibility by checking weight constraints at each step. It prioritizes solutions with higher combined normalized objectives and intelligently explores neighbors by considering both item removals/additions and random flips, accepting moves that improve at least one objective. The algorithm balances exploration and exploitation by focusing on a small subset of items for swaps and controlled random flips.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (here, we select the one with the highest sum of normalized objectives)\n    normalized_scores = []\n    max_value1 = max(obj[0] for _, obj in archive) if archive else 1.0\n    max_value2 = max(obj[1] for _, obj in archive) if archive else 1.0\n\n    for sol, obj in archive:\n        norm_obj1 = obj[0] / max_value1 if max_value1 > 0 else 0.0\n        norm_obj2 = obj[1] / max_value2 if max_value2 > 0 else 0.0\n        normalized_scores.append(norm_obj1 + norm_obj2)\n\n    selected_idx = np.argmax(normalized_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Generate neighbor using hybrid local search\n    # Step 1: Randomly select a subset of items to consider for swaps\n    num_items = len(weight_lst)\n    subset_size = min(5, num_items)  # Consider up to 5 items for swaps\n    swap_indices = random.sample(range(num_items), subset_size)\n\n    # Step 2: Perform item swaps while maintaining feasibility\n    for i in swap_indices:\n        if new_solution[i] == 1:\n            # Try removing item i\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = np.sum(weight_lst[temp_solution == 1])\n\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                # After removing, try adding other items\n                for j in swap_indices:\n                    if j != i and new_solution[j] == 0:\n                        temp_solution2 = new_solution.copy()\n                        temp_solution2[j] = 1\n                        temp_weight2 = np.sum(weight_lst[temp_solution2 == 1])\n\n                        if temp_weight2 <= capacity:\n                            # Accept the move if it improves at least one objective\n                            current_value1 = np.sum(value1_lst[new_solution == 1])\n                            current_value2 = np.sum(value2_lst[new_solution == 1])\n                            new_value1 = np.sum(value1_lst[temp_solution2 == 1])\n                            new_value2 = np.sum(value2_lst[temp_solution2 == 1])\n\n                            if (new_value1 > current_value1 or new_value2 > current_value2):\n                                new_solution = temp_solution2\n                                break\n        else:\n            # Try adding item i\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = np.sum(weight_lst[temp_solution == 1])\n\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n\n    # Step 3: Perform a novel neighborhood exploration (randomly flip a small number of items)\n    flip_count = min(2, num_items)  # Flip up to 2 items\n    flip_indices = random.sample(range(num_items), flip_count)\n\n    for i in flip_indices:\n        temp_solution = new_solution.copy()\n        temp_solution[i] = 1 - temp_solution[i]\n        temp_weight = np.sum(weight_lst[temp_solution == 1])\n\n        if temp_weight <= capacity:\n            # Accept the flip if it improves at least one objective\n            current_value1 = np.sum(value1_lst[new_solution == 1])\n            current_value2 = np.sum(value2_lst[new_solution == 1])\n            new_value1 = np.sum(value1_lst[temp_solution == 1])\n            new_value2 = np.sum(value2_lst[temp_solution == 1])\n\n            if (new_value1 > current_value1 or new_value2 > current_value2):\n                new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -0.3141328391655218,
            3.2796249389648438
        ]
    }
]