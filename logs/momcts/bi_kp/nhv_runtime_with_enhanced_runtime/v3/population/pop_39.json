[
    {
        "algorithm": "The algorithm selects a solution from the archive based on a weighted objective score (70% value1 + 30% value2) and applies a local search by flipping up to 5 items with the highest marginal contribution (also weighted 70-30) while ensuring feasibility. It dynamically adjusts the solution by adding or removing items to maximize the combined objective without exceeding the knapsack capacity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution using a weighted objective score (0.7*value1 + 0.3*value2)\n    selected_idx = 0\n    max_score = -1\n    for i, (sol, obj) in enumerate(archive):\n        score = 0.7 * obj[0] + 0.3 * obj[1]\n        if score > max_score:\n            max_score = score\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Compute marginal contributions for each item\n    marginal1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = 0.7 * marginal1 + 0.3 * marginal2\n\n    # Sort items by marginal contribution (descending)\n    sorted_indices = np.argsort(-combined_marginal)\n\n    # Dynamic flip strategy: flip up to 5 items with highest marginal contribution\n    flip_count = min(5, len(sorted_indices))\n    for idx in sorted_indices[:flip_count]:\n        if new_solution[idx] == 1:\n            # Try to remove if feasible\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try to add if feasible\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8742819369527933,
            1.159465342760086
        ]
    },
    {
        "algorithm": "The algorithm selects the most crowded solution in the archive (highest dominance count) and applies a hybrid local search combining adaptive item replacement (prioritizing high-impact items) and probabilistic insertion/removal, while ensuring feasibility through dynamic weight adjustment. It prioritizes items with high normalized impact scores (combining both objectives) and replaces low-impact items with high-impact ones, while probabilistically adding/removing high-impact items. Feasibility is maintained by removing low-impact items if needed.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate dominance counts for each solution\n    dominance_counts = []\n    for i, (sol_i, obj_i) in enumerate(archive):\n        count = 0\n        for j, (sol_j, obj_j) in enumerate(archive):\n            if i != j and (obj_j[0] >= obj_i[0] and obj_j[1] >= obj_i[1]) and (obj_j[0] > obj_i[0] or obj_j[1] > obj_i[1]):\n                count += 1\n        dominance_counts.append(count)\n\n    # Select solution with highest dominance count (most crowded)\n    selected_idx = np.argmax(dominance_counts)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Compute normalized impact scores (considering both objectives and weight efficiency)\n    impact_scores = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n    normalized_scores = impact_scores / (np.max(impact_scores) + 1e-6)\n\n    # Adaptive replacement strategy: replace items with low impact with high impact items\n    low_impact_mask = normalized_scores < 0.3\n    high_impact_items = np.where(normalized_scores >= 0.7)[0]\n\n    if np.any(low_impact_mask) and len(high_impact_items) > 0:\n        low_impact_indices = np.where(low_impact_mask)[0]\n        for idx in low_impact_indices:\n            if new_solution[idx] == 1:\n                # Try to replace with a high impact item\n                for high_idx in high_impact_items:\n                    if new_solution[high_idx] == 0 and current_weight - weight_lst[idx] + weight_lst[high_idx] <= capacity:\n                        new_solution[idx], new_solution[high_idx] = new_solution[high_idx], new_solution[idx]\n                        current_weight = current_weight - weight_lst[idx] + weight_lst[high_idx]\n                        break\n\n    # Probabilistic insertion/removal of high impact items\n    for idx in high_impact_items:\n        if new_solution[idx] == 0 and np.random.rand() < 0.4 * normalized_scores[idx]:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1 and np.random.rand() < 0.2 * (1 - normalized_scores[idx]):\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic weight adjustment to maintain feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        # Remove items with lowest impact until feasible\n        sorted_indices = np.argsort(normalized_scores)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n                if excess_weight <= 0:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.9084257576837889,
            2.1438385248184204
        ]
    },
    {
        "algorithm": "The algorithm combines crowding-distance selection with a tiered local search that prioritizes high-marginal-gain items, uses a weighted swap mechanism, and probabilistically flips items based on their combined normalized impact scores, ensuring feasibility through dynamic weight checks. It first selects the most crowded solution in the archive, then applies three refinement tiers: flipping top marginal items, swapping high/low marginal items, and probabilistic flips based on normalized scores, all while maintaining capacity constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate crowding distance for each solution\n    crowding_distances = []\n    for i, (sol_i, obj_i) in enumerate(archive):\n        distances = []\n        for j, (sol_j, obj_j) in enumerate(archive):\n            if i != j:\n                dist = np.sqrt((obj_j[0] - obj_i[0])**2 + (obj_j[1] - obj_i[1])**2)\n                distances.append(dist)\n        crowding_distances.append(np.min(distances) if distances else float('inf'))\n\n    # Select solution with minimum crowding distance (most crowded)\n    selected_idx = np.argmin(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate combined marginal gains\n    marginal_value1 = value1_lst / (weight_lst + 1e-6)\n    marginal_value2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Tier 1: Flip top marginal items for both objectives\n    sorted_indices = np.argsort(-combined_marginal)\n    flip_count = min(5, len(sorted_indices))\n    for idx in sorted_indices[:flip_count]:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Tier 2: Weighted swap mechanism\n    if len(sorted_indices) >= 2:\n        # Select items with highest and lowest marginal gains\n        high_idx = sorted_indices[0]\n        low_idx = sorted_indices[-1]\n\n        # Calculate weight difference\n        weight_diff = weight_lst[high_idx] - weight_lst[low_idx]\n\n        # Perform swap if feasible\n        if new_solution[high_idx] != new_solution[low_idx]:\n            if new_solution[high_idx] == 1:\n                if current_weight + weight_diff <= capacity:\n                    new_solution[high_idx], new_solution[low_idx] = new_solution[low_idx], new_solution[high_idx]\n            else:\n                if current_weight - weight_diff <= capacity:\n                    new_solution[high_idx], new_solution[low_idx] = new_solution[low_idx], new_solution[high_idx]\n\n    # Tier 3: Probabilistic flip based on combined impact\n    normalized_scores = combined_marginal / (np.max(combined_marginal) + 1e-6)\n    for idx in range(len(normalized_scores)):\n        if np.random.rand() < 0.3 * normalized_scores[idx]:\n            if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif new_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9215646050728925,
            9.20160436630249
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive prioritizing higher scores (60% value2 + 40% value1), then applies a hybrid local search that flips up to 3 high-marginal-contribution items (weighted 60% value2 + 40% value1) while ensuring feasibility, followed by a probabilistic swap of two items to escape local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution using a weighted objective score (0.4*value1 + 0.6*value2)\n    selected_idx = 0\n    max_score = -1\n    for i, (sol, obj) in enumerate(archive):\n        score = 0.4 * obj[0] + 0.6 * obj[1]\n        if score > max_score:\n            max_score = score\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Compute marginal contributions for each item (0.6*value2 + 0.4*value1)\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = 0.6 * marginal2 + 0.4 * marginal1\n\n    # Sort items by marginal contribution (descending)\n    sorted_indices = np.argsort(-combined_marginal)\n\n    # Dynamic flip strategy: flip up to 3 items with highest marginal contribution\n    flip_count = min(3, len(sorted_indices))\n    for idx in sorted_indices[:flip_count]:\n        if new_solution[idx] == 1:\n            # Try to remove if feasible\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try to add if feasible\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Probabilistic swap of two items to escape local optima\n    if len(sorted_indices) >= 2:\n        swap_candidates = sorted_indices[:5]  # Consider top 5 items for swap\n        if len(swap_candidates) >= 2:\n            i, j = np.random.choice(swap_candidates, size=2, replace=False)\n            # Check if swapping is feasible\n            if new_solution[i] != new_solution[j]:\n                if new_solution[i] == 1 and current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                elif new_solution[j] == 1 and current_weight - weight_lst[j] + weight_lst[i] <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.7724345802780868,
            1.3127074539661407
        ]
    },
    {
        "algorithm": "The algorithm selects a high-scoring solution from the archive (prioritizing 70% value1 + 30% value2) and generates a neighbor by flipping up to 4 high-marginal-contribution items (weighted similarly) while ensuring feasibility, followed by a probabilistic 3-item swap to explore diverse neighborhoods. It dynamically balances exploitation (flipping high-marginal items) and exploration (random swaps) while maintaining feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution using a weighted objective score (0.7*value1 + 0.3*value2)\n    selected_idx = 0\n    max_score = -1\n    for i, (sol, obj) in enumerate(archive):\n        score = 0.7 * obj[0] + 0.3 * obj[1]\n        if score > max_score:\n            max_score = score\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Compute marginal contributions for each item (0.7*value1 + 0.3*value2)\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = 0.7 * marginal1 + 0.3 * marginal2\n\n    # Sort items by marginal contribution (descending)\n    sorted_indices = np.argsort(-combined_marginal)\n\n    # Dynamic flip strategy: flip up to 4 items with highest marginal contribution\n    flip_count = min(4, len(sorted_indices))\n    for idx in sorted_indices[:flip_count]:\n        if new_solution[idx] == 1:\n            # Try to remove if feasible\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try to add if feasible\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Probabilistic swap of three items to explore diverse neighborhoods\n    if len(sorted_indices) >= 3:\n        swap_candidates = sorted_indices[:6]  # Consider top 6 items for swap\n        if len(swap_candidates) >= 3:\n            i, j, k = np.random.choice(swap_candidates, size=3, replace=False)\n            # Check if swapping is feasible\n            if new_solution[i] != new_solution[j]:\n                if new_solution[i] == 1 and current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                elif new_solution[j] == 1 and current_weight - weight_lst[j] + weight_lst[i] <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            if new_solution[j] != new_solution[k]:\n                if new_solution[j] == 1 and current_weight - weight_lst[j] + weight_lst[k] <= capacity:\n                    new_solution[j], new_solution[k] = new_solution[k], new_solution[j]\n                elif new_solution[k] == 1 and current_weight - weight_lst[k] + weight_lst[j] <= capacity:\n                    new_solution[j], new_solution[k] = new_solution[k], new_solution[j]\n\n    return new_solution\n\n",
        "score": [
            -0.8631499479602416,
            1.3316587507724762
        ]
    },
    {
        "algorithm": "The algorithm dynamically selects a solution from the archive based on alternating priorities (value1, value2, or a hybrid) and applies a two-stage local search: first flipping items with the highest normalized marginal gains (weighted by a time-varying factor) to improve both objectives, then performing a probabilistic swap of items to explore the solution space while maintaining feasibility. The selection strategy cycles through different objective preferences, and the local search uses both deterministic and stochastic operations to balance exploitation and exploration.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Dynamic selection based on time-varying weights (cyclic between objectives)\n    current_time = len(archive) % 4\n    if current_time == 0:\n        # Focus on value2\n        selected_idx = np.argmax([obj[1] for _, obj in archive])\n    elif current_time == 1:\n        # Focus on value1\n        selected_idx = np.argmax([obj[0] for _, obj in archive])\n    elif current_time == 2:\n        # Hybrid approach (weighted sum)\n        selected_idx = np.argmax([0.6 * obj[0] + 0.4 * obj[1] for _, obj in archive])\n    else:\n        # Random selection to encourage diversity\n        selected_idx = np.random.randint(0, len(archive))\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Time-varying marginal contribution calculation\n    beta = 0.8 if (current_time % 2 == 0) else 0.2  # Alternate between objectives\n    combined_marginal = beta * (value1_lst / (weight_lst + 1e-6)) + (1 - beta) * (value2_lst / (weight_lst + 1e-6))\n\n    # Stage 1: Flip top items with highest marginal contribution\n    sorted_indices = np.argsort(-combined_marginal)\n    flip_count = min(3, len(sorted_indices))\n    for idx in sorted_indices[:flip_count]:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Stage 2: Probabilistic item swap\n    if np.random.random() < 0.6:  # 60% chance to perform swap\n        swap_candidates = sorted_indices[:5]  # Consider top 5 items\n        if len(swap_candidates) >= 2:\n            i, j = np.random.choice(swap_candidates, size=2, replace=False)\n            if new_solution[i] != new_solution[j]:\n                weight_diff = weight_lst[j] - weight_lst[i]\n                if new_solution[i] == 1:\n                    if current_weight + weight_diff <= capacity:\n                        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                else:\n                    if current_weight - weight_diff <= capacity:\n                        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.7210599016669208,
            1.2667514085769653
        ]
    },
    {
        "algorithm": "This heuristic algorithm selects a promising solution from an archive by prioritizing those with high combined objective values, then applies a two-phase hybrid local search: first probabilistically replacing items based on combined value-to-weight ratios, and second dynamically adjusting item selection based on the current solution's objective values to bias toward the underperforming objective. The algorithm ensures feasibility by always checking weight constraints before applying changes.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) == 1:\n        selected_solution = archive[0][0].copy()\n    else:\n        # Sort solutions by their total value (sum of both objectives) and select the top 20% for further consideration\n        archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        top_solutions = archive_sorted[:max(1, len(archive_sorted) // 5)]\n        selected_solution = random.choice(top_solutions)[0].copy()\n\n    new_solution = selected_solution.copy()\n\n    # Phase 1: Probabilistic item replacement based on value-to-weight ratios\n    vw_ratio1 = value1_lst / weight_lst\n    vw_ratio2 = value2_lst / weight_lst\n    combined_ratio = vw_ratio1 + vw_ratio2\n\n    # Normalize ratios for probability calculation\n    max_ratio = np.max(combined_ratio)\n    if max_ratio > 0:\n        normalized_ratio = combined_ratio / max_ratio\n\n    # Probabilistically replace items\n    for i in range(len(new_solution)):\n        if random.random() < 0.3:  # 30% chance to consider replacement\n            if new_solution[i] == 1:\n                # Consider removing this item\n                temp_solution = new_solution.copy()\n                temp_solution[i] = 0\n                if np.sum(weight_lst * temp_solution) <= capacity:\n                    new_solution = temp_solution\n            else:\n                # Consider adding this item with probability proportional to its ratio\n                if random.random() < normalized_ratio[i]:\n                    temp_solution = new_solution.copy()\n                    temp_solution[i] = 1\n                    if np.sum(weight_lst * temp_solution) <= capacity:\n                        new_solution = temp_solution\n\n    # Phase 2: Dynamic adjustment based on current solution's objective values\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate bias towards objective 1 or 2 based on current values\n    if current_value1 > current_value2:\n        bias = 0.7  # More bias towards objective 1\n    elif current_value2 > current_value1:\n        bias = 0.3  # More bias towards objective 2\n    else:\n        bias = 0.5  # Equal bias\n\n    # Adjust probabilities based on bias\n    adjusted_ratio = (bias * vw_ratio1) + ((1 - bias) * vw_ratio2)\n\n    # Apply final adjustments\n    sorted_indices = np.argsort(-adjusted_ratio)\n    for idx in sorted_indices:\n        if new_solution[idx] == 0:\n            temp_solution = new_solution.copy()\n            temp_solution[idx] = 1\n            if np.sum(weight_lst * temp_solution) <= capacity:\n                new_solution = temp_solution\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.9039259109576373,
            2.7756621539592743
        ]
    },
    {
        "algorithm": "The heuristic selects a high-value solution from the archive (based on the maximum of either objective value) and applies a hybrid local search by flipping items prioritized by their combined value-to-weight ratios (sum of ratios for both objectives), ensuring feasibility by checking weight constraints. It randomly selects up to 5 high-priority items to flip, removing or adding them if the operation doesn\u2019t exceed capacity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential (e.g., those with high diversity or low dominance)\n    # Here, we randomly select a solution with high value in at least one objective\n    max_value = -1\n    selected_idx = 0\n    for i, (sol, obj) in enumerate(archive):\n        if max(obj[0], obj[1]) > max_value:\n            max_value = max(obj[0], obj[1])\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: flip items with high value-to-weight ratio in a random order\n    # First, compute value-to-weight ratios for both objectives\n    ratio1 = value1_lst / weight_lst\n    ratio2 = value2_lst / weight_lst\n\n    # Combine ratios and sort by descending order\n    combined_ratio = ratio1 + ratio2\n    sorted_indices = np.argsort(-combined_ratio)\n\n    # Randomly select a subset of items to flip\n    flip_indices = np.random.choice(sorted_indices, size=min(5, len(sorted_indices)), replace=False)\n\n    # Flip selected items while ensuring feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try to remove if feasible\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                total_weight -= weight_lst[idx]\n        else:\n            # Try to add if feasible\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.30518390165972703,
            1.3124490082263947
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive based on crowding distance to balance exploration and exploitation, then applies a hybrid local search that first removes low-value-density items, adds high-marginal-contribution items with dynamic probabilities, and occasionally performs a controlled swap to escape local optima while maintaining feasibility. The method prioritizes items with combined high value densities in both objectives and uses probabilistic selection to explore promising neighbors efficiently.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest crowding distance\n    def crowding_distance(solutions):\n        distances = []\n        for i in range(len(solutions)):\n            left = solutions[max(0, i-1)][1]\n            right = solutions[min(len(solutions)-1, i+1)][1]\n            dist = abs(right[0] - left[0]) + abs(right[1] - left[1])\n            distances.append(dist)\n        return distances\n\n    sorted_archive = sorted(archive, key=lambda x: (x[1][0], x[1][1]))\n    distances = crowding_distance(sorted_archive)\n    selected_idx = np.argmax(distances)\n    base_solution = sorted_archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 1: Remove redundant items with low value density\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            density1 = value1_lst[i] / weight_lst[i]\n            density2 = value2_lst[i] / weight_lst[i]\n            if (density1 + density2) / 2 < 0.5:  # Density threshold\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n\n    # Step 2: Add high-marginal items with dynamic probabilities\n    available_items = np.where(new_solution == 0)[0]\n    if len(available_items) > 0 and current_weight < capacity:\n        # Calculate marginal contributions\n        marginal1 = value1_lst[available_items] / (weight_lst[available_items] + 1e-6)\n        marginal2 = value2_lst[available_items] / (weight_lst[available_items] + 1e-6)\n        combined_marginal = marginal1 + marginal2\n\n        # Dynamic probability based on normalized marginal contributions\n        probabilities = combined_marginal / np.sum(combined_marginal)\n        num_to_add = min(2, len(available_items))\n        selected_items = np.random.choice(available_items, size=num_to_add, p=probabilities, replace=False)\n\n        for i in selected_items:\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Step 3: Controlled random swap with feasibility check\n    if random.random() < 0.2:  # 20% chance of swap\n        included_items = np.where(new_solution == 1)[0]\n        excluded_items = np.where(new_solution == 0)[0]\n\n        if len(included_items) > 0 and len(excluded_items) > 0:\n            # Select item to remove with high weight\n            item_to_remove = np.random.choice(included_items, p=weight_lst[included_items]/np.sum(weight_lst[included_items]))\n\n            # Select item to add with high marginal contribution\n            available_for_add = [i for i in excluded_items if current_weight - weight_lst[item_to_remove] + weight_lst[i] <= capacity]\n            if available_for_add:\n                marginals = (value1_lst[available_for_add] + value2_lst[available_for_add]) / (weight_lst[available_for_add] + 1e-6)\n                item_to_add = available_for_add[np.argmax(marginals)]\n\n                new_solution[item_to_remove] = 0\n                new_solution[item_to_add] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.8951800694937821,
            6.113027483224869
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive based on crowding distance (prioritizing less-explored regions), then applies a hybrid local search: it first removes low-value-to-weight items, probabilistically adds high-marginal-contribution items, and occasionally perturbs the solution with a dynamic swap to balance objectives while respecting capacity constraints. It prioritizes items with higher combined value-to-weight ratios and dynamically adjusts selection probabilities to explore promising regions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high crowding distance (indicating less-explored regions)\n    crowding_distances = []\n    objectives = np.array([obj for _, obj in archive])\n    for i in range(len(archive)):\n        left = i - 1 if i > 0 else None\n        right = i + 1 if i < len(archive) - 1 else None\n        if left is not None and right is not None:\n            dist1 = abs(objectives[right, 0] - objectives[left, 0])\n            dist2 = abs(objectives[right, 1] - objectives[left, 1])\n            crowding_distances.append(dist1 + dist2)\n        else:\n            crowding_distances.append(float('inf'))\n\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 1: Remove items with lowest combined value-to-weight ratios\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        ratios = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n        sorted_indices = np.argsort(ratios)\n        for i in sorted_indices[:max(1, len(included_items) // 5)]:\n            item_idx = included_items[i]\n            if current_weight - weight_lst[item_idx] >= 0:\n                new_solution[item_idx] = 0\n                current_weight -= weight_lst[item_idx]\n\n    # Step 2: Add high-marginal-contribution items probabilistically\n    available_items = np.where(new_solution == 0)[0]\n    if len(available_items) > 0 and current_weight < capacity:\n        marginal1 = value1_lst[available_items] / (weight_lst[available_items] + 1e-6)\n        marginal2 = value2_lst[available_items] / (weight_lst[available_items] + 1e-6)\n        marginal_scores = marginal1 + marginal2\n        probabilities = np.exp(marginal_scores)\n        probabilities = probabilities / np.sum(probabilities)\n\n        num_to_add = min(3, len(available_items))\n        selected_items = np.random.choice(available_items, size=num_to_add, p=probabilities, replace=False)\n\n        for i in selected_items:\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Step 3: Dynamic perturbation based on current solution quality\n    if random.random() < 0.2:\n        included_items = np.where(new_solution == 1)[0]\n        excluded_items = np.where(new_solution == 0)[0]\n\n        if len(included_items) > 0 and len(excluded_items) > 0:\n            item_in = random.choice(included_items)\n            item_out = random.choice(excluded_items)\n\n            if current_weight - weight_lst[item_in] + weight_lst[item_out] <= capacity:\n                new_solution[item_in] = 0\n                new_solution[item_out] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.8365927085229392,
            3.2634280025959015
        ]
    }
]