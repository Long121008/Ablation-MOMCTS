[
    {
        "algorithm": "The algorithm selects a solution from the archive based on a weighted objective score (70% value1 + 30% value2) and applies a local search by flipping up to 5 items with the highest marginal contribution (also weighted 70-30) while ensuring feasibility. It dynamically adjusts the solution by adding or removing items to maximize the combined objective without exceeding the knapsack capacity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution using a weighted objective score (0.7*value1 + 0.3*value2)\n    selected_idx = 0\n    max_score = -1\n    for i, (sol, obj) in enumerate(archive):\n        score = 0.7 * obj[0] + 0.3 * obj[1]\n        if score > max_score:\n            max_score = score\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Compute marginal contributions for each item\n    marginal1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = 0.7 * marginal1 + 0.3 * marginal2\n\n    # Sort items by marginal contribution (descending)\n    sorted_indices = np.argsort(-combined_marginal)\n\n    # Dynamic flip strategy: flip up to 5 items with highest marginal contribution\n    flip_count = min(5, len(sorted_indices))\n    for idx in sorted_indices[:flip_count]:\n        if new_solution[idx] == 1:\n            # Try to remove if feasible\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try to add if feasible\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8742819369527933,
            1.159465342760086
        ]
    },
    {
        "algorithm": "The algorithm selects the most crowded solution in the archive (highest dominance count) and applies a hybrid local search combining adaptive item replacement (prioritizing high-impact items) and probabilistic insertion/removal, while ensuring feasibility through dynamic weight adjustment. It prioritizes items with high normalized impact scores (combining both objectives) and replaces low-impact items with high-impact ones, while probabilistically adding/removing high-impact items. Feasibility is maintained by removing low-impact items if needed.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate dominance counts for each solution\n    dominance_counts = []\n    for i, (sol_i, obj_i) in enumerate(archive):\n        count = 0\n        for j, (sol_j, obj_j) in enumerate(archive):\n            if i != j and (obj_j[0] >= obj_i[0] and obj_j[1] >= obj_i[1]) and (obj_j[0] > obj_i[0] or obj_j[1] > obj_i[1]):\n                count += 1\n        dominance_counts.append(count)\n\n    # Select solution with highest dominance count (most crowded)\n    selected_idx = np.argmax(dominance_counts)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Compute normalized impact scores (considering both objectives and weight efficiency)\n    impact_scores = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n    normalized_scores = impact_scores / (np.max(impact_scores) + 1e-6)\n\n    # Adaptive replacement strategy: replace items with low impact with high impact items\n    low_impact_mask = normalized_scores < 0.3\n    high_impact_items = np.where(normalized_scores >= 0.7)[0]\n\n    if np.any(low_impact_mask) and len(high_impact_items) > 0:\n        low_impact_indices = np.where(low_impact_mask)[0]\n        for idx in low_impact_indices:\n            if new_solution[idx] == 1:\n                # Try to replace with a high impact item\n                for high_idx in high_impact_items:\n                    if new_solution[high_idx] == 0 and current_weight - weight_lst[idx] + weight_lst[high_idx] <= capacity:\n                        new_solution[idx], new_solution[high_idx] = new_solution[high_idx], new_solution[idx]\n                        current_weight = current_weight - weight_lst[idx] + weight_lst[high_idx]\n                        break\n\n    # Probabilistic insertion/removal of high impact items\n    for idx in high_impact_items:\n        if new_solution[idx] == 0 and np.random.rand() < 0.4 * normalized_scores[idx]:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1 and np.random.rand() < 0.2 * (1 - normalized_scores[idx]):\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Dynamic weight adjustment to maintain feasibility\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        # Remove items with lowest impact until feasible\n        sorted_indices = np.argsort(normalized_scores)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n                if excess_weight <= 0:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.9084257576837889,
            2.1438385248184204
        ]
    },
    {
        "algorithm": "This algorithm selects a promising solution from an archive using a hybrid metric of dominance rank and solution density, then applies a tiered local search combining marginal gain analysis, adaptive swaps, and probabilistic perturbations to generate a neighbor solution while ensuring feasibility through dynamic weight tracking. The search prioritizes items with high combined marginal gains (value1 + value2) and uses adaptive swaps between high and low marginal items, followed by probabilistic flips weighted by normalized marginal values.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Selection: Combine dominance rank and solution density\n    objectives = np.array([obj for _, obj in archive])\n    ranks = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        ranks[sorted_idx] += np.arange(len(archive))\n    density_scores = np.zeros(len(archive))\n    for i in range(len(archive)):\n        dist = np.linalg.norm(objectives - objectives[i], axis=1)\n        density_scores[i] = 1 / (np.sum(dist) + 1e-6)\n    combined_scores = ranks + density_scores\n    selected_idx = np.argmin(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-aware marginal flips\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = marginal1 + marginal2\n    sorted_indices = np.argsort(-combined_marginal)\n    for idx in sorted_indices[:min(3, len(sorted_indices))]:\n        if new_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 2: Adaptive objective-aware swaps\n    if len(sorted_indices) >= 2:\n        high_idx, low_idx = sorted_indices[0], sorted_indices[-1]\n        if new_solution[high_idx] != new_solution[low_idx]:\n            weight_diff = weight_lst[high_idx] - weight_lst[low_idx]\n            if (new_solution[high_idx] == 1 and current_weight + weight_diff <= capacity) or \\\n               (new_solution[high_idx] == 0 and current_weight - weight_diff <= capacity):\n                new_solution[high_idx], new_solution[low_idx] = new_solution[low_idx], new_solution[high_idx]\n\n    # Phase 3: Probabilistic objective-aware perturbation\n    for idx in np.random.permutation(len(new_solution)):\n        if np.random.rand() < 0.2:\n            prob = 0.5 + 0.5 * (marginal1[idx] + marginal2[idx]) / (np.max(marginal1) + np.max(marginal2) + 1e-6)\n            if np.random.rand() < prob:\n                if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                elif new_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9828175680529148,
            8.38978260755539
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive based on high diversity and low dominance, then applies a four-phase local search: first flipping high-marginal items, then swapping high- and low-marginal items, followed by probabilistic perturbation, and finally trade-off-aware mutations to balance both objectives while ensuring feasibility. The selection prioritizes solutions with extreme objective values, and the local search phases progressively refine the solution by leveraging marginal gains, weighted swaps, and adaptive perturbations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate diversity and dominance metrics\n    objectives = np.array([obj for _, obj in archive])\n    diversity_scores = np.zeros(len(archive))\n    dominance_scores = np.zeros(len(archive))\n\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        diversity_scores[sorted_idx[0]] += 1\n        diversity_scores[sorted_idx[-1]] += 1\n        for i in range(1, len(archive)-1):\n            diversity_scores[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m] + 1e-6)\n\n    # Select solution with high diversity and low dominance\n    combined_scores = diversity_scores - 0.5 * dominance_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Weighted Flips\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = (marginal1 + marginal2) / 2\n    sorted_indices = np.argsort(-combined_marginal)\n\n    for idx in sorted_indices[:min(10, len(sorted_indices))]:\n        if new_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 2: Weighted Swaps\n    if len(sorted_indices) >= 2:\n        high_idx, low_idx = sorted_indices[0], sorted_indices[-1]\n        weight_diff = weight_lst[high_idx] - weight_lst[low_idx]\n        if (new_solution[high_idx] == 1 and current_weight + weight_diff <= capacity) or \\\n           (new_solution[high_idx] == 0 and current_weight - weight_diff <= capacity):\n            new_solution[high_idx], new_solution[low_idx] = new_solution[low_idx], new_solution[high_idx]\n\n    # Phase 3: Adaptive Perturbation\n    perturbation_prob = 0.2\n    for idx in np.random.permutation(len(new_solution)):\n        if np.random.rand() < perturbation_prob:\n            if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n            elif new_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 4: Trade-off Mutation\n    tradeoff_factor = 0.7\n    for idx in np.random.permutation(len(new_solution)):\n        if np.random.rand() < 0.15:\n            if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                if (value1_lst[idx] / (value2_lst[idx] + 1e-6)) > tradeoff_factor:\n                    new_solution[idx] = 1\n            elif new_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                if (value2_lst[idx] / (value1_lst[idx] + 1e-6)) > tradeoff_factor:\n                    new_solution[idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9106922084132536,
            3.750513046979904
        ]
    },
    {
        "algorithm": "This algorithm selects the most crowded solution from the archive (based on crowding distance) and applies a two-phase local search: first flipping high-marginal-value items and then swapping high/low-marginal items while ensuring feasibility. The selection prioritizes solutions in dense regions of the Pareto front, and the local search balances both objectives through marginal gains and adaptive swaps.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate crowding distances for each solution\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.zeros(len(archive))\n\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding_distances[sorted_idx[0]] = np.inf\n        crowding_distances[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            crowding_distances[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m] + 1e-6)\n\n    # Select solution with maximum crowding distance\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: High-marginal flips\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = marginal1 + marginal2\n    sorted_indices = np.argsort(-combined_marginal)\n\n    for idx in sorted_indices[:min(5, len(sorted_indices))]:\n        if new_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        elif new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 2: Adaptive objective-aware swaps\n    if len(sorted_indices) >= 2:\n        high_idx, low_idx = sorted_indices[0], sorted_indices[-1]\n        weight_diff = weight_lst[high_idx] - weight_lst[low_idx]\n        if (new_solution[high_idx] == 1 and current_weight + weight_diff <= capacity) or \\\n           (new_solution[high_idx] == 0 and current_weight - weight_diff <= capacity):\n            new_solution[high_idx], new_solution[low_idx] = new_solution[low_idx], new_solution[high_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8928027884040193,
            1.6058310270309448
        ]
    },
    {
        "algorithm": "The algorithm combines crowding-distance selection with a tiered local search that prioritizes high-marginal-gain items, uses a weighted swap mechanism, and probabilistically flips items based on their combined normalized impact scores, ensuring feasibility through dynamic weight checks. It first selects the most crowded solution in the archive, then applies three refinement tiers: flipping top marginal items, swapping high/low marginal items, and probabilistic flips based on normalized scores, all while maintaining capacity constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate crowding distance for each solution\n    crowding_distances = []\n    for i, (sol_i, obj_i) in enumerate(archive):\n        distances = []\n        for j, (sol_j, obj_j) in enumerate(archive):\n            if i != j:\n                dist = np.sqrt((obj_j[0] - obj_i[0])**2 + (obj_j[1] - obj_i[1])**2)\n                distances.append(dist)\n        crowding_distances.append(np.min(distances) if distances else float('inf'))\n\n    # Select solution with minimum crowding distance (most crowded)\n    selected_idx = np.argmin(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate combined marginal gains\n    marginal_value1 = value1_lst / (weight_lst + 1e-6)\n    marginal_value2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Tier 1: Flip top marginal items for both objectives\n    sorted_indices = np.argsort(-combined_marginal)\n    flip_count = min(5, len(sorted_indices))\n    for idx in sorted_indices[:flip_count]:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Tier 2: Weighted swap mechanism\n    if len(sorted_indices) >= 2:\n        # Select items with highest and lowest marginal gains\n        high_idx = sorted_indices[0]\n        low_idx = sorted_indices[-1]\n\n        # Calculate weight difference\n        weight_diff = weight_lst[high_idx] - weight_lst[low_idx]\n\n        # Perform swap if feasible\n        if new_solution[high_idx] != new_solution[low_idx]:\n            if new_solution[high_idx] == 1:\n                if current_weight + weight_diff <= capacity:\n                    new_solution[high_idx], new_solution[low_idx] = new_solution[low_idx], new_solution[high_idx]\n            else:\n                if current_weight - weight_diff <= capacity:\n                    new_solution[high_idx], new_solution[low_idx] = new_solution[low_idx], new_solution[high_idx]\n\n    # Tier 3: Probabilistic flip based on combined impact\n    normalized_scores = combined_marginal / (np.max(combined_marginal) + 1e-6)\n    for idx in range(len(normalized_scores)):\n        if np.random.rand() < 0.3 * normalized_scores[idx]:\n            if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif new_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9215646050728925,
            9.20160436630249
        ]
    },
    {
        "algorithm": "The algorithm dynamically selects a solution from the archive based on alternating priorities (value1, value2, or a hybrid) and applies a two-stage local search: first flipping items with the highest normalized marginal gains (weighted by a time-varying factor) to improve both objectives, then performing a probabilistic swap of items to explore the solution space while maintaining feasibility. The selection strategy cycles through different objective preferences, and the local search uses both deterministic and stochastic operations to balance exploitation and exploration.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Dynamic selection based on time-varying weights (cyclic between objectives)\n    current_time = len(archive) % 4\n    if current_time == 0:\n        # Focus on value2\n        selected_idx = np.argmax([obj[1] for _, obj in archive])\n    elif current_time == 1:\n        # Focus on value1\n        selected_idx = np.argmax([obj[0] for _, obj in archive])\n    elif current_time == 2:\n        # Hybrid approach (weighted sum)\n        selected_idx = np.argmax([0.6 * obj[0] + 0.4 * obj[1] for _, obj in archive])\n    else:\n        # Random selection to encourage diversity\n        selected_idx = np.random.randint(0, len(archive))\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Time-varying marginal contribution calculation\n    beta = 0.8 if (current_time % 2 == 0) else 0.2  # Alternate between objectives\n    combined_marginal = beta * (value1_lst / (weight_lst + 1e-6)) + (1 - beta) * (value2_lst / (weight_lst + 1e-6))\n\n    # Stage 1: Flip top items with highest marginal contribution\n    sorted_indices = np.argsort(-combined_marginal)\n    flip_count = min(3, len(sorted_indices))\n    for idx in sorted_indices[:flip_count]:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Stage 2: Probabilistic item swap\n    if np.random.random() < 0.6:  # 60% chance to perform swap\n        swap_candidates = sorted_indices[:5]  # Consider top 5 items\n        if len(swap_candidates) >= 2:\n            i, j = np.random.choice(swap_candidates, size=2, replace=False)\n            if new_solution[i] != new_solution[j]:\n                weight_diff = weight_lst[j] - weight_lst[i]\n                if new_solution[i] == 1:\n                    if current_weight + weight_diff <= capacity:\n                        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                else:\n                    if current_weight - weight_diff <= capacity:\n                        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.7210599016669208,
            1.2667514085769653
        ]
    },
    {
        "algorithm": "This heuristic algorithm selects a promising solution from an archive by prioritizing those with high combined objective values, then applies a two-phase hybrid local search: first probabilistically replacing items based on combined value-to-weight ratios, and second dynamically adjusting item selection based on the current solution's objective values to bias toward the underperforming objective. The algorithm ensures feasibility by always checking weight constraints before applying changes.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if len(archive) == 1:\n        selected_solution = archive[0][0].copy()\n    else:\n        # Sort solutions by their total value (sum of both objectives) and select the top 20% for further consideration\n        archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        top_solutions = archive_sorted[:max(1, len(archive_sorted) // 5)]\n        selected_solution = random.choice(top_solutions)[0].copy()\n\n    new_solution = selected_solution.copy()\n\n    # Phase 1: Probabilistic item replacement based on value-to-weight ratios\n    vw_ratio1 = value1_lst / weight_lst\n    vw_ratio2 = value2_lst / weight_lst\n    combined_ratio = vw_ratio1 + vw_ratio2\n\n    # Normalize ratios for probability calculation\n    max_ratio = np.max(combined_ratio)\n    if max_ratio > 0:\n        normalized_ratio = combined_ratio / max_ratio\n\n    # Probabilistically replace items\n    for i in range(len(new_solution)):\n        if random.random() < 0.3:  # 30% chance to consider replacement\n            if new_solution[i] == 1:\n                # Consider removing this item\n                temp_solution = new_solution.copy()\n                temp_solution[i] = 0\n                if np.sum(weight_lst * temp_solution) <= capacity:\n                    new_solution = temp_solution\n            else:\n                # Consider adding this item with probability proportional to its ratio\n                if random.random() < normalized_ratio[i]:\n                    temp_solution = new_solution.copy()\n                    temp_solution[i] = 1\n                    if np.sum(weight_lst * temp_solution) <= capacity:\n                        new_solution = temp_solution\n\n    # Phase 2: Dynamic adjustment based on current solution's objective values\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate bias towards objective 1 or 2 based on current values\n    if current_value1 > current_value2:\n        bias = 0.7  # More bias towards objective 1\n    elif current_value2 > current_value1:\n        bias = 0.3  # More bias towards objective 2\n    else:\n        bias = 0.5  # Equal bias\n\n    # Adjust probabilities based on bias\n    adjusted_ratio = (bias * vw_ratio1) + ((1 - bias) * vw_ratio2)\n\n    # Apply final adjustments\n    sorted_indices = np.argsort(-adjusted_ratio)\n    for idx in sorted_indices:\n        if new_solution[idx] == 0:\n            temp_solution = new_solution.copy()\n            temp_solution[idx] = 1\n            if np.sum(weight_lst * temp_solution) <= capacity:\n                new_solution = temp_solution\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.9039259109576373,
            2.7756621539592743
        ]
    },
    {
        "algorithm": "The algorithm selects a high-scoring solution from the archive (prioritizing 70% value1 + 30% value2) and generates a neighbor by flipping up to 4 high-marginal-contribution items (weighted similarly) while ensuring feasibility, followed by a probabilistic 3-item swap to explore diverse neighborhoods. It dynamically balances exploitation (flipping high-marginal items) and exploration (random swaps) while maintaining feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution using a weighted objective score (0.7*value1 + 0.3*value2)\n    selected_idx = 0\n    max_score = -1\n    for i, (sol, obj) in enumerate(archive):\n        score = 0.7 * obj[0] + 0.3 * obj[1]\n        if score > max_score:\n            max_score = score\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Compute marginal contributions for each item (0.7*value1 + 0.3*value2)\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = 0.7 * marginal1 + 0.3 * marginal2\n\n    # Sort items by marginal contribution (descending)\n    sorted_indices = np.argsort(-combined_marginal)\n\n    # Dynamic flip strategy: flip up to 4 items with highest marginal contribution\n    flip_count = min(4, len(sorted_indices))\n    for idx in sorted_indices[:flip_count]:\n        if new_solution[idx] == 1:\n            # Try to remove if feasible\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try to add if feasible\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Probabilistic swap of three items to explore diverse neighborhoods\n    if len(sorted_indices) >= 3:\n        swap_candidates = sorted_indices[:6]  # Consider top 6 items for swap\n        if len(swap_candidates) >= 3:\n            i, j, k = np.random.choice(swap_candidates, size=3, replace=False)\n            # Check if swapping is feasible\n            if new_solution[i] != new_solution[j]:\n                if new_solution[i] == 1 and current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                elif new_solution[j] == 1 and current_weight - weight_lst[j] + weight_lst[i] <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            if new_solution[j] != new_solution[k]:\n                if new_solution[j] == 1 and current_weight - weight_lst[j] + weight_lst[k] <= capacity:\n                    new_solution[j], new_solution[k] = new_solution[k], new_solution[j]\n                elif new_solution[k] == 1 and current_weight - weight_lst[k] + weight_lst[j] <= capacity:\n                    new_solution[j], new_solution[k] = new_solution[k], new_solution[j]\n\n    return new_solution\n\n",
        "score": [
            -0.8631499479602416,
            1.3316587507724762
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive prioritizing higher scores (60% value2 + 40% value1), then applies a hybrid local search that flips up to 3 high-marginal-contribution items (weighted 60% value2 + 40% value1) while ensuring feasibility, followed by a probabilistic swap of two items to escape local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution using a weighted objective score (0.4*value1 + 0.6*value2)\n    selected_idx = 0\n    max_score = -1\n    for i, (sol, obj) in enumerate(archive):\n        score = 0.4 * obj[0] + 0.6 * obj[1]\n        if score > max_score:\n            max_score = score\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Compute marginal contributions for each item (0.6*value2 + 0.4*value1)\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = 0.6 * marginal2 + 0.4 * marginal1\n\n    # Sort items by marginal contribution (descending)\n    sorted_indices = np.argsort(-combined_marginal)\n\n    # Dynamic flip strategy: flip up to 3 items with highest marginal contribution\n    flip_count = min(3, len(sorted_indices))\n    for idx in sorted_indices[:flip_count]:\n        if new_solution[idx] == 1:\n            # Try to remove if feasible\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try to add if feasible\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Probabilistic swap of two items to escape local optima\n    if len(sorted_indices) >= 2:\n        swap_candidates = sorted_indices[:5]  # Consider top 5 items for swap\n        if len(swap_candidates) >= 2:\n            i, j = np.random.choice(swap_candidates, size=2, replace=False)\n            # Check if swapping is feasible\n            if new_solution[i] != new_solution[j]:\n                if new_solution[i] == 1 and current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                elif new_solution[j] == 1 and current_weight - weight_lst[j] + weight_lst[i] <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.7724345802780868,
            1.3127074539661407
        ]
    }
]