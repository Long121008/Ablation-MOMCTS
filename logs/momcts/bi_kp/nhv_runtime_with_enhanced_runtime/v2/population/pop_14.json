[
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a diverse solution from the archive (prioritize those with high objective values but not already explored)\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]) / 2, reverse=True)\n    selected_idx = min(int(len(archive) * 0.4), len(archive) - 1)  # Select from top 40% of solutions\n    base_solution = archive_sorted[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate dynamic marginal contribution (combining both objectives with weight adjustment)\n    alpha = 0.5  # Initial balance factor between objectives\n    if current_weight > 0.7 * capacity:\n        alpha = 0.7  # Increase focus on objective 1 when close to capacity\n    marginal_contribution = alpha * (value1_lst / weight_lst) + (1 - alpha) * (value2_lst / weight_lst)\n\n    # Sort items by dynamic marginal contribution (descending)\n    sorted_indices = np.argsort(-marginal_contribution)\n\n    # Perform targeted swaps and additions\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            # Try removing item i if it's not critical\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n                break\n        else:\n            # Try adding item i if it fits\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                # Check if adding this item improves both objectives sufficiently\n                if (value1_lst[i] > 0 and value2_lst[i] > 0) or (temp_weight <= 0.9 * capacity):\n                    new_solution[i] = 1\n                    current_weight = temp_weight\n                    break\n\n    # Adaptive diversification (higher probability when stuck)\n    diversification_rate = 0.2 if current_weight > 0.8 * capacity else 0.1\n    if np.random.rand() < diversification_rate:\n        # Perform multiple random flips with feasibility checks\n        flip_indices = np.random.choice(len(weight_lst), size=min(4, len(weight_lst)), replace=False)\n        for i in flip_indices:\n            if new_solution[i] == 1:\n                temp_solution = new_solution.copy()\n                temp_solution[i] = 0\n                temp_weight = current_weight - weight_lst[i]\n                if temp_weight <= capacity:\n                    new_solution = temp_solution\n                    current_weight = temp_weight\n            else:\n                temp_weight = current_weight + weight_lst[i]\n                if temp_weight <= capacity:\n                    new_solution[i] = 1\n                    current_weight = temp_weight\n\n    return new_solution\n\n",
        "score": [
            -0.9208547939029279,
            1.5441421568393707
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive with the minimum sum of objectives, then applies a hybrid local search that prioritizes items with high marginal contribution (combining both objectives) through targeted swaps and adaptive perturbations, while ensuring feasibility by checking weight constraints at each step. The method balances exploitation (via marginal contribution sorting) and exploration (via random perturbations), with higher priority given to items that improve both objectives proportionally.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with the minimum sum of objectives (diverse selection)\n    selected = min(archive, key=lambda x: sum(x[1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: prioritize items with high marginal contribution for both objectives\n    marginal_value1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_value2 = value2_lst / (weight_lst + 1e-6)\n    marginal_contribution = marginal_value1 + marginal_value2\n\n    # Sort items by marginal contribution (descending)\n    sorted_indices = np.argsort(-marginal_contribution)\n\n    # Step 1: Perform targeted swaps (explore neighborhood)\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            # Try removing item i\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n                break\n        else:\n            # Try adding item i\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n                break\n\n    # Step 2: Adaptive perturbation with higher probability (50% chance)\n    if np.random.rand() < 0.5:\n        # Select a random subset of items to perturb (up to 5 items)\n        perturbation_indices = np.random.choice(len(weight_lst), size=min(5, len(weight_lst)), replace=False)\n        for i in perturbation_indices:\n            if new_solution[i] == 1:\n                temp_solution = new_solution.copy()\n                temp_solution[i] = 0\n                temp_weight = current_weight - weight_lst[i]\n                if temp_weight <= capacity:\n                    new_solution = temp_solution\n                    current_weight = temp_weight\n            else:\n                temp_solution = new_solution.copy()\n                temp_solution[i] = 1\n                temp_weight = current_weight + weight_lst[i]\n                if temp_weight <= capacity:\n                    new_solution = temp_solution\n                    current_weight = temp_weight\n\n    return new_solution\n\n",
        "score": [
            -0.8062330467894219,
            1.2104815542697906
        ]
    },
    {
        "algorithm": "The algorithm dynamically selects promising solutions from the archive using a hybrid ranking metric combining \u03b5-dominance and objective diversity, then applies a value-weighted swap operator that prioritizes items with high marginal gains for both objectives while maintaining feasibility, followed by an adaptive perturbation phase that probabilistically swaps items based on their marginal gains and current capacity utilization. The selection prioritizes items with better marginal gains for both objectives, and the perturbation phase adjusts exploration intensity based on capacity usage.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Hybrid ranking: combine \u03b5-dominance and objective diversity\n    def hybrid_rank(solutions):\n        ranks = {}\n        for i, (sol_i, obj_i) in enumerate(solutions):\n            rank = 0\n            for j, (sol_j, obj_j) in enumerate(solutions):\n                if i != j:\n                    # \u03b5-dominance component\n                    if obj_j[0] >= obj_i[0] and obj_j[1] >= obj_i[1]:\n                        if obj_j[0] > obj_i[0] or obj_j[1] > obj_i[1]:\n                            rank += 1\n                    # Objective diversity component\n                    rank += abs(obj_i[0] - obj_j[0]) + abs(obj_i[1] - obj_j[1])\n            ranks[i] = rank\n        return ranks\n\n    ranks = hybrid_rank(archive)\n    sorted_indices = sorted(ranks.keys(), key=lambda x: ranks[x])\n    top_20_percent = max(1, len(archive) // 5)\n    selected_idx = random.choice(sorted_indices[:top_20_percent])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Value-weighted swap operator\n    weight_factor = 0.5 if current_weight > 0.6 * capacity else 0.6\n    marginal_gain = (weight_factor * value1_lst + (1 - weight_factor) * value2_lst) / (weight_lst + 1e-6)\n    sorted_items = np.argsort(-marginal_gain)\n\n    # Perform value-weighted swaps\n    for i in sorted_items:\n        if new_solution[i] == 1:\n            # Try removing item i\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = temp_weight\n                break\n        else:\n            # Try adding item i\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = temp_weight\n                break\n\n    # Adaptive perturbation based on marginal gains\n    perturbation_prob = 0.2 if current_weight > 0.7 * capacity else 0.1\n    if random.random() < perturbation_prob:\n        # Select items with high marginal gains for potential swap\n        candidate_indices = [i for i in sorted_items[:min(10, len(sorted_items))]\n                           if (new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                              (new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if candidate_indices:\n            num_swaps = random.randint(1, min(2, len(candidate_indices)))\n            swap_indices = random.sample(candidate_indices, num_swaps)\n            for i in swap_indices:\n                new_solution[i] = 1 - new_solution[i]\n                current_weight += (1 if new_solution[i] == 1 else -1) * weight_lst[i]\n\n    # Final feasibility check\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        # Remove item with lowest marginal gain\n        excess_items_sorted = sorted(excess_items, key=lambda x: marginal_gain[x])\n        remove_idx = excess_items_sorted[0]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9292649166811169,
            2.8038553595542908
        ]
    },
    {
        "algorithm": "The algorithm implements an adaptive local search that selects a solution from the archive based on crowding distance for diversity, then applies a hybrid approach combining greedy and randomized item selection with dynamic objective weighting (prioritizing value1 when near capacity, value2 otherwise) and quality-based diversification. It iteratively improves the solution by removing low-impact items and adding high-marginal-benefit items, with adaptive probabilities for further diversification when solution quality is low.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution with highest crowding distance in objective space for diversity\n    def crowding_distance(solutions):\n        if len(solutions) < 3:\n            return [1.0] * len(solutions)\n        sorted_obj1 = sorted(solutions, key=lambda x: x[1][0])\n        sorted_obj2 = sorted(solutions, key=lambda x: x[1][1])\n\n        distances = [0.0] * len(solutions)\n        for i in range(1, len(solutions)-1):\n            distances[i] = (sorted_obj1[i+1][1][0] - sorted_obj1[i-1][1][0]) / (sorted_obj1[-1][1][0] - sorted_obj1[0][1][0]) + \\\n                          (sorted_obj2[i+1][1][1] - sorted_obj2[i-1][1][1]) / (sorted_obj2[-1][1][1] - sorted_obj2[0][1][1])\n        return distances\n\n    distances = crowding_distance(archive)\n    selected_idx = np.argmax(distances)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Dynamic objective weighting based on solution quality\n    alpha = 0.5\n    if current_weight > 0.8 * capacity:\n        alpha = 0.6 + 0.2 * (current_weight / capacity)  # More emphasis on value1 as capacity approaches\n    else:\n        alpha = 0.4 + 0.4 * (current_weight / capacity)  # More emphasis on value2 when capacity is underutilized\n\n    # Hybrid selection metric combining efficiency and diversity\n    efficiency = (alpha * value1_lst + (1-alpha) * value2_lst) / weight_lst\n    diversity = np.abs(new_solution - 0.5)  # Items not in solution get higher diversity score\n    selection_metric = efficiency * (1 + 0.5 * diversity)\n\n    # Sort items by selection metric (descending)\n    sorted_indices = np.argsort(-selection_metric)\n\n    # Perform targeted operations\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            # Consider removing item if it's not critical\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity and (temp_weight >= 0.7 * capacity or np.random.rand() < 0.3):\n                new_solution = temp_solution\n                current_weight = temp_weight\n                break\n        else:\n            # Consider adding item if it fits and improves both objectives\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                improvement1 = value1_lst[i] / (temp_weight - current_weight)\n                improvement2 = value2_lst[i] / (temp_weight - current_weight)\n                if (improvement1 > 0.1 or improvement2 > 0.1) and (temp_weight <= 0.95 * capacity or np.random.rand() < 0.4):\n                    new_solution[i] = 1\n                    current_weight = temp_weight\n                    break\n\n    # Adaptive diversification with quality-based probability\n    quality = (np.sum(value1_lst * new_solution) + np.sum(value2_lst * new_solution)) / (2 * np.sum(weight_lst * new_solution))\n    diversification_rate = 0.1 + 0.3 * (1 - quality)  # Higher rate when solution quality is low\n\n    if np.random.rand() < diversification_rate:\n        # Perform multiple guided flips\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            for i in np.random.choice(flip_candidates, size=min(3, len(flip_candidates)), replace=False):\n                temp_solution = new_solution.copy()\n                temp_solution[i] = 0\n                temp_weight = current_weight - weight_lst[i]\n                if temp_weight <= capacity and (temp_weight >= 0.6 * capacity or np.random.rand() < 0.5):\n                    new_solution = temp_solution\n                    current_weight = temp_weight\n\n        # Add new items with high marginal benefit\n        available_items = np.where(new_solution == 0)[0]\n        if len(available_items) > 0:\n            marginal_benefit = (alpha * value1_lst[available_items] + (1-alpha) * value2_lst[available_items]) / weight_lst[available_items]\n            best_add = np.argmax(marginal_benefit)\n            i = available_items[best_add]\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity and (temp_weight <= 0.9 * capacity or np.random.rand() < 0.6):\n                new_solution[i] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.8573164286911579,
            1.61256542801857
        ]
    },
    {
        "algorithm": "The algorithm uses \u03b5-dominance ranking to select high-quality, diverse solutions from the archive, then applies a hybrid local search combining weighted marginal gain prioritization (with adaptive weights based on current knapsack utilization) and targeted perturbations (flipping 1-3 random items with probability dependent on capacity usage), ensuring feasibility at every step. The weighted marginal gain balances both objectives dynamically, while adaptive perturbations introduce controlled exploration.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # \u03b5-dominance ranking to select diverse high-quality solutions\n    epsilon = 0.1  # \u03b5 parameter for \u03b5-dominance\n    ranked_solutions = []\n    for sol, obj in archive:\n        dominated = False\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] - epsilon and other_obj[1] >= obj[1] - epsilon and\n                (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated = True\n                break\n        if not dominated:\n            ranked_solutions.append((sol, obj))\n\n    if not ranked_solutions:\n        ranked_solutions = archive\n\n    # Select solution with highest \u03b5-dominated rank (sum of objectives)\n    selected = max(ranked_solutions, key=lambda x: sum(x[1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate weighted marginal gains\n    weight_factor = 0.6 if current_weight > 0.8 * capacity else 0.4\n    marginal_gain = (weight_factor * value1_lst + (1 - weight_factor) * value2_lst) / (weight_lst + 1e-6)\n\n    # Sort items by marginal gain (descending)\n    sorted_indices = np.argsort(-marginal_gain)\n\n    # Local search with targeted flips\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            # Try removing item\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = temp_weight\n                break\n        else:\n            # Try adding item\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = temp_weight\n                break\n\n    # Adaptive perturbation\n    perturbation_prob = 0.3 if current_weight > 0.7 * capacity else 0.15\n    if np.random.rand() < perturbation_prob:\n        # Select 3 random items to perturb\n        perturb_indices = np.random.choice(len(weight_lst), size=min(3, len(weight_lst)), replace=False)\n        for i in perturb_indices:\n            if new_solution[i] == 1:\n                temp_weight = current_weight - weight_lst[i]\n                if temp_weight <= capacity:\n                    new_solution[i] = 0\n                    current_weight = temp_weight\n            else:\n                temp_weight = current_weight + weight_lst[i]\n                if temp_weight <= capacity:\n                    new_solution[i] = 1\n                    current_weight = temp_weight\n\n    return new_solution\n\n",
        "score": [
            -0.4076089573457292,
            1.276840090751648
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using dynamic \u03b5-dominance ranking (prioritizing solutions with high combined value, weighted 70% to value1 and 30% to value2), then applies a hybrid local search that flips item selections based on weighted marginal gains while adaptively perturbing the solution to escape local optima, ensuring feasibility through strict weight constraint checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Dynamic \u03b5-dominance ranking\n    \u03b5 = 0.1  # \u03b5 parameter for dominance\n    ranked_solutions = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and\n                (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                if not (obj[0] >= other_obj[0] - \u03b5 * other_obj[0] and obj[1] >= other_obj[1] - \u03b5 * other_obj[1]):\n                    dominated = True\n                    break\n        if not dominated:\n            ranked_solutions.append((sol, obj))\n\n    if not ranked_solutions:\n        ranked_solutions = archive\n\n    # Select a solution with high potential for improvement\n    selected = max(ranked_solutions, key=lambda x: 0.7 * x[1][0] + 0.3 * x[1][1])\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate weighted marginal gains\n    marginal_gain = (0.7 * value1_lst + 0.3 * value2_lst) / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(-marginal_gain)\n\n    # Targeted flips based on marginal gains\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = temp_weight\n                break\n        else:\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = temp_weight\n                break\n\n    # Adaptive perturbation\n    perturbation_rate = 0.3 if np.sum(new_solution) > 0.7 * len(new_solution) else 0.1\n    if np.random.rand() < perturbation_rate:\n        candidate_indices = [i for i in range(len(new_solution))\n                           if (new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                              (new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if candidate_indices:\n            num_flips = min(3, len(candidate_indices))\n            flip_indices = np.random.choice(candidate_indices, size=num_flips, replace=False)\n            for flip_idx in flip_indices:\n                new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # Ensure feasibility\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        remove_idx = np.random.choice(excess_items)\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.7585863788249091,
            1.4973205626010895
        ]
    },
    {
        "algorithm": "The algorithm selects a promising base solution from the archive by prioritizing those with higher combined normalized values (60% weight for value1, 40% for value2) and then applies a hybrid local search: it first flips the top 5 items that most improve both objectives while maintaining feasibility, followed by occasional aggressive random flips to escape local optima, and finally ensures feasibility by removing items if necessary. The approach balances exploitation (targeted flips) and exploration (random flips) while strictly enforcing the knapsack capacity constraint.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select base solution with high potential for improvement in both objectives\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        candidates.append((sol, obj, total_weight))\n\n    # Sort by a weighted combination of both objectives (prioritize higher values)\n    candidates.sort(key=lambda x: (0.6 * x[1][0] / np.sum(value1_lst)) + 0.4 * (x[1][1] / np.sum(value2_lst)), reverse=True)\n\n    # Select top 30% of candidates or at least 1\n    selection_pool = candidates[:max(1, len(candidates) // 3)]\n    base_sol, _, base_weight = random.choice(selection_pool)\n\n    new_solution = base_sol.copy()\n\n    # Hybrid local search strategy\n    # 1. Find items that can be flipped to improve both objectives\n    candidates_to_flip = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Consider removing this item\n            new_weight = base_weight - weight_lst[i]\n            if new_weight <= capacity:\n                improvement = (value1_lst[i] + value2_lst[i])  # Combined improvement for both objectives\n                candidates_to_flip.append((i, improvement, new_weight))\n        else:\n            # Consider adding this item\n            new_weight = base_weight + weight_lst[i]\n            if new_weight <= capacity:\n                improvement = (value1_lst[i] + value2_lst[i])  # Combined improvement for both objectives\n                candidates_to_flip.append((i, improvement, new_weight))\n\n    # 2. Select top 5 candidates with highest combined improvement\n    candidates_to_flip.sort(key=lambda x: x[1], reverse=True)\n    selected_flips = candidates_to_flip[:min(5, len(candidates_to_flip))]\n\n    # 3. Apply the flips\n    for i, _, _ in selected_flips:\n        new_solution[i] = 1 - new_solution[i]\n\n    # 4. Additional more aggressive random flips to escape local optima\n    if random.random() > 0.5:  # 50% chance\n        candidate_indices = [i for i in range(len(new_solution))\n                            if (new_solution[i] == 1 and base_weight - weight_lst[i] <= capacity) or\n                               (new_solution[i] == 0 and base_weight + weight_lst[i] <= capacity)]\n        if candidate_indices:\n            # Select multiple random flips (2-3)\n            num_flips = random.randint(2, 3)\n            flip_indices = random.sample(candidate_indices, min(num_flips, len(candidate_indices)))\n            for flip_idx in flip_indices:\n                new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    while total_weight > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        remove_idx = random.choice(excess_items)\n        new_solution[remove_idx] = 0\n        total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9241693697524226,
            4.843086838722229
        ]
    },
    {
        "algorithm": "The algorithm combines \u03b5-dominance-based solution selection with a hybrid local search that prioritizes high-marginal-gain items, adaptively perturbs solutions based on capacity utilization, and ensures feasibility through rigorous checks. It balances exploitation (value-weighted flips) and exploration (perturbation) while dynamically adjusting search intensity based on solution quality and capacity constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Hybrid ranking combining \u03b5-dominance and objective diversity\n    def hybrid_rank(solutions):\n        ranks = {}\n        for i, (sol_i, obj_i) in enumerate(solutions):\n            rank = 0\n            for j, (sol_j, obj_j) in enumerate(solutions):\n                if i != j:\n                    # \u03b5-dominance component\n                    if obj_j[0] >= obj_i[0] and obj_j[1] >= obj_i[1]:\n                        if obj_j[0] > obj_i[0] or obj_j[1] > obj_i[1]:\n                            rank += 1\n                    # Objective diversity component\n                    rank += abs(obj_i[0] - obj_j[0]) + abs(obj_i[1] - obj_j[1])\n            ranks[i] = rank\n        return ranks\n\n    ranks = hybrid_rank(archive)\n    sorted_indices = sorted(ranks.keys(), key=lambda x: ranks[x])\n    top_20_percent = max(1, len(archive) // 5)\n    selected_idx = random.choice(sorted_indices[:top_20_percent])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Value-weighted flip operator\n    weight_factor = 0.5 if current_weight > 0.6 * capacity else 0.6\n    marginal_gain = (weight_factor * value1_lst + (1 - weight_factor) * value2_lst) / (weight_lst + 1e-6)\n    sorted_items = np.argsort(-marginal_gain)\n\n    # Perform value-weighted flips\n    for i in sorted_items:\n        if new_solution[i] == 1:\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = temp_weight\n                break\n        else:\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = temp_weight\n                break\n\n    # Capacity-aware item prioritization\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Prioritize items with high marginal gain and low weight\n        prioritized_items = np.argsort(-marginal_gain / (weight_lst + 1e-6))\n        for i in prioritized_items:\n            if new_solution[i] == 0 and weight_lst[i] <= remaining_capacity:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n                if remaining_capacity <= 0:\n                    break\n\n    # Adaptive perturbation based on marginal gains and capacity\n    perturbation_prob = 0.2 if current_weight > 0.7 * capacity else 0.1\n    if random.random() < perturbation_prob:\n        candidate_indices = [i for i in sorted_items[:min(10, len(sorted_items))]\n                           if (new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                              (new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if candidate_indices:\n            num_swaps = random.randint(1, min(2, len(candidate_indices)))\n            swap_indices = random.sample(candidate_indices, num_swaps)\n            for i in swap_indices:\n                new_solution[i] = 1 - new_solution[i]\n                current_weight += (1 if new_solution[i] == 1 else -1) * weight_lst[i]\n\n    # Final feasibility check\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        excess_items_sorted = sorted(excess_items, key=lambda x: marginal_gain[x])\n        remove_idx = excess_items_sorted[0]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9032156835717859,
            3.3540995121002197
        ]
    },
    {
        "algorithm": "The algorithm dynamically selects a high-quality solution from the archive using a hybrid ranking metric that balances normalized objective improvements and diversity, then applies a multi-phase local search: first performing targeted flips based on adaptive marginal contribution (prioritizing items with higher normalized value-to-weight ratios) and second introducing controlled random walks to escape local optima, while strictly maintaining feasibility through capacity checks. The marginal contribution calculation adapts to the current solution's weight status (tightening capacity constraints increase the weight factor's influence), and the random walk phase occasionally flips items to explore new regions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Dynamic selection: Hybrid ranking combining normalized objectives and diversity\n    def hybrid_rank(sol_obj):\n        sol, obj = sol_obj\n        norm_obj1 = obj[0] / (np.sum(value1_lst) + 1e-6)\n        norm_obj2 = obj[1] / (np.sum(value2_lst) + 1e-6)\n        diversity = np.sum(sol != archive[0][0]) / len(sol)\n        return (norm_obj1 + norm_obj2) * 0.7 + diversity * 0.3\n\n    ranked_solutions = sorted(archive, key=hybrid_rank, reverse=True)\n    base_solution = ranked_solutions[0][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Targeted flips based on adaptive marginal contribution\n    alpha = 0.5\n    if current_weight > 0.6 * capacity:\n        alpha = 0.7\n    marginal_contrib = alpha * (value1_lst / weight_lst) + (1 - alpha) * (value2_lst / weight_lst)\n    sorted_indices = np.argsort(-marginal_contrib)\n\n    for i in sorted_indices[:3]:  # Consider top 3 candidates\n        if new_solution[i] == 1:\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = temp_weight\n                break\n        else:\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = temp_weight\n                break\n\n    # Phase 2: Controlled random walk for exploration\n    if np.random.rand() < 0.4:  # 40% chance of random walk\n        walk_steps = np.random.randint(1, 4)\n        for _ in range(walk_steps):\n            flip_candidates = np.where(new_solution == 1)[0]\n            if len(flip_candidates) > 0:\n                i = np.random.choice(flip_candidates)\n                temp_weight = current_weight - weight_lst[i]\n                if temp_weight <= capacity:\n                    new_solution[i] = 0\n                    current_weight = temp_weight\n\n    return new_solution\n\n",
        "score": [
            -0.9022887170714534,
            3.910616010427475
        ]
    },
    {
        "algorithm": "The algorithm selects promising solutions from the archive based on \u03b5-dominance ranks, prioritizes flips using weighted marginal gains combining both objectives, and applies adaptive perturbations to balance exploration and exploitation while strictly maintaining feasibility through targeted item flips and final feasibility checks. The weight factor dynamically adjusts based on current capacity usage, and perturbations are more frequent when near capacity limits.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Calculate \u03b5-dominance ranks for all solutions\n    def calculate_epsilon_dominance(solutions):\n        ranks = {}\n        for i, (sol_i, obj_i) in enumerate(solutions):\n            rank = 0\n            for j, (sol_j, obj_j) in enumerate(solutions):\n                if i != j and obj_j[0] >= obj_i[0] and obj_j[1] >= obj_i[1]:\n                    if obj_j[0] > obj_i[0] or obj_j[1] > obj_i[1]:\n                        rank += 1\n            ranks[i] = rank\n        return ranks\n\n    ranks = calculate_epsilon_dominance(archive)\n    sorted_indices = sorted(ranks.keys(), key=lambda x: ranks[x])\n    top_20_percent = max(1, len(archive) // 5)\n    selected_idx = random.choice(sorted_indices[:top_20_percent])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate weighted marginal gains\n    weight_factor = 0.6 if current_weight > 0.7 * capacity else 0.4\n    marginal_gain = (weight_factor * value1_lst + (1 - weight_factor) * value2_lst) / (weight_lst + 1e-6)\n    sorted_items = np.argsort(-marginal_gain)\n\n    # Perform targeted flips\n    for i in sorted_items:\n        if new_solution[i] == 1:\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = temp_weight\n                break\n        else:\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = temp_weight\n                break\n\n    # Adaptive perturbation\n    perturbation_prob = 0.3 if current_weight > 0.8 * capacity else 0.1\n    if random.random() < perturbation_prob:\n        candidate_indices = [i for i in range(len(weight_lst))\n                           if (new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                              (new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if candidate_indices:\n            num_flips = random.randint(1, min(3, len(candidate_indices)))\n            flip_indices = random.sample(candidate_indices, num_flips)\n            for i in flip_indices:\n                new_solution[i] = 1 - new_solution[i]\n                current_weight += (1 if new_solution[i] == 1 else -1) * weight_lst[i]\n\n    # Final feasibility check\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        remove_idx = random.choice(excess_items)\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.3368376317066809,
            1.4845050573349
        ]
    }
]