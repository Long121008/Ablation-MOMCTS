[
    {
        "algorithm": "The algorithm selects a solution from the archive with the minimum sum of objectives, then applies a hybrid local search that prioritizes items with high marginal contribution (combining both objectives) through targeted swaps and adaptive perturbations, while ensuring feasibility by checking weight constraints at each step. The method balances exploitation (via marginal contribution sorting) and exploration (via random perturbations), with higher priority given to items that improve both objectives proportionally.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with the minimum sum of objectives (diverse selection)\n    selected = min(archive, key=lambda x: sum(x[1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: prioritize items with high marginal contribution for both objectives\n    marginal_value1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_value2 = value2_lst / (weight_lst + 1e-6)\n    marginal_contribution = marginal_value1 + marginal_value2\n\n    # Sort items by marginal contribution (descending)\n    sorted_indices = np.argsort(-marginal_contribution)\n\n    # Step 1: Perform targeted swaps (explore neighborhood)\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            # Try removing item i\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n                break\n        else:\n            # Try adding item i\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n                break\n\n    # Step 2: Adaptive perturbation with higher probability (50% chance)\n    if np.random.rand() < 0.5:\n        # Select a random subset of items to perturb (up to 5 items)\n        perturbation_indices = np.random.choice(len(weight_lst), size=min(5, len(weight_lst)), replace=False)\n        for i in perturbation_indices:\n            if new_solution[i] == 1:\n                temp_solution = new_solution.copy()\n                temp_solution[i] = 0\n                temp_weight = current_weight - weight_lst[i]\n                if temp_weight <= capacity:\n                    new_solution = temp_solution\n                    current_weight = temp_weight\n            else:\n                temp_solution = new_solution.copy()\n                temp_solution[i] = 1\n                temp_weight = current_weight + weight_lst[i]\n                if temp_weight <= capacity:\n                    new_solution = temp_solution\n                    current_weight = temp_weight\n\n    return new_solution\n\n",
        "score": [
            -0.8062330467894219,
            1.2104815542697906
        ]
    },
    {
        "algorithm": "The algorithm combines dynamic \u03b5-dominance filtering to select promising solutions, ranks them by objective balance and total value, and generates neighbors through an objective-balanced flip strategy that prioritizes items with high combined marginal gains across both objectives while dynamically adjusting perturbation probabilities based on solution balance and capacity constraints. It ensures feasibility by strategically flipping items in order of combined gain and balance ratio, with adaptive perturbations to escape local optima when needed.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Dynamic \u03b5-dominance filtering and ranking\n    epsilon = 0.1\n    filtered_solutions = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] >= obj[0] - epsilon and other_obj[1] >= obj[1] - epsilon and\n                (other_obj[0] > obj[0] - epsilon or other_obj[1] > obj[1] - epsilon)):\n                dominated = True\n                break\n        if not dominated:\n            filtered_solutions.append((sol, obj))\n\n    if not filtered_solutions:\n        filtered_solutions = archive.copy()\n\n    # Rank solutions by objective balance and value\n    ranked_solutions = sorted(filtered_solutions, key=lambda x: (abs(x[1][0] - x[1][1]), x[1][0] + x[1][1]), reverse=True)\n    selected_idx = min(int(len(ranked_solutions) * 0.3), len(ranked_solutions) - 1)\n    base_solution = ranked_solutions[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate current values\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Objective-balanced flip strategy\n    marginal_gain1 = value1_lst / (weight_lst + 1e-6)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Sort by combined gain and value balance\n    balance_ratio = value2_lst / (value1_lst + 1e-6)\n    sorted_indices = np.argsort(-combined_gain * balance_ratio)\n\n    # Try to flip items with high combined gain and balanced values\n    for i in sorted_indices:\n        if new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n            break\n        elif new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n            break\n\n    # Adaptive perturbation based on solution balance\n    balance_diff = abs(current_value1 - current_value2)\n    perturbation_prob = 0.2 if balance_diff > 0.1 * max(current_value1, current_value2) else 0.1\n\n    if np.random.rand() < perturbation_prob:\n        # Perturb by flipping items with low combined gain\n        low_gain_indices = np.argsort(combined_gain)\n        for i in low_gain_indices[:min(3, len(low_gain_indices))]:\n            if new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n            elif new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.8743937739183254,
            1.3375412225723267
        ]
    },
    {
        "algorithm": "The algorithm dynamically selects promising solutions from an archive using \u03b5-dominance ranking, prioritizes item flips based on weighted marginal gains combining both objectives, and applies adaptive perturbations proportional to remaining capacity while ensuring feasibility at each step. It first filters non-dominated solutions, selects the best one, calculates weighted marginal gains to guide flips, and then performs feasibility-aware additions/removals with adaptive perturbation for further exploration. The weight factor balances objectives based on current capacity utilization, and final checks ensure feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Dynamic \u03b5-dominance ranking\n    epsilon = 0.1\n    filtered_solutions = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] >= obj[0] - epsilon and other_obj[1] >= obj[1] - epsilon and\n                (other_obj[0] > obj[0] - epsilon or other_obj[1] > obj[1] - epsilon)):\n                dominated = True\n                break\n        if not dominated:\n            filtered_solutions.append((sol, obj))\n\n    if not filtered_solutions:\n        filtered_solutions = archive.copy()\n\n    # Select solution with best \u03b5-dominance rank\n    selected_idx = np.argmax([sum(obj) for _, obj in filtered_solutions])\n    base_solution = filtered_solutions[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate weighted marginal gains\n    weight_factor = 0.5 if current_weight > 0.6 * capacity else 0.6\n    marginal_gain = (weight_factor * value1_lst + (1 - weight_factor) * value2_lst) / (weight_lst + 1e-6)\n\n    # Sort by marginal gain (descending)\n    sorted_indices = np.argsort(-marginal_gain)\n\n    # Perform feasibility-aware flips\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            # Try removing item\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = temp_weight\n                break\n        else:\n            # Try adding item\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = temp_weight\n                break\n\n    # Adaptive perturbation based on remaining capacity\n    remaining_capacity = capacity - current_weight\n    perturbation_prob = min(0.3, 0.1 + remaining_capacity / capacity * 0.2)\n\n    if np.random.rand() < perturbation_prob:\n        # Select items with low marginal gain for potential flip\n        low_gain_indices = np.argsort(marginal_gain)\n        for i in low_gain_indices[:min(3, len(low_gain_indices))]:\n            if new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n            elif new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Final feasibility check\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        excess_items_sorted = sorted(excess_items, key=lambda x: marginal_gain[x])\n        remove_idx = excess_items_sorted[0]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9674873137843483,
            1.3716097474098206
        ]
    },
    {
        "algorithm": "The algorithm uses \u03b5-dominance ranking to select high-quality, diverse solutions from the archive, then applies a hybrid local search combining weighted marginal gain prioritization (with adaptive weights based on current knapsack utilization) and targeted perturbations (flipping 1-3 random items with probability dependent on capacity usage), ensuring feasibility at every step. The weighted marginal gain balances both objectives dynamically, while adaptive perturbations introduce controlled exploration.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # \u03b5-dominance ranking to select diverse high-quality solutions\n    epsilon = 0.1  # \u03b5 parameter for \u03b5-dominance\n    ranked_solutions = []\n    for sol, obj in archive:\n        dominated = False\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] - epsilon and other_obj[1] >= obj[1] - epsilon and\n                (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated = True\n                break\n        if not dominated:\n            ranked_solutions.append((sol, obj))\n\n    if not ranked_solutions:\n        ranked_solutions = archive\n\n    # Select solution with highest \u03b5-dominated rank (sum of objectives)\n    selected = max(ranked_solutions, key=lambda x: sum(x[1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate weighted marginal gains\n    weight_factor = 0.6 if current_weight > 0.8 * capacity else 0.4\n    marginal_gain = (weight_factor * value1_lst + (1 - weight_factor) * value2_lst) / (weight_lst + 1e-6)\n\n    # Sort items by marginal gain (descending)\n    sorted_indices = np.argsort(-marginal_gain)\n\n    # Local search with targeted flips\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            # Try removing item\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = temp_weight\n                break\n        else:\n            # Try adding item\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = temp_weight\n                break\n\n    # Adaptive perturbation\n    perturbation_prob = 0.3 if current_weight > 0.7 * capacity else 0.15\n    if np.random.rand() < perturbation_prob:\n        # Select 3 random items to perturb\n        perturb_indices = np.random.choice(len(weight_lst), size=min(3, len(weight_lst)), replace=False)\n        for i in perturb_indices:\n            if new_solution[i] == 1:\n                temp_weight = current_weight - weight_lst[i]\n                if temp_weight <= capacity:\n                    new_solution[i] = 0\n                    current_weight = temp_weight\n            else:\n                temp_weight = current_weight + weight_lst[i]\n                if temp_weight <= capacity:\n                    new_solution[i] = 1\n                    current_weight = temp_weight\n\n    return new_solution\n\n",
        "score": [
            -0.4076089573457292,
            1.276840090751648
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a diverse solution from the archive (prioritize those with high objective values but not already explored)\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]) / 2, reverse=True)\n    selected_idx = min(int(len(archive) * 0.4), len(archive) - 1)  # Select from top 40% of solutions\n    base_solution = archive_sorted[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate dynamic marginal contribution (combining both objectives with weight adjustment)\n    alpha = 0.5  # Initial balance factor between objectives\n    if current_weight > 0.7 * capacity:\n        alpha = 0.7  # Increase focus on objective 1 when close to capacity\n    marginal_contribution = alpha * (value1_lst / weight_lst) + (1 - alpha) * (value2_lst / weight_lst)\n\n    # Sort items by dynamic marginal contribution (descending)\n    sorted_indices = np.argsort(-marginal_contribution)\n\n    # Perform targeted swaps and additions\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            # Try removing item i if it's not critical\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n                break\n        else:\n            # Try adding item i if it fits\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                # Check if adding this item improves both objectives sufficiently\n                if (value1_lst[i] > 0 and value2_lst[i] > 0) or (temp_weight <= 0.9 * capacity):\n                    new_solution[i] = 1\n                    current_weight = temp_weight\n                    break\n\n    # Adaptive diversification (higher probability when stuck)\n    diversification_rate = 0.2 if current_weight > 0.8 * capacity else 0.1\n    if np.random.rand() < diversification_rate:\n        # Perform multiple random flips with feasibility checks\n        flip_indices = np.random.choice(len(weight_lst), size=min(4, len(weight_lst)), replace=False)\n        for i in flip_indices:\n            if new_solution[i] == 1:\n                temp_solution = new_solution.copy()\n                temp_solution[i] = 0\n                temp_weight = current_weight - weight_lst[i]\n                if temp_weight <= capacity:\n                    new_solution = temp_solution\n                    current_weight = temp_weight\n            else:\n                temp_weight = current_weight + weight_lst[i]\n                if temp_weight <= capacity:\n                    new_solution[i] = 1\n                    current_weight = temp_weight\n\n    return new_solution\n\n",
        "score": [
            -0.9208547939029279,
            1.5441421568393707
        ]
    },
    {
        "algorithm": "The algorithm dynamically selects promising solutions from the archive using a hybrid ranking metric combining \u03b5-dominance and objective diversity, then applies a value-weighted swap operator that prioritizes items with high marginal gains for both objectives while maintaining feasibility, followed by an adaptive perturbation phase that probabilistically swaps items based on their marginal gains and current capacity utilization. The selection prioritizes items with better marginal gains for both objectives, and the perturbation phase adjusts exploration intensity based on capacity usage.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Hybrid ranking: combine \u03b5-dominance and objective diversity\n    def hybrid_rank(solutions):\n        ranks = {}\n        for i, (sol_i, obj_i) in enumerate(solutions):\n            rank = 0\n            for j, (sol_j, obj_j) in enumerate(solutions):\n                if i != j:\n                    # \u03b5-dominance component\n                    if obj_j[0] >= obj_i[0] and obj_j[1] >= obj_i[1]:\n                        if obj_j[0] > obj_i[0] or obj_j[1] > obj_i[1]:\n                            rank += 1\n                    # Objective diversity component\n                    rank += abs(obj_i[0] - obj_j[0]) + abs(obj_i[1] - obj_j[1])\n            ranks[i] = rank\n        return ranks\n\n    ranks = hybrid_rank(archive)\n    sorted_indices = sorted(ranks.keys(), key=lambda x: ranks[x])\n    top_20_percent = max(1, len(archive) // 5)\n    selected_idx = random.choice(sorted_indices[:top_20_percent])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Value-weighted swap operator\n    weight_factor = 0.5 if current_weight > 0.6 * capacity else 0.6\n    marginal_gain = (weight_factor * value1_lst + (1 - weight_factor) * value2_lst) / (weight_lst + 1e-6)\n    sorted_items = np.argsort(-marginal_gain)\n\n    # Perform value-weighted swaps\n    for i in sorted_items:\n        if new_solution[i] == 1:\n            # Try removing item i\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = temp_weight\n                break\n        else:\n            # Try adding item i\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = temp_weight\n                break\n\n    # Adaptive perturbation based on marginal gains\n    perturbation_prob = 0.2 if current_weight > 0.7 * capacity else 0.1\n    if random.random() < perturbation_prob:\n        # Select items with high marginal gains for potential swap\n        candidate_indices = [i for i in sorted_items[:min(10, len(sorted_items))]\n                           if (new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                              (new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if candidate_indices:\n            num_swaps = random.randint(1, min(2, len(candidate_indices)))\n            swap_indices = random.sample(candidate_indices, num_swaps)\n            for i in swap_indices:\n                new_solution[i] = 1 - new_solution[i]\n                current_weight += (1 if new_solution[i] == 1 else -1) * weight_lst[i]\n\n    # Final feasibility check\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        # Remove item with lowest marginal gain\n        excess_items_sorted = sorted(excess_items, key=lambda x: marginal_gain[x])\n        remove_idx = excess_items_sorted[0]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9292649166811169,
            2.8038553595542908
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using a hybrid ranking method combining \u03b5-dominance and objective diversity, then applies a dynamic marginal-gain-based local search with adaptive perturbation to generate a feasible neighbor solution, prioritizing high-value items while respecting capacity constraints. The method balances exploration and exploitation through weighted marginal gains and capacity-aware perturbations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Hybrid selection: \u03b5-dominance ranking combined with objective diversity\n    def hybrid_rank(solutions):\n        ranks = {}\n        for i, (sol_i, obj_i) in enumerate(solutions):\n            rank = 0\n            for j, (sol_j, obj_j) in enumerate(solutions):\n                if i != j:\n                    # \u03b5-dominance component\n                    if obj_j[0] >= obj_i[0] and obj_j[1] >= obj_i[1]:\n                        if obj_j[0] > obj_i[0] or obj_j[1] > obj_i[1]:\n                            rank += 1\n                    # Objective diversity component\n                    rank += abs(obj_i[0] - obj_j[0]) + abs(obj_i[1] - obj_j[1])\n            ranks[i] = rank\n        return ranks\n\n    ranks = hybrid_rank(archive)\n    sorted_indices = sorted(ranks.keys(), key=lambda x: ranks[x])\n    top_30_percent = max(1, len(archive) // 3)\n    selected_idx = random.choice(sorted_indices[:top_30_percent])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Dynamic marginal gain calculation with adaptive weighting\n    weight_factor = 0.5 if current_weight > 0.6 * capacity else 0.6\n    marginal_gain = (weight_factor * value1_lst + (1 - weight_factor) * value2_lst) / (weight_lst + 1e-6)\n    sorted_items = np.argsort(-marginal_gain)\n\n    # Priority-based flips: first try to add high-gain items, then remove low-gain items\n    for i in sorted_items:\n        if new_solution[i] == 0:\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = temp_weight\n                break\n\n    if current_weight < capacity:\n        for i in sorted_items:\n            if new_solution[i] == 1:\n                temp_weight = current_weight - weight_lst[i]\n                if temp_weight <= capacity:\n                    new_solution[i] = 0\n                    current_weight = temp_weight\n                    break\n\n    # Adaptive perturbation based on marginal gains and capacity\n    perturbation_prob = 0.3 if current_weight > 0.7 * capacity else 0.15\n    if random.random() < perturbation_prob:\n        candidate_indices = [i for i in sorted_items[:min(10, len(sorted_items))]\n                           if (new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                              (new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if candidate_indices:\n            num_swaps = random.randint(1, min(3, len(candidate_indices)))\n            swap_indices = random.sample(candidate_indices, num_swaps)\n            for i in swap_indices:\n                new_solution[i] = 1 - new_solution[i]\n                current_weight += (1 if new_solution[i] == 1 else -1) * weight_lst[i]\n\n    # Final feasibility check\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        excess_items_sorted = sorted(excess_items, key=lambda x: marginal_gain[x])\n        remove_idx = excess_items_sorted[0]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9413592984666055,
            3.0691100358963013
        ]
    },
    {
        "algorithm": "The algorithm selects a non-dominated solution from the archive using Pareto dominance scores, then applies a hybrid local search combining marginal-gain flips (prioritizing high-value items), objective-biased removals (targeting low-value items), and adaptive diversification (30% chance to remove low-combined-value items) while ensuring feasibility through capacity checks. The solution's objective weights dynamically influence item selection, favoring either value1 or value2 based on relative importance.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Dynamic selection based on Pareto dominance\n    obj1_vals = np.array([x[1][0] for x in archive])\n    obj2_vals = np.array([x[1][1] for x in archive])\n    max_obj1, max_obj2 = np.max(obj1_vals), np.max(obj2_vals)\n\n    # Calculate dominance scores\n    dominance_scores = np.zeros(len(archive))\n    for i in range(len(archive)):\n        dominated_count = 0\n        for j in range(len(archive)):\n            if i != j:\n                if (obj1_vals[i] <= obj1_vals[j] and obj2_vals[i] <= obj2_vals[j]) and (obj1_vals[i] < obj1_vals[j] or obj2_vals[i] < obj2_vals[j]):\n                    dominated_count += 1\n        dominance_scores[i] = dominated_count\n\n    # Select solution with highest dominance score (least dominated)\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Calculate objective weights\n    total_obj = archive[selected_idx][1][0] + archive[selected_idx][1][1] + 1e-6\n    obj1_weight = archive[selected_idx][1][0] / total_obj\n    obj2_weight = archive[selected_idx][1][1] / total_obj\n\n    # Step 1: Marginal gain-based flips with adaptive weights\n    flip_scores = np.zeros(len(new_solution))\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Removal case\n            marginal_gain = obj1_weight * value1_lst[i] + obj2_weight * value2_lst[i]\n            flip_scores[i] = -marginal_gain * 0.3\n        else:\n            # Addition case\n            if current_weight + weight_lst[i] <= capacity:\n                marginal_gain = obj1_weight * value1_lst[i] + obj2_weight * value2_lst[i]\n                flip_scores[i] = marginal_gain * 0.7\n\n    if np.any(flip_scores > 0):\n        flip_idx = np.random.choice(len(new_solution), p=flip_scores/np.sum(flip_scores))\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n        current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 2: Objective-biased removals\n    if obj1_weight < obj2_weight:\n        # Remove items with lowest value1/weight ratio\n        value_ratio = value1_lst / (weight_lst + 1e-6)\n        for i in np.argsort(value_ratio):\n            if new_solution[i] == 1:\n                new_solution[i] = 0\n                break\n    else:\n        # Remove items with lowest value2/weight ratio\n        value_ratio = value2_lst / (weight_lst + 1e-6)\n        for i in np.argsort(value_ratio):\n            if new_solution[i] == 1:\n                new_solution[i] = 0\n                break\n\n    # Step 3: Adaptive diversification (30% chance)\n    if random.random() < 0.3:\n        # Remove items with lowest combined value/weight ratio\n        combined_ratio = (obj1_weight * value1_lst + obj2_weight * value2_lst) / (weight_lst + 1e-6)\n        for i in np.argsort(combined_ratio):\n            if new_solution[i] == 1:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.9247401309973853,
            2.7925316095352173
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using dynamic \u03b5-dominance ranking (prioritizing solutions with high combined value, weighted 70% to value1 and 30% to value2), then applies a hybrid local search that flips item selections based on weighted marginal gains while adaptively perturbing the solution to escape local optima, ensuring feasibility through strict weight constraint checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Dynamic \u03b5-dominance ranking\n    \u03b5 = 0.1  # \u03b5 parameter for dominance\n    ranked_solutions = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and\n                (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                if not (obj[0] >= other_obj[0] - \u03b5 * other_obj[0] and obj[1] >= other_obj[1] - \u03b5 * other_obj[1]):\n                    dominated = True\n                    break\n        if not dominated:\n            ranked_solutions.append((sol, obj))\n\n    if not ranked_solutions:\n        ranked_solutions = archive\n\n    # Select a solution with high potential for improvement\n    selected = max(ranked_solutions, key=lambda x: 0.7 * x[1][0] + 0.3 * x[1][1])\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate weighted marginal gains\n    marginal_gain = (0.7 * value1_lst + 0.3 * value2_lst) / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(-marginal_gain)\n\n    # Targeted flips based on marginal gains\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = temp_weight\n                break\n        else:\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = temp_weight\n                break\n\n    # Adaptive perturbation\n    perturbation_rate = 0.3 if np.sum(new_solution) > 0.7 * len(new_solution) else 0.1\n    if np.random.rand() < perturbation_rate:\n        candidate_indices = [i for i in range(len(new_solution))\n                           if (new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                              (new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if candidate_indices:\n            num_flips = min(3, len(candidate_indices))\n            flip_indices = np.random.choice(candidate_indices, size=num_flips, replace=False)\n            for flip_idx in flip_indices:\n                new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # Ensure feasibility\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        remove_idx = np.random.choice(excess_items)\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.7585863788249091,
            1.4973205626010895
        ]
    },
    {
        "algorithm": "The algorithm first selects a promising solution from the archive using a hybrid novelty score that combines Pareto efficiency and objective-space diversity, focusing on the top 25% of solutions. It then applies a dynamic multi-objective local search with weighted marginal gains, where items are flipped based on their combined value-to-weight ratio, with adjustments for current solution density. The method ensures feasibility through targeted perturbations and final marginal-gain-based corrections while maintaining a balance between the two objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Novel hybrid selection: Pareto efficiency + objective-space diversity\n    def novelty_score(solutions):\n        scores = {}\n        for i, (sol_i, obj_i) in enumerate(solutions):\n            score = 0\n            for j, (sol_j, obj_j) in enumerate(solutions):\n                if i != j:\n                    # Pareto efficiency component\n                    if obj_j[0] >= obj_i[0] and obj_j[1] >= obj_i[1]:\n                        if obj_j[0] > obj_i[0] or obj_j[1] > obj_i[1]:\n                            score += 1\n                    # Objective-space diversity component\n                    score += np.sqrt((obj_i[0] - obj_j[0])**2 + (obj_i[1] - obj_j[1])**2)\n            scores[i] = score\n        return scores\n\n    scores = novelty_score(archive)\n    sorted_indices = sorted(scores.keys(), key=lambda x: scores[x])\n    top_25_percent = max(1, len(archive) // 4)\n    selected_idx = random.choice(sorted_indices[:top_25_percent])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Dynamic multi-objective gain calculation\n    weight_factor = 0.5 + 0.4 * (current_weight / capacity)\n    marginal_gain = (weight_factor * value1_lst + (1 - weight_factor) * value2_lst) / (weight_lst + 1e-6)\n    marginal_gain[new_solution == 1] *= 0.8  # Reduce gain for already included items\n\n    # Adaptive local search with density-based perturbations\n    flip_candidates = np.argsort(-marginal_gain)\n    flip_count = min(4, len(flip_candidates))\n    perturbation_threshold = 0.7 * capacity\n\n    for i in flip_candidates[:flip_count]:\n        if new_solution[i] == 1:\n            if current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n        else:\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Targeted perturbations based on solution density\n    if current_weight > perturbation_threshold:\n        density = np.sum(new_solution) / len(new_solution)\n        perturbation_prob = 0.4 * density\n        if random.random() < perturbation_prob:\n            candidate_indices = [i for i in flip_candidates[:min(6, len(flip_candidates))]\n                               if (new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                                  (new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n            if candidate_indices:\n                num_flips = random.randint(1, min(2, len(candidate_indices)))\n                flip_indices = random.sample(candidate_indices, num_flips)\n                for i in flip_indices:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += (1 if new_solution[i] == 1 else -1) * weight_lst[i]\n\n    # Final feasibility check with marginal gain prioritization\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        excess_items_sorted = sorted(excess_items, key=lambda x: -marginal_gain[x])\n        remove_idx = excess_items_sorted[0]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9491427377566615,
            7.735425531864166
        ]
    }
]