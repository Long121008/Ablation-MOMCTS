[
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a diverse solution from the archive (prioritize those with high objective values but not already explored)\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]) / 2, reverse=True)\n    selected_idx = min(int(len(archive) * 0.4), len(archive) - 1)  # Select from top 40% of solutions\n    base_solution = archive_sorted[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate dynamic marginal contribution (combining both objectives with weight adjustment)\n    alpha = 0.5  # Initial balance factor between objectives\n    if current_weight > 0.7 * capacity:\n        alpha = 0.7  # Increase focus on objective 1 when close to capacity\n    marginal_contribution = alpha * (value1_lst / weight_lst) + (1 - alpha) * (value2_lst / weight_lst)\n\n    # Sort items by dynamic marginal contribution (descending)\n    sorted_indices = np.argsort(-marginal_contribution)\n\n    # Perform targeted swaps and additions\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            # Try removing item i if it's not critical\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n                break\n        else:\n            # Try adding item i if it fits\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                # Check if adding this item improves both objectives sufficiently\n                if (value1_lst[i] > 0 and value2_lst[i] > 0) or (temp_weight <= 0.9 * capacity):\n                    new_solution[i] = 1\n                    current_weight = temp_weight\n                    break\n\n    # Adaptive diversification (higher probability when stuck)\n    diversification_rate = 0.2 if current_weight > 0.8 * capacity else 0.1\n    if np.random.rand() < diversification_rate:\n        # Perform multiple random flips with feasibility checks\n        flip_indices = np.random.choice(len(weight_lst), size=min(4, len(weight_lst)), replace=False)\n        for i in flip_indices:\n            if new_solution[i] == 1:\n                temp_solution = new_solution.copy()\n                temp_solution[i] = 0\n                temp_weight = current_weight - weight_lst[i]\n                if temp_weight <= capacity:\n                    new_solution = temp_solution\n                    current_weight = temp_weight\n            else:\n                temp_weight = current_weight + weight_lst[i]\n                if temp_weight <= capacity:\n                    new_solution[i] = 1\n                    current_weight = temp_weight\n\n    return new_solution\n\n",
        "score": [
            -0.9208547939029279,
            1.5441421568393707
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive with the minimum sum of objectives, then applies a hybrid local search that prioritizes items with high marginal contribution (combining both objectives) through targeted swaps and adaptive perturbations, while ensuring feasibility by checking weight constraints at each step. The method balances exploitation (via marginal contribution sorting) and exploration (via random perturbations), with higher priority given to items that improve both objectives proportionally.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with the minimum sum of objectives (diverse selection)\n    selected = min(archive, key=lambda x: sum(x[1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: prioritize items with high marginal contribution for both objectives\n    marginal_value1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_value2 = value2_lst / (weight_lst + 1e-6)\n    marginal_contribution = marginal_value1 + marginal_value2\n\n    # Sort items by marginal contribution (descending)\n    sorted_indices = np.argsort(-marginal_contribution)\n\n    # Step 1: Perform targeted swaps (explore neighborhood)\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            # Try removing item i\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n                break\n        else:\n            # Try adding item i\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n                break\n\n    # Step 2: Adaptive perturbation with higher probability (50% chance)\n    if np.random.rand() < 0.5:\n        # Select a random subset of items to perturb (up to 5 items)\n        perturbation_indices = np.random.choice(len(weight_lst), size=min(5, len(weight_lst)), replace=False)\n        for i in perturbation_indices:\n            if new_solution[i] == 1:\n                temp_solution = new_solution.copy()\n                temp_solution[i] = 0\n                temp_weight = current_weight - weight_lst[i]\n                if temp_weight <= capacity:\n                    new_solution = temp_solution\n                    current_weight = temp_weight\n            else:\n                temp_solution = new_solution.copy()\n                temp_solution[i] = 1\n                temp_weight = current_weight + weight_lst[i]\n                if temp_weight <= capacity:\n                    new_solution = temp_solution\n                    current_weight = temp_weight\n\n    return new_solution\n\n",
        "score": [
            -0.8062330467894219,
            1.2104815542697906
        ]
    },
    {
        "algorithm": "The algorithm selects a promising base solution from the archive by prioritizing those with higher combined normalized values (60% weight for value1, 40% for value2) and then applies a hybrid local search: it first flips the top 5 items that most improve both objectives while maintaining feasibility, followed by occasional aggressive random flips to escape local optima, and finally ensures feasibility by removing items if necessary. The approach balances exploitation (targeted flips) and exploration (random flips) while strictly enforcing the knapsack capacity constraint.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select base solution with high potential for improvement in both objectives\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        candidates.append((sol, obj, total_weight))\n\n    # Sort by a weighted combination of both objectives (prioritize higher values)\n    candidates.sort(key=lambda x: (0.6 * x[1][0] / np.sum(value1_lst)) + 0.4 * (x[1][1] / np.sum(value2_lst)), reverse=True)\n\n    # Select top 30% of candidates or at least 1\n    selection_pool = candidates[:max(1, len(candidates) // 3)]\n    base_sol, _, base_weight = random.choice(selection_pool)\n\n    new_solution = base_sol.copy()\n\n    # Hybrid local search strategy\n    # 1. Find items that can be flipped to improve both objectives\n    candidates_to_flip = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Consider removing this item\n            new_weight = base_weight - weight_lst[i]\n            if new_weight <= capacity:\n                improvement = (value1_lst[i] + value2_lst[i])  # Combined improvement for both objectives\n                candidates_to_flip.append((i, improvement, new_weight))\n        else:\n            # Consider adding this item\n            new_weight = base_weight + weight_lst[i]\n            if new_weight <= capacity:\n                improvement = (value1_lst[i] + value2_lst[i])  # Combined improvement for both objectives\n                candidates_to_flip.append((i, improvement, new_weight))\n\n    # 2. Select top 5 candidates with highest combined improvement\n    candidates_to_flip.sort(key=lambda x: x[1], reverse=True)\n    selected_flips = candidates_to_flip[:min(5, len(candidates_to_flip))]\n\n    # 3. Apply the flips\n    for i, _, _ in selected_flips:\n        new_solution[i] = 1 - new_solution[i]\n\n    # 4. Additional more aggressive random flips to escape local optima\n    if random.random() > 0.5:  # 50% chance\n        candidate_indices = [i for i in range(len(new_solution))\n                            if (new_solution[i] == 1 and base_weight - weight_lst[i] <= capacity) or\n                               (new_solution[i] == 0 and base_weight + weight_lst[i] <= capacity)]\n        if candidate_indices:\n            # Select multiple random flips (2-3)\n            num_flips = random.randint(2, 3)\n            flip_indices = random.sample(candidate_indices, min(num_flips, len(candidate_indices)))\n            for flip_idx in flip_indices:\n                new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    while total_weight > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        remove_idx = random.choice(excess_items)\n        new_solution[remove_idx] = 0\n        total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9241693697524226,
            4.843086838722229
        ]
    },
    {
        "algorithm": "The algorithm dynamically selects a high-quality solution from the archive using a hybrid ranking metric that balances normalized objective improvements and diversity, then applies a multi-phase local search: first performing targeted flips based on adaptive marginal contribution (prioritizing items with higher normalized value-to-weight ratios) and second introducing controlled random walks to escape local optima, while strictly maintaining feasibility through capacity checks. The marginal contribution calculation adapts to the current solution's weight status (tightening capacity constraints increase the weight factor's influence), and the random walk phase occasionally flips items to explore new regions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Dynamic selection: Hybrid ranking combining normalized objectives and diversity\n    def hybrid_rank(sol_obj):\n        sol, obj = sol_obj\n        norm_obj1 = obj[0] / (np.sum(value1_lst) + 1e-6)\n        norm_obj2 = obj[1] / (np.sum(value2_lst) + 1e-6)\n        diversity = np.sum(sol != archive[0][0]) / len(sol)\n        return (norm_obj1 + norm_obj2) * 0.7 + diversity * 0.3\n\n    ranked_solutions = sorted(archive, key=hybrid_rank, reverse=True)\n    base_solution = ranked_solutions[0][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Targeted flips based on adaptive marginal contribution\n    alpha = 0.5\n    if current_weight > 0.6 * capacity:\n        alpha = 0.7\n    marginal_contrib = alpha * (value1_lst / weight_lst) + (1 - alpha) * (value2_lst / weight_lst)\n    sorted_indices = np.argsort(-marginal_contrib)\n\n    for i in sorted_indices[:3]:  # Consider top 3 candidates\n        if new_solution[i] == 1:\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = temp_weight\n                break\n        else:\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = temp_weight\n                break\n\n    # Phase 2: Controlled random walk for exploration\n    if np.random.rand() < 0.4:  # 40% chance of random walk\n        walk_steps = np.random.randint(1, 4)\n        for _ in range(walk_steps):\n            flip_candidates = np.where(new_solution == 1)[0]\n            if len(flip_candidates) > 0:\n                i = np.random.choice(flip_candidates)\n                temp_weight = current_weight - weight_lst[i]\n                if temp_weight <= capacity:\n                    new_solution[i] = 0\n                    current_weight = temp_weight\n\n    return new_solution\n\n",
        "score": [
            -0.9022887170714534,
            3.910616010427475
        ]
    },
    {
        "algorithm": "The algorithm implements an adaptive local search that selects a solution from the archive based on crowding distance for diversity, then applies a hybrid approach combining greedy and randomized item selection with dynamic objective weighting (prioritizing value1 when near capacity, value2 otherwise) and quality-based diversification. It iteratively improves the solution by removing low-impact items and adding high-marginal-benefit items, with adaptive probabilities for further diversification when solution quality is low.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution with highest crowding distance in objective space for diversity\n    def crowding_distance(solutions):\n        if len(solutions) < 3:\n            return [1.0] * len(solutions)\n        sorted_obj1 = sorted(solutions, key=lambda x: x[1][0])\n        sorted_obj2 = sorted(solutions, key=lambda x: x[1][1])\n\n        distances = [0.0] * len(solutions)\n        for i in range(1, len(solutions)-1):\n            distances[i] = (sorted_obj1[i+1][1][0] - sorted_obj1[i-1][1][0]) / (sorted_obj1[-1][1][0] - sorted_obj1[0][1][0]) + \\\n                          (sorted_obj2[i+1][1][1] - sorted_obj2[i-1][1][1]) / (sorted_obj2[-1][1][1] - sorted_obj2[0][1][1])\n        return distances\n\n    distances = crowding_distance(archive)\n    selected_idx = np.argmax(distances)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Dynamic objective weighting based on solution quality\n    alpha = 0.5\n    if current_weight > 0.8 * capacity:\n        alpha = 0.6 + 0.2 * (current_weight / capacity)  # More emphasis on value1 as capacity approaches\n    else:\n        alpha = 0.4 + 0.4 * (current_weight / capacity)  # More emphasis on value2 when capacity is underutilized\n\n    # Hybrid selection metric combining efficiency and diversity\n    efficiency = (alpha * value1_lst + (1-alpha) * value2_lst) / weight_lst\n    diversity = np.abs(new_solution - 0.5)  # Items not in solution get higher diversity score\n    selection_metric = efficiency * (1 + 0.5 * diversity)\n\n    # Sort items by selection metric (descending)\n    sorted_indices = np.argsort(-selection_metric)\n\n    # Perform targeted operations\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            # Consider removing item if it's not critical\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity and (temp_weight >= 0.7 * capacity or np.random.rand() < 0.3):\n                new_solution = temp_solution\n                current_weight = temp_weight\n                break\n        else:\n            # Consider adding item if it fits and improves both objectives\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                improvement1 = value1_lst[i] / (temp_weight - current_weight)\n                improvement2 = value2_lst[i] / (temp_weight - current_weight)\n                if (improvement1 > 0.1 or improvement2 > 0.1) and (temp_weight <= 0.95 * capacity or np.random.rand() < 0.4):\n                    new_solution[i] = 1\n                    current_weight = temp_weight\n                    break\n\n    # Adaptive diversification with quality-based probability\n    quality = (np.sum(value1_lst * new_solution) + np.sum(value2_lst * new_solution)) / (2 * np.sum(weight_lst * new_solution))\n    diversification_rate = 0.1 + 0.3 * (1 - quality)  # Higher rate when solution quality is low\n\n    if np.random.rand() < diversification_rate:\n        # Perform multiple guided flips\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            for i in np.random.choice(flip_candidates, size=min(3, len(flip_candidates)), replace=False):\n                temp_solution = new_solution.copy()\n                temp_solution[i] = 0\n                temp_weight = current_weight - weight_lst[i]\n                if temp_weight <= capacity and (temp_weight >= 0.6 * capacity or np.random.rand() < 0.5):\n                    new_solution = temp_solution\n                    current_weight = temp_weight\n\n        # Add new items with high marginal benefit\n        available_items = np.where(new_solution == 0)[0]\n        if len(available_items) > 0:\n            marginal_benefit = (alpha * value1_lst[available_items] + (1-alpha) * value2_lst[available_items]) / weight_lst[available_items]\n            best_add = np.argmax(marginal_benefit)\n            i = available_items[best_add]\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity and (temp_weight <= 0.9 * capacity or np.random.rand() < 0.6):\n                new_solution[i] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.8573164286911579,
            1.61256542801857
        ]
    },
    {
        "algorithm": "The algorithm selects the most promising solution from the archive (based on the sum of objectives) and applies a hybrid local search strategy that prioritizes items with high marginal contribution (combining both objectives) through strategic swaps, followed by adaptive perturbation for exploration. It ensures feasibility by checking weight constraints at each step, balancing exploitation (targeted swaps) with exploration (random perturbations).",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution (here, we select the one with the highest sum of objectives)\n    selected = max(archive, key=lambda x: sum(x[1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: swap items with high potential and adaptive perturbation\n    # Step 1: Identify items with high marginal contribution\n    marginal_value1 = value1_lst / weight_lst\n    marginal_value2 = value2_lst / weight_lst\n    marginal_contribution = marginal_value1 + marginal_value2\n\n    # Step 2: Sort items by marginal contribution (descending)\n    sorted_indices = np.argsort(-marginal_contribution)\n\n    # Step 3: Perform item swaps (explore neighborhood)\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            # Try removing item i\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n                break\n        else:\n            # Try adding item i\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n                break\n\n    # Step 4: Adaptive perturbation (explore further)\n    if np.random.rand() < 0.3:  # 30% chance of perturbation\n        perturbation_indices = np.random.choice(len(weight_lst), size=min(3, len(weight_lst)), replace=False)\n        for i in perturbation_indices:\n            if new_solution[i] == 1:\n                temp_solution = new_solution.copy()\n                temp_solution[i] = 0\n                temp_weight = current_weight - weight_lst[i]\n                if temp_weight <= capacity:\n                    new_solution = temp_solution\n                    current_weight = temp_weight\n            else:\n                temp_solution = new_solution.copy()\n                temp_solution[i] = 1\n                temp_weight = current_weight + weight_lst[i]\n                if temp_weight <= capacity:\n                    new_solution = temp_solution\n                    current_weight = temp_weight\n\n    return new_solution\n\n",
        "score": [
            -0.5071726637714051,
            1.588004618883133
        ]
    },
    {
        "algorithm": "The algorithm uses \u03b5-dominance ranking to select high-quality, diverse solutions from the archive, then applies a hybrid local search combining weighted marginal gain prioritization (with adaptive weights based on current knapsack utilization) and targeted perturbations (flipping 1-3 random items with probability dependent on capacity usage), ensuring feasibility at every step. The weighted marginal gain balances both objectives dynamically, while adaptive perturbations introduce controlled exploration.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # \u03b5-dominance ranking to select diverse high-quality solutions\n    epsilon = 0.1  # \u03b5 parameter for \u03b5-dominance\n    ranked_solutions = []\n    for sol, obj in archive:\n        dominated = False\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] - epsilon and other_obj[1] >= obj[1] - epsilon and\n                (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated = True\n                break\n        if not dominated:\n            ranked_solutions.append((sol, obj))\n\n    if not ranked_solutions:\n        ranked_solutions = archive\n\n    # Select solution with highest \u03b5-dominated rank (sum of objectives)\n    selected = max(ranked_solutions, key=lambda x: sum(x[1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate weighted marginal gains\n    weight_factor = 0.6 if current_weight > 0.8 * capacity else 0.4\n    marginal_gain = (weight_factor * value1_lst + (1 - weight_factor) * value2_lst) / (weight_lst + 1e-6)\n\n    # Sort items by marginal gain (descending)\n    sorted_indices = np.argsort(-marginal_gain)\n\n    # Local search with targeted flips\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            # Try removing item\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = temp_weight\n                break\n        else:\n            # Try adding item\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = temp_weight\n                break\n\n    # Adaptive perturbation\n    perturbation_prob = 0.3 if current_weight > 0.7 * capacity else 0.15\n    if np.random.rand() < perturbation_prob:\n        # Select 3 random items to perturb\n        perturb_indices = np.random.choice(len(weight_lst), size=min(3, len(weight_lst)), replace=False)\n        for i in perturb_indices:\n            if new_solution[i] == 1:\n                temp_weight = current_weight - weight_lst[i]\n                if temp_weight <= capacity:\n                    new_solution[i] = 0\n                    current_weight = temp_weight\n            else:\n                temp_weight = current_weight + weight_lst[i]\n                if temp_weight <= capacity:\n                    new_solution[i] = 1\n                    current_weight = temp_weight\n\n    return new_solution\n\n",
        "score": [
            -0.4076089573457292,
            1.276840090751648
        ]
    },
    {
        "algorithm": "The algorithm selects a base solution from the archive, prioritizing those with lower weights or higher values, then applies a hybrid local search that combines value-based flips with an objective-balancing mechanism to explore trade-offs between the two objectives, occasionally introducing random perturbations to escape local optima while ensuring feasibility. The selection process weighs weight diversity (50%), value1 (30%), and value2 (20%) in the candidate ranking, and the local search dynamically prioritizes one objective or balances both based on the current solution's objective balance.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select base solution with a focus on diversity and potential improvement\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        candidates.append((sol, obj, total_weight))\n\n    # Sort by a combination of weight diversity, value balance, and potential improvement\n    candidates.sort(key=lambda x: (0.5 * (x[2] / capacity) + 0.3 * (x[1][0] / np.sum(value1_lst)) + 0.2 * (x[1][1] / np.sum(value2_lst))))\n\n    # Select top 25% of candidates or at least 1\n    selection_pool = candidates[:max(1, len(candidates) // 4)]\n    base_sol, base_obj, base_weight = random.choice(selection_pool)\n\n    new_solution = base_sol.copy()\n\n    # Hybrid local search with novel objective-balancing mechanism\n    # 1. Calculate objective balance score (how well balanced the current solution is)\n    obj_balance = base_obj[0] / (base_obj[1] + 1e-6)  # Avoid division by zero\n\n    # 2. Determine if we should focus on improving one objective or balancing both\n    if random.random() < 0.6:  # 60% chance to focus on one objective\n        prioritize_value1 = random.random() > 0.5\n    else:  # 40% chance to balance objectives\n        prioritize_value1 = obj_balance < 1.0  # If value1 is underrepresented, prioritize it\n\n    # 3. Find candidate flips with a novel evaluation metric\n    candidates_to_flip = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Consider removing this item\n            new_weight = base_weight - weight_lst[i]\n            if new_weight <= capacity:\n                # Evaluate flip based on both objectives with a balancing factor\n                if prioritize_value1:\n                    improvement = value1_lst[i] - 0.3 * value2_lst[i]  # Slightly penalize value2\n                else:\n                    improvement = value2_lst[i] - 0.3 * value1_lst[i]  # Slightly penalize value1\n                candidates_to_flip.append((i, improvement, new_weight))\n        else:\n            # Consider adding this item\n            new_weight = base_weight + weight_lst[i]\n            if new_weight <= capacity:\n                # Evaluate flip based on both objectives with a balancing factor\n                if prioritize_value1:\n                    improvement = value1_lst[i] - 0.3 * value2_lst[i]\n                else:\n                    improvement = value2_lst[i] - 0.3 * value1_lst[i]\n                candidates_to_flip.append((i, improvement, new_weight))\n\n    # 4. Select top 4 candidates with highest improvement\n    candidates_to_flip.sort(key=lambda x: x[1], reverse=True)\n    selected_flips = candidates_to_flip[:min(4, len(candidates_to_flip))]\n\n    # 5. Apply the flips\n    for i, _, _ in selected_flips:\n        new_solution[i] = 1 - new_solution[i]\n\n    # 6. Novel perturbation mechanism: occasionally flip based on objective balance\n    if random.random() < 0.4:  # 40% chance\n        if obj_balance > 1.5:  # Value1 is overrepresented\n            # Try to reduce value1 by removing high-value1 items\n            candidate_indices = [i for i in range(len(new_solution))\n                               if new_solution[i] == 1 and value1_lst[i] > np.mean(value1_lst)]\n        elif obj_balance < 0.7:  # Value2 is overrepresented\n            # Try to reduce value2 by removing high-value2 items\n            candidate_indices = [i for i in range(len(new_solution))\n                               if new_solution[i] == 1 and value2_lst[i] > np.mean(value2_lst)]\n        else:\n            # Neutral balance, choose randomly\n            candidate_indices = [i for i in range(len(new_solution))\n                              if (new_solution[i] == 1 and base_weight - weight_lst[i] <= capacity) or\n                                 (new_solution[i] == 0 and base_weight + weight_lst[i] <= capacity)]\n\n        if candidate_indices:\n            flip_idx = random.choice(candidate_indices)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # Ensure feasibility (safeguard)\n    total_weight = np.sum(weight_lst * new_solution)\n    while total_weight > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        remove_idx = random.choice(excess_items)\n        new_solution[remove_idx] = 0\n        total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8751480396795817,
            4.595240443944931
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with high average objective values, then applies a hybrid local search combining random bit-flips and greedy item swaps to generate a neighbor solution while ensuring feasibility. It first performs a random bit-flip with feasibility checks, then greedily adds high-value items for each objective, and finally introduces occasional diversification through additional random flips. The selection focuses on the top 30% of solutions, and the local search balances exploration and exploitation to improve both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Sort solutions by average objective value (ascending order)\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]) / 2)\n    selected_idx = min(int(len(archive) * 0.3), len(archive) - 1)  # Select from top 30% of solutions\n    base_solution = archive_sorted[selected_idx][0].copy()\n\n    # Generate a neighbor solution using hybrid local search\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 1: Random bit-flip with feasibility check\n    flip_idx = random.randint(0, len(new_solution) - 1)\n    if new_solution[flip_idx] == 1:\n        new_solution[flip_idx] = 0\n    else:\n        if current_weight + weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 1\n\n    # Step 2: Greedy item swap for both objectives\n    # For objective 1\n    for i in range(len(new_solution)):\n        if new_solution[i] == 0:\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                # Calculate potential improvement\n                if value1_lst[i] > 0:\n                    new_solution[i] = 1\n                    current_weight = temp_weight\n                    break\n\n    # For objective 2\n    for i in range(len(new_solution)):\n        if new_solution[i] == 0:\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                # Calculate potential improvement\n                if value2_lst[i] > 0:\n                    new_solution[i] = 1\n                    current_weight = temp_weight\n                    break\n\n    # Step 3: Random diversification (small probability)\n    if random.random() < 0.2:\n        flip_idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[flip_idx] == 1:\n            new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.8386472432390504,
            2.298644572496414
        ]
    },
    {
        "algorithm": "The algorithm selects promising solutions from the archive based on \u03b5-dominance ranks, prioritizes flips using weighted marginal gains combining both objectives, and applies adaptive perturbations to balance exploration and exploitation while strictly maintaining feasibility through targeted item flips and final feasibility checks. The weight factor dynamically adjusts based on current capacity usage, and perturbations are more frequent when near capacity limits.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Calculate \u03b5-dominance ranks for all solutions\n    def calculate_epsilon_dominance(solutions):\n        ranks = {}\n        for i, (sol_i, obj_i) in enumerate(solutions):\n            rank = 0\n            for j, (sol_j, obj_j) in enumerate(solutions):\n                if i != j and obj_j[0] >= obj_i[0] and obj_j[1] >= obj_i[1]:\n                    if obj_j[0] > obj_i[0] or obj_j[1] > obj_i[1]:\n                        rank += 1\n            ranks[i] = rank\n        return ranks\n\n    ranks = calculate_epsilon_dominance(archive)\n    sorted_indices = sorted(ranks.keys(), key=lambda x: ranks[x])\n    top_20_percent = max(1, len(archive) // 5)\n    selected_idx = random.choice(sorted_indices[:top_20_percent])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate weighted marginal gains\n    weight_factor = 0.6 if current_weight > 0.7 * capacity else 0.4\n    marginal_gain = (weight_factor * value1_lst + (1 - weight_factor) * value2_lst) / (weight_lst + 1e-6)\n    sorted_items = np.argsort(-marginal_gain)\n\n    # Perform targeted flips\n    for i in sorted_items:\n        if new_solution[i] == 1:\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = temp_weight\n                break\n        else:\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = temp_weight\n                break\n\n    # Adaptive perturbation\n    perturbation_prob = 0.3 if current_weight > 0.8 * capacity else 0.1\n    if random.random() < perturbation_prob:\n        candidate_indices = [i for i in range(len(weight_lst))\n                           if (new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                              (new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if candidate_indices:\n            num_flips = random.randint(1, min(3, len(candidate_indices)))\n            flip_indices = random.sample(candidate_indices, num_flips)\n            for i in flip_indices:\n                new_solution[i] = 1 - new_solution[i]\n                current_weight += (1 if new_solution[i] == 1 else -1) * weight_lst[i]\n\n    # Final feasibility check\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        remove_idx = random.choice(excess_items)\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.3368376317066809,
            1.4845050573349
        ]
    }
]