[
    {
        "algorithm": "The algorithm selects a diverse solution from the archive based on its distance from the mean objectives, then generates neighbors through two phases: first flipping items with highest weighted marginal gains, followed by probabilistic perturbations prioritizing underrepresented objectives while respecting capacity constraints. The selection weights favor solutions with imbalanced objective values, and the marginal gain calculation adapts to the current solution's objective weights, ensuring balanced exploration of both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Calculate diversity-based selection weights\n    v1_values = [obj[0] for _, obj in archive]\n    v2_values = [obj[1] for _, obj in archive]\n    v1_mean = np.mean(v1_values)\n    v2_mean = np.mean(v2_values)\n    selection_weights = []\n    for sol, obj in archive:\n        # Weight solutions based on their distance from the mean objectives\n        dist_v1 = abs(obj[0] - v1_mean)\n        dist_v2 = abs(obj[1] - v2_mean)\n        selection_weights.append(dist_v1 + dist_v2)\n\n    # Select solution with highest diversity weight\n    selected_idx = np.argmax(selection_weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate adaptive objective weights\n    total_v1 = np.sum(value1_lst * base_solution)\n    total_v2 = np.sum(value2_lst * base_solution)\n    obj_weight1 = 1 / (total_v1 + 1e-6)\n    obj_weight2 = 1 / (total_v2 + 1e-6)\n\n    # Phase 1: Weighted marginal gain flips\n    marginal_gain = (obj_weight1 * value1_lst + obj_weight2 * value2_lst) / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(-marginal_gain)\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = temp_weight\n        else:\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = temp_weight\n\n    # Phase 2: Capacity-aware probabilistic perturbations\n    remaining_capacity = capacity - current_weight\n    perturbation_strength = min(0.5, 1.5 * (remaining_capacity / capacity))\n    num_perturbations = max(1, int(5 * perturbation_strength))\n\n    for _ in range(num_perturbations):\n        if np.random.rand() < perturbation_strength:\n            # Select item based on weighted randomness\n            weights = (obj_weight1 * value1_lst + obj_weight2 * value2_lst) * (1 - new_solution)\n            weights = np.where(weights > 0, weights, 1e-6)\n            perturbation_candidate = np.random.choice(len(weight_lst), p=weights/np.sum(weights))\n\n            if new_solution[perturbation_candidate] == 1:\n                temp_weight = current_weight - weight_lst[perturbation_candidate]\n                if temp_weight <= capacity:\n                    new_solution[perturbation_candidate] = 0\n                    current_weight = temp_weight\n            else:\n                temp_weight = current_weight + weight_lst[perturbation_candidate]\n                if temp_weight <= capacity:\n                    new_solution[perturbation_candidate] = 1\n                    current_weight = temp_weight\n\n    return new_solution\n\n",
        "score": [
            -1.0062992848680385,
            2.266831934452057
        ]
    },
    {
        "algorithm": "This algorithm selects high-potential solutions from the archive using adaptive dominance thresholds, then generates neighbors by combining greedy item flips (weighted by both objectives) with random perturbations, dynamically adjusting flip intensity based on remaining capacity. It prioritizes value1 (70%) over value2 (30%) in marginal gains but balances both objectives in selection, while ensuring feasibility through iterative capacity checks and removals of least valuable items. The hybrid approach of greedy and random flips, along with dynamic perturbation intensity, enables exploration of promising regions while maintaining solution quality.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Adaptive dominance threshold selection\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    threshold1 = max_obj1 * 0.15\n    threshold2 = max_obj2 * 0.15\n\n    # Filter solutions with high dominance\n    filtered_solutions = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] >= obj[0] - threshold1 and\n                other_obj[1] >= obj[1] - threshold2 and\n                (other_obj[0] > obj[0] - threshold1 or\n                 other_obj[1] > obj[1] - threshold2)):\n                dominated = True\n                break\n        if not dominated:\n            filtered_solutions.append((sol, obj))\n\n    if not filtered_solutions:\n        filtered_solutions = archive.copy()\n\n    # Select solution with highest combined objective value\n    selected = max(filtered_solutions, key=lambda x: (x[1][0] * 0.6 + x[1][1] * 0.4))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid weighted marginal gains\n    capacity_ratio = (capacity - current_weight) / capacity\n    weight_factor = 0.3 + 0.7 * capacity_ratio\n    marginal_gain = (value1_lst * 0.7 + value2_lst * 0.3) * weight_factor / (weight_lst + 1e-6)\n\n    # Greedy and random flip combination\n    sorted_indices = np.argsort(-marginal_gain)\n    for i in sorted_indices[:min(5, len(sorted_indices))]:\n        if np.random.rand() < 0.7:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Dynamic perturbation intensity\n    perturbation_intensity = min(0.6, 0.3 + capacity_ratio * 0.4)\n    if np.random.rand() < perturbation_intensity:\n        for i in np.random.permutation(len(new_solution))[:3]:\n            if new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n            elif new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Final feasibility check\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        excess_items_sorted = sorted(excess_items, key=lambda x: marginal_gain[x])\n        remove_idx = excess_items_sorted[0]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.33919618652905564,
            1.2035576105117798
        ]
    },
    {
        "algorithm": "The algorithm dynamically selects a promising solution from the archive using \u03b5-dominance ranking, then applies a hybrid local search combining value-weighted item flips and capacity-aware swaps of low-contribution items, with adaptive probabilities based on remaining capacity and objective trade-offs, while ensuring feasibility through iterative capacity checks and removal of least valuable items. The \u03b5-thresholds are dynamically adjusted to balance exploration and exploitation, prioritizing items with higher combined value-to-weight ratios while strategically swapping low-contribution items when capacity allows.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Dynamic \u03b5-dominance ranking\n    def dominance_rank(sol, obj, \u03b5):\n        rank = 0\n        for _, other_obj in archive:\n            if (other_obj[0] >= obj[0] - \u03b5[0] and other_obj[1] >= obj[1] - \u03b5[1] and\n                (other_obj[0] > obj[0] - \u03b5[0] or other_obj[1] > obj[1] - \u03b5[1])):\n                rank += 1\n        return rank\n\n    # Calculate adaptive \u03b5 thresholds\n    obj1_values = [obj[0] for _, obj in archive]\n    obj2_values = [obj[1] for _, obj in archive]\n    \u03b51 = (max(obj1_values) - min(obj1_values)) * 0.1\n    \u03b52 = (max(obj2_values) - min(obj2_values)) * 0.1\n    \u03b5 = (\u03b51, \u03b52)\n\n    # Select solution with lowest dominance rank\n    selected = min(archive, key=lambda x: dominance_rank(x[0], x[1], \u03b5))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid value-weighted flips\n    value_ratio = np.sum(value1_lst) / (np.sum(value2_lst) + 1e-6)\n    flip_weights = (value1_lst * value_ratio + value2_lst) / (weight_lst + 1e-6)\n    flip_indices = np.argsort(-flip_weights)\n\n    for i in flip_indices[:min(5, len(flip_indices))]:\n        if new_solution[i] == 1:\n            if current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n        else:\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Capacity-aware swaps\n    remaining_capacity = capacity - current_weight\n    swap_prob = 0.3 * (remaining_capacity / capacity) ** 1.5\n\n    if np.random.rand() < swap_prob:\n        # Identify low-contribution items\n        contribution = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        low_contribution = [i for i in range(len(contribution)) if contribution[i] < np.median(contribution)]\n\n        if len(low_contribution) >= 2:\n            i, j = np.random.choice(low_contribution, size=2, replace=False)\n            if new_solution[i] == 1 and new_solution[j] == 0:\n                if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Feasibility check\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        excess_items_sorted = sorted(excess_items, key=lambda x: (value1_lst[x] + value2_lst[x]) / (weight_lst[x] + 1e-6))\n        remove_idx = excess_items_sorted[0]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9681051770267518,
            1.9767147600650787
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive with the minimum sum of objectives, then applies a hybrid local search that prioritizes items with high marginal contribution (combining both objectives) through targeted swaps and adaptive perturbations, while ensuring feasibility by checking weight constraints at each step. The method balances exploitation (via marginal contribution sorting) and exploration (via random perturbations), with higher priority given to items that improve both objectives proportionally.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with the minimum sum of objectives (diverse selection)\n    selected = min(archive, key=lambda x: sum(x[1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: prioritize items with high marginal contribution for both objectives\n    marginal_value1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_value2 = value2_lst / (weight_lst + 1e-6)\n    marginal_contribution = marginal_value1 + marginal_value2\n\n    # Sort items by marginal contribution (descending)\n    sorted_indices = np.argsort(-marginal_contribution)\n\n    # Step 1: Perform targeted swaps (explore neighborhood)\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            # Try removing item i\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n                break\n        else:\n            # Try adding item i\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n                break\n\n    # Step 2: Adaptive perturbation with higher probability (50% chance)\n    if np.random.rand() < 0.5:\n        # Select a random subset of items to perturb (up to 5 items)\n        perturbation_indices = np.random.choice(len(weight_lst), size=min(5, len(weight_lst)), replace=False)\n        for i in perturbation_indices:\n            if new_solution[i] == 1:\n                temp_solution = new_solution.copy()\n                temp_solution[i] = 0\n                temp_weight = current_weight - weight_lst[i]\n                if temp_weight <= capacity:\n                    new_solution = temp_solution\n                    current_weight = temp_weight\n            else:\n                temp_solution = new_solution.copy()\n                temp_solution[i] = 1\n                temp_weight = current_weight + weight_lst[i]\n                if temp_weight <= capacity:\n                    new_solution = temp_solution\n                    current_weight = temp_weight\n\n    return new_solution\n\n",
        "score": [
            -0.8062330467894219,
            1.2104815542697906
        ]
    },
    {
        "algorithm": "The algorithm dynamically selects promising solutions from an archive using \u03b5-dominance ranking, prioritizes item flips based on weighted marginal gains combining both objectives, and applies adaptive perturbations proportional to remaining capacity while ensuring feasibility at each step. It first filters non-dominated solutions, selects the best one, calculates weighted marginal gains to guide flips, and then performs feasibility-aware additions/removals with adaptive perturbation for further exploration. The weight factor balances objectives based on current capacity utilization, and final checks ensure feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Dynamic \u03b5-dominance ranking\n    epsilon = 0.1\n    filtered_solutions = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] >= obj[0] - epsilon and other_obj[1] >= obj[1] - epsilon and\n                (other_obj[0] > obj[0] - epsilon or other_obj[1] > obj[1] - epsilon)):\n                dominated = True\n                break\n        if not dominated:\n            filtered_solutions.append((sol, obj))\n\n    if not filtered_solutions:\n        filtered_solutions = archive.copy()\n\n    # Select solution with best \u03b5-dominance rank\n    selected_idx = np.argmax([sum(obj) for _, obj in filtered_solutions])\n    base_solution = filtered_solutions[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate weighted marginal gains\n    weight_factor = 0.5 if current_weight > 0.6 * capacity else 0.6\n    marginal_gain = (weight_factor * value1_lst + (1 - weight_factor) * value2_lst) / (weight_lst + 1e-6)\n\n    # Sort by marginal gain (descending)\n    sorted_indices = np.argsort(-marginal_gain)\n\n    # Perform feasibility-aware flips\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            # Try removing item\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = temp_weight\n                break\n        else:\n            # Try adding item\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = temp_weight\n                break\n\n    # Adaptive perturbation based on remaining capacity\n    remaining_capacity = capacity - current_weight\n    perturbation_prob = min(0.3, 0.1 + remaining_capacity / capacity * 0.2)\n\n    if np.random.rand() < perturbation_prob:\n        # Select items with low marginal gain for potential flip\n        low_gain_indices = np.argsort(marginal_gain)\n        for i in low_gain_indices[:min(3, len(low_gain_indices))]:\n            if new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n            elif new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Final feasibility check\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        excess_items_sorted = sorted(excess_items, key=lambda x: marginal_gain[x])\n        remove_idx = excess_items_sorted[0]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9674873137843483,
            1.3716097474098206
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Hybrid selection strategy combining \u03b5-dominance and objective diversity\n    epsilon = 0.15\n    candidate_solutions = []\n    for sol, obj in archive:\n        is_dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] >= obj[0] - epsilon * obj[0] and\n                other_obj[1] >= obj[1] - epsilon * obj[1] and\n                (other_obj[0] > obj[0] - epsilon * obj[0] or\n                 other_obj[1] > obj[1] - epsilon * obj[1])):\n                is_dominated = True\n                break\n        if not is_dominated:\n            candidate_solutions.append((sol, obj))\n\n    if not candidate_solutions:\n        candidate_solutions = archive.copy()\n\n    # Select solution with highest objective diversity (balance between objectives)\n    selected = max(candidate_solutions, key=lambda x: abs(x[1][0] - x[1][1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dynamic objective weighting based on current solution's balance\n    obj_balance = selected[1][0] / (selected[1][0] + selected[1][1] + 1e-6)\n    weighted_value = (obj_balance * value1_lst + (1 - obj_balance) * value2_lst)\n\n    # Phase 1: Greedy flips with dynamic objective weighting\n    marginal_gain = weighted_value / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(-marginal_gain)\n\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            if current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n                break\n        else:\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n                break\n\n    # Phase 2: Capacity-aware diversification\n    remaining_cap = capacity - current_weight\n    diversification_prob = min(0.4, 0.1 + 0.3 * (remaining_cap / capacity))\n\n    if np.random.rand() < diversification_prob:\n        # Select items with low weighted value but high weight\n        low_value_mask = weighted_value < np.percentile(weighted_value, 25)\n        candidate_indices = np.where(low_value_mask & (weight_lst > np.mean(weight_lst)))[0]\n\n        if len(candidate_indices) > 0:\n            for i in candidate_indices:\n                if new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Phase 3: Feasibility maintenance with objective-aware removal\n    while current_weight > capacity:\n        excess_items = np.where(new_solution)[0]\n        if len(excess_items) == 0:\n            break\n        # Remove items with lowest weighted value\n        excess_items_sorted = sorted(excess_items, key=lambda x: weighted_value[x])\n        remove_idx = excess_items_sorted[0]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9315055833279462,
            1.3082004487514496
        ]
    },
    {
        "algorithm": "The algorithm selects high-potential solutions from the archive using adaptive \u03b5-dominance ranking, prioritizes item flips based on weighted marginal gains combining both objectives with \u03b5-scaling, and applies capacity-aware perturbations to generate feasible neighbors while balancing exploration and exploitation through dynamic \u03b5 adjustment and probabilistic perturbations. It emphasizes high-marginal-gain items and ensures feasibility through iterative checks and removals, with solution selection guided by \u03b5-dominance and neighbor generation balancing greedy flips with adaptive perturbations. The algorithm dynamically adjusts \u03b5 based on capacity utilization and prioritizes flips that maximize combined objective gains while maintaining feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Dynamic \u03b5-dominance ranking with adaptive \u03b5\n    epsilon = 0.1\n    filtered_solutions = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] >= obj[0] - epsilon * obj[0] and\n                other_obj[1] >= obj[1] - epsilon * obj[1] and\n                (other_obj[0] > obj[0] - epsilon * obj[0] or\n                 other_obj[1] > obj[1] - epsilon * obj[1])):\n                dominated = True\n                break\n        if not dominated:\n            filtered_solutions.append((sol, obj))\n\n    if not filtered_solutions:\n        filtered_solutions = archive.copy()\n\n    # Select solution with highest \u03b5-dominance rank (more dominated)\n    selected = max(filtered_solutions, key=lambda x: (x[1][0] + x[1][1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive weighted marginal gains with dynamic \u03b5\n    capacity_ratio = (capacity - current_weight) / capacity\n    epsilon = max(0.05, 0.2 * capacity_ratio)  # Dynamic \u03b5 scaling\n    marginal_gain = (value1_lst + epsilon * value2_lst) * (1 + capacity_ratio) / (weight_lst + 1e-6)\n\n    # Sort by marginal gain (descending)\n    sorted_indices = np.argsort(-marginal_gain)\n\n    # Perform feasibility-aware flips\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            # Try removing item\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = temp_weight\n                break\n        else:\n            # Try adding item\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = temp_weight\n                break\n\n    # Adaptive perturbation based on marginal gain and remaining capacity\n    perturbation_prob = min(0.5, 0.2 + capacity_ratio * 0.3)\n    if np.random.rand() < perturbation_prob:\n        # Select items with low marginal gain for potential flip\n        low_gain_indices = np.argsort(marginal_gain)\n        for i in low_gain_indices[:min(3, len(low_gain_indices))]:\n            if new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n            elif new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Final feasibility check\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        excess_items_sorted = sorted(excess_items, key=lambda x: marginal_gain[x])\n        remove_idx = excess_items_sorted[0]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8663889708756349,
            1.2869084477424622
        ]
    },
    {
        "algorithm": "The algorithm selects a Pareto-efficient solution from the archive using a hypervolume-aware ranking, then generates neighbors by flipping items based on a weighted gain metric (prioritizing value2 over value1) while dynamically balancing capacity constraints, followed by probabilistic swaps and final feasibility checks. The key design ideas are the hybrid dominance filter, capacity-constrained flipping with dynamic weight balancing, and adaptive probabilistic swaps to escape local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Hybrid dominance filter with hypervolume-aware ranking\n    epsilon = 0.15\n    filtered_solutions = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and\n                (other_obj[0] > obj[0] or other_obj[1] > obj[1])):\n                dominated = True\n                break\n        if not dominated:\n            filtered_solutions.append((sol, obj))\n\n    if not filtered_solutions:\n        filtered_solutions = archive.copy()\n\n    # Select solution with highest hypervolume contribution\n    selected = max(filtered_solutions, key=lambda x: (x[1][0] * x[1][1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Multi-objective flipping with dynamic weight balancing\n    alpha = 0.4\n    beta = 0.6\n    capacity_ratio = (capacity - current_weight) / capacity\n    weighted_gain = (alpha * value1_lst + beta * value2_lst) * (1 + 0.5 * capacity_ratio) / (weight_lst + 1e-6)\n\n    # Sort by weighted gain (descending)\n    sorted_indices = np.argsort(-weighted_gain)\n\n    # Perform capacity-constrained flips\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            if current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n                break\n        else:\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n                break\n\n    # Probabilistic item swaps with adaptive temperature\n    temperature = 0.3 * (1 - capacity_ratio)\n    if np.random.rand() < temperature:\n        swap_candidates = np.where(new_solution == 1)[0]\n        if len(swap_candidates) > 1:\n            i, j = np.random.choice(swap_candidates, 2, replace=False)\n            if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Final feasibility check with dynamic weight adjustment\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = np.where(new_solution == 1)[0]\n        if len(excess_items) == 0:\n            break\n        remove_idx = np.random.choice(excess_items)\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9527302533395847,
            1.3536373376846313
        ]
    },
    {
        "algorithm": "The algorithm dynamically selects promising solutions from the archive using \u03b5-dominance ranking, prioritizes flips based on weighted marginal gains balancing both objectives, and applies adaptive feasibility-aware perturbations to generate high-quality neighbors while ensuring the solution remains feasible. It prioritizes items with higher weighted marginal gains (combining value1 and \u03b5-scaled value2) and adjusts perturbations based on remaining capacity, with final checks to enforce feasibility. The selection process emphasizes solutions with better \u03b5-dominance ranks, while the local search dynamically balances exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Dynamic \u03b5-dominance ranking\n    epsilon = 0.1\n    filtered_solutions = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] >= obj[0] - epsilon * obj[0] and\n                other_obj[1] >= obj[1] - epsilon * obj[1] and\n                (other_obj[0] > obj[0] - epsilon * obj[0] or\n                 other_obj[1] > obj[1] - epsilon * obj[1])):\n                dominated = True\n                break\n        if not dominated:\n            filtered_solutions.append((sol, obj))\n\n    if not filtered_solutions:\n        filtered_solutions = archive.copy()\n\n    # Select solution with highest \u03b5-dominance rank (more dominated)\n    selected = max(filtered_solutions, key=lambda x: (x[1][0] + x[1][1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate weighted marginal gains\n    capacity_ratio = (capacity - current_weight) / capacity\n    marginal_gain = (value1_lst + epsilon * value2_lst) * (1 + capacity_ratio) / (weight_lst + 1e-6)\n\n    # Sort by marginal gain (descending)\n    sorted_indices = np.argsort(-marginal_gain)\n\n    # Perform feasibility-aware flips\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            # Try removing item\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = temp_weight\n                break\n        else:\n            # Try adding item\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = temp_weight\n                break\n\n    # Adaptive perturbation based on remaining capacity\n    perturbation_prob = min(0.5, 0.2 + capacity_ratio * 0.3)\n    if np.random.rand() < perturbation_prob:\n        # Select items with low marginal gain for potential flip\n        low_gain_indices = np.argsort(marginal_gain)\n        for i in low_gain_indices[:min(3, len(low_gain_indices))]:\n            if new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n            elif new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Final feasibility check\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        excess_items_sorted = sorted(excess_items, key=lambda x: marginal_gain[x])\n        remove_idx = excess_items_sorted[0]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.810395973782146,
            1.230062574148178
        ]
    },
    {
        "algorithm": "The algorithm dynamically selects high-potential solutions from the archive using \u03b5-dominance ranking with adaptive \u03b5 scaling, prioritizes item flips based on weighted marginal gains combining both objectives, and applies capacity-aware perturbations to generate feasible neighbors while balancing exploration and exploitation through dynamic \u03b5 adjustment and probabilistic perturbations. It emphasizes high-marginal-gain items and ensures feasibility through iterative checks and removals, with solution selection guided by \u03b5-dominance and neighbor generation balancing greedy flips with adaptive perturbations. The algorithm dynamically adjusts perturbation intensity based on remaining capacity, ensuring high-quality solutions across multiple objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Dynamic \u03b5-dominance ranking with adaptive \u03b5\n    epsilon = 0.1\n    filtered_solutions = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] >= obj[0] - epsilon * obj[0] and\n                other_obj[1] >= obj[1] - epsilon * obj[1] and\n                (other_obj[0] > obj[0] - epsilon * obj[0] or\n                 other_obj[1] > obj[1] - epsilon * obj[1])):\n                dominated = True\n                break\n        if not dominated:\n            filtered_solutions.append((sol, obj))\n\n    if not filtered_solutions:\n        filtered_solutions = archive.copy()\n\n    # Select solution with highest \u03b5-dominance rank (more dominated)\n    selected = max(filtered_solutions, key=lambda x: (x[1][0] + x[1][1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive weighted marginal gains with dynamic \u03b5\n    capacity_ratio = (capacity - current_weight) / capacity\n    epsilon = max(0.05, 0.2 * capacity_ratio)  # Dynamic \u03b5 scaling\n    marginal_gain = (value1_lst + epsilon * value2_lst) * (1 + capacity_ratio) / (weight_lst + 1e-6)\n\n    # Sort by marginal gain (descending)\n    sorted_indices = np.argsort(-marginal_gain)\n\n    # Perform feasibility-aware flips\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            # Try removing item\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = temp_weight\n                break\n        else:\n            # Try adding item\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = temp_weight\n                break\n\n    # Adaptive perturbation based on marginal gain and remaining capacity\n    perturbation_prob = min(0.5, 0.2 + capacity_ratio * 0.3)\n    if np.random.rand() < perturbation_prob:\n        # Select items with low marginal gain for potential flip\n        low_gain_indices = np.argsort(marginal_gain)\n        for i in low_gain_indices[:min(3, len(low_gain_indices))]:\n            if new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n            elif new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Final feasibility check\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        excess_items_sorted = sorted(excess_items, key=lambda x: marginal_gain[x])\n        remove_idx = excess_items_sorted[0]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8302463086258107,
            1.2706534266471863
        ]
    }
]