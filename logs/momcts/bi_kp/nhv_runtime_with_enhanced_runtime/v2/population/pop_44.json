[
    {
        "algorithm": "The algorithm selects a solution from the archive with the minimum sum of objectives, then applies a hybrid local search that prioritizes items with high marginal contribution (combining both objectives) through targeted swaps and adaptive perturbations, while ensuring feasibility by checking weight constraints at each step. The method balances exploitation (via marginal contribution sorting) and exploration (via random perturbations), with higher priority given to items that improve both objectives proportionally.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with the minimum sum of objectives (diverse selection)\n    selected = min(archive, key=lambda x: sum(x[1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: prioritize items with high marginal contribution for both objectives\n    marginal_value1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_value2 = value2_lst / (weight_lst + 1e-6)\n    marginal_contribution = marginal_value1 + marginal_value2\n\n    # Sort items by marginal contribution (descending)\n    sorted_indices = np.argsort(-marginal_contribution)\n\n    # Step 1: Perform targeted swaps (explore neighborhood)\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            # Try removing item i\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n                break\n        else:\n            # Try adding item i\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n                break\n\n    # Step 2: Adaptive perturbation with higher probability (50% chance)\n    if np.random.rand() < 0.5:\n        # Select a random subset of items to perturb (up to 5 items)\n        perturbation_indices = np.random.choice(len(weight_lst), size=min(5, len(weight_lst)), replace=False)\n        for i in perturbation_indices:\n            if new_solution[i] == 1:\n                temp_solution = new_solution.copy()\n                temp_solution[i] = 0\n                temp_weight = current_weight - weight_lst[i]\n                if temp_weight <= capacity:\n                    new_solution = temp_solution\n                    current_weight = temp_weight\n            else:\n                temp_solution = new_solution.copy()\n                temp_solution[i] = 1\n                temp_weight = current_weight + weight_lst[i]\n                if temp_weight <= capacity:\n                    new_solution = temp_solution\n                    current_weight = temp_weight\n\n    return new_solution\n\n",
        "score": [
            -0.8062330467894219,
            1.2104815542697906
        ]
    },
    {
        "algorithm": "The algorithm dynamically selects promising solutions from an archive using \u03b5-dominance ranking, prioritizes item flips based on weighted marginal gains combining both objectives, and applies adaptive perturbations proportional to remaining capacity while ensuring feasibility at each step. It first filters non-dominated solutions, selects the best one, calculates weighted marginal gains to guide flips, and then performs feasibility-aware additions/removals with adaptive perturbation for further exploration. The weight factor balances objectives based on current capacity utilization, and final checks ensure feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Dynamic \u03b5-dominance ranking\n    epsilon = 0.1\n    filtered_solutions = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] >= obj[0] - epsilon and other_obj[1] >= obj[1] - epsilon and\n                (other_obj[0] > obj[0] - epsilon or other_obj[1] > obj[1] - epsilon)):\n                dominated = True\n                break\n        if not dominated:\n            filtered_solutions.append((sol, obj))\n\n    if not filtered_solutions:\n        filtered_solutions = archive.copy()\n\n    # Select solution with best \u03b5-dominance rank\n    selected_idx = np.argmax([sum(obj) for _, obj in filtered_solutions])\n    base_solution = filtered_solutions[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate weighted marginal gains\n    weight_factor = 0.5 if current_weight > 0.6 * capacity else 0.6\n    marginal_gain = (weight_factor * value1_lst + (1 - weight_factor) * value2_lst) / (weight_lst + 1e-6)\n\n    # Sort by marginal gain (descending)\n    sorted_indices = np.argsort(-marginal_gain)\n\n    # Perform feasibility-aware flips\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            # Try removing item\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = temp_weight\n                break\n        else:\n            # Try adding item\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = temp_weight\n                break\n\n    # Adaptive perturbation based on remaining capacity\n    remaining_capacity = capacity - current_weight\n    perturbation_prob = min(0.3, 0.1 + remaining_capacity / capacity * 0.2)\n\n    if np.random.rand() < perturbation_prob:\n        # Select items with low marginal gain for potential flip\n        low_gain_indices = np.argsort(marginal_gain)\n        for i in low_gain_indices[:min(3, len(low_gain_indices))]:\n            if new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n            elif new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Final feasibility check\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        excess_items_sorted = sorted(excess_items, key=lambda x: marginal_gain[x])\n        remove_idx = excess_items_sorted[0]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9674873137843483,
            1.3716097474098206
        ]
    },
    {
        "algorithm": "The algorithm combines \u03b5-dominance ranking with a hybrid local search strategy, prioritizing solutions with higher dominance ranks (more dominated) and applying dominance-aware swaps based on weighted marginal gains (balancing both objectives and capacity ratio) followed by adaptive perturbations (probabilistically swapping low-contribution items) while ensuring feasibility. The \u03b5 value dynamically adjusts to focus on higher gains, and the perturbation probability scales with remaining capacity. The marginal gain calculation weights value1 and value2 with \u03b5, and the overall structure ensures both exploitation (via dominance-aware swaps) and exploration (via adaptive perturbations), dynamically balancing the trade-off between objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # \u03b5-dominance ranking\n    def \u03b5_dominance_rank(sol_obj):\n        rank = 0\n        \u03b5 = 0.1  # Initial \u03b5 value\n        for other_obj in [obj for (sol, obj) in archive]:\n            if other_obj[0] >= sol_obj[0] - \u03b5 * sol_obj[0] and other_obj[1] >= sol_obj[1] - \u03b5 * sol_obj[1]:\n                rank += 1\n        return rank\n\n    # Select solution with highest \u03b5-dominance rank (more dominated)\n    selected = max(archive, key=lambda x: \u03b5_dominance_rank(x[1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dynamic weighted marginal gain calculation\n    \u03b5 = 0.2  # Adjustable \u03b5 value\n    capacity_ratio = (capacity - current_weight) / capacity\n    marginal_gain = (value1_lst + \u03b5 * value2_lst) * (1 + capacity_ratio) / (weight_lst + 1e-6)\n\n    # Step 1: Dominance-aware swaps based on weighted marginal gains\n    sorted_indices = np.argsort(-marginal_gain)\n    for i in sorted_indices:\n        for j in sorted_indices:\n            if i != j and new_solution[i] != new_solution[j]:\n                if new_solution[i] == 1 and new_solution[j] == 0:\n                    temp_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    if temp_weight <= capacity:\n                        temp_solution = new_solution.copy()\n                        temp_solution[i], temp_solution[j] = 0, 1\n                        new_solution = temp_solution\n                        current_weight = temp_weight\n                        \u03b5 *= 0.9  # Reduce \u03b5 to focus on higher gains\n                        break\n        else:\n            continue\n        break\n\n    # Step 2: Adaptive perturbation based on marginal gain and remaining capacity\n    perturbation_prob = min(0.7, 0.3 + capacity_ratio * 0.4)\n    if np.random.rand() < perturbation_prob:\n        # Select items with lowest marginal gain to perturb\n        perturbation_indices = np.argsort(marginal_gain)[:min(5, len(weight_lst))]\n        for i in perturbation_indices:\n            for j in perturbation_indices:\n                if i != j and new_solution[i] != new_solution[j]:\n                    if new_solution[i] == 1 and new_solution[j] == 0:\n                        temp_weight = current_weight - weight_lst[i] + weight_lst[j]\n                        if temp_weight <= capacity:\n                            temp_solution = new_solution.copy()\n                            temp_solution[i], temp_solution[j] = 0, 1\n                            new_solution = temp_solution\n                            current_weight = temp_weight\n                            break\n            else:\n                continue\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.9686614622491247,
            4.974836885929108
        ]
    },
    {
        "algorithm": "The algorithm dynamically selects promising solutions from the archive using \u03b5-dominance ranking, prioritizes flips based on weighted marginal gains balancing both objectives, and applies adaptive feasibility-aware perturbations to generate high-quality neighbors while ensuring the solution remains feasible. It prioritizes items with higher weighted marginal gains (combining value1 and \u03b5-scaled value2) and adjusts perturbations based on remaining capacity, with final checks to enforce feasibility. The selection process emphasizes solutions with better \u03b5-dominance ranks, while the local search dynamically balances exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Dynamic \u03b5-dominance ranking\n    epsilon = 0.1\n    filtered_solutions = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] >= obj[0] - epsilon * obj[0] and\n                other_obj[1] >= obj[1] - epsilon * obj[1] and\n                (other_obj[0] > obj[0] - epsilon * obj[0] or\n                 other_obj[1] > obj[1] - epsilon * obj[1])):\n                dominated = True\n                break\n        if not dominated:\n            filtered_solutions.append((sol, obj))\n\n    if not filtered_solutions:\n        filtered_solutions = archive.copy()\n\n    # Select solution with highest \u03b5-dominance rank (more dominated)\n    selected = max(filtered_solutions, key=lambda x: (x[1][0] + x[1][1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate weighted marginal gains\n    capacity_ratio = (capacity - current_weight) / capacity\n    marginal_gain = (value1_lst + epsilon * value2_lst) * (1 + capacity_ratio) / (weight_lst + 1e-6)\n\n    # Sort by marginal gain (descending)\n    sorted_indices = np.argsort(-marginal_gain)\n\n    # Perform feasibility-aware flips\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            # Try removing item\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = temp_weight\n                break\n        else:\n            # Try adding item\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = temp_weight\n                break\n\n    # Adaptive perturbation based on remaining capacity\n    perturbation_prob = min(0.5, 0.2 + capacity_ratio * 0.3)\n    if np.random.rand() < perturbation_prob:\n        # Select items with low marginal gain for potential flip\n        low_gain_indices = np.argsort(marginal_gain)\n        for i in low_gain_indices[:min(3, len(low_gain_indices))]:\n            if new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n            elif new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Final feasibility check\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        excess_items_sorted = sorted(excess_items, key=lambda x: marginal_gain[x])\n        remove_idx = excess_items_sorted[0]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.810395973782146,
            1.230062574148178
        ]
    },
    {
        "algorithm": "The algorithm selects promising solutions from the archive using \u03b5-dominance ranking with adaptive \u03b5 scaling, prioritizes item flips based on weighted marginal gains combining both objectives, and applies capacity-aware perturbations to generate feasible neighbors while dynamically adjusting \u03b5 to balance exploration and exploitation. It emphasizes high-marginal-gain items and uses probabilistic perturbations to escape local optima, ensuring feasibility through iterative checks and removals. The solution selection is guided by \u03b5-dominance, while the neighbor generation balances greedy flips with adaptive perturbations to maintain diversity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Dynamic \u03b5-dominance ranking with adaptive \u03b5\n    epsilon = 0.1\n    filtered_solutions = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] >= obj[0] - epsilon * obj[0] and\n                other_obj[1] >= obj[1] - epsilon * obj[1] and\n                (other_obj[0] > obj[0] - epsilon * obj[0] or\n                 other_obj[1] > obj[1] - epsilon * obj[1])):\n                dominated = True\n                break\n        if not dominated:\n            filtered_solutions.append((sol, obj))\n\n    if not filtered_solutions:\n        filtered_solutions = archive.copy()\n\n    # Select solution with highest \u03b5-dominance rank (more dominated)\n    selected = max(filtered_solutions, key=lambda x: (x[1][0] + x[1][1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive weighted marginal gains with dynamic \u03b5\n    capacity_ratio = (capacity - current_weight) / capacity\n    epsilon = max(0.05, 0.2 * capacity_ratio)  # Dynamic \u03b5 scaling\n    marginal_gain = (value1_lst + epsilon * value2_lst) * (1 + capacity_ratio) / (weight_lst + 1e-6)\n\n    # Sort by marginal gain (descending)\n    sorted_indices = np.argsort(-marginal_gain)\n\n    # Perform feasibility-aware flips\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            # Try removing item\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = temp_weight\n                break\n        else:\n            # Try adding item\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = temp_weight\n                break\n\n    # Adaptive perturbation based on marginal gain and remaining capacity\n    perturbation_prob = min(0.5, 0.2 + capacity_ratio * 0.3)\n    if np.random.rand() < perturbation_prob:\n        # Select items with low marginal gain for potential flip\n        low_gain_indices = np.argsort(marginal_gain)\n        for i in low_gain_indices[:min(3, len(low_gain_indices))]:\n            if new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n            elif new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Final feasibility check\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        excess_items_sorted = sorted(excess_items, key=lambda x: marginal_gain[x])\n        remove_idx = excess_items_sorted[0]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8363632804928134,
            1.2785993218421936
        ]
    },
    {
        "algorithm": "The algorithm dynamically selects high-potential solutions from the archive using \u03b5-dominance ranking with adaptive \u03b5 scaling, prioritizes item flips based on weighted marginal gains combining both objectives, and applies capacity-aware perturbations to generate feasible neighbors while balancing exploration and exploitation through dynamic \u03b5 adjustment and probabilistic perturbations. It emphasizes high-marginal-gain items and ensures feasibility through iterative checks and removals, with solution selection guided by \u03b5-dominance and neighbor generation balancing greedy flips with adaptive perturbations. The algorithm dynamically adjusts perturbation intensity based on remaining capacity, ensuring high-quality solutions across multiple objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Dynamic \u03b5-dominance ranking with adaptive \u03b5\n    epsilon = 0.1\n    filtered_solutions = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] >= obj[0] - epsilon * obj[0] and\n                other_obj[1] >= obj[1] - epsilon * obj[1] and\n                (other_obj[0] > obj[0] - epsilon * obj[0] or\n                 other_obj[1] > obj[1] - epsilon * obj[1])):\n                dominated = True\n                break\n        if not dominated:\n            filtered_solutions.append((sol, obj))\n\n    if not filtered_solutions:\n        filtered_solutions = archive.copy()\n\n    # Select solution with highest \u03b5-dominance rank (more dominated)\n    selected = max(filtered_solutions, key=lambda x: (x[1][0] + x[1][1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive weighted marginal gains with dynamic \u03b5\n    capacity_ratio = (capacity - current_weight) / capacity\n    epsilon = max(0.05, 0.2 * capacity_ratio)  # Dynamic \u03b5 scaling\n    marginal_gain = (value1_lst + epsilon * value2_lst) * (1 + capacity_ratio) / (weight_lst + 1e-6)\n\n    # Sort by marginal gain (descending)\n    sorted_indices = np.argsort(-marginal_gain)\n\n    # Perform feasibility-aware flips\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            # Try removing item\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = temp_weight\n                break\n        else:\n            # Try adding item\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = temp_weight\n                break\n\n    # Adaptive perturbation based on marginal gain and remaining capacity\n    perturbation_prob = min(0.5, 0.2 + capacity_ratio * 0.3)\n    if np.random.rand() < perturbation_prob:\n        # Select items with low marginal gain for potential flip\n        low_gain_indices = np.argsort(marginal_gain)\n        for i in low_gain_indices[:min(3, len(low_gain_indices))]:\n            if new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n            elif new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Final feasibility check\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        excess_items_sorted = sorted(excess_items, key=lambda x: marginal_gain[x])\n        remove_idx = excess_items_sorted[0]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8302463086258107,
            1.2706534266471863
        ]
    },
    {
        "algorithm": "This algorithm selects high-potential solutions from the archive using adaptive dominance thresholds, then generates neighbors by combining greedy item flips (weighted by both objectives) with random perturbations, dynamically adjusting flip intensity based on remaining capacity. It prioritizes value1 (70%) over value2 (30%) in marginal gains but balances both objectives in selection, while ensuring feasibility through iterative capacity checks and removals of least valuable items. The hybrid approach of greedy and random flips, along with dynamic perturbation intensity, enables exploration of promising regions while maintaining solution quality.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Adaptive dominance threshold selection\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    threshold1 = max_obj1 * 0.15\n    threshold2 = max_obj2 * 0.15\n\n    # Filter solutions with high dominance\n    filtered_solutions = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] >= obj[0] - threshold1 and\n                other_obj[1] >= obj[1] - threshold2 and\n                (other_obj[0] > obj[0] - threshold1 or\n                 other_obj[1] > obj[1] - threshold2)):\n                dominated = True\n                break\n        if not dominated:\n            filtered_solutions.append((sol, obj))\n\n    if not filtered_solutions:\n        filtered_solutions = archive.copy()\n\n    # Select solution with highest combined objective value\n    selected = max(filtered_solutions, key=lambda x: (x[1][0] * 0.6 + x[1][1] * 0.4))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid weighted marginal gains\n    capacity_ratio = (capacity - current_weight) / capacity\n    weight_factor = 0.3 + 0.7 * capacity_ratio\n    marginal_gain = (value1_lst * 0.7 + value2_lst * 0.3) * weight_factor / (weight_lst + 1e-6)\n\n    # Greedy and random flip combination\n    sorted_indices = np.argsort(-marginal_gain)\n    for i in sorted_indices[:min(5, len(sorted_indices))]:\n        if np.random.rand() < 0.7:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Dynamic perturbation intensity\n    perturbation_intensity = min(0.6, 0.3 + capacity_ratio * 0.4)\n    if np.random.rand() < perturbation_intensity:\n        for i in np.random.permutation(len(new_solution))[:3]:\n            if new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n            elif new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Final feasibility check\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        excess_items_sorted = sorted(excess_items, key=lambda x: marginal_gain[x])\n        remove_idx = excess_items_sorted[0]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.33919618652905564,
            1.2035576105117798
        ]
    },
    {
        "algorithm": "The algorithm combines a multi-phase approach: it first selects the best solution by combined objective value, then uses weighted marginal gains to perform high-impact flips while ensuring feasibility, followed by adaptive perturbations to remove low-value items, and finally enforces strict feasibility checks by removing the least valuable items. The weighted marginal gain prioritizes items with higher combined value-to-weight ratios, while the perturbation phase adaptively removes items based on remaining capacity, ensuring diversity in the search.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select base solution with highest combined objective value\n    selected_idx = np.argmax([obj[0] + obj[1] for _, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate weighted marginal gains\n    weight_factor = 0.7\n    weighted_gain = (value1_lst + value2_lst) / (weight_lst ** weight_factor + 1e-6)\n    sorted_indices = np.argsort(-weighted_gain)\n\n    # Phase 1: High-impact flips with feasibility check\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            if current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n                break\n        else:\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n                break\n\n    # Phase 2: Capacity-aware perturbations\n    remaining_capacity = capacity - current_weight\n    perturbation_factor = min(0.5, 0.1 + 0.3 * (remaining_capacity / capacity))\n\n    if np.random.rand() < perturbation_factor:\n        # Select items with low weighted gain and high weight contribution\n        low_gain_mask = weighted_gain < np.percentile(weighted_gain, 30)\n        candidate_indices = np.where(new_solution)[0]\n\n        if len(candidate_indices) > 0:\n            candidate_indices = sorted(candidate_indices, key=lambda x: weight_lst[x] / (value1_lst[x] + value2_lst[x] + 1e-6))\n            for i in candidate_indices[:min(2, len(candidate_indices))]:\n                if current_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Phase 3: Strict feasibility validation\n    while current_weight > capacity:\n        excess_items = np.where(new_solution)[0]\n        if len(excess_items) == 0:\n            break\n        # Remove items with lowest weighted gain\n        excess_items_sorted = sorted(excess_items, key=lambda x: weighted_gain[x])\n        remove_idx = excess_items_sorted[0]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9270132370417286,
            1.3193289637565613
        ]
    },
    {
        "algorithm": "The algorithm dynamically selects a promising solution from the archive using \u03b5-dominance ranking, then applies a hybrid local search combining value-weighted item flips and capacity-aware swaps of low-contribution items, with adaptive probabilities based on remaining capacity and objective trade-offs, while ensuring feasibility through iterative capacity checks and removal of least valuable items. The \u03b5-thresholds are dynamically adjusted to balance exploration and exploitation, prioritizing items with higher combined value-to-weight ratios while strategically swapping low-contribution items when capacity allows.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Dynamic \u03b5-dominance ranking\n    def dominance_rank(sol, obj, \u03b5):\n        rank = 0\n        for _, other_obj in archive:\n            if (other_obj[0] >= obj[0] - \u03b5[0] and other_obj[1] >= obj[1] - \u03b5[1] and\n                (other_obj[0] > obj[0] - \u03b5[0] or other_obj[1] > obj[1] - \u03b5[1])):\n                rank += 1\n        return rank\n\n    # Calculate adaptive \u03b5 thresholds\n    obj1_values = [obj[0] for _, obj in archive]\n    obj2_values = [obj[1] for _, obj in archive]\n    \u03b51 = (max(obj1_values) - min(obj1_values)) * 0.1\n    \u03b52 = (max(obj2_values) - min(obj2_values)) * 0.1\n    \u03b5 = (\u03b51, \u03b52)\n\n    # Select solution with lowest dominance rank\n    selected = min(archive, key=lambda x: dominance_rank(x[0], x[1], \u03b5))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid value-weighted flips\n    value_ratio = np.sum(value1_lst) / (np.sum(value2_lst) + 1e-6)\n    flip_weights = (value1_lst * value_ratio + value2_lst) / (weight_lst + 1e-6)\n    flip_indices = np.argsort(-flip_weights)\n\n    for i in flip_indices[:min(5, len(flip_indices))]:\n        if new_solution[i] == 1:\n            if current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n        else:\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Capacity-aware swaps\n    remaining_capacity = capacity - current_weight\n    swap_prob = 0.3 * (remaining_capacity / capacity) ** 1.5\n\n    if np.random.rand() < swap_prob:\n        # Identify low-contribution items\n        contribution = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        low_contribution = [i for i in range(len(contribution)) if contribution[i] < np.median(contribution)]\n\n        if len(low_contribution) >= 2:\n            i, j = np.random.choice(low_contribution, size=2, replace=False)\n            if new_solution[i] == 1 and new_solution[j] == 0:\n                if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Feasibility check\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        excess_items_sorted = sorted(excess_items, key=lambda x: (value1_lst[x] + value2_lst[x]) / (weight_lst[x] + 1e-6))\n        remove_idx = excess_items_sorted[0]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9681051770267518,
            1.9767147600650787
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive using a hybrid metric combining crowding distance and dominance area, then applies a multi-step local search with probabilistic flips, capacity-aware swaps, and dynamic adjustments to improve solution quality while ensuring feasibility through iterative repair. It prioritizes high-value-to-weight items and removes low-contribution items probabilistically, with adaptive thresholds based on remaining capacity. The method balances exploration of the solution space with exploitation of promising regions through probabilistic operations and capacity-sensitive decision-making.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Hybrid selection criterion\n    def crowding_distance(obj, \u03b5):\n        distances = []\n        for _, other_obj in archive:\n            if (other_obj[0] >= obj[0] - \u03b5[0] and other_obj[1] >= obj[1] - \u03b5[1]):\n                distances.append((obj[0] - other_obj[0])**2 + (obj[1] - other_obj[1])**2)\n        return np.mean(distances) if distances else 0\n\n    def dominance_area(obj, \u03b5):\n        count = 0\n        for _, other_obj in archive:\n            if (other_obj[0] >= obj[0] - \u03b5[0] and other_obj[1] >= obj[1] - \u03b5[1] and\n                (other_obj[0] > obj[0] - \u03b5[0] or other_obj[1] > obj[1] - \u03b5[1])):\n                count += 1\n        return count\n\n    # Calculate adaptive thresholds\n    obj1_values = [obj[0] for _, obj in archive]\n    obj2_values = [obj[1] for _, obj in archive]\n    \u03b51 = (max(obj1_values) - min(obj1_values)) * 0.2\n    \u03b52 = (max(obj2_values) - min(obj2_values)) * 0.2\n    \u03b5 = (\u03b51, \u03b52)\n\n    # Select solution with highest crowding distance and lowest dominance area\n    selected = max(archive, key=lambda x: crowding_distance(x[1], \u03b5) - dominance_area(x[1], \u03b5))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Probabilistic value-to-weight flips\n    value_to_weight = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n    flip_probs = value_to_weight / (np.sum(value_to_weight) + 1e-6)\n    flip_indices = np.random.choice(len(weight_lst), size=min(3, len(weight_lst)), p=flip_probs, replace=False)\n\n    for i in flip_indices:\n        if new_solution[i] == 1:\n            if current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n        else:\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Capacity-aware item swaps\n    remaining_capacity = capacity - current_weight\n    swap_threshold = 0.4 * (remaining_capacity / capacity) ** 1.2\n\n    if np.random.rand() < swap_threshold:\n        # Identify items with low marginal contribution\n        marginal_contribution = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        low_contrib = [i for i in range(len(marginal_contribution)) if marginal_contribution[i] < np.percentile(marginal_contribution, 30)]\n\n        if len(low_contrib) >= 2:\n            i, j = np.random.choice(low_contrib, size=2, replace=False)\n            if new_solution[i] == 1 and new_solution[j] == 0:\n                if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Dynamic weight adjustment\n    adjustment_factor = min(0.5, 0.2 + remaining_capacity / capacity * 0.3)\n    if np.random.rand() < adjustment_factor:\n        # Remove low-value items with probability proportional to their contribution\n        contribution = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        for i in np.random.permutation(len(new_solution)):\n            if new_solution[i] == 1 and np.random.rand() < (1 - contribution[i]) * 0.4:\n                if current_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Feasibility repair\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        excess_items_sorted = sorted(excess_items, key=lambda x: (value1_lst[x] + value2_lst[x]) / (weight_lst[x] + 1e-6))\n        remove_idx = excess_items_sorted[0]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.898983159039418,
            6.421661883592606
        ]
    }
]