[
    {
        "algorithm": "The algorithm selects a solution from the archive with the minimum sum of objectives, then applies a hybrid local search that prioritizes items with high marginal contribution (combining both objectives) through targeted swaps and adaptive perturbations, while ensuring feasibility by checking weight constraints at each step. The method balances exploitation (via marginal contribution sorting) and exploration (via random perturbations), with higher priority given to items that improve both objectives proportionally.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with the minimum sum of objectives (diverse selection)\n    selected = min(archive, key=lambda x: sum(x[1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: prioritize items with high marginal contribution for both objectives\n    marginal_value1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_value2 = value2_lst / (weight_lst + 1e-6)\n    marginal_contribution = marginal_value1 + marginal_value2\n\n    # Sort items by marginal contribution (descending)\n    sorted_indices = np.argsort(-marginal_contribution)\n\n    # Step 1: Perform targeted swaps (explore neighborhood)\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            # Try removing item i\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n                break\n        else:\n            # Try adding item i\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n                break\n\n    # Step 2: Adaptive perturbation with higher probability (50% chance)\n    if np.random.rand() < 0.5:\n        # Select a random subset of items to perturb (up to 5 items)\n        perturbation_indices = np.random.choice(len(weight_lst), size=min(5, len(weight_lst)), replace=False)\n        for i in perturbation_indices:\n            if new_solution[i] == 1:\n                temp_solution = new_solution.copy()\n                temp_solution[i] = 0\n                temp_weight = current_weight - weight_lst[i]\n                if temp_weight <= capacity:\n                    new_solution = temp_solution\n                    current_weight = temp_weight\n            else:\n                temp_solution = new_solution.copy()\n                temp_solution[i] = 1\n                temp_weight = current_weight + weight_lst[i]\n                if temp_weight <= capacity:\n                    new_solution = temp_solution\n                    current_weight = temp_weight\n\n    return new_solution\n\n",
        "score": [
            -0.8062330467894219,
            1.2104815542697906
        ]
    },
    {
        "algorithm": "The algorithm dynamically selects promising solutions from an archive using \u03b5-dominance ranking, prioritizes item flips based on weighted marginal gains combining both objectives, and applies adaptive perturbations proportional to remaining capacity while ensuring feasibility at each step. It first filters non-dominated solutions, selects the best one, calculates weighted marginal gains to guide flips, and then performs feasibility-aware additions/removals with adaptive perturbation for further exploration. The weight factor balances objectives based on current capacity utilization, and final checks ensure feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Dynamic \u03b5-dominance ranking\n    epsilon = 0.1\n    filtered_solutions = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] >= obj[0] - epsilon and other_obj[1] >= obj[1] - epsilon and\n                (other_obj[0] > obj[0] - epsilon or other_obj[1] > obj[1] - epsilon)):\n                dominated = True\n                break\n        if not dominated:\n            filtered_solutions.append((sol, obj))\n\n    if not filtered_solutions:\n        filtered_solutions = archive.copy()\n\n    # Select solution with best \u03b5-dominance rank\n    selected_idx = np.argmax([sum(obj) for _, obj in filtered_solutions])\n    base_solution = filtered_solutions[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate weighted marginal gains\n    weight_factor = 0.5 if current_weight > 0.6 * capacity else 0.6\n    marginal_gain = (weight_factor * value1_lst + (1 - weight_factor) * value2_lst) / (weight_lst + 1e-6)\n\n    # Sort by marginal gain (descending)\n    sorted_indices = np.argsort(-marginal_gain)\n\n    # Perform feasibility-aware flips\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            # Try removing item\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = temp_weight\n                break\n        else:\n            # Try adding item\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = temp_weight\n                break\n\n    # Adaptive perturbation based on remaining capacity\n    remaining_capacity = capacity - current_weight\n    perturbation_prob = min(0.3, 0.1 + remaining_capacity / capacity * 0.2)\n\n    if np.random.rand() < perturbation_prob:\n        # Select items with low marginal gain for potential flip\n        low_gain_indices = np.argsort(marginal_gain)\n        for i in low_gain_indices[:min(3, len(low_gain_indices))]:\n            if new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n            elif new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Final feasibility check\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        excess_items_sorted = sorted(excess_items, key=lambda x: marginal_gain[x])\n        remove_idx = excess_items_sorted[0]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9674873137843483,
            1.3716097474098206
        ]
    },
    {
        "algorithm": "The algorithm combines \u03b5-dominance ranking with a hybrid local search strategy, prioritizing solutions with higher dominance ranks (more dominated) and applying dominance-aware swaps based on weighted marginal gains (balancing both objectives and capacity ratio) followed by adaptive perturbations (probabilistically swapping low-contribution items) while ensuring feasibility. The \u03b5 value dynamically adjusts to focus on higher gains, and the perturbation probability scales with remaining capacity. The marginal gain calculation weights value1 and value2 with \u03b5, and the overall structure ensures both exploitation (via dominance-aware swaps) and exploration (via adaptive perturbations), dynamically balancing the trade-off between objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # \u03b5-dominance ranking\n    def \u03b5_dominance_rank(sol_obj):\n        rank = 0\n        \u03b5 = 0.1  # Initial \u03b5 value\n        for other_obj in [obj for (sol, obj) in archive]:\n            if other_obj[0] >= sol_obj[0] - \u03b5 * sol_obj[0] and other_obj[1] >= sol_obj[1] - \u03b5 * sol_obj[1]:\n                rank += 1\n        return rank\n\n    # Select solution with highest \u03b5-dominance rank (more dominated)\n    selected = max(archive, key=lambda x: \u03b5_dominance_rank(x[1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dynamic weighted marginal gain calculation\n    \u03b5 = 0.2  # Adjustable \u03b5 value\n    capacity_ratio = (capacity - current_weight) / capacity\n    marginal_gain = (value1_lst + \u03b5 * value2_lst) * (1 + capacity_ratio) / (weight_lst + 1e-6)\n\n    # Step 1: Dominance-aware swaps based on weighted marginal gains\n    sorted_indices = np.argsort(-marginal_gain)\n    for i in sorted_indices:\n        for j in sorted_indices:\n            if i != j and new_solution[i] != new_solution[j]:\n                if new_solution[i] == 1 and new_solution[j] == 0:\n                    temp_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    if temp_weight <= capacity:\n                        temp_solution = new_solution.copy()\n                        temp_solution[i], temp_solution[j] = 0, 1\n                        new_solution = temp_solution\n                        current_weight = temp_weight\n                        \u03b5 *= 0.9  # Reduce \u03b5 to focus on higher gains\n                        break\n        else:\n            continue\n        break\n\n    # Step 2: Adaptive perturbation based on marginal gain and remaining capacity\n    perturbation_prob = min(0.7, 0.3 + capacity_ratio * 0.4)\n    if np.random.rand() < perturbation_prob:\n        # Select items with lowest marginal gain to perturb\n        perturbation_indices = np.argsort(marginal_gain)[:min(5, len(weight_lst))]\n        for i in perturbation_indices:\n            for j in perturbation_indices:\n                if i != j and new_solution[i] != new_solution[j]:\n                    if new_solution[i] == 1 and new_solution[j] == 0:\n                        temp_weight = current_weight - weight_lst[i] + weight_lst[j]\n                        if temp_weight <= capacity:\n                            temp_solution = new_solution.copy()\n                            temp_solution[i], temp_solution[j] = 0, 1\n                            new_solution = temp_solution\n                            current_weight = temp_weight\n                            break\n            else:\n                continue\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.9686614622491247,
            4.974836885929108
        ]
    },
    {
        "algorithm": "The algorithm dynamically selects promising solutions from the archive using \u03b5-dominance ranking, prioritizes flips based on weighted marginal gains balancing both objectives, and applies adaptive feasibility-aware perturbations to generate high-quality neighbors while ensuring the solution remains feasible. It prioritizes items with higher weighted marginal gains (combining value1 and \u03b5-scaled value2) and adjusts perturbations based on remaining capacity, with final checks to enforce feasibility. The selection process emphasizes solutions with better \u03b5-dominance ranks, while the local search dynamically balances exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Dynamic \u03b5-dominance ranking\n    epsilon = 0.1\n    filtered_solutions = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] >= obj[0] - epsilon * obj[0] and\n                other_obj[1] >= obj[1] - epsilon * obj[1] and\n                (other_obj[0] > obj[0] - epsilon * obj[0] or\n                 other_obj[1] > obj[1] - epsilon * obj[1])):\n                dominated = True\n                break\n        if not dominated:\n            filtered_solutions.append((sol, obj))\n\n    if not filtered_solutions:\n        filtered_solutions = archive.copy()\n\n    # Select solution with highest \u03b5-dominance rank (more dominated)\n    selected = max(filtered_solutions, key=lambda x: (x[1][0] + x[1][1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate weighted marginal gains\n    capacity_ratio = (capacity - current_weight) / capacity\n    marginal_gain = (value1_lst + epsilon * value2_lst) * (1 + capacity_ratio) / (weight_lst + 1e-6)\n\n    # Sort by marginal gain (descending)\n    sorted_indices = np.argsort(-marginal_gain)\n\n    # Perform feasibility-aware flips\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            # Try removing item\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = temp_weight\n                break\n        else:\n            # Try adding item\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = temp_weight\n                break\n\n    # Adaptive perturbation based on remaining capacity\n    perturbation_prob = min(0.5, 0.2 + capacity_ratio * 0.3)\n    if np.random.rand() < perturbation_prob:\n        # Select items with low marginal gain for potential flip\n        low_gain_indices = np.argsort(marginal_gain)\n        for i in low_gain_indices[:min(3, len(low_gain_indices))]:\n            if new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n            elif new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Final feasibility check\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        excess_items_sorted = sorted(excess_items, key=lambda x: marginal_gain[x])\n        remove_idx = excess_items_sorted[0]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.810395973782146,
            1.230062574148178
        ]
    },
    {
        "algorithm": "The algorithm selects promising solutions from the archive using \u03b5-dominance ranking with adaptive \u03b5 scaling, prioritizes item flips based on weighted marginal gains combining both objectives, and applies capacity-aware perturbations to generate feasible neighbors while dynamically adjusting \u03b5 to balance exploration and exploitation. It emphasizes high-marginal-gain items and uses probabilistic perturbations to escape local optima, ensuring feasibility through iterative checks and removals. The solution selection is guided by \u03b5-dominance, while the neighbor generation balances greedy flips with adaptive perturbations to maintain diversity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Dynamic \u03b5-dominance ranking with adaptive \u03b5\n    epsilon = 0.1\n    filtered_solutions = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] >= obj[0] - epsilon * obj[0] and\n                other_obj[1] >= obj[1] - epsilon * obj[1] and\n                (other_obj[0] > obj[0] - epsilon * obj[0] or\n                 other_obj[1] > obj[1] - epsilon * obj[1])):\n                dominated = True\n                break\n        if not dominated:\n            filtered_solutions.append((sol, obj))\n\n    if not filtered_solutions:\n        filtered_solutions = archive.copy()\n\n    # Select solution with highest \u03b5-dominance rank (more dominated)\n    selected = max(filtered_solutions, key=lambda x: (x[1][0] + x[1][1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive weighted marginal gains with dynamic \u03b5\n    capacity_ratio = (capacity - current_weight) / capacity\n    epsilon = max(0.05, 0.2 * capacity_ratio)  # Dynamic \u03b5 scaling\n    marginal_gain = (value1_lst + epsilon * value2_lst) * (1 + capacity_ratio) / (weight_lst + 1e-6)\n\n    # Sort by marginal gain (descending)\n    sorted_indices = np.argsort(-marginal_gain)\n\n    # Perform feasibility-aware flips\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            # Try removing item\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = temp_weight\n                break\n        else:\n            # Try adding item\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = temp_weight\n                break\n\n    # Adaptive perturbation based on marginal gain and remaining capacity\n    perturbation_prob = min(0.5, 0.2 + capacity_ratio * 0.3)\n    if np.random.rand() < perturbation_prob:\n        # Select items with low marginal gain for potential flip\n        low_gain_indices = np.argsort(marginal_gain)\n        for i in low_gain_indices[:min(3, len(low_gain_indices))]:\n            if new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n            elif new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Final feasibility check\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        excess_items_sorted = sorted(excess_items, key=lambda x: marginal_gain[x])\n        remove_idx = excess_items_sorted[0]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8363632804928134,
            1.2785993218421936
        ]
    },
    {
        "algorithm": "The algorithm dynamically selects high-potential solutions from the archive using \u03b5-dominance ranking with adaptive \u03b5 scaling, prioritizes item flips based on weighted marginal gains combining both objectives, and applies capacity-aware perturbations to generate feasible neighbors while balancing exploration and exploitation through dynamic \u03b5 adjustment and probabilistic perturbations. It emphasizes high-marginal-gain items and ensures feasibility through iterative checks and removals, with solution selection guided by \u03b5-dominance and neighbor generation balancing greedy flips with adaptive perturbations. The algorithm dynamically adjusts perturbation intensity based on remaining capacity, ensuring high-quality solutions across multiple objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Dynamic \u03b5-dominance ranking with adaptive \u03b5\n    epsilon = 0.1\n    filtered_solutions = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] >= obj[0] - epsilon * obj[0] and\n                other_obj[1] >= obj[1] - epsilon * obj[1] and\n                (other_obj[0] > obj[0] - epsilon * obj[0] or\n                 other_obj[1] > obj[1] - epsilon * obj[1])):\n                dominated = True\n                break\n        if not dominated:\n            filtered_solutions.append((sol, obj))\n\n    if not filtered_solutions:\n        filtered_solutions = archive.copy()\n\n    # Select solution with highest \u03b5-dominance rank (more dominated)\n    selected = max(filtered_solutions, key=lambda x: (x[1][0] + x[1][1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Adaptive weighted marginal gains with dynamic \u03b5\n    capacity_ratio = (capacity - current_weight) / capacity\n    epsilon = max(0.05, 0.2 * capacity_ratio)  # Dynamic \u03b5 scaling\n    marginal_gain = (value1_lst + epsilon * value2_lst) * (1 + capacity_ratio) / (weight_lst + 1e-6)\n\n    # Sort by marginal gain (descending)\n    sorted_indices = np.argsort(-marginal_gain)\n\n    # Perform feasibility-aware flips\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            # Try removing item\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = temp_weight\n                break\n        else:\n            # Try adding item\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = temp_weight\n                break\n\n    # Adaptive perturbation based on marginal gain and remaining capacity\n    perturbation_prob = min(0.5, 0.2 + capacity_ratio * 0.3)\n    if np.random.rand() < perturbation_prob:\n        # Select items with low marginal gain for potential flip\n        low_gain_indices = np.argsort(marginal_gain)\n        for i in low_gain_indices[:min(3, len(low_gain_indices))]:\n            if new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n            elif new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Final feasibility check\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        excess_items_sorted = sorted(excess_items, key=lambda x: marginal_gain[x])\n        remove_idx = excess_items_sorted[0]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8302463086258107,
            1.2706534266471863
        ]
    },
    {
        "algorithm": "This algorithm selects high-potential solutions from the archive using adaptive dominance thresholds, then generates neighbors by combining greedy item flips (weighted by both objectives) with random perturbations, dynamically adjusting flip intensity based on remaining capacity. It prioritizes value1 (70%) over value2 (30%) in marginal gains but balances both objectives in selection, while ensuring feasibility through iterative capacity checks and removals of least valuable items. The hybrid approach of greedy and random flips, along with dynamic perturbation intensity, enables exploration of promising regions while maintaining solution quality.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Adaptive dominance threshold selection\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    threshold1 = max_obj1 * 0.15\n    threshold2 = max_obj2 * 0.15\n\n    # Filter solutions with high dominance\n    filtered_solutions = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] >= obj[0] - threshold1 and\n                other_obj[1] >= obj[1] - threshold2 and\n                (other_obj[0] > obj[0] - threshold1 or\n                 other_obj[1] > obj[1] - threshold2)):\n                dominated = True\n                break\n        if not dominated:\n            filtered_solutions.append((sol, obj))\n\n    if not filtered_solutions:\n        filtered_solutions = archive.copy()\n\n    # Select solution with highest combined objective value\n    selected = max(filtered_solutions, key=lambda x: (x[1][0] * 0.6 + x[1][1] * 0.4))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid weighted marginal gains\n    capacity_ratio = (capacity - current_weight) / capacity\n    weight_factor = 0.3 + 0.7 * capacity_ratio\n    marginal_gain = (value1_lst * 0.7 + value2_lst * 0.3) * weight_factor / (weight_lst + 1e-6)\n\n    # Greedy and random flip combination\n    sorted_indices = np.argsort(-marginal_gain)\n    for i in sorted_indices[:min(5, len(sorted_indices))]:\n        if np.random.rand() < 0.7:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Dynamic perturbation intensity\n    perturbation_intensity = min(0.6, 0.3 + capacity_ratio * 0.4)\n    if np.random.rand() < perturbation_intensity:\n        for i in np.random.permutation(len(new_solution))[:3]:\n            if new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n            elif new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Final feasibility check\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        excess_items_sorted = sorted(excess_items, key=lambda x: marginal_gain[x])\n        remove_idx = excess_items_sorted[0]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.33919618652905564,
            1.2035576105117798
        ]
    },
    {
        "algorithm": "The algorithm combines a multi-phase approach: it first selects the best solution by combined objective value, then uses weighted marginal gains to perform high-impact flips while ensuring feasibility, followed by adaptive perturbations to remove low-value items, and finally enforces strict feasibility checks by removing the least valuable items. The weighted marginal gain prioritizes items with higher combined value-to-weight ratios, while the perturbation phase adaptively removes items based on remaining capacity, ensuring diversity in the search.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select base solution with highest combined objective value\n    selected_idx = np.argmax([obj[0] + obj[1] for _, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate weighted marginal gains\n    weight_factor = 0.7\n    weighted_gain = (value1_lst + value2_lst) / (weight_lst ** weight_factor + 1e-6)\n    sorted_indices = np.argsort(-weighted_gain)\n\n    # Phase 1: High-impact flips with feasibility check\n    for i in sorted_indices:\n        if new_solution[i] == 1:\n            if current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n                break\n        else:\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n                break\n\n    # Phase 2: Capacity-aware perturbations\n    remaining_capacity = capacity - current_weight\n    perturbation_factor = min(0.5, 0.1 + 0.3 * (remaining_capacity / capacity))\n\n    if np.random.rand() < perturbation_factor:\n        # Select items with low weighted gain and high weight contribution\n        low_gain_mask = weighted_gain < np.percentile(weighted_gain, 30)\n        candidate_indices = np.where(new_solution)[0]\n\n        if len(candidate_indices) > 0:\n            candidate_indices = sorted(candidate_indices, key=lambda x: weight_lst[x] / (value1_lst[x] + value2_lst[x] + 1e-6))\n            for i in candidate_indices[:min(2, len(candidate_indices))]:\n                if current_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Phase 3: Strict feasibility validation\n    while current_weight > capacity:\n        excess_items = np.where(new_solution)[0]\n        if len(excess_items) == 0:\n            break\n        # Remove items with lowest weighted gain\n        excess_items_sorted = sorted(excess_items, key=lambda x: weighted_gain[x])\n        remove_idx = excess_items_sorted[0]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9270132370417286,
            1.3193289637565613
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using adaptive \u03b5-dominance ranking, prioritizes item flips based on dynamic weighted marginal gains combining both objectives, and applies a hybrid local search strategy (70% greedy flips, 30% random perturbations) while ensuring feasibility through capacity-aware checks and iterative removal of least valuable items. It dynamically adjusts exploration/exploitation based on remaining capacity and marginal gains, balancing greedy improvement with randomness for better multi-objective optimization.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Adaptive \u03b5-dominance ranking\n    epsilon = 0.1\n    filtered_solutions = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] >= obj[0] - epsilon * obj[0] and\n                other_obj[1] >= obj[1] - epsilon * obj[1] and\n                (other_obj[0] > obj[0] - epsilon * obj[0] or\n                 other_obj[1] > obj[1] - epsilon * obj[1])):\n                dominated = True\n                break\n        if not dominated:\n            filtered_solutions.append((sol, obj))\n\n    if not filtered_solutions:\n        filtered_solutions = archive.copy()\n\n    # Select solution with highest \u03b5-dominance rank (more dominated)\n    selected = max(filtered_solutions, key=lambda x: (x[1][0] + x[1][1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Dynamic weighted marginal gains with \u03b5-scaling\n    capacity_ratio = (capacity - current_weight) / capacity\n    epsilon = max(0.05, 0.2 * capacity_ratio)\n    marginal_gain = (value1_lst + epsilon * value2_lst) * (1 + capacity_ratio) / (weight_lst + 1e-6)\n\n    # Hybrid flip mechanism: prioritize high-marginal-gain items (70%) or random flips (30%)\n    sorted_indices = np.argsort(-marginal_gain)\n    for i in sorted_indices[:min(5, len(sorted_indices))]:\n        if np.random.rand() < 0.7:\n            if new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n            elif new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Adaptive perturbation based on marginal gain and remaining capacity\n    perturbation_prob = min(0.5, 0.2 + capacity_ratio * 0.3)\n    if np.random.rand() < perturbation_prob:\n        # Random flip for exploration\n        for i in np.random.permutation(len(new_solution))[:3]:\n            if new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n            elif new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Final feasibility check\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        if not excess_items:\n            break\n        excess_items_sorted = sorted(excess_items, key=lambda x: marginal_gain[x])\n        remove_idx = excess_items_sorted[0]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.38660622864331223,
            1.225898563861847
        ]
    },
    {
        "algorithm": "The algorithm dynamically selects a solution from the archive based on preference-weighted objectives, then applies a three-phase local search: 1) value-weighted random flips of included items, 2) adaptive addition of high-value items within capacity, and 3) capacity-balanced pruning of low-contribution items. The selection prioritizes solutions with balanced objective contributions, while the search phases prioritize high-value/weight ratios and maintain feasibility through capacity checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Dynamic preference-based selection\n    objectives = np.array([obj for _, obj in archive])\n    ideal = np.max(objectives, axis=0)\n    nadir = np.min(objectives, axis=0)\n    preference_weights = (ideal - nadir) / (np.sum(ideal - nadir) + 1e-6)\n    scores = np.dot(objectives, preference_weights)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate normalized objective contributions\n    total_value1 = np.sum(value1_lst * base_solution)\n    total_value2 = np.sum(value2_lst * base_solution)\n    total_weight = np.sum(weight_lst * base_solution)\n\n    # Phase 1: Value-weighted random walk\n    if total_weight > 0:\n        contribution = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        sorted_indices = np.argsort(-contribution * base_solution)\n        for i in sorted_indices[:max(1, len(sorted_indices)//3)]:\n            if np.random.rand() < 0.4:  # 40% chance to consider flipping\n                if base_solution[i] == 1 and total_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n                    total_weight -= weight_lst[i]\n                elif base_solution[i] == 0 and total_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    total_weight += weight_lst[i]\n\n    # Phase 2: Adaptive item swapping\n    remaining_capacity = capacity - total_weight\n    if remaining_capacity > 0:\n        swap_candidates = np.where(~base_solution)[0]\n        if len(swap_candidates) > 0:\n            swap_candidates = sorted(swap_candidates, key=lambda x: (value1_lst[x] + value2_lst[x]) / weight_lst[x])\n            for i in swap_candidates[:min(2, len(swap_candidates))]:\n                if weight_lst[i] <= remaining_capacity:\n                    new_solution[i] = 1\n                    total_weight += weight_lst[i]\n                    remaining_capacity -= weight_lst[i]\n\n    # Phase 3: Objective-balanced pruning\n    while total_weight > capacity:\n        excess_items = np.where(new_solution)[0]\n        if len(excess_items) == 0:\n            break\n        # Remove items with lowest weighted contribution\n        excess_contribution = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        remove_idx = excess_items[np.argmin(excess_contribution[excess_items])]\n        new_solution[remove_idx] = 0\n        total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8861757616050703,
            2.8719278275966644
        ]
    }
]