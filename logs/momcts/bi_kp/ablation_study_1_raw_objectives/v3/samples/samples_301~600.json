[
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the archive by prioritizing Pareto-dominant solutions with high marginal contributions, then applies dominance-aware flips and dynamic perturbations to generate a neighbor solution while ensuring feasibility through marginal-contribution-based removals. It balances multi-objective trade-offs by weighting marginal contributions and dynamically adjusts perturbation intensity based on archive size, with critical design emphasis on adaptive trade-off exploration, marginal contribution analysis, and feasibility-aware perturbations.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Identify Pareto-dominant solutions and calculate trade-off weights\n    pareto_indices = []\n    objectives = np.array([obj for _, obj in archive])\n    trade_off = np.sum(value1_lst) / (np.sum(value2_lst) + 1e-6)\n\n    for i in range(len(archive)):\n        dominated = False\n        for j in range(len(archive)):\n            if i != j and (objectives[j][0] >= objectives[i][0] and objectives[j][1] >= objectives[i][1] and\n                          (objectives[j][0] > objectives[i][0] or objectives[j][1] > objectives[i][1])):\n                dominated = True\n                break\n        if not dominated:\n            pareto_indices.append(i)\n\n    # Step 2: Select solution with highest marginal contribution or underrepresented region\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = (trade_off * marginal1) + ((1 - trade_off) * marginal2)\n\n    if len(pareto_indices) > 0:\n        # Select Pareto solution with highest combined marginal contribution\n        pareto_marginals = []\n        for idx in pareto_indices:\n            sol = archive[idx][0]\n            pareto_marginals.append(np.sum(combined_marginal[sol == 1]))\n        selected_idx = pareto_indices[np.argmax(pareto_marginals)]\n    else:\n        # Select solution with highest combined marginal contribution\n        marginal_scores = []\n        for (sol, _) in archive:\n            marginal_scores.append(np.sum(combined_marginal[sol == 1]))\n        selected_idx = np.argmax(marginal_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 3: Calculate dominance-aware marginal contributions\n    dominance_scores = np.zeros(len(weight_lst))\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            # Potential addition\n            temp_weight = current_weight + weight_lst[i]\n            temp_obj1 = np.sum(value1_lst[new_solution == 1]) + value1_lst[i]\n            temp_obj2 = np.sum(value2_lst[new_solution == 1]) + value2_lst[i]\n\n            # Count how many existing solutions this would dominate\n            dominated_count = 0\n            for (sol, obj) in archive:\n                if (temp_obj1 >= obj[0] and temp_obj2 >= obj[1] and\n                    (temp_obj1 > obj[0] or temp_obj2 > obj[1])):\n                    dominated_count += 1\n            dominance_scores[i] = dominated_count * combined_marginal[i]\n\n        elif new_solution[i] == 1:\n            # Potential removal\n            temp_weight = current_weight - weight_lst[i]\n            temp_obj1 = np.sum(value1_lst[new_solution == 1]) - value1_lst[i]\n            temp_obj2 = np.sum(value2_lst[new_solution == 1]) - value2_lst[i]\n\n            # Count how many existing solutions this would dominate\n            dominated_count = 0\n            for (sol, obj) in archive:\n                if (temp_obj1 >= obj[0] and temp_obj2 >= obj[1] and\n                    (temp_obj1 > obj[0] or temp_obj2 > obj[1])):\n                    dominated_count += 1\n            dominance_scores[i] = dominated_count * combined_marginal[i]\n\n    # Step 4: Perform dominance-aware flips with marginal contribution weighting\n    candidate_indices = np.where(dominance_scores > 0)[0]\n    if len(candidate_indices) > 0:\n        top_candidates = candidate_indices[np.argsort(dominance_scores[candidate_indices])[-min(5, len(candidate_indices)):]]\n        for idx in top_candidates:\n            if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif new_solution[idx] == 1:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Step 5: Dynamic perturbation based on local dominance and marginal contribution\n    perturbation_prob = min(0.6, 0.2 + 0.05 * len(archive))\n    if random.random() < perturbation_prob:\n        # Select items with high marginal contribution for perturbation\n        high_marginal = np.argsort(combined_marginal)[-min(10, len(weight_lst)):]\n        perturb_candidates = np.intersect1d(high_marginal, np.where(new_solution != base_solution)[0])\n        if len(perturb_candidates) > 0:\n            perturb_idx = np.random.choice(perturb_candidates)\n            new_solution[perturb_idx] = 1 - new_solution[perturb_idx]\n            if new_solution[perturb_idx] == 1:\n                current_weight += weight_lst[perturb_idx]\n            else:\n                current_weight -= weight_lst[perturb_idx]\n\n    # Step 6: Feasibility enforcement with marginal contribution-aware removals\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        # Remove items with lowest marginal contribution\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 301,
        "algorithm": "The algorithm selects a solution from the archive's underrepresented regions using crowding distance, then performs adaptive neighborhood search by flipping items with probabilities based on their criticality scores (calculated from potential dominance and value-weight ratios), while ensuring feasibility by removing low-marginal-contribution items if capacity is exceeded. It prioritizes items that could dominate existing solutions or improve the objective space coverage, balancing exploration and exploitation through dynamic flip probabilities and capacity-constrained removals.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Calculate crowding distances and select solution from underrepresented regions\n    objectives = np.array([obj for _, obj in archive])\n    crowding = np.zeros(len(archive))\n\n    # Normalize objectives\n    obj1_min, obj1_max = np.min(objectives[:,0]), np.max(objectives[:,0])\n    obj2_min, obj2_max = np.min(objectives[:,1]), np.max(objectives[:,1])\n    norm_obj = np.zeros_like(objectives)\n    norm_obj[:,0] = (objectives[:,0] - obj1_min) / (obj1_max - obj1_min + 1e-6)\n    norm_obj[:,1] = (objectives[:,1] - obj2_min) / (obj2_max - obj2_min + 1e-6)\n\n    # Sort by each objective\n    sorted_idx1 = np.argsort(norm_obj[:,0])\n    sorted_idx2 = np.argsort(norm_obj[:,1])\n\n    # Calculate crowding distance\n    for i in range(len(archive)):\n        if i == 0 or i == len(archive)-1:\n            crowding[i] = np.inf\n        else:\n            crowding[i] = (norm_obj[sorted_idx1[i+1],0] - norm_obj[sorted_idx1[i-1],0]) + \\\n                          (norm_obj[sorted_idx2[i+1],1] - norm_obj[sorted_idx2[i-1],1])\n\n    # Select solution with lowest crowding distance (most underrepresented)\n    selected_idx = np.argmin(crowding)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Calculate item criticality scores\n    criticality_scores = np.zeros(len(weight_lst))\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1:\n            # Criticality for included items\n            temp_weight = current_weight - weight_lst[i]\n            temp_obj1 = np.sum(value1_lst[new_solution == 1]) - value1_lst[i]\n            temp_obj2 = np.sum(value2_lst[new_solution == 1]) - value2_lst[i]\n\n            # Count how many existing solutions this would dominate\n            dominated_count = 0\n            for (sol, obj) in archive:\n                if (temp_obj1 >= obj[0] and temp_obj2 >= obj[1] and\n                    (temp_obj1 > obj[0] or temp_obj2 > obj[1])):\n                    dominated_count += 1\n            criticality_scores[i] = dominated_count * (value1_lst[i] + value2_lst[i]) / (weight_lst[i] + 1e-6)\n        else:\n            # Criticality for excluded items\n            if (current_weight + weight_lst[i]) <= capacity:\n                temp_weight = current_weight + weight_lst[i]\n                temp_obj1 = np.sum(value1_lst[new_solution == 1]) + value1_lst[i]\n                temp_obj2 = np.sum(value2_lst[new_solution == 1]) + value2_lst[i]\n\n                dominated_count = 0\n                for (sol, obj) in archive:\n                    if (temp_obj1 >= obj[0] and temp_obj2 >= obj[1] and\n                        (temp_obj1 > obj[0] or temp_obj2 > obj[1])):\n                        dominated_count += 1\n                criticality_scores[i] = dominated_count * (value1_lst[i] + value2_lst[i]) / (weight_lst[i] + 1e-6)\n\n    # Step 3: Adaptive neighborhood search with dynamic flip probabilities\n    flip_probs = np.zeros(len(weight_lst))\n    total_criticality = np.sum(criticality_scores)\n    if total_criticality > 0:\n        flip_probs = criticality_scores / total_criticality\n    else:\n        flip_probs = np.ones(len(weight_lst)) / len(weight_lst)\n\n    # Apply flips based on probabilities\n    for i in range(len(weight_lst)):\n        if random.random() < flip_probs[i]:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n            elif new_solution[i] == 1:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n\n    # Step 4: Feasibility enforcement with capacity-aware removals\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        # Remove items with lowest marginal contribution (weight/value ratio)\n        marginal_ratios = (weight_lst[in_items] + 1e-6) / (value1_lst[in_items] + value2_lst[in_items] + 1e-6)\n        worst_item = in_items[np.argmin(marginal_ratios)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9539766286650638,
            2.072556436061859
        ],
        "raw_score": [
            29.681523033685686,
            30.470516646173024
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Calculate crowding distances and select solution from underrepresented regions\n    objectives = np.array([obj for _, obj in archive])\n    crowding = np.zeros(len(archive))\n\n    # Normalize objectives\n    obj1_min, obj1_max = np.min(objectives[:,0]), np.max(objectives[:,0])\n    obj2_min, obj2_max = np.min(objectives[:,1]), np.max(objectives[:,1])\n    norm_obj = np.zeros_like(objectives)\n    norm_obj[:,0] = (objectives[:,0] - obj1_min) / (obj1_max - obj1_min + 1e-6)\n    norm_obj[:,1] = (objectives[:,1] - obj2_min) / (obj2_max - obj2_min + 1e-6)\n\n    # Sort by each objective\n    sorted_idx1 = np.argsort(norm_obj[:,0])\n    sorted_idx2 = np.argsort(norm_obj[:,1])\n\n    # Calculate crowding distance\n    for i in range(len(archive)):\n        if i == 0 or i == len(archive)-1:\n            crowding[i] = np.inf\n        else:\n            crowding[i] = (norm_obj[sorted_idx1[i+1],0] - norm_obj[sorted_idx1[i-1],0]) + \\\n                          (norm_obj[sorted_idx2[i+1],1] - norm_obj[sorted_idx2[i-1],1])\n\n    # Select solution with lowest crowding distance (most underrepresented)\n    selected_idx = np.argmin(crowding)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Calculate item criticality scores\n    criticality_scores = np.zeros(len(weight_lst))\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1:\n            # Criticality for included items\n            temp_weight = current_weight - weight_lst[i]\n            temp_obj1 = np.sum(value1_lst[new_solution == 1]) - value1_lst[i]\n            temp_obj2 = np.sum(value2_lst[new_solution == 1]) - value2_lst[i]\n\n            # Count how many existing solutions this would dominate\n            dominated_count = 0\n            for (sol, obj) in archive:\n                if (temp_obj1 >= obj[0] and temp_obj2 >= obj[1] and\n                    (temp_obj1 > obj[0] or temp_obj2 > obj[1])):\n                    dominated_count += 1\n            criticality_scores[i] = dominated_count * (value1_lst[i] + value2_lst[i]) / (weight_lst[i] + 1e-6)\n        else:\n            # Criticality for excluded items\n            if (current_weight + weight_lst[i]) <= capacity:\n                temp_weight = current_weight + weight_lst[i]\n                temp_obj1 = np.sum(value1_lst[new_solution == 1]) + value1_lst[i]\n                temp_obj2 = np.sum(value2_lst[new_solution == 1]) + value2_lst[i]\n\n                dominated_count = 0\n                for (sol, obj) in archive:\n                    if (temp_obj1 >= obj[0] and temp_obj2 >= obj[1] and\n                        (temp_obj1 > obj[0] or temp_obj2 > obj[1])):\n                        dominated_count += 1\n                criticality_scores[i] = dominated_count * (value1_lst[i] + value2_lst[i]) / (weight_lst[i] + 1e-6)\n\n    # Step 3: Adaptive neighborhood search with dynamic flip probabilities\n    flip_probs = np.zeros(len(weight_lst))\n    total_criticality = np.sum(criticality_scores)\n    if total_criticality > 0:\n        flip_probs = criticality_scores / total_criticality\n    else:\n        flip_probs = np.ones(len(weight_lst)) / len(weight_lst)\n\n    # Apply flips based on probabilities\n    for i in range(len(weight_lst)):\n        if random.random() < flip_probs[i]:\n            if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n            elif new_solution[i] == 1:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n\n    # Step 4: Feasibility enforcement with capacity-aware removals\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        # Remove items with lowest marginal contribution (weight/value ratio)\n        marginal_ratios = (weight_lst[in_items] + 1e-6) / (value1_lst[in_items] + value2_lst[in_items] + 1e-6)\n        worst_item = in_items[np.argmin(marginal_ratios)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 4 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing Pareto-dominant solutions with high marginal contributions, then applies dominance-aware flips and dynamic perturbations to generate a neighbor solution while ensuring feasibility through marginal-contribution-based removals. It balances multi-objective trade-offs by weighting marginal contributions and dynamically adjusts perturbation intensity based on archive size, with critical design emphasis on adaptive trade-off exploration, marginal contribution analysis, and feasibility-aware perturbations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Identify Pareto-dominant solutions and calculate trade-off weights\n    pareto_indices = []\n    objectives = np.array([obj for _, obj in archive])\n    trade_off = np.sum(value1_lst) / (np.sum(value2_lst) + 1e-6)\n\n    for i in range(len(archive)):\n        dominated = False\n        for j in range(len(archive)):\n            if i != j and (objectives[j][0] >= objectives[i][0] and objectives[j][1] >= objectives[i][1] and\n                          (objectives[j][0] > objectives[i][0] or objectives[j][1] > objectives[i][1])):\n                dominated = True\n                break\n        if not dominated:\n            pareto_indices.append(i)\n\n    # Step 2: Select solution with highest marginal contribution or underrepresented region\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = (trade_off * marginal1) + ((1 - trade_off) * marginal2)\n\n    if len(pareto_indices) > 0:\n        # Select Pareto solution with highest combined marginal contribution\n        pareto_marginals = []\n        for idx in pareto_indices:\n            sol = archive[idx][0]\n            pareto_marginals.append(np.sum(combined_marginal[sol == 1]))\n        selected_idx = pareto_indices[np.argmax(pareto_marginals)]\n    else:\n        # Select solution with highest combined marginal contribution\n        marginal_scores = []\n        for (sol, _) in archive:\n            marginal_scores.append(np.sum(combined_marginal[sol == 1]))\n        selected_idx = np.argmax(marginal_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 3: Calculate dominance-aware marginal contributions\n    dominance_scores = np.zeros(len(weight_lst))\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            # Potential addition\n            temp_weight = current_weight + weight_lst[i]\n            temp_obj1 = np.sum(value1_lst[new_solution == 1]) + value1_lst[i]\n            temp_obj2 = np.sum(value2_lst[new_solution == 1]) + value2_lst[i]\n\n            # Count how many existing solutions this would dominate\n            dominated_count = 0\n            for (sol, obj) in archive:\n                if (temp_obj1 >= obj[0] and temp_obj2 >= obj[1] and\n                    (temp_obj1 > obj[0] or temp_obj2 > obj[1])):\n                    dominated_count += 1\n            dominance_scores[i] = dominated_count * combined_marginal[i]\n\n        elif new_solution[i] == 1:\n            # Potential removal\n            temp_weight = current_weight - weight_lst[i]\n            temp_obj1 = np.sum(value1_lst[new_solution == 1]) - value1_lst[i]\n            temp_obj2 = np.sum(value2_lst[new_solution == 1]) - value2_lst[i]\n\n            # Count how many existing solutions this would dominate\n            dominated_count = 0\n            for (sol, obj) in archive:\n                if (temp_obj1 >= obj[0] and temp_obj2 >= obj[1] and\n                    (temp_obj1 > obj[0] or temp_obj2 > obj[1])):\n                    dominated_count += 1\n            dominance_scores[i] = dominated_count * combined_marginal[i]\n\n    # Step 4: Perform dominance-aware flips with marginal contribution weighting\n    candidate_indices = np.where(dominance_scores > 0)[0]\n    if len(candidate_indices) > 0:\n        top_candidates = candidate_indices[np.argsort(dominance_scores[candidate_indices])[-min(5, len(candidate_indices)):]]\n        for idx in top_candidates:\n            if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif new_solution[idx] == 1:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Step 5: Dynamic perturbation based on local dominance and marginal contribution\n    perturbation_prob = min(0.6, 0.2 + 0.05 * len(archive))\n    if random.random() < perturbation_prob:\n        # Select items with high marginal contribution for perturbation\n        high_marginal = np.argsort(combined_marginal)[-min(10, len(weight_lst)):]\n        perturb_candidates = np.intersect1d(high_marginal, np.where(new_solution != base_solution)[0])\n        if len(perturb_candidates) > 0:\n            perturb_idx = np.random.choice(perturb_candidates)\n            new_solution[perturb_idx] = 1 - new_solution[perturb_idx]\n            if new_solution[perturb_idx] == 1:\n                current_weight += weight_lst[perturb_idx]\n            else:\n                current_weight -= weight_lst[perturb_idx]\n\n    # Step 6: Feasibility enforcement with marginal contribution-aware removals\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        # Remove items with lowest marginal contribution\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive Pareto-frontier selection with dominance-aware local search, prioritizing solutions on the Pareto front or weighted regions, then performs item flips that maximize dominance over existing solutions while maintaining feasibility through constrained swaps and adaptive perturbations. It balances exploration (via dominance-aware flips) and exploitation (via Pareto frontier focus), with dynamic feasibility enforcement ensuring high-quality neighbors. The method emphasizes multi-objective improvements through dominance scores and trade-off-aware perturbations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Identify Pareto-dominant solutions\n    pareto_indices = []\n    objectives = np.array([obj for _, obj in archive])\n    for i in range(len(archive)):\n        dominated = False\n        for j in range(len(archive)):\n            if i != j and (objectives[j][0] >= objectives[i][0] and objectives[j][1] >= objectives[i][1] and\n                          (objectives[j][0] > objectives[i][0] or objectives[j][1] > objectives[i][1])):\n                dominated = True\n                break\n        if not dominated:\n            pareto_indices.append(i)\n\n    # Step 2: Select from Pareto front or underrepresented regions\n    if len(pareto_indices) > 0:\n        selected_idx = random.choice(pareto_indices)\n    else:\n        # Fallback to weighted random selection if no Pareto front\n        weights = [obj[0] * 0.6 + obj[1] * 0.4 for (sol, obj) in archive]\n        selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 3: Calculate dominance-aware marginal contributions\n    dominance_scores = np.zeros(len(weight_lst))\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            # Potential addition\n            temp_weight = current_weight + weight_lst[i]\n            temp_obj1 = np.sum(value1_lst[new_solution == 1]) + value1_lst[i]\n            temp_obj2 = np.sum(value2_lst[new_solution == 1]) + value2_lst[i]\n\n            # Count how many existing solutions this would dominate\n            dominated_count = 0\n            for (sol, obj) in archive:\n                if (temp_obj1 >= obj[0] and temp_obj2 >= obj[1] and\n                    (temp_obj1 > obj[0] or temp_obj2 > obj[1])):\n                    dominated_count += 1\n            dominance_scores[i] = dominated_count\n\n        elif new_solution[i] == 1:\n            # Potential removal\n            temp_weight = current_weight - weight_lst[i]\n            temp_obj1 = np.sum(value1_lst[new_solution == 1]) - value1_lst[i]\n            temp_obj2 = np.sum(value2_lst[new_solution == 1]) - value2_lst[i]\n\n            # Count how many existing solutions this would dominate\n            dominated_count = 0\n            for (sol, obj) in archive:\n                if (temp_obj1 >= obj[0] and temp_obj2 >= obj[1] and\n                    (temp_obj1 > obj[0] or temp_obj2 > obj[1])):\n                    dominated_count += 1\n            dominance_scores[i] = dominated_count\n\n    # Step 4: Perform dominance-aware flips\n    candidate_indices = np.where(dominance_scores > 0)[0]\n    if len(candidate_indices) > 0:\n        top_candidates = candidate_indices[np.argsort(dominance_scores[candidate_indices])[-min(3, len(candidate_indices)):]]\n        for idx in top_candidates:\n            if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif new_solution[idx] == 1:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Step 5: Adaptive perturbation based on local dominance\n    if len(pareto_indices) > 0 and random.random() < 0.4:\n        # Higher perturbation probability in non-Pareto regions\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 6: Feasibility enforcement with dominance-aware removals\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        # Remove items that contribute least to dominance\n        removal_scores = []\n        for idx in in_items:\n            temp_obj1 = np.sum(value1_lst[new_solution == 1]) - value1_lst[idx]\n            temp_obj2 = np.sum(value2_lst[new_solution == 1]) - value2_lst[idx]\n            dominated_count = 0\n            for (sol, obj) in archive:\n                if (temp_obj1 >= obj[0] and temp_obj2 >= obj[1] and\n                    (temp_obj1 > obj[0] or temp_obj2 > obj[1])):\n                    dominated_count += 1\n            removal_scores.append(dominated_count)\n\n        worst_item = in_items[np.argmin(removal_scores)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm combines multi-objective clustering with a hybrid local search that prioritizes solutions from underrepresented clusters, uses trade-off-aware marginal contributions to guide item additions/removals, and employs adaptive perturbations and feasibility enforcement to maintain solution quality and diversity. It dynamically balances exploration and exploitation by adjusting perturbation intensity based on cluster trade-offs, while always ensuring feasibility through marginal contribution-based removals. The key variables are weighted by cluster-specific trade-offs, and the algorithm alternates between adding high-marginal items and removing low-marginal ones to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Cluster solutions based on objective trade-offs\n    objectives = np.array([obj for _, obj in archive])\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-6)\n    cluster_centers = np.array([[0.2, 0.8], [0.5, 0.5], [0.8, 0.2]])\n    distances = np.linalg.norm(normalized[:, None] - cluster_centers, axis=2)\n    cluster_assignments = np.argmin(distances, axis=1)\n\n    # Step 2: Select from the least represented cluster\n    cluster_counts = np.bincount(cluster_assignments, minlength=3)\n    selected_cluster = np.argmin(cluster_counts)\n    cluster_indices = np.where(cluster_assignments == selected_cluster)[0]\n    selected_idx = np.random.choice(cluster_indices)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 3: Calculate trade-off-aware marginal contributions\n    tradeoff = cluster_centers[selected_cluster][0]  # Use cluster center's first objective weight\n    marginal = (tradeoff * value1_lst + (1 - tradeoff) * value2_lst) / (weight_lst + 1e-6)\n\n    # Step 4: Hybrid neighborhood expansion\n    # Phase 1: Add items with high marginal contributions\n    candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n    if len(candidate_indices) > 0:\n        top_items = np.argsort(marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n        for idx in candidate_indices[top_items]:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 2: Remove items with low marginal contributions\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = marginal[in_items]\n        bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 5: Adaptive trade-off perturbations\n    perturbation_prob = 0.3 + 0.2 * (1 - tradeoff)\n    if random.random() < perturbation_prob:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 6: Feasibility enforcement with adaptive weight balancing\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        combined_marginal = marginal[in_items]\n        worst_item = in_items[np.argmin(combined_marginal)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive (prioritizing those with high item density and near-capacity weight) and applies a hybrid local search by flipping items with the highest marginal contributions (balancing both objectives) while ensuring feasibility through a final weight-checking step. It intelligently flips a subset of items based on their combined value-to-weight ratio, with a fallback to remove heaviest items if needed.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_solution = max(archive, key=lambda x: sum(x[0]) * (1 - (sum(weight_lst[x[0] == 1]) / capacity)) if sum(weight_lst[x[0] == 1]) <= capacity else -np.inf)[0].copy()\n\n    # Apply a hybrid local search operator: flip a subset of items based on their marginal contributions\n    new_solution = selected_solution.copy()\n    marginal_contributions = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(marginal_contributions)[::-1]\n\n    # Flip the top-k items with the highest marginal contributions\n    k = max(1, len(new_solution) // 10)\n    for idx in sorted_indices[:k]:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            if sum(weight_lst[new_solution == 1]) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Ensure feasibility (redundant but safe)\n    total_weight = sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # If infeasible, flip the heaviest items until feasible\n        sorted_heavy = np.argsort(weight_lst[new_solution == 1])[::-1]\n        for idx in sorted_heavy:\n            if total_weight <= capacity:\n                break\n            new_solution[idx] = 0\n            total_weight -= weight_lst[idx]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design framework (100 words):\n\n- **Keywords**: *Adaptive trade-off momentum, hybrid local search, feasibility-aware perturbations, diversity-aware selection*\n- **Advice**: Combine marginal contribution analysis with dynamic trade-off momentum (e.g., prioritize knee solutions), use hybrid local search with adaptive perturbations, and enforce feasibility via adaptive removal.\n- **Avoid**: Static weights, rigid selection, single-objective focus, and blind perturbations. Avoid over-reliance on dominance counts.\n- **Explanation**: A hybrid strategy balances exploration and exploitation, ensuring diverse, high-quality neighbors while maintaining feasibility. Dynamic trade-off momentum improves Pareto front diversity.\n\n**Step-by-step reasoning**:\n1. **Diversity-aware selection**: Dynamically adjust weights based on Pareto dominance and marginal gains (e.g., prioritize knee solutions).\n2. **Hybrid local search**: Combine marginal flips (exploitation) with adaptive perturbations (exploration) using trade-off momentum.\n3. **Adaptive trade-off momentum**: Scale perturbations based on local optima and objective trade-offs (e.g., higher when stuck).\n4. **Feasibility checks**: Enforce feasibility via adaptive removal of over-weighted items, ensuring robust neighbor generation.\n\nThis ensures high-quality, diverse neighbors while maintaining feasibility.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 302,
        "algorithm": "The algorithm selects knee solutions from the archive by combining Pareto dominance and marginal contribution analysis, then applies a hybrid local search that alternates between dominance-aware flips (prioritizing items that maximize dominated solutions) and adaptive perturbations (targeting high-marginal items), while dynamically adjusting trade-off momentum and ensuring feasibility through adaptive item removal. It prioritizes knee solutions to improve both objectives and balances exploration/exploitation through dynamic trade-off momentum and marginal contribution analysis.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Identify knee solutions and calculate trade-off momentum\n    objectives = np.array([obj for _, obj in archive])\n    knee_indices = []\n    trade_off = np.sum(value1_lst) / (np.sum(value2_lst) + 1e-6)\n\n    # Calculate knee solutions using both dominance and marginal contributions\n    for i in range(len(archive)):\n        dominated = False\n        for j in range(len(archive)):\n            if i != j and (objectives[j][0] >= objectives[i][0] and objectives[j][1] >= objectives[i][1] and\n                          (objectives[j][0] > objectives[i][0] or objectives[j][1] > objectives[i][1])):\n                dominated = True\n                break\n        if not dominated:\n            knee_indices.append(i)\n\n    # If no knee solutions, fall back to high-marginal solutions\n    if not knee_indices:\n        marginal1 = value1_lst / (weight_lst + 1e-6)\n        marginal2 = value2_lst / (weight_lst + 1e-6)\n        combined_marginal = (trade_off * marginal1) + ((1 - trade_off) * marginal2)\n        marginal_scores = []\n        for (sol, _) in archive:\n            marginal_scores.append(np.sum(combined_marginal[sol == 1]))\n        knee_indices = [np.argmax(marginal_scores)]\n\n    selected_idx = random.choice(knee_indices)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Hybrid local search with adaptive trade-off momentum\n    dominance_scores = np.zeros(len(weight_lst))\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            # Potential addition\n            temp_weight = current_weight + weight_lst[i]\n            temp_obj1 = np.sum(value1_lst[new_solution == 1]) + value1_lst[i]\n            temp_obj2 = np.sum(value2_lst[new_solution == 1]) + value2_lst[i]\n\n            # Count how many existing solutions this would dominate\n            dominated_count = 0\n            for (sol, obj) in archive:\n                if (temp_obj1 >= obj[0] and temp_obj2 >= obj[1] and\n                    (temp_obj1 > obj[0] or temp_obj2 > obj[1])):\n                    dominated_count += 1\n            dominance_scores[i] = dominated_count\n\n        elif new_solution[i] == 1:\n            # Potential removal\n            temp_weight = current_weight - weight_lst[i]\n            temp_obj1 = np.sum(value1_lst[new_solution == 1]) - value1_lst[i]\n            temp_obj2 = np.sum(value2_lst[new_solution == 1]) - value2_lst[i]\n\n            # Count how many existing solutions this would dominate\n            dominated_count = 0\n            for (sol, obj) in archive:\n                if (temp_obj1 >= obj[0] and temp_obj2 >= obj[1] and\n                    (temp_obj1 > obj[0] or temp_obj2 > obj[1])):\n                    dominated_count += 1\n            dominance_scores[i] = dominated_count\n\n    # Step 3: Perform dominance-aware flips with adaptive trade-off momentum\n    candidate_indices = np.where(dominance_scores > 0)[0]\n    if len(candidate_indices) > 0:\n        top_candidates = candidate_indices[np.argsort(dominance_scores[candidate_indices])[-min(5, len(candidate_indices)):]]\n        for idx in top_candidates:\n            if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif new_solution[idx] == 1:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Step 4: Adaptive perturbations based on trade-off momentum\n    perturbation_prob = min(0.6, 0.2 + 0.05 * len(archive))\n    if random.random() < perturbation_prob:\n        # Select items with high marginal contribution for perturbation\n        marginal1 = value1_lst / (weight_lst + 1e-6)\n        marginal2 = value2_lst / (weight_lst + 1e-6)\n        combined_marginal = (trade_off * marginal1) + ((1 - trade_off) * marginal2)\n        high_marginal = np.argsort(combined_marginal)[-min(10, len(weight_lst)):]\n        perturb_candidates = np.intersect1d(high_marginal, np.where(new_solution != base_solution)[0])\n        if len(perturb_candidates) > 0:\n            perturb_idx = np.random.choice(perturb_candidates)\n            new_solution[perturb_idx] = 1 - new_solution[perturb_idx]\n            if new_solution[perturb_idx] == 1:\n                current_weight += weight_lst[perturb_idx]\n            else:\n                current_weight -= weight_lst[perturb_idx]\n\n    # Step 5: Feasibility enforcement with adaptive removal\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        # Remove items with lowest marginal contribution\n        marginal1 = value1_lst / (weight_lst + 1e-6)\n        marginal2 = value2_lst / (weight_lst + 1e-6)\n        combined_marginal = (trade_off * marginal1) + ((1 - trade_off) * marginal2)\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.7733144008538796,
            2.0439703166484833
        ],
        "raw_score": [
            27.15524590140645,
            27.704452292170522
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Identify knee solutions and calculate trade-off momentum\n    objectives = np.array([obj for _, obj in archive])\n    knee_indices = []\n    trade_off = np.sum(value1_lst) / (np.sum(value2_lst) + 1e-6)\n\n    # Calculate knee solutions using both dominance and marginal contributions\n    for i in range(len(archive)):\n        dominated = False\n        for j in range(len(archive)):\n            if i != j and (objectives[j][0] >= objectives[i][0] and objectives[j][1] >= objectives[i][1] and\n                          (objectives[j][0] > objectives[i][0] or objectives[j][1] > objectives[i][1])):\n                dominated = True\n                break\n        if not dominated:\n            knee_indices.append(i)\n\n    # If no knee solutions, fall back to high-marginal solutions\n    if not knee_indices:\n        marginal1 = value1_lst / (weight_lst + 1e-6)\n        marginal2 = value2_lst / (weight_lst + 1e-6)\n        combined_marginal = (trade_off * marginal1) + ((1 - trade_off) * marginal2)\n        marginal_scores = []\n        for (sol, _) in archive:\n            marginal_scores.append(np.sum(combined_marginal[sol == 1]))\n        knee_indices = [np.argmax(marginal_scores)]\n\n    selected_idx = random.choice(knee_indices)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Hybrid local search with adaptive trade-off momentum\n    dominance_scores = np.zeros(len(weight_lst))\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            # Potential addition\n            temp_weight = current_weight + weight_lst[i]\n            temp_obj1 = np.sum(value1_lst[new_solution == 1]) + value1_lst[i]\n            temp_obj2 = np.sum(value2_lst[new_solution == 1]) + value2_lst[i]\n\n            # Count how many existing solutions this would dominate\n            dominated_count = 0\n            for (sol, obj) in archive:\n                if (temp_obj1 >= obj[0] and temp_obj2 >= obj[1] and\n                    (temp_obj1 > obj[0] or temp_obj2 > obj[1])):\n                    dominated_count += 1\n            dominance_scores[i] = dominated_count\n\n        elif new_solution[i] == 1:\n            # Potential removal\n            temp_weight = current_weight - weight_lst[i]\n            temp_obj1 = np.sum(value1_lst[new_solution == 1]) - value1_lst[i]\n            temp_obj2 = np.sum(value2_lst[new_solution == 1]) - value2_lst[i]\n\n            # Count how many existing solutions this would dominate\n            dominated_count = 0\n            for (sol, obj) in archive:\n                if (temp_obj1 >= obj[0] and temp_obj2 >= obj[1] and\n                    (temp_obj1 > obj[0] or temp_obj2 > obj[1])):\n                    dominated_count += 1\n            dominance_scores[i] = dominated_count\n\n    # Step 3: Perform dominance-aware flips with adaptive trade-off momentum\n    candidate_indices = np.where(dominance_scores > 0)[0]\n    if len(candidate_indices) > 0:\n        top_candidates = candidate_indices[np.argsort(dominance_scores[candidate_indices])[-min(5, len(candidate_indices)):]]\n        for idx in top_candidates:\n            if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif new_solution[idx] == 1:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Step 4: Adaptive perturbations based on trade-off momentum\n    perturbation_prob = min(0.6, 0.2 + 0.05 * len(archive))\n    if random.random() < perturbation_prob:\n        # Select items with high marginal contribution for perturbation\n        marginal1 = value1_lst / (weight_lst + 1e-6)\n        marginal2 = value2_lst / (weight_lst + 1e-6)\n        combined_marginal = (trade_off * marginal1) + ((1 - trade_off) * marginal2)\n        high_marginal = np.argsort(combined_marginal)[-min(10, len(weight_lst)):]\n        perturb_candidates = np.intersect1d(high_marginal, np.where(new_solution != base_solution)[0])\n        if len(perturb_candidates) > 0:\n            perturb_idx = np.random.choice(perturb_candidates)\n            new_solution[perturb_idx] = 1 - new_solution[perturb_idx]\n            if new_solution[perturb_idx] == 1:\n                current_weight += weight_lst[perturb_idx]\n            else:\n                current_weight -= weight_lst[perturb_idx]\n\n    # Step 5: Feasibility enforcement with adaptive removal\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        # Remove items with lowest marginal contribution\n        marginal1 = value1_lst / (weight_lst + 1e-6)\n        marginal2 = value2_lst / (weight_lst + 1e-6)\n        combined_marginal = (trade_off * marginal1) + ((1 - trade_off) * marginal2)\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 5 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution using a weighted random choice\n    weights = [obj[0] + obj[1] for (sol, obj) in archive]\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Calculate marginal contributions for both objectives\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = marginal1 + marginal2\n\n    # Step 4: Identify candidate items to flip\n    candidate_indices = np.where((base_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) == 0:\n        # If no items can be added, try removing low-value items\n        candidate_indices = np.where(base_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            return base_solution  # No change possible\n\n    # Step 5: Select top-k items based on combined marginal contributions\n    k = max(1, min(5, len(candidate_indices) // 2))\n    top_indices = np.argsort(combined_marginal[candidate_indices])[-k:][::-1]\n\n    # Step 6: Create new solution by flipping selected items\n    new_solution = base_solution.copy()\n    for idx in candidate_indices[top_indices]:\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 7: Dynamic weight adjustment phase\n    while current_weight > capacity:\n        # Identify items to remove based on least combined marginal value\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive with a weighted random choice prioritizing solutions with higher combined objective values (70% weight for value1, 30% for value2), then employs a dynamic flipping strategy that considers both addition and removal of items based on their normalized marginal contributions (60% weight for value1, 40% for value2), while ensuring feasibility through capacity-aware adjustments and occasional random perturbations to escape local optima.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution using a weighted random choice\n    weights = [obj[0] * 0.7 + obj[1] * 0.3 for (sol, obj) in archive]\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Calculate normalized marginal contributions for both objectives\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = 0.6 * marginal1 + 0.4 * marginal2\n\n    # Step 4: Identify candidate items to flip\n    candidate_indices = np.where((base_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) == 0:\n        candidate_indices = np.where(base_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            return base_solution\n\n    # Step 5: Select top items based on combined marginal contributions\n    k = max(1, min(3, len(candidate_indices) // 3))\n    top_indices = np.argsort(combined_marginal[candidate_indices])[-k:][::-1]\n\n    # Step 6: Create new solution by flipping selected items\n    new_solution = base_solution.copy()\n    for idx in candidate_indices[top_indices]:\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 7: Adaptive adjustment phase\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    # Step 8: Random perturbation to escape local optima\n    if random.random() < 0.3:\n        perturb_idx = np.random.choice(np.where(base_solution != new_solution)[0])\n        new_solution[perturb_idx] = 1 - new_solution[perturb_idx]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive trade-off-aware selection with hybrid local search, dynamically balancing marginal contribution flips and feasibility-aware perturbations to prioritize high-value items while maintaining Pareto front diversity, with higher weight given to objective scores (60%) compared to dominance (40%) in selection. The hybrid local search alternates between adding promising items (weighted by trade-off momentum) and removing low-value items, while occasional dynamic perturbations introduce diversity. Feasibility is strictly enforced by removing the least valuable items when capacity is exceeded.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Adaptive trade-off-aware selection\n    objective_scores = [obj[0] + obj[1] for _, obj in archive]\n    dominance_scores = []\n    for _, obj in archive:\n        dominance = sum(1 for _, o in archive if (o[0] > obj[0] and o[1] >= obj[1]) or (o[0] >= obj[0] and o[1] > obj[1]))\n        dominance_scores.append(dominance)\n    combined_scores = [objective_scores[i] * 0.6 + dominance_scores[i] * 0.4 for i in range(len(archive))]\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 2: Calculate dynamic marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n\n    # Step 3: Determine trade-off momentum\n    tradeoff_momentum = 0.5\n    if len(archive) > 1:\n        tradeoff_momentum = 0.5 + 0.3 * (dominance_scores[selected_idx] / max(1, max(dominance_scores)))\n\n    # Step 4: Hybrid local search\n    # Phase 1: Add promising items\n    candidate_indices = np.where((new_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) > 0:\n        weighted_marginal = tradeoff_momentum * marginal1 + (1 - tradeoff_momentum) * marginal2\n        top_items = np.argsort(weighted_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n        for idx in candidate_indices[top_items]:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Remove low-value items\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = (1 - tradeoff_momentum) * marginal1[in_items] + tradeoff_momentum * marginal2[in_items]\n        bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 5: Dynamic perturbation\n    perturbation_prob = 0.2 + 0.3 * (1 - tradeoff_momentum)\n    if random.random() < perturbation_prob:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 6: Feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        combined_marginal = marginal1[in_items] + marginal2[in_items]\n        worst_item = in_items[np.argmin(combined_marginal)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm implements a hybrid local search strategy that combines dominance-based selection with adaptive perturbation, using a trade-off-aware marginal contribution metric to guide item additions and removals, prioritizing solutions with high dominance counts while dynamically balancing exploration of high-value items and preservation of solution quality through dominance-ranked removals. The method alternates between adding items with high combined marginal contributions and those with high trade-off diversity, followed by adaptive removal based on dominance and marginal scores, ensuring feasibility through a final enforcement step.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Identify non-dominated solutions and compute dominance metrics\n    objectives = np.array([obj for _, obj in archive])\n    dominance_counts = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j and (objectives[j, 0] >= objectives[i, 0] and objectives[j, 1] >= objectives[i, 1] and\n                          (objectives[j, 0] > objectives[i, 0] or objectives[j, 1] > objectives[i, 1])):\n                dominance_counts[i] += 1\n\n    # Select solution with highest dominance count (most dominated)\n    selected_idx = np.argmax(dominance_counts)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Compute adaptive marginal contributions\n    dominance_rank = np.sum((objectives >= objectives[selected_idx]) & (objectives != objectives[selected_idx]), axis=1)\n    rank_weight = 1 / (dominance_rank + 1)\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = (rank_weight[selected_idx] * marginal1 + (1 - rank_weight[selected_idx]) * marginal2) * (1 + 0.1 * np.abs(value1_lst - value2_lst))\n\n    # Step 3: Objective-aware perturbation with trade-off diversity\n    if random.random() < 0.5:\n        # Phase 1: Add items with high combined marginal\n        candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n        if len(candidate_indices) > 0:\n            top_items = np.argsort(combined_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n            for idx in candidate_indices[top_items]:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n    else:\n        # Phase 2: Add items with high trade-off diversity\n        tradeoff_diversity = np.abs(value1_lst - value2_lst)\n        candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n        if len(candidate_indices) > 0:\n            top_items = np.argsort(tradeoff_diversity[candidate_indices])[-min(2, len(candidate_indices)):]\n            for idx in candidate_indices[top_items]:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 4: Adaptive removal based on dominance and marginal\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = combined_marginal[in_items] * (1 + 0.2 * dominance_rank[selected_idx])\n        bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 5: Feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        removal_scores = combined_marginal[in_items] * (1 + 0.1 * dominance_counts[selected_idx])\n        worst_item = in_items[np.argmin(removal_scores)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThis algorithm implements a trade-off-aware local search that prioritizes solutions with higher combined objective values, dynamically adjusts exploration based on objective trade-offs, and uses marginal contribution analysis to intelligently add/remove items while enforcing feasibility through capacity-constrained perturbations. The method balances exploitation (via marginal contribution) and exploration (via probabilistic flips) while adaptively adjusting exploration intensity based on solution quality.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select solution with highest combined objective value\n    objectives = np.array([obj for _, obj in archive])\n    combined_scores = objectives[:, 0] + objectives[:, 1]\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Dynamic objective prioritization based on solution quality\n    obj1_total = sum(value1_lst[new_solution == 1])\n    obj2_total = sum(value2_lst[new_solution == 1])\n    if obj1_total + obj2_total > 0:\n        priority = obj1_total / (obj1_total + obj2_total)\n    else:\n        priority = 0.5\n\n    # Step 3: Hybrid local search with adaptive item selection\n    # Phase 1: Add items with high weighted marginal contributions\n    marginal = (priority * value1_lst + (1 - priority) * value2_lst) / (weight_lst + 1e-6)\n    candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n    if len(candidate_indices) > 0:\n        top_items = np.argsort(marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n        for idx in candidate_indices[top_items]:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 2: Remove items with low marginal contributions\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = marginal[in_items]\n        bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 4: Adaptive perturbation based on solution diversity\n    perturbation_prob = 0.1 + 0.2 * priority\n    if random.random() < perturbation_prob:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 5: Feasibility enforcement with capacity-aware removals\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        # Remove items with lowest priority-weighted marginal contribution\n        weighted_marginal = (priority * value1_lst + (1 - priority) * value2_lst)[in_items]\n        worst_item = in_items[np.argmin(weighted_marginal)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: - **Keywords**: *Adaptive trade-off momentum, hybrid local search, feasibility-aware perturbations, diversity-aware selection*\n- **Advice**: Combine marginal contribution analysis with dynamic trade-off momentum (e.g., prioritize knee solutions), use hybrid local search with adaptive perturbations, and enforce feasibility via adaptive removal.\n- **Avoid**: Static weights, rigid selection, single-objective focus, and blind perturbations. Avoid over-reliance on dominance counts.\n- **Explanation**: A hybrid strategy balances exploration and exploitation, ensuring diverse, high-quality neighbors while maintaining feasibility. Dynamic trade-off momentum improves Pareto front diversity. *(99 words)*\n\n**Final Answer**:\n```python\ndef select_neighbor(archive, weights, capacity, item_weights, item_values1, item_values2):\n    # Step 1: Diversity-aware selection\n    selected_idx = choices(range(len(archive)), weights=weights)[0]\n    solution = archive[selected_idx].copy()\n    current_weight = sum(solution * item_weights)\n\n    # Step 2: Hybrid local search (marginal flips + adaptive perturbations)\n    for _ in range(10):\n        # Exploitation: Marginal contribution flips\n        marginals = np.zeros(len(solution))\n        for i in range(len(solution)):\n            if solution[i] == 0:\n                marginals[i] = (item_values1[i] + item_values2[i]) / item_weights[i]\n            else:\n                marginals[i] = - (item_values1[i] + item_values2[i]) / item_weights[i]\n        candidate = np.argsort(marginals)[-5:]  # Top 5 candidates\n\n        # Adaptive trade-off momentum\n        if random() < 0.7:  # Exploitation bias\n            i = choices(candidate)[0]\n            if solution[i] == 0 and current_weight + item_weights[i] <= capacity:\n                solution[i] = 1\n            elif solution[i] == 1:\n                solution[i] = 0\n        else:  # Exploration via random perturbation\n            i = np.random.randint(len(solution))\n            if solution[i] == 0 and current_weight + item_weights[i] <= capacity:\n                solution[i] = 1\n            elif solution[i] == 1:\n                solution[i] = 0\n\n    # Step 3: Feasibility check\n    while current_weight > capacity:\n        heavy_items = np.where(solution == 1)[0]\n        worst_item = min(heavy_items, key=lambda x: (item_values1[x] + item_values2[x]) / item_weights[x])\n        solution[worst_item] = 0\n        current_weight -= item_weights[worst_item]\n\n    return solution\n```\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 303,
        "algorithm": "This algorithm implements a hybrid local search strategy that first selects a knee-point solution from the archive, then uses adaptive trade-off momentum to guide item additions and removals through dynamic marginal contribution analysis, with feasibility-aware perturbations to maintain diversity while ensuring capacity constraints are satisfied. The method alternates between exploitation (adding high-margin items) and exploration (removing low-margin items), and occasionally applies random flips to escape local optima, with final feasibility enforcement to guarantee valid solutions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Knee-point selection with adaptive trade-off momentum\n    objectives = np.array([obj for _, obj in archive])\n    ideal = np.max(objectives, axis=0)\n    anti_ideal = np.min(objectives, axis=0)\n    distances = np.linalg.norm((objectives - anti_ideal) / (ideal - anti_ideal + 1e-6), axis=1)\n    selected_idx = np.argmin(distances)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Dynamic marginal contribution with trade-off momentum\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    tradeoff_momentum = 0.5 + 0.3 * (objectives[selected_idx, 0] - objectives[selected_idx, 1]) / (ideal[0] - ideal[1] + 1e-6)\n    combined_marginal = tradeoff_momentum * marginal1 + (1 - tradeoff_momentum) * marginal2\n\n    # Step 3: Hybrid local search with adaptive perturbations\n    for phase in range(2):\n        if phase == 0:  # Exploitation phase\n            # Add promising items\n            candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n            if len(candidate_indices) > 0:\n                top_items = np.argsort(combined_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n                for idx in candidate_indices[top_items]:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n        else:  # Exploration phase\n            # Remove low-value items\n            in_items = np.where(new_solution == 1)[0]\n            if len(in_items) > 0:\n                removal_scores = combined_marginal[in_items] * (1 + 0.1 * np.random.random())\n                bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n                for idx in in_items[bottom_items]:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n\n    # Step 4: Adaptive perturbation\n    if random.random() < 0.4:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 5: Feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9747587947420927,
            0.2266540229320526
        ],
        "raw_score": [
            27.313617492409126,
            28.207693203055175
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Knee-point selection with adaptive trade-off momentum\n    objectives = np.array([obj for _, obj in archive])\n    ideal = np.max(objectives, axis=0)\n    anti_ideal = np.min(objectives, axis=0)\n    distances = np.linalg.norm((objectives - anti_ideal) / (ideal - anti_ideal + 1e-6), axis=1)\n    selected_idx = np.argmin(distances)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Dynamic marginal contribution with trade-off momentum\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    tradeoff_momentum = 0.5 + 0.3 * (objectives[selected_idx, 0] - objectives[selected_idx, 1]) / (ideal[0] - ideal[1] + 1e-6)\n    combined_marginal = tradeoff_momentum * marginal1 + (1 - tradeoff_momentum) * marginal2\n\n    # Step 3: Hybrid local search with adaptive perturbations\n    for phase in range(2):\n        if phase == 0:  # Exploitation phase\n            # Add promising items\n            candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n            if len(candidate_indices) > 0:\n                top_items = np.argsort(combined_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n                for idx in candidate_indices[top_items]:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n        else:  # Exploration phase\n            # Remove low-value items\n            in_items = np.where(new_solution == 1)[0]\n            if len(in_items) > 0:\n                removal_scores = combined_marginal[in_items] * (1 + 0.1 * np.random.random())\n                bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n                for idx in in_items[bottom_items]:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n\n    # Step 4: Adaptive perturbation\n    if random.random() < 0.4:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 5: Feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThis algorithm implements a hybrid local search strategy that first selects a knee-point solution from the archive, then uses adaptive trade-off momentum to guide item additions and removals through dynamic marginal contribution analysis, with feasibility-aware perturbations to maintain diversity while ensuring capacity constraints are satisfied. The method alternates between exploitation (adding high-margin items) and exploration (removing low-margin items), and occasionally applies random flips to escape local optima, with final feasibility enforcement to guarantee valid solutions.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Knee-point selection with adaptive trade-off momentum\n    objectives = np.array([obj for _, obj in archive])\n    ideal = np.max(objectives, axis=0)\n    anti_ideal = np.min(objectives, axis=0)\n    distances = np.linalg.norm((objectives - anti_ideal) / (ideal - anti_ideal + 1e-6), axis=1)\n    selected_idx = np.argmin(distances)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Dynamic marginal contribution with trade-off momentum\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    tradeoff_momentum = 0.5 + 0.3 * (objectives[selected_idx, 0] - objectives[selected_idx, 1]) / (ideal[0] - ideal[1] + 1e-6)\n    combined_marginal = tradeoff_momentum * marginal1 + (1 - tradeoff_momentum) * marginal2\n\n    # Step 3: Hybrid local search with adaptive perturbations\n    for phase in range(2):\n        if phase == 0:  # Exploitation phase\n            # Add promising items\n            candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n            if len(candidate_indices) > 0:\n                top_items = np.argsort(combined_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n                for idx in candidate_indices[top_items]:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n        else:  # Exploration phase\n            # Remove low-value items\n            in_items = np.where(new_solution == 1)[0]\n            if len(in_items) > 0:\n                removal_scores = combined_marginal[in_items] * (1 + 0.1 * np.random.random())\n                bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n                for idx in in_items[bottom_items]:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n\n    # Step 4: Adaptive perturbation\n    if random.random() < 0.4:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 5: Feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm implements a hybrid local search strategy that prioritizes knee solutions (where objective trade-offs are balanced) while dynamically adjusting item selections based on adaptive trade-off momentum, marginal contribution analysis, and controlled perturbations to explore high-quality neighbors while maintaining feasibility through dominance-aware feasibility enforcement. It balances item additions (favoring high marginal value) with selective removals (targeting low-value items) and occasionally perturbs the solution to escape local optima, all while ensuring the generated neighbor remains feasible. The trade-off momentum parameter (derived from objective diversity) dynamically adjusts the weighting between the two objectives, influencing both item selection and perturbation probability.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Compute knee solutions and dominance metrics\n    objectives = np.array([obj for _, obj in archive])\n    knee_idx = np.argmin(np.abs(objectives[:, 0] - objectives[:, 1]))\n    base_solution = archive[knee_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Compute adaptive trade-off momentum\n    tradeoff_momentum = 0.5 + 0.4 * np.std(objectives[:, 0] - objectives[:, 1]) / np.mean(objectives)\n\n    # Step 3: Hybrid local search with marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    weighted_marginal = tradeoff_momentum * marginal1 + (1 - tradeoff_momentum) * marginal2\n\n    # Phase 1: Add promising items\n    candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n    if len(candidate_indices) > 0:\n        top_items = np.argsort(weighted_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n        for idx in candidate_indices[top_items]:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 2: Remove low-value items\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = weighted_marginal[in_items] * (1 + 0.2 * np.abs(value1_lst[in_items] - value2_lst[in_items]))\n        bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 4: Adaptive perturbation\n    perturbation_prob = 0.2 + 0.3 * (1 - tradeoff_momentum)\n    if random.random() < perturbation_prob:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 5: Feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        combined_marginal = marginal1[in_items] + marginal2[in_items]\n        worst_item = in_items[np.argmin(combined_marginal)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: *Adaptive trade-off momentum, hybrid local search, feasibility-aware perturbations, diversity-aware selection*\n- **Advice**: Combine marginal contribution analysis with dynamic trade-off momentum (e.g., prioritize knee solutions), use hybrid local search with adaptive perturbations, and enforce feasibility via adaptive removal.\n- **Avoid**: Static weights, rigid selection, single-objective focus, and blind perturbations. Avoid over-reliance on dominance counts.\n- **Explanation**: A hybrid strategy balances exploration and exploitation, ensuring diverse, high-quality neighbors while maintaining feasibility. Dynamic trade-off momentum improves Pareto front diversity. *(99 words)*\n\n**Final Answer**:\n```python\ndef select_neighbor(archive, weights, capacity, item_weights, item_values1, item_values2):\n    # Step 1: Diversity-aware selection\n    selected_idx = choices(range(len(archive)), weights=weights)[0]\n    solution = archive[selected_idx].copy()\n    current_weight = sum(solution * item_weights)\n\n    # Step 2: Hybrid local search (marginal flips + adaptive perturbations)\n    for _ in range(10):\n        # Exploitation: Marginal contribution flips\n        marginals = np.zeros(len(solution))\n        for i in range(len(solution)):\n            if solution[i] == 0:\n                marginals[i] = (item_values1[i] + item_values2[i]) / item_weights[i]\n            else:\n                marginals[i] = - (item_values1[i] + item_values2[i]) / item_weights[i]\n        candidate = np.argsort(marginals)[-5:]  # Top 5 candidates\n\n        # Adaptive trade-off momentum\n        if random() < 0.7:  # Exploitation bias\n            i = choices(candidate)[0]\n            if solution[i] == 0 and current_weight + item_weights[i] <= capacity:\n                solution[i] = 1\n            elif solution[i] == 1:\n                solution[i] = 0\n        else:  # Exploration via random perturbation\n            i = np.random.randint(len(solution))\n            if solution[i] == 0 and current_weight + item_weights[i] <= capacity:\n                solution[i] = 1\n            elif solution[i] == 1:\n                solution[i] = 0\n\n    # Step 3: Feasibility check\n    while current_weight > capacity:\n        heavy_items = np.where(solution == 1)[0]\n        worst_item = min(heavy_items, key=lambda x: (item_values1[x] + item_values2[x]) / item_weights[x])\n        solution[worst_item] = 0\n        current_weight -= item_weights[worst_item]\n\n    return solution\n```\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 304,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution with high diversity in objectives\n    objectives = np.array([obj for _, obj in archive])\n    ideal = np.max(objectives, axis=0)\n    anti_ideal = np.min(objectives, axis=0)\n    distances = np.linalg.norm((objectives - anti_ideal) / (ideal - anti_ideal + 1e-6), axis=1)\n    selected_idx = np.argmax(distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Dynamic trade-off momentum based on objective diversity\n    tradeoff_momentum = 0.5 + 0.4 * (objectives[selected_idx, 0] - objectives[selected_idx, 1]) / (ideal[0] - ideal[1] + 1e-6)\n\n    # Step 3: Hybrid local search with value-driven perturbations\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = tradeoff_momentum * marginal1 + (1 - tradeoff_momentum) * marginal2\n\n    # Phase 1: Add high-margin items\n    candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n    if len(candidate_indices) > 0:\n        top_items = np.argsort(combined_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n        for idx in candidate_indices[top_items]:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 2: Remove low-margin items with adaptive probability\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = combined_marginal[in_items] * (0.5 + 0.5 * np.random.random(len(in_items)))\n        bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 4: Value-aware perturbation\n    if random.random() < 0.3:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 5: Feasibility enforcement with value-aware removal\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8187965746700502,
            0.2511448860168457
        ],
        "raw_score": [
            26.937050265249386,
            27.791070982505367
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution with high diversity in objectives\n    objectives = np.array([obj for _, obj in archive])\n    ideal = np.max(objectives, axis=0)\n    anti_ideal = np.min(objectives, axis=0)\n    distances = np.linalg.norm((objectives - anti_ideal) / (ideal - anti_ideal + 1e-6), axis=1)\n    selected_idx = np.argmax(distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Dynamic trade-off momentum based on objective diversity\n    tradeoff_momentum = 0.5 + 0.4 * (objectives[selected_idx, 0] - objectives[selected_idx, 1]) / (ideal[0] - ideal[1] + 1e-6)\n\n    # Step 3: Hybrid local search with value-driven perturbations\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = tradeoff_momentum * marginal1 + (1 - tradeoff_momentum) * marginal2\n\n    # Phase 1: Add high-margin items\n    candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n    if len(candidate_indices) > 0:\n        top_items = np.argsort(combined_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n        for idx in candidate_indices[top_items]:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 2: Remove low-margin items with adaptive probability\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = combined_marginal[in_items] * (0.5 + 0.5 * np.random.random(len(in_items)))\n        bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 4: Value-aware perturbation\n    if random.random() < 0.3:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 5: Feasibility enforcement with value-aware removal\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution using a weighted random choice\n    weights = [obj[0] + obj[1] for (sol, obj) in archive]\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Calculate marginal contributions for both objectives\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = marginal1 + marginal2\n\n    # Step 4: Identify candidate items to flip\n    candidate_indices = np.where((base_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) == 0:\n        # If no items can be added, try removing low-value items\n        candidate_indices = np.where(base_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            return base_solution  # No change possible\n\n    # Step 5: Select top-k items based on combined marginal contributions\n    k = max(1, min(5, len(candidate_indices) // 2))\n    top_indices = np.argsort(combined_marginal[candidate_indices])[-k:][::-1]\n\n    # Step 6: Create new solution by flipping selected items\n    new_solution = base_solution.copy()\n    for idx in candidate_indices[top_indices]:\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 7: Dynamic weight adjustment phase\n    while current_weight > capacity:\n        # Identify items to remove based on least combined marginal value\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm implements a hybrid local search strategy that prioritizes knee solutions (where objective trade-offs are balanced) while dynamically adjusting item selections based on adaptive trade-off momentum, marginal contribution analysis, and controlled perturbations to explore high-quality neighbors while maintaining feasibility through dominance-aware feasibility enforcement. It balances item additions (favoring high marginal value) with selective removals (targeting low-value items) and occasionally perturbs the solution to escape local optima, all while ensuring the generated neighbor remains feasible. The trade-off momentum parameter (derived from objective diversity) dynamically adjusts the weighting between the two objectives, influencing both item selection and perturbation probability.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Compute knee solutions and dominance metrics\n    objectives = np.array([obj for _, obj in archive])\n    knee_idx = np.argmin(np.abs(objectives[:, 0] - objectives[:, 1]))\n    base_solution = archive[knee_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Compute adaptive trade-off momentum\n    tradeoff_momentum = 0.5 + 0.4 * np.std(objectives[:, 0] - objectives[:, 1]) / np.mean(objectives)\n\n    # Step 3: Hybrid local search with marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    weighted_marginal = tradeoff_momentum * marginal1 + (1 - tradeoff_momentum) * marginal2\n\n    # Phase 1: Add promising items\n    candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n    if len(candidate_indices) > 0:\n        top_items = np.argsort(weighted_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n        for idx in candidate_indices[top_items]:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 2: Remove low-value items\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = weighted_marginal[in_items] * (1 + 0.2 * np.abs(value1_lst[in_items] - value2_lst[in_items]))\n        bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 4: Adaptive perturbation\n    perturbation_prob = 0.2 + 0.3 * (1 - tradeoff_momentum)\n    if random.random() < perturbation_prob:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 5: Feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        combined_marginal = marginal1[in_items] + marginal2[in_items]\n        worst_item = in_items[np.argmin(combined_marginal)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: *Adaptive trade-off momentum, hybrid local search, feasibility-aware perturbations, diversity-aware selection*\n- **Advice**: Combine marginal contribution analysis with dynamic trade-off momentum (e.g., prioritize knee solutions), use hybrid local search with adaptive perturbations, and enforce feasibility via adaptive removal.\n- **Avoid**: Static weights, rigid selection, single-objective focus, and blind perturbations. Avoid over-reliance on dominance counts.\n- **Explanation**: A hybrid strategy balances exploration and exploitation, ensuring diverse, high-quality neighbors while maintaining feasibility. Dynamic trade-off momentum improves Pareto front diversity. *(99 words)*\n\n**Final Answer**:\n```python\ndef select_neighbor(archive, weights, capacity, item_weights, item_values1, item_values2):\n    # Step 1: Diversity-aware selection\n    selected_idx = choices(range(len(archive)), weights=weights)[0]\n    solution = archive[selected_idx].copy()\n    current_weight = sum(solution * item_weights)\n\n    # Step 2: Hybrid local search (marginal flips + adaptive perturbations)\n    for _ in range(10):\n        # Exploitation: Marginal contribution flips\n        marginals = np.zeros(len(solution))\n        for i in range(len(solution)):\n            if solution[i] == 0:\n                marginals[i] = (item_values1[i] + item_values2[i]) / item_weights[i]\n            else:\n                marginals[i] = - (item_values1[i] + item_values2[i]) / item_weights[i]\n        candidate = np.argsort(marginals)[-5:]  # Top 5 candidates\n\n        # Adaptive trade-off momentum\n        if random() < 0.7:  # Exploitation bias\n            i = choices(candidate)[0]\n            if solution[i] == 0 and current_weight + item_weights[i] <= capacity:\n                solution[i] = 1\n            elif solution[i] == 1:\n                solution[i] = 0\n        else:  # Exploration via random perturbation\n            i = np.random.randint(len(solution))\n            if solution[i] == 0 and current_weight + item_weights[i] <= capacity:\n                solution[i] = 1\n            elif solution[i] == 1:\n                solution[i] = 0\n\n    # Step 3: Feasibility check\n    while current_weight > capacity:\n        heavy_items = np.where(solution == 1)[0]\n        worst_item = min(heavy_items, key=lambda x: (item_values1[x] + item_values2[x]) / item_weights[x])\n        solution[worst_item] = 0\n        current_weight -= item_weights[worst_item]\n\n    return solution\n```\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 305,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution with high combined objective value\n    objectives = np.array([obj[0] + obj[1] for (sol, obj) in archive])\n    selected_idx = np.argmax(objectives)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Calculate normalized marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = (marginal1 + marginal2) / 2\n\n    # Step 4: Identify candidate items to add (high marginal value)\n    candidate_add = np.where((base_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_add) > 0:\n        top_add = candidate_add[np.argsort(combined_marginal[candidate_add])[-min(3, len(candidate_add)):]]\n\n    # Step 5: Identify candidate items to remove (low marginal value)\n    candidate_remove = np.where(base_solution == 1)[0]\n    if len(candidate_remove) > 0:\n        bottom_remove = candidate_remove[np.argsort(combined_marginal[candidate_remove])[:min(2, len(candidate_remove))]]\n\n    # Step 6: Create new solution with balanced additions and removals\n    new_solution = base_solution.copy()\n    if len(candidate_add) > 0:\n        for idx in top_add:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    if len(candidate_remove) > 0:\n        for idx in bottom_remove:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 7: Dynamic weight adjustment if overweight\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    # Step 8: Optional: Add a small random perturbation\n    if random.random() < 0.2:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Final feasibility check\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8268058015428194,
            0.19291913509368896
        ],
        "raw_score": [
            27.150826882528143,
            27.670931862305245
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution with high combined objective value\n    objectives = np.array([obj[0] + obj[1] for (sol, obj) in archive])\n    selected_idx = np.argmax(objectives)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Calculate normalized marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = (marginal1 + marginal2) / 2\n\n    # Step 4: Identify candidate items to add (high marginal value)\n    candidate_add = np.where((base_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_add) > 0:\n        top_add = candidate_add[np.argsort(combined_marginal[candidate_add])[-min(3, len(candidate_add)):]]\n\n    # Step 5: Identify candidate items to remove (low marginal value)\n    candidate_remove = np.where(base_solution == 1)[0]\n    if len(candidate_remove) > 0:\n        bottom_remove = candidate_remove[np.argsort(combined_marginal[candidate_remove])[:min(2, len(candidate_remove))]]\n\n    # Step 6: Create new solution with balanced additions and removals\n    new_solution = base_solution.copy()\n    if len(candidate_add) > 0:\n        for idx in top_add:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    if len(candidate_remove) > 0:\n        for idx in bottom_remove:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 7: Dynamic weight adjustment if overweight\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    # Step 8: Optional: Add a small random perturbation\n    if random.random() < 0.2:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Final feasibility check\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm implements a hybrid local search strategy that prioritizes knee solutions (where objective trade-offs are balanced) while dynamically adjusting item selections based on adaptive trade-off momentum, marginal contribution analysis, and controlled perturbations to explore high-quality neighbors while maintaining feasibility through dominance-aware feasibility enforcement. It balances item additions (favoring high marginal value) with selective removals (targeting low-value items) and occasionally perturbs the solution to escape local optima, all while ensuring the generated neighbor remains feasible. The trade-off momentum parameter (derived from objective diversity) dynamically adjusts the weighting between the two objectives, influencing both item selection and perturbation probability.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Compute knee solutions and dominance metrics\n    objectives = np.array([obj for _, obj in archive])\n    knee_idx = np.argmin(np.abs(objectives[:, 0] - objectives[:, 1]))\n    base_solution = archive[knee_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Compute adaptive trade-off momentum\n    tradeoff_momentum = 0.5 + 0.4 * np.std(objectives[:, 0] - objectives[:, 1]) / np.mean(objectives)\n\n    # Step 3: Hybrid local search with marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    weighted_marginal = tradeoff_momentum * marginal1 + (1 - tradeoff_momentum) * marginal2\n\n    # Phase 1: Add promising items\n    candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n    if len(candidate_indices) > 0:\n        top_items = np.argsort(weighted_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n        for idx in candidate_indices[top_items]:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 2: Remove low-value items\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = weighted_marginal[in_items] * (1 + 0.2 * np.abs(value1_lst[in_items] - value2_lst[in_items]))\n        bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 4: Adaptive perturbation\n    perturbation_prob = 0.2 + 0.3 * (1 - tradeoff_momentum)\n    if random.random() < perturbation_prob:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 5: Feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        combined_marginal = marginal1[in_items] + marginal2[in_items]\n        worst_item = in_items[np.argmin(combined_marginal)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 306,
        "algorithm": "This heuristic algorithm combines adaptive objective balancing, value-aware marginal contributions, and multi-stage local search (addition, removal, and perturbation) to generate high-quality neighbors while ensuring feasibility through controlled item swaps and value-aware removals. It prioritizes items with high marginal contributions, adjusts trade-off sensitivity dynamically, and uses diversity-based selection to explore promising regions of the solution space. The algorithm balances exploration (perturbation) and exploitation (marginal contributions) while maintaining feasibility through a hybrid removal strategy.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select base solution with highest objective diversity\n    objectives = np.array([obj for _, obj in archive])\n    diversity_scores = np.abs(objectives[:, 0] - objectives[:, 1]) / (np.sum(objectives, axis=1) + 1e-6)\n    base_idx = np.argmax(diversity_scores)\n    base_solution = archive[base_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Compute adaptive trade-off sensitivity\n    tradeoff_sensitivity = 0.3 + 0.7 * np.std(objectives[:, 0] - objectives[:, 1]) / (np.mean(objectives) + 1e-6)\n\n    # Step 3: Calculate value-aware marginal contributions\n    value_ratio = np.maximum(value1_lst, value2_lst) / (np.minimum(value1_lst, value2_lst) + 1e-6)\n    marginal_contribution = (tradeoff_sensitivity * value1_lst + (1 - tradeoff_sensitivity) * value2_lst) / (weight_lst + 1e-6)\n    weighted_contribution = marginal_contribution * (1 + 0.5 * np.log1p(value_ratio))\n\n    # Step 4: Multi-stage local search\n    # Phase 1: Add high-contribution items\n    candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n    if len(candidate_indices) > 0:\n        top_items = np.argsort(weighted_contribution[candidate_indices])[-min(5, len(candidate_indices)):]\n        for idx in candidate_indices[top_items]:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 2: Remove low-impact items\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = weighted_contribution[in_items] * (1 - 0.3 * np.abs(value1_lst[in_items] - value2_lst[in_items]) / (np.sum(objectives, axis=1)[base_idx] + 1e-6))\n        bottom_items = np.argsort(removal_scores)[:min(3, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 5: Value-aware perturbation\n    perturbation_strength = 0.1 + 0.4 * (1 - tradeoff_sensitivity)\n    if random.random() < perturbation_strength:\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Swap one low-value item with one high-value item\n            low_value_item = in_items[np.argmin(weighted_contribution[in_items])]\n            high_value_item = out_items[np.argmax(weighted_contribution[out_items])]\n            if weight_lst[high_value_item] <= capacity - current_weight + weight_lst[low_value_item]:\n                new_solution[low_value_item] = 0\n                new_solution[high_value_item] = 1\n                current_weight = current_weight - weight_lst[low_value_item] + weight_lst[high_value_item]\n\n    # Step 6: Feasibility enforcement with value-aware removal\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        # Remove items with lowest value-to-weight ratio\n        removal_candidates = np.argsort(value1_lst[in_items] + value2_lst[in_items])[:min(2, len(in_items))]\n        for idx in in_items[removal_candidates]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.6519947531319517,
            0.5350252985954285
        ],
        "raw_score": [
            27.539937746197815,
            28.78310779888307
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select base solution with highest objective diversity\n    objectives = np.array([obj for _, obj in archive])\n    diversity_scores = np.abs(objectives[:, 0] - objectives[:, 1]) / (np.sum(objectives, axis=1) + 1e-6)\n    base_idx = np.argmax(diversity_scores)\n    base_solution = archive[base_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Compute adaptive trade-off sensitivity\n    tradeoff_sensitivity = 0.3 + 0.7 * np.std(objectives[:, 0] - objectives[:, 1]) / (np.mean(objectives) + 1e-6)\n\n    # Step 3: Calculate value-aware marginal contributions\n    value_ratio = np.maximum(value1_lst, value2_lst) / (np.minimum(value1_lst, value2_lst) + 1e-6)\n    marginal_contribution = (tradeoff_sensitivity * value1_lst + (1 - tradeoff_sensitivity) * value2_lst) / (weight_lst + 1e-6)\n    weighted_contribution = marginal_contribution * (1 + 0.5 * np.log1p(value_ratio))\n\n    # Step 4: Multi-stage local search\n    # Phase 1: Add high-contribution items\n    candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n    if len(candidate_indices) > 0:\n        top_items = np.argsort(weighted_contribution[candidate_indices])[-min(5, len(candidate_indices)):]\n        for idx in candidate_indices[top_items]:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 2: Remove low-impact items\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = weighted_contribution[in_items] * (1 - 0.3 * np.abs(value1_lst[in_items] - value2_lst[in_items]) / (np.sum(objectives, axis=1)[base_idx] + 1e-6))\n        bottom_items = np.argsort(removal_scores)[:min(3, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 5: Value-aware perturbation\n    perturbation_strength = 0.1 + 0.4 * (1 - tradeoff_sensitivity)\n    if random.random() < perturbation_strength:\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Swap one low-value item with one high-value item\n            low_value_item = in_items[np.argmin(weighted_contribution[in_items])]\n            high_value_item = out_items[np.argmax(weighted_contribution[out_items])]\n            if weight_lst[high_value_item] <= capacity - current_weight + weight_lst[low_value_item]:\n                new_solution[low_value_item] = 0\n                new_solution[high_value_item] = 1\n                current_weight = current_weight - weight_lst[low_value_item] + weight_lst[high_value_item]\n\n    # Step 6: Feasibility enforcement with value-aware removal\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        # Remove items with lowest value-to-weight ratio\n        removal_candidates = np.argsort(value1_lst[in_items] + value2_lst[in_items])[:min(2, len(in_items))]\n        for idx in in_items[removal_candidates]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm implements a hybrid local search strategy that prioritizes knee solutions (where objective trade-offs are balanced) while dynamically adjusting item selections based on adaptive trade-off momentum, marginal contribution analysis, and controlled perturbations to explore high-quality neighbors while maintaining feasibility through dominance-aware feasibility enforcement. It balances item additions (favoring high marginal value) with selective removals (targeting low-value items) and occasionally perturbs the solution to escape local optima, all while ensuring the generated neighbor remains feasible. The trade-off momentum parameter (derived from objective diversity) dynamically adjusts the weighting between the two objectives, influencing both item selection and perturbation probability.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Compute knee solutions and dominance metrics\n    objectives = np.array([obj for _, obj in archive])\n    knee_idx = np.argmin(np.abs(objectives[:, 0] - objectives[:, 1]))\n    base_solution = archive[knee_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Compute adaptive trade-off momentum\n    tradeoff_momentum = 0.5 + 0.4 * np.std(objectives[:, 0] - objectives[:, 1]) / np.mean(objectives)\n\n    # Step 3: Hybrid local search with marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    weighted_marginal = tradeoff_momentum * marginal1 + (1 - tradeoff_momentum) * marginal2\n\n    # Phase 1: Add promising items\n    candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n    if len(candidate_indices) > 0:\n        top_items = np.argsort(weighted_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n        for idx in candidate_indices[top_items]:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 2: Remove low-value items\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = weighted_marginal[in_items] * (1 + 0.2 * np.abs(value1_lst[in_items] - value2_lst[in_items]))\n        bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 4: Adaptive perturbation\n    perturbation_prob = 0.2 + 0.3 * (1 - tradeoff_momentum)\n    if random.random() < perturbation_prob:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 5: Feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        combined_marginal = marginal1[in_items] + marginal2[in_items]\n        worst_item = in_items[np.argmin(combined_marginal)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 307,
        "algorithm": "This algorithm implements a dynamic marginal-contribution-based local search that prioritizes solutions with moderate objective correlation, adaptively weights item selections based on their dual-objective contributions, and uses controlled perturbations guided by solution quality while ensuring feasibility through multi-criteria removal. It alternates between adding high-weighted-marginal items and removing low-contribution items, with probabilistic flips to explore the neighborhood, and enforces feasibility by iteratively removing least valuable items when capacity is exceeded.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select solution with highest objective correlation\n    objectives = np.array([obj for _, obj in archive])\n    correlations = np.corrcoef(objectives, rowvar=False)[0, 1]\n    base_idx = np.argmax(np.abs(correlations - 0.5))  # Prefer solutions with moderate correlation\n    base_solution = archive[base_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Compute dynamic trade-off weights\n    obj_std = np.std(objectives, axis=0)\n    tradeoff_weights = obj_std / np.sum(obj_std)\n\n    # Step 3: Marginal contribution analysis with dynamic weights\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    weighted_marginal = tradeoff_weights[0] * marginal1 + tradeoff_weights[1] * marginal2\n\n    # Phase 1: Add items with high weighted marginal contribution\n    candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n    if len(candidate_indices) > 0:\n        top_items = np.argsort(weighted_marginal[candidate_indices])[-min(5, len(candidate_indices)):]\n        for idx in candidate_indices[top_items]:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 2: Remove items with low marginal contribution to both objectives\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = (1 - tradeoff_weights[0]) * marginal1[in_items] + (1 - tradeoff_weights[1]) * marginal2[in_items]\n        bottom_items = np.argsort(removal_scores)[:min(3, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 4: Adaptive perturbation based on solution quality\n    solution_quality = np.mean(objectives[base_idx])\n    perturbation_prob = 0.1 + 0.4 * (1 - solution_quality / np.max(objectives))\n    if random.random() < perturbation_prob:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 5: Multi-criteria feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        # Remove items with lowest combined marginal contribution\n        combined_marginal = marginal1[in_items] + marginal2[in_items]\n        worst_item = in_items[np.argmin(combined_marginal)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.7917803860477658,
            0.3371904790401459
        ],
        "raw_score": [
            26.891514769263217,
            27.897428368157346
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select solution with highest objective correlation\n    objectives = np.array([obj for _, obj in archive])\n    correlations = np.corrcoef(objectives, rowvar=False)[0, 1]\n    base_idx = np.argmax(np.abs(correlations - 0.5))  # Prefer solutions with moderate correlation\n    base_solution = archive[base_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Compute dynamic trade-off weights\n    obj_std = np.std(objectives, axis=0)\n    tradeoff_weights = obj_std / np.sum(obj_std)\n\n    # Step 3: Marginal contribution analysis with dynamic weights\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    weighted_marginal = tradeoff_weights[0] * marginal1 + tradeoff_weights[1] * marginal2\n\n    # Phase 1: Add items with high weighted marginal contribution\n    candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n    if len(candidate_indices) > 0:\n        top_items = np.argsort(weighted_marginal[candidate_indices])[-min(5, len(candidate_indices)):]\n        for idx in candidate_indices[top_items]:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 2: Remove items with low marginal contribution to both objectives\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = (1 - tradeoff_weights[0]) * marginal1[in_items] + (1 - tradeoff_weights[1]) * marginal2[in_items]\n        bottom_items = np.argsort(removal_scores)[:min(3, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 4: Adaptive perturbation based on solution quality\n    solution_quality = np.mean(objectives[base_idx])\n    perturbation_prob = 0.1 + 0.4 * (1 - solution_quality / np.max(objectives))\n    if random.random() < perturbation_prob:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 5: Multi-criteria feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        # Remove items with lowest combined marginal contribution\n        combined_marginal = marginal1[in_items] + marginal2[in_items]\n        worst_item = in_items[np.argmin(combined_marginal)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 4 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm implements a hybrid local search strategy that prioritizes knee solutions (where objective trade-offs are balanced) while dynamically adjusting item selections based on adaptive trade-off momentum, marginal contribution analysis, and controlled perturbations to explore high-quality neighbors while maintaining feasibility through dominance-aware feasibility enforcement. It balances item additions (favoring high marginal value) with selective removals (targeting low-value items) and occasionally perturbs the solution to escape local optima, all while ensuring the generated neighbor remains feasible. The trade-off momentum parameter (derived from objective diversity) dynamically adjusts the weighting between the two objectives, influencing both item selection and perturbation probability.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Compute knee solutions and dominance metrics\n    objectives = np.array([obj for _, obj in archive])\n    knee_idx = np.argmin(np.abs(objectives[:, 0] - objectives[:, 1]))\n    base_solution = archive[knee_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Compute adaptive trade-off momentum\n    tradeoff_momentum = 0.5 + 0.4 * np.std(objectives[:, 0] - objectives[:, 1]) / np.mean(objectives)\n\n    # Step 3: Hybrid local search with marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    weighted_marginal = tradeoff_momentum * marginal1 + (1 - tradeoff_momentum) * marginal2\n\n    # Phase 1: Add promising items\n    candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n    if len(candidate_indices) > 0:\n        top_items = np.argsort(weighted_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n        for idx in candidate_indices[top_items]:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 2: Remove low-value items\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = weighted_marginal[in_items] * (1 + 0.2 * np.abs(value1_lst[in_items] - value2_lst[in_items]))\n        bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 4: Adaptive perturbation\n    perturbation_prob = 0.2 + 0.3 * (1 - tradeoff_momentum)\n    if random.random() < perturbation_prob:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 5: Feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        combined_marginal = marginal1[in_items] + marginal2[in_items]\n        worst_item = in_items[np.argmin(combined_marginal)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThis algorithm combines adaptive Pareto-dominance-aware selection with dynamic trade-off-aware marginal flips, prioritizing knee solutions (high dominance) while balancing exploration (perturbations) and exploitation (marginal contributions). It uses a weighted combination of objective scores (70%) and dominance scores (30%) to select promising solutions, then applies a hybrid local search that adds high-marginal items and removes low-value items, with dynamic perturbation probabilities based on trade-off momentum. The method ensures feasibility through a greedy repair mechanism, making it effective for multi-objective knapsack problems.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Adaptive Pareto-dominance-aware selection\n    objective_scores = [obj[0] + obj[1] for _, obj in archive]\n    dominance_scores = []\n    for i, (_, obj) in enumerate(archive):\n        dominance = sum(1 for _, o in archive if (o[0] > obj[0] and o[1] >= obj[1]) or (o[0] >= obj[0] and o[1] > obj[1]))\n        dominance_scores.append(dominance)\n\n    # Combine objective and dominance scores (70% objective, 30% dominance)\n    combined_scores = [0.7 * objective_scores[i] + 0.3 * dominance_scores[i] for i in range(len(archive))]\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Initialize new solution\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Calculate dynamic marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n\n    # Step 4: Determine trade-off momentum (higher for knee solutions)\n    tradeoff_momentum = 0.5\n    if len(archive) > 1:\n        max_dominance = max(dominance_scores)\n        tradeoff_momentum = 0.5 + 0.4 * (dominance_scores[selected_idx] / max(1, max_dominance))\n\n    # Step 5: Hybrid local search\n    # Phase 1: Add promising items (weighted by trade-off momentum)\n    candidate_indices = np.where((new_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) > 0:\n        weighted_marginal = tradeoff_momentum * marginal1 + (1 - tradeoff_momentum) * marginal2\n        top_items = np.argsort(weighted_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n        for idx in candidate_indices[top_items]:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Remove low-value items\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = (1 - tradeoff_momentum) * marginal1[in_items] + tradeoff_momentum * marginal2[in_items]\n        bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 6: Dynamic perturbation (higher for knee solutions)\n    perturbation_prob = 0.2 + 0.6 * (1 - tradeoff_momentum)\n    if random.random() < perturbation_prob:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 7: Feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        combined_marginal = marginal1[in_items] + marginal2[in_items]\n        worst_item = in_items[np.argmin(combined_marginal)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm combines multi-objective clustering with a hybrid local search that prioritizes solutions from underrepresented clusters, uses trade-off-aware marginal contributions to guide item additions/removals, and employs adaptive perturbations and feasibility enforcement to maintain solution quality and diversity. It dynamically balances exploration and exploitation by adjusting perturbation intensity based on cluster trade-offs, while always ensuring feasibility through marginal contribution-based removals. The key variables are weighted by cluster-specific trade-offs, and the algorithm alternates between adding high-marginal items and removing low-marginal ones to improve both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Cluster solutions based on objective trade-offs\n    objectives = np.array([obj for _, obj in archive])\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-6)\n    cluster_centers = np.array([[0.2, 0.8], [0.5, 0.5], [0.8, 0.2]])\n    distances = np.linalg.norm(normalized[:, None] - cluster_centers, axis=2)\n    cluster_assignments = np.argmin(distances, axis=1)\n\n    # Step 2: Select from the least represented cluster\n    cluster_counts = np.bincount(cluster_assignments, minlength=3)\n    selected_cluster = np.argmin(cluster_counts)\n    cluster_indices = np.where(cluster_assignments == selected_cluster)[0]\n    selected_idx = np.random.choice(cluster_indices)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 3: Calculate trade-off-aware marginal contributions\n    tradeoff = cluster_centers[selected_cluster][0]  # Use cluster center's first objective weight\n    marginal = (tradeoff * value1_lst + (1 - tradeoff) * value2_lst) / (weight_lst + 1e-6)\n\n    # Step 4: Hybrid neighborhood expansion\n    # Phase 1: Add items with high marginal contributions\n    candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n    if len(candidate_indices) > 0:\n        top_items = np.argsort(marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n        for idx in candidate_indices[top_items]:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 2: Remove items with low marginal contributions\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = marginal[in_items]\n        bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 5: Adaptive trade-off perturbations\n    perturbation_prob = 0.3 + 0.2 * (1 - tradeoff)\n    if random.random() < perturbation_prob:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 6: Feasibility enforcement with adaptive weight balancing\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        combined_marginal = marginal[in_items]\n        worst_item = in_items[np.argmin(combined_marginal)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive (prioritizing those with high item density and near-capacity weight) and applies a hybrid local search by flipping items with the highest marginal contributions (balancing both objectives) while ensuring feasibility through a final weight-checking step. It intelligently flips a subset of items based on their combined value-to-weight ratio, with a fallback to remove heaviest items if needed.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_solution = max(archive, key=lambda x: sum(x[0]) * (1 - (sum(weight_lst[x[0] == 1]) / capacity)) if sum(weight_lst[x[0] == 1]) <= capacity else -np.inf)[0].copy()\n\n    # Apply a hybrid local search operator: flip a subset of items based on their marginal contributions\n    new_solution = selected_solution.copy()\n    marginal_contributions = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(marginal_contributions)[::-1]\n\n    # Flip the top-k items with the highest marginal contributions\n    k = max(1, len(new_solution) // 10)\n    for idx in sorted_indices[:k]:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            if sum(weight_lst[new_solution == 1]) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Ensure feasibility (redundant but safe)\n    total_weight = sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # If infeasible, flip the heaviest items until feasible\n        sorted_heavy = np.argsort(weight_lst[new_solution == 1])[::-1]\n        for idx in sorted_heavy:\n            if total_weight <= capacity:\n                break\n            new_solution[idx] = 0\n            total_weight -= weight_lst[idx]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: *Adaptive trade-off momentum, hybrid local search, feasibility-aware perturbations, diversity-aware selection*\n- **Advice**: Combine marginal contribution analysis with dynamic trade-off momentum (e.g., prioritize knee solutions), use hybrid local search with adaptive perturbations, and enforce feasibility via adaptive removal.\n- **Avoid**: Static weights, rigid selection, single-objective focus, and blind perturbations. Avoid over-reliance on dominance counts.\n- **Explanation**: A hybrid strategy balances exploration and exploitation, ensuring diverse, high-quality neighbors while maintaining feasibility. Dynamic trade-off momentum improves Pareto front diversity. *(99 words)*\n\n**Final Answer**:\n```python\ndef select_neighbor(archive, weights, capacity, item_weights, item_values1, item_values2):\n    # Step 1: Diversity-aware selection\n    selected_idx = choices(range(len(archive)), weights=weights)[0]\n    solution = archive[selected_idx].copy()\n    current_weight = sum(solution * item_weights)\n\n    # Step 2: Hybrid local search (marginal flips + adaptive perturbations)\n    for _ in range(10):\n        # Exploitation: Marginal contribution flips\n        marginals = np.zeros(len(solution))\n        for i in range(len(solution)):\n            if solution[i] == 0:\n                marginals[i] = (item_values1[i] + item_values2[i]) / item_weights[i]\n            else:\n                marginals[i] = - (item_values1[i] + item_values2[i]) / item_weights[i]\n        candidate = np.argsort(marginals)[-5:]  # Top 5 candidates\n\n        # Adaptive trade-off momentum\n        if random() < 0.7:  # Exploitation bias\n            i = choices(candidate)[0]\n            if solution[i] == 0 and current_weight + item_weights[i] <= capacity:\n                solution[i] = 1\n            elif solution[i] == 1:\n                solution[i] = 0\n        else:  # Exploration via random perturbation\n            i = np.random.randint(len(solution))\n            if solution[i] == 0 and current_weight + item_weights[i] <= capacity:\n                solution[i] = 1\n            elif solution[i] == 1:\n                solution[i] = 0\n\n    # Step 3: Feasibility check\n    while current_weight > capacity:\n        heavy_items = np.where(solution == 1)[0]\n        worst_item = min(heavy_items, key=lambda x: (item_values1[x] + item_values2[x]) / item_weights[x])\n        solution[worst_item] = 0\n        current_weight -= item_weights[worst_item]\n\n    return solution\n```\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 308,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Adaptive trade-off momentum and knee solution selection\n    objectives = np.array([obj for _, obj in archive])\n    knee_idx = np.argmin(np.abs(objectives[:, 0] - objectives[:, 1]))\n    base_solution = archive[knee_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Calculate trade-off momentum based on objective diversity\n    tradeoff_momentum = 0.5 + 0.4 * np.std(objectives[:, 0] - objectives[:, 1]) / (np.mean(objectives) + 1e-6)\n\n    # Step 2: Cluster-based selection enhancement\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-6)\n    cluster_centers = np.array([[0.2, 0.8], [0.5, 0.5], [0.8, 0.2]])\n    distances = np.linalg.norm(normalized[:, None] - cluster_centers, axis=2)\n    cluster_assignments = np.argmin(distances, axis=1)\n    cluster_counts = np.bincount(cluster_assignments, minlength=3)\n    selected_cluster = np.argmin(cluster_counts)\n    cluster_indices = np.where(cluster_assignments == selected_cluster)[0]\n    if len(cluster_indices) > 0:\n        cluster_idx = np.random.choice(cluster_indices)\n        cluster_tradeoff = cluster_centers[selected_cluster][0]\n        tradeoff_momentum = 0.7 * tradeoff_momentum + 0.3 * cluster_tradeoff\n\n    # Step 3: Hybrid local search with adaptive marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    weighted_marginal = tradeoff_momentum * marginal1 + (1 - tradeoff_momentum) * marginal2\n\n    # Phase 1: Add high-marginal items\n    candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n    if len(candidate_indices) > 0:\n        top_items = np.argsort(weighted_marginal[candidate_indices])[-min(5, len(candidate_indices)):]\n        for idx in candidate_indices[top_items]:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 2: Remove low-marginal items\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = weighted_marginal[in_items] * (1 + 0.3 * np.abs(value1_lst[in_items] - value2_lst[in_items]))\n        bottom_items = np.argsort(removal_scores)[:min(3, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 4: Adaptive perturbation with cluster-aware intensity\n    perturbation_prob = 0.2 + 0.5 * (1 - tradeoff_momentum)\n    if random.random() < perturbation_prob:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 5: Multi-objective feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        combined_marginal = marginal1[in_items] + marginal2[in_items]\n        worst_item = in_items[np.argmin(combined_marginal)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    # Step 6: Final neighborhood enhancement with density-based flips\n    density = np.sum(new_solution) / len(new_solution)\n    if random.random() < 0.3 * density:\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            if current_weight - weight_lst[flip_idx] >= 0:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9085131500733497,
            0.33834153413772583
        ],
        "raw_score": [
            27.18273890155102,
            27.796199303205192
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Adaptive trade-off momentum and knee solution selection\n    objectives = np.array([obj for _, obj in archive])\n    knee_idx = np.argmin(np.abs(objectives[:, 0] - objectives[:, 1]))\n    base_solution = archive[knee_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Calculate trade-off momentum based on objective diversity\n    tradeoff_momentum = 0.5 + 0.4 * np.std(objectives[:, 0] - objectives[:, 1]) / (np.mean(objectives) + 1e-6)\n\n    # Step 2: Cluster-based selection enhancement\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-6)\n    cluster_centers = np.array([[0.2, 0.8], [0.5, 0.5], [0.8, 0.2]])\n    distances = np.linalg.norm(normalized[:, None] - cluster_centers, axis=2)\n    cluster_assignments = np.argmin(distances, axis=1)\n    cluster_counts = np.bincount(cluster_assignments, minlength=3)\n    selected_cluster = np.argmin(cluster_counts)\n    cluster_indices = np.where(cluster_assignments == selected_cluster)[0]\n    if len(cluster_indices) > 0:\n        cluster_idx = np.random.choice(cluster_indices)\n        cluster_tradeoff = cluster_centers[selected_cluster][0]\n        tradeoff_momentum = 0.7 * tradeoff_momentum + 0.3 * cluster_tradeoff\n\n    # Step 3: Hybrid local search with adaptive marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    weighted_marginal = tradeoff_momentum * marginal1 + (1 - tradeoff_momentum) * marginal2\n\n    # Phase 1: Add high-marginal items\n    candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n    if len(candidate_indices) > 0:\n        top_items = np.argsort(weighted_marginal[candidate_indices])[-min(5, len(candidate_indices)):]\n        for idx in candidate_indices[top_items]:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 2: Remove low-marginal items\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = weighted_marginal[in_items] * (1 + 0.3 * np.abs(value1_lst[in_items] - value2_lst[in_items]))\n        bottom_items = np.argsort(removal_scores)[:min(3, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 4: Adaptive perturbation with cluster-aware intensity\n    perturbation_prob = 0.2 + 0.5 * (1 - tradeoff_momentum)\n    if random.random() < perturbation_prob:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 5: Multi-objective feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        combined_marginal = marginal1[in_items] + marginal2[in_items]\n        worst_item = in_items[np.argmin(combined_marginal)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    # Step 6: Final neighborhood enhancement with density-based flips\n    density = np.sum(new_solution) / len(new_solution)\n    if random.random() < 0.3 * density:\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            if current_weight - weight_lst[flip_idx] >= 0:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 5 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution using a weighted random choice\n    weights = [obj[0] + obj[1] for (sol, obj) in archive]\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Calculate marginal contributions for both objectives\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = marginal1 + marginal2\n\n    # Step 4: Identify candidate items to flip\n    candidate_indices = np.where((base_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) == 0:\n        # If no items can be added, try removing low-value items\n        candidate_indices = np.where(base_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            return base_solution  # No change possible\n\n    # Step 5: Select top-k items based on combined marginal contributions\n    k = max(1, min(5, len(candidate_indices) // 2))\n    top_indices = np.argsort(combined_marginal[candidate_indices])[-k:][::-1]\n\n    # Step 6: Create new solution by flipping selected items\n    new_solution = base_solution.copy()\n    for idx in candidate_indices[top_indices]:\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 7: Dynamic weight adjustment phase\n    while current_weight > capacity:\n        # Identify items to remove based on least combined marginal value\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive with a weighted random choice prioritizing solutions with higher combined objective values (70% weight for value1, 30% for value2), then employs a dynamic flipping strategy that considers both addition and removal of items based on their normalized marginal contributions (60% weight for value1, 40% for value2), while ensuring feasibility through capacity-aware adjustments and occasional random perturbations to escape local optima.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution using a weighted random choice\n    weights = [obj[0] * 0.7 + obj[1] * 0.3 for (sol, obj) in archive]\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Calculate normalized marginal contributions for both objectives\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = 0.6 * marginal1 + 0.4 * marginal2\n\n    # Step 4: Identify candidate items to flip\n    candidate_indices = np.where((base_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) == 0:\n        candidate_indices = np.where(base_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            return base_solution\n\n    # Step 5: Select top items based on combined marginal contributions\n    k = max(1, min(3, len(candidate_indices) // 3))\n    top_indices = np.argsort(combined_marginal[candidate_indices])[-k:][::-1]\n\n    # Step 6: Create new solution by flipping selected items\n    new_solution = base_solution.copy()\n    for idx in candidate_indices[top_indices]:\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 7: Adaptive adjustment phase\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    # Step 8: Random perturbation to escape local optima\n    if random.random() < 0.3:\n        perturb_idx = np.random.choice(np.where(base_solution != new_solution)[0])\n        new_solution[perturb_idx] = 1 - new_solution[perturb_idx]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive trade-off-aware selection with hybrid local search, dynamically balancing marginal contribution flips and feasibility-aware perturbations to prioritize high-value items while maintaining Pareto front diversity, with higher weight given to objective scores (60%) compared to dominance (40%) in selection. The hybrid local search alternates between adding promising items (weighted by trade-off momentum) and removing low-value items, while occasional dynamic perturbations introduce diversity. Feasibility is strictly enforced by removing the least valuable items when capacity is exceeded.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Adaptive trade-off-aware selection\n    objective_scores = [obj[0] + obj[1] for _, obj in archive]\n    dominance_scores = []\n    for _, obj in archive:\n        dominance = sum(1 for _, o in archive if (o[0] > obj[0] and o[1] >= obj[1]) or (o[0] >= obj[0] and o[1] > obj[1]))\n        dominance_scores.append(dominance)\n    combined_scores = [objective_scores[i] * 0.6 + dominance_scores[i] * 0.4 for i in range(len(archive))]\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 2: Calculate dynamic marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n\n    # Step 3: Determine trade-off momentum\n    tradeoff_momentum = 0.5\n    if len(archive) > 1:\n        tradeoff_momentum = 0.5 + 0.3 * (dominance_scores[selected_idx] / max(1, max(dominance_scores)))\n\n    # Step 4: Hybrid local search\n    # Phase 1: Add promising items\n    candidate_indices = np.where((new_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) > 0:\n        weighted_marginal = tradeoff_momentum * marginal1 + (1 - tradeoff_momentum) * marginal2\n        top_items = np.argsort(weighted_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n        for idx in candidate_indices[top_items]:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Remove low-value items\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = (1 - tradeoff_momentum) * marginal1[in_items] + tradeoff_momentum * marginal2[in_items]\n        bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 5: Dynamic perturbation\n    perturbation_prob = 0.2 + 0.3 * (1 - tradeoff_momentum)\n    if random.random() < perturbation_prob:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 6: Feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        combined_marginal = marginal1[in_items] + marginal2[in_items]\n        worst_item = in_items[np.argmin(combined_marginal)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm implements a hybrid local search strategy that combines dominance-based selection with adaptive perturbation, using a trade-off-aware marginal contribution metric to guide item additions and removals, prioritizing solutions with high dominance counts while dynamically balancing exploration of high-value items and preservation of solution quality through dominance-ranked removals. The method alternates between adding items with high combined marginal contributions and those with high trade-off diversity, followed by adaptive removal based on dominance and marginal scores, ensuring feasibility through a final enforcement step.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Identify non-dominated solutions and compute dominance metrics\n    objectives = np.array([obj for _, obj in archive])\n    dominance_counts = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j and (objectives[j, 0] >= objectives[i, 0] and objectives[j, 1] >= objectives[i, 1] and\n                          (objectives[j, 0] > objectives[i, 0] or objectives[j, 1] > objectives[i, 1])):\n                dominance_counts[i] += 1\n\n    # Select solution with highest dominance count (most dominated)\n    selected_idx = np.argmax(dominance_counts)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Compute adaptive marginal contributions\n    dominance_rank = np.sum((objectives >= objectives[selected_idx]) & (objectives != objectives[selected_idx]), axis=1)\n    rank_weight = 1 / (dominance_rank + 1)\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = (rank_weight[selected_idx] * marginal1 + (1 - rank_weight[selected_idx]) * marginal2) * (1 + 0.1 * np.abs(value1_lst - value2_lst))\n\n    # Step 3: Objective-aware perturbation with trade-off diversity\n    if random.random() < 0.5:\n        # Phase 1: Add items with high combined marginal\n        candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n        if len(candidate_indices) > 0:\n            top_items = np.argsort(combined_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n            for idx in candidate_indices[top_items]:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n    else:\n        # Phase 2: Add items with high trade-off diversity\n        tradeoff_diversity = np.abs(value1_lst - value2_lst)\n        candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n        if len(candidate_indices) > 0:\n            top_items = np.argsort(tradeoff_diversity[candidate_indices])[-min(2, len(candidate_indices)):]\n            for idx in candidate_indices[top_items]:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 4: Adaptive removal based on dominance and marginal\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = combined_marginal[in_items] * (1 + 0.2 * dominance_rank[selected_idx])\n        bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 5: Feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        removal_scores = combined_marginal[in_items] * (1 + 0.1 * dominance_counts[selected_idx])\n        worst_item = in_items[np.argmin(removal_scores)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThis algorithm implements a hybrid local search strategy that first selects a knee-point solution from the archive, then uses adaptive trade-off momentum to guide item additions and removals through dynamic marginal contribution analysis, with feasibility-aware perturbations to maintain diversity while ensuring capacity constraints are satisfied. The method alternates between exploitation (adding high-margin items) and exploration (removing low-margin items), and occasionally applies random flips to escape local optima, with final feasibility enforcement to guarantee valid solutions.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Knee-point selection with adaptive trade-off momentum\n    objectives = np.array([obj for _, obj in archive])\n    ideal = np.max(objectives, axis=0)\n    anti_ideal = np.min(objectives, axis=0)\n    distances = np.linalg.norm((objectives - anti_ideal) / (ideal - anti_ideal + 1e-6), axis=1)\n    selected_idx = np.argmin(distances)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Dynamic marginal contribution with trade-off momentum\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    tradeoff_momentum = 0.5 + 0.3 * (objectives[selected_idx, 0] - objectives[selected_idx, 1]) / (ideal[0] - ideal[1] + 1e-6)\n    combined_marginal = tradeoff_momentum * marginal1 + (1 - tradeoff_momentum) * marginal2\n\n    # Step 3: Hybrid local search with adaptive perturbations\n    for phase in range(2):\n        if phase == 0:  # Exploitation phase\n            # Add promising items\n            candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n            if len(candidate_indices) > 0:\n                top_items = np.argsort(combined_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n                for idx in candidate_indices[top_items]:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n        else:  # Exploration phase\n            # Remove low-value items\n            in_items = np.where(new_solution == 1)[0]\n            if len(in_items) > 0:\n                removal_scores = combined_marginal[in_items] * (1 + 0.1 * np.random.random())\n                bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n                for idx in in_items[bottom_items]:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n\n    # Step 4: Adaptive perturbation\n    if random.random() < 0.4:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 5: Feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s the refined heuristic design framework (100 words):\n\n- **Keywords**: *Adaptive trade-off momentum, hybrid local search, feasibility-aware perturbations, diversity-aware selection*\n- **Advice**: Combine marginal contribution analysis with dynamic trade-off momentum (e.g., prioritize knee solutions), use hybrid local search with adaptive perturbations, and enforce feasibility via adaptive removal.\n- **Avoid**: Static weights, rigid selection, single-objective focus, and blind perturbations. Avoid over-reliance on dominance counts.\n- **Explanation**: A hybrid strategy balances exploration and exploitation, ensuring diverse, high-quality neighbors while maintaining feasibility. Dynamic trade-off momentum improves Pareto front diversity.\n\n**Step-by-step reasoning**:\n1. **Diversity-aware selection**: Dynamically adjust weights based on Pareto dominance and marginal gains (e.g., prioritize knee solutions).\n2. **Hybrid local search**: Combine marginal flips (exploitation) with adaptive perturbations (exploration) using trade-off momentum.\n3. **Adaptive trade-off momentum**: Scale perturbations based on local optima and objective trade-offs (e.g., higher when stuck).\n4. **Feasibility checks**: Enforce feasibility via adaptive removal of over-weighted items, ensuring robust neighbor generation.\n\nThis ensures high-quality, diverse neighbors while maintaining feasibility.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 309,
        "algorithm": "This algorithm implements a hybrid local search strategy that combines knee-point selection with adaptive trade-off momentum to prioritize solutions near the Pareto front, followed by dynamic marginal contribution analysis to guide item additions and removals, and finally adaptive perturbations to maintain diversity while ensuring feasibility. The method alternates between exploitation (adding high-marginal items) and exploration (removing low-marginal items) phases, with a probabilistic flip operation to escape local optima, and always enforces capacity constraints by removing the least valuable items when needed.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Knee-point selection with adaptive trade-off momentum\n    objectives = np.array([obj for _, obj in archive])\n    ideal = np.max(objectives, axis=0)\n    anti_ideal = np.min(objectives, axis=0)\n    distances = np.linalg.norm((objectives - anti_ideal) / (ideal - anti_ideal + 1e-6), axis=1)\n    selected_idx = np.argmin(distances)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Dynamic marginal contribution with trade-off momentum\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    tradeoff_momentum = 0.5 + 0.3 * (objectives[selected_idx, 0] - objectives[selected_idx, 1]) / (ideal[0] - ideal[1] + 1e-6)\n    combined_marginal = tradeoff_momentum * marginal1 + (1 - tradeoff_momentum) * marginal2\n\n    # Step 3: Hybrid local search with adaptive perturbations\n    for phase in range(2):\n        if phase == 0:  # Exploitation phase\n            # Add promising items\n            candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n            if len(candidate_indices) > 0:\n                top_items = np.argsort(combined_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n                for idx in candidate_indices[top_items]:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n        else:  # Exploration phase\n            # Remove low-value items\n            in_items = np.where(new_solution == 1)[0]\n            if len(in_items) > 0:\n                removal_scores = combined_marginal[in_items] * (1 + 0.1 * np.random.random())\n                bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n                for idx in in_items[bottom_items]:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n\n    # Step 4: Adaptive perturbation\n    if random.random() < 0.4:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 5: Feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8896590379542146,
            0.22669869661331177
        ],
        "raw_score": [
            27.365585598547362,
            27.966143764137858
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Knee-point selection with adaptive trade-off momentum\n    objectives = np.array([obj for _, obj in archive])\n    ideal = np.max(objectives, axis=0)\n    anti_ideal = np.min(objectives, axis=0)\n    distances = np.linalg.norm((objectives - anti_ideal) / (ideal - anti_ideal + 1e-6), axis=1)\n    selected_idx = np.argmin(distances)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Dynamic marginal contribution with trade-off momentum\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    tradeoff_momentum = 0.5 + 0.3 * (objectives[selected_idx, 0] - objectives[selected_idx, 1]) / (ideal[0] - ideal[1] + 1e-6)\n    combined_marginal = tradeoff_momentum * marginal1 + (1 - tradeoff_momentum) * marginal2\n\n    # Step 3: Hybrid local search with adaptive perturbations\n    for phase in range(2):\n        if phase == 0:  # Exploitation phase\n            # Add promising items\n            candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n            if len(candidate_indices) > 0:\n                top_items = np.argsort(combined_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n                for idx in candidate_indices[top_items]:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n        else:  # Exploration phase\n            # Remove low-value items\n            in_items = np.where(new_solution == 1)[0]\n            if len(in_items) > 0:\n                removal_scores = combined_marginal[in_items] * (1 + 0.1 * np.random.random())\n                bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n                for idx in in_items[bottom_items]:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n\n    # Step 4: Adaptive perturbation\n    if random.random() < 0.4:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 5: Feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "operation": "elitist"
    }
]