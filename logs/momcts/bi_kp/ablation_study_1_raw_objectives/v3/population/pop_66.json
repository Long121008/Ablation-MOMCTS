[
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution using a weighted random choice\n    weights = [obj[0] + obj[1] for (sol, obj) in archive]\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Calculate marginal contributions for both objectives\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = marginal1 + marginal2\n\n    # Step 4: Identify candidate items to flip\n    candidate_indices = np.where((base_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) == 0:\n        # If no items can be added, try removing low-value items\n        candidate_indices = np.where(base_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            return base_solution  # No change possible\n\n    # Step 5: Select top-k items based on combined marginal contributions\n    k = max(1, min(5, len(candidate_indices) // 2))\n    top_indices = np.argsort(combined_marginal[candidate_indices])[-k:][::-1]\n\n    # Step 6: Create new solution by flipping selected items\n    new_solution = base_solution.copy()\n    for idx in candidate_indices[top_indices]:\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 7: Dynamic weight adjustment phase\n    while current_weight > capacity:\n        # Identify items to remove based on least combined marginal value\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8379839795366024,
            0.18839186429977417
        ],
        "raw_score": [
            27.127153134971913,
            27.930397004202053
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive with a weighted random choice prioritizing solutions with higher combined objective values (70% weight for value1, 30% for value2), then employs a dynamic flipping strategy that considers both addition and removal of items based on their normalized marginal contributions (60% weight for value1, 40% for value2), while ensuring feasibility through capacity-aware adjustments and occasional random perturbations to escape local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution using a weighted random choice\n    weights = [obj[0] * 0.7 + obj[1] * 0.3 for (sol, obj) in archive]\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Calculate normalized marginal contributions for both objectives\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = 0.6 * marginal1 + 0.4 * marginal2\n\n    # Step 4: Identify candidate items to flip\n    candidate_indices = np.where((base_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) == 0:\n        candidate_indices = np.where(base_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            return base_solution\n\n    # Step 5: Select top items based on combined marginal contributions\n    k = max(1, min(3, len(candidate_indices) // 3))\n    top_indices = np.argsort(combined_marginal[candidate_indices])[-k:][::-1]\n\n    # Step 6: Create new solution by flipping selected items\n    new_solution = base_solution.copy()\n    for idx in candidate_indices[top_indices]:\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 7: Adaptive adjustment phase\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    # Step 8: Random perturbation to escape local optima\n    if random.random() < 0.3:\n        perturb_idx = np.random.choice(np.where(base_solution != new_solution)[0])\n        new_solution[perturb_idx] = 1 - new_solution[perturb_idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9067608502595553,
            0.1949823498725891
        ],
        "raw_score": [
            27.17264943660627,
            27.61900648416579
        ]
    },
    {
        "algorithm": "The algorithm combines adaptive trade-off-aware selection with hybrid local search, dynamically balancing marginal contribution flips and feasibility-aware perturbations to prioritize high-value items while maintaining Pareto front diversity, with higher weight given to objective scores (60%) compared to dominance (40%) in selection. The hybrid local search alternates between adding promising items (weighted by trade-off momentum) and removing low-value items, while occasional dynamic perturbations introduce diversity. Feasibility is strictly enforced by removing the least valuable items when capacity is exceeded.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Adaptive trade-off-aware selection\n    objective_scores = [obj[0] + obj[1] for _, obj in archive]\n    dominance_scores = []\n    for _, obj in archive:\n        dominance = sum(1 for _, o in archive if (o[0] > obj[0] and o[1] >= obj[1]) or (o[0] >= obj[0] and o[1] > obj[1]))\n        dominance_scores.append(dominance)\n    combined_scores = [objective_scores[i] * 0.6 + dominance_scores[i] * 0.4 for i in range(len(archive))]\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 2: Calculate dynamic marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n\n    # Step 3: Determine trade-off momentum\n    tradeoff_momentum = 0.5\n    if len(archive) > 1:\n        tradeoff_momentum = 0.5 + 0.3 * (dominance_scores[selected_idx] / max(1, max(dominance_scores)))\n\n    # Step 4: Hybrid local search\n    # Phase 1: Add promising items\n    candidate_indices = np.where((new_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) > 0:\n        weighted_marginal = tradeoff_momentum * marginal1 + (1 - tradeoff_momentum) * marginal2\n        top_items = np.argsort(weighted_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n        for idx in candidate_indices[top_items]:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Remove low-value items\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = (1 - tradeoff_momentum) * marginal1[in_items] + tradeoff_momentum * marginal2[in_items]\n        bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 5: Dynamic perturbation\n    perturbation_prob = 0.2 + 0.3 * (1 - tradeoff_momentum)\n    if random.random() < perturbation_prob:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 6: Feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        combined_marginal = marginal1[in_items] + marginal2[in_items]\n        worst_item = in_items[np.argmin(combined_marginal)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -1.0045928222599145,
            0.33167794346809387
        ],
        "raw_score": [
            27.445732010766882,
            27.815016452349727
        ]
    },
    {
        "algorithm": "The algorithm implements a hybrid local search strategy that combines dominance-based selection with adaptive perturbation, using a trade-off-aware marginal contribution metric to guide item additions and removals, prioritizing solutions with high dominance counts while dynamically balancing exploration of high-value items and preservation of solution quality through dominance-ranked removals. The method alternates between adding items with high combined marginal contributions and those with high trade-off diversity, followed by adaptive removal based on dominance and marginal scores, ensuring feasibility through a final enforcement step.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Identify non-dominated solutions and compute dominance metrics\n    objectives = np.array([obj for _, obj in archive])\n    dominance_counts = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j and (objectives[j, 0] >= objectives[i, 0] and objectives[j, 1] >= objectives[i, 1] and\n                          (objectives[j, 0] > objectives[i, 0] or objectives[j, 1] > objectives[i, 1])):\n                dominance_counts[i] += 1\n\n    # Select solution with highest dominance count (most dominated)\n    selected_idx = np.argmax(dominance_counts)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Compute adaptive marginal contributions\n    dominance_rank = np.sum((objectives >= objectives[selected_idx]) & (objectives != objectives[selected_idx]), axis=1)\n    rank_weight = 1 / (dominance_rank + 1)\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = (rank_weight[selected_idx] * marginal1 + (1 - rank_weight[selected_idx]) * marginal2) * (1 + 0.1 * np.abs(value1_lst - value2_lst))\n\n    # Step 3: Objective-aware perturbation with trade-off diversity\n    if random.random() < 0.5:\n        # Phase 1: Add items with high combined marginal\n        candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n        if len(candidate_indices) > 0:\n            top_items = np.argsort(combined_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n            for idx in candidate_indices[top_items]:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n    else:\n        # Phase 2: Add items with high trade-off diversity\n        tradeoff_diversity = np.abs(value1_lst - value2_lst)\n        candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n        if len(candidate_indices) > 0:\n            top_items = np.argsort(tradeoff_diversity[candidate_indices])[-min(2, len(candidate_indices)):]\n            for idx in candidate_indices[top_items]:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 4: Adaptive removal based on dominance and marginal\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = combined_marginal[in_items] * (1 + 0.2 * dominance_rank[selected_idx])\n        bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 5: Feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        removal_scores = combined_marginal[in_items] * (1 + 0.1 * dominance_counts[selected_idx])\n        worst_item = in_items[np.argmin(removal_scores)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -1.0282877411763403,
            0.7436960339546204
        ],
        "raw_score": [
            27.142858726401684,
            27.666181691841704
        ]
    },
    {
        "algorithm": "This algorithm selects a promising solution from the archive using Pareto-dominance-aware weighted selection, then applies a hybrid flip strategy that prioritizes adding high-marginal-value items and removing low-marginal-value items while dynamically adjusting perturbations based on local optima density to maintain feasibility. The method combines greedy selection with controlled randomness to explore trade-offs between objectives while ensuring solutions remain feasible.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Pareto-dominance-aware weighted selection\n    pareto_front = [sol_obj for sol_obj in archive if not any(\n        (sol_obj[1][0] < other[1][0] and sol_obj[1][1] <= other[1][1]) or\n        (sol_obj[1][0] <= other[1][0] and sol_obj[1][1] < other[1][1])\n        for other in archive\n    )]\n\n    if not pareto_front:\n        pareto_front = archive\n\n    weights = [obj[0] + obj[1] for (sol, obj) in pareto_front]\n    selected_idx = random.choices(range(len(pareto_front)), weights=weights, k=1)[0]\n    base_solution = pareto_front[selected_idx][0].copy()\n\n    # Step 2: Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Calculate adaptive marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = (marginal1 + marginal2) * (1 + 0.1 * np.random.rand(len(weight_lst)))\n\n    # Step 4: Hybrid flip strategy\n    new_solution = base_solution.copy()\n    candidate_indices = np.where((base_solution == 0) & (weight_lst <= remaining_capacity))[0]\n\n    if len(candidate_indices) > 0:\n        # Add items with high marginal value\n        top_add = np.argsort(combined_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n        for idx in candidate_indices[top_add]:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Remove items with low marginal value\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        bottom_remove = np.argsort(combined_marginal[in_items])[:min(2, len(in_items))]\n        for idx in in_items[bottom_remove]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 5: Dynamic perturbation scaling\n    perturbation_intensity = 0.1 if len(pareto_front) > 2 else 0.3\n    if random.random() < perturbation_intensity:\n        flip_candidates = np.where(base_solution != new_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # Step 6: Feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9033869833134398,
            0.27192428708076477
        ],
        "raw_score": [
            27.304415110215366,
            28.04960465379954
        ]
    },
    {
        "algorithm": "The algorithm implements a trade-off-aware local search by first selecting a solution with high trade-off diversity, then using adaptive marginal contributions and dynamic trade-off metrics to intelligently add and remove items, prioritizing items with both high marginal value and favorable trade-offs while ensuring feasibility through dominance-ranked removals. It alternates between two phases (adding items based on trade-off metrics or combined marginals) and applies adaptive removal to maintain solution quality, with a final feasibility enforcement step.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Identify solutions with high trade-off diversity\n    objectives = np.array([obj for _, obj in archive])\n    tradeoff_diversity = np.abs(objectives[:, 0] - objectives[:, 1])\n    selected_idx = np.argmax(tradeoff_diversity)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Compute adaptive trade-off-aware marginal contributions\n    dominance_rank = np.sum((objectives >= objectives[selected_idx]) & (objectives != objectives[selected_idx]), axis=1)\n    rank_weight = 1 / (dominance_rank + 1)\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    tradeoff_metric = np.abs(value1_lst - value2_lst) / (weight_lst + 1e-6)\n    combined_marginal = (rank_weight[selected_idx] * marginal1 + (1 - rank_weight[selected_idx]) * marginal2) * (1 + 0.2 * tradeoff_metric)\n\n    # Step 3: Trade-off-aware perturbation\n    if random.random() < 0.5:\n        # Phase 1: Add items with high trade-off metric\n        candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n        if len(candidate_indices) > 0:\n            top_items = np.argsort(tradeoff_metric[candidate_indices])[-min(2, len(candidate_indices)):]\n            for idx in candidate_indices[top_items]:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n    else:\n        # Phase 2: Add items with high combined marginal\n        candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n        if len(candidate_indices) > 0:\n            top_items = np.argsort(combined_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n            for idx in candidate_indices[top_items]:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 4: Adaptive removal based on trade-off and marginal\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = combined_marginal[in_items] * (1 + 0.3 * tradeoff_metric[in_items])\n        bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 5: Feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        removal_scores = tradeoff_metric[in_items] * (1 + 0.1 * dominance_rank[selected_idx])\n        worst_item = in_items[np.argmin(removal_scores)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9031850328402994,
            0.23509398102760315
        ],
        "raw_score": [
            27.35298546264498,
            27.783816859293136
        ]
    },
    {
        "algorithm": "The algorithm combines diversity-aware selection with a multi-objective evolutionary-inspired local search that dynamically balances exploitation (focusing on high-marginal-value items) and exploration (adaptive perturbations) while maintaining feasibility through capacity-aware removal. It prioritizes items with higher marginal contributions (weighted by a trade-off momentum factor) and selectively flips items based on their impact on both objectives, ensuring robust neighbor generation across diverse problem instances.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution with balanced diversity and objective values\n    diversity_scores = [np.sum(sol != archive[0][0]) for sol, _ in archive]\n    objective_scores = [obj[0] + obj[1] for _, obj in archive]\n    combined_scores = [diversity_scores[i] * 0.4 + objective_scores[i] * 0.6 for i in range(len(archive))]\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 2: Calculate Pareto-dominance-aware marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n\n    # Step 3: Determine trade-off momentum based on Pareto front characteristics\n    if len(archive) > 1:\n        pareto_front = [obj for _, obj in archive]\n        dominance_counts = [sum(1 for obj in pareto_front if (obj[0] > o[0] and obj[1] >= o[1]) or (obj[0] >= o[0] and obj[1] > o[1])) for o in pareto_front]\n        tradeoff_momentum = 0.5 + 0.3 * (dominance_counts[selected_idx] / max(1, max(dominance_counts)))\n    else:\n        tradeoff_momentum = 0.5\n\n    # Step 4: Hybrid evolutionary-inspired flip operator\n    # Phase 1: Add high-marginal-value items\n    candidate_indices = np.where((new_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) > 0:\n        weighted_marginal = tradeoff_momentum * marginal1 + (1 - tradeoff_momentum) * marginal2\n        top_items = np.argsort(weighted_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n        for idx in candidate_indices[top_items]:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Remove low-marginal-value items\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = tradeoff_momentum * marginal1[in_items] + (1 - tradeoff_momentum) * marginal2[in_items]\n        bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 5: Adaptive perturbation based on trade-off momentum\n    perturbation_prob = 0.2 + 0.3 * (1 - tradeoff_momentum)\n    if random.random() < perturbation_prob:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 6: Feasibility enforcement with capacity-aware removal\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        combined_marginal = marginal1[in_items] + marginal2[in_items]\n        worst_item = in_items[np.argmin(combined_marginal)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -1.0020446767352404,
            0.5365514159202576
        ],
        "raw_score": [
            27.5437456059957,
            27.722443407638877
        ]
    },
    {
        "algorithm": "This algorithm combines Pareto-dominance-aware selection with adaptive trade-off exploration, using dynamic marginal flips to generate high-quality neighbors while ensuring feasibility through adaptive removal and controlled perturbations. It prioritizes solutions with high combined objective scores and low dominance counts, then applies a weighted marginal contribution strategy to add/remove items, adjusting trade-offs dynamically based on dominance scores. The algorithm maintains feasibility by enforcing capacity constraints and includes probabilistic perturbations to escape local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Pareto-dominance-aware selection\n    dominance_scores = []\n    for _, obj in archive:\n        dominance = sum(1 for _, o in archive if (o[0] > obj[0] and o[1] >= obj[1]) or (o[0] >= obj[0] and o[1] > obj[1]))\n        dominance_scores.append(dominance)\n\n    # Combine objective scores and dominance for selection\n    objective_scores = [obj[0] + obj[1] for _, obj in archive]\n    combined_scores = [objective_scores[i] * 0.7 + dominance_scores[i] * 0.3 for i in range(len(archive))]\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 2: Calculate dynamic marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n\n    # Step 3: Determine trade-off momentum\n    tradeoff_momentum = 0.5\n    if len(archive) > 1:\n        tradeoff_momentum = 0.5 + 0.3 * (dominance_scores[selected_idx] / max(1, max(dominance_scores)))\n\n    # Step 4: Adaptive marginal flips\n    # Phase 1: Add promising items\n    candidate_indices = np.where((new_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) > 0:\n        weighted_marginal = tradeoff_momentum * marginal1 + (1 - tradeoff_momentum) * marginal2\n        top_items = np.argsort(weighted_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n        for idx in candidate_indices[top_items]:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Remove low-value items\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = (1 - tradeoff_momentum) * marginal1[in_items] + tradeoff_momentum * marginal2[in_items]\n        bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 5: Dynamic perturbation\n    perturbation_prob = 0.2 + 0.3 * (1 - tradeoff_momentum)\n    if random.random() < perturbation_prob:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 6: Feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        combined_marginal = marginal1[in_items] + marginal2[in_items]\n        worst_item = in_items[np.argmin(combined_marginal)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.929088927451721,
            0.3352687358856201
        ],
        "raw_score": [
            27.402483114024747,
            27.783139284632146
        ]
    },
    {
        "algorithm": "The algorithm combines Pareto-frontier-aware selection with hybrid multi-objective marginal flips and adaptive trade-off perturbations, dynamically balancing exploration and exploitation while maintaining feasibility through capacity-aware adjustments and diversity-aware perturbations. It prioritizes solutions with high combined objective scores while penalizing those with high dominance counts, then applies a weighted marginal approach to add/remove items and occasionally perturbs the trade-off momentum to escape local optima. The algorithm ensures feasibility by enforcing capacity constraints and removing low-value items when necessary.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Pareto-frontier-aware selection\n    objective_scores = [obj[0] + obj[1] for _, obj in archive]\n    dominance_scores = []\n    for _, obj in archive:\n        dominance = sum(1 for _, o in archive if (o[0] > obj[0] and o[1] >= obj[1]) or (o[0] >= obj[0] and o[1] > obj[1]))\n        dominance_scores.append(dominance)\n    combined_scores = [objective_scores[i] * 0.7 - dominance_scores[i] * 0.3 for i in range(len(archive))]\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 2: Calculate dynamic marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n\n    # Step 3: Determine trade-off momentum\n    tradeoff_momentum = 0.5\n    if len(archive) > 1:\n        tradeoff_momentum = 0.5 + 0.3 * (dominance_scores[selected_idx] / max(1, max(dominance_scores)))\n\n    # Step 4: Hybrid multi-objective marginal flips\n    # Phase 1: Add promising items\n    candidate_indices = np.where((new_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) > 0:\n        weighted_marginal = tradeoff_momentum * marginal1 + (1 - tradeoff_momentum) * marginal2\n        top_items = np.argsort(weighted_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n        for idx in candidate_indices[top_items]:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Remove low-value items\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = (1 - tradeoff_momentum) * marginal1[in_items] + tradeoff_momentum * marginal2[in_items]\n        bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 5: Adaptive trade-off perturbations\n    perturbation_prob = 0.2 + 0.3 * (1 - tradeoff_momentum)\n    if random.random() < perturbation_prob:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 6: Feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        combined_marginal = marginal1[in_items] + marginal2[in_items]\n        worst_item = in_items[np.argmin(combined_marginal)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9783751206717932,
            0.35745254158973694
        ],
        "raw_score": [
            27.30149628518629,
            27.862317571025947
        ]
    },
    {
        "algorithm": "The algorithm combines dynamic trade-off-aware selection with a hybrid local search strategy, prioritizing knee solutions in the Pareto front and using adaptive marginal contributions to guide item additions and removals while dynamically adjusting perturbations to balance exploration and exploitation. It enforces feasibility through dominance-ranked removals and scales perturbations inversely with solution quality to generate diverse, high-quality neighbors.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Identify knee solutions and select a base solution\n    objectives = np.array([obj for _, obj in archive])\n    pareto_front = []\n    for i in range(len(archive)):\n        dominated = False\n        for j in range(len(archive)):\n            if i != j and objectives[j, 0] >= objectives[i, 0] and objectives[j, 1] >= objectives[i, 1] and (objectives[j, 0] > objectives[i, 0] or objectives[j, 1] > objectives[i, 1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(i)\n\n    if not pareto_front:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        # Calculate knee points\n        knee_scores = []\n        for i in pareto_front:\n            distances = np.sum(np.abs(objectives[pareto_front] - objectives[i]), axis=1)\n            knee_scores.append(np.min(distances))\n        selected_idx = pareto_front[np.argmax(knee_scores)]\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Calculate adaptive marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    tradeoff_momentum = 0.5 + 0.4 * (objectives[selected_idx, 0] - objectives[selected_idx, 1]) / (np.max(objectives) - np.min(objectives) + 1e-6)\n\n    # Step 3: Hybrid local search with adaptive perturbations\n    # Phase 1: Add high-marginal items\n    candidate_indices = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n    if len(candidate_indices) > 0:\n        weighted_marginal = tradeoff_momentum * marginal1 + (1 - tradeoff_momentum) * marginal2\n        top_items = np.argsort(weighted_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n        for idx in candidate_indices[top_items]:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Phase 2: Remove low-contributing items\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = (1 - tradeoff_momentum) * marginal1[in_items] + tradeoff_momentum * marginal2[in_items]\n        bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 4: Adaptive perturbation based on local optima detection\n    perturbation_prob = 0.2 + 0.5 * (1 - tradeoff_momentum)\n    if random.random() < perturbation_prob:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 5: Feasibility enforcement with dominance-ranked removals\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        dominance_rank = np.sum((objectives >= objectives[selected_idx]) & (objectives != objectives[selected_idx]), axis=1)\n        removal_scores = marginal1[in_items] + marginal2[in_items] + dominance_rank[selected_idx] * 0.1\n        worst_item = in_items[np.argmin(removal_scores)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9905577356771424,
            0.4152751564979553
        ],
        "raw_score": [
            27.47571841331398,
            28.14225209862867
        ]
    }
]