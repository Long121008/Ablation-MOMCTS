[
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution using a weighted random choice\n    weights = [obj[0] + obj[1] for (sol, obj) in archive]\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Calculate marginal contributions for both objectives\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = marginal1 + marginal2\n\n    # Step 4: Identify candidate items to flip\n    candidate_indices = np.where((base_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) == 0:\n        # If no items can be added, try removing low-value items\n        candidate_indices = np.where(base_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            return base_solution  # No change possible\n\n    # Step 5: Select top-k items based on combined marginal contributions\n    k = max(1, min(5, len(candidate_indices) // 2))\n    top_indices = np.argsort(combined_marginal[candidate_indices])[-k:][::-1]\n\n    # Step 6: Create new solution by flipping selected items\n    new_solution = base_solution.copy()\n    for idx in candidate_indices[top_indices]:\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 7: Dynamic weight adjustment phase\n    while current_weight > capacity:\n        # Identify items to remove based on least combined marginal value\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8379839795366024,
            0.18839186429977417
        ],
        "raw_score": [
            27.127153134971913,
            27.930397004202053
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive with a weighted random choice prioritizing solutions with higher combined objective values (70% weight for value1, 30% for value2), then employs a dynamic flipping strategy that considers both addition and removal of items based on their normalized marginal contributions (60% weight for value1, 40% for value2), while ensuring feasibility through capacity-aware adjustments and occasional random perturbations to escape local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution using a weighted random choice\n    weights = [obj[0] * 0.7 + obj[1] * 0.3 for (sol, obj) in archive]\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Calculate normalized marginal contributions for both objectives\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = 0.6 * marginal1 + 0.4 * marginal2\n\n    # Step 4: Identify candidate items to flip\n    candidate_indices = np.where((base_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) == 0:\n        candidate_indices = np.where(base_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            return base_solution\n\n    # Step 5: Select top items based on combined marginal contributions\n    k = max(1, min(3, len(candidate_indices) // 3))\n    top_indices = np.argsort(combined_marginal[candidate_indices])[-k:][::-1]\n\n    # Step 6: Create new solution by flipping selected items\n    new_solution = base_solution.copy()\n    for idx in candidate_indices[top_indices]:\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 7: Adaptive adjustment phase\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    # Step 8: Random perturbation to escape local optima\n    if random.random() < 0.3:\n        perturb_idx = np.random.choice(np.where(base_solution != new_solution)[0])\n        new_solution[perturb_idx] = 1 - new_solution[perturb_idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9067608502595553,
            0.1949823498725891
        ],
        "raw_score": [
            27.17264943660627,
            27.61900648416579
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive (prioritizing those with high item density and near-capacity weight) and applies a hybrid local search by flipping items with the highest marginal contributions (balancing both objectives) while ensuring feasibility through a final weight-checking step. It intelligently flips a subset of items based on their combined value-to-weight ratio, with a fallback to remove heaviest items if needed.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected_solution = max(archive, key=lambda x: sum(x[0]) * (1 - (sum(weight_lst[x[0] == 1]) / capacity)) if sum(weight_lst[x[0] == 1]) <= capacity else -np.inf)[0].copy()\n\n    # Apply a hybrid local search operator: flip a subset of items based on their marginal contributions\n    new_solution = selected_solution.copy()\n    marginal_contributions = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(marginal_contributions)[::-1]\n\n    # Flip the top-k items with the highest marginal contributions\n    k = max(1, len(new_solution) // 10)\n    for idx in sorted_indices[:k]:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            if sum(weight_lst[new_solution == 1]) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Ensure feasibility (redundant but safe)\n    total_weight = sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # If infeasible, flip the heaviest items until feasible\n        sorted_heavy = np.argsort(weight_lst[new_solution == 1])[::-1]\n        for idx in sorted_heavy:\n            if total_weight <= capacity:\n                break\n            new_solution[idx] = 0\n            total_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8267687850791628,
            1.6086755692958832
        ],
        "raw_score": [
            27.502875572787605,
            28.1224251595386
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using a weighted random choice based on a combined objective score, then applies a hybrid local search strategy combining item swaps, flips, and adaptive perturbations with dynamic perturbation sizes and objective-aware selection to generate a feasible neighbor solution while exploring the solution space effectively. The strategy prioritizes value1 (70% weight) over value2 (30% weight) in selection and uses adaptive mechanisms like dynamic perturbation sizes and feasibility checks to ensure high-quality solutions across multiple objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution using a weighted random choice\n    combined_scores = [obj[0] * 0.7 + obj[1] * 0.3 for (sol, obj) in archive]  # Weighted sum of objectives\n    selected_idx = random.choices(range(len(archive)), weights=combined_scores, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Hybrid local search with novel mechanisms\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Dynamic perturbation size based on solution quality\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    max_perturb_size = min(5, n_items // 5)  # Adaptive based on problem size\n    perturb_size = random.randint(1, max_perturb_size)\n\n    # Objective-aware selection for perturbation\n    if random.random() < 0.6:  # Higher chance for value1-focused perturbation\n        candidate_indices = np.argsort(value1_lst)[-n_items//2:]  # Top 50% value1 items\n    else:\n        candidate_indices = np.argsort(value2_lst)[-n_items//2:]  # Top 50% value2 items\n\n    # Apply hybrid strategy\n    strategy = random.choice([\"swap\", \"flip\", \"perturb\", \"adaptive_flip\"])\n\n    if strategy == \"swap\":\n        # Enhanced swap with objective-aware selection\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Select items with high value ratio\n            value_ratios = (value1_lst + value2_lst) / weight_lst\n            swap_in = random.choice(in_items)\n            swap_out = random.choice(out_items)\n\n            # Check feasibility\n            new_weight = current_weight - weight_lst[swap_in] + weight_lst[swap_out]\n            if new_weight <= capacity:\n                new_solution[swap_in] = 0\n                new_solution[swap_out] = 1\n\n    elif strategy == \"flip\":\n        # Value-based flip with multiple attempts\n        for _ in range(3):  # Try multiple flips\n            flip_idx = random.choice(candidate_indices)\n            if new_solution[flip_idx] == 1:\n                new_weight = current_weight - weight_lst[flip_idx]\n                if new_weight <= capacity:\n                    new_solution[flip_idx] = 0\n                    break\n            else:\n                new_weight = current_weight + weight_lst[flip_idx]\n                if new_weight <= capacity:\n                    new_solution[flip_idx] = 1\n                    break\n\n    elif strategy == \"perturb\":\n        # Dynamic perturbation with multiple attempts\n        perturb_indices = random.sample(list(candidate_indices), min(perturb_size, len(candidate_indices)))\n        for idx in perturb_indices:\n            if new_solution[idx] == 1:\n                new_weight = current_weight - weight_lst[idx]\n                if new_weight <= capacity:\n                    new_solution[idx] = 0\n            else:\n                new_weight = current_weight + weight_lst[idx]\n                if new_weight <= capacity:\n                    new_solution[idx] = 1\n\n    elif strategy == \"adaptive_flip\":\n        # Adaptive flip based on remaining capacity\n        flip_candidates = []\n        for idx in candidate_indices:\n            if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                flip_candidates.append(idx)\n            elif new_solution[idx] == 1 and (current_weight - weight_lst[idx]) <= capacity:\n                flip_candidates.append(idx)\n\n        if flip_candidates:\n            flip_idx = random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.2619377052959229,
            0.27632978558540344
        ],
        "raw_score": [
            49.21545254802683,
            48.10415543548359
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution with high potential for improvement using a combination of randomness and quality metrics\n    quality_scores = [obj[0] * 0.7 + obj[1] * 0.3 for (sol, obj) in archive]  # Bias towards value1\n    selected_idx = random.choices(range(len(archive)), weights=quality_scores, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Calculate current state and remaining capacity\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Calculate normalized marginal contributions for both objectives\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    norm_marginal1 = (marginal1 - np.min(marginal1)) / (np.max(marginal1) - np.min(marginal1) + 1e-6)\n    norm_marginal2 = (marginal2 - np.min(marginal2)) / (np.max(marginal2) - np.min(marginal2) + 1e-6)\n    combined_marginal = 0.6 * norm_marginal1 + 0.4 * norm_marginal2  # Weighted combination\n\n    # Step 4: Identify candidate items for flip with adaptive selection pressure\n    candidate_indices = np.where((base_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) == 0:\n        candidate_indices = np.where(base_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            return base_solution\n\n    # Step 5: Select items based on combined marginal with probabilistic acceptance\n    new_solution = base_solution.copy()\n    for idx in candidate_indices:\n        if new_solution[idx] == 0:\n            if random.random() < combined_marginal[idx] * 0.8:  # Higher probability for better items\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n        else:\n            if random.random() < (1 - combined_marginal[idx]) * 0.3:  # Lower probability to remove worse items\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Step 6: Feasibility enforcement with dynamic weight adjustment\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    # Step 7: Additional diversification with random flips\n    if random.random() < 0.3:  # 30% chance for diversification\n        flip_candidates = np.where((base_solution != new_solution) & (weight_lst <= remaining_capacity))[0]\n        if len(flip_candidates) > 0:\n            flip_idx = random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.746434209281546,
            0.2783259451389313
        ],
        "raw_score": [
            27.30265413212179,
            27.813117844786174
        ]
    },
    {
        "algorithm": "The algorithm selects a diverse solution from the archive using crowding distance, then applies a hybrid local search combining item swapping based on marginal value and probabilistic addition/removal of high/low-marginal items, ensuring feasibility by removing the least valuable items if capacity is exceeded. It prioritizes items with high combined normalized marginal values (value1 + value2) for inclusion while strategically swapping or removing items to improve both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a diverse solution using crowding distance\n    distances = []\n    for i, (sol1, _) in enumerate(archive):\n        min_dist = float('inf')\n        for j, (sol2, _) in enumerate(archive):\n            if i != j:\n                dist = np.sum(np.abs(sol1 - sol2))\n                if dist < min_dist:\n                    min_dist = dist\n        distances.append(min_dist)\n    selected_idx = np.argmax(distances)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Calculate normalized marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = marginal1 + marginal2\n    normalized_marginal = (combined_marginal - np.min(combined_marginal)) / (np.max(combined_marginal) - np.min(combined_marginal) + 1e-6)\n\n    # Step 4: Identify candidate items for swap\n    in_items = np.where(base_solution == 1)[0]\n    out_items = np.where((base_solution == 0) & (weight_lst <= remaining_capacity))[0]\n\n    # Step 5: Perform item swapping based on marginal value\n    if len(in_items) > 0 and len(out_items) > 0:\n        swap_candidates = []\n        for in_idx in in_items:\n            for out_idx in out_items:\n                if (current_weight - weight_lst[in_idx] + weight_lst[out_idx]) <= capacity:\n                    gain = normalized_marginal[out_idx] - normalized_marginal[in_idx]\n                    swap_candidates.append((gain, in_idx, out_idx))\n\n        if swap_candidates:\n            swap_candidates.sort(reverse=True, key=lambda x: x[0])\n            best_gain, in_idx, out_idx = swap_candidates[0]\n            if best_gain > 0:\n                base_solution[in_idx] = 0\n                base_solution[out_idx] = 1\n\n    # Step 6: Apply probabilistic addition of high-marginal items\n    for idx in np.argsort(normalized_marginal)[::-1]:\n        if base_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            if random.random() < 0.7:  # 70% chance to add high-marginal item\n                base_solution[idx] = 1\n                current_weight += weight_lst[idx]\n        elif base_solution[idx] == 1 and random.random() < 0.3:  # 30% chance to remove low-marginal item\n            base_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 7: Ensure feasibility\n    while current_weight > capacity:\n        in_items = np.where(base_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(normalized_marginal[in_items])]\n        base_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return base_solution\n\n",
        "metric_score": [
            -0.7482636747814694,
            2.051643818616867
        ],
        "raw_score": [
            28.72048259087137,
            29.331001561033222
        ]
    },
    {
        "algorithm": "The heuristic selects a promising solution from the archive by weighting choices based on combined objective values, then applies a hybrid local search combining swaps, flips, and adaptive perturbations to explore the solution space while ensuring feasibility through strict weight constraint checks. The strategy is randomly chosen among three options, with perturbations adaptively sized for exploration, prioritizing solutions with higher combined objective values while maintaining feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution (prioritize high-value or diverse solutions)\n    selected_idx = random.choices(range(len(archive)), weights=[obj[0] + obj[1] for (sol, obj) in archive], k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Hybrid local search (swaps, flips, and adaptive perturbations)\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Randomly choose one of three local search strategies\n    strategy = random.choice([\"swap\", \"flip\", \"perturb\"])\n\n    if strategy == \"swap\":\n        # Swap two items (one in, one out)\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            swap_in = random.choice(in_items)\n            swap_out = random.choice(out_items)\n\n            # Check feasibility after swap\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            new_weight = current_weight - weight_lst[swap_in] + weight_lst[swap_out]\n\n            if new_weight <= capacity:\n                new_solution[swap_in] = 0\n                new_solution[swap_out] = 1\n\n    elif strategy == \"flip\":\n        # Flip a random item (0 to 1 or 1 to 0)\n        flip_idx = random.randint(0, n_items - 1)\n\n        if new_solution[flip_idx] == 1:\n            # Check feasibility if removing the item\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            new_weight = current_weight - weight_lst[flip_idx]\n\n            if new_weight <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            # Check feasibility if adding the item\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            new_weight = current_weight + weight_lst[flip_idx]\n\n            if new_weight <= capacity:\n                new_solution[flip_idx] = 1\n\n    elif strategy == \"perturb\":\n        # Perturb a subset of items (adaptive based on objective values)\n        perturb_size = max(1, min(5, n_items // 10))  # Adaptive size\n        perturb_indices = random.sample(range(n_items), perturb_size)\n\n        for idx in perturb_indices:\n            if new_solution[idx] == 1:\n                # Check feasibility if removing the item\n                current_weight = np.sum(weight_lst[new_solution == 1])\n                new_weight = current_weight - weight_lst[idx]\n\n                if new_weight <= capacity:\n                    new_solution[idx] = 0\n            else:\n                # Check feasibility if adding the item\n                current_weight = np.sum(weight_lst[new_solution == 1])\n                new_weight = current_weight + weight_lst[idx]\n\n                if new_weight <= capacity:\n                    new_solution[idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.34147716771420633,
            0.3407798707485199
        ],
        "raw_score": [
            49.672216305965385,
            49.76474444776558
        ]
    },
    {
        "algorithm": "The algorithm first selects a solution from the archive by prioritizing those with high combined objective values and diversity (distance from centroid), then applies a hybrid local search combining value-weighted random walks and adaptive perturbations, dynamically adjusting neighborhood size based on solution properties, while ensuring feasibility through greedy repair when capacity is exceeded. The method emphasizes balancing exploration (diversity) and exploitation (value-weighted operations) while maintaining feasibility constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a diversity-aware solution\n    objectives = np.array([obj for (sol, obj) in archive])\n    centroid = np.mean(objectives, axis=0)\n    distances = np.linalg.norm(objectives - centroid, axis=1)\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    diversity_scores = distances * combined_values\n    selected_idx = np.argmax(diversity_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Hybrid local search with adaptive perturbations\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Value-weighted random walk\n    for _ in range(5):\n        included = new_solution == 1\n        excluded = new_solution == 0\n\n        # Calculate value-weighted probabilities for flipping\n        if np.any(included):\n            remove_probs = (value1_lst[included] + value2_lst[included]) / np.sum(value1_lst[included] + value2_lst[included])\n            remove_idx = np.random.choice(np.where(included)[0], p=remove_probs)\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n        if np.any(excluded) and current_weight < capacity:\n            add_probs = (value1_lst[excluded] + value2_lst[excluded]) / np.sum(value1_lst[excluded] + value2_lst[excluded])\n            potential_adds = np.where(excluded)[0]\n            add_idx = np.random.choice(potential_adds, p=add_probs)\n            if current_weight + weight_lst[add_idx] <= capacity:\n                new_solution[add_idx] = 1\n                current_weight += weight_lst[add_idx]\n\n    # Adaptive neighborhood perturbation\n    perturbation_size = max(1, min(3, n_items // 10))\n    perturb_indices = np.random.choice(n_items, perturbation_size, replace=False)\n\n    for idx in perturb_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Greedy repair if still over capacity\n    while current_weight > capacity:\n        included = new_solution == 1\n        if not np.any(included):\n            break\n        remove_probs = (value1_lst[included] + value2_lst[included]) / np.sum(value1_lst[included] + value2_lst[included])\n        remove_idx = np.random.choice(np.where(included)[0], p=remove_probs)\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.48024596244323714,
            0.9026797115802765
        ],
        "raw_score": [
            42.44937177148621,
            41.97733846309583
        ]
    },
    {
        "algorithm": "The algorithm selects a high-value solution from the archive (weighted by the product of its objectives) and applies one of three local search strategies: adaptive swaps (prioritizing high-value item exchanges), greedy flips (maximizing combined value improvements), or neighborhood perturbations (adaptively adjusting perturbation size based on solution quality). It ensures feasibility by strictly checking weight constraints at each step. The approach balances exploration (via random strategy selection) and exploitation (via value-weighted selections) to navigate the multi-objective solution space effectively.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution (prioritize high-value solutions)\n    selected_idx = random.choices(range(len(archive)), weights=[obj[0] * obj[1] for (sol, obj) in archive], k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Hybrid local search (adaptive swaps, greedy flips, and neighborhood perturbations)\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Randomly choose one of three local search strategies\n    strategy = random.choice([\"adaptive_swap\", \"greedy_flip\", \"neighborhood_perturb\"])\n\n    if strategy == \"adaptive_swap\":\n        # Adaptive swap: prioritize high-value items\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Select high-value items to remove\n            in_values = value1_lst[in_items] * value2_lst[in_items]\n            swap_in = in_items[np.argmax(in_values)]\n\n            # Select high-value items to add\n            out_values = value1_lst[out_items] * value2_lst[out_items]\n            swap_out = out_items[np.argmax(out_values)]\n\n            # Check feasibility after swap\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            new_weight = current_weight - weight_lst[swap_in] + weight_lst[swap_out]\n\n            if new_weight <= capacity:\n                new_solution[swap_in] = 0\n                new_solution[swap_out] = 1\n\n    elif strategy == \"greedy_flip\":\n        # Greedy flip: prioritize items that improve both objectives\n        flip_candidates = []\n        current_weight = np.sum(weight_lst[new_solution == 1])\n\n        for idx in range(n_items):\n            if new_solution[idx] == 1:\n                new_weight = current_weight - weight_lst[idx]\n                if new_weight <= capacity:\n                    flip_candidates.append((idx, -1))  # -1 means remove\n            else:\n                new_weight = current_weight + weight_lst[idx]\n                if new_weight <= capacity:\n                    flip_candidates.append((idx, 1))  # 1 means add\n\n        if flip_candidates:\n            # Select flip that maximizes the product of value improvements\n            best_flip = None\n            best_score = -1\n\n            for idx, action in flip_candidates:\n                if action == 1:\n                    value1 = value1_lst[idx]\n                    value2 = value2_lst[idx]\n                else:\n                    value1 = -value1_lst[idx]\n                    value2 = -value2_lst[idx]\n\n                # Score based on combined value improvement\n                score = value1 * value2\n\n                if score > best_score:\n                    best_score = score\n                    best_flip = (idx, action)\n\n            if best_flip:\n                idx, action = best_flip\n                new_solution[idx] = 1 if action == 1 else 0\n\n    elif strategy == \"neighborhood_perturb\":\n        # Neighborhood perturbation: adaptive size based on solution quality\n        combined_value = archive[selected_idx][1][0] * archive[selected_idx][1][1]\n        perturb_size = max(1, min(10, int(n_items * 0.1 * (1 + 1/combined_value))))  # Larger perturbation for low-quality solutions\n\n        perturb_indices = random.sample(range(n_items), perturb_size)\n\n        for idx in perturb_indices:\n            if new_solution[idx] == 1:\n                # Check feasibility if removing the item\n                current_weight = np.sum(weight_lst[new_solution == 1])\n                new_weight = current_weight - weight_lst[idx]\n\n                if new_weight <= capacity:\n                    new_solution[idx] = 0\n            else:\n                # Check feasibility if adding the item\n                current_weight = np.sum(weight_lst[new_solution == 1])\n                new_weight = current_weight + weight_lst[idx]\n\n                if new_weight <= capacity:\n                    new_solution[idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.36170978658075825,
            0.38660886883735657
        ],
        "raw_score": [
            46.73448477806161,
            47.3380410115805
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using weighted random selection based on combined objective values, then applies a hybrid local search combining marginal contribution flips, adaptive perturbations, and feasibility-aware swaps, dynamically adjusting perturbation size and prioritizing items with high combined marginal value-to-weight ratios to generate a feasible neighbor solution. The strategy selection balances exploration (flip, perturb) and exploitation (swap) while ensuring feasibility through marginal contribution-based repair.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on combined objective values\n    weights = [obj[0] + obj[1] for (sol, obj) in archive]\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Step 2: Hybrid local search with adaptive components\n    # Calculate marginal contributions for both objectives\n    marginal_contributions = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(marginal_contributions)[::-1]\n\n    # Strategy selection with adaptive parameters\n    strategy = random.choices(\n        [\"flip\", \"perturb\", \"swap\"],\n        weights=[0.4, 0.3, 0.3],\n        k=1\n    )[0]\n\n    if strategy == \"flip\":\n        # Flip top-k items with highest marginal contributions\n        k = max(1, min(5, n_items // 5))\n        for idx in sorted_indices[:k]:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n            else:\n                if np.sum(weight_lst[new_solution == 1]) + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n\n    elif strategy == \"perturb\":\n        # Adaptive perturbation based on solution density\n        density = np.sum(new_solution) / n_items\n        perturb_size = max(1, min(5, int(n_items * (0.5 - 0.3 * density))))\n\n        for _ in range(perturb_size):\n            idx = random.randint(0, n_items - 1)\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n            else:\n                if np.sum(weight_lst[new_solution == 1]) + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n\n    elif strategy == \"swap\":\n        # Feasibility-aware swap between included and excluded items\n        included = np.where(new_solution == 1)[0]\n        excluded = np.where(new_solution == 0)[0]\n\n        if len(included) > 0 and len(excluded) > 0:\n            # Select item to remove (lowest marginal contribution among included)\n            remove_idx = included[np.argmin(marginal_contributions[included])]\n            # Select item to add (highest marginal contribution among excluded)\n            add_idx = excluded[np.argmax(marginal_contributions[excluded])]\n\n            # Check feasibility\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            new_weight = current_weight - weight_lst[remove_idx] + weight_lst[add_idx]\n\n            if new_weight <= capacity:\n                new_solution[remove_idx] = 0\n                new_solution[add_idx] = 1\n\n    # Final feasibility check and repair\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items with lowest marginal contributions until feasible\n        included = np.where(new_solution == 1)[0]\n        sorted_included = included[np.argsort(marginal_contributions[included])]\n\n        for idx in sorted_included:\n            if total_weight <= capacity:\n                break\n            new_solution[idx] = 0\n            total_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.3664895686882935,
            0.4963635206222534
        ],
        "raw_score": [
            53.555185276224066,
            52.91987793367716
        ]
    }
]