[
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution using a weighted random choice\n    weights = [obj[0] + obj[1] for (sol, obj) in archive]\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Calculate marginal contributions for both objectives\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = marginal1 + marginal2\n\n    # Step 4: Identify candidate items to flip\n    candidate_indices = np.where((base_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) == 0:\n        # If no items can be added, try removing low-value items\n        candidate_indices = np.where(base_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            return base_solution  # No change possible\n\n    # Step 5: Select top-k items based on combined marginal contributions\n    k = max(1, min(5, len(candidate_indices) // 2))\n    top_indices = np.argsort(combined_marginal[candidate_indices])[-k:][::-1]\n\n    # Step 6: Create new solution by flipping selected items\n    new_solution = base_solution.copy()\n    for idx in candidate_indices[top_indices]:\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 7: Dynamic weight adjustment phase\n    while current_weight > capacity:\n        # Identify items to remove based on least combined marginal value\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8379839795366024,
            0.18839186429977417
        ],
        "raw_score": [
            27.127153134971913,
            27.930397004202053
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive with a weighted random choice prioritizing solutions with higher combined objective values (70% weight for value1, 30% for value2), then employs a dynamic flipping strategy that considers both addition and removal of items based on their normalized marginal contributions (60% weight for value1, 40% for value2), while ensuring feasibility through capacity-aware adjustments and occasional random perturbations to escape local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution using a weighted random choice\n    weights = [obj[0] * 0.7 + obj[1] * 0.3 for (sol, obj) in archive]\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Calculate normalized marginal contributions for both objectives\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = 0.6 * marginal1 + 0.4 * marginal2\n\n    # Step 4: Identify candidate items to flip\n    candidate_indices = np.where((base_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) == 0:\n        candidate_indices = np.where(base_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            return base_solution\n\n    # Step 5: Select top items based on combined marginal contributions\n    k = max(1, min(3, len(candidate_indices) // 3))\n    top_indices = np.argsort(combined_marginal[candidate_indices])[-k:][::-1]\n\n    # Step 6: Create new solution by flipping selected items\n    new_solution = base_solution.copy()\n    for idx in candidate_indices[top_indices]:\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 7: Adaptive adjustment phase\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    # Step 8: Random perturbation to escape local optima\n    if random.random() < 0.3:\n        perturb_idx = np.random.choice(np.where(base_solution != new_solution)[0])\n        new_solution[perturb_idx] = 1 - new_solution[perturb_idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9067608502595553,
            0.1949823498725891
        ],
        "raw_score": [
            27.17264943660627,
            27.61900648416579
        ]
    },
    {
        "algorithm": "The algorithm combines adaptive trade-off-aware selection with hybrid local search, dynamically balancing marginal contribution flips and feasibility-aware perturbations to prioritize high-value items while maintaining Pareto front diversity, with higher weight given to objective scores (60%) compared to dominance (40%) in selection. The hybrid local search alternates between adding promising items (weighted by trade-off momentum) and removing low-value items, while occasional dynamic perturbations introduce diversity. Feasibility is strictly enforced by removing the least valuable items when capacity is exceeded.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Adaptive trade-off-aware selection\n    objective_scores = [obj[0] + obj[1] for _, obj in archive]\n    dominance_scores = []\n    for _, obj in archive:\n        dominance = sum(1 for _, o in archive if (o[0] > obj[0] and o[1] >= obj[1]) or (o[0] >= obj[0] and o[1] > obj[1]))\n        dominance_scores.append(dominance)\n    combined_scores = [objective_scores[i] * 0.6 + dominance_scores[i] * 0.4 for i in range(len(archive))]\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 2: Calculate dynamic marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n\n    # Step 3: Determine trade-off momentum\n    tradeoff_momentum = 0.5\n    if len(archive) > 1:\n        tradeoff_momentum = 0.5 + 0.3 * (dominance_scores[selected_idx] / max(1, max(dominance_scores)))\n\n    # Step 4: Hybrid local search\n    # Phase 1: Add promising items\n    candidate_indices = np.where((new_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) > 0:\n        weighted_marginal = tradeoff_momentum * marginal1 + (1 - tradeoff_momentum) * marginal2\n        top_items = np.argsort(weighted_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n        for idx in candidate_indices[top_items]:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Remove low-value items\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = (1 - tradeoff_momentum) * marginal1[in_items] + tradeoff_momentum * marginal2[in_items]\n        bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 5: Dynamic perturbation\n    perturbation_prob = 0.2 + 0.3 * (1 - tradeoff_momentum)\n    if random.random() < perturbation_prob:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 6: Feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        combined_marginal = marginal1[in_items] + marginal2[in_items]\n        worst_item = in_items[np.argmin(combined_marginal)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -1.0045928222599145,
            0.33167794346809387
        ],
        "raw_score": [
            27.445732010766882,
            27.815016452349727
        ]
    },
    {
        "algorithm": "The algorithm combines Pareto-dominance-aware selection with a dynamic marginal contribution strategy to generate feasible neighbor solutions, prioritizing non-dominated solutions and adaptively balancing trade-offs between objectives while enforcing feasibility through iterative removal and probabilistic perturbation. It dynamically adjusts the selection of items to flip based on trade-off weights and ensures feasibility through iterative removal of low-marginal items, with occasional perturbations to escape local optima. The selection of items to flip is guided by a weighted combination of marginal contributions for both objectives, with non-dominated solutions receiving higher selection weights.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Pareto-dominance-aware weighted random selection\n    pareto_weights = []\n    for (sol, obj) in archive:\n        dominated = False\n        for (_, other_obj) in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] > obj[1]) or (other_obj[0] > obj[0] and other_obj[1] >= obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_weights.append(obj[0] * 0.6 + obj[1] * 0.4)\n        else:\n            pareto_weights.append(0.1 * (obj[0] + obj[1]))\n\n    selected_idx = random.choices(range(len(archive)), weights=pareto_weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Dynamic marginal contribution calculation\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    trade_off = np.sum(value1_lst) / (np.sum(value2_lst) + 1e-6)\n    combined_marginal = (trade_off * marginal1) + ((1 - trade_off) * marginal2)\n\n    # Step 4: Identify candidate items to flip\n    candidate_indices = np.where((base_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) == 0:\n        candidate_indices = np.where(base_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            return base_solution\n\n    # Step 5: Select top-k items based on dynamic marginal contributions\n    k = max(1, min(5, len(candidate_indices) // 2))\n    top_indices = np.argsort(combined_marginal[candidate_indices])[-k:][::-1]\n\n    # Step 6: Create new solution by flipping selected items\n    new_solution = base_solution.copy()\n    for idx in candidate_indices[top_indices]:\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 7: Adaptive feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    # Step 8: Dynamic perturbation scaling\n    perturbation_prob = min(0.5, 0.1 + 0.05 * len(archive))\n    if random.random() < perturbation_prob:\n        perturb_indices = np.where(base_solution != new_solution)[0]\n        if len(perturb_indices) > 0:\n            perturb_idx = np.random.choice(perturb_indices)\n            new_solution[perturb_idx] = 1 - new_solution[perturb_idx]\n            if new_solution[perturb_idx] == 1:\n                current_weight += weight_lst[perturb_idx]\n            else:\n                current_weight -= weight_lst[perturb_idx]\n\n    # Step 9: Final feasibility check\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.772012137365541,
            0.24318775534629822
        ],
        "raw_score": [
            27.421736819659714,
            27.936880974691945
        ]
    },
    {
        "algorithm": "This algorithm selects a promising solution from the archive using Pareto-dominance-aware weighted selection, then applies a hybrid flip strategy that prioritizes adding high-marginal-value items and removing low-marginal-value items while dynamically adjusting perturbations based on local optima density to maintain feasibility. The method combines greedy selection with controlled randomness to explore trade-offs between objectives while ensuring solutions remain feasible.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Pareto-dominance-aware weighted selection\n    pareto_front = [sol_obj for sol_obj in archive if not any(\n        (sol_obj[1][0] < other[1][0] and sol_obj[1][1] <= other[1][1]) or\n        (sol_obj[1][0] <= other[1][0] and sol_obj[1][1] < other[1][1])\n        for other in archive\n    )]\n\n    if not pareto_front:\n        pareto_front = archive\n\n    weights = [obj[0] + obj[1] for (sol, obj) in pareto_front]\n    selected_idx = random.choices(range(len(pareto_front)), weights=weights, k=1)[0]\n    base_solution = pareto_front[selected_idx][0].copy()\n\n    # Step 2: Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Calculate adaptive marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = (marginal1 + marginal2) * (1 + 0.1 * np.random.rand(len(weight_lst)))\n\n    # Step 4: Hybrid flip strategy\n    new_solution = base_solution.copy()\n    candidate_indices = np.where((base_solution == 0) & (weight_lst <= remaining_capacity))[0]\n\n    if len(candidate_indices) > 0:\n        # Add items with high marginal value\n        top_add = np.argsort(combined_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n        for idx in candidate_indices[top_add]:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Remove items with low marginal value\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        bottom_remove = np.argsort(combined_marginal[in_items])[:min(2, len(in_items))]\n        for idx in in_items[bottom_remove]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 5: Dynamic perturbation scaling\n    perturbation_intensity = 0.1 if len(pareto_front) > 2 else 0.3\n    if random.random() < perturbation_intensity:\n        flip_candidates = np.where(base_solution != new_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # Step 6: Feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9033869833134398,
            0.27192428708076477
        ],
        "raw_score": [
            27.304415110215366,
            28.04960465379954
        ]
    },
    {
        "algorithm": "The algorithm combines diversity-aware selection with a multi-objective evolutionary-inspired local search that dynamically balances exploitation (focusing on high-marginal-value items) and exploration (adaptive perturbations) while maintaining feasibility through capacity-aware removal. It prioritizes items with higher marginal contributions (weighted by a trade-off momentum factor) and selectively flips items based on their impact on both objectives, ensuring robust neighbor generation across diverse problem instances.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution with balanced diversity and objective values\n    diversity_scores = [np.sum(sol != archive[0][0]) for sol, _ in archive]\n    objective_scores = [obj[0] + obj[1] for _, obj in archive]\n    combined_scores = [diversity_scores[i] * 0.4 + objective_scores[i] * 0.6 for i in range(len(archive))]\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 2: Calculate Pareto-dominance-aware marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n\n    # Step 3: Determine trade-off momentum based on Pareto front characteristics\n    if len(archive) > 1:\n        pareto_front = [obj for _, obj in archive]\n        dominance_counts = [sum(1 for obj in pareto_front if (obj[0] > o[0] and obj[1] >= o[1]) or (obj[0] >= o[0] and obj[1] > o[1])) for o in pareto_front]\n        tradeoff_momentum = 0.5 + 0.3 * (dominance_counts[selected_idx] / max(1, max(dominance_counts)))\n    else:\n        tradeoff_momentum = 0.5\n\n    # Step 4: Hybrid evolutionary-inspired flip operator\n    # Phase 1: Add high-marginal-value items\n    candidate_indices = np.where((new_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) > 0:\n        weighted_marginal = tradeoff_momentum * marginal1 + (1 - tradeoff_momentum) * marginal2\n        top_items = np.argsort(weighted_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n        for idx in candidate_indices[top_items]:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Remove low-marginal-value items\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = tradeoff_momentum * marginal1[in_items] + (1 - tradeoff_momentum) * marginal2[in_items]\n        bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 5: Adaptive perturbation based on trade-off momentum\n    perturbation_prob = 0.2 + 0.3 * (1 - tradeoff_momentum)\n    if random.random() < perturbation_prob:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 6: Feasibility enforcement with capacity-aware removal\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        combined_marginal = marginal1[in_items] + marginal2[in_items]\n        worst_item = in_items[np.argmin(combined_marginal)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -1.0020446767352404,
            0.5365514159202576
        ],
        "raw_score": [
            27.5437456059957,
            27.722443407638877
        ]
    },
    {
        "algorithm": "The algorithm combines Pareto-dominance-aware selection with adaptive hybrid local search, dynamically balancing marginal contribution flips and feasibility-aware perturbations to prioritize high-value items while maintaining Pareto front diversity, with adaptive perturbation scaling that increases when solutions become stuck in local optima. It selects a base solution from the archive based on combined objective and dominance scores, then applies a two-phase local search (adding promising items and removing low-value items) with adaptive trade-off momentum, followed by probabilistic perturbations and feasibility enforcement to ensure weight constraints are met.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Pareto-dominance-aware selection\n    objective_scores = [obj[0] + obj[1] for _, obj in archive]\n    dominance_scores = []\n    for _, obj in archive:\n        dominance = sum(1 for _, o in archive if (o[0] > obj[0] and o[1] >= obj[1]) or (o[0] >= obj[0] and o[1] > obj[1]))\n        dominance_scores.append(dominance)\n    combined_scores = [objective_scores[i] * 0.7 + dominance_scores[i] * 0.3 for i in range(len(archive))]\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 2: Calculate dynamic marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n\n    # Step 3: Determine trade-off momentum and perturbation probability\n    tradeoff_momentum = 0.5\n    if len(archive) > 1:\n        tradeoff_momentum = 0.5 + 0.4 * (dominance_scores[selected_idx] / max(1, max(dominance_scores)))\n\n    # Step 4: Hybrid local search with adaptive perturbations\n    # Phase 1: Add promising items\n    candidate_indices = np.where((new_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) > 0:\n        weighted_marginal = tradeoff_momentum * marginal1 + (1 - tradeoff_momentum) * marginal2\n        top_items = np.argsort(weighted_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n        for idx in candidate_indices[top_items]:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Remove low-value items\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = (1 - tradeoff_momentum) * marginal1[in_items] + tradeoff_momentum * marginal2[in_items]\n        bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 5: Adaptive perturbation\n    perturbation_prob = 0.2 + 0.5 * (1 - tradeoff_momentum)\n    if random.random() < perturbation_prob:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 6: Feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        combined_marginal = marginal1[in_items] + marginal2[in_items]\n        worst_item = in_items[np.argmin(combined_marginal)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9332434096628822,
            0.34574583172798157
        ],
        "raw_score": [
            27.432138311338672,
            27.84953240567269
        ]
    },
    {
        "algorithm": "The algorithm combines Pareto-frontier-aware selection with hybrid multi-objective marginal flips and adaptive trade-off perturbations, dynamically balancing exploration and exploitation while maintaining feasibility through capacity-aware adjustments and diversity-aware perturbations. It prioritizes solutions with high combined objective scores while penalizing those with high dominance counts, then applies a weighted marginal approach to add/remove items and occasionally perturbs the trade-off momentum to escape local optima. The algorithm ensures feasibility by enforcing capacity constraints and removing low-value items when necessary.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Pareto-frontier-aware selection\n    objective_scores = [obj[0] + obj[1] for _, obj in archive]\n    dominance_scores = []\n    for _, obj in archive:\n        dominance = sum(1 for _, o in archive if (o[0] > obj[0] and o[1] >= obj[1]) or (o[0] >= obj[0] and o[1] > obj[1]))\n        dominance_scores.append(dominance)\n    combined_scores = [objective_scores[i] * 0.7 - dominance_scores[i] * 0.3 for i in range(len(archive))]\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 2: Calculate dynamic marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n\n    # Step 3: Determine trade-off momentum\n    tradeoff_momentum = 0.5\n    if len(archive) > 1:\n        tradeoff_momentum = 0.5 + 0.3 * (dominance_scores[selected_idx] / max(1, max(dominance_scores)))\n\n    # Step 4: Hybrid multi-objective marginal flips\n    # Phase 1: Add promising items\n    candidate_indices = np.where((new_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) > 0:\n        weighted_marginal = tradeoff_momentum * marginal1 + (1 - tradeoff_momentum) * marginal2\n        top_items = np.argsort(weighted_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n        for idx in candidate_indices[top_items]:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Remove low-value items\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = (1 - tradeoff_momentum) * marginal1[in_items] + tradeoff_momentum * marginal2[in_items]\n        bottom_items = np.argsort(removal_scores)[:min(2, len(in_items))]\n        for idx in in_items[bottom_items]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 5: Adaptive trade-off perturbations\n    perturbation_prob = 0.2 + 0.3 * (1 - tradeoff_momentum)\n    if random.random() < perturbation_prob:\n        flip_candidates = np.where(new_solution != base_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            if new_solution[flip_idx] == 1:\n                current_weight += weight_lst[flip_idx]\n            else:\n                current_weight -= weight_lst[flip_idx]\n\n    # Step 6: Feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        combined_marginal = marginal1[in_items] + marginal2[in_items]\n        worst_item = in_items[np.argmin(combined_marginal)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9783751206717932,
            0.35745254158973694
        ],
        "raw_score": [
            27.30149628518629,
            27.862317571025947
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with high entropy (diversity), near-capacity weight utilization, and high Pareto dominance, then applies a hybrid local search that flips items based on weighted marginal contributions (balancing both objectives) while dynamically adjusting perturbation intensity and ensuring feasibility by removing low-value items if capacity is exceeded. The selection score balances entropy, weight utilization, and dominance, while the local search prioritizes high-marginal-value items and adaptively adjusts flips to avoid local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    def selection_score(sol_obj):\n        sol = sol_obj[0]\n        entropy = -np.sum(sol * np.log(sol + 1e-6) + (1 - sol) * np.log(1 - sol + 1e-6))\n        weight_util = np.sum(weight_lst[sol == 1]) / capacity\n        # Pareto dominance factor: count how many solutions this dominates\n        dominates = sum(1 for (_, (v1, v2)) in archive if (v1 <= sol_obj[1][0] and v2 <= sol_obj[1][1]) and (v1 < sol_obj[1][0] or v2 < sol_obj[1][1]))\n        return entropy * (1 - abs(weight_util - 0.9)) * (1 + dominates)\n\n    selected_solution = max(archive, key=selection_score)[0].copy()\n    new_solution = selected_solution.copy()\n\n    # Hybrid local search: flip items based on weighted marginal contributions\n    norm_value1 = value1_lst / (np.max(value1_lst) + 1e-6)\n    norm_value2 = value2_lst / (np.max(value2_lst) + 1e-6)\n    marginal_contributions = np.sqrt(norm_value1 * norm_value2) / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(marginal_contributions)[::-1]\n\n    # Dynamic perturbation: adjust number of flips based on local optima\n    k = max(1, len(new_solution) // 5)\n    for idx in sorted_indices[:k]:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            if np.sum(weight_lst[new_solution == 1]) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Feasibility check: remove items with lowest combined value-to-weight ratios if needed\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        included_indices = np.where(new_solution == 1)[0]\n        value_ratios = (value1_lst[included_indices] + value2_lst[included_indices]) / (weight_lst[included_indices] + 1e-6)\n        sorted_least_val = included_indices[np.argsort(value_ratios)]\n        for idx in sorted_least_val:\n            if total_weight <= capacity:\n                break\n            new_solution[idx] = 0\n            total_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9450169886182402,
            1.6589842736721039
        ],
        "raw_score": [
            27.461915009353113,
            27.871701693291868
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution with high combined value and low dominance using adaptive weights\n    objective_scores = [obj[0] + obj[1] for _, obj in archive]\n    dominance_scores = []\n    for _, obj in archive:\n        dominance = sum(1 for _, o in archive if (o[0] > obj[0] and o[1] >= obj[1]) or (o[0] >= obj[0] and o[1] > obj[1]))\n        dominance_scores.append(dominance)\n    combined_scores = [objective_scores[i] / (1 + dominance_scores[i]) for i in range(len(archive))]\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Calculate adaptive marginal contributions with dynamic trade-off weights\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    tradeoff_weight = 0.5 + 0.4 * (dominance_scores[selected_idx] / max(1, max(dominance_scores)))\n    combined_marginal = tradeoff_weight * marginal1 + (1 - tradeoff_weight) * marginal2\n\n    # Step 4: Hybrid local search with three phases\n    new_solution = base_solution.copy()\n\n    # Phase 1: Add high-marginal items with capacity-aware selection\n    candidate_indices = np.where((new_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) > 0:\n        k = max(1, min(4, len(candidate_indices) // 3))\n        top_indices = np.argsort(combined_marginal[candidate_indices])[-k:][::-1]\n        for idx in candidate_indices[top_indices]:\n            if (current_weight + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 2: Remove low-marginal items with adaptive selection\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        removal_scores = (1 - tradeoff_weight) * marginal1[in_items] + tradeoff_weight * marginal2[in_items]\n        k = max(1, min(3, len(in_items) // 2))\n        bottom_indices = np.argsort(removal_scores)[:k]\n        for idx in in_items[bottom_indices]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Phase 3: Adaptive swap-based perturbation\n    perturbation_prob = 0.3 + 0.4 * (1 - tradeoff_weight)\n    if random.random() < perturbation_prob:\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Select a pair of items to swap\n            swap_in = np.random.choice(in_items)\n            swap_out = np.random.choice(out_items)\n            if (current_weight - weight_lst[swap_in] + weight_lst[swap_out]) <= capacity:\n                new_solution[swap_in] = 0\n                new_solution[swap_out] = 1\n                current_weight = current_weight - weight_lst[swap_in] + weight_lst[swap_out]\n\n    # Step 5: Feasibility enforcement with marginal-based removal\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.28389385812344675,
            0.2544379234313965
        ],
        "raw_score": [
            50.432492930805694,
            50.59611873435261
        ]
    }
]