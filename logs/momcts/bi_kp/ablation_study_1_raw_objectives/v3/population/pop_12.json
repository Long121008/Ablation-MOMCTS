[
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution using a weighted random choice\n    weights = [obj[0] + obj[1] for (sol, obj) in archive]\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Calculate marginal contributions for both objectives\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = marginal1 + marginal2\n\n    # Step 4: Identify candidate items to flip\n    candidate_indices = np.where((base_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) == 0:\n        # If no items can be added, try removing low-value items\n        candidate_indices = np.where(base_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            return base_solution  # No change possible\n\n    # Step 5: Select top-k items based on combined marginal contributions\n    k = max(1, min(5, len(candidate_indices) // 2))\n    top_indices = np.argsort(combined_marginal[candidate_indices])[-k:][::-1]\n\n    # Step 6: Create new solution by flipping selected items\n    new_solution = base_solution.copy()\n    for idx in candidate_indices[top_indices]:\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 7: Dynamic weight adjustment phase\n    while current_weight > capacity:\n        # Identify items to remove based on least combined marginal value\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8379839795366024,
            0.18839186429977417
        ],
        "raw_score": [
            27.127153134971913,
            27.930397004202053
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive with a weighted random choice prioritizing solutions with higher combined objective values (70% weight for value1, 30% for value2), then employs a dynamic flipping strategy that considers both addition and removal of items based on their normalized marginal contributions (60% weight for value1, 40% for value2), while ensuring feasibility through capacity-aware adjustments and occasional random perturbations to escape local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution using a weighted random choice\n    weights = [obj[0] * 0.7 + obj[1] * 0.3 for (sol, obj) in archive]\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Calculate normalized marginal contributions for both objectives\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = 0.6 * marginal1 + 0.4 * marginal2\n\n    # Step 4: Identify candidate items to flip\n    candidate_indices = np.where((base_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) == 0:\n        candidate_indices = np.where(base_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            return base_solution\n\n    # Step 5: Select top items based on combined marginal contributions\n    k = max(1, min(3, len(candidate_indices) // 3))\n    top_indices = np.argsort(combined_marginal[candidate_indices])[-k:][::-1]\n\n    # Step 6: Create new solution by flipping selected items\n    new_solution = base_solution.copy()\n    for idx in candidate_indices[top_indices]:\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 7: Adaptive adjustment phase\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    # Step 8: Random perturbation to escape local optima\n    if random.random() < 0.3:\n        perturb_idx = np.random.choice(np.where(base_solution != new_solution)[0])\n        new_solution[perturb_idx] = 1 - new_solution[perturb_idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9067608502595553,
            0.1949823498725891
        ],
        "raw_score": [
            27.17264943660627,
            27.61900648416579
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive based on combined objective values and weight efficiency, then applies a hybrid local search that prioritizes high-marginal-contribution items for swapping while maintaining feasibility, with occasional adaptive perturbations for exploration. It emphasizes both objective optimization and weight balance, using marginal contribution analysis to guide item selection and removal, and includes a final feasibility check to ensure the solution remains valid.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution with high combined objective value and near-capacity weight\n    selected = max(archive, key=lambda x: (x[1][0] + x[1][1]) * (1 - (np.sum(weight_lst[x[0] == 1]) / capacity)) if np.sum(weight_lst[x[0] == 1]) <= capacity else -np.inf)\n    selected_solution = selected[0].copy()\n    current_weight = np.sum(weight_lst[selected_solution == 1])\n\n    # Step 2: Calculate normalized marginal contributions\n    weight_norm = weight_lst + 1e-6\n    marginal1 = value1_lst / weight_norm\n    marginal2 = value2_lst / weight_norm\n    combined_marginal = (marginal1 + marginal2) * (1 + 0.1 * np.random.rand(len(weight_lst)))\n\n    # Step 3: Identify candidate items for hybrid local search\n    out_items = np.where(selected_solution == 0)[0]\n    in_items = np.where(selected_solution == 1)[0]\n\n    # Step 4: Apply hybrid local search (item swapping + marginal contribution)\n    new_solution = selected_solution.copy()\n    if len(out_items) > 0 and len(in_items) > 0:\n        # Select top marginal items to add\n        add_candidates = out_items[np.argsort(combined_marginal[out_items])[-min(3, len(out_items)):]]\n        # Select worst marginal items to remove\n        remove_candidates = in_items[np.argsort(combined_marginal[in_items])[:min(3, len(in_items))]]\n\n        # Perform swaps while maintaining feasibility\n        for add_idx in add_candidates:\n            if current_weight + weight_lst[add_idx] <= capacity:\n                new_solution[add_idx] = 1\n                current_weight += weight_lst[add_idx]\n\n        for remove_idx in remove_candidates:\n            if new_solution[remove_idx] == 1:\n                new_solution[remove_idx] = 0\n                current_weight -= weight_lst[remove_idx]\n\n    # Step 5: Adaptive perturbation for exploration\n    if random.random() < 0.3:\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 1:\n            flip_idx1, flip_idx2 = random.sample(list(flip_candidates), 2)\n            if weight_lst[flip_idx1] + weight_lst[flip_idx2] <= capacity:\n                new_solution[flip_idx1], new_solution[flip_idx2] = new_solution[flip_idx2], new_solution[flip_idx1]\n\n    # Step 6: Final feasibility check\n    while np.sum(weight_lst[new_solution == 1]) > capacity:\n        worst_item = np.argmin(combined_marginal[new_solution == 1])\n        new_solution[np.where(new_solution == 1)[0][worst_item]] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9414381367377272,
            0.6581200361251831
        ],
        "raw_score": [
            27.463074193494123,
            28.070324531844413
        ]
    },
    {
        "algorithm": "The algorithm combines Pareto-dominance-aware selection with a dynamic marginal contribution strategy to generate feasible neighbor solutions, prioritizing non-dominated solutions and adaptively balancing trade-offs between objectives while enforcing feasibility through iterative removal and probabilistic perturbation. It dynamically adjusts the selection of items to flip based on trade-off weights and ensures feasibility through iterative removal of low-marginal items, with occasional perturbations to escape local optima. The selection of items to flip is guided by a weighted combination of marginal contributions for both objectives, with non-dominated solutions receiving higher selection weights.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Pareto-dominance-aware weighted random selection\n    pareto_weights = []\n    for (sol, obj) in archive:\n        dominated = False\n        for (_, other_obj) in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] > obj[1]) or (other_obj[0] > obj[0] and other_obj[1] >= obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_weights.append(obj[0] * 0.6 + obj[1] * 0.4)\n        else:\n            pareto_weights.append(0.1 * (obj[0] + obj[1]))\n\n    selected_idx = random.choices(range(len(archive)), weights=pareto_weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Dynamic marginal contribution calculation\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    trade_off = np.sum(value1_lst) / (np.sum(value2_lst) + 1e-6)\n    combined_marginal = (trade_off * marginal1) + ((1 - trade_off) * marginal2)\n\n    # Step 4: Identify candidate items to flip\n    candidate_indices = np.where((base_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) == 0:\n        candidate_indices = np.where(base_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            return base_solution\n\n    # Step 5: Select top-k items based on dynamic marginal contributions\n    k = max(1, min(5, len(candidate_indices) // 2))\n    top_indices = np.argsort(combined_marginal[candidate_indices])[-k:][::-1]\n\n    # Step 6: Create new solution by flipping selected items\n    new_solution = base_solution.copy()\n    for idx in candidate_indices[top_indices]:\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 7: Adaptive feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    # Step 8: Dynamic perturbation scaling\n    perturbation_prob = min(0.5, 0.1 + 0.05 * len(archive))\n    if random.random() < perturbation_prob:\n        perturb_indices = np.where(base_solution != new_solution)[0]\n        if len(perturb_indices) > 0:\n            perturb_idx = np.random.choice(perturb_indices)\n            new_solution[perturb_idx] = 1 - new_solution[perturb_idx]\n            if new_solution[perturb_idx] == 1:\n                current_weight += weight_lst[perturb_idx]\n            else:\n                current_weight -= weight_lst[perturb_idx]\n\n    # Step 9: Final feasibility check\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.772012137365541,
            0.24318775534629822
        ],
        "raw_score": [
            27.421736819659714,
            27.936880974691945
        ]
    },
    {
        "algorithm": "This algorithm selects a promising solution from the archive using Pareto-dominance-aware weighted selection, then applies a hybrid flip strategy that prioritizes adding high-marginal-value items and removing low-marginal-value items while dynamically adjusting perturbations based on local optima density to maintain feasibility. The method combines greedy selection with controlled randomness to explore trade-offs between objectives while ensuring solutions remain feasible.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Pareto-dominance-aware weighted selection\n    pareto_front = [sol_obj for sol_obj in archive if not any(\n        (sol_obj[1][0] < other[1][0] and sol_obj[1][1] <= other[1][1]) or\n        (sol_obj[1][0] <= other[1][0] and sol_obj[1][1] < other[1][1])\n        for other in archive\n    )]\n\n    if not pareto_front:\n        pareto_front = archive\n\n    weights = [obj[0] + obj[1] for (sol, obj) in pareto_front]\n    selected_idx = random.choices(range(len(pareto_front)), weights=weights, k=1)[0]\n    base_solution = pareto_front[selected_idx][0].copy()\n\n    # Step 2: Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Calculate adaptive marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = (marginal1 + marginal2) * (1 + 0.1 * np.random.rand(len(weight_lst)))\n\n    # Step 4: Hybrid flip strategy\n    new_solution = base_solution.copy()\n    candidate_indices = np.where((base_solution == 0) & (weight_lst <= remaining_capacity))[0]\n\n    if len(candidate_indices) > 0:\n        # Add items with high marginal value\n        top_add = np.argsort(combined_marginal[candidate_indices])[-min(3, len(candidate_indices)):]\n        for idx in candidate_indices[top_add]:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Remove items with low marginal value\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        bottom_remove = np.argsort(combined_marginal[in_items])[:min(2, len(in_items))]\n        for idx in in_items[bottom_remove]:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 5: Dynamic perturbation scaling\n    perturbation_intensity = 0.1 if len(pareto_front) > 2 else 0.3\n    if random.random() < perturbation_intensity:\n        flip_candidates = np.where(base_solution != new_solution)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # Step 6: Feasibility enforcement\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9033869833134398,
            0.27192428708076477
        ],
        "raw_score": [
            27.304415110215366,
            28.04960465379954
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with balanced objective values (using a weighted sum of normalized objectives), then applies a guided mutation that probabilistically flips items based on their weighted marginal contributions to both objectives, with an adaptive trade-off factor derived from the solution's current objective balance. It ensures feasibility by selectively removing items with the lowest marginal contribution to the less-critical objective when the capacity is exceeded. The key innovations include dynamic trade-off adaptation, probabilistic Pareto-aware selection, and guided mutation with feasibility preservation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected = max(archive, key=lambda x: (x[1][0] / (sum(value1_lst) + 1e-6)) + (x[1][1] / (sum(value2_lst) + 1e-6)))[0].copy()\n    new_solution = selected.copy()\n\n    # Calculate adaptive trade-off factor based on current solution's objective balance\n    total_v1 = sum(value1_lst[new_solution == 1])\n    total_v2 = sum(value2_lst[new_solution == 1])\n    tradeoff = 0.5 if (total_v1 == 0 or total_v2 == 0) else total_v1 / (total_v1 + total_v2)\n\n    # Calculate weighted marginal contributions\n    marginal_v1 = value1_lst / (weight_lst + 1e-6)\n    marginal_v2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = (tradeoff * marginal_v1) + ((1 - tradeoff) * marginal_v2)\n\n    # Guided mutation: probabilistically flip items based on marginal contributions\n    current_weight = sum(weight_lst[new_solution == 1])\n    for idx in np.random.permutation(len(new_solution)):\n        if np.random.rand() < 0.3:  # Probabilistic flip\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Feasibility preservation: remove items with lowest marginal contribution to less-critical objective\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        less_critical_obj = value2_lst if tradeoff > 0.5 else value1_lst\n        marginal_to_remove = less_critical_obj / (weight_lst + 1e-6)\n        sorted_remove = np.argsort(marginal_to_remove)[::-1]\n        for idx in sorted_remove:\n            if excess <= 0:\n                break\n            if new_solution[idx] == 1 and weight_lst[idx] <= excess:\n                new_solution[idx] = 0\n                excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9043377163325347,
            1.7856785953044891
        ],
        "raw_score": [
            27.40781355213597,
            27.761735936870014
        ]
    },
    {
        "algorithm": "The algorithm selects the most promising solution from the archive based on a weighted combination of its objectives and item density, then applies a dynamic local search that flips items using a trade-off factor between the two objectives while ensuring feasibility through probabilistic weight adjustments. It prioritizes items with high combined marginal value (adjusted by the trade-off factor) and dynamically determines how many items to flip, with a fallback mechanism to remove excess weight if needed.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    selected = max(archive, key=lambda x: (x[1][0] + x[1][1]) * (sum(x[0]) / (sum(weight_lst[x[0] == 1]) + 1e-6)))[0].copy()\n    new_solution = selected.copy()\n\n    # Calculate dynamic trade-off factor based on current solution's objective balance\n    total_v1 = sum(value1_lst[new_solution == 1])\n    total_v2 = sum(value2_lst[new_solution == 1])\n    tradeoff = 0.5 if total_v1 == 0 or total_v2 == 0 else total_v1 / (total_v1 + total_v2)\n\n    # Calculate weighted marginal contributions\n    marginal_v1 = value1_lst / (weight_lst + 1e-6)\n    marginal_v2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = (tradeoff * marginal_v1) + ((1 - tradeoff) * marginal_v2)\n\n    # Flip items with highest combined marginal value\n    sorted_indices = np.argsort(combined_marginal)[::-1]\n    flip_count = min(3, len(new_solution) // 5)  # Dynamic flip count\n\n    for idx in sorted_indices[:flip_count]:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            current_weight = sum(weight_lst[new_solution == 1])\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Probabilistic weight adjustment for feasibility\n    current_weight = sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        heavy_items = np.where(new_solution == 1)[0]\n        for idx in heavy_items:\n            if excess <= 0:\n                break\n            if np.random.rand() < 0.7 and weight_lst[idx] <= excess:\n                new_solution[idx] = 0\n                excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8466784613051457,
            1.1704210042953491
        ],
        "raw_score": [
            27.25861347233308,
            27.800354429493918
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with high combined objective values and item density, then applies a hybrid local search that dynamically adjusts the trade-off between objectives based on the current solution's balance. It flips items with the highest combined marginal contributions (weighted by a dynamic trade-off factor) while ensuring feasibility through probabilistic weight adjustments, and adaptively determines the number of flips based on solution density.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected = max(archive, key=lambda x: (x[1][0] + x[1][1]) * (sum(x[0]) / (sum(weight_lst[x[0] == 1]) + 1e-6)))[0].copy()\n    new_solution = selected.copy()\n\n    # Calculate dynamic trade-off factor based on current solution's objective balance\n    total_v1 = sum(value1_lst[new_solution == 1])\n    total_v2 = sum(value2_lst[new_solution == 1])\n    tradeoff = 0.5 if total_v1 == 0 or total_v2 == 0 else total_v1 / (total_v1 + total_v2)\n\n    # Calculate combined marginal contributions for both objectives\n    marginal_v1 = value1_lst / (weight_lst + 1e-6)\n    marginal_v2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = (tradeoff * marginal_v1) + ((1 - tradeoff) * marginal_v2)\n\n    # Determine flip count adaptively\n    flip_count = min(5, max(1, len(new_solution) // 10))\n\n    # Flip items with highest combined marginal value\n    sorted_indices = np.argsort(combined_marginal)[::-1]\n    for idx in sorted_indices[:flip_count]:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            current_weight = sum(weight_lst[new_solution == 1])\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Probabilistic weight adjustment for feasibility\n    current_weight = sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        heavy_items = np.where(new_solution == 1)[0]\n        heavy_items_sorted = sorted(heavy_items, key=lambda x: weight_lst[x], reverse=True)\n        for idx in heavy_items_sorted:\n            if excess <= 0:\n                break\n            if np.random.rand() < 0.7 and weight_lst[idx] <= excess:\n                new_solution[idx] = 0\n                excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8949480421001679,
            1.1984608471393585
        ],
        "raw_score": [
            27.555605343602405,
            28.309887111574227
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using a weighted random choice based on a combined objective score, then applies a hybrid local search strategy combining item swaps, flips, and adaptive perturbations with dynamic perturbation sizes and objective-aware selection to generate a feasible neighbor solution while exploring the solution space effectively. The strategy prioritizes value1 (70% weight) over value2 (30% weight) in selection and uses adaptive mechanisms like dynamic perturbation sizes and feasibility checks to ensure high-quality solutions across multiple objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution using a weighted random choice\n    combined_scores = [obj[0] * 0.7 + obj[1] * 0.3 for (sol, obj) in archive]  # Weighted sum of objectives\n    selected_idx = random.choices(range(len(archive)), weights=combined_scores, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Hybrid local search with novel mechanisms\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Dynamic perturbation size based on solution quality\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    max_perturb_size = min(5, n_items // 5)  # Adaptive based on problem size\n    perturb_size = random.randint(1, max_perturb_size)\n\n    # Objective-aware selection for perturbation\n    if random.random() < 0.6:  # Higher chance for value1-focused perturbation\n        candidate_indices = np.argsort(value1_lst)[-n_items//2:]  # Top 50% value1 items\n    else:\n        candidate_indices = np.argsort(value2_lst)[-n_items//2:]  # Top 50% value2 items\n\n    # Apply hybrid strategy\n    strategy = random.choice([\"swap\", \"flip\", \"perturb\", \"adaptive_flip\"])\n\n    if strategy == \"swap\":\n        # Enhanced swap with objective-aware selection\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Select items with high value ratio\n            value_ratios = (value1_lst + value2_lst) / weight_lst\n            swap_in = random.choice(in_items)\n            swap_out = random.choice(out_items)\n\n            # Check feasibility\n            new_weight = current_weight - weight_lst[swap_in] + weight_lst[swap_out]\n            if new_weight <= capacity:\n                new_solution[swap_in] = 0\n                new_solution[swap_out] = 1\n\n    elif strategy == \"flip\":\n        # Value-based flip with multiple attempts\n        for _ in range(3):  # Try multiple flips\n            flip_idx = random.choice(candidate_indices)\n            if new_solution[flip_idx] == 1:\n                new_weight = current_weight - weight_lst[flip_idx]\n                if new_weight <= capacity:\n                    new_solution[flip_idx] = 0\n                    break\n            else:\n                new_weight = current_weight + weight_lst[flip_idx]\n                if new_weight <= capacity:\n                    new_solution[flip_idx] = 1\n                    break\n\n    elif strategy == \"perturb\":\n        # Dynamic perturbation with multiple attempts\n        perturb_indices = random.sample(list(candidate_indices), min(perturb_size, len(candidate_indices)))\n        for idx in perturb_indices:\n            if new_solution[idx] == 1:\n                new_weight = current_weight - weight_lst[idx]\n                if new_weight <= capacity:\n                    new_solution[idx] = 0\n            else:\n                new_weight = current_weight + weight_lst[idx]\n                if new_weight <= capacity:\n                    new_solution[idx] = 1\n\n    elif strategy == \"adaptive_flip\":\n        # Adaptive flip based on remaining capacity\n        flip_candidates = []\n        for idx in candidate_indices:\n            if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                flip_candidates.append(idx)\n            elif new_solution[idx] == 1 and (current_weight - weight_lst[idx]) <= capacity:\n                flip_candidates.append(idx)\n\n        if flip_candidates:\n            flip_idx = random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.2619377052959229,
            0.27632978558540344
        ],
        "raw_score": [
            49.21545254802683,
            48.10415543548359
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution with high potential for improvement using a combination of randomness and quality metrics\n    quality_scores = [obj[0] * 0.7 + obj[1] * 0.3 for (sol, obj) in archive]  # Bias towards value1\n    selected_idx = random.choices(range(len(archive)), weights=quality_scores, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Calculate current state and remaining capacity\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Calculate normalized marginal contributions for both objectives\n    marginal1 = value1_lst / (weight_lst + 1e-6)\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n    norm_marginal1 = (marginal1 - np.min(marginal1)) / (np.max(marginal1) - np.min(marginal1) + 1e-6)\n    norm_marginal2 = (marginal2 - np.min(marginal2)) / (np.max(marginal2) - np.min(marginal2) + 1e-6)\n    combined_marginal = 0.6 * norm_marginal1 + 0.4 * norm_marginal2  # Weighted combination\n\n    # Step 4: Identify candidate items for flip with adaptive selection pressure\n    candidate_indices = np.where((base_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(candidate_indices) == 0:\n        candidate_indices = np.where(base_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            return base_solution\n\n    # Step 5: Select items based on combined marginal with probabilistic acceptance\n    new_solution = base_solution.copy()\n    for idx in candidate_indices:\n        if new_solution[idx] == 0:\n            if random.random() < combined_marginal[idx] * 0.8:  # Higher probability for better items\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n        else:\n            if random.random() < (1 - combined_marginal[idx]) * 0.3:  # Lower probability to remove worse items\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Step 6: Feasibility enforcement with dynamic weight adjustment\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        worst_item = in_items[np.argmin(combined_marginal[in_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    # Step 7: Additional diversification with random flips\n    if random.random() < 0.3:  # 30% chance for diversification\n        flip_candidates = np.where((base_solution != new_solution) & (weight_lst <= remaining_capacity))[0]\n        if len(flip_candidates) > 0:\n            flip_idx = random.choice(flip_candidates)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.746434209281546,
            0.2783259451389313
        ],
        "raw_score": [
            27.30265413212179,
            27.813117844786174
        ]
    }
]