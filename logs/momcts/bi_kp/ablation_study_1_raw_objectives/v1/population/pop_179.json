[
    {
        "algorithm": "The algorithm selects a solution from the archive with the highest objective diversity (difference between value1 and value2), then performs a hybrid local search by flipping items based on their normalized marginal contributions to both objectives, prioritizing those with the highest combined marginal value while ensuring feasibility. It sorts items by their normalized marginal value and iteratively flips items to maximize combined objective gains without exceeding capacity. The key design ideas are prioritizing objective diversity for selection and using normalized marginal contributions for intelligent flipping.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select the solution with the highest objective diversity (difference between value1 and value2)\n    best_idx = max(range(len(archive)), key=lambda i: abs(archive[i][1][0] - archive[i][1][1]))\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate normalized marginal contributions for each item\n    marginal_value1 = value1_lst - (base_solution * value1_lst)\n    marginal_value2 = value2_lst - (base_solution * value2_lst)\n    marginal_combined = marginal_value1 + marginal_value2\n\n    # Normalize marginal contributions\n    max_marginal = np.max(marginal_combined)\n    if max_marginal > 0:\n        normalized_marginal = marginal_combined / max_marginal\n    else:\n        normalized_marginal = marginal_combined\n\n    # Sort items by normalized marginal contribution (descending)\n    sorted_indices = np.argsort(-normalized_marginal)\n\n    # Try to flip items with high normalized marginal contribution\n    for idx in sorted_indices:\n        if base_solution[idx] == 1:\n            # If item is in the solution, try to remove it\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # If item is not in the solution, try to add it\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9101876645710116,
            0.3497251272201538
        ],
        "raw_score": [
            27.004661735141276,
            27.688360888346264
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive by prioritizing those with high marginal gains in both objectives, then applies a hybrid local search that probabilistically adds, removes, or swaps items based on their marginal contributions, ensuring feasibility through adaptive weight checks. It balances exploration/exploitation by favoring diverse marginal gains and intelligently navigating the Pareto front through probabilistic operations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high marginal gains in both objectives\n    selected_idx = 0\n    max_marginal_product = -1\n\n    for i, (solution, objective) in enumerate(archive):\n        current_weight = np.sum(weight_lst[solution == 1])\n        excluded_items = np.where(solution == 0)[0]\n        included_items = np.where(solution == 1)[0]\n\n        if len(excluded_items) == 0 or len(included_items) == 0:\n            continue\n\n        # Calculate marginal gains for excluded items\n        marginal_gains1 = value1_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        marginal_gains2 = value2_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        marginal_product = np.mean(marginal_gains1) * np.mean(marginal_gains2)\n\n        if marginal_product > max_marginal_product:\n            max_marginal_product = marginal_product\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate marginal contributions for all items\n    marginal_value1 = value1_lst - (base_solution * value1_lst)\n    marginal_value2 = value2_lst - (base_solution * value2_lst)\n    marginal_combined = marginal_value1 + marginal_value2\n\n    # Sort items by marginal contribution (descending)\n    sorted_indices = np.argsort(-marginal_combined)\n\n    # Hybrid local search: probabilistic decision between add, remove, or swap\n    excluded_items = np.where(new_solution == 0)[0]\n    included_items = np.where(new_solution == 1)[0]\n\n    if len(excluded_items) > 0 and len(included_items) > 0:\n        decision = random.choices(['add', 'remove', 'swap'], weights=[0.4, 0.3, 0.3])[0]\n\n        if decision == 'add':\n            # Add the best excluded item based on combined marginal gain\n            excluded_sorted = sorted(excluded_items, key=lambda x: marginal_combined[x], reverse=True)\n            for item in excluded_sorted:\n                if np.sum(weight_lst[new_solution == 1]) + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                    break\n\n        elif decision == 'remove':\n            # Remove the least marginal item in either objective\n            included_sorted = sorted(included_items, key=lambda x: min(marginal_value1[x], marginal_value2[x]))\n            for item in included_sorted:\n                if np.sum(weight_lst[new_solution == 1]) - weight_lst[item] >= 0:\n                    new_solution[item] = 0\n                    break\n\n        elif decision == 'swap':\n            # Swap one excluded with one included item\n            swap_excluded = random.choice(excluded_items)\n            swap_included = random.choice(included_items)\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            new_weight = current_weight - weight_lst[swap_included] + weight_lst[swap_excluded]\n            if new_weight <= capacity:\n                new_solution[swap_included] = 0\n                new_solution[swap_excluded] = 1\n\n    # If no swap possible, try to add the best excluded item\n    else:\n        excluded_items = np.where(new_solution == 0)[0]\n        if len(excluded_items) > 0:\n            excluded_sorted = sorted(excluded_items, key=lambda x: marginal_combined[x], reverse=True)\n            for item in excluded_sorted:\n                if np.sum(weight_lst[new_solution == 1]) + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                    break\n\n    return new_solution\n\n",
        "metric_score": [
            -1.002058205017338,
            1.9492744207382202
        ],
        "raw_score": [
            27.19939705469744,
            27.641547598415023
        ]
    },
    {
        "algorithm": "The algorithm selects the most promising solution from the archive using a hypervolume-aware metric, then applies a multi-phase local search combining Pareto frontier exploration (60% chance) with frontier-aware flips and marginal contribution analysis, or diversity-aware perturbation (40% chance) with adaptive neighborhood swaps, ensuring feasibility through weight checks. If no improvement is found, it intensifies search by removing the least valuable included items. The approach balances exploration and exploitation while prioritizing solutions with high hypervolume contributions and marginal value improvements.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hypervolume-aware solution selection\n    def hypervolume(obj1, obj2, ref_point):\n        return (ref_point[0] - obj1) * (ref_point[1] - obj2)\n\n    max_hv = -1\n    best_idx = 0\n    ref_point = (np.max([obj[0] for _, obj in archive]), np.max([obj[1] for _, obj in archive]))\n\n    for i, (solution, obj) in enumerate(archive):\n        hv = hypervolume(obj[0], obj[1], ref_point)\n        if hv > max_hv:\n            max_hv = hv\n            best_idx = i\n\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Multi-phase local search\n    if random.random() < 0.6:  # 60% chance for frontier exploration\n        # Pareto frontier-aware flips\n        frontier_items = np.where(new_solution == 1)[0]\n        non_frontier_items = np.where(new_solution == 0)[0]\n\n        if len(frontier_items) > 0 and len(non_frontier_items) > 0:\n            # Calculate marginal contributions\n            frontier_marginal = (value1_lst[frontier_items] + value2_lst[frontier_items]) / weight_lst[frontier_items]\n            non_frontier_marginal = (value1_lst[non_frontier_items] + value2_lst[non_frontier_items]) / weight_lst[non_frontier_items]\n\n            # Find best swaps\n            best_frontier = frontier_items[np.argmin(frontier_marginal)]\n            best_non_frontier = non_frontier_items[np.argmax(non_frontier_marginal)]\n\n            # Check feasibility\n            new_weight = current_weight - weight_lst[best_frontier] + weight_lst[best_non_frontier]\n            if new_weight <= capacity:\n                new_solution[best_frontier] = 0\n                new_solution[best_non_frontier] = 1\n                current_weight = new_weight\n    else:  # 40% chance for diversity-aware perturbation\n        # Adaptive neighborhood search\n        num_perturbations = min(2, len(weight_lst) // 10)\n        perturb_indices = np.random.choice(len(weight_lst), size=num_perturbations, replace=False)\n\n        for idx in perturb_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Fallback mechanism: Pareto-aware intensification\n    if np.array_equal(new_solution, base_solution):\n        # Intensify search around current solution\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Find least valuable included item\n            included_marginal = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n            least_val_item = included_items[np.argmin(included_marginal)]\n\n            # Try to remove it\n            if current_weight - weight_lst[least_val_item] >= 0:\n                new_solution[least_val_item] = 0\n                current_weight -= weight_lst[least_val_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8962181579365913,
            0.19705554842948914
        ],
        "raw_score": [
            26.959826063541488,
            27.544373065968784
        ]
    },
    {
        "algorithm": "The algorithm selects the most promising solution from the archive (based on normalized marginal gains) and applies a hybrid local search (60% flips, 40% swaps) with adaptive weights (higher priority to the weaker objective). It ensures feasibility by removing least marginal items if no improvement is found, prioritizing balanced improvements across both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest normalized sum of marginal gains\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    best_idx = max(range(len(archive)), key=lambda i: (archive[i][1][0] + archive[i][1][1]) / (max_obj1 + max_obj2 + 1e-10))\n\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate marginal contributions with adaptive weights\n    marginal_value1 = value1_lst - (base_solution * value1_lst)\n    marginal_value2 = value2_lst - (base_solution * value2_lst)\n\n    # Adaptive weights based on objective dominance\n    total_value1 = np.sum(value1_lst[base_solution == 1])\n    total_value2 = np.sum(value2_lst[base_solution == 1])\n    weight_obj1 = 1.0 if total_value1 < total_value2 else 0.7\n    weight_obj2 = 1.0 if total_value2 < total_value1 else 0.7\n\n    marginal_combined = weight_obj1 * marginal_value1 + weight_obj2 * marginal_value2\n\n    # Hybrid local search with probabilistic operations\n    decision = random.choices(['flip', 'swap'], weights=[0.6, 0.4])[0]\n\n    if decision == 'flip':\n        # Flip items with highest marginal gain while maintaining feasibility\n        sorted_indices = np.argsort(-marginal_combined)\n        for idx in sorted_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    else:  # swap\n        # Swap items with high and low marginal gains\n        high_marginal = np.argsort(-marginal_combined)[:len(weight_lst)//3]\n        low_marginal = np.argsort(marginal_combined)[:len(weight_lst)//3]\n\n        for h in high_marginal:\n            for l in low_marginal:\n                if new_solution[h] == 1 and new_solution[l] == 0:\n                    new_weight = current_weight - weight_lst[h] + weight_lst[l]\n                    if new_weight <= capacity:\n                        new_solution[h], new_solution[l] = 0, 1\n                        current_weight = new_weight\n                        break\n            else:\n                continue\n            break\n\n    # If no improvement, remove least marginal items to ensure feasibility\n    if np.array_equal(new_solution, base_solution):\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            sorted_items = sorted(included_items, key=lambda x: marginal_value1[x] + marginal_value2[x])\n            for item in sorted_items:\n                if current_weight - weight_lst[item] >= 0:\n                    new_solution[item] = 0\n                    current_weight -= weight_lst[item]\n                    break\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9514271204468423,
            0.9768357276916504
        ],
        "raw_score": [
            27.865390153322615,
            28.203870181276848
        ]
    },
    {
        "algorithm": "The algorithm combines adaptive Pareto selection with a hybrid local search that uses probabilistic flips (60%) and value-balancing swaps (40%), dynamically adjusting operation probabilities based on solution sparsity. It prioritizes items with high marginal gains in both objectives, using normalized marginal contributions with adaptive weights to balance value1 and value2, while ensuring feasibility through greedy removal of least marginal items when needed. The selection criterion favors solutions with high combined marginal gains and balanced value distributions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest combined marginal gains and balanced value distribution\n    selected_idx = 0\n    max_score = -1\n\n    for i, (solution, objective) in enumerate(archive):\n        included = solution == 1\n        excluded = solution == 0\n\n        if not np.any(included) or not np.any(excluded):\n            continue\n\n        # Calculate marginal gains for excluded items\n        marginal_gains1 = value1_lst[excluded] / (weight_lst[excluded] + 1e-6)\n        marginal_gains2 = value2_lst[excluded] / (weight_lst[excluded] + 1e-6)\n\n        # Calculate value balance score\n        total_value1 = objective[0]\n        total_value2 = objective[1]\n        value_balance = 1 - abs(total_value1 - total_value2) / (total_value1 + total_value2 + 1e-6)\n\n        # Combine marginal gains and value balance\n        score = (np.sum(marginal_gains1) + np.sum(marginal_gains2)) * (1 + value_balance)\n\n        if score > max_score:\n            max_score = score\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Hybrid local search with dynamic operation probabilities\n    flip_prob = 0.6\n    swap_prob = 0.4\n    if np.sum(base_solution) < len(base_solution) * 0.2:  # More exploration when solution is sparse\n        flip_prob = 0.7\n        swap_prob = 0.3\n\n    operation = random.choices(['flip', 'swap'], weights=[flip_prob, swap_prob])[0]\n\n    if operation == 'flip':\n        # Calculate marginal contributions for all items\n        marginal_value1 = value1_lst - (base_solution * value1_lst)\n        marginal_value2 = value2_lst - (base_solution * value2_lst)\n\n        # Calculate normalized marginal gains\n        max_marginal1 = np.max(marginal_value1) if np.any(marginal_value1) else 1\n        max_marginal2 = np.max(marginal_value2) if np.any(marginal_value2) else 1\n\n        normalized_marginal1 = marginal_value1 / max_marginal1\n        normalized_marginal2 = marginal_value2 / max_marginal2\n\n        # Combine normalized marginal gains with adaptive weights\n        total_value1 = np.sum(value1_lst[base_solution == 1])\n        total_value2 = np.sum(value2_lst[base_solution == 1])\n        weight_obj1 = 1.0 if total_value1 < total_value2 else 0.6\n        weight_obj2 = 1.0 if total_value2 < total_value1 else 0.6\n\n        marginal_combined = weight_obj1 * normalized_marginal1 + weight_obj2 * normalized_marginal2\n\n        # Sort items by combined marginal contribution (descending)\n        sorted_indices = np.argsort(-marginal_combined)\n\n        # Try to flip items with high marginal contribution\n        for idx in sorted_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    else:  # value-balancing swap\n        included_items = np.where(new_solution == 1)[0]\n        excluded_items = np.where(new_solution == 0)[0]\n\n        if len(included_items) > 0 and len(excluded_items) > 0:\n            # Calculate value balance potential for included items\n            value_balance = (value1_lst[included_items] - value2_lst[included_items]) / (value1_lst[included_items] + value2_lst[included_items] + 1e-6)\n\n            # Find most imbalanced included item\n            worst_included = included_items[np.argmax(np.abs(value_balance))]\n\n            # Find best excluded item based on opposite marginal need\n            if value_balance[np.argmax(np.abs(value_balance))] > 0:\n                # Need more value2\n                marginal_criteria = value2_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n            else:\n                # Need more value1\n                marginal_criteria = value1_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n\n            best_excluded = excluded_items[np.argmax(marginal_criteria)]\n\n            # Check feasibility\n            new_weight = current_weight - weight_lst[worst_included] + weight_lst[best_excluded]\n            if new_weight <= capacity:\n                new_solution[worst_included] = 0\n                new_solution[best_excluded] = 1\n            else:\n                # Adaptive greedy removal if swap is infeasible\n                included_sorted = sorted(included_items, key=lambda x: (value1_lst[x] + value2_lst[x]) / (weight_lst[x] + 1e-6))\n                for item in included_sorted:\n                    if current_weight - weight_lst[item] >= 0:\n                        new_solution[item] = 0\n                        current_weight -= weight_lst[item]\n                        break\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9781888634903011,
            1.3077029585838318
        ],
        "raw_score": [
            27.20729109509217,
            27.754358929629916
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest adaptive Pareto marginal gains and diversity potential\n    selected_idx = 0\n    max_pareto_score = -1\n    max_diversity = -1\n\n    for i, (solution, objective) in enumerate(archive):\n        current_weight = np.sum(weight_lst[solution == 1])\n        excluded_items = np.where(solution == 0)[0]\n\n        # Calculate adaptive Pareto marginal gains\n        if len(excluded_items) > 0:\n            pareto_weights = np.random.uniform(0.3, 0.7, size=len(excluded_items))\n            pareto_gains = (value1_lst[excluded_items] * pareto_weights + value2_lst[excluded_items] * (1-pareto_weights)) / weight_lst[excluded_items]\n            pareto_score = np.sum(pareto_gains)\n        else:\n            pareto_score = 0\n\n        # Calculate diversity potential\n        diversity = len(excluded_items)\n\n        total_score = pareto_score * (1 + 0.1 * diversity)\n        if total_score > max_pareto_score or (total_score == max_pareto_score and diversity > max_diversity):\n            max_pareto_score = total_score\n            max_diversity = diversity\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: 80% flips with adaptive Pareto ratios, 20% swaps with dynamic feasibility\n    if np.random.random() < 0.8:\n        # Adaptive Pareto flip\n        excluded_items = np.where(new_solution == 0)[0]\n        if len(excluded_items) > 0:\n            # Calculate adaptive Pareto ratios\n            pareto_weights = np.random.uniform(0.4, 0.6, size=len(excluded_items))\n            pareto_ratios = (value1_lst[excluded_items] * pareto_weights + value2_lst[excluded_items] * (1-pareto_weights)) / weight_lst[excluded_items]\n\n            # Select top 3 items by Pareto ratio\n            top_items = np.argsort(pareto_ratios)[-min(3, len(excluded_items)):]\n\n            for item in excluded_items[top_items]:\n                if np.sum(weight_lst[new_solution == 1]) + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n    else:\n        # Dynamic feasibility swap\n        included_items = np.where(new_solution == 1)[0]\n        excluded_items = np.where(new_solution == 0)[0]\n\n        if len(included_items) > 0 and len(excluded_items) > 0:\n            # Select item to remove (lowest Pareto contribution)\n            pareto_weights = np.random.uniform(0.4, 0.6, size=len(included_items))\n            pareto_contributions = (value1_lst[included_items] * pareto_weights + value2_lst[included_items] * (1-pareto_weights)) / weight_lst[included_items]\n            remove_item = included_items[np.argmin(pareto_contributions)]\n\n            # Select item to add (highest Pareto gain)\n            pareto_weights = np.random.uniform(0.4, 0.6, size=len(excluded_items))\n            pareto_gains = (value1_lst[excluded_items] * pareto_weights + value2_lst[excluded_items] * (1-pareto_weights)) / weight_lst[excluded_items]\n            add_item = excluded_items[np.argmax(pareto_gains)]\n\n            # Check feasibility and swap\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            new_weight = current_weight - weight_lst[remove_item] + weight_lst[add_item]\n\n            if new_weight <= capacity:\n                new_solution[remove_item] = 0\n                new_solution[add_item] = 1\n\n    # Dynamic perturbation if no improvement\n    if np.array_equal(new_solution, base_solution):\n        perturbation_rate = min(0.25, max_pareto_score / (np.sum(value1_lst) + np.sum(value2_lst)))\n        if np.random.random() < perturbation_rate:\n            # Greedy removal of low-value items\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) > 0:\n                pareto_weights = np.random.uniform(0.4, 0.6, size=len(included_items))\n                pareto_values = (value1_lst[included_items] * pareto_weights + value2_lst[included_items] * (1-pareto_weights))\n                remove_item = included_items[np.argmin(pareto_values)]\n\n                if np.sum(weight_lst[new_solution == 1]) - weight_lst[remove_item] >= 0:\n                    new_solution[remove_item] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9528050126275986,
            1.0804893970489502
        ],
        "raw_score": [
            26.933719804115533,
            27.68222017773451
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive based on dominance and diversity, then applies a hybrid local search combining objective-specific item swaps (prioritizing high-value items) and adaptive perturbation (balancing exploration/exploitation) to generate feasible neighbors while ensuring the total weight doesn't exceed capacity. It dynamically adjusts perturbation rates based on current solution quality and alternates between targeted swaps and random perturbations to improve both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select solution with highest dominance score and diversity\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    selected_idx = max(range(len(archive)), key=lambda i: (archive[i][1][0]/max_obj1 + archive[i][1][1]/max_obj2) * (1 - 0.2 * np.sum(archive[i][0])))\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search combining objective-specific swaps and adaptive perturbation\n    if random.random() < 0.6:\n        # Objective-specific item swaps\n        current_v1 = np.sum(value1_lst[new_solution == 1])\n        current_v2 = np.sum(value2_lst[new_solution == 1])\n\n        if current_v1 < 0.7 * max_obj1 or current_v2 < 0.7 * max_obj2:\n            # Swap items with potential for higher objective values\n            included_items = np.where(new_solution == 1)[0]\n            excluded_items = np.where(new_solution == 0)[0]\n\n            if len(included_items) > 0 and len(excluded_items) > 0:\n                # Calculate potential improvements\n                v1_improvement = value1_lst[excluded_items] / weight_lst[excluded_items]\n                v2_improvement = value2_lst[excluded_items] / weight_lst[excluded_items]\n\n                if current_v1 < current_v2:\n                    best_out = excluded_items[np.argmax(v1_improvement)]\n                    worst_in = included_items[np.argmin(value1_lst[included_items] / weight_lst[included_items])]\n                else:\n                    best_out = excluded_items[np.argmax(v2_improvement)]\n                    worst_in = included_items[np.argmin(value2_lst[included_items] / weight_lst[included_items])]\n\n                if current_weight - weight_lst[worst_in] + weight_lst[best_out] <= capacity:\n                    new_solution[worst_in] = 0\n                    new_solution[best_out] = 1\n                    current_weight = current_weight - weight_lst[worst_in] + weight_lst[best_out]\n        else:\n            # Random swap with objective balancing\n            candidates = [i for i in range(len(weight_lst)) if (new_solution[i] == 1 and current_weight - weight_lst[i] >= 0) or\n                         (new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n            if len(candidates) > 1:\n                idx1, idx2 = np.random.choice(candidates, 2, replace=False)\n                if (new_solution[idx1] == 1 and new_solution[idx2] == 0 and\n                    current_weight - weight_lst[idx1] + weight_lst[idx2] <= capacity):\n                    new_solution[idx1], new_solution[idx2] = 0, 1\n                    current_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n    else:\n        # Adaptive perturbation with objective awareness\n        current_v1 = np.sum(value1_lst[new_solution == 1])\n        current_v2 = np.sum(value2_lst[new_solution == 1])\n        perturbation_rate = 0.15 + 0.15 * (1 - (current_v1/max_obj1 + current_v2/max_obj2)/2)\n\n        if random.random() < perturbation_rate:\n            # Objective-aware perturbation\n            if current_v1 < current_v2:\n                # Perturb towards improving value1\n                candidates = [i for i in range(len(weight_lst)) if\n                            (new_solution[i] == 1 and current_weight - weight_lst[i] >= 0) or\n                            (new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n                if candidates:\n                    idx = np.random.choice(candidates)\n                    new_solution[idx] = 1 - new_solution[idx]\n            else:\n                # Perturb towards improving value2\n                candidates = [i for i in range(len(weight_lst)) if\n                            (new_solution[i] == 1 and current_weight - weight_lst[i] >= 0) or\n                            (new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n                if candidates:\n                    idx = np.random.choice(candidates)\n                    new_solution[idx] = 1 - new_solution[idx]\n\n    # Feasibility check and repair\n    while np.sum(weight_lst[new_solution == 1]) > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        # Remove items with lowest combined value-to-weight ratio\n        v1_ratio = value1_lst[included_items] / weight_lst[included_items]\n        v2_ratio = value2_lst[included_items] / weight_lst[included_items]\n        combined_ratio = (v1_ratio + v2_ratio) / 2\n        remove_idx = included_items[np.argmin(combined_ratio)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.936682850058253,
            0.3860514461994171
        ],
        "raw_score": [
            27.29260272698267,
            27.744371309311738
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with adaptive Pareto dominance and high marginal gains\n    selected_idx = 0\n    max_score = -1\n\n    for i, (solution, objective) in enumerate(archive):\n        # Calculate Pareto score (balance between both objectives)\n        pareto_score = (objective[0] + objective[1]) / (1 + abs(objective[0] - objective[1]))\n\n        # Calculate marginal gains for excluded items\n        excluded_items = np.where(solution == 0)[0]\n        if len(excluded_items) > 0:\n            marginal_gains1 = value1_lst[excluded_items] / weight_lst[excluded_items]\n            marginal_gains2 = value2_lst[excluded_items] / weight_lst[excluded_items]\n            max_marginal_gain = np.max(marginal_gains1) + np.max(marginal_gains2)\n        else:\n            max_marginal_gain = 0\n\n        # Combine scores with adaptive weights\n        combined_score = 0.6 * pareto_score + 0.4 * max_marginal_gain\n        if combined_score > max_score:\n            max_score = combined_score\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid perturbation with dynamic probability adjustment\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    flip_prob = min(0.8, 0.5 + 0.3 * (capacity - current_weight) / capacity)  # Higher when closer to capacity\n    perturbation_type = np.random.choice(['flip', 'swap'], p=[flip_prob, 1 - flip_prob])\n\n    if perturbation_type == 'flip':\n        # Targeted flip: prioritize items with high normalized marginal gains in both objectives\n        marginal_value1 = value1_lst - (base_solution * value1_lst)\n        marginal_value2 = value2_lst - (base_solution * value2_lst)\n\n        # Normalize and combine marginal gains\n        max_marginal1 = np.max(marginal_value1)\n        max_marginal2 = np.max(marginal_value2)\n        if max_marginal1 > 0:\n            normalized_marginal1 = marginal_value1 / max_marginal1\n        else:\n            normalized_marginal1 = marginal_value1\n        if max_marginal2 > 0:\n            normalized_marginal2 = marginal_value2 / max_marginal2\n        else:\n            normalized_marginal2 = marginal_value2\n\n        combined_marginal = normalized_marginal1 + normalized_marginal2\n        sorted_indices = np.argsort(-combined_marginal)\n\n        for idx in sorted_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    else:  # swap\n        # Guided swap: exchange between high-value and low-value items with dynamic reallocation\n        included_items = np.where(new_solution == 1)[0]\n        excluded_items = np.where(new_solution == 0)[0]\n\n        if len(included_items) > 0 and len(excluded_items) > 0:\n            # Categorize items by value-to-weight ratio\n            included_vw1 = value1_lst[included_items] / weight_lst[included_items]\n            included_vw2 = value2_lst[included_items] / weight_lst[included_items]\n            excluded_vw1 = value1_lst[excluded_items] / weight_lst[excluded_items]\n            excluded_vw2 = value2_lst[excluded_items] / weight_lst[excluded_items]\n\n            # Select low-value included item and high-value excluded item\n            low_value_included = included_items[np.argmin(included_vw1 + included_vw2)]\n            high_value_excluded = excluded_items[np.argmax(excluded_vw1 + excluded_vw2)]\n\n            new_weight = current_weight - weight_lst[low_value_included] + weight_lst[high_value_excluded]\n\n            if new_weight <= capacity:\n                new_solution[low_value_included] = 0\n                new_solution[high_value_excluded] = 1\n            else:\n                # Dynamic feasibility adjustment: remove least valuable items\n                while new_weight > capacity:\n                    included_items = np.where(new_solution == 1)[0]\n                    if len(included_items) == 0:\n                        break\n                    included_vw = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n                    least_value_item = included_items[np.argmin(included_vw)]\n                    new_solution[least_value_item] = 0\n                    new_weight -= weight_lst[least_value_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9391471875610538,
            0.7680032551288605
        ],
        "raw_score": [
            27.429453800336066,
            27.866844325341717
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest normalized objective product (balancing both objectives)\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        best_idx = 0\n    else:\n        best_idx = max(range(len(archive)), key=lambda i: (archive[i][1][0] * archive[i][1][1]) / (max_obj1 * max_obj2))\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate normalized marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    marginal_norm1 = marginal_gain1 / (np.max(marginal_gain1) + 1e-10)\n    marginal_norm2 = marginal_gain2 / (np.max(marginal_gain2) + 1e-10)\n\n    # Combine marginal gains with adaptive weights based on solution's current performance\n    weight_obj1 = 1.0 if np.sum(value1_lst[base_solution == 1]) < 0.7 * max_obj1 else 0.5\n    weight_obj2 = 1.0 if np.sum(value2_lst[base_solution == 1]) < 0.7 * max_obj2 else 0.5\n    combined_marginal = weight_obj1 * marginal_norm1 + weight_obj2 * marginal_norm2\n\n    # Sort items by combined marginal gain and attempt to flip top candidates\n    sorted_indices = np.argsort(-combined_marginal)\n    for idx in sorted_indices[:max(1, len(weight_lst)//10)]:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # If no improvement, perform a targeted swap between high-marginal and low-marginal items\n    if np.array_equal(new_solution, base_solution):\n        high_marginal = np.argsort(-combined_marginal)[:len(weight_lst)//2]\n        low_marginal = np.argsort(combined_marginal)[:len(weight_lst)//2]\n\n        for h in high_marginal:\n            for l in low_marginal:\n                if new_solution[h] == 1 and new_solution[l] == 0:\n                    new_weight = current_weight - weight_lst[h] + weight_lst[l]\n                    if new_weight <= capacity:\n                        new_solution[h], new_solution[l] = 0, 1\n                        current_weight = new_weight\n                        break\n            else:\n                continue\n            break\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8522335976313615,
            0.24278834462165833
        ],
        "raw_score": [
            27.69394350063845,
            28.12451233846662
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest combined marginal gains and high diversity potential\n    selected_idx = 0\n    max_marginal_gain = -1\n    max_diversity = -1\n\n    for i, (solution, objective) in enumerate(archive):\n        current_weight = np.sum(weight_lst[solution == 1])\n        excluded_items = np.where(solution == 0)[0]\n\n        # Calculate marginal gains for excluded items\n        marginal_gains1 = value1_lst[excluded_items] / weight_lst[excluded_items]\n        marginal_gains2 = value2_lst[excluded_items] / weight_lst[excluded_items]\n        combined_gain_excluded = np.sum(marginal_gains1) + np.sum(marginal_gains2)\n\n        # Calculate diversity potential (number of items not in the current solution)\n        diversity = len(excluded_items)\n\n        total_score = combined_gain_excluded * diversity\n        if total_score > max_marginal_gain or (total_score == max_marginal_gain and diversity > max_diversity):\n            max_marginal_gain = total_score\n            max_diversity = diversity\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: probabilistic flip with value-to-weight ratio and diversity-aware swaps\n    flip_prob = 0.6\n    if np.random.random() < flip_prob:\n        # Value-to-weight ratio based flip\n        excluded_items = np.where(new_solution == 0)[0]\n        if len(excluded_items) > 0:\n            ratios = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n            selected_item = np.random.choice(excluded_items, p=ratios/np.sum(ratios))\n\n            if np.sum(weight_lst[new_solution == 1]) + weight_lst[selected_item] <= capacity:\n                new_solution[selected_item] = 1\n    else:\n        # Diversity-aware swap: swap a high-value item with a low-value excluded item\n        included_items = np.where(new_solution == 1)[0]\n        excluded_items = np.where(new_solution == 0)[0]\n\n        if len(included_items) > 0 and len(excluded_items) > 0:\n            # Select high-value included item\n            high_value_item = np.argmax((value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items])\n            high_value_item = included_items[high_value_item]\n\n            # Select low-value excluded item\n            low_value_item = np.argmin((value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items])\n            low_value_item = excluded_items[low_value_item]\n\n            # Check feasibility and swap\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            new_weight = current_weight - weight_lst[high_value_item] + weight_lst[low_value_item]\n\n            if new_weight <= capacity:\n                new_solution[high_value_item] = 0\n                new_solution[low_value_item] = 1\n\n    # If no improvement, perform a probabilistic perturbation to escape local optima\n    if np.array_equal(new_solution, base_solution):\n        perturbation_rate = min(0.3, max_marginal_gain / (np.sum(value1_lst) + np.sum(value2_lst)))\n        if np.random.random() < perturbation_rate:\n            candidates = [i for i in range(len(weight_lst)) if (new_solution[i] == 1 and np.sum(weight_lst[new_solution == 1]) - weight_lst[i] >= 0) or\n                         (new_solution[i] == 0 and np.sum(weight_lst[new_solution == 1]) + weight_lst[i] <= capacity)]\n            if candidates:\n                idx = np.random.choice(candidates)\n                new_solution[idx] = 1 - new_solution[idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9614967420754377,
            1.5302500426769257
        ],
        "raw_score": [
            26.967240128335717,
            27.494577329075724
        ]
    }
]