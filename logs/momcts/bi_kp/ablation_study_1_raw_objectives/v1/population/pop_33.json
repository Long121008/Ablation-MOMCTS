[
    {
        "algorithm": "The algorithm selects a solution from the archive with the highest objective diversity (difference between value1 and value2), then performs a hybrid local search by flipping items based on their normalized marginal contributions to both objectives, prioritizing those with the highest combined marginal value while ensuring feasibility. It sorts items by their normalized marginal value and iteratively flips items to maximize combined objective gains without exceeding capacity. The key design ideas are prioritizing objective diversity for selection and using normalized marginal contributions for intelligent flipping.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select the solution with the highest objective diversity (difference between value1 and value2)\n    best_idx = max(range(len(archive)), key=lambda i: abs(archive[i][1][0] - archive[i][1][1]))\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate normalized marginal contributions for each item\n    marginal_value1 = value1_lst - (base_solution * value1_lst)\n    marginal_value2 = value2_lst - (base_solution * value2_lst)\n    marginal_combined = marginal_value1 + marginal_value2\n\n    # Normalize marginal contributions\n    max_marginal = np.max(marginal_combined)\n    if max_marginal > 0:\n        normalized_marginal = marginal_combined / max_marginal\n    else:\n        normalized_marginal = marginal_combined\n\n    # Sort items by normalized marginal contribution (descending)\n    sorted_indices = np.argsort(-normalized_marginal)\n\n    # Try to flip items with high normalized marginal contribution\n    for idx in sorted_indices:\n        if base_solution[idx] == 1:\n            # If item is in the solution, try to remove it\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # If item is not in the solution, try to add it\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9101876645710116,
            0.3497251272201538
        ],
        "raw_score": [
            27.004661735141276,
            27.688360888346264
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive by prioritizing those with high marginal gains in both objectives, then applies a hybrid local search that probabilistically adds, removes, or swaps items based on their marginal contributions, ensuring feasibility through adaptive weight checks. It balances exploration/exploitation by favoring diverse marginal gains and intelligently navigating the Pareto front through probabilistic operations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high marginal gains in both objectives\n    selected_idx = 0\n    max_marginal_product = -1\n\n    for i, (solution, objective) in enumerate(archive):\n        current_weight = np.sum(weight_lst[solution == 1])\n        excluded_items = np.where(solution == 0)[0]\n        included_items = np.where(solution == 1)[0]\n\n        if len(excluded_items) == 0 or len(included_items) == 0:\n            continue\n\n        # Calculate marginal gains for excluded items\n        marginal_gains1 = value1_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        marginal_gains2 = value2_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        marginal_product = np.mean(marginal_gains1) * np.mean(marginal_gains2)\n\n        if marginal_product > max_marginal_product:\n            max_marginal_product = marginal_product\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate marginal contributions for all items\n    marginal_value1 = value1_lst - (base_solution * value1_lst)\n    marginal_value2 = value2_lst - (base_solution * value2_lst)\n    marginal_combined = marginal_value1 + marginal_value2\n\n    # Sort items by marginal contribution (descending)\n    sorted_indices = np.argsort(-marginal_combined)\n\n    # Hybrid local search: probabilistic decision between add, remove, or swap\n    excluded_items = np.where(new_solution == 0)[0]\n    included_items = np.where(new_solution == 1)[0]\n\n    if len(excluded_items) > 0 and len(included_items) > 0:\n        decision = random.choices(['add', 'remove', 'swap'], weights=[0.4, 0.3, 0.3])[0]\n\n        if decision == 'add':\n            # Add the best excluded item based on combined marginal gain\n            excluded_sorted = sorted(excluded_items, key=lambda x: marginal_combined[x], reverse=True)\n            for item in excluded_sorted:\n                if np.sum(weight_lst[new_solution == 1]) + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                    break\n\n        elif decision == 'remove':\n            # Remove the least marginal item in either objective\n            included_sorted = sorted(included_items, key=lambda x: min(marginal_value1[x], marginal_value2[x]))\n            for item in included_sorted:\n                if np.sum(weight_lst[new_solution == 1]) - weight_lst[item] >= 0:\n                    new_solution[item] = 0\n                    break\n\n        elif decision == 'swap':\n            # Swap one excluded with one included item\n            swap_excluded = random.choice(excluded_items)\n            swap_included = random.choice(included_items)\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            new_weight = current_weight - weight_lst[swap_included] + weight_lst[swap_excluded]\n            if new_weight <= capacity:\n                new_solution[swap_included] = 0\n                new_solution[swap_excluded] = 1\n\n    # If no swap possible, try to add the best excluded item\n    else:\n        excluded_items = np.where(new_solution == 0)[0]\n        if len(excluded_items) > 0:\n            excluded_sorted = sorted(excluded_items, key=lambda x: marginal_combined[x], reverse=True)\n            for item in excluded_sorted:\n                if np.sum(weight_lst[new_solution == 1]) + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                    break\n\n    return new_solution\n\n",
        "metric_score": [
            -1.002058205017338,
            1.9492744207382202
        ],
        "raw_score": [
            27.19939705469744,
            27.641547598415023
        ]
    },
    {
        "algorithm": "The algorithm selects the most promising solution from the archive using a hypervolume-aware metric, then applies a multi-phase local search combining Pareto frontier exploration (60% chance) with frontier-aware flips and marginal contribution analysis, or diversity-aware perturbation (40% chance) with adaptive neighborhood swaps, ensuring feasibility through weight checks. If no improvement is found, it intensifies search by removing the least valuable included items. The approach balances exploration and exploitation while prioritizing solutions with high hypervolume contributions and marginal value improvements.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hypervolume-aware solution selection\n    def hypervolume(obj1, obj2, ref_point):\n        return (ref_point[0] - obj1) * (ref_point[1] - obj2)\n\n    max_hv = -1\n    best_idx = 0\n    ref_point = (np.max([obj[0] for _, obj in archive]), np.max([obj[1] for _, obj in archive]))\n\n    for i, (solution, obj) in enumerate(archive):\n        hv = hypervolume(obj[0], obj[1], ref_point)\n        if hv > max_hv:\n            max_hv = hv\n            best_idx = i\n\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Multi-phase local search\n    if random.random() < 0.6:  # 60% chance for frontier exploration\n        # Pareto frontier-aware flips\n        frontier_items = np.where(new_solution == 1)[0]\n        non_frontier_items = np.where(new_solution == 0)[0]\n\n        if len(frontier_items) > 0 and len(non_frontier_items) > 0:\n            # Calculate marginal contributions\n            frontier_marginal = (value1_lst[frontier_items] + value2_lst[frontier_items]) / weight_lst[frontier_items]\n            non_frontier_marginal = (value1_lst[non_frontier_items] + value2_lst[non_frontier_items]) / weight_lst[non_frontier_items]\n\n            # Find best swaps\n            best_frontier = frontier_items[np.argmin(frontier_marginal)]\n            best_non_frontier = non_frontier_items[np.argmax(non_frontier_marginal)]\n\n            # Check feasibility\n            new_weight = current_weight - weight_lst[best_frontier] + weight_lst[best_non_frontier]\n            if new_weight <= capacity:\n                new_solution[best_frontier] = 0\n                new_solution[best_non_frontier] = 1\n                current_weight = new_weight\n    else:  # 40% chance for diversity-aware perturbation\n        # Adaptive neighborhood search\n        num_perturbations = min(2, len(weight_lst) // 10)\n        perturb_indices = np.random.choice(len(weight_lst), size=num_perturbations, replace=False)\n\n        for idx in perturb_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Fallback mechanism: Pareto-aware intensification\n    if np.array_equal(new_solution, base_solution):\n        # Intensify search around current solution\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Find least valuable included item\n            included_marginal = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n            least_val_item = included_items[np.argmin(included_marginal)]\n\n            # Try to remove it\n            if current_weight - weight_lst[least_val_item] >= 0:\n                new_solution[least_val_item] = 0\n                current_weight -= weight_lst[least_val_item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8962181579365913,
            0.19705554842948914
        ],
        "raw_score": [
            26.959826063541488,
            27.544373065968784
        ]
    },
    {
        "algorithm": "The algorithm selects the most promising solution from the archive (based on normalized marginal gains) and applies a hybrid local search (60% flips, 40% swaps) with adaptive weights (higher priority to the weaker objective). It ensures feasibility by removing least marginal items if no improvement is found, prioritizing balanced improvements across both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest normalized sum of marginal gains\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    best_idx = max(range(len(archive)), key=lambda i: (archive[i][1][0] + archive[i][1][1]) / (max_obj1 + max_obj2 + 1e-10))\n\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate marginal contributions with adaptive weights\n    marginal_value1 = value1_lst - (base_solution * value1_lst)\n    marginal_value2 = value2_lst - (base_solution * value2_lst)\n\n    # Adaptive weights based on objective dominance\n    total_value1 = np.sum(value1_lst[base_solution == 1])\n    total_value2 = np.sum(value2_lst[base_solution == 1])\n    weight_obj1 = 1.0 if total_value1 < total_value2 else 0.7\n    weight_obj2 = 1.0 if total_value2 < total_value1 else 0.7\n\n    marginal_combined = weight_obj1 * marginal_value1 + weight_obj2 * marginal_value2\n\n    # Hybrid local search with probabilistic operations\n    decision = random.choices(['flip', 'swap'], weights=[0.6, 0.4])[0]\n\n    if decision == 'flip':\n        # Flip items with highest marginal gain while maintaining feasibility\n        sorted_indices = np.argsort(-marginal_combined)\n        for idx in sorted_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    else:  # swap\n        # Swap items with high and low marginal gains\n        high_marginal = np.argsort(-marginal_combined)[:len(weight_lst)//3]\n        low_marginal = np.argsort(marginal_combined)[:len(weight_lst)//3]\n\n        for h in high_marginal:\n            for l in low_marginal:\n                if new_solution[h] == 1 and new_solution[l] == 0:\n                    new_weight = current_weight - weight_lst[h] + weight_lst[l]\n                    if new_weight <= capacity:\n                        new_solution[h], new_solution[l] = 0, 1\n                        current_weight = new_weight\n                        break\n            else:\n                continue\n            break\n\n    # If no improvement, remove least marginal items to ensure feasibility\n    if np.array_equal(new_solution, base_solution):\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            sorted_items = sorted(included_items, key=lambda x: marginal_value1[x] + marginal_value2[x])\n            for item in sorted_items:\n                if current_weight - weight_lst[item] >= 0:\n                    new_solution[item] = 0\n                    current_weight -= weight_lst[item]\n                    break\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9514271204468423,
            0.9768357276916504
        ],
        "raw_score": [
            27.865390153322615,
            28.203870181276848
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using adaptive Pareto dominance with value-to-weight ratio prioritization\n    selected_idx = 0\n    max_dominance = -1\n\n    for i, (solution, objective) in enumerate(archive):\n        excluded_items = np.where(solution == 0)[0]\n        included_items = np.where(solution == 1)[0]\n\n        if len(excluded_items) == 0 or len(included_items) == 0:\n            continue\n\n        # Calculate marginal gains for excluded items\n        marginal_gains1 = value1_lst[excluded_items] / weight_lst[excluded_items]\n        marginal_gains2 = value2_lst[excluded_items] / weight_lst[excluded_items]\n\n        # Calculate dominance score with value-to-weight ratio emphasis\n        dominance = np.sum(marginal_gains1) + np.sum(marginal_gains2) + 0.3 * len(excluded_items)\n        if dominance > max_dominance:\n            max_dominance = dominance\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Hybrid local search with probabilistic perturbations (60% flip, 30% swap, 10% random)\n    operation = random.choices(['flip', 'swap', 'random'], weights=[0.6, 0.3, 0.1])[0]\n\n    if operation == 'flip':\n        # Calculate marginal contributions for all items\n        marginal_value1 = value1_lst - (base_solution * value1_lst)\n        marginal_value2 = value2_lst - (base_solution * value2_lst)\n        marginal_combined = marginal_value1 + marginal_value2\n\n        # Sort items by marginal contribution (descending)\n        sorted_indices = np.argsort(-marginal_combined)\n\n        # Try to flip items with high marginal contribution\n        for idx in sorted_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    elif operation == 'swap':\n        excluded_items = np.where(new_solution == 0)[0]\n        included_items = np.where(new_solution == 1)[0]\n\n        if len(excluded_items) > 0 and len(included_items) > 0:\n            # Calculate value-to-weight ratios\n            excluded_ratios = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n            included_ratios = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n\n            # Find best swap candidates\n            best_excluded = excluded_items[np.argmax(excluded_ratios)]\n            worst_included = included_items[np.argmin(included_ratios)]\n\n            # Check feasibility\n            new_weight = current_weight - weight_lst[worst_included] + weight_lst[best_excluded]\n            if new_weight <= capacity:\n                new_solution[worst_included] = 0\n                new_solution[best_excluded] = 1\n            else:\n                # Greedy removal if swap is infeasible\n                included_sorted = sorted(included_items, key=lambda x: (value1_lst[x] + value2_lst[x]) / weight_lst[x])\n                for item in included_sorted:\n                    if current_weight - weight_lst[item] >= 0:\n                        new_solution[item] = 0\n                        current_weight -= weight_lst[item]\n                        break\n\n    else:  # random operation\n        # Randomly select an item to flip\n        item = random.randint(0, len(base_solution) - 1)\n        if base_solution[item] == 1:\n            if current_weight - weight_lst[item] >= 0:\n                new_solution[item] = 0\n        else:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9203519748969622,
            0.8286850452423096
        ],
        "raw_score": [
            27.281622249252226,
            28.362586948017658
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive prioritizing those with high combined marginal gains in both objectives, then applies a hybrid local search combining adaptive probabilistic flipping (70%) and swapping (30%) operations, dynamically adjusting perturbation rates based on solution quality and ensuring feasibility through greedy removal of low-marginal items if capacity is exceeded. It balances exploration and exploitation by favoring high-marginal items for inclusion and low-marginal items for exclusion, with adaptive probabilities that decrease with solution quality.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest combined marginal gain in both objectives\n    selected_idx = 0\n    max_marginal_gain = -1\n    current_weight = np.sum(weight_lst[archive[0][0] == 1])\n\n    for i, (solution, objective) in enumerate(archive):\n        included_items = np.where(solution == 1)[0]\n        excluded_items = np.where(solution == 0)[0]\n\n        # Calculate marginal gains for included items\n        if len(included_items) > 0:\n            included_marginal1 = value1_lst[included_items] / weight_lst[included_items]\n            included_marginal2 = value2_lst[included_items] / weight_lst[included_items]\n            min_included_gain = np.min(included_marginal1 + included_marginal2)\n        else:\n            min_included_gain = 0\n\n        # Calculate marginal gains for excluded items\n        if len(excluded_items) > 0:\n            excluded_marginal1 = value1_lst[excluded_items] / weight_lst[excluded_items]\n            excluded_marginal2 = value2_lst[excluded_items] / weight_lst[excluded_items]\n            max_excluded_gain = np.max(excluded_marginal1 + excluded_marginal2)\n        else:\n            max_excluded_gain = 0\n\n        combined_gain = max_excluded_gain - min_included_gain\n\n        if combined_gain > max_marginal_gain:\n            max_marginal_gain = combined_gain\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search with adaptive perturbation rates\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    # Calculate solution quality (normalized)\n    if len(included_items) > 0:\n        solution_quality = np.sum(value1_lst[included_items] + value2_lst[included_items]) / (capacity * 2)\n    else:\n        solution_quality = 0\n\n    # Adjust perturbation probabilities based on solution quality\n    flip_prob = 0.7 * (1 - solution_quality)\n    swap_prob = 0.3 * (1 - solution_quality)\n\n    if random.random() < flip_prob and len(included_items) > 0 and len(excluded_items) > 0:\n        # Flip operation (adaptive probability)\n        # Select low-marginal included item\n        included_marginal = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n        flip_candidate = included_items[np.argmin(included_marginal)]\n\n        # Find best excluded item to add\n        excluded_marginal = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n        excluded_sorted = excluded_items[np.argsort(-excluded_marginal)]\n\n        for item in excluded_sorted:\n            if current_weight - weight_lst[flip_candidate] + weight_lst[item] <= capacity:\n                new_solution[flip_candidate] = 0\n                new_solution[item] = 1\n                break\n    elif random.random() < swap_prob and len(included_items) > 0 and len(excluded_items) > 0:\n        # Swap operation (adaptive probability)\n        # Select low-marginal included item\n        included_marginal = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n        swap_included = included_items[np.argmin(included_marginal)]\n\n        # Select high-marginal excluded item\n        excluded_marginal = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n        swap_excluded = excluded_items[np.argmax(excluded_marginal)]\n\n        # Check feasibility\n        if current_weight - weight_lst[swap_included] + weight_lst[swap_excluded] <= capacity:\n            new_solution[swap_included] = 0\n            new_solution[swap_excluded] = 1\n\n    # Dynamic feasibility check: remove low-marginal items if over capacity\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    while current_weight > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        included_marginal = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n        remove_candidate = included_items[np.argmin(included_marginal)]\n        new_solution[remove_candidate] = 0\n        current_weight -= weight_lst[remove_candidate]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9253254076360551,
            0.8825206160545349
        ],
        "raw_score": [
            27.392082242290748,
            27.994851382912653
        ]
    },
    {
        "algorithm": "The algorithm combines adaptive Pareto selection with a hybrid local search that uses probabilistic flips (60%) and value-balancing swaps (40%), dynamically adjusting operation probabilities based on solution sparsity. It prioritizes items with high marginal gains in both objectives, using normalized marginal contributions with adaptive weights to balance value1 and value2, while ensuring feasibility through greedy removal of least marginal items when needed. The selection criterion favors solutions with high combined marginal gains and balanced value distributions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest combined marginal gains and balanced value distribution\n    selected_idx = 0\n    max_score = -1\n\n    for i, (solution, objective) in enumerate(archive):\n        included = solution == 1\n        excluded = solution == 0\n\n        if not np.any(included) or not np.any(excluded):\n            continue\n\n        # Calculate marginal gains for excluded items\n        marginal_gains1 = value1_lst[excluded] / (weight_lst[excluded] + 1e-6)\n        marginal_gains2 = value2_lst[excluded] / (weight_lst[excluded] + 1e-6)\n\n        # Calculate value balance score\n        total_value1 = objective[0]\n        total_value2 = objective[1]\n        value_balance = 1 - abs(total_value1 - total_value2) / (total_value1 + total_value2 + 1e-6)\n\n        # Combine marginal gains and value balance\n        score = (np.sum(marginal_gains1) + np.sum(marginal_gains2)) * (1 + value_balance)\n\n        if score > max_score:\n            max_score = score\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Hybrid local search with dynamic operation probabilities\n    flip_prob = 0.6\n    swap_prob = 0.4\n    if np.sum(base_solution) < len(base_solution) * 0.2:  # More exploration when solution is sparse\n        flip_prob = 0.7\n        swap_prob = 0.3\n\n    operation = random.choices(['flip', 'swap'], weights=[flip_prob, swap_prob])[0]\n\n    if operation == 'flip':\n        # Calculate marginal contributions for all items\n        marginal_value1 = value1_lst - (base_solution * value1_lst)\n        marginal_value2 = value2_lst - (base_solution * value2_lst)\n\n        # Calculate normalized marginal gains\n        max_marginal1 = np.max(marginal_value1) if np.any(marginal_value1) else 1\n        max_marginal2 = np.max(marginal_value2) if np.any(marginal_value2) else 1\n\n        normalized_marginal1 = marginal_value1 / max_marginal1\n        normalized_marginal2 = marginal_value2 / max_marginal2\n\n        # Combine normalized marginal gains with adaptive weights\n        total_value1 = np.sum(value1_lst[base_solution == 1])\n        total_value2 = np.sum(value2_lst[base_solution == 1])\n        weight_obj1 = 1.0 if total_value1 < total_value2 else 0.6\n        weight_obj2 = 1.0 if total_value2 < total_value1 else 0.6\n\n        marginal_combined = weight_obj1 * normalized_marginal1 + weight_obj2 * normalized_marginal2\n\n        # Sort items by combined marginal contribution (descending)\n        sorted_indices = np.argsort(-marginal_combined)\n\n        # Try to flip items with high marginal contribution\n        for idx in sorted_indices:\n            if base_solution[idx] == 1:\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    else:  # value-balancing swap\n        included_items = np.where(new_solution == 1)[0]\n        excluded_items = np.where(new_solution == 0)[0]\n\n        if len(included_items) > 0 and len(excluded_items) > 0:\n            # Calculate value balance potential for included items\n            value_balance = (value1_lst[included_items] - value2_lst[included_items]) / (value1_lst[included_items] + value2_lst[included_items] + 1e-6)\n\n            # Find most imbalanced included item\n            worst_included = included_items[np.argmax(np.abs(value_balance))]\n\n            # Find best excluded item based on opposite marginal need\n            if value_balance[np.argmax(np.abs(value_balance))] > 0:\n                # Need more value2\n                marginal_criteria = value2_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n            else:\n                # Need more value1\n                marginal_criteria = value1_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n\n            best_excluded = excluded_items[np.argmax(marginal_criteria)]\n\n            # Check feasibility\n            new_weight = current_weight - weight_lst[worst_included] + weight_lst[best_excluded]\n            if new_weight <= capacity:\n                new_solution[worst_included] = 0\n                new_solution[best_excluded] = 1\n            else:\n                # Adaptive greedy removal if swap is infeasible\n                included_sorted = sorted(included_items, key=lambda x: (value1_lst[x] + value2_lst[x]) / (weight_lst[x] + 1e-6))\n                for item in included_sorted:\n                    if current_weight - weight_lst[item] >= 0:\n                        new_solution[item] = 0\n                        current_weight -= weight_lst[item]\n                        break\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9781888634903011,
            1.3077029585838318
        ],
        "raw_score": [
            27.20729109509217,
            27.754358929629916
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest combined marginal gains and high diversity potential\n    selected_idx = 0\n    max_marginal_gain = -1\n    max_diversity = -1\n\n    for i, (solution, objective) in enumerate(archive):\n        current_weight = np.sum(weight_lst[solution == 1])\n        excluded_items = np.where(solution == 0)[0]\n\n        # Calculate marginal gains for excluded items\n        marginal_gains1 = value1_lst[excluded_items] / weight_lst[excluded_items]\n        marginal_gains2 = value2_lst[excluded_items] / weight_lst[excluded_items]\n        combined_gain_excluded = np.sum(marginal_gains1) + np.sum(marginal_gains2)\n\n        # Calculate diversity potential (number of items not in the current solution)\n        diversity = len(excluded_items)\n\n        total_score = combined_gain_excluded * diversity\n        if total_score > max_marginal_gain or (total_score == max_marginal_gain and diversity > max_diversity):\n            max_marginal_gain = total_score\n            max_diversity = diversity\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: probabilistic flip with value-to-weight ratio and diversity-aware swaps\n    flip_prob = 0.6\n    if np.random.random() < flip_prob:\n        # Value-to-weight ratio based flip\n        excluded_items = np.where(new_solution == 0)[0]\n        if len(excluded_items) > 0:\n            ratios = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n            selected_item = np.random.choice(excluded_items, p=ratios/np.sum(ratios))\n\n            if np.sum(weight_lst[new_solution == 1]) + weight_lst[selected_item] <= capacity:\n                new_solution[selected_item] = 1\n    else:\n        # Diversity-aware swap: swap a high-value item with a low-value excluded item\n        included_items = np.where(new_solution == 1)[0]\n        excluded_items = np.where(new_solution == 0)[0]\n\n        if len(included_items) > 0 and len(excluded_items) > 0:\n            # Select high-value included item\n            high_value_item = np.argmax((value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items])\n            high_value_item = included_items[high_value_item]\n\n            # Select low-value excluded item\n            low_value_item = np.argmin((value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items])\n            low_value_item = excluded_items[low_value_item]\n\n            # Check feasibility and swap\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            new_weight = current_weight - weight_lst[high_value_item] + weight_lst[low_value_item]\n\n            if new_weight <= capacity:\n                new_solution[high_value_item] = 0\n                new_solution[low_value_item] = 1\n\n    # If no improvement, perform a probabilistic perturbation to escape local optima\n    if np.array_equal(new_solution, base_solution):\n        perturbation_rate = min(0.3, max_marginal_gain / (np.sum(value1_lst) + np.sum(value2_lst)))\n        if np.random.random() < perturbation_rate:\n            candidates = [i for i in range(len(weight_lst)) if (new_solution[i] == 1 and np.sum(weight_lst[new_solution == 1]) - weight_lst[i] >= 0) or\n                         (new_solution[i] == 0 and np.sum(weight_lst[new_solution == 1]) + weight_lst[i] <= capacity)]\n            if candidates:\n                idx = np.random.choice(candidates)\n                new_solution[idx] = 1 - new_solution[idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9614967420754377,
            1.5302500426769257
        ],
        "raw_score": [
            26.967240128335717,
            27.494577329075724
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest normalized objective product (balancing both objectives)\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        best_idx = 0\n    else:\n        best_idx = max(range(len(archive)), key=lambda i: (archive[i][1][0] * archive[i][1][1]) / (max_obj1 * max_obj2))\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate normalized marginal gains for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    marginal_norm1 = marginal_gain1 / (np.max(marginal_gain1) + 1e-10)\n    marginal_norm2 = marginal_gain2 / (np.max(marginal_gain2) + 1e-10)\n\n    # Combine marginal gains with adaptive weights based on solution's current performance\n    weight_obj1 = 1.0 if np.sum(value1_lst[base_solution == 1]) < 0.7 * max_obj1 else 0.5\n    weight_obj2 = 1.0 if np.sum(value2_lst[base_solution == 1]) < 0.7 * max_obj2 else 0.5\n    combined_marginal = weight_obj1 * marginal_norm1 + weight_obj2 * marginal_norm2\n\n    # Sort items by combined marginal gain and attempt to flip top candidates\n    sorted_indices = np.argsort(-combined_marginal)\n    for idx in sorted_indices[:max(1, len(weight_lst)//10)]:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # If no improvement, perform a targeted swap between high-marginal and low-marginal items\n    if np.array_equal(new_solution, base_solution):\n        high_marginal = np.argsort(-combined_marginal)[:len(weight_lst)//2]\n        low_marginal = np.argsort(combined_marginal)[:len(weight_lst)//2]\n\n        for h in high_marginal:\n            for l in low_marginal:\n                if new_solution[h] == 1 and new_solution[l] == 0:\n                    new_weight = current_weight - weight_lst[h] + weight_lst[l]\n                    if new_weight <= capacity:\n                        new_solution[h], new_solution[l] = 0, 1\n                        current_weight = new_weight\n                        break\n            else:\n                continue\n            break\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8522335976313615,
            0.24278834462165833
        ],
        "raw_score": [
            27.69394350063845,
            28.12451233846662
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive based on a weighted combination of normalized objectives, then performs a hybrid local search by iteratively flipping items with the highest marginal contribution to both objectives, while dynamically adjusting weights to prioritize underperforming objectives and ensuring feasibility. It also includes a diversification step to escape local optima by randomly flipping an item if no improvement is found. The key design ideas are adaptive objective weighting, marginal contribution-based flipping, and a diversification mechanism to enhance solution quality.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest weighted sum of objectives (adaptive weights)\n    max_obj1 = max(obj[0] for _, obj in archive)\n    max_obj2 = max(obj[1] for _, obj in archive)\n    if max_obj1 == 0 or max_obj2 == 0:\n        best_idx = 0\n    else:\n        best_idx = max(range(len(archive)), key=lambda i: (archive[i][1][0]/max_obj1 + archive[i][1][1]/max_obj2))\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Calculate normalized marginal contributions\n    marginal_value1 = value1_lst - (base_solution * value1_lst)\n    marginal_value2 = value2_lst - (base_solution * value2_lst)\n    marginal_norm1 = marginal_value1 / (np.max(marginal_value1) + 1e-10)\n    marginal_norm2 = marginal_value2 / (np.max(marginal_value2) + 1e-10)\n\n    # Adaptive weight based on current solution's performance\n    weight_obj1 = 1.0 if current_value1 < 0.5 * max_obj1 else 0.7\n    weight_obj2 = 1.0 if current_value2 < 0.5 * max_obj2 else 0.7\n    marginal_combined = weight_obj1 * marginal_norm1 + weight_obj2 * marginal_norm2\n\n    # Sort items by combined marginal contribution\n    sorted_indices = np.argsort(-marginal_combined)\n\n    # Try to flip items with high marginal contribution\n    for idx in sorted_indices:\n        if base_solution[idx] == 1:\n            # Try to remove item\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try to add item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Additional diversification: flip one random item if no improvement\n    if np.array_equal(new_solution, base_solution):\n        candidates = [i for i in range(len(weight_lst)) if (base_solution[i] == 1 and current_weight - weight_lst[i] >= 0) or\n                     (base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if candidates:\n            idx = np.random.choice(candidates)\n            new_solution[idx] = 1 - new_solution[idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9034034519201828,
            0.4050176739692688
        ],
        "raw_score": [
            27.177010817087208,
            27.878927497500193
        ]
    }
]